{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lib import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import load_metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dts):\n",
    "    path = f'MuP_dataset/{dts}_complete.jsonl'\n",
    "    try:\n",
    "        with open(path, 'r') as json_file:\n",
    "            json_list = list(json_file)\n",
    "        col_name = [\"paper_id\",\"summary\"]\n",
    "    except:\n",
    "        print(f\"Warning: Did not load dataset from {path}\")\n",
    "        return\n",
    "    summary_df = pd.DataFrame(columns=col_name)\n",
    "    for json_str in json_list[:]:\n",
    "        result = json.loads(json_str)\n",
    "        df = pd.DataFrame([[result[\"paper_id\"], result[\"summary\"]]], columns=col_name)\n",
    "        summary_df = pd.concat([summary_df,df])\n",
    "    return summary_df\n",
    "\n",
    "def split_sum_num(df):\n",
    "    num_paper = df.groupby(['paper_id']).count()\n",
    "    num_paper['num_paper'] = 1\n",
    "    num_paper.groupby(['summary']).count()\n",
    "    num_paper = df.groupby(['paper_id']).count()\n",
    "    num_paper['num_paper'] = 1\n",
    "    num_paper.groupby(['summary']).count()\n",
    "    num_paper.drop('num_paper', inplace=True,axis=1)\n",
    "    num_paper.sort_values([\"summary\"])\n",
    "\n",
    "    df_list = []\n",
    "    for i in range(0, max(num_paper['summary'])):\n",
    "        paper_id = (list((num_paper[num_paper[\"summary\"]==(i+1)]).index))\n",
    "        df_i = df[df.paper_id.isin(paper_id)].sort_values(\"paper_id\")\n",
    "        df_list.append(df_i.groupby('paper_id').apply(lambda df_: df_[['summary']].values.flatten()).apply(pd.Series).reset_index())\n",
    "        \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts = \"training\"\n",
    "summary_df = load_data(dts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = split_sum_num(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_scores(df, subscore_col):\n",
    "    n = len(df.columns)-1\n",
    "    pairs = [f'{i}-{j}' for i in range(n) for j in range(i+1, n)]\n",
    "    col = pd.MultiIndex.from_product([subscore_col, pairs])\n",
    "    scores = pd.DataFrame(columns=col)\n",
    "    scores.insert(0, \"paper_id\", df[\"paper_id\"])\n",
    "    # scores.set_index(\"paper_id\", inplace=True)\n",
    "    return scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rougescore = load(\"rouge\")\n",
    "rougescore = load_metric(\"rouge\")\n",
    "\n",
    "def rouge_cal(df):\n",
    "    n = len(df.columns)-1\n",
    "    print(f\"Calculating ROUGE on {n} summaries\")\n",
    "\n",
    "    rouge_list = ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
    "    score_list = ['precision', 'recall', 'fmeasure']\n",
    "\n",
    "    df_score_dict = {}\n",
    "    mux = pd.MultiIndex.from_product([[\"summary\"],(list(df.columns))[1:]])\n",
    "    df_score = pd.DataFrame(columns=mux)\n",
    "    df_score.insert(0, \"paper_id\", df[\"paper_id\"])\n",
    "    for col in df:\n",
    "        if col != 'paper_id':\n",
    "            df_score[('summary', col)] = df[col]\n",
    "    df_score = df_score.merge(n_scores(df, score_list), left_on='paper_id', right_on='paper_id')\n",
    "    for r in rouge_list:\n",
    "        df_score_dict[r] = df_score\n",
    "\n",
    "    df_len = len(df)\n",
    "    for idx, row in df.iterrows():\n",
    "        sys.stdout.write(f\"\\r{idx+1}/{df_len}\")\n",
    "        sys.stdout.flush()\n",
    "        for i in range(n):\n",
    "            for j in range(i+1,n):\n",
    "                pair = f'{i}-{j}'\n",
    "                score = rougescore.compute(predictions=[row[i]], references=[row[j]], use_stemmer=False)\n",
    "                for r in rouge_list:\n",
    "                    df_score_dict[r].loc[idx, ('precision', pair)] = ((score[r]).low).precision\n",
    "                    df_score_dict[r].loc[idx, ('recall', pair)] = ((score[r]).low).recall\n",
    "                    df_score_dict[r].loc[idx, ('fmeasure', pair)] = ((score[r]).low).fmeasure\n",
    "\n",
    "    return df_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, df in enumerate(df_list):\n",
    "    if n+1 > 1:\n",
    "        dict_result = rouge_cal(df)\n",
    "        for key, val in dict_result.items():\n",
    "            val.to_csv(f\"visualization_data/rouge-between-sum/{key}/{dts}_{key}_{n+1}sum.csv\")\n",
    "dict_result['rouge1']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BERTScore on 3 summaries\n",
      "0-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zw/q5kx3f693rgfk0h2y_jgmhnm0000gn/T/ipykernel_26093/3945739358.py:14: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_score = df_score.merge(n_scores(df, score_list), left_on='paper_id', right_on='paper_id')\n",
      "/var/folders/zw/q5kx3f693rgfk0h2y_jgmhnm0000gn/T/ipykernel_26093/3945739358.py:25: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_score.loc[:, (score, pair)] = result[score]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th colspan=\"3\" halign=\"left\">summary</th>\n",
       "      <th colspan=\"3\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"3\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"3\" halign=\"left\">f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0-1</th>\n",
       "      <th>0-2</th>\n",
       "      <th>1-2</th>\n",
       "      <th>0-1</th>\n",
       "      <th>0-2</th>\n",
       "      <th>1-2</th>\n",
       "      <th>0-1</th>\n",
       "      <th>0-2</th>\n",
       "      <th>1-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:001ae7379191bb40fc356a37deb2f0ffc4426e52</td>\n",
       "      <td>This paper proposes EgoTR for cross-view geo-l...</td>\n",
       "      <td>The paper tackles the cross-view geo-localizat...</td>\n",
       "      <td>This paper proposes to use transformer for cro...</td>\n",
       "      <td>0.224304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.056118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.140213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:0045d9a733e9d3db6e42c4fcadaa7dc57f7b5004</td>\n",
       "      <td>This paper considers the problem of generaliza...</td>\n",
       "      <td>This paper aims to design a counterfactual rei...</td>\n",
       "      <td>The paper presents a method to improve the gen...</td>\n",
       "      <td>-0.104706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.213069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:0055dca69c153ed21b420741c479a2ef00be2ef6</td>\n",
       "      <td>This paper compares the so-called \"State Evolu...</td>\n",
       "      <td>This paper considers the state evolution equat...</td>\n",
       "      <td>This paper provides derivations of equivalence...</td>\n",
       "      <td>0.054633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.191037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.123345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      paper_id  \\\n",
       "                                                 \n",
       "0  SP:001ae7379191bb40fc356a37deb2f0ffc4426e52   \n",
       "1  SP:0045d9a733e9d3db6e42c4fcadaa7dc57f7b5004   \n",
       "2  SP:0055dca69c153ed21b420741c479a2ef00be2ef6   \n",
       "\n",
       "                                             summary  \\\n",
       "                                                   0   \n",
       "0  This paper proposes EgoTR for cross-view geo-l...   \n",
       "1  This paper considers the problem of generaliza...   \n",
       "2  This paper compares the so-called \"State Evolu...   \n",
       "\n",
       "                                                      \\\n",
       "                                                   1   \n",
       "0  The paper tackles the cross-view geo-localizat...   \n",
       "1  This paper aims to design a counterfactual rei...   \n",
       "2  This paper considers the state evolution equat...   \n",
       "\n",
       "                                                     precision            \\\n",
       "                                                   2       0-1  0-2  1-2   \n",
       "0  This paper proposes to use transformer for cro...  0.224304  NaN  NaN   \n",
       "1  The paper presents a method to improve the gen... -0.104706  NaN  NaN   \n",
       "2  This paper provides derivations of equivalence...  0.054633  NaN  NaN   \n",
       "\n",
       "     recall                  f1            \n",
       "        0-1  0-2  1-2       0-1  0-2  1-2  \n",
       "0  0.056118  NaN  NaN  0.140213  NaN  NaN  \n",
       "1  0.213069  NaN  NaN  0.050674  NaN  NaN  \n",
       "2  0.191037  NaN  NaN  0.123345  NaN  NaN  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore = load(\"bertscore\")\n",
    "def bertscore_cal(df):\n",
    "    n = len(df.columns)-1\n",
    "    print(f\"Calculating BERTScore on {n} summaries\")\n",
    "    \n",
    "    score_list = ['precision', 'recall', 'f1']\n",
    "\n",
    "    mux = pd.MultiIndex.from_product([[\"summary\"],(list(df.columns))[1:]])\n",
    "    df_score = pd.DataFrame(columns=mux)\n",
    "    df_score.insert(0, \"paper_id\", df[\"paper_id\"])\n",
    "    for col in df:\n",
    "        if col != 'paper_id':\n",
    "            df_score[('summary', col)] = df[col]\n",
    "    df_score = df_score.merge(n_scores(df, score_list), left_on='paper_id', right_on='paper_id')\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n-1):\n",
    "            pair = f'{i}-{j}'\n",
    "            summary1 = list(df_score.loc[:, ('summary', i)])\n",
    "            summary2 = list(df_score.loc[:, ('summary', j)])\n",
    "            print(pair)\n",
    "            result = bertscore.compute(predictions=summary1, references=summary2, lang=\"en\", rescale_with_baseline=True)\n",
    "            for score in score_list:\n",
    "                df_score.loc[:, (score, pair)] = result[score]\n",
    "\n",
    "    return df_score\n",
    "    \n",
    "bertscore_cal(df_list[2][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, df in enumerate(df_list):\n",
    "    if n+1 > 1:\n",
    "        result = bertscore_cal(df)\n",
    "        val.to_csv(f\"visualization_data/bertscore-between-sum/{dts}_bertscore_{n+1}sum.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c41a15a33a59f0eeae9566b7a824606ae2e90e5c5eb8240ec6145ee367642a6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
