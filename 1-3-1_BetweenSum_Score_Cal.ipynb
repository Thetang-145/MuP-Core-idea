{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lib import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import load_metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dts):\n",
    "    path = f'MuP_dataset/{dts}_complete.jsonl'\n",
    "    try:\n",
    "        with open(path, 'r') as json_file:\n",
    "            json_list = list(json_file)\n",
    "        col_name = [\"paper_id\",\"summary\"]\n",
    "    except:\n",
    "        print(f\"Warning: Did not load dataset from {path}\")\n",
    "        return\n",
    "    summary_df = pd.DataFrame(columns=col_name)\n",
    "    for json_str in json_list[:]:\n",
    "        result = json.loads(json_str)\n",
    "        df = pd.DataFrame([[result[\"paper_id\"], result[\"summary\"]]], columns=col_name)\n",
    "        summary_df = pd.concat([summary_df,df])\n",
    "    return summary_df\n",
    "\n",
    "def split_sum_num(df):\n",
    "    num_paper = df.groupby(['paper_id']).count()\n",
    "    num_paper['num_paper'] = 1\n",
    "    num_paper.groupby(['summary']).count()\n",
    "    num_paper = df.groupby(['paper_id']).count()\n",
    "    num_paper['num_paper'] = 1\n",
    "    num_paper.groupby(['summary']).count()\n",
    "    num_paper.drop('num_paper', inplace=True,axis=1)\n",
    "    num_paper.sort_values([\"summary\"])\n",
    "\n",
    "    df_list = []\n",
    "    for i in range(0, max(num_paper['summary'])):\n",
    "        paper_id = (list((num_paper[num_paper[\"summary\"]==(i+1)]).index))\n",
    "        df_i = df[df.paper_id.isin(paper_id)].sort_values(\"paper_id\")\n",
    "        df_list.append(df_i.groupby('paper_id').apply(lambda df_: df_[['summary']].values.flatten()).apply(pd.Series).reset_index())\n",
    "        \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts = \"training\"\n",
    "summary_df = load_data(dts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = split_sum_num(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:00130f3b3a6b3b71f9b487003a18b43517cacbbb</td>\n",
       "      <td>This work proposes a new method for subgame so...</td>\n",
       "      <td>This paper proposes a novel technique for sear...</td>\n",
       "      <td>The authors develop a new approximation to for...</td>\n",
       "      <td>This paper deals with two related problems. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:00215e91570b72ae8202535812037e710e766253</td>\n",
       "      <td>The paper studies continual learning and that ...</td>\n",
       "      <td>The paper learns the binary basis mask for a f...</td>\n",
       "      <td>The paper describes an approach to continual l...</td>\n",
       "      <td>In the current paper, the authors propose a no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:006a99a453b861691e5ea2c02012a2aef44d393e</td>\n",
       "      <td>The paper considers the setting in which a sin...</td>\n",
       "      <td>This paper proposes a single-actor, multi-crit...</td>\n",
       "      <td>This paper proposes to extend the actor-critic...</td>\n",
       "      <td>The paper introduces a variant of actor-critic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:006e9fb3f4bd9fce1b751e6491f93ca9a918b1d0</td>\n",
       "      <td>Summary. Prior works have used auxiliary tasks...</td>\n",
       "      <td>This work proposes random General Value Functi...</td>\n",
       "      <td>Summary -------  Owing to the importance of st...</td>\n",
       "      <td>This paper introduces a new auxiliary task for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:008b937acb21afd5449982967b6daac37b4134ab</td>\n",
       "      <td>This paper studies a relatively little-concern...</td>\n",
       "      <td>This paper studies positive and unlabeled (PU)...</td>\n",
       "      <td>This paper addresses the problem of class-prio...</td>\n",
       "      <td>This paper studies the prior $\\pi$ in PU learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>SP:ff321c62ff012f2a3c4fb02f9ba95daee33636f0</td>\n",
       "      <td>In this work, the authors propose a new featur...</td>\n",
       "      <td>The paper proposes an infinite-width parameter...</td>\n",
       "      <td>The authors study a certain variant of an MLP ...</td>\n",
       "      <td>The paper introduces an approach (named pi-lim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>SP:ff608359d72b2fd9207c2c8d86282ace1d8b619b</td>\n",
       "      <td>This paper proposes a defense method against p...</td>\n",
       "      <td>This paper studies the problem of certifying a...</td>\n",
       "      <td>This paper studied how to certificate a policy...</td>\n",
       "      <td>This paper proposes a certification method aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>SP:ff641ae83dfd806ab9770e37bd824e928c2b06a6</td>\n",
       "      <td>This paper has the following contributions: * ...</td>\n",
       "      <td>This paper introduces a neural network archite...</td>\n",
       "      <td>This paper proposes to use self-attention betw...</td>\n",
       "      <td>Deep parametric models have demonstrated treme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>SP:ffb273a8ad8895be2fcfa2af3cb2624617304de9</td>\n",
       "      <td>In this paper, the authors propose a novel S...</td>\n",
       "      <td>A method called LaGraph is proposed for semi-s...</td>\n",
       "      <td>The paper proposes a new self-supervised learn...</td>\n",
       "      <td>The authors propose a self-supervised learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>SP:ffd382a81da7298be3a1e5fe9dd539cb4c18658b</td>\n",
       "      <td>This paper proposes PoNet, an efficient model ...</td>\n",
       "      <td>In this paper, the authors aim to resolve the ...</td>\n",
       "      <td>This paper proposed PoNet, which is an efficie...</td>\n",
       "      <td>PoNet addresses the quadratic time and memory ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1113 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_id  \\\n",
       "0     SP:00130f3b3a6b3b71f9b487003a18b43517cacbbb   \n",
       "1     SP:00215e91570b72ae8202535812037e710e766253   \n",
       "2     SP:006a99a453b861691e5ea2c02012a2aef44d393e   \n",
       "3     SP:006e9fb3f4bd9fce1b751e6491f93ca9a918b1d0   \n",
       "4     SP:008b937acb21afd5449982967b6daac37b4134ab   \n",
       "...                                           ...   \n",
       "1108  SP:ff321c62ff012f2a3c4fb02f9ba95daee33636f0   \n",
       "1109  SP:ff608359d72b2fd9207c2c8d86282ace1d8b619b   \n",
       "1110  SP:ff641ae83dfd806ab9770e37bd824e928c2b06a6   \n",
       "1111  SP:ffb273a8ad8895be2fcfa2af3cb2624617304de9   \n",
       "1112  SP:ffd382a81da7298be3a1e5fe9dd539cb4c18658b   \n",
       "\n",
       "                                                      0  \\\n",
       "0     This work proposes a new method for subgame so...   \n",
       "1     The paper studies continual learning and that ...   \n",
       "2     The paper considers the setting in which a sin...   \n",
       "3     Summary. Prior works have used auxiliary tasks...   \n",
       "4     This paper studies a relatively little-concern...   \n",
       "...                                                 ...   \n",
       "1108  In this work, the authors propose a new featur...   \n",
       "1109  This paper proposes a defense method against p...   \n",
       "1110  This paper has the following contributions: * ...   \n",
       "1111    In this paper, the authors propose a novel S...   \n",
       "1112  This paper proposes PoNet, an efficient model ...   \n",
       "\n",
       "                                                      1  \\\n",
       "0     This paper proposes a novel technique for sear...   \n",
       "1     The paper learns the binary basis mask for a f...   \n",
       "2     This paper proposes a single-actor, multi-crit...   \n",
       "3     This work proposes random General Value Functi...   \n",
       "4     This paper studies positive and unlabeled (PU)...   \n",
       "...                                                 ...   \n",
       "1108  The paper proposes an infinite-width parameter...   \n",
       "1109  This paper studies the problem of certifying a...   \n",
       "1110  This paper introduces a neural network archite...   \n",
       "1111  A method called LaGraph is proposed for semi-s...   \n",
       "1112  In this paper, the authors aim to resolve the ...   \n",
       "\n",
       "                                                      2  \\\n",
       "0     The authors develop a new approximation to for...   \n",
       "1     The paper describes an approach to continual l...   \n",
       "2     This paper proposes to extend the actor-critic...   \n",
       "3     Summary -------  Owing to the importance of st...   \n",
       "4     This paper addresses the problem of class-prio...   \n",
       "...                                                 ...   \n",
       "1108  The authors study a certain variant of an MLP ...   \n",
       "1109  This paper studied how to certificate a policy...   \n",
       "1110  This paper proposes to use self-attention betw...   \n",
       "1111  The paper proposes a new self-supervised learn...   \n",
       "1112  This paper proposed PoNet, which is an efficie...   \n",
       "\n",
       "                                                      3  \n",
       "0     This paper deals with two related problems. Th...  \n",
       "1     In the current paper, the authors propose a no...  \n",
       "2     The paper introduces a variant of actor-critic...  \n",
       "3     This paper introduces a new auxiliary task for...  \n",
       "4     This paper studies the prior $\\pi$ in PU learn...  \n",
       "...                                                 ...  \n",
       "1108  The paper introduces an approach (named pi-lim...  \n",
       "1109  This paper proposes a certification method aga...  \n",
       "1110  Deep parametric models have demonstrated treme...  \n",
       "1111  The authors propose a self-supervised learning...  \n",
       "1112  PoNet addresses the quadratic time and memory ...  \n",
       "\n",
       "[1113 rows x 5 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_scores(df, subscore_col):\n",
    "    n = len(df.columns)-1\n",
    "    pairs = [f'{i}-{j}' for i in range(n) for j in range(i+1, n)]\n",
    "    col = pd.MultiIndex.from_product([subscore_col, pairs])\n",
    "    scores = pd.DataFrame(columns=col)\n",
    "    scores.insert(0, \"paper_id\", df[\"paper_id\"])\n",
    "    # scores.set_index(\"paper_id\", inplace=True)\n",
    "    return scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "rougescore = load_metric(\"rouge\")\n",
    "\n",
    "def rouge_cal(df):\n",
    "    n = len(df.columns)-1\n",
    "    print(f\"Calculating ROUGE on {n} summaries\")\n",
    "\n",
    "    rouge_list = ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
    "    score_list = ['precision', 'recall', 'fmeasure']\n",
    "\n",
    "    df_score_dict = {}\n",
    "    mux = pd.MultiIndex.from_product([[\"summary\"],(list(df.columns))[1:]])\n",
    "    df_score = pd.DataFrame(columns=mux)\n",
    "    df_score.insert(0, \"paper_id\", df[\"paper_id\"])\n",
    "    for col in df:\n",
    "        if col != 'paper_id':\n",
    "            df_score[('summary', col)] = df[col]\n",
    "    df_score = df_score.merge(n_scores(df, score_list), left_on='paper_id', right_on='paper_id')\n",
    "    for r in rouge_list:\n",
    "        df_score_dict[r] = df_score.copy(deep=True)\n",
    "\n",
    "    df_len = len(df)\n",
    "    for idx, row in df.iterrows():\n",
    "        sys.stdout.write(f\"\\r{idx+1}/{df_len}\")\n",
    "        sys.stdout.flush()\n",
    "        for i in range(n):\n",
    "            for j in range(i+1,n):\n",
    "                pair = f'{i}-{j}'\n",
    "                score = rougescore.compute(predictions=[row[i]], references=[row[j]], use_stemmer=False)\n",
    "                for r in rouge_list:\n",
    "                    df_score_dict[r].loc[idx, ('precision', pair)] = ((score[r]).low).precision\n",
    "                    df_score_dict[r].loc[idx, ('recall', pair)] = ((score[r]).low).recall\n",
    "                    df_score_dict[r].loc[idx, ('fmeasure', pair)] = ((score[r]).low).fmeasure\n",
    "                break\n",
    "            break\n",
    "        break\n",
    "\n",
    "    return df_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12149532710280374"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['The authors describe the conditioned GAN model to generate speaker conditioned Mel spectra. They augment the z-space corresponding to the identification with latent variables that allow a richer set of produced audio. In a way this is like a partially conditioned model that has \"extra\" degrees of freedom. It looks that the \"latent\" variables are just concaneted to the \"original\" set of z-values (altough with particular conditions to maximize independence). The conditioning of the z-space has originality in it and may provide interesting to the audience. Ultimately one coud think about z-space direction being totally mapped to specific features of the produced signal.',\n",
    " 'Quality: This submission claims to present a model that can control non-annotated attributes such as speaking style, accent, background noise, etc. Though empirical evidence in the form of numerical measurements is presented for some controllable attributes more evidence other than individual samples and authors claims is needed. For example a reliable numerical evidence is needed on page 4 following \"We also found...\", page 5 following \"We discovered....\", page 5 following \"It clearly presents...\", page 5 following \"Drawing samples...\" evidence is given only for 1 dimension, page 6 following \"Figure 7(b)...\". ']\n",
    "score = rougescore.compute(predictions=[text[0]], references=[text[1]], use_stemmer=False)\n",
    "score['rouge1'].low.precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating ROUGE on 2 summaries\n",
      "1/2845rouge1\n",
      "rouge2\n",
      "rougeL\n",
      "rougeLsum\n",
      "Calculating ROUGE on 3 summaries\n",
      "1/2116rouge1\n",
      "rouge2\n",
      "rougeL\n",
      "rougeLsum\n",
      "Calculating ROUGE on 4 summaries\n",
      "1/1113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zw/q5kx3f693rgfk0h2y_jgmhnm0000gn/T/ipykernel_26093/4199912427.py:17: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_score = df_score.merge(n_scores(df, score_list), left_on='paper_id', right_on='paper_id')\n",
      "/var/folders/zw/q5kx3f693rgfk0h2y_jgmhnm0000gn/T/ipykernel_26093/4199912427.py:17: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_score = df_score.merge(n_scores(df, score_list), left_on='paper_id', right_on='paper_id')\n",
      "/var/folders/zw/q5kx3f693rgfk0h2y_jgmhnm0000gn/T/ipykernel_26093/4199912427.py:17: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_score = df_score.merge(n_scores(df, score_list), left_on='paper_id', right_on='paper_id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1\n",
      "rouge2\n",
      "rougeL\n",
      "rougeLsum\n",
      "Calculating ROUGE on 5 summaries\n",
      "1/10rouge1\n",
      "rouge2\n",
      "rougeL\n",
      "rougeLsum\n",
      "Calculating ROUGE on 6 summaries\n",
      "1/15rouge1\n",
      "rouge2\n",
      "rougeL\n",
      "rougeLsum\n",
      "Calculating ROUGE on 7 summaries\n",
      "1/4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zw/q5kx3f693rgfk0h2y_jgmhnm0000gn/T/ipykernel_26093/4199912427.py:17: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_score = df_score.merge(n_scores(df, score_list), left_on='paper_id', right_on='paper_id')\n",
      "/var/folders/zw/q5kx3f693rgfk0h2y_jgmhnm0000gn/T/ipykernel_26093/4199912427.py:17: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_score = df_score.merge(n_scores(df, score_list), left_on='paper_id', right_on='paper_id')\n",
      "/var/folders/zw/q5kx3f693rgfk0h2y_jgmhnm0000gn/T/ipykernel_26093/4199912427.py:17: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_score = df_score.merge(n_scores(df, score_list), left_on='paper_id', right_on='paper_id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1\n",
      "rouge2\n",
      "rougeL\n",
      "rougeLsum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th colspan=\"7\" halign=\"left\">summary</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">fmeasure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>0-1</th>\n",
       "      <th>0-2</th>\n",
       "      <th>...</th>\n",
       "      <th>2-3</th>\n",
       "      <th>2-4</th>\n",
       "      <th>2-5</th>\n",
       "      <th>2-6</th>\n",
       "      <th>3-4</th>\n",
       "      <th>3-5</th>\n",
       "      <th>3-6</th>\n",
       "      <th>4-5</th>\n",
       "      <th>4-6</th>\n",
       "      <th>5-6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:2cf4a3964537ff5dd1f7b600ab567b4d0b3cc03e</td>\n",
       "      <td>This work reports the problem of image classif...</td>\n",
       "      <td>The paper evaluates pathologies of modern neur...</td>\n",
       "      <td>The paper identifies sparse sets of pixels whi...</td>\n",
       "      <td>The paper presents an interesting finding that...</td>\n",
       "      <td>Authors define \"overinterpretation\" as an unde...</td>\n",
       "      <td>This paper proposes \"overinterpretation\" which...</td>\n",
       "      <td>The work utilizes the SIS (a local feature-imp...</td>\n",
       "      <td>0.23301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:b622788bec805621c2abf11ffa25c0d55e50f4d3</td>\n",
       "      <td>The paper performs a detailed hyperparameter s...</td>\n",
       "      <td>This paper was previously rejected by NeurIPS ...</td>\n",
       "      <td>In data-parallel distributed training, increas...</td>\n",
       "      <td>This paper revisits the effectiveness of the o...</td>\n",
       "      <td>I carefully read the responses from the author...</td>\n",
       "      <td>In this work, the authors compared the standar...</td>\n",
       "      <td>The authors detail the significant effort requ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:ddc796b9185d372f4d0829f436bbca50c3990867</td>\n",
       "      <td>This paper introduces a Jax package for implic...</td>\n",
       "      <td>The paper proposes a modular and efficient fra...</td>\n",
       "      <td>This paper presents a module for implicit diff...</td>\n",
       "      <td>The paper promises extension of Googleâ€™s JAX l...</td>\n",
       "      <td>This paper provides a unified tool for combini...</td>\n",
       "      <td>A good paper considers a critical problem, but...</td>\n",
       "      <td>The authors propose a unified modular framewor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:f202f3d6780876a0bdd7d7bd4d7047719a145177</td>\n",
       "      <td>The authors propose a novel skill discovery me...</td>\n",
       "      <td>This method learns a space of intrinsic goals ...</td>\n",
       "      <td>The paper presents a framework for an unsuperv...</td>\n",
       "      <td>The paper proposes an unsupervised exploration...</td>\n",
       "      <td>To increase the state space coverage with unsu...</td>\n",
       "      <td>The paper proposes a novel algorithm for learn...</td>\n",
       "      <td>The idea of this work is to maximize coverage ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      paper_id  \\\n",
       "                                                 \n",
       "0  SP:2cf4a3964537ff5dd1f7b600ab567b4d0b3cc03e   \n",
       "1  SP:b622788bec805621c2abf11ffa25c0d55e50f4d3   \n",
       "2  SP:ddc796b9185d372f4d0829f436bbca50c3990867   \n",
       "3  SP:f202f3d6780876a0bdd7d7bd4d7047719a145177   \n",
       "\n",
       "                                             summary  \\\n",
       "                                                   0   \n",
       "0  This work reports the problem of image classif...   \n",
       "1  The paper performs a detailed hyperparameter s...   \n",
       "2  This paper introduces a Jax package for implic...   \n",
       "3  The authors propose a novel skill discovery me...   \n",
       "\n",
       "                                                      \\\n",
       "                                                   1   \n",
       "0  The paper evaluates pathologies of modern neur...   \n",
       "1  This paper was previously rejected by NeurIPS ...   \n",
       "2  The paper proposes a modular and efficient fra...   \n",
       "3  This method learns a space of intrinsic goals ...   \n",
       "\n",
       "                                                      \\\n",
       "                                                   2   \n",
       "0  The paper identifies sparse sets of pixels whi...   \n",
       "1  In data-parallel distributed training, increas...   \n",
       "2  This paper presents a module for implicit diff...   \n",
       "3  The paper presents a framework for an unsuperv...   \n",
       "\n",
       "                                                      \\\n",
       "                                                   3   \n",
       "0  The paper presents an interesting finding that...   \n",
       "1  This paper revisits the effectiveness of the o...   \n",
       "2  The paper promises extension of Googleâ€™s JAX l...   \n",
       "3  The paper proposes an unsupervised exploration...   \n",
       "\n",
       "                                                      \\\n",
       "                                                   4   \n",
       "0  Authors define \"overinterpretation\" as an unde...   \n",
       "1  I carefully read the responses from the author...   \n",
       "2  This paper provides a unified tool for combini...   \n",
       "3  To increase the state space coverage with unsu...   \n",
       "\n",
       "                                                      \\\n",
       "                                                   5   \n",
       "0  This paper proposes \"overinterpretation\" which...   \n",
       "1  In this work, the authors compared the standar...   \n",
       "2  A good paper considers a critical problem, but...   \n",
       "3  The paper proposes a novel algorithm for learn...   \n",
       "\n",
       "                                                     precision       ...  \\\n",
       "                                                   6       0-1  0-2  ...   \n",
       "0  The work utilizes the SIS (a local feature-imp...   0.23301  NaN  ...   \n",
       "1  The authors detail the significant effort requ...       NaN  NaN  ...   \n",
       "2  The authors propose a unified modular framewor...       NaN  NaN  ...   \n",
       "3  The idea of this work is to maximize coverage ...       NaN  NaN  ...   \n",
       "\n",
       "  fmeasure                                               \n",
       "       2-3  2-4  2-5  2-6  3-4  3-5  3-6  4-5  4-6  5-6  \n",
       "0      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[4 rows x 71 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for n, df in enumerate(df_list):\n",
    "    if n+1 > 1:\n",
    "        dict_result = rouge_cal(df)\n",
    "        for key, val in dict_result.items():\n",
    "            print(key)\n",
    "            # val.to_csv(f\"visualization_data/rouge-between-sum/{key}/{dts}_{key}_{n+1}sum.csv\")\n",
    "dict_result['rouge1']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BERTScore on 3 summaries\n",
      "0-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zw/q5kx3f693rgfk0h2y_jgmhnm0000gn/T/ipykernel_26093/3945739358.py:14: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_score = df_score.merge(n_scores(df, score_list), left_on='paper_id', right_on='paper_id')\n",
      "/var/folders/zw/q5kx3f693rgfk0h2y_jgmhnm0000gn/T/ipykernel_26093/3945739358.py:25: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_score.loc[:, (score, pair)] = result[score]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th colspan=\"3\" halign=\"left\">summary</th>\n",
       "      <th colspan=\"3\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"3\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"3\" halign=\"left\">f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0-1</th>\n",
       "      <th>0-2</th>\n",
       "      <th>1-2</th>\n",
       "      <th>0-1</th>\n",
       "      <th>0-2</th>\n",
       "      <th>1-2</th>\n",
       "      <th>0-1</th>\n",
       "      <th>0-2</th>\n",
       "      <th>1-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:001ae7379191bb40fc356a37deb2f0ffc4426e52</td>\n",
       "      <td>This paper proposes EgoTR for cross-view geo-l...</td>\n",
       "      <td>The paper tackles the cross-view geo-localizat...</td>\n",
       "      <td>This paper proposes to use transformer for cro...</td>\n",
       "      <td>0.224304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.056118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.140213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:0045d9a733e9d3db6e42c4fcadaa7dc57f7b5004</td>\n",
       "      <td>This paper considers the problem of generaliza...</td>\n",
       "      <td>This paper aims to design a counterfactual rei...</td>\n",
       "      <td>The paper presents a method to improve the gen...</td>\n",
       "      <td>-0.104706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.213069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:0055dca69c153ed21b420741c479a2ef00be2ef6</td>\n",
       "      <td>This paper compares the so-called \"State Evolu...</td>\n",
       "      <td>This paper considers the state evolution equat...</td>\n",
       "      <td>This paper provides derivations of equivalence...</td>\n",
       "      <td>0.054633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.191037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.123345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      paper_id  \\\n",
       "                                                 \n",
       "0  SP:001ae7379191bb40fc356a37deb2f0ffc4426e52   \n",
       "1  SP:0045d9a733e9d3db6e42c4fcadaa7dc57f7b5004   \n",
       "2  SP:0055dca69c153ed21b420741c479a2ef00be2ef6   \n",
       "\n",
       "                                             summary  \\\n",
       "                                                   0   \n",
       "0  This paper proposes EgoTR for cross-view geo-l...   \n",
       "1  This paper considers the problem of generaliza...   \n",
       "2  This paper compares the so-called \"State Evolu...   \n",
       "\n",
       "                                                      \\\n",
       "                                                   1   \n",
       "0  The paper tackles the cross-view geo-localizat...   \n",
       "1  This paper aims to design a counterfactual rei...   \n",
       "2  This paper considers the state evolution equat...   \n",
       "\n",
       "                                                     precision            \\\n",
       "                                                   2       0-1  0-2  1-2   \n",
       "0  This paper proposes to use transformer for cro...  0.224304  NaN  NaN   \n",
       "1  The paper presents a method to improve the gen... -0.104706  NaN  NaN   \n",
       "2  This paper provides derivations of equivalence...  0.054633  NaN  NaN   \n",
       "\n",
       "     recall                  f1            \n",
       "        0-1  0-2  1-2       0-1  0-2  1-2  \n",
       "0  0.056118  NaN  NaN  0.140213  NaN  NaN  \n",
       "1  0.213069  NaN  NaN  0.050674  NaN  NaN  \n",
       "2  0.191037  NaN  NaN  0.123345  NaN  NaN  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore = load(\"bertscore\")\n",
    "def bertscore_cal(df):\n",
    "    n = len(df.columns)-1\n",
    "    print(f\"Calculating BERTScore on {n} summaries\")\n",
    "    \n",
    "    score_list = ['precision', 'recall', 'f1']\n",
    "\n",
    "    mux = pd.MultiIndex.from_product([[\"summary\"],(list(df.columns))[1:]])\n",
    "    df_score = pd.DataFrame(columns=mux)\n",
    "    df_score.insert(0, \"paper_id\", df[\"paper_id\"])\n",
    "    for col in df:\n",
    "        if col != 'paper_id':\n",
    "            df_score[('summary', col)] = df[col]\n",
    "    df_score = df_score.merge(n_scores(df, score_list), left_on='paper_id', right_on='paper_id')\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n-1):\n",
    "            pair = f'{i}-{j}'\n",
    "            summary1 = list(df_score.loc[:, ('summary', i)])\n",
    "            summary2 = list(df_score.loc[:, ('summary', j)])\n",
    "            print(pair)\n",
    "            result = bertscore.compute(predictions=summary1, references=summary2, lang=\"en\", rescale_with_baseline=True)\n",
    "            for score in score_list:\n",
    "                df_score.loc[:, (score, pair)] = result[score]\n",
    "\n",
    "    return df_score\n",
    "    \n",
    "bertscore_cal(df_list[2][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, df in enumerate(df_list):\n",
    "    if n+1 > 1:\n",
    "        result = bertscore_cal(df)\n",
    "        val.to_csv(f\"visualization_data/bertscore-between-sum/{dts}_bertscore_{n+1}sum.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c41a15a33a59f0eeae9566b7a824606ae2e90e5c5eb8240ec6145ee367642a6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
