{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b07343381df44b59fed1114bfd130f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7eae9ccf924580b9d2b583e3c1e83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538cfd45d05841419e13eeb64e0587dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8aae21776f4034ae92543014dd1c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")\n",
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [1.0000001192092896, 0.9999999403953552],\n",
       " 'recall': [1.0000001192092896, 0.9999999403953552],\n",
       " 'f1': [1.0000001192092896, 0.9999999403953552],\n",
       " 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.25.1)'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_1_p': 0.21782178217821782, 'rouge_we_1_r': 0.22, 'rouge_we_1_f': 0.21890547263681592}\n"
     ]
    }
   ],
   "source": [
    "# pylint: disable=C0103,C0301\n",
    "import unittest\n",
    "from summ_eval.rouge_we_metric import RougeWeMetric\n",
    "from summ_eval.test_util import EPS, CANDS_l2s, REFS_l2s\n",
    "\n",
    "\n",
    "class TestScore(unittest.TestCase):\n",
    "    def test_score_single(self):\n",
    "        metric = RougeWeMetric(n_gram=1)\n",
    "        score = metric.evaluate_example(CANDS_l2s[0], REFS_l2s[0])\n",
    "        self.assertTrue((score['rouge_we_1_f'] - 0.22) < EPS)\n",
    "        metric = RougeWeMetric(n_gram=2)\n",
    "        score = metric.evaluate_example(CANDS_l2s[0], REFS_l2s[0])\n",
    "        self.assertTrue((score['rouge_we_2_f'] - 0.09090909090909093) < EPS)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # unittest.main()\n",
    "    metric = RougeWeMetric(n_gram=1)\n",
    "    score = metric.evaluate_example(CANDS_l2s[0], REFS_l2s[0])\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_1_p': 0.25, 'rouge_we_1_r': 0.3333333333333333, 'rouge_we_1_f': 0.28571428571428575}\n"
     ]
    }
   ],
   "source": [
    "# print(CANDS_l2s[0], REFS_l2s[0])\n",
    "metric = RougeWeMetric(n_gram=1)\n",
    "score = metric.evaluate_example([\"There is a cat\"], [\"There are cats\"])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 09:04:07) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c41a15a33a59f0eeae9566b7a824606ae2e90e5c5eb8240ec6145ee367642a6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
