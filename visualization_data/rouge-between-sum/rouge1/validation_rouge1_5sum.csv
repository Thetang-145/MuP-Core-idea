,paper_id,summary,summary,summary,summary,summary,precision,precision,precision,precision,precision,precision,precision,precision,precision,precision,recall,recall,recall,recall,recall,recall,recall,recall,recall,recall,fmeasure,fmeasure,fmeasure,fmeasure,fmeasure,fmeasure,fmeasure,fmeasure,fmeasure,fmeasure
,,0,1,2,3,4,0-1,0-2,0-3,0-4,1-2,1-3,1-4,2-3,2-4,3-4,0-1,0-2,0-3,0-4,1-2,1-3,1-4,2-3,2-4,3-4,0-1,0-2,0-3,0-4,1-2,1-3,1-4,2-3,2-4,3-4
0,SP:000cbfda2e26fdcfee50a628799a73b6886cfccc,"This paper proposes to empirically investigate to what extent large language models like GPT-3 learn (or ""distill"") a simplicity prior, i.e., a prior that favors concepts with shorter description length. The authors investigate this by randomly choosing 8 concepts/programs in the P3 language whose total number of P3 instructions number from 1 to 8, respectively. Using the framework of Telle et al. (2019), the authors are able to determine the ""witness set,"" the minimal number of examples necessary for a learner with the correct simplicity prior to distinguish the intended concept from others. This witness set is fed to a learner, which is then evaluated on 5 randomly selected test examples of the concept. The authors also consider feeding additional sets of 2 and then 3 examples to the learner, each with its own random test set. The authors evaluate the accuracy of GPT learners, human learners, and 2 inductive program learners on these 3 test sets. They also elicit explanations from the learners.","This paper empirically compares humans, language models, and inductive programming systems through the framework of machine teaching. Concepts and example sets are selected using a simplicity prior with reference to the P3 language. The main experiments present the example sets to the humans or machines and ask them to infer the corresponding concept. This setup leads to several experimental questions regarding the alignment between humans and the computational approaches and the extent to which language models like GPT have distilled a simplicity prior.","This paper studies the type of patterns learned by large pre-trained language models (LMs) in a few-show setting. The authors differentiate between external patterns (e.g., common-sense or world-knowledge), and internal patterns, such as ABAB, and focus on the latter. They frame this as a teaching problem with strong priors, and study the size of the example set (number of shots in the few-shot setting) compared to the length of explanation that can be provided to the model in order to teach it the given pattern. The authors focus on the simplicity prior, and study whether it is implicitly encoded in such large models. Experiment that compare LMs, program induction systems and humans are performed. The main findings are that LMs perform as well as humans in few-shot settings, but the two populations differ in their ability to generate explanations.  I would say upfront that I am not an expert in this topic, and have found many points in the paper unclear, perhaps due to this. However, I wasn't fully convinced by the setup used by the authors. I am looking forward to the author response that might clarify some of these points. ","This paper attempts to ask whether language models have a bias that allows them to learn from fewer examples in cases where a rule is simpler. They compare exploitation of rule simplicity in a variety of models, including human participants. This prior towards simplicity is most strongly observed in larger models, but the minimal example set is rarely enough to train any system, so with the exploitation of simplicity is not a perfect prior.  The paper also provides an analysis of the capability of these systems to provide explanations of the rule, but only humans and the algorithm that they specifically select for this purpose were capable of providing such explanations.","In this paper, the authors compare the few-shot learning abilities of humans and GPT* language models (and inductive programming systems) from a machine teaching point of view. Models (and humans) are given a minimal witness set (examples using as few bits of information as possible) that should be sufficient to uniquely determine a program (function from a sequence of bits to another) under a pretty strict simplicity prior. The authors also examine whether additional examples (on top of the minimal witness set) help performance. They consider 8 different P3 programs of increasing complexity based on the number of operators. Examples are presented as English prompts.  The minimal witness set is often not sufficient for humans and LMs to generalize correctly. Nevertheless, there is some evidence that GPT models favor simplicity to some degree. Overall, larger GPT models generally perform better than smaller ones, but the correlation is not perfect. GPT-3 models often generalize better than the human candidates based on the few provided examples. However, humans sometimes provide acceptable explanations (for the shorter programs), but the authors could not get GPT models to explain their reasoning. ",0.15568862275449102,0.20359281437125748,0.15568862275449102,0.18562874251497005,0.26506024096385544,0.20481927710843373,0.3614457831325301,0.125,0.17,0.25225225225225223,0.3132530120481928,0.17,0.23423423423423423,0.16489361702127658,0.11,0.15315315315315314,0.1595744680851064,0.22522522522522523,0.18085106382978725,0.14893617021276595,0.208,0.18528610354223438,0.18705035971223025,0.17464788732394365,0.15547703180212016,0.1752577319587629,0.22140221402214025,0.16077170418006428,0.1752577319587629,0.18729096989966554
1,SP:0346eba4f587acbe3492d039066f1737360fd870,"The paper considers a class of nonsmooth and low-rank matrix optimization problems. Major contributions include: (1) Discuss strict complementarity for nonsmooth problems and challenges of low-rank projected subgradient steps. (2) Under certain assumptions, a special type of nonsmooth problems can be reformulated as maximum of smooth ones and thereby a minimax form, and develop a projected extragradient method with low-rank projections. (3) Use the proposed method to solve several classical low-rank approximation problems in applications. ","This paper studies the problem of minimizing a convex, non-smooth objective function of matrices with low-rank constraints. For the smooth counterpart of the same problem, it has been previously shown that SVDs computed during the iterations of algorithms such as projected sub-gradient descent can be replaced by low-rank SVDs, thus improving the computational complexity. This paper studies the conditions under which such a replacement can be used for non-smooth objective functions.   The main result of the paper consists of describing the class of non-smooth functions for which low-rank SVDs can be used. The paper proves theoretically and empirically that for non-smooth functions that have a saddle point structure (can be written as a sum of a smooth function and a point-wise maximum of affine functions), and when the initialization is within a certain radius w.r.t the ground truth, low0rank SVDs lead to the same solution as full SVDs and a O(1/t) convergence can be achieved.   Further, the paper also shows empirically that using low-rank SVDs on non-smooth objectives leads to the same solution as using full SVDs. ","In this paper, motivated by a new efficient method in solving smooth low-rank matrix optimization problems, the authors propose to extend the method to nonsmooth problems. However, direct generalization is not possible, as is shown for a specific failure case. Thus, the authors propose to introduce some auxiliary parameters and transform the original nonsmooth problem to a smooth saddle-point problem. The authors then extend to the method of this new problem and derive a new algorithm that is suitable for the saddle-point problem. Theoretically, the authors proved the convergence of their proposed method. And empirical results verify the correctness of their proposed method.","This paper develops an extragradient method for low-rank and nonsmooth matrix optimization problems. Under certain conditions, the proposed method converges to an optimal solution with rate O(1/t). Numerical experiments are provided to support the theoretical results.","This paper considers the problem of minimizing a non-smooth matrix function  $f(X)$ over the spectrahedron $S_n$, i.e., positive semidefinite matrices with trace equal to 1. Such optimization problems often arise as the convex relaxation of various low-rank matrix recovery problems. In general solving these problems with projected subgradient descent requires a projection onto the spectraherdon at every iteration, which is expensive because of the need to compute a full SVD at every step.  Under the assumption that the non-smooth objective function $f(X)$ can be written as the pointwise maximum of a family of smooth functions,  the authors reformulate the original optimization problem as a saddle point problem which can be solved via the projected extragradient method. The key contribution is that under a “generalized strict complementarity” condition and when close to the ground truth, the projection onto $S_n$ can be replaced by a low-rank projection. Therefore, the overall algorithm can be significantly more efficient, because only a low-rank SVD is needed.",0.31645569620253167,0.22784810126582278,0.1518987341772152,0.35443037974683544,0.13541666666666666,0.078125,0.234375,0.1320754716981132,0.2641509433962264,0.28205128205128205,0.13020833333333334,0.16981132075471697,0.3076923076923077,0.16374269005847952,0.24528301886792453,0.38461538461538464,0.2631578947368421,0.358974358974359,0.16374269005847952,0.06432748538011696,0.18450184501845018,0.19459459459459458,0.2033898305084746,0.22399999999999998,0.174496644295302,0.12987012987012986,0.24793388429752067,0.19310344827586207,0.20216606498194947,0.10476190476190476
2,SP:07def8c80d05f86402ce769313480b30cd99af43,"1. The paper proposes GDWS with an error optimization strategy to replace regular convolution for enhancing both throughput (FPS) and adversarila robustness. 2. Experimental results on CIFAR-10, SVHN, and ImageNet validate that the replacing a CNN's regular conv with GDWS can achieve significantly higher FPS and preserve adversarial robustness.","The paper proposes a post-training transformation of a pre-trained 2D convolutional layer into a general depth-wise separable convolution operation. The optimization primarily focuses on minimizing error and limiting computation complexity. The paper claims to achieve a higher robustness (i.e., defend adversarial input attack) and higher frame per second than existing methods.","This paper proposed a method named  Generalized Depthwise-Separable (GDWS) to improve the throughput on real-life hardware while simultaneously preserving robustness. The advantage of GDWS is that does not need any additional training.  This paper has demonstrated the effectiveness of GDWS via extensive experiments on CIFAR-10, SVHN, and ImageNet datasets.  ",The authors propose Generalized Depthwise-Separable (GDWS) convolutions for processing images for the purpose of getting high throughput in efficiency and robustness. This is carried out by introducing channel distribution vectors in the standard 2D CNNs. The efficiency is managed by means of the singular value decomposition of the matrix in the convolutional operations after vectorizations. Experiments show that the method provides similar results for some benchmark data. ,The paper proposes a generalization of depthwise-separable convolutions (called GDWS) where each channel can have multiple depthwise filters (instead of just one) that are subsequently combined using a pointwise convolution. Two algorithms are proposed to minimize the error/complexity of mapping general convolutions to GDWS as a post-processing step after training. Results show small degradation on natural and robust accuracy while increasing the FPS substantially.,0.19607843137254902,0.21568627450980393,0.1568627450980392,0.21568627450980393,0.14545454545454545,0.09090909090909091,0.23636363636363636,0.23076923076923078,0.23076923076923078,0.16176470588235295,0.18181818181818182,0.21153846153846154,0.11764705882352941,0.16417910447761194,0.15384615384615385,0.07352941176470588,0.19402985074626866,0.17647058823529413,0.1791044776119403,0.16417910447761194,0.18867924528301885,0.21359223300970875,0.13445378151260504,0.18644067796610167,0.14953271028037382,0.0813008130081301,0.2131147540983607,0.20000000000000004,0.20168067226890757,0.16296296296296298
3,SP:0f7ff312a242a553dc9ecf35b421e58fb2d50a26,"The paper investigates the well-known 1-step heuristic for Q-function based offline RL methods. The method is evaluated for a model-free, Q-function based offline RL method on various benchmarks and the overall good performance of the approach is shown. The paper differs from results published in [1] mainly by the benchmarks used and the analysis of the reasons for the good performance.   [1] Gulcehre et al, Addressing Extrapolation Error in Deep Offline Reinforcement Learning, preprint 2021. ","# Offline RL Without Off-Policy Evaluation  ## Summary  The paper examines an issue with existing offline RL methods and proposes a way to prevent the issue that leads to a strong family of baselines. The key idea is not to perform multiple steps of off-policy evaluation and improvement in offline RL.  In addition to providing evidence to the claim that one-step methods outperform multistep and iterative ones, the paper also provides explantion and a toy example that shed light on the issues faced by multistep and iterative offline RL methods. I believe these examples can be useful in the future as ""unit tests"" for new offline RL methods.  ## For the response  Could you please comment on Gulcehre et al. (https://arxiv.org/pdf/2103.09575.pdf) in relation to your work?   Please include a discussion of the broader societal impact of your work.","This paper applies a simple baseline to the offline-RL paradigm. Rather than iterating through steps of policy evaluation and improvement as done by most current offline-RL algorithms, in this work the authors investigate the performance of one-step of constrained policy improvement on the D4RL benchmark. This simple baseline is shown to perform considerably well when compared to existing methods. The paper then claims that the reason for this is likely due to the deleterious effects of off-policy evaluation. A simple experiment of different algorithms shows that strong regularization against the behavior policy during learning can be crucial in the offline setting. The authors then analyze the potential pitfalls of off policy evaluation through simple analysis on an existing task and a convincing gridworld experiment. Finally the paper tries to shed some intuition as to when multi-step approaches may perform better than the one-step methods.  ","Popular RL (both online and offline) algorithms iterate between two stages: policy evaluation where a Q-function: $S \times A \rightarrow \mathbb{E} \sum r$ is estimated and policy improvement where the policy $\pi: S \rightarrow A$ which maximizes the rewards is constructed. Typically, the stages are interleaved through the training process. The paper evaluates and argues for the idea of using, in the case of offline RL, only a single step of policy improvement after training Q-function to convergence.","The authors study the notion of iterative policy improvement in offline reinforcement learning, notably finding that a single policy improvement step can outperform standard iterative benchmarks on the D4RL benchmark. To provide more insight on this, the authors also compare to an intermediate version, “multi-step”, and analyze the performance of the three variants (one-step, multi-step, and iterative) with different regularization hyperparameters. They also show results for the MSE of the estimated Q function, as well as illustrate multi-step overestimation on Gridworld environments. Finally, the authors discuss when multi-step algorithms are better, namely when noise signal is low and more propagation of signal can help.",0.2625,0.25,0.1875,0.1875,0.2152777777777778,0.13194444444444445,0.1527777777777778,0.13333333333333333,0.18666666666666668,0.18518518518518517,0.14583333333333334,0.13333333333333333,0.18518518518518517,0.13761467889908258,0.20666666666666667,0.2345679012345679,0.2018348623853211,0.24691358024691357,0.25688073394495414,0.13761467889908258,0.18750000000000003,0.1739130434782609,0.1863354037267081,0.15873015873015875,0.21088435374149658,0.16888888888888887,0.17391304347826086,0.17316017316017315,0.21621621621621623,0.15789473684210525
4,SP:0ff862542ada5b664d615c26e7a4a95b6cbe540e,"The authors present a technique for modeling source code. They point out that modeling code is different from language because of the tight binding between ASTs, data, and control flow. Also they mention some weakness of GNNs. To compete with GNNs, they introduce a new method which is a sequence-based transformer that incorporates graph structure through the attention weights. The model is shown to be effective for code summarization.","The paper proposes an Transformer-based architecture for embedding source code snippets that integrates encoding of absolute and relative AST paths for all code tokens into self-attention. Following up on prior work in relative position encoding, they map AST paths into the position encoding framework, modify the self-attention computation accordingly, and evaluate on method summarization. The approach is compared to recent Transformer-based baselines on the standard method summarization benchmark, as well as to code2seq, which pioneered path-only source code encoding. The results improve performance significantly on almost all benchmarks.","This work continues on earlier advances in how positional and relational encoding is used by the self attention primitive of Transformers, in particular in the context of source-code understanding. Prior work has biased self attention to encode relative relational information between inputs (e.g., edges or distance on some graph), and to separate the self-attention term due to position from that due to input.  For the former, TPTrans runs the path between any two tokens (specifically, the path in the code Parse Tree between two leaves -- the authors call this the ""relative path"") through an RNN, and uses the resulting embedding to bias the self attention between those tokens.  For the latter, TPTrans-$\alpha$ runs the path from the parse-tree root to a token through an RNN (the ""absolute path""), and uses that to construct a separate positional self-attention term.  The results show that both TPTrans and TPTrans-$\alpha$ outperform prior work (most notably, Code Transformer), but TPTrans seems to dominate TPTrans-$\alpha$ with a smaller set of trainable parameters.","This paper introduces a new neural network architecture for code, TPTrans (Tree Path Transformer), by modifying the attention calculation in the Transformer architecture to use information about paths in the syntax trees of programs. The modification works by computing path embeddings between pairs of leaf nodes (""relative path embeddings"") and between leaf nodes and the root (forming nodes' ""absolute path embeddings""), and incorporating these into the Transformer's attention module. The paper evaluates TPTrans, including baselines and variants, on code summarization -- the task of predicting a function's name given its body -- for four different programming languages. The main experiments reveal the value of including embeddings of sequences (the paths) in the attention calculation over baselines, and subsequent experimentation compares the impact of relative and absolute paths, and the effect of pointer network outputs on the model.","The paper presents a way to incorporate the tree-structure information into a transformer architecture to better learn representation for code. The tree structures are first dispatched as leaf-to-leaf ""relative paths"" and leaf-to-root ""absolute paths"", and then embedded and modulated as additional learnable parts of the query, key, and value components within the transformer attention. The authors evaluate their proposal on the task of extreme code summarization -- predicting function names. Results show improvements over 4 previous non-transformer and transformer models on 3 out of 4 programming languages tested. The authors also carry out ablation studies to understand the effect of absolute paths and pointer networks but many important questions remain unanswered. ",0.2,0.2,0.18571428571428572,0.17142857142857143,0.1935483870967742,0.1935483870967742,0.21505376344086022,0.16091954022988506,0.1206896551724138,0.24087591240875914,0.15053763440860216,0.08045977011494253,0.0948905109489051,0.10344827586206896,0.10344827586206896,0.13138686131386862,0.1724137931034483,0.20437956204379562,0.1810344827586207,0.28448275862068967,0.17177914110429446,0.11475409836065573,0.12560386473429952,0.12903225806451615,0.13483146067415733,0.1565217391304348,0.19138755980861244,0.18006430868167203,0.14482758620689656,0.2608695652173913
5,SP:115d679338ab35829dbc594472d13cc02be5ed4c,"This paper introduces a method  to perform text-image matching and demonstrate that  it can be used to solve several language-vision downstream tasks  ranging from image-text retrieval, VQA and national language for visual reasoning among others.   * Given an  image and a textual input visual and  textual embedding are obtained  that are then fed  to a multimodal encoder with  cross-attention layers.  * The first key idea of this paper lies in the image-text contrastive loss employed between the image/text embeddings before feeding them to the multimodal  decoder with the intuition behind that being that forcing these embeddings to align before fusing them through the multi-modal encoder results into better representations for downstream tasks * The second key idea is in the usage of  a momentum model that generates pseudo-target labels by keeping a moving average that are then used for supervision at training time.   An in-depth discussion is provided: 1) for each of the losses used, 2) on the fact that the proposed approach maximizes a lower bound on the mutual information between different “views” of an image-text pair  Extensive Results for several tasks and datasets are provided and strong results are reported. The qualitative results demonstrating where the learned attention is focusing for each downstream task are also quite insightful","In this paper, the authors study the vision-transformer-like vision-language-pretraining (VLP) methods. The raw image and text are first encoded by a vision transformer and a text transformer respectively, and are then sent into a multimodal transformer for fusion. There are two major technical contributions, i.e., 1) the proposed ITC loss and 2) the moving average “teacher” to generate the pseudo targets.     The proposed method (ALBEF) outperforms previous E2E VLP methods, and achieves comparable performance to the VLP methods that take object region features. ","The paper proposes to learn joint vision and language representations by addressing several limitations in the existing methods. Firstly, they learn separate image and text representations using unimodal encoders without the need for bounding box annotations. Second, they fuse these two representations using a multimodal encoder based on cross modal attention and, third, they address the noise in large scale web based image-text datasets using a Momentum Distillation approach that generates pseudo-targets as additional supervision. They demonstrate the effectiveness of their approach on various downstream V+L tasks and gain substantial improvement over SOTA methods. Their main contributions are: removing the need for pre-trained object detector and high resolution images and combining it with the contrastive loss function for learning effective multi-modal representations, image-text contrastive learning loss (ITC). They also generate pseudo-targets for the ITC loss and the masked language modeling (MLM) loss using the momentum encoder model to address the weak correlations in the noisy image-text web data. This achieves high performance on both reasoning and retrieval tasks unlike other methods. The paper  is very well written and easy to follow and understand.  ","This paper presents an vision-and-language pretraining framework that utilizes momentum distillation to address the issue of training on noisy web data. More specifically, it presents a self-training approach to learn from pseudo-targets that are generated by a momentum model. In contrast to existing approaches which simply use cross-modal attention to reason about concatenated sequences of image regions and words, this work also leverages contrastive learning to learn more effective representations before using cross-modal attention.","This paper proposes a new vision-language representation learning framework, ALBEF, which uses image-text contrastive (ITC), masked language modeling (MLM), and image-text matching (ITM) losses with momentum distillation to learn SOTA representations. The ITC and MLM losses are adapted to be convex combinations of the original loss and the KL divergence between the predicted probability distribution (of the image or text or masked tokens) and the soft pseudo targets obtained from the momentum model.   The pipeline is evaluated on image-text retrieval, visual entailment, NLVR, VQA, and grounding and shows improved performance on all tasks compared to prior work, and with fewer training samples in comparison to several prior methods. Qualitative visualizations also verify the quality of the learned representations, with convincing heat maps suggesting well grounded, semantically aligned embeddings. ",0.10138248847926268,0.16129032258064516,0.08755760368663594,0.14285714285714285,0.2727272727272727,0.13636363636363635,0.25,0.09424083769633508,0.17277486910994763,0.2375,0.25,0.18324607329842932,0.2375,0.23484848484848486,0.1256544502617801,0.15,0.16666666666666666,0.225,0.25,0.14393939393939395,0.14426229508196722,0.1715686274509804,0.12794612794612795,0.17765042979942694,0.17204301075268813,0.14285714285714282,0.2,0.13284132841328414,0.20433436532507737,0.1792452830188679
6,SP:167a8b7e0173bffc5f08a9c2f378fe7bdf837da3,"In this paper, the author propose a stochastic version of Anderson acceleration (widely used in fixed point iterations)  to solve non convex optimization problem. Some important modifications of the deterministic  version are introduced in order to stabilize and improve the algorithm. The paper theoretically shows that the new algorithm can achieve O(epsilon^{-2}) sample complexity. Numerical results are provided to verify the performance of SAM.","In this manuscript, the authors proposes a Stochastic Anderson Mixing (SAM) scheme to solve nonconvex optimization problems. Under the smoothness, unbiased gradient estimate with bounded variance assumptions, the authors show different variants of the scheme (SAM, SAM with variance reduction, Ada-SAM) have asymptotic and non-asymptotic convergence. Experiments on MNIST, CIFAR and Penn Treebank seem to show the superior performance over other baselines. ","The paper applies Anderson mixing to stochastic optimization problems and shows its effectiveness in training neural networks. To make Anderson mixing work in stochastic settings, the paper proposes a series of strategies to handle noise and uncertainty, including damped projection, adaptive regularization, variance reduction, and preconditioned mixing. Proof of convergence is provided, together with numerical evaluations.  ","This paper proposes a stochastic Anderson mixing method to solve non-convex stochastic optimization problems. The main contribution is a  convergence theory and the applications of this method for deep learning problems. Adaptive, variance reduced, and preconditioned versions of this methods are also studied.  ",The paper under review consider the stochastic Anderson Mixing algorithm and  shows its convergence analysis. An enhanced variance reduction of the algorithms is also derived. The algorithms are tested on extensive data sets with other existing method. This paper seems to be the first one to address the theoretical convergence analysis in this direction.,0.22727272727272727,0.15151515151515152,0.21212121212121213,0.16666666666666666,0.1875,0.234375,0.15625,0.26785714285714285,0.21428571428571427,0.20454545454545456,0.234375,0.17857142857142858,0.3181818181818182,0.2037037037037037,0.21428571428571427,0.3409090909090909,0.18518518518518517,0.3409090909090909,0.2222222222222222,0.16666666666666666,0.23076923076923075,0.16393442622950818,0.2545454545454546,0.18333333333333332,0.19999999999999998,0.2777777777777778,0.1694915254237288,0.3,0.21818181818181817,0.18367346938775508
7,SP:17088db004fbf4902c5c3d53e387d1b68f4d69a5,"The paper proposed a self-supervised capsule based architecture for 3D point cloud. The main goal is to learn a  canonicalization operation that allows unbiased object-centric reasoning.  The idea is that an object is decomposed to K keypoints using canonical capsules, the whole system is trained in an unsupervised fashion based on pairs of randomly rotated/translated  of the same object. The capsule pose equivariance is enforced by requiring the equivariance of two keypoint sets based on the known relative transformation of the pair images and the capsule descriptor invariance is enforced by matching the pair keypoints. The proposed framework have been evaluated in 3D autoencoding and reconstruction, unsupervised classification and canonicalization on ShapeNet dataset.","This paper proposes a way of learning a capsule-based representation of 3D point clouds. The representation decomposes an input point cloud into parts, each corresponding to a capsule. This decomposition is trained to be consistent across SE(3) transformations of the point cloud using loss terms that encourage feature invariance and pose equivariance across two random presentations of the input point cloud. Moreover, the model learns a canonical pose for each part that is tied to the identity of the object (not its presented pose).  The experiments show that 1. The reconstruction quality is high, showing that the model has capacity to fit point clouds from ShapeNet. 1. The canonical pose is indeed consistent (measured by low std deviation in relative angle of rotation). 1. The model can be used for pairwise registration (but DeepGMR does even better using RRI features, but doesn't do any of the other things this model can do.) 1. The learned features lend themselves well to unsupervised clustering/classification. 1. All the proposed loss terms are useful and contribute to better reconstruction and canonicalization.","The paper proposes a capsule-based network architecture that allows self-supervised representation learning from 3D point clouds. While existing methods rely heavily on pre-canonicalized (aligned) 3D models for training, this work proposes to automatically discover the ""optimal"" canonical transformation for alignment while learning to decompose and reconstruct the input point clouds.  Specifically, it exploits the transformation invariance and equivariance properties of object parts (capsules) to learn a latent representation. The experimental results on the (unaligned) ShapeNet dataset show that the method can effectively learn to decompose the 3D point cloud into consistent parts across objects and canonicalize unaligned data. It outperforms the state-of-the-art methods in terms of reconstruction accuracy, canonicalization accuracy and stability, as well as unsupervised classification accuracy from latent representation. It is very encouraging to see that the need of 3D pose/viewpoint annotations can be removed and such competitive performance is reached.","This paper proposes to learn a Canonical Capsule decomposition of shape point clouds in a self-supervised manner.  Given an unaligned 3D point cloud dataset, the proposed method constructs pairwise data with random SE(3) transformations, and then extracts the per-capsule pose and a transformation-invariant descriptor. The experiment results show the importance of the object-centric representation with capsule decomposition in many applications, including reconstruction, canonicalization, and classification. ","The paper proposes a self-supervised capsule architecture for 3D point clouds. In order to circumvent the customary need to train on pre-aligned datasets, the authors introduce the Canonical Capsules to compute the K-part decomposition of a point cloud that allows unsupervised ""object-centric"" learning of 3D representations without requiring a semantically aligned dataset. The main idea of the canonical capsules is to enforce invariance/equivariance by relating the decomposition result of two random rigid transformations.  The authors compare the proposed method against state-of-the-art methods on 3D point cloud reconstruction, canonicalization, and unsupervised classification.",0.28448275862068967,0.22413793103448276,0.16379310344827586,0.29310344827586204,0.1878453038674033,0.13259668508287292,0.16022099447513813,0.16,0.23333333333333334,0.3142857142857143,0.18232044198895028,0.17333333333333334,0.2714285714285714,0.3434343434343434,0.22666666666666666,0.34285714285714286,0.29292929292929293,0.34285714285714286,0.35353535353535354,0.2222222222222222,0.22222222222222224,0.19548872180451127,0.2043010752688172,0.3162790697674418,0.20543806646525678,0.19123505976095617,0.20714285714285713,0.21818181818181817,0.28112449799196787,0.26035502958579876
8,SP:19cd64baeb7db11b5ec066e6f8ccb4bc576d3588,"This paper proposes a stochastic approximation to the E-step of the EM algorithm to reduce the computational cost of fitting mixture models when the number of components $K$ is large. Specifically, the paper proposes using $M << K$ samples of the latent variables $z$ from a Metropolis-Hasting (MH) sampler to approximate the E-step. This lets us only use $M$ likelihood evaluations instead of $K$ for each observation in the E-step. The paper compares there proposed method against other EM-based methods on Gaussian mixture models on synthetic data, and sum product  transform networks and non-volume preserving flows on 19 UCI datasets. ","The paper presents a modified version of the EM algorithm that allows for faster fitting of mixture models. The approach is based on the idea of evaluating and updating a single mixture component per iteration. Furthermore, they present a generalized version that extends beyond the standard case of the exponential family.   The authors then follow with an empirical demonstration of the benefits: up to two orders of magnitude faster training while in some cases increasing the likelihood compared to the standard SGD approach.  The evaluation is carried on two architectures, SPTNs and mixture of real NVP flows. ","This paper proposes a new method for scalably fitting mixture models. The authors tackle the problem of fitting with a large number of mixture components. While there exist some works handling this problem, these methods are all limited to mixtures of exponential family distributions, whereas the authors’ method applies to generic mixture models (as long as the model provides a likelihood p(data point i | cluster k)). They do so by proposing a modified version of the EM algorithm: instead of exactly computing the expectations in the E step, the authors propose to use a Metropolis Hastings algorithm to approximate the required expectations. In experiments, the authors show that their method (1) outperforms pre-existing large-K methods (where such previous applications are applicable), and (2) show that their method outperforms standard stochastic gradient descent in settings where other large-K methods are not applicable. The authors’ method seems to work well, but I have a few clarification questions about the technical ideas behind the proposed algorithm and its empirical evaluation. Currently, I put a borderline score for the paper, but I’m definitely open to increasing it after discussion.","The paper suggests a method for efficiently evaluating mixture models. The main idea is to use Expectation-Maximization (EM) and Metropolis-Hastings (MH) to evaluate only a small number of mixture components, reducing the computational cost by consequence. The theoretical contributions of the manuscript are two-folded. First, the authors proposed an EM-based algorithm for training, which uses MH for sampling from a smaller set of mixture components. Second, the manuscript generalizes the EM-based algorithm by making it compatible with gradient-based optimization methods. The practical contributions include experiments with Gaussian mixture models (GMMs), sum-product networks (SPNs), and mixtures of real-valued flows. Results show a benchmark speed-up of 100x.","This paper proposes a stochastic EM algorithm. Specifically, the authors use a minibatch to approximate the data and use samples obtained from Metropolis-Hasting (MH) to approximate the likelihood component per datum. The proposed method is tested on a synthetic dataset and several UCI datasets.",0.20952380952380953,0.2571428571428571,0.26666666666666666,0.24761904761904763,0.26804123711340205,0.25773195876288657,0.14432989690721648,0.14210526315789473,0.1,0.11403508771929824,0.2268041237113402,0.14210526315789473,0.24561403508771928,0.5777777777777777,0.1368421052631579,0.21929824561403508,0.3111111111111111,0.23684210526315788,0.4222222222222222,0.28888888888888886,0.21782178217821782,0.18305084745762712,0.25570776255707756,0.3466666666666667,0.18118466898954702,0.23696682464454974,0.1971830985915493,0.17763157894736842,0.16170212765957445,0.16352201257861634
9,SP:19fbd1a381598538662417a4a1885ba4ac04f5f8,"Learned video compression is a promising field and has demonstrated that it can be as effective as the classic video compression method. In terms of rate distortion it has caught up with the classical methods greatly. However binding the prediction mode and fixed network is what hinders the field to go forward. This paper proposes a versatile learned video compression framework that learns one mode to predict all possible modes. The paper proposes versatile compression where the motion compensation applies 3D motion vector fields, trilinear warping. Motion estimation here acts as a decoupler of prediction modes away from framework design, allowing its dependence to be not affected by framework design. For multiple reference frame prediction, the network predicts the motion fields with a unified polynomial function. The flow prediction can lead to reduction of computation by reducing voxel flow transmission. ","First, the paper introduces the idea of using multiple predictions (e.g. M=25) for learning-based video coding. Second, to reduce the required motion bits, a flow prediction method using polynomial approximation is developed. The idea is reasonable, and the reported performance seems promising. However, the paper is written rather poorly, and how the algorithm is actually designed is not clear. Thus, the reported performance is not convincing either. ","The authors introduce VLVC, a new neural video compression codec. Thanks to a new 3D motion compensation structure based on spatio-temporal interpolation, a single trained model can be run in arbitrary prediction modes (such as low-delay or random-access settings). In addition, each frame can be compressed with an arbitrary number of reference frames. There are a number of smaller changes to established neural video codecs. The resulting VLVC codec is demonstrated on standard datasets, showing good rate-distortion results (in particular when trained and evaluated on MS-SSIM).","This paper introduces multi-frame references for learned video coding, which estimates multiple optical flows as voxel flows for motion compensation. With the weighted map, it can achieve weighted trilinear warping to combine the multiple predictions into  the final prediction. It is a good idea to obtain a better predcition to search information across multiple frames.  The author introduces  the polynominal motion modeling to use multiple backward optical flow to generate the single optical flow. Based on the method of softmax spaltting, they convert the backward flow into a forward flow using the flow reversal layer. Then use the forward flow and softmax spaltting for motion compensation. The overall architecture is a hybrid video coding system and the main contribution is inter coding. Residual coding is applied on the feature domain. ","This paper proposes a neural video compression method that is designed around the idea of using a voxel flow instead of the more traditional pixel warping idea. The key difference here is that a volume of reference frames is used, and flow is computed to all of them. This allows the compression method to be quite liberal in terms of what information from the GOP can be used, yielding a better RD performance than methods that rely on a single reference frame.  Overall I think this is a step in the right direction, but I fear that such a method is completely impractical for the foreseeable future.",0.07857142857142857,0.1,0.16428571428571428,0.15,0.12857142857142856,0.2857142857142857,0.24285714285714285,0.14285714285714285,0.15384615384615385,0.17557251908396945,0.15714285714285714,0.15384615384615385,0.17557251908396945,0.19626168224299065,0.0989010989010989,0.15267175572519084,0.1588785046728972,0.09923664122137404,0.1308411214953271,0.21495327102803738,0.10476190476190475,0.12121212121212123,0.16974169741697417,0.1700404858299595,0.11180124223602485,0.1990049751243781,0.192090395480226,0.11711711711711711,0.14141414141414138,0.19327731092436976
10,SP:1ce1cef9988a07ccd2175a718b29ad23bc779429,"This paper address the problem of negative interference which happens when a single transformer model is shared among the different tasks in a multi-task learning setup specifically those of multilingual translation, speech recognition, and multi-domain speech translation.  The proposed approach is to adaptively make use of specific attention heads for a particular task among a pool of attention heads. In this way, the common attention heads between tasks can reinforce the positive transfer while the attention heads unique to each task will avoid the negative transfer. Extensive experiments on multiple tasks of multilingual translation and speech translation demonstrate improvements in performance over strong baselines.","This work proposes an approach to learn to share attention heads in multitask (multilingual, multi-domain) transformer models with multi-head attention layers. Given a multi-head attention layer with $H'$ heads being trained on a set of tasks, each task learns to use $H$ heads, and the choice of attention heads is dictated by learnt latent variables. 2 strategies are proposed for this attention head selection: 1. Subset selection, selects top-$H$ heads for each task. 2. Group selection, where $H'$ heads are divided into groups of $H'/H$ heads, and 1 head is selected per task from each group.  This approach is compared against baseline approaches with full parameter sharing (transformers for MT, speech-transformer for other tasks) and baselines enhanced with adapter modules [1] on multilingual Machine Translation, multilingual ASR, multi-domain ASR, multilingual speech translation and multi-domain speech translation. On all these tasks the proposed head-sharing approach shows modest improvements over the fully-shared baselines.  References: [1] Simple scalable adaptation for neural machine translation, Bapna et al.","This paper aims to mitigate the problem of negative interference when learning models across different languages and domains. In particular, it proposes an approach that learns to share or specialize attention heads based on two different strategies, namely subset, and group selection.  The evaluation of multi-lingual/domain settings shows that this approach outperforms standard transformers and adapters without increasing the number of parameters. ","The paper proposes a transformer architecture for multi-task learning, based on sharing some attention heads in multi-head attention between different tasks. The model is supplied with more heads than necessary and a neural module using gumbel-softmax is used to select a subset of these heads for each task.  A variant of this is described, where heads are distributed between groups and exactly one head is selected from each group.",Multi-head attention is an essential component for popular Transformer models. This paper proposes to learn shared and specialized attention heads for different languages and domains. The authors formulate attention selection as latent variables and adopt Gumbel softmax to select attention heads.  Experiments on text-to-text and speech-to-text translation verify the effectiveness of the proposed approach. ,0.24528301886792453,0.16981132075471697,0.18867924528301888,0.1509433962264151,0.10982658959537572,0.15606936416184972,0.11560693641618497,0.140625,0.234375,0.18055555555555555,0.15028901734104047,0.28125,0.2777777777777778,0.2711864406779661,0.296875,0.375,0.3389830508474576,0.125,0.2542372881355932,0.22033898305084745,0.1863799283154122,0.21176470588235294,0.2247191011235955,0.1939393939393939,0.16033755274261605,0.22040816326530616,0.1724137931034483,0.1323529411764706,0.2439024390243902,0.1984732824427481
11,SP:1e86c162b8e8d652a0590b66aa5f7c363955cc5b,"Summary:  - This submission deals with designing stable and smooth denoisers that could be directly used for regularization, or for plug-and-play (PnP) methods to solve inverse problems.  - This is an improvement upon existing denoisers such as RED and PnP which are not necessarily stable.  - The key idea is to craft neural networks that output scalar-valued potential function g whose gradient is the denoiser residual. To guarantee convergence and stability, g has to be smooth and h=1/2x^2 - g convex.  - Advantages: the denoisers lead to symmetric Jacobians, allowing for a MAP estimation; denoisers can be integrated into optimization schemes with backtracking step size, and thus no need for enforcing Lipschitz continuity. - To construct such a network, GraDnCNN stacks conv layers and nonlinear activations, and proposes DnICNNs with non-negative weights and convex activations. Variants of DnICNN are discussed that achieve better denoising/recovery performance for Gaussian deblurring, and image superresolution.  Contributions: - construct stable denoisers based on neural networks as gradients of smooth potential functions g - integrate the denoisers as a regularizer for solving inverse problems and test it out for gaussian image deblurring and superresolution which outperforms RED and traditional PnP methods "," This paper considers the problem of designing an image denoiser that can be used as a prior within plug-and-play priors (PnP) or regularization by denosing (RED). Prior work has proved the convergence of PnP/RED for contractive, nonexpansive, and/or firmly nonexpansive denoisers. The design of denoisers that enable PnP/RED convergence is an active research area.  This paper focuses on denoisers that correspond to the gradients of some potential functions. By using such denoisers within RED, one can guarantee convergence via traditional optimization. The key idea in the paper is to use a deep neural network to parameterize a potential function (instead of the denoiser), then train that function for denoising by using its gradient. Additionally, when the weights of the network are nonlinear and activation functions are nondecreasing and convex, the denoiser corresponds to a convex function.  The key contribution of the paper is the formulation of a procedure for training a potential function that can be used to obtain a denoiser. The theoretical arguments presented in Lemma 2 and Theorem 1, are well known in optimization (see below for reference). Similarly, Algorithm 1 corresponds exactly to the RED-SD algorithm using a potential-driven denoiser. The empirical results compare three proposed variants of denoisers against PnP-PGD and RED-SD on problems of image deblurring and superresolution.","The paper proposes image denoising based CNNs as regularizers that can be constructed as the gradient of smooth potential functions $g$. The main promise is mentioned to be making an optimization algorithm has explicit regularization, when equipped with those denoisers. Unlike original regularization by denoising (RED) that the explicit regularizer exists if the denoisers satisfy several strict conditions, the proposed denoisers only rely on smoothness. Particularly, the denoisers consist of smooth activation functions to ensure the differential continuity and are trained in a residual denoising fashion using MSE loss. As a result, the proposed algorithm can be formulated as steepest descent variant of RED optimized by directly adopting the gradient of the objective function $F$. Standard back-tracking is used to ensure convergence. A convergence analysis is provided following the common optimization theory. Finally, the performance of the proposed method is evaluated over two image inverse problems such as gaussian deblur and super-resolution, with satisfactory results compared to existing methods based on PnP and RED. ","Motivated by the RED algorithm for solving inverse problems, the authors propose a neural-net denoiser that is the gradient of an explicit potential function.  This guarantees that the Jacobian is symmetric definite, which then guarantees that the RED algorithm minimizes an explicit cost function, which in turn makes convergence straightforward to prove, thereby solving an important open problem about the convergence of RED and plug-and-play (PnP)-type algorithms.  The fact that there is an explicit cost also enables the use of adaptive stepsize selection within RED, with one particular scheme proposed by the authors.  Numerical comparisons to RED and PnP algorithms show improved PSNR and SSIM performance, as well as enhanced stability.","**Summary**: This paper addresses an important issue in the framework of regularization by denoising (RED), which is that the explicit RED regularizer $\frac{1}{2}x^T(x-D_\sigma(x))$ exists only if a set of strict conditions on the denoiser are met. Due to this problem, RED fails to formulate explicit regularizers for advanced denoisers (e.g. CNN) since they generally do not satisfy the conditions. Although some work has established some theoretical analysis for RED algorithms using deep denoisers, a linkage between the denoiser and the regularizer is generally missing.   In this paper, the authors proposed to formulate the regularizer as a *smooth potential functional* $g(x)$, which is parameterized by a CNN with smooth activation functions. To link the potential functional to a denoiser, the authors trained the CNN such that the gradient $\nabla g(x)$ outputs the noise residual for the AWGN. In this way, the proposed method can formulate the gradient-based RED update by directly taking the gradient of the objective function $F(x)$.  Since the objective function is available, the authors also proposed to use the standard back-tracking trick in their framework to guarantee convergence. Additionally, a convergence analysis is also introduced by following the common nonconvex optimization analysis given the handy $F(x)$. ",0.2358974358974359,0.13333333333333333,0.11282051282051282,0.1282051282051282,0.17567567567567569,0.12612612612612611,0.18468468468468469,0.13855421686746988,0.3253012048192771,0.2,0.2072072072072072,0.1566265060240964,0.19130434782608696,0.11737089201877934,0.23493975903614459,0.24347826086956523,0.19248826291079812,0.2,0.2535211267605634,0.107981220657277,0.22062350119904078,0.14404432132963987,0.14193548387096774,0.12254901960784313,0.20103092783505155,0.16617210682492584,0.18850574712643678,0.16370106761565836,0.2849604221635884,0.1402439024390244
12,SP:22822f378c3fbc15b77eb736194b1ce7f0585072,The authors propose a method called Natural Continual Learning (NCL). NCL unifies the concepts of weight regularization and gradient projection into non-interfering subspaces. Gradient projection is implemented as a trust region optimization using the Fisher information matrix. The authors also introduce a Kronecker-factor approximation to improve the scalability properties of their method. The comparison against other continual learning approaches is conducted using recurrent neural network (RNN) architectures. ,"This paper proposes a novel regularization based continual learning approach, NCL, which is mainly used for recurrent neural network (RNN). Since NCL is based on Bayesian continual learning, NCL utilizes the approximate posterior of previous tasks as a prior for current task, and the Laplace approximation is used to compute the approximate posterior. Through simple toy analyses on convex and non-convex loss landscapes for NCL and other baseline methods, authors show that previous methods have a problem on the trajectories of convergence when learning a new task. Based on the results on simple toy analyses, authors proposed a novel trust region based regularization method that modulate the gradient by considering the curvature of prior distribution via its precision matrix. The proposed technique is highly similar to projection based methods, but its origin is quite different from previous methods. Experiment results show that NCL outperforms other baselines in stimulus-response and MNIST tasks. ","The paper addresses the problem of catastrophic forgetting during sequential task learning with recurrent neural networks, a notoriously difficult continual learning setting.   The main theoretical contribution is a formalism, Natural Continual Learning (NCL), which generalizes several related continual learning approaches in the regularization-based family, including several recent SOTA techniques. This formalism applies to the probabilistic learning setting using neural networks, so it is not restricted to supervised learning or recurrent models.  Experimental evidence is provided to support the claim that NCL outperforms previous approaches.  Finally, interesting analogies are made to models of biological learning, which are also supported by accompanying experiments; similar analysis tools are applied to practical instantiations of the NCL framework in controlled experimental settings. ","This paper proposes a model for continual learning. Specifically, it intends to merge parameter regularization methods and gradient projection methods. The regularization is achieved by taking a bayesian perspective over the distribution over parameters, that is approximated by a Laplace distribution in a variational fashion, with online updates. The gradient projection is addressed by trust-region optimization, resulting in an update rule that uses the precision matrix to precondition the gradient of the current task objective, plus a term that keeps the parameters close to the previous mean. Experiments are carried out for sequential problems on a stimulus-response dataset and on stroke MNIST. ","The authors introduce an extension to Bayesian continual learning whereby updates in successive tasks are constrained to be close to a “trust region” of the parameters found in preceding tasks. Exploiting the Bayesian nature of the model, the trust region in question can be defined in terms of the prior precision matrix. The authors show that the method, when applied to RNNs, is effective against baselines in a) a suite of neuroscience related tasks, and b) stroke MNIST datasets.",0.2608695652173913,0.2028985507246377,0.2753623188405797,0.21739130434782608,0.1437908496732026,0.1830065359477124,0.1437908496732026,0.13559322033898305,0.1016949152542373,0.21153846153846154,0.11764705882352941,0.11864406779661017,0.18269230769230768,0.189873417721519,0.1864406779661017,0.2692307692307692,0.27848101265822783,0.15384615384615385,0.1518987341772152,0.27848101265822783,0.16216216216216217,0.1497326203208556,0.21965317919075142,0.20270270270270271,0.16236162361623616,0.21789883268482488,0.1896551724137931,0.14414414414414414,0.12182741116751271,0.24043715846994534
13,SP:23a2171eab71c4fd3754791ca2aac9be87411cdb,The paper proposes a new regularization method for training and fine-tuning large neural networks. The paper proposes to constrain the maximum change in network parameters during fine-tuning. This constraint is different in each layer. Experiments demonstrate that the proposed method outperforms previous approaches.,This paper studies the generalization and robustness of regularized fine-tuning. They present a PAC-Bayes generalization bound that depends on the distance traveled in each layer during fine-tuning and the noise stability of the pre-trained model. They empirically measure these quantities to analyze the behavior of fine-tuning. They present an algorithm that interpolates between two components: (i) regularization over the amount of distance traveled in each layer; (ii) iteratively correcting mislabeled data points that the model is highly confident and down-weighting less confident data points. ,"This paper includes a PAC-Bayesian analysis of distance-based regularisation during fine-tuning. Using this analysis and supplementary experiments, the authors propose a new means for tuning hyperparameters for distance-based regularisation with constraints and heuristics for dealing with label noise during fine-tuning. The experiments show that the method works slightly better than previous approaches designed for both fine-tuning and training with label noise.","This paper studies the aspects of fine-tuning a model (pre-trained on a separate dataset) in order to learn a new task. It has the following contribution:  (i) Generalization properties of fine-tuning explained by the PAC-Bayes generalization bound that depends on two terms: (a) distance between each layer from the pre-trained model and (b) noise stability of the pre-trained model.  (ii) Inspired by the generalization analysis, the paper presents an algorithm to perform fine-tuning. This algorithm includes (a) regularization term that computes the distance between the current parameters and the pre-trained model, and (b) iteratively corrects mislabeled examples where model has high confidence and down-weighting less confident examples.  (iii) Proposed algorithm is evaluated on a suite of benchmark tasks including transfer learning and few shot classification tasks.  ","The paper analyses the fine-tuning of neural networks. It provides a PAC-Bayes bound for the generalization of a fine-tuned network. The paper then provides three tricks to improve finetuning: layerwise regularization, label correction, and label removal. The resulting fine-tuning algorithm improves performance on various image classification tasks, including those with artificially-added label noise.",0.3111111111111111,0.3111111111111111,0.3111111111111111,0.26666666666666666,0.18888888888888888,0.45555555555555555,0.17777777777777778,0.23880597014925373,0.208955223880597,0.14814814814814814,0.15555555555555556,0.208955223880597,0.1037037037037037,0.20689655172413793,0.2537313432835821,0.3037037037037037,0.27586206896551724,0.11851851851851852,0.2413793103448276,0.3448275862068966,0.2074074074074074,0.25,0.15555555555555556,0.23300970873786406,0.2165605095541401,0.3644444444444444,0.2162162162162162,0.15841584158415845,0.224,0.2072538860103627
14,SP:242da1384f48260d58a0e7949438611c05079197,"EDIT: After reading authors' responses, I decided to keep my score as is.  The paper studies the problem of exact representation of continuous functions via neural networks with the ReLU activation. The literature on the approximation power of neural nets is large, however the paper here delves into the less studied question of whether the class of *exactly* representable functions strictly increases when adding more layers (with no restrictions on size).  The authors want to understand the function classes exactly represented by different architectures and a step towards this direction is to analayze the class of functions captured by a depth-d neural net (without width constraints) and how this class of functions changes as we get to depth-d+1 neural nets.  It is obvious that ReLU nets will output continuous piecewise linear functions (CPWL for short) and a non-trivial fact from previous works is that $\log(n+1)$ hidden layers suffice to represent *any* CPWL in n dimensions, via a ReLU net. Let d is a parameter for the depth and and ReLU(d) is all functions representable exactly via ReLU nets of depth at most d. The paper tries to understand ReLU(d) as d goes from 0 to $\log(n+1)$.  The authors put forth two equivalent conjectures about the relations between the class of functions ReLU(d) for different d. Conjecture 1.1 states that every additional layer will indeed be substantial in terms of the representational capabilities of ReLU nets up to $d\le \log(n+1)$ of course, at which point all CPWL are representable. The authors reformulate this with Conjecture 1.2 that is a simple statement about max functions.   The authors then show a special case of Conj. 1.2 that corresponds to showing that the max function on 5 variables cannot be representted with 2 or 3 hidden layers, with the caveat that they need a certain assumption on the breakpoints of the function represented by any intermediate neuron. Along the same lines,  the authors show that the class ReLU(k) contains more functions than just taking the max on $2^k+1$ variables. To achieve this they use the theory of polyhedral complexes associated with CPWL functions.  Finally, the authors find upper bounds on the sizes of the networks needed for expressing arbitrary CPWL functions with p linear pieces, as given in Theorem 4.4, which basically involves depth O(logn) nets with width growing as $p^{n^2}$.   ","This paper studies the role of depth in exactly representing real functions by ReLU networks.  Unlike the common ML setting, the focus is on neural nets that are equal in every point to the target function.  Some partial results are given as well as a conjecture that networks of depth k+1 have strictly more expressivity than networks of depth k.  ","The authors study the class of functions that can be represented by a fully connected neural network with ReLU activations. First, They conjectured that for any $k\in\mathbb{N}$, $n=2^k$, the function $f_n(x)=\max\{0,x_1,\dots,x_n\}$ cannot be represented by a fully connected network with $k$ hidden layers, and prove this conjecture for $k=2$ under some mild assumption. Second, they proved the class of functions that can be represented by a $(k + 1)$-layer NN is strictly larger than the class of functions that are linear combinations of $2^k$-term max functions. Finally, they provided a bound on the width of the NN required to represent continuous piecewise linear functions. ","It is known from the universal approximation theorem that ReLU networks with one hidden layer can approximate any continuous function on compact sets arbitrarily well. Instead of approximations, this paper investigates  the set of functions that can precisely be described by a network of certain depth. For a given input dimension D, a ReLU network with L=ceil[ log2(D+1) ] (or more) hidden layers (and arbitrary width) can describe the entire set of piecewise continuous functions. Here, new insight is provided for networks with having between 1 and L layers. In particular, under an unproven assumption, the paper shows that L is a strict lower limit for the depth and that adding layers to a network strictly increases the set of describable functions. This is achieved by studying a natural candidate function to require a larger number of hidden layers. The candidate function suggests a conjecture on a nice description of ReLU network functions of finite depth, which is shown to not hold true. Finally, the paper derives a bound on the width and depth of networks that can describe any piecewise linear function with fixed number of linear pieces.","This paper considers the problem of characterizing exact representations for ReLU networks of a given depth, but any width. It was previously shown that the functions represented by ReLU networks of depth logarithmic in dimension is exactly equal to the set of all continuous piecewise linear functions. This work provides some results which suggest that this result is tight. That is, a depth logarithmic in dimension is necessary to exactly represent all piecewise linear functions.   Proposition 1.3 simplifies this conjecture by giving a simple equivalent condition in terms of representing max(0,x_1,\dots,x_n) and proves the conjecture up to dimension 4 under the assumption 2.4 which is unproven. In section 3 it is shown that the set of functions representable by a depth k network is a strict super set of Max(2^k) - i.e, set of all functions which can written as a linear combination of max of 2^k affine functions. This provides further evidence in support of the conjecture.  Section 4 then extends the results of Arora et. al 2018 to provide an upper bound on the width required for a relu network to exactly represent affine function with p pieces. This bound is $p^{O(n^2)}$.",0.06326034063260341,0.09975669099756691,0.1362530413625304,0.14841849148418493,0.29508196721311475,0.32786885245901637,0.3770491803278688,0.32231404958677684,0.3305785123966942,0.2198952879581152,0.4262295081967213,0.33884297520661155,0.2931937172774869,0.2932692307692308,0.1487603305785124,0.10471204188481675,0.11057692307692307,0.20418848167539266,0.19230769230769232,0.20192307692307693,0.11016949152542374,0.15413533834586465,0.18604651162790697,0.19709208400646208,0.1978021978021978,0.15873015873015872,0.17100371747211895,0.25,0.24316109422492402,0.21052631578947367
15,SP:26de056be14962312c759be5d284ef235d660f9c,"This paper addresses the problem of constructing injective normalizing flows, which connect some low-dimensional space with the data manifold of interest in the high-dimensional space. Typically injective (or rectangular) flows are composed of two square flows with the “upsampling” padding layer between them. Because the volume change term in the case of injective flows is seemingly intractable, current approaches find workarounds by training these two square flows separately step-by-step. Though this decision has certain drawbacks and may result in suboptimal performance. Current work suggests to employ numerical linear algebra methods to make volume change computation tractable. Experiments demonstrate that taking into account volume сhanging term improves the generation results both for synthetic and real-life data. Interestingly, it also improves out of distribution detection score, allowing the model trained on FashionMNItST to assign lower probability for the MNIST data samples.","The task of interest is to simultaneously learn a manifold (with a fixed predefined dimensionality) and the density on it, from training data. The proposed method, rectangular flows, is developed based on an existing work (Brehmer and Cranmer [6]) that used a two-step training procedure (for manifold matching and density matching, respectively). The main contributions include: (1) revealing that the two-step training can be improved by joint training; (2) a new technique to enable computing the Jacobian-transpose-Jacobian term of the joint training objective with better efficiency. Experiments on simulated data and MNIST/FMNIST are conducted to demonstrate the proposed method.","This paper is motivated by the desire to circumvent a problematic requirement in Normalizing Flows (NFs) on the function $f: \mathbb{R}^d \rightarrow \mathbb{R}^D$ that produces the pushforward measure --- namely, that $f$ must be strictly invertible. This is difficult for generative models, since the dimension of the latent space $d$ is usually much smaller than that of the target data space $D$, i.e. $d << D$. The invertibility requirement centers around the change-of-variables formula, which is crucial for computing the cost function in NFs, and which requires computing the Jacobian of $f^{-1}$. To enable the use of NFs on latent/data spaces where $d << D$, the authors propose ""Rectangular"" NFs (RNFs). The name comes from the fact that the Jacobian of $f$ is now rectangular in the $d << D$ case. This involves the use of a differential geometric variant of the change-of-variables formula, and is much more computationally taxing, but provides superior density estimation performance to previous work. ","The paper addresses the challenge of learning a normalizing flow, under the assumption that the data probability function is concentrated on a low dimensional manifold. Utilizing the manifold assumption introduces a challenge in computing the volume change term. This paper suggests addressing this computational challenge in two ways: i) If the manifold dimension is low enough, it is reasonable to calculate the map differential exactly based on AD forward mode; ii) alternatively, an unbiased stochastic estimator for the log det can be used. ","The paper presents new methods for estimating densities using rectangular normalizing flows. Rectangular normalizing flows, unlike squared normalizing flows, allow considering injective instead of bijective flows. This property is exploited for estimating the density of data residing on a low (d) dimensional manifold in R^D, for D>d. Existing works using rectangular flows to estimate densities supported on low dimensional manifolds assume that the manifold is known, and therefore are restricted to tori, spheres, etc. In contrast, this work does not make this assumption and shows that density estimation for injective flows based on ML is tractable. Two methods are proposed, which are based on incorporating and estimating the “Jacobian-transpose-Jacobian” in the objective. One is based on an exact derivation, which is computationally demanding. The other is based on stochastic gradient estimates. Experimental results on a simulation and a couple of datasets are shown, demonstrating the advantage of the proposed methods compared to an existing method as well as the tradeoff between memory and variance incurred by the two proposed methods.",0.14583333333333334,0.1527777777777778,0.1527777777777778,0.16666666666666666,0.18269230769230768,0.16346153846153846,0.25,0.10843373493975904,0.1686746987951807,0.2891566265060241,0.20192307692307693,0.13253012048192772,0.26506024096385544,0.13793103448275862,0.1144578313253012,0.20481927710843373,0.14942528735632185,0.21686746987951808,0.16091954022988506,0.13793103448275862,0.16935483870967744,0.14193548387096777,0.19383259911894274,0.1509433962264151,0.14074074074074072,0.18181818181818185,0.18705035971223022,0.14457831325301204,0.16470588235294115,0.1867704280155642
16,SP:27c58dad7fa7743a8ff56fad863aa0dae823dccb,"This paper presents a novel type of liquid state machine - neuron-astrocyte liquid state machine (NALSM), which introduces feedback from the network activity to the synaptic plasticity. The proposed mechanism helps to position the liquid (reservoir) layer in the edge-of-chaos dynamics regime, a known key factor to achieve good computational performance. The main contribution of this paper is transforming a biological observation (the role played by astrocytes for modulating the synaptic plasticity) into a novel idea of modulating the liquid activity. It uses feedbacks to obtain edge-of-chaos property in liquid state machine (LSM), and further showing meaningful improvement over the previously proposed LSM-based methods for real-world tasks.",The paper proposes a new version of LSM by adding a factor intended to mimic a proposed role for astrocytes: modulating STDP. The effect is homeostatic in nature and works to keep the network in a computationally efficient regime. It works. The result is a higher performance on MNIST and N-MNIST data sets. ,"Liquid State Machines (LSM)  circumvents the need for backpropagation and allows the training of recurrent neural networks by local plasticity in the readout weights. Previous studies have shown that optimal performance is achieved near a critical phase transition of the reservoir (the liquid). However, the exact parameters of the critical phase transition in the liquid vary and depend on the input. In this work, the authors present a biologically inspired model that allows self-organization near the critical transition. Here, the authors propose a biologically inspired model in which the liquid self-organizes near the critical point. The model is composed of a reservoir of integrate-and-fire neurons. The synaptic efficacies within have unsupervised spike-time dependent plasticity (STDP). The authors propose an additional dynamical variable akin to the activity of astrocytes in the circuit, which modifies the STDP learning rates. The model self-organizes close to the critical point. The authors train several networks on the MNIST and N-MNIST dataset (a spiking version of MNIST, made for neuromorphic computing). They show that the SLM model with astrocyte-dependent STDP plasticity outperforms other LSM models.","The authors propose of a way modulating the connections in a liquid state machine (LSM) so that it moves towards the edge of chaos (EOC) to maximize its performance for various tasks. They do this using by introducing an additional ""astrocyte"" that modulates the parameters of STDP in the neuron model -- specifically the depression term. The authors compare their model to other forms of LSMs. ","This paper extends liquid state machine (LSM) with a biologically inspired astrocyte model (NALSM) to optimize the neuronal dynamics in LSM at the edge-of-chaos, to improve the accuracy and stability of LSMs. With NALSM, the spiking model can maintain a high accuracy without re-tuning parameters for different datasets. Experiments with MNIST and N-MNIST dataset demonstrate that NALSM outperforms classic LSM and other STDP-based LSM approaches, and most existing spiking neuron models including multi-layer SNNs.",0.12389380530973451,0.21238938053097345,0.1504424778761062,0.19469026548672566,0.3333333333333333,0.18518518518518517,0.25925925925925924,0.11229946524064172,0.13903743315508021,0.2153846153846154,0.25925925925925924,0.12834224598930483,0.26153846153846155,0.275,0.0962566844919786,0.15384615384615385,0.175,0.3230769230769231,0.325,0.175,0.1676646706586826,0.16,0.19101123595505617,0.22797927461139897,0.14937759336099585,0.16806722689075632,0.208955223880597,0.16666666666666669,0.1947565543071161,0.19310344827586207
17,SP:2db4aba9a370df67f786157f18cbaa4167c6a46d,"A sizable effort has been made in recent history to obtain the accuracy of very large language models at a fraction of the parameter of the large models. Broadly these methods fall into various categories like model compression, factorized representation, distillation etc. This paper underlines another such attempt at obtaining a factorized representation of matrices to reduce the parameter space. The authors justify the use of Kronecker products to factorize parameter space, by showing that stacked layers of low rank matrices increase expressiveness. They also show the effectiveness of their proposed method by achieving a 4 to 14-fold reduction in parameters without sacrificing accuracy.","This paper presents an approach called ShapeShifter to compress large language models. The paper follows the approach of reducing number of parameters by using factorized matrix representations. The primary idea is to represent the matrix as a sum of Kronecker products, instead of standard low-rank factorizations. The paper theoretically shows that for non-square matrices, the proposed approach allows for increased reduction in parameters for the same decomposition rank. For square matrices, it allows for increased expressiveness of the decomposition for the same rank. Experimental results on machine translation tasks show that the proposed approach performs much better than the state-of-the-art model compression approaches and is just slightly worse than the large models.",Shapeshifter reparameterizes dense kernels into a product of two lower-rank matrices. Shapeshifter introduces reshapes and transposes to make this reparameterization more efficient. The paper provides a theoretical justification for its expressivity and strong experimental results in machine translation.,"This paper proposes an algorithm they call ‘Shapeshifter’ to reduce the number of parameters needed for Transformer-based models while preserving expressiveness and performance. The proposed algorithm is based on the idea of low-rank factorizations of weight matrices, but uses a different factorization method involving sums of Kronecker products that leads to greater expressiveness. They show theoretical analysis to prove their factorization can accurately represent any $n \times m$ matrix or stack of matrices (in an idealized case), and experimental results using transformer-based models for translation on English-German, English-French and English-Romanian. They demonstrate superior or comparable performance with vastly fewer parameters compared to some other model compression techniques.","This paper proposes a method to reduce the number of parameters by weight factorization. Unlike traditional low-rank factorization (n x r and r x m), this work decomposes the matrix into two sqrt(mn) x r matrices. The algorithm includes the reordering of elements to recover the desired shape. The authors find connections to Kronecker products and theoretically support the expressiveness of the proposed method. Experiments on NMT tasks show that Shapeshifter can achieve better parameter efficiency (fewer parameters with comparable performance). The results are compared to two similar works: PHM and DeLighT.",0.2,0.0761904761904762,0.17142857142857143,0.17142857142857143,0.09401709401709402,0.20512820512820512,0.2222222222222222,0.2564102564102564,0.20512820512820512,0.20353982300884957,0.1794871794871795,0.20512820512820512,0.1592920353982301,0.19148936170212766,0.28205128205128205,0.21238938053097345,0.2765957446808511,0.08849557522123894,0.0851063829787234,0.24468085106382978,0.18918918918918923,0.1111111111111111,0.16513761467889912,0.18090452261306533,0.14102564102564102,0.20869565217391303,0.24644549763033174,0.13157894736842105,0.12030075187969924,0.2222222222222222
18,SP:3477b64480ed638b1c4e1f8aa73fc2e77666c89a,"This work studies the query complexity of learning general hypothesis classes $(X,H)$ in the randomized equivalence query model (w/ PAC guarantees). In this interactive model, the learner has access to the “EQ oracle” which upon input of a hypothesis in H, outputs a random counterexample (based upon the target concept and marginal distribution chosen originally by the adversary). The authors use a boosting procedure to show that learning in the randomized EQ model requires only $d*\text{polylog}(1/\varepsilon)$ queries where $d$ is the VC-dimension of $(X,H)$. This provides an exponential separation with the PAC model, which takes $\Omega(d/\varepsilon)$ queries to achieve the same guarantees.  The authors motivate this theoretical result by tying it to recent research in adversarial robustness. They argue that the EQ model can be seen as adversarial training against a restricted adversary. They claim that their results give a theoretical explanation of recent experimental work showing that (on-manifold) adversarial training achieves good generalization, and argue that the exponential separation could be used as a potential tool to prove robustness against such adversaries. ","The paper studies the query complexity of learning a VC class under a certain query model called the Equivalence-Query (EQ) model by Angluin'98. In this model, given a distribution $\mathcal{D}$ and the ground truth $g$, the learner interacts with the data in the following way: (1) learner selects a function f and (2) learner receives a random counter-example distributed according to $\mathcal{D}$, that is, a random draw from $\mathcal{D}|_{f \ne g}$. Under this model, the authors prove an exponentially improved upper bound of $d \cdot \mathsf{polylog}(1/\epsilon)$ compared to the $d/\epsilon$ bound for PAC learning. The paper further draws connections between this model of learning and adversarial robustness. The main argument here relies on viewing the equivalence-query sample oracle as the adversary restricted to on-manifold attacks.","The main result of the paper is showing a separation between the sample complexity of PAC model and the query complexity of an interactive model called Equivalence-Query-learning. The interactive model requires exponentially fewer queries/samples (in the mistake parameter - epsilon). Further, the implication of this result on the adversarial robustness is discussed. ","This paper introduces a new abstract learning model called the EQ-learning, in which the oracle returns examples that the current classifier gets incorrect (rather than arbitrary examples drawn from the data distribution) and returns YES if no such examples exist (indicating the current classifier is correct). They then provide an algorithm which achieves a sample complexity (assuming finite VC dimension d)that is polylog in $1/\epsilon$ as opposed to $O(1/\epsilon)$. This is an exponential increase, and is a very interesting theoretical result on its own.  They then argue how their formalism plays a role in learning from on-manifold adversarial examples. In particular, each of these examples reveals a point that the classifier gets incorrect, and their result consequently suggests that learning from these results should improve the training procedure. ","The paper studies the problem of approximately learning a target function (in the realizable case) when having access to an equivalence-query oracle. In this direction an exponential separation is shown between the two learning models by using an algorithm that borrows ideas from boosting techniques. Furthermore, the authors connect the counterexamples returned from the equivalence query oracle to adversarial examples and thus try to connect their work with adversarially robust learning. ",0.20218579234972678,0.10382513661202186,0.15300546448087432,0.11475409836065574,0.13768115942028986,0.18840579710144928,0.16666666666666666,0.2222222222222222,0.24074074074074073,0.13432835820895522,0.26811594202898553,0.35185185185185186,0.208955223880597,0.2916666666666667,0.35185185185185186,0.19402985074626866,0.3194444444444444,0.08955223880597014,0.18055555555555555,0.25,0.23052959501557635,0.16033755274261605,0.17665615141955834,0.16470588235294117,0.19791666666666666,0.19117647058823528,0.21904761904761905,0.1276595744680851,0.20634920634920634,0.17475728155339806
19,SP:34cc3466ff7786968f437007b6af7d9ffd4decc7,"This paper introduces a conformity score that aims to decrease average interval lengths and improve conditional coverage from a black-box estimate  $\hat{P}(y \mid x)$ for split conformal prediction. The method, conformal histogram regression (CHR), involves first binning the space of $Y$, resulting in a conditional histogram from which approximate oracle intervals can be computed. A nested sequence of these intervals is then created for a sequence of predictive miscoverage values $\tau$, where $\tau$ will be close to $\alpha$ if $\hat{P}(y \mid x)$ is a good estimate. The value of $\tau$ is selected through a conformity score, and the authors show their method obtains finite marginal coverage and asymptotic conditional coverage. The authors then demonstrate the method on a few examples. ","The paper shows how to obtain *short* prediction intervals that approximately have the right conditional coverage. In order to do so, the method estimates the conditional distribution of a new label given its features, and then uses a conformal score based on the quantiles implied by such estimate to create the prediction intervals. The experiments show that the method outperforms other quantile-based conformal methods in terms of width while still approximately controlling conditional coverage. Some theoretical results that prove converge to the oracle (i.e., the shortest prediction interval) are also shown.","This paper proposes an extension to conformal prediction that adapts to skewed data, and can achieve better conditional coverage (and provably achieves conditional coverage asymptotically). Conformal prediction in general is a methodology for constructing confidence sets that output likely response candidates $\widehat{\mathcal{C}}(X) \subseteq \mathcal{Y}$ for and input $X$, rather than a single value. The goal is to ensure that $\widehat{\mathcal{C}}$ covers the true response variable, $Y$, with specifiably high probability. While many prior methods provably control *marginal* coverage, *conditional* coverage is a much harder (and more practically important) goal (albeit impossible in finite samples in the general case). This paper attacks this problem by developing a novel conformalization strategy that leverages calibrated estimates of the conditional density $Y \mid X$ to obtain approximate conditional coverage in finite samples (empirically), and asymptotic conditional coverage (theoretically). ",This paper introduces a new method to construct conformal prediction intervals based on histograms of the conditional distribution of an outcome variable. Given a histogram of the conditional distribution of the outcome variable the method finds the shortest interval whose associated mass is no less than the desired coverage probability of the prediction interval. This yields intervals that automatically adapt to the skewness of the data. The intervals have provably correct marginal coverage in finite samples and correct conditional coverage and optimal length in large samples. A simulation study and numerical experiments on several benchmark data sets corroborate the theoretical results and demonstrate the advantage over several competing methods. ,"This paper proposes a new nonconformity-score based on conditional density estimates P(Y|X). The main idea is to approximate the optimal prediction interval based on the conditional density estimate. The proposed non-conformity score is experimentally assessed using the conformalization technique of split conformal. The overall method provably achieves marginal coverage, performs comparably to other methods for conditional coverage, and achieves the shortest prediction intervals on all datasets. ",0.16,0.2,0.208,0.184,0.20430107526881722,0.23655913978494625,0.21505376344086022,0.16428571428571428,0.14285714285714285,0.2018348623853211,0.21505376344086022,0.17857142857142858,0.23853211009174313,0.32857142857142857,0.1357142857142857,0.2018348623853211,0.2857142857142857,0.21100917431192662,0.2857142857142857,0.3142857142857143,0.1834862385321101,0.1886792452830189,0.22222222222222224,0.2358974358974359,0.1630901287553648,0.21782178217821785,0.24539877300613497,0.18473895582329317,0.19047619047619047,0.24581005586592178
20,SP:3660d1d4a8e8f281880781ba32df7b678b705f9c,"The paper considers a scenario where a fixed computer vision system (such as CNN based classification or regression models) is given and one tries to adapt the design of objects in order to increase their chance of being correctly detected by the system. This setting is similar to the design of marker systems for computer vision with the difference that the detection algorithm is considered fixed.  Two approaches are presented to design (i) patches that can be printed and sticked onto objects and (ii) complete textures that cover the surface of 3D objects. Both approaches follow the design of adversarial perturbations with the difference that instead of maximizing the loss of the system, it is now minimized to improve its performance instead of weakening it.  Experiments evaluate how these approaches can improve the overall performance of the given system as well as its robustness against a variety of different corruptions. Experiments are performed on synthetic 2D and 3D data, as well as on real objects, where the designed patches are printed out and attached to physical objects. Overall, they demonstrate consistent and significant improvements over non-modified objects and simple baselines.","This work proposes and studies two techniques to generate unadversarial images (images which cause a computer vision deep learning model to more reliably give accurate predictions). One technique is for creating unadversarial patches which can be overlaid on testing images to increase the robustness of a pre-trained classifier, the other is for creating unadversarial textures for 3D meshes which when applied to 3D meshes. The work provides strong empirical evidence for unadversarial patches on ImageNet and CIFAR, including results where images are corrupted after applying the patches. Evidence is provided for unadversarial textures on simulated data and a small scale real world experiment.","In this work, the authors leverage techniques from the adversarial examples literature to design patches and textures that aid in classifying an object *correctly.* In a fixed-model setting, they construct patches / textures using gradient-based methods and demonstrate effectiveness on clean CIFAR-10 and ImageNet and various robustness benchmarks such as ImageNet-C (common perturbations). The authors also compare their patches / textures to simple baselines such as QR codes, smaller-sized images from the training set, and predefined fixed patterns.","This work introduces and studies ""unadversarial"" input modifications (patches or object textures) designed to *increase* classifier accuracy, particularly in corrupted images. The work is inspired by research on adversarial examples (in particular ""adversarial patches"" which trick a classifier into predicting a particular class when the patch is present in the scene, regardless of what other class might be present).  Given access to a known, fixed, pre-trained network, a small patch (or the entire object texture) are optimized by gradient descent to increase prediction accuracy. When applied, the method is shown to be quite effective for increasing classification accuracy (and performance on a simple regression task) under a variety of simulated image corruptions (blur, fog, etc.). In addition, the patch method is shown to significantly aid classification even when printed and affixed to real physical objects.","This paper exploits the  known-sensitivity of deep models to perturbation in the input data in order to improve (rather than decrease) the performance of a pre-trained model in a classification task. Specifically, the authors propose to alter the input data (i.e. images)  by 1) adding a patch to the image 2) altering the texture of specific objects. The paper shows experimentally that this improves both in-domain performance and robustness to data corruptions.",0.1099476439790576,0.09947643979057591,0.13089005235602094,0.10471204188481675,0.14423076923076922,0.23076923076923078,0.14423076923076922,0.18518518518518517,0.16049382716049382,0.13970588235294118,0.20192307692307693,0.2345679012345679,0.18382352941176472,0.2631578947368421,0.18518518518518517,0.17647058823529413,0.19736842105263158,0.11029411764705882,0.17105263157894737,0.25,0.1423728813559322,0.13970588235294118,0.15290519877675843,0.14981273408239698,0.16216216216216214,0.20000000000000004,0.16666666666666666,0.13824884792626727,0.16560509554140126,0.17924528301886794
21,SP:3751625929b707ced417c3eb10064e4917866048,"This paper discusses a variant of sum-product networks (SPNs) called ""interventional sum-product networks"" which is a variant of SPNs that take as input a causal graph and use this to model interventional distributions. The claim is that this is the first paper that applies tractable probabilistic models to causality. Theoretical aspects are discussed and the method is evaluated and compared to existing methods. ","The paper proposes to learn interventional distributions using a family of generative models known as sum-product networks (SPN). SPNs are models based on gate functions that allow for tractable inference. Specifically, the authors propose interventional SPNs (iSPN) which are conditional SPNs (they model conditional distributions) that, licensed by a causal graph and samples from the interventional distribution, are shown to be expressive and causally adequate.","This submission proposes interventional sum-product networks, a tractable method for estimating causal effects from interventional data. The authors prove that iSPNs are universal function approximators. They show that iSPNs produce accurate estimates of interventional queries from interventional data on collection of synthetic data generating processes.",This paper proposes a modification of sum product networks termed iSPN to estimate interventional distributions from data. The proposed model performs a manipulation to the structure of the SPN in order to provide estimates from the mutilated distribution. The authors motivate the use of this model in terms of computational complexity and the ability to represent estimates of arbitrary causal quantities on the graph. Empirical results show the proposed model having impressive running time and comparable error results to modern software packages for causal effect estimation. ,The paper proposes a new causal inference framework based on so-called ‘interventional Sum-Product Networks’ to target the problem of a lack of tractability in causal inference. It is based on standard SPNs and employs deep learning techniques to capture complex nonparametric functions describing multivariate conditional probability distributions. It is evaluated on several small synthetic data sets. ,0.27692307692307694,0.16923076923076924,0.27692307692307694,0.23076923076923078,0.19696969696969696,0.22727272727272727,0.18181818181818182,0.2608695652173913,0.21739130434782608,0.1744186046511628,0.2727272727272727,0.2391304347826087,0.20930232558139536,0.25862068965517243,0.2826086956521739,0.1744186046511628,0.20689655172413793,0.13953488372093023,0.1724137931034483,0.25862068965517243,0.2748091603053435,0.19819819819819823,0.23841059602649006,0.24390243902439024,0.23214285714285715,0.19736842105263158,0.1935483870967742,0.18181818181818182,0.19230769230769232,0.20833333333333331
22,SP:395dae632dab83f3f61bdf67eabe4d351492798c,"This paper proposes a biologically motivated mechanism that could allow a network of slow-responding neurons (primarily due to the response lag) to perform computation at a much faster timescale. The key modeling idea is to assume that the neurons compute a ""prospective"" latent state, by linearly extrapolating from the current position in the phase space, by the current momentum and a specific timescale. The authors then assume that neural dynamics is along the extrema of an energy function in the latent state space; hence called the ""Latent Equilibrium"" framework. Using synthetic data, the authors demonstrate that the proposed model can indeed lead to fast computation and learning; they also apply the model to real data from cortical microcircuits. The authors also go further and discuss how the model can be modified to self-correct timescale mismatches.","This paper asks an important question, proposes novel ideas, and presents compelling contributions. The problem being addressed is fundamental and yet has received not much attention,  with no existing good solution. The problem is that physical and biological elements in the brain are slow. Computations propagating through a neural network hierarchy with such elements will introduce time lag.  The mismatch between teaching signals and the current state of the system,  when the input is constantly changing, presents a problem for learning.  The two existing solutions involve (1) separating inference and learning into the ""relaxation"" phase for the computation to complete and the ""learning"" phase for weight update, or (2) use a very slow weight update rate. Both of these are suboptimal.  They proposed a prospective energy function in which the membrane potential of a neuron is trained to map onto a latent equilibrium space where during the relaxation state, the instantaneous outputs of the neurons are the prospective target membrane potentials of the neurons with those recurrent computations. This will allow weight update to be done concurrently with relaxation and solving a problem of achieving arbitrary fast computation with arbitrarily slow neurons.  The resulting model can be interpreted as a biologically plausible approximation of error backpropagation in deep cortical networks with continuous-time leaky neuronal dynamics and continuous active local plasticity. They showed this method work in MINST and CIFAR100, and in fact, the method works better than BP during the early epochs of training.","The authors propose a framework from which a neuron model with (slow) neural dynamics close to physical substrates can be derived  along with a plasticity rule for learning that is similar to backprop. The neuron model allows fast propagation of signals through the network in spite of the slow dynamics of the components, which avoids having to control the timing of learning to turn it on only after the signal has propagated. The authors perform empirical evaluations of networks based on this model on various tasks.","The authors introduce a novel framework called Latent Equilibrium that enables quasi-instantaneous inference regardless of network depth and learning without phased plasticity in networks with slow neuronal elements.  Notably, the framework offers a biologically plausible model of back-propagation. Authors show that the models generated according to the framework have reasonable prediction quality on standard benchmark datasets. The authors also show that the framework can generate good models of cortical networks. Finally, authors explore heterogeneous substrates and conclude that framework is robust.","The paper introduces Latent Equilibrium, a new framework for inference and learning in networks of slow components.   Authors use the leaky integrator dynamics that characterize biological neurons to jointly derive disentangled neuron and synapse dynamics. The neuronal dynamics evolve along a constant-energy manifold, called the Latent Equilibrium.   They show that LE allows for performance gains after the beginning of training, when the disruptive effects of relaxation begin to dominate, as well as robustness of LE on a MNIST classification task. ",0.25547445255474455,0.145985401459854,0.1386861313868613,0.145985401459854,0.09387755102040816,0.07755102040816327,0.08979591836734693,0.20930232558139536,0.19767441860465115,0.21686746987951808,0.14285714285714285,0.23255813953488372,0.2289156626506024,0.24691358024691357,0.26744186046511625,0.2289156626506024,0.2716049382716049,0.21686746987951808,0.20987654320987653,0.2222222222222222,0.18324607329842935,0.179372197309417,0.1727272727272727,0.18348623853211007,0.1389728096676737,0.11585365853658537,0.13496932515337423,0.21301775147928995,0.20359281437125748,0.2195121951219512
23,SP:3c65b3e69a024431cafdc1b4bfbccd432de69faf,"This work proposes counterfactual maximum likelihood estimation (CMLE), a new training objective for suppressing the spurious effect of confounding variables. The authors derive two types of upperbound formulation for interventional log-likelihood (i.e. implicit CMLE and explicit CMLE). Using natural language inference (NLI) and image captioning as the intervention modeling tasks, the proposed method demonstrated superior performance in terms of human-perceived performance.",The paper tackles the problem of spurious correlations caused by observed confounders and offers two potential solutions: implicit and explicit counterfactual maximum likelihood estimation. Specifically the paper deals with the setup of predicting the outcome Y of some action T on X and considers X to potentially be a confounder. The paper compares the performance of the proposed methods to on a natural language inference and an image captioning task and shows improvements in terms of human evaluation but little difference in terms of automatic evaluation.,"This paper applies methodology from CATE estimation to do maximum likelihood with respect to samples from the interventional distributions Y|do(T),X, which they call Counterfactual MLE (CMLE). They provide two algorithms, Implicit CMLE and Explicit CMLE. The implicit variant uses the CATE generalization bounds from Shalit's CATE generalization bounds paper to get bounds on the likelihood from the desired counterfactual sampling distribution. The Explicit variant writes bounds in terms of the distribution T|Y,X. The two methods are applied to natural language inference and image captioning tasks. The authors suggest that this methodology and the surrounding literature on causally-inspired prediction should play a large role in the standard approach of deep learning in order to avoid shortcut learning / relying on spurious correlations.","In this work, authors propose the Counterfactual Maximum Likelihood Objective CMLE, where the parameters of the statistical model are inferred by maximizing the likelihood of the data under the interventional distribution, as opposed to the observational data. For the assumed model X -> Y <- T and X -> T, where X is the covariate, T is the treatment and Y is the outcome, the objective is to learn the parameters \theta that predict Y|X=x,T=t using just the causal link T->Y and not the spurious features in X=x. Ideally, if one could intervene on T and set do(T=t), it is possible to collect data where the outcome is observed upon the intervention done on T. Then maximizing the following likelihood: (CMLE objective) \argmax_\theta \sum_t E_{X|t}  E_{Y|x,t} p_\theta(Y|X=x,do(T=t)) would give us the MLE estimate of the parameter \theta under the set of interventional distributions do(T=t), thereby eliminating any effect of the spurious features in X on the prediction of the outcome label Y. The paper proposes two upper bounds for the above CMLE objective: i) Implicit MLE: focuses on obtaining better representations of the covariates X, such that the distribution of these representations is similar (by Wasserstein distance) for every value of T; and ii) Explicit MLE: where counterfactual examples are generated during training. Expectations in the theoretical derivations of the above upper bounds, can be estimated by Monte Carlo evaluations using only the observational data. Results are provided on two downstream tasks where models often rely upon spurious correlations: i) Natural Language Inference (NLI); and ii) Image Captioning (IC).","This paper proposed to use counterfactual maximum likelihood estimation to learn deep learning models that are less susceptible to spurious correlation relationships. In particular, it proposes two general algorithms, Implicit CMLE and Explicit CMLE, for learning causal predictions of DL models under observational data. The proposed method shows improvement over the regular MLE method in two real data sets.",0.296875,0.3125,0.40625,0.25,0.3023255813953488,0.3023255813953488,0.12790697674418605,0.25196850393700787,0.13385826771653545,0.06785714285714285,0.22093023255813954,0.15748031496062992,0.09285714285714286,0.2711864406779661,0.2047244094488189,0.09285714285714286,0.1864406779661017,0.11428571428571428,0.288135593220339,0.3220338983050847,0.25333333333333335,0.20942408376963348,0.15116279069767444,0.2601626016260163,0.24413145539906103,0.14207650273224043,0.15172413793103448,0.15724815724815724,0.18279569892473121,0.11209439528023599
24,SP:3ca7fdaba9793a61a1f9d264a551fe895e55dd99,"The paper studies a coalition formation process in federated learning. When agents form a coalition, they aggregate their learned parameters in the hope of a more accurate result. The paper presented an algorithm to obtain the optimal way of partitioning the agents in coalitions, so that the total weighted error of the agents is minimized. In addtion, the paper also analyzed the price of anarchy and provided upper bounds of it.","This paper studies price of anarchy (PoA) in federated learning. Following the prior work of Donahue and Kleinberg [2021] which initiate a game theoretic model for federated learning, the authors propose a notion of optimality given the average error rates among agents. Under this notion of optimality, the authors first provide an efficient algorithm to compute the optimal solution, and then give PoA bounds that depend on parameters of settings.","This paper studies a basic federated learning problem, in which some agents, each one with their own dataset, have to jointly agree on a global model. The paper focuses on the trade-off between stability (enforcing that agents are incentivized to collaborate in the global model) and optimality (maximizing social welfare). The paper studies this trade-off by means of a Price of Anarchy analysis.","This paper studies the stable coalition in federated learning, where the agents can choose to join one coalition or leave with incentives to minimize their own errors. The paper focuses on the task of mean estimation, where the error has a closed-form solution. The main contributions are: 1. proposing an optimal algorithm to minimize the weighted sum of errors; 2. providing the upper bound on PoA.","This paper examines the game theoretic aspect of federated learning. In the proposed model, the players are strategic and may not provide their data to the learning platform and choose to federate in a small coalition. The authors provide an algorithm to compute the optimal federating arrangement, and also analyze the bound of the price of anarchy in theory.",0.2535211267605634,0.2676056338028169,0.29577464788732394,0.2535211267605634,0.21428571428571427,0.24285714285714285,0.2857142857142857,0.2923076923076923,0.26153846153846155,0.23880597014925373,0.2571428571428571,0.2923076923076923,0.31343283582089554,0.3050847457627119,0.23076923076923078,0.2537313432835821,0.3389830508474576,0.2835820895522388,0.288135593220339,0.2711864406779661,0.2553191489361702,0.27941176470588236,0.3043478260869565,0.276923076923077,0.22222222222222224,0.24817518248175185,0.3100775193798449,0.28787878787878785,0.27419354838709675,0.25396825396825395
25,SP:3f10ca1e7f8fef6cb0c5957ec2f0689fb9bed753,"This article proposes a study on the rates of estimation of Brenier maps using the plug in ""barycentric mapping"" estimator. As a consequence of this study authors obtain rates of convergence for $W_2^{2}$ in various context (depending on the regularity of the measures and on the setting: discrete-discrete of semi-discrete). They apply their results for Wasserstein barycenter estimation and Nonparametric independence testing. ","This paper analyze the statistical behavior of the general plug-in estimators of OT defined by barycentric projections. The authors provide a thorough analysis of the rate of convergence for the transport cost and the transport map. They also consider kernel smoothed plug-in estimators and relate its rate of convergence to the smoothness of the densities, which alleviates the curse of dimensionality suffered by the plug-in estimator.","Summary =======  Context: --------  This paper tackles the problem of estimating the rate of convergence of empirical Monge maps (through its Kantorovich barycentric map approximator) to the true Monge map for  absolutely continuous Lebesgue measures.    Contribution ------------  - The authors provide new rates of convergence of the barycentric map using standard  empirical plug-in estimators (O(n^{-2/d})) - If the measures are regular enough (Holder smooth), the dependence on the dimension completely vanishes (which was established for Gaussian distributions https://arxiv.org/pdf/1905.10155.pdf) - The authors propose to take advantage of this smoothness result to sample from smoothened distributions (using a Kernel density estimator) and provide the sufficient conditions to obtain a desired rate. Higher smoothness however requires more samples: a tradeoff between statistical accuracy and computational cost cannot be avoided.  ","In standard OT problem, marginal distributions of the data are unknown. The current work considers plug-in estimation using Barycentric projection and derived rate of estimation. The idea of Barycentric projection is to plug the estimated marginal distributions of the data in the OT problem. Conditional mean of given us estimated and rate of estimation is derived. Various plug-in estimators of density of are considered such as empirical CDF and kernel density estimator.","This paper studies the problem of estimating an optimal transport map between two probability distributions on Euclidean space, given IID samples from each of the distributions. The main result (Theorem 2.1) gives a general upper bound, in terms of the dual representation of the 2-Wasserstein distance. This is used to give upper bounds, in probability, on the rate of decay of the estimation risk both for the plugging in empirical distributions in the absence of smoothness assumptions and for kernel estimates under smoothness assumptions. Finally, implications for two applications (Wasserstein barycenter estimation and nonparametric independence testing) are discussed.",0.2727272727272727,0.25757575757575757,0.21212121212121213,0.36363636363636365,0.3333333333333333,0.2753623188405797,0.2608695652173913,0.14615384615384616,0.17692307692307693,0.2702702702702703,0.2608695652173913,0.13076923076923078,0.1891891891891892,0.24,0.17692307692307693,0.25675675675675674,0.18,0.25675675675675674,0.23,0.2,0.2666666666666666,0.17346938775510207,0.20000000000000004,0.2891566265060241,0.23115577889447236,0.2657342657342658,0.21301775147928995,0.1862745098039216,0.2,0.22988505747126436
26,SP:41a6753bc56eb16040600666a859294ae36cfa9c,"The paper studies the problem of active learning on graphs to identify two classes. The main assumption is that the vertices of the same class form a geodesically convex set, and the two classes are halfspace separable.  The authors propose a simple halfspace querying algorithm, and analyzes the upper and lower bounds on the number of queries required to deduce all labels of the graph for binary classification on connected undirected graphs. In particular this number of queries is related to the graph properties and the separation condition between two classes. Furthermore the VC dimension of the hypothesis class is related to the aforementioned properties.  ","This paper studies the query complexity of learning geodesically convex halfspaces on graphs.  In the present context, a geodesically convex set of a graph $G = (V,E)$ is a subset $C$ of $V$ such that each shortest path containing any two vertices of $C$ is contained in $C$, and a halfspace of $G$ is any convex set of $G$ whose complement is also convex.  The main contributions are upper and lower bounds for the query complexity of a class of halfspaces on a weighted graph in terms of various graph parameters.  One upper and almost matching lower bound is given in terms of the size of the minimum shortest cover and the graph diameter.  Another upper bound is given in terms of the minimum size of a hull set, the graph diameter and the maximum size of a set $W_{=ab}^*$ of vertices over all pairs $(a,b)$ of vertices, where $W_{=ab}^*$ is defined to be the set of all points that avoid the intersection of rays from $a$ (resp. $b$) to any point neither in the convex hull of $a/b$ nor in that of $b/a$ and are themselves not in these convex hulls.  The size of the set $W_{=ab}^*$ can also be bounded in terms of the treewidth.  It is shown, moreover, that increasingly tighter lower bounds can be obtained as more stringent separation axioms are assumed.         ","This paper presents novel bounds on the query complexity of learning halfspaces on graphs via convex analysis. Two general upper-bounds were derived along with a simple general lower bound based on extreme vertices. Based on these bounds, the authors developed two querying strategies based on greedy and selective sampling approaches. One interesting practical aspect of the proposed active learning algorithm is the evidence that ground-truth communities in real-world graphs are typically convex. The proposed bounds are compared to previous results based on the cut-size, which show that the halfspace assumption enables learning with large cuts, whereas previous bounds become less applicable.",The authors study the problem of  learning geodesically convex halfspaces on graphs within an active learning setting. They propose a new algorithm and rigorously analyzed it by showing lower and upper bounds of the query complexity. They also carry out an experimental evaluation to validate their theoretical results. ,"This work studies the query complexity of active learning geodesically convex halfspaces on graphs (that is given a graph $G=(V,E)$, the class of subsets $S \subseteq V$ such that $S$ and $V \setminus S$ are both convex). While most prior works gave hypothesis-dependent upper bounds, here the authors give two novel worst-case bounds based on natural graph parameters: the first on the smallest shortest path cover, the second on the hull size, diameter, and tree-width. While neither algorithm is computationally efficient in its original form, the former can be efficiently approximated to within a (multiplicative) logarithmic factor in the diameter, and the latter can be computed efficiently on graphs with bounded tree-width.  The authors also prove a complementary series of lower bounds. The first show both bounds are tight in a weak sense for general graphs in the sense that there exist examples matching the upper bound. They then provide a series of lower bounds based on four (successively stronger) standard convexity properties of the underlying graph $G$. Their final (and tightest) bound holds for graphs on which every two disjoint convex sets are halfspace separable. In this case the only gap between the upper and lower bounds is that between the Radon number and Tree-width of the graph. The authors also provide a number of reasonably natural classes on which their bounds are exactly tight, including trees, $K_{2,3}$ minor-free graphs, partial cubes, and weakly median graphs.   Finally, the authors provide some experimental motivation for their setting, along with a number of heuristic implementations of their algorithm. They compare performance to two non-trivial baseline algorithms, the label propagation algorithm of Zhu et al. (2003), and the $S^2$ algorithm of Dasarathy et al. (2015), and show preliminary experimental evidence that their algorithm outperforms both.",0.3523809523809524,0.19047619047619047,0.1523809523809524,0.38095238095238093,0.1336206896551724,0.06896551724137931,0.27155172413793105,0.12380952380952381,0.3142857142857143,0.4375,0.15948275862068967,0.19047619047619047,0.3333333333333333,0.13114754098360656,0.29523809523809524,0.3333333333333333,0.20655737704918034,0.2708333333333333,0.10819672131147541,0.06885245901639345,0.21958456973293772,0.19047619047619047,0.20915032679738563,0.1951219512195122,0.1839762611275964,0.1142857142857143,0.23463687150837992,0.16993464052287582,0.16097560975609757,0.11898016997167138
27,SP:4c12852373f5f113bd47dce3e2434c5e7d61a202,"This paper studies the problem of high-variance Q-targets under data augmentation, and proposes a method to reduce the variance of the targets called SVEA. The key idea contains three parts: (1) Apply augmentation to the Q-value estimation of the current state and not the next state Q-targets for bootstrapping, and (2) modify the objective to include both the targets using augmented and original observations and (3) optimize the actor using only the unaugmented data for actor-critic algorithms, with parameter sharing.   The paper performed experiments in DeepMind control suite and its variants (with raw pixel inputs). Compared to other data augmentation methods (e.g. DrQ) their proposed SVEA method is robust to the type of data augmentation and is more sample efficient with a better final performance. Some ablations were also presented among the above components to indicate the usefulness of all components. Generalization performance was demonstrated in the DistractingCS and robotic manipulation environments. The method also appears to help when using a Vision Transformers architecture.  ","(Auxiliary Review only -- the authors need not respond to this).  This work proposes issues with data augmentation in RL and proposes a couple of techniques to address those issues. It applies augmentation only on the current state and not future state to address erroneous bootstrapping. It also proposes a Q objective that uses both the augmented and un-augmented data. Also, for actor critic experiments, the actor is optimised only with un-augmented data and learn a  policy that is general via sharing parameters between the networks. These are simple techniques that help the paper demonstrate good results in a range of tasks.  This is a clear paper with good set of experiments. The problem has been described clearly and the work proposes simple refinements to the data augmentation strategies used in RL. While I am convinced of the quality of the method itself and the experiments, this work could have benefitted from more rigour with the baselines to make a stronger case for the method. Hence, I am offering a score of 6 noting that the paper is marginally above acceptance threshold.","The paper presents a way of improving training stability of DrQ (an image-based RL algorithm that uses data augmentation) by applying image augmentation more carefully. The authors propose to input a mix of augmented and un-augmented observations into the critic, and stop augmenting the actor's inputs. On the considered benchmarks the proposed method demonstrates better generalization results. ","The paper addresses the question of zero-shot or fast generalization of value-based deep reinforcement learning agents using visual inputs to image transformation which do not change the (conceptual) state of the environment. The long term goal is therefore training agents which learn efficient, high return control policies both which are robust to irrelevant variations in high dimensional input observations. The ultimate goal seems to be generalization of learned skills to novel environments, but as far as I can tell this particular evaluation philosophy is implemented in experiments.  The paper reviews previous attempts to learn robust state representations to visual variations and formulates clear hypotheses for explaining the causes of difficulties which prior methods faced and were hindered by. The said hypotheses suggest a simplified approach (SVEA) which is empirically developed and evaluated in the remainder of the paper. Control tasks from widely used benchmarks are used to evaluate the method, somewhat less usual is the focus on vision-based high-dimensional versions of such tasks, instead of standard domains such as Atari games and benchmarks for generalization such as Natural Atari [1], CoinRun/ProcGen [2].  ",This work proposes a simple technique to improve the robustness and sample-efficiency of reinforcement learning. The technique can be applied to any algorithm via a simple modification of the input pipeline to said algorithm's Q-learning subroutine. The claim is that this modification reduces the variance of Q-targets and therefore stabilizes learning.,0.2529411764705882,0.11176470588235295,0.17058823529411765,0.09411764705882353,0.09289617486338798,0.15300546448087432,0.09289617486338798,0.31666666666666665,0.16666666666666666,0.0855614973262032,0.23497267759562843,0.31666666666666665,0.15508021390374332,0.2909090909090909,0.2833333333333333,0.1497326203208556,0.3090909090909091,0.10160427807486631,0.18181818181818182,0.2909090909090909,0.24362606232294617,0.16521739130434784,0.16246498599439776,0.14222222222222222,0.13991769547325106,0.15135135135135133,0.14285714285714288,0.15384615384615383,0.17391304347826086,0.1322314049586777
28,SP:4c7d14ab3304cfbf083815aa6e6d9c0e0a5fba6f,"The paper presents a gauge equivariant transformer for geometric learning. The gauge equivariance aims to solve the orientation ambiguity when doing the convolution or local aggregation operations within a neighborhood. Specifically, this work achieves the gauge equivariant self-attention within the neighborhood defined by mesh data. Different from existing gauge equivariant layers, the paper proposes to accommodate the parallel transport in the regular field. As a result, the gauge equivariance is up to a certain error bound. Further, this work validates the effectiveness on two datasets including shape classification (SHREC) and human body segmentation.","This paper addresses the main challenge in attention to manifolds, namely, that there are no coordinates to use as input in positional encoding. The network uses regular fields of cyclic groups and a parallel transport method for transporting features to these fields. Invariance to global rotations is achieved by taking only local position vectors. Experiments are performed on SHREC and Human Segmentation using a fraction of the usual transformer capacity.   ","This paper considers the problem of introducing attention to data lying on manifolds (without a global symmetry). Since there is no canonical coordinate system available in such cases to parameterize neighborhoods, the authors instead use the notion of gauge equivariance, proposing a so-called gauge equivariant transformer. Some additional innovations in the intermediate layers are introduced to improve expressivity, and equivariance error is characterized. Experiments are reported on SHREC and Human Body Segmentation tasks, showing good performance with significant parameter efficiency compared to prior art. ","This paper proposes a gauge-equivariant transformer (GET) for manifolds. The challenging issue for self-attention on a manifold is the lack of canonical coordinate systems on a surface, which results in rotation ambiguity. To address it, this work introduces the regular field of cyclic groups as feature fields, proposes a novel parallel transport approach that puts the feature vectors in these fields, and develops the gauge-equivariant self-attention by adopting Taylor expansion in solving equivariant constraints. The proposed method is validated on the tasks of 3D shape classification and segmentation, achieving SOTA on SHREC dataset and the Human Body Segmentation dataset.","The authors address an important gap in existing literature at the intersection of self-attention networks (transformers) and the equivariant neural networks -- how to apply self-attention to manifolds or meshes (discretized versions of manifolds). This has immediate applications in the area of 3D shapes which are 2D manifolds embedded in 3D. The key challenge is that of gauge-equivariance as there is no canonical coordinate system and we would like the self-attention blocks to be equivariant to the choice of the gauge. To this end, the authors build a provably (approximate) gauge-invariant score function and a gauge-equivariant value function. The experiments show the importance of the proposed methods. ",0.14893617021276595,0.20212765957446807,0.2978723404255319,0.19148936170212766,0.3142857142857143,0.3,0.22857142857142856,0.29411764705882354,0.23529411764705882,0.18446601941747573,0.2,0.2235294117647059,0.27184466019417475,0.16071428571428573,0.25882352941176473,0.20388349514563106,0.14285714285714285,0.24271844660194175,0.17857142857142858,0.16964285714285715,0.17073170731707318,0.2122905027932961,0.28426395939086296,0.17475728155339804,0.28387096774193554,0.24277456647398843,0.1758241758241758,0.2659574468085107,0.20304568527918784,0.17674418604651163
29,SP:506dca4f64f837e32958c3c43a0c68f194a36bb3,"This paper addresses the problem of set encoding when the dimensionality and/or cardinality of the set it too large to fit into memory to feed into an encoder or when set elements arrive in a stream. This paper defines a property, mini-batch consistency, for set encoding functions that encode the set in non-overlapping subsets (mini-batches) then aggregate the mini-batch encodings to achieve the set encoding. If obeying mini-batch consistency, the encoder achieves the same set encoding as if the encoding function was applied directly to the entire set. Finally, the paper proposes an encoding function, Slot Set Encoder, to satisfy mini-batch consistency.","This paper introduces a new concept called “mini-batch consistency” (MBC), which is presented as necessary for efficiently training large-scale set encoding models using mini-batch processing of sets.  MBC is appropriate when the cardinality of the sets in the data is very high, and thus all set elements cannot be loaded into memory, or when the data arrives in a stream.  MBC adheres to the required properties of invariance and equivariance for set encoding models.  A MBC-based set encoding mechanism is also proposed, called the slot set encoder.  Extensive experimental results are provided, which demonstrate that the proposed method is scalable and generally outperforms competing approaches.","The authors proposes the use of attention based set encoder which can scale to arbitrary set sizes. Attention in Transformers has the quadratic dependence on number of positions (i.e. cardinality of the set). The proposed method makes the problem easier by enabling the use of slots while preserving a property which method defines as mini-batch consistency. The proposed method is invariant to the order of the subsets, and invariant to permutations on the set elements.  ","This paper studies the problem of set encoding in the setting where the cardinality of the set is prohibitively large or unbounded. For example, this is the case when dealing with streaming data. A property called Mini-Batch Consistency (MBC) is defined, and it is argued that set encoding algorithms must have the MBC property to learn useful representations of the entire set when partitions of the set are being processed incrementally. A slot-based algorithm that is MBC is proposed. It models interactions between the inputs and slots to learn strong representations. The algorithm, called the Slot Set Encoder (SSE), is compared against Deep Sets and the Set Transformer on a variety of relevant tasks. ","The paper addresses the problem of set encoding when the set is too large to fit in the memory, or given as a stream of data. The proposed method randomly partitions the set,  encodes each random subset and then aggregates all the encodings. The key contribution of the proposed method is that the aggregation of the encodings is required to be equal to the encoding of the full set and it satisfies permutation invariance and equivariance. This property is formally defined and named as Mini-Batch Consistent Set Encoding in the paper. Compared to DeepSets, which also satisfy Mini-Batch Consistent Set Encoding, the proposed method can model pairwise interactions, while DeepSets lack this property. The encoding is implemented using previously introduced slot attention [8] (the attention is done over “slots” instead of self-attention) with the two differences: softmax is replaced with sigmoid in constructing the attention matrix and GRU update of slots is omitted here. The experiments compare the proposed method with two previous methods for set encoding in three tasks showing some improvement.",0.24770642201834864,0.1834862385321101,0.3211009174311927,0.3394495412844037,0.1651376146788991,0.27522935779816515,0.24770642201834864,0.3116883116883117,0.38961038961038963,0.29310344827586204,0.24770642201834864,0.2597402597402597,0.3017241379310345,0.21022727272727273,0.23376623376623376,0.25862068965517243,0.1534090909090909,0.20689655172413793,0.17045454545454544,0.19318181818181818,0.24770642201834864,0.21505376344086022,0.31111111111111106,0.2596491228070176,0.19354838709677422,0.26666666666666666,0.18947368421052635,0.24870466321243526,0.23715415019762845,0.23287671232876714
30,SP:545554de09d17df77d6169a5cc8f36022ecb355c,The paper aims at the identifiability of nonlinear ICA. It proposes a principle as a constraint of mixture functions based on the modified independent causal mechanism principle in the causal discovery literature; investigates the identifiability of nonlinear ICA under such an assumption; then applies it to nonlinear ICA. It also shows that the identifiability results can cover some non-identifiable cases in the existed literature.,"The paper proposes applying the theory of independent causal mechanisms (ICM), from causal discovery, to nonlinear ICA approaches to the blind source separation problem (BSS).  ICM is based on the idea that variables in a system are algorithmically independent or do not share information with each other. The paper shows, however, that ICM is not sufficient for BSS as spurious solutions exist which are not equivalent to the truth.  To address these difficulties, the paper proposes a new condition for identifiability which places an orthogonality condition on the columns of the Jacobian and provides information theoretic and geometric interpretations. The paper then shows theoretically that a large class of spurious solutions are not admitted under the IMA formulation.   Experiments on toy examples demonstrate that the model is identifiable under these spurious solutions.","This work proposes a new regularization scheme to improve identifiability in the _nonlinear blind source separation problem_ (nonlinear ICA) inspired by the notion of _independence of mechanism_ coming from causal inference. The idea is to consider only mixing functions which have a Jacobian matrix with orthogonal columns everywhere. They show how this extra assumption allows to exclude two classical types of degeneracies in nonlinear ICA, although without showing identifiability. The theoretical claims are validated by synthetic experiments.  ","The paper proposes a criterion for non-linear ICA as applied to Blind Source Separation inspired by Independence of Causal Mechanisms in the causal discovery literature. The general idea is to constrain the gradients of the output with respect to the input sources to be orthogonal to each other; this is linked to the notion that the mixing mechanism is in some sense independent (or not ""too fine-tuned"") to the input sources. The authors show that this constraint eliminates a number of known counterexamples to identifiability in non-linear ICA, and test it experimentally to show that helps to characterize true solutions (both as an evaluation metric, and as a regularizer). The authors conclude with a discussion putting their contributions into context.","The authors propose to borrow concepts from causality, in particular ""independent causal mechanisms"" , to propose a novel framework termed ""independent mechanism analysis"" (IMA), which can provide non-spurious solutions to nonlinear blind source separation. IMA can be seen as a restricted nonlinear ICA model, where the contributions of the latent variables $z_i$ to the nonlinear mixing $\mathbf{f}$ are independent, i.e. the columns of the Jacobian $J_\mathbf{f}$ are orthogonal. ",0.2923076923076923,0.2,0.3076923076923077,0.15384615384615385,0.12878787878787878,0.20454545454545456,0.15151515151515152,0.2987012987012987,0.22077922077922077,0.13821138211382114,0.14393939393939395,0.16883116883116883,0.16260162601626016,0.136986301369863,0.22077922077922077,0.21951219512195122,0.273972602739726,0.18699186991869918,0.2328767123287671,0.2328767123287671,0.19289340101522845,0.18309859154929578,0.2127659574468085,0.14492753623188406,0.16267942583732056,0.21176470588235297,0.1951219512195122,0.22999999999999995,0.22666666666666663,0.173469387755102
31,SP:573fbdbe5857c4aace1dfc27e25b8d65a18c9b96,"In this work the authors extend the Kernel Inducing Points (KIP) method for dataset distillation to a new set of kernel functions and achieve new state of the art results on dataset compression. Since the KIP algorithm is a key algorithmic mechanism in this work, I will summarize it: The KIP method optimizes what can be seen as a test residual of a target dataset fitted by a kernel regression model that is created using a support dataset. This means that given a target dataset distribution, one can differentiate through the kernel computations to evolve the support data points in the support dataset freely in the input space and optimize them. After optimization the support dataset (Which is usually taken to be much smaller than the target distribution) can be used as a distilled version of the dataset. This compressed dataset enables classification and training without training with extensively large datasets. In this work the authors use the KIP algorithm using a family of kernels corresponding to infinitely wide neural networks that were discovered in the realm of NTK. Such infinite NTK convolution kernels are known to provide state of the art results (when compared with other kernels) on classic classification tasks such as MNIST, CIFAR, etc. The biggest issue of such infinite-network kernels is that they require immense amounts of computation to construct the kernel. In this work, the authors construct such kernels at each training step (!) and then back-propagate through the kernels (!!) to optimize the datapoint. This impressive feat is made possible by considering 3 layer convolutional neural networks and working with a relatively small number of data-points (5K as opposed to the whole dataset). This is still highly computationally challenging and the authors create a careful implementation including an orchestration system working with 100s of GPUs for optimizing the support dataset. With this new kernel family the authors achieve state of the art results on dataset compression and analyze the compressed dataset using high dimensional statistics tools.","The paper proposes to use infinitely wide CNNs to perform dataset distillation – obtaining a tiny dataset that enables high accuracy. The approach is an extension of a prior work (Kernel Inducing Points (KIP), etc.). Results are shown on MNIST, Fashion-MNIST, SVHN, CIFAR-10/100 datasets.","Paper mainly extends the dataset distillation algorithms KIP and LS (Nguyen et al. 2021) to infinitely wide neural networks. To that end, authors present a distributed framework that draws upon huge hardware resources and show improvement on the distillation performance. Paper also analyzes the synthesized data samples (images, labels) via multiple studies.","This paper performs dataset distillation to improve the deep learning training efficiency. By using the algorithm made by [1] and some expanded methods, the authors achieved the state-of-the-arts accuracy on CIFAR-10, MNIST, Fashion-MNIST, CIFAR10, CIFAR100, and SVHN datasets.  [1] DATASET META-LEARNING FROM KERNEL RIDGE REGRESSION, ICLR 2021","The paper performs thorough analysis and exploration on the implication of the proposed KIP and LS methods by Nyugen 2021 for dataset distillation. KIP and LS are based on the inf-width network limit as kernels, and devised based on kernel Ridge regression, and has been shown in prior work to have good dataset distillation performance. This paper greatly extends the analysis in Nyugen 2021, by investigating how KIP and LS can be used to achieve SOTA dataset distillation results in a kernel setting, and also sometimes in a neural network (NN) transfer setting. Furthermore, the authors provide impressive and insightful analyses on (1) how the dataset distillation performance behaves as knobs of the algorithms are tuned (2) what are the properties (spectral, intrinsic dim., visual) of the distilled data. Not every paper needs to propose a new method or new theory. Here, thorough analysis and understanding of an existing good method should still be appreciated.",0.04804804804804805,0.05105105105105105,0.06306306306306306,0.11411411411411411,0.17391304347826086,0.2391304347826087,0.2391304347826087,0.1346153846153846,0.34615384615384615,0.2641509433962264,0.34782608695652173,0.3269230769230769,0.39622641509433965,0.24358974358974358,0.15384615384615385,0.20754716981132076,0.07051282051282051,0.1320754716981132,0.11538461538461539,0.08974358974358974,0.08443271767810026,0.08831168831168831,0.1088082901554404,0.15541922290388546,0.16326530612244897,0.22222222222222224,0.10891089108910891,0.13333333333333333,0.17307692307692307,0.1339712918660287
32,SP:590b67b1278267e966cf0b31456d981441e61bb1,This paper develops a learning based approach for end-to-end reconstruction of operators for ill-posed problems. In particular it examines the problem of image reconstruction. The main contribution is to combine traditional variational approach with an optimal transport based regularizer.,"This paper proposes a method for adversarial regularization, to be used in image reconstruction. This method relies on a joint training of the regularizing part of the system and the reconstruction. Several properties regarding convergence are proven, and the method is shown to outperform similar regularization methods for this task.","This paper proposes a deep learning based reconstruction for ill-posed inverse problems that combines ideas from end-to-end supervised training with learned regularization in a variational setting. The method adversarially trains the weights of a deep neural network (used as a prior for regularization) while also learning an end-to-end, unrolled deep network. The unrolled network takes the form of a learned primal-dual algorithm, and the regularizer aims to discern between ground-truth images and images generated by the unrolled network. After training, the end-to-end network can be used for reconstruction alone, or as an initialization for a separate reconstruction that strictly uses the learned regularizer in a variational setting. The authors claim that this combines the best of both worlds, as an end-to-end model can be used for fast reconstruction, while the variational model can be used for refinement (while also being more amenable to analysis). The authors provide theoretical and empirical evidence that their approach is successful and outperforms other state-of-the-art methods. ","This paper proposes a framework for training an adversarial network, where the discriminator is a regularization functional, for image reconstruction.  A similar work mentioned in the paper is [14]. The key difference between [14] and the proposed method, UAR, is that the former is based on the variational inference while the latter replaces it with an unfolding network, making UAR a pure end-to-end training deep learning model. Since UAR incorporates the forward model in the loss function, it is self-supervised requiring only $y$ to impose supervision.  The author also addresses the theoretical properties of UAR, presenting interesting results on the optimality, influence of $\lambda$, and justification of end-to-end learning & regularization.","This paper proposes a framework, named UAR, for jointly training an iterative deep unfolding neural network (DUNN) and an adversarial discriminator based on Wasserstein distance for solving image inverse problems, inspired by adversarial regularization (AR) method (Lunz’2018). Unlike original AR method that takes pseudo-inverse reconstruction as input images, the proposed method assimilates the reconstruction from DUNN that unrolls the iterative primal-dual algorithm in each training step. The authors also provide theoretical analysis about when such adversarial training with unrolling networks would be successful. The theoretical results are well established by with thorough proofs. Finally, the performance of the proposed method is evaluated for solving CT inverse problem with satisfactory results compared to both supervised and unsupervised deep learning methods such as U-Net, LPD, and AR.",0.30952380952380953,0.42857142857142855,0.30952380952380953,0.2857142857142857,0.38,0.4,0.36,0.17142857142857143,0.16,0.24347826086956523,0.26,0.10285714285714286,0.11304347826086956,0.09302325581395349,0.10857142857142857,0.17391304347826086,0.13953488372093023,0.2608695652173913,0.21705426356589147,0.21705426356589147,0.2826086956521739,0.16589861751152074,0.1656050955414013,0.14035087719298245,0.1688888888888889,0.24242424242424243,0.20111731843575417,0.20689655172413796,0.18421052631578952,0.22950819672131148
33,SP:59cfeb59cecac51fecff8f8ceb0266fc6ac22a05,"In this paper, the authors study the problem of deep sparse prediction based on NAS. In order to reduce the search cost, they propose a distilled search space, which is a low-rank approximation of the full space. They also propose a progressive differentiable search to capture the order-priority in sparse prediction. Numerous experiments are conducted to demonstrate the effectiveness of the proposed method. ","This paper proposes a method for searching for the interaction of the feature columns in a CTR prediction application. The paper title suggests an application for deep sparse networks but it doesn’t seem to be explicitly tied with the requirement of the input being sparse. To this end, the paper proposes an iterative algorithm that incrementally learns the interaction tensor from lower rank to higher rank, and from lower order to higher order. Empirically it observes some benefits compared to current competitive methods on Criteo, Avazu and ML1M datasets.","This paper targets applying NAS to Deep Sparse Network (DSN) domain. To search for a good DSN, previous methods that apply DARTS based method to search an encoding vector, where each element represents the probability to select feature-interaction. Due to the interaction grows in a factorial way, the search parameters will soon become intractable. This work proposes to decompose this vector into multiple low-rank ones, to reduce the search space dramatically.  Experiments on various datasets show a clear improvement comparing to the previous baseline AutoFIS. I would recommend accepting this one but since I am not really familiar with the DSN domain, I might change my mind based on other reviews.","The authors consider the problem of designing accurate and computationally efficient deep sparse networks (DSNs), which are an important problem in applications with sparse features such as click-through rate or movie recommendation. The authors propose a new approach based on neural architecture search (NAS) using two techniques: distillation of the search space (of cross-features), and a progressive search algorithm. They show that their approach leads to improvements in both accuracy and inference time, on three datasets.","This paper proposes a neural architecture search approach, PROFIT,  for deep sparse networks.  PROFIT introduces a distilled low-rank search space and a progressive search algorithm from the lower orders. The proposed method is evaluated on three benchmark datasets and the authors conduct extensive ablation study and discussion on the method. The paper is well written and very easy to follow even for people without a NAS background.   ",0.2153846153846154,0.26153846153846155,0.3076923076923077,0.24615384615384617,0.18888888888888888,0.16666666666666666,0.15555555555555556,0.10619469026548672,0.11504424778761062,0.1794871794871795,0.15555555555555556,0.1504424778761062,0.2564102564102564,0.23529411764705882,0.1504424778761062,0.19230769230769232,0.20588235294117646,0.15384615384615385,0.19117647058823528,0.20588235294117646,0.18064516129032257,0.19101123595505617,0.27972027972027974,0.2406015037593985,0.16748768472906403,0.17857142857142855,0.17721518987341772,0.1256544502617801,0.143646408839779,0.19178082191780824
34,SP:5e3572a386f890c5864437985cf63b13844f338f,"This paper introduces a novel adversarial fine-tuning method, which they apply to language model fine-tuning. Their method, named RIFT, takes an information-theoretic perspective to define the new loss; this paper is very clearly written and includes mostly useful figures that help explain their novel approach. They show strong experimental results with a number of baselines, and run an ablation study for the hyperparameters introduced by their approach.","This paper studies the catastrophic forgetting problem when fine-tuning pre-trained language models towards adversarial robustness. They argue that existing robust training methods, such as adversarial training, make the objective model deviated too much from the pre-trained model, resulting in bad generalization. Starting from an information-theoretical perspective, the authors propose RIFT, a fine-tuning method that maximizes the mutual information between the outputs of the objective model and the outputs of the pre-trained model when conditioned on the labels. The experimental results show that RIFT has a better performance than other baselines, which supports the better generalization as the authors claim. In addition, they give explanations why considering I(S;T|Y) in the objective is better than considering I(S;T).   ==== After Rebuttal ====  Thanks for the response. All my questions are properly resolved.","This paper proposes a new method for finetuning pretrained NLP models to achieve both high standard and high robust accuracy. They argue that finetuning on the more difficult and plentiful adversarial examples can lead to catastrophic forgetting, more so than standard finetuning of models. They propose an additional loss wherein the model is encouraged to get high accuracy while also retaining features from the pretrained weights. This improves the accuracy over standard finetuning and various other ways of regularizing adversarial finetuning.","The paper studies the problem of adversarial fine-tuning of pretrained NLP models, that is fine-tuning them in a way that makes them robust to adversarial attacks. It proposes a new method called RIFT. RIFT alters the usual adversarial training by adding a regularization term that maximizes the conditional mutual information between feature vectors produced by the original pretrained model and the currently fine-tuned one. The motivation is to alleviate catastrophic forgetting. The experiments show RIFT getting a slightly higher adversarial robustness than the baselines methods, such as e.g. using the L2 penalty instead of the proposed regularizer.  ",This paper argues that applying adversarial training into the fine-tuning of the pre-trained language model suffers severely from catastrophic forgetting. It then proposes Robust Informative Fine-Tuning (RIFT) to encourage an objective model to retain the features learned from the pre-trained model. The results on sentiment analysis and natural language inference tasks show that the proposed method is able to outperform the strong baseline models in terms of Genetic and PWWS attacks.,0.2571428571428571,0.17142857142857143,0.21428571428571427,0.2571428571428571,0.10144927536231885,0.2318840579710145,0.1956521739130435,0.18518518518518517,0.18518518518518517,0.16831683168316833,0.13043478260869565,0.14814814814814814,0.1485148514851485,0.24,0.1728395061728395,0.31683168316831684,0.36,0.1485148514851485,0.2,0.22666666666666666,0.17307692307692307,0.15894039735099338,0.17543859649122806,0.2482758620689655,0.1278538812785388,0.2677824267782427,0.2535211267605634,0.16483516483516483,0.1923076923076923,0.19318181818181818
35,SP:64ccd697d3c11d7d8947ef1b06c61d94b6a2e575,"The paper studied the problem of imbalanced classification on graphs, by proposing to unify the quantity imbalance and topology imbalance together. The authors develop a label propagation algorithm that locates the topological position of the labeled nodes, and then re-weight nodes to alleviate the imbalanced data distribution. Experimental results on various benchmark datasets show the performance of the proposed model. ","This paper first points out the topology-imbalance problem of node representation learning on graph-structured data. To address the problem (which is denoted as Topology-Imbalance Node Representation Learning, TINL), this paper presents a conflict detection-based metric (named Totoro) based on label propagation algorithm and Personalized PageRank matrix. Then, the authors introduce the ReNode algorithm that considers the Totoro of each node in semi-supervised training of GNN models. The ample experimental results show the superiority of ReNode in addressing the TINL problem. "," The issue of imbalance is a very critical problem in ML, especially in a realistic setting. In general, imbalance is quantitative, but this paper points out topological imbalance as a graph-specific problem. As a solution to topological imbalance, a method of reweighting called ReNode is proposed and its effectiveness is verified.","The authors concerns the topological imbalance problem in node classification problem. The imbalance caused by  asymmetric topological structure during the semi-supervised learning process. The authors introduces the intuition with classical label propagation problem and extended it to the case of learning GNN. To alleviate the pain of the imbalance issue the author introduced the Node reweighting loss, which puts more effort on learning with nodes that have less distance weighted conflicts.   ","Authors study a problem named topology imbalance which is led from the topological difference of labelled nodes in a given graph. It degrades the performance of node classifiers by 'shifting' the decision boundary. The main contributions of this paper are (1) it points out the topology imbalance problem in node classification tasks; (2) it proposes a metric (Totoro) to measure the topology imbalance; (3) it designs an annealing method to reweight samples based on their topological importance; (4) authors provide vast experimental results over multiple scenarios, datasets, and baselines.",0.3770491803278688,0.13114754098360656,0.2786885245901639,0.21311475409836064,0.1411764705882353,0.18823529411764706,0.21176470588235294,0.19230769230769232,0.28846153846153844,0.20833333333333334,0.27058823529411763,0.15384615384615385,0.2361111111111111,0.14606741573033707,0.23076923076923078,0.2222222222222222,0.20224719101123595,0.1388888888888889,0.16853932584269662,0.16853932584269662,0.31506849315068497,0.1415929203539823,0.25563909774436094,0.1733333333333333,0.17518248175182483,0.2038216560509554,0.20689655172413793,0.16129032258064516,0.2127659574468085,0.1863354037267081
36,SP:660137b0f84e47c06dc2bee1c95b299c67e4cb67,"The paper presents a technique for dealing with the problem of choosing bandwidths for positional encodings in implicit functions. The method presented uses higher frequency positional encodings as training progresses and clips the maximum frequency when a quality criterion has been reached for a position (therefore it is spatially adaptive) in order to avoid the appearance of artifacts.  Results on several domains (images, 3d occupancy, and mesh deformations) are presented with good results in all cases.","The submission presents a way of improving training of deep implicit networks, that take Cartesian coordinates (e.g., 2D or 3D) as inputs. The method uses additional embeddings of the input coordinates, similarly to Positional Encodings and variations (SIREN, FFN), with 2 differences: - embeddings corresponding to higher spatial frequencies are only be made available later during the optimization phase, and only if the network does not fit well enough - they can be made available selectively on different parts of the input space, based on a spatial grid. This method makes it possible to better represent inputs where the maximal spatial frequency changes a lot between regions (e.g., an image with large smooth regions, and regions of higher detail), and compares favorably to similar methods.",This paper proposes an improvement of implicit function approximation for image and mesh generation. The main contribution is to use a progressive low resolution to high resolution optimization as well as spatially adapt this `masking`. Performance is shown to be better than FFN by a significant margin.,"This paper highlights a problem with Position Encoding models that use Fourier features: they're very sensitive to a bandwidth parameter that trades-off between reproduction of low- and high-spatial frequency features. Their solution is an iterative feedback algorithm that reconstructs images in a coarse-to-fine manner. They describe incremental improvements across-the-board, and large and impressive improvements in their 2D silhouette reconstruction task.","Implicit neural representations are a promising approach to learning compressed representations of data --- for example they can learn to represent an image where the network inputs are the (x,y) coordinates and the outputs are the RGB pixel values. This idea has all sorts of applications in data science and physics.   This work provides a method for improving the optimization of these implicit neural representations. It addresses the challenge that standard MLPs are biased towards learning low-spatial frequencies, and that a dataset (e.g. an image to compress) can have different frequency distributions in different regions. ",0.23684210526315788,0.10526315789473684,0.15789473684210525,0.15789473684210525,0.088,0.08,0.16,0.1702127659574468,0.1702127659574468,0.16417910447761194,0.144,0.1702127659574468,0.1791044776119403,0.12371134020618557,0.23404255319148937,0.14925373134328357,0.20618556701030927,0.11940298507462686,0.08247422680412371,0.1134020618556701,0.17910447761194032,0.13008130081300812,0.1678321678321678,0.13872832369942198,0.12790697674418605,0.10416666666666666,0.1801801801801802,0.14035087719298248,0.1111111111111111,0.13414634146341464
37,SP:69c522cea4a150624bc709e1c12c0f65183c1b2a,"This work provides theoretical insight for why overparameterized models perform well when there is some covariate shift between the training and test sets. The authors' characterize their results by introducing a notion of ""relative hardness"". They present empirical evidence to match their intuition, and corroborate the main results in the paper using several empirical benchmarks.",This paper studies random feature regression in high dimensional setting with the presence of covariate shift between train and test data. The authors compute the high-dimensional asymptotic limit of the test error for Gaussian covariates with a shift in the covariance matrix. They also provide results characterizing the bias and variance decomposition.,"The authors study covariate shift in over-parameterized random features models.  They provide an analysis of the test error, as well as an analysis of the decomposition of the test error into the bias and variance components.  This results in a partial ordering over test errors WRT the ""hardness"" of the covariate shift.  Further, the theoretical results provide a concrete explanation of the linear trend that has been observed in past work between the test error on clean and corrupted error.  ","The paper studies the test error, as well as the bias and variance, of random feature regression in the asymptotic regime, in a setting with covariate shift — i.e., when the covariance matrix of the features is different at testing time than at training time. The paper defines a partial ordering over covariance shifts, and it proves that this corresponds to increased or decreased performance compared to the case of no shift. It also obtains a few results that relate these notions to overparameterization.","This paper presents a theoretical study of covariate shift under the setting of kernel ridge regression in the asymptotic regime. They charaterize the limiting test error, bias, and variance in this setting. They relates these with a quantity named hardness. They claim that their findings agree with several interesting empirical phenomena. ",0.21818181818181817,0.21818181818181817,0.18181818181818182,0.21818181818181817,0.2830188679245283,0.32075471698113206,0.2641509433962264,0.25925925925925924,0.19753086419753085,0.15476190476190477,0.22641509433962265,0.14814814814814814,0.11904761904761904,0.23529411764705882,0.18518518518518517,0.20238095238095238,0.27450980392156865,0.25,0.3137254901960784,0.2549019607843137,0.2222222222222222,0.17647058823529413,0.14388489208633096,0.22641509433962262,0.22388059701492538,0.2481751824817518,0.2692307692307692,0.2545454545454545,0.24242424242424243,0.1925925925925926
38,SP:6e8134eeaf524db765a6186f3de74e936243f8d4,"Contribute an attack where the DNN is more confident of its incorrect predictions than about its correct ones without having its accuracy reduced. Attacks contributed in the white-box and black-box regime, where the black-box regime here constitutes ""the attacker has no knowledge of the target network"". Demonstrate minimal perturbations successfully attack existing uncertainty estimation methods. ","This paper presents a novel uncertainty estimation attack technique. Unlike most existing adversarial attacks, which cause incorrect prediction results, this novel attack technique only cripples the network’s capacity for uncertainty estimation. The result is that, after the attack, the DNN is more confident of its incorrect predictions than its correct ones without having its accuracy reduced. Also, as this proposed attack can be accomplished without harming the model’s accuracy, and thus avoid raising suspicion about a possible attack.","The paper shows that one can manipulate the uncertainty estimation of a neural network without harming its accuracy by perturbing the inputs. To this end, the paper proposes a greedy heuristic to decrease the perturbation size of FGSM until the adversarial example does not flip the original prediction. Experimental results show that the proposed method indeed can increase several uncertainty estimation metrics (i.e., AURC, NLL, and Brier Score) of several types of neural networks regarding the uncertainty, e.g., softmax-based or MC dropout, without reducing their accuracy. ","The paper presents a novel way for adversarial attacks.  This work studies the problem of attacking networks to change their confidence without affecting the accuracy. Such attacks increase the confidence of the network on wrong predictions and decrease the confidence of the networks on correct predictions. Since the accuracy of the network is not the target, this enables the. attacker to use smaller attacks that might not be easily detected. The paper studies both white-box and black-box attacks on different kinds of uncertainty estimation methods including MC-dropout, SelectiveNets, and Ensemble methods. Finally, the paper presents extensive empirical evaluations that support the proposed method.","The paper presents an interesting method to create adversarial examples that do not change the class label, but rather flips the confidence in that label.  In other words, the accuracy of the classification system is not changed.  Rather, the idea is that the attack will force a system with well calibrated confidence to become confidently wrong and unconfidently correct rather than the desired behavior of being unconfidently wrong and confidently correct. The overall approach is basically the same as a standard label adversarial attack (i.e., follow the gradient), but at a lower magnitude as not to change the label.  The other minor difference is to determine the direction of the gradient depending on the ground truth label of the test sample.  That is increase confidence if the classification label prediction is incorrect and reduce the confidence otherwise. The paper does include extensive experimentation over various neural network models including uncertainty-aware models such as ensembles, MC dropout and SelectiveNet. ",0.3793103448275862,0.20689655172413793,0.27586206896551724,0.20689655172413793,0.1625,0.225,0.2,0.23595505617977527,0.24719101123595505,0.27358490566037735,0.275,0.1348314606741573,0.1509433962264151,0.075,0.14606741573033707,0.16981132075471697,0.1,0.19811320754716982,0.1375,0.18125,0.3188405797101449,0.163265306122449,0.1951219512195122,0.11009174311926606,0.15384615384615385,0.1935483870967742,0.13333333333333333,0.2153846153846154,0.17670682730923695,0.2180451127819549
39,SP:727bcd651b11b7d84dd2c2d535cc85402f9117d4,"This paper has presented HiT, a Transformer-based generator for high-resolution image synthesis based on GANs. Instead of using full attention, this paper has proposed the multi-axis blocked self-attention, which captures local and global dependencies within non-overlapping image blocks in parallel. In addition, HiT introduces the cross-attention mechanism to integrate noise information into multi-stages of the generator. Extensive experiments demonstrate the superiority of the proposed method.","The paper describes a purely attention-based GAN generator architecture where low-resolution deeper layers feature larger-scale (more distant) communication and higher-resolution layers synthesize locally using MLPs,  but still conditioned (indirectly) on the initial latent code.  State-of-the-art results are claimed for 128^2 unconditional ImageNet synthesis (but I believe this claim to be false, see below). In addition, results are shown for CelebA-HQ and FFHQ. While the architecture have some similarities to the near-concurrent work of Hudson and Zitnick (ICML 2021), lack of comparisons should not be held against this paper.  I remain unconvinced by the argumentation and how the results support them. Visually high-quality results are only shown for the simple face image datasets, for which attention mechanisms do not appear to be as necessary as for more complex ones that feature scene compositions. I feel I do not walk away feeling that I learned something.",This paper proposes a new transformer-based generator for high-resolution image generation. It addresses the quadratic scaling problem of the attention operator with multi-axis blocked self-attention which considering the within blocks and across blocks attention. The proposed cross-attention for input and intermediate features is also novel. The evaluation is done in ImageNet and FFHQ datasets.  Promising results are provided. ,"To address the quadratic complexity of the self-attention operation, this paper proposes a new Transformer-based generator for high-resolution image generation based on GANs, denoted as HiT. In the low-resolution stage, the authors propose a multi-axis blocked self-attention. In the high-resolution stage, they keep multi-layer perceptrons reminiscent of the implicit neural function. Extensive experiments demonstrate the effectiveness of the proposed method. ","The paper proposes a transformer based generative model which shows competitive results on multiple image generation benchmarks. It combines existing techniques of blocked and axial attention to reduce the computational complexity of self-attention mechanism. To further reduce the complexity, the proposed attention mechanism is only used at lower resolution blocks. The paper also employs technique similar to self-modulation to condition image generation process on the input latent code at all levels.  ",0.2222222222222222,0.3333333333333333,0.4444444444444444,0.20833333333333334,0.0967741935483871,0.0967741935483871,0.0967741935483871,0.36507936507936506,0.30158730158730157,0.22058823529411764,0.1032258064516129,0.38095238095238093,0.47058823529411764,0.2054794520547945,0.23809523809523808,0.22058823529411764,0.2054794520547945,0.3382352941176471,0.2602739726027397,0.2054794520547945,0.14096916299559473,0.35555555555555557,0.45714285714285713,0.20689655172413793,0.13761467889908258,0.13452914798206278,0.13157894736842105,0.35114503816793896,0.27941176470588236,0.21276595744680848
40,SP:7520cc1203bb06bbe432e7cc679892e95258ed99,"The paper studies methods to select source models from a diverse set, considering both the quality of the proxy for downstream performance, and the speed of computing the proxy. The paper introduces a new benchmark for evaluating the ability to choose from diverse source models, studies a number of existing methods, and highlights some shortcomings. It then proposes some tweaks to improve these. Finally, the paper proposes a new proxy PARC, which performs well on their benchmark (also using the aforementioned tricks), and also on an extended evaluation on crowd-sourced models.","This paper introduced a unified benchmark to test the performance of existing transferability estimation algorithms. The main contribution is firstly its unified benchmark, and then, its experiment models and datasets are large, which show a fair comparison for all methods. Finally, they modified an existing algorithm to propose a new one, which achieves better Person correlation score over others.","The paper studies model selection for transfer learning: given a number of source or upstream models, and a new downstream or target data, how can we choose the best model to finetune? The paper offers two main contributions. First, it proposes a specific benchmark with source models, target tasks, and an evaluation metric to compare different approaches. Second, after testing on a number of methods from the recent literature, it identifies some algorithmic aspects that seem to hurt these methods and proposes an alternative approach called Pairwise Annotation Representation Comparison (PARC) which addresses those. Experiments suggest PARC outperforms the original algorithms.","The authors introduce the “scalable diverse model selection” task and introduce several tools and benchmarks for evaluating model selection methods in this setting. They show that current transferability and model selection methods fail to beat simple baselines in this new setting. They analyze the reason for this case and provide techniques to improve performance. They develop PARC, a method that outperforms other methods on diverse model selection.","The paper proposes a model selection method wherein best experts are selected from a model zoo to fine-tune on the target task. The proposed method ""Pairwise Annotation Representation Comparison"" is an improvement over RSA [8], instead of using a small dnn trained on target task (or probe network) the authors use spearman correlation between RDM of features and label as model selection score (called PARC score). The proposed method is compared to many baselines NCE, LEEP, RSA, DDS etc. and shows better correlation to fine-tuning accuracy.",0.15217391304347827,0.2826086956521739,0.13043478260869565,0.15217391304347827,0.2033898305084746,0.15254237288135594,0.1694915254237288,0.12871287128712872,0.15841584158415842,0.16417910447761194,0.23728813559322035,0.25742574257425743,0.1791044776119403,0.1590909090909091,0.1188118811881188,0.13432835820895522,0.11363636363636363,0.19402985074626866,0.18181818181818182,0.125,0.18543046357615892,0.2694300518134715,0.1509433962264151,0.15555555555555559,0.15,0.14285714285714288,0.13605442176870747,0.15476190476190477,0.16931216931216933,0.14193548387096772
41,SP:75f80e4e7836a7575e60de7f055820c6c7065fcb,"The paper studies the underdamped Langevin diffusion for strongly-convex potential consists of finite sum of smooth components. The authors propose ALUM, which achieves optimal asymptotic complexity in the full gradient setting, and only requires one gradient at each iteration compared to RMM. For the stochastic gradient setting, VR-ALUM methods are proposed which improve over the previous methods in gradient complexity. The authors also accompany with a lower bound showing that the proposed methods are optimal in related parameters for the approximation problem.  ","The paper makes new contributions to the literature on sampling from a strongly log-concave smooth measure. This is done by approximating the Underdamped Langevin Diffusion (ULD), and so, a fortiori, the paper also contributes to this approximation problem.  The main result is a new algorithm to approximate the ULD, which is well suited to a stochastic setting, where the gradient of the potential is replaced by certain estimators.  In the full gradient (i.e. without using an estimator for the gradient) setting the new algorithm matches the asymptotic performance of previous works while cutting the number of Gradient queries by about half. In the stochastic setting, if the potential can be represented as a sum of $N$ smooth functions, then the authors also show how to modify their algorithm to accommodate estimators to the gradient and reduce the overall query and iteration complexity.  The results of the stochastic setting are also complemented by a lower bound which essentially show that the dependence on the parameters $N$, and $d$, the dimension are essentially optimal. ","In the context of sum-decomposable, smooth, and strongly convex potential functions the authors propose algorithms to improve the upper bound on the approximation error for estimating a Underdamped Langevin Diffusion (ULD) process and on the sampling error of the strongly-log-concave sampling problem. The continuous time ULD process has the strongly-log-concave distribution as its invariant distribution so approximating this process and sampling from this distribution are closely related. In the full gradient setting, the authors present a novel algorithm, ALUM which has optimal iteration complexity in $d$, $N$ and $\epsilon$ for the ULD approximation problem. Here, $N$ is the number of terms in the sum-decomposable function, $d$ is the input dimension and $\epsilon$ is the accuracy parameter. In comparison to the RMM algorithm (Lee et al), the dependence on $d$, $N$ and $\epsilon$ in the iteration complexity are matched, but the number of gradient evaluations are reduced by a factor of 2. Next the stochastic gradient oracle setting is considered: here the authors propose algorithms (SVRG-ALUM and SAGA-ALUM) and analyze the corresponding sampling/discretization error. Finally an improvement in the lower bound for the gradient complexity of the ULD approximation problem to $\Omega(N + d^{1/3}N^{2/3}/\epsilon^{2/3})$ is presented. This shows that the gradient complexity of the presented Variance reduction modifications of ALUM match the lower bound in $d$, $N$ and $n$ in the sum-decomposable setting with a stochastic gradient oracle.","The paper considers methods for approximating underdamped Langevin diffusion processes with sum-decomposable strongly convex potential. The main contribution in the paper is the proposal of the Accelerated ULD-MCMC algorithm and its variance-reduced variants. This is followed by a detailed analysis of convergence for each of the algorithms, and the derivation of an information-based lower bound for gradient complexity in the task of estimating ULD that matches the upper bound (in dimensionality, component number, and target accuracy). The authors conclude with a discussion of the optimality (or lack thereof) of ALUM with respect to all the variables. Comprehensive experiments are presented to compare the performance of various algorithms on estimation ULD processes, showing that ALUM and its variants achieve better performance than previous algorithms.","This paper proposes a randomized algorithm for approximating a trajectory of underdamped Langevin dynamics, similar to the RMM method cited in the paper. It further uses variance reduction method to improve the error over sum-decomposable problems. An information theoretic lower bound is established, which the proposed method matches.",0.35714285714285715,0.36904761904761907,0.2857142857142857,0.15476190476190477,0.28735632183908044,0.1896551724137931,0.08620689655172414,0.15918367346938775,0.06938775510204082,0.13385826771653545,0.1724137931034483,0.12653061224489795,0.1889763779527559,0.2653061224489796,0.20408163265306123,0.25984251968503935,0.30612244897959184,0.30708661417322836,0.3469387755102041,0.3469387755102041,0.23255813953488377,0.1884498480243161,0.22748815165876776,0.1954887218045113,0.23866348448687352,0.21926910299003322,0.13452914798206278,0.2096774193548387,0.11564625850340135,0.19318181818181818
42,SP:765942c86da1594b33268df6d0d15c682bc7eaa6,"A new vision transformer architecture VITAE, with a better use of intrinsic inductive bias IB via a new architecture using convolutional dillated layers. Both scale and locality IB are enabled by that architecture. Empirical results show that the new method can achieve excellent results with much less parameters than other recent methods.","This work incorporates two architecture changes which induce the inductive biases of 1) locality and 2) scale-invariance. It does so though a sequence of Reduction Cells followed by Normal Cells. In doing so, the authors demonstrate comparable performance to strong CNN baselines and improvements over Transformer-based ImageNet models -- the top performing ViTAE model achieves a 83.0% Top-1 accuracy. ","The standard vision transformer model lacks the capability to model inductive biases desirable for images e.g., local features encoding, and scale invariance. It, therefore, requires large-scale training data (300 million images), or other variants (e.g., Data Efficient ViT) distilling Knowledge from a pertained CNN. The paper proposes an architecture, which tries to take care of these inductive biases. The architecture comprises of 3 “Reduction cells” at the beginning followed by multiple “Normal Cells”. A reduction cell gets a pyramid effect using dilated convolutions at the beginning which gradually downsamples features. The normal cell doesn’t have any dilated convolutions. Each block has Convolution and attention running in parallel.  The assumption here is that convolution captures local relationships, pyramid structure (via diluted convolutions) captures scale invariance, and attention captures global relationships. ","This paper proposed two types of basic cells to modify the vanilla vision transformer structure: reduction cell (RC) and normal cell (NC). RCs are used to down-sample and embed the input images into tokens and NCs are to jointly model locality and global dependencies in the token sequence. Specifically, they used paralleled attention module and convolutional layers followed by a feed-forward network (FFN) to construct these two cells. Experiments on ImageNet and downstream tasks verified the superiority of the proposed network design.",The paper propose to inject inductive bias (IB) for vision tasks to boost the performance of vision transformers (ViT). The main contributions of the paper are two-fold: a reduction cell that aggregate the features from different scales by controlling the dilation of a  few of parallel convolution branches and a parallel convolution branch with the multi-head self-attention (MHSA) block. The results on ImageNet is promising compared with the selected baselines but I found it is hard to get a conclusive result on downstream classification tasks. ,0.09615384615384616,0.17307692307692307,0.11538461538461539,0.15384615384615385,0.2903225806451613,0.1774193548387097,0.1774193548387097,0.09774436090225563,0.15037593984962405,0.16666666666666666,0.08064516129032258,0.06766917293233082,0.07142857142857142,0.09090909090909091,0.13533834586466165,0.13095238095238096,0.125,0.15476190476190477,0.22727272727272727,0.1590909090909091,0.08771929824561403,0.0972972972972973,0.08823529411764706,0.1142857142857143,0.1846153846153846,0.1506849315068493,0.14666666666666667,0.11981566820276497,0.18099547511312214,0.1627906976744186
43,SP:7693974b70806d9b67920b8ddd2335afc4883319,"In this work, the authors explore how representations learned with vision transformers (ViT) compare with those of convolutional neural networks (resnet). Making use of centered kernel alignment (CKA), they compare the representations learned at different layers of the same mode, between models, and at different spatial positions. They find that ViT tends to learn similar representations  across all layers while resnets tend to show a clear distinction between lower-level and higher-level representations. They also provide experiments showing that residual connections play a crucial role in transformers, i.e. removing a residual connection causes a big change between preceding and following representations. Another interesting phenomenon in ViT is that residual connections tend to preserve information of the classification token during the first half of the model while it tends to change during the second half of the model. In addition, they compare how ViT and ResNets treat spatial information. They find that both process local information in the first layers but ViT uses global information earlier than ResNets. In fact, they show that while local processing is ""hardcoded"" in convolutions, ViT requires larger training sets to learn such inductive bias. Finally, they show that MLP Mixer is closer to ViT than to ResNet.","Neural network architectures based on self-attention instead of convolutions (e.g., the Vision Transformer, ViT), have recently be shown to reach similar or better performances on ImageNet classification than CNNs. In this work, the authors investigate whether the ""internal representation structure"" learned by Vision Transformers is also similar to CNNs. Using Centered Kernel Alignment as main metric to compare internal representations, the authors perform several analyses comparing aspects of three Vision Transformer variants (ViT-B/32, ViT-B/16, ViT-L/16) and two ResNet variants (ResNet50x1, ResNet152x2). The analyses performed look at similarity of representations across different depths, local vs. global information aggregation, importance of skip connections, spatial localization of information and effects of the amount of training data. The analyses reveal several differences between the ViTs and ResNets, indicating that despite similar classification performance, the image processing strategies are quite different for the two model families.",The paper studies the representation of features learned by convnet and transformers. It evaluates the similarity of representations within and between architectures using Centered Kernel Alignment. It studies models trained on datasets of different sizes.,"The paper presents a comparison study between internal representations of recently Vision Transformers and ResNet networks for image classification, using various established tools: Centered kernel alignment, attention distance analysis, effective receptive fields, representation propagation analysis, spatial localization analysis and linear probes. The also train some new models for additional analysis. The findings show significant difference between the models.","This work addresses some fundamental questions on Vision Transformers including 1. how are Vision Transformers solving vision tasks? 2. Do they act like convolutions, learning the same inductive biases from scratch? 3. And what is the role of scale in learning these representations? To answer these questions, they investigate the internal representation structure of ViTs and CNN by using representational similarity techniques like CKA (Centered Kernel Alignment). ",0.14705882352941177,0.049019607843137254,0.06372549019607843,0.0784313725490196,0.087248322147651,0.10067114093959731,0.09395973154362416,0.2857142857142857,0.2857142857142857,0.13793103448275862,0.20134228187919462,0.2857142857142857,0.22413793103448276,0.23880597014925373,0.37142857142857144,0.25862068965517243,0.208955223880597,0.1724137931034483,0.14925373134328357,0.11940298507462686,0.16997167138810199,0.08368200836820083,0.09923664122137404,0.11808118081180813,0.14130434782608695,0.14492753623188404,0.12962962962962962,0.21505376344086022,0.196078431372549,0.12799999999999997
44,SP:772277d969c95924755113c86663fb0e009f24cc,"This paper presents a GP model for refining coarse-grained spatial data, which can be used for handling aggregated data that are unmatched spatially and temporally. The authors also develop the two-stage regression algorithm for downscaling. The effectiveness of the proposed model is demonstrated using synthetic and real-world datasets.","The paper considers the problem of learning a function  $$f:\mathcal{X}\to \mathbb{R}$$ from the relationship  $$g(y) = \int_x f(x) \mathbb{P}[x|y]dx$$ where the training data consists of two datasets. The first set is  $\mathcal{D}_1 = ( x^b_i, y_i )$ where each $x^b_i$ is a bag of points in $\mathcal{X}$ and $y_i$ is a single point in a space $\mathcal{Y}$, these are empirical samples from some distribution $\mathbb{P}[x|y]\mathbb{P}[y]$. The second dataset is of $\mathcal{D}_2 = (\tilde y_j, \tilde z_i)$ with $\tilde y_j \in \mathcal{Y}$ and $\tilde z_i \in \mathbb{R}$ is a set of input-output pairs to from $\tilde z_i = g(\tilde y_i)$.  Learning models for $f(x)$ from aggregate data, (input bag, output) pairs e.g. $( x^b_i, z_i )$ has been studied, similarly the use of  there are intermediate covariates $y_i \in \mathcal{Y}$ with a dataset of the form $( x^b_i, y_i, z_i )$ has been studied. As I undertsand, the novel constributino of this work is the extension to the case where there are two datasets, $( x^b_i, y_i)$ and $(\tilde y_j, \tilde z_j )$ that both contain points from the domain $\mathcal{Y}$ yet they are not the same points, they are mismatched.  The paper proposes a ""conditional mean process"", a Gaussian process model that interpolates aggregated data as well as the marginalization operater in order to infer the un-aggregated latent function under this above problem setting.   ","This paper extends on the work of deconditional mean embeddings (DMEs) and task transformed Gaussian processes (TTGPs) from Hsu and Ramos (2019) from both an application and theoretical stand point.  From a theoretical stand point, the authors developed the framework around deconditional mean embeddings further by three ways: (1) formulating another elegant way to arrive at deconditional posteriors from Hsu and Ramos (2019), (2) establishing deconditional mean operators (DMOs) as vector-valued regressors in a manner that mirrors Grunewalder et al (2012) which highlights its interpretation as a reconstruction operator, and (3) enhancing guarantees on the convergence rate of deconditional mean operators from what was established in Hsu and Ramos (2019) using the setup and results from  Caponnetto and De Vito (2007), Szabó et al (2016), and Singh et al (2019).  From an application stand point, the authors apply DMEs for refining low resolution spatial fields with high resolution information. This is the special case of DMEs and TTGPs where the task dataset consists of collections of low resolution covariates ($\tilde{y}$) and aggregated targets ($\tilde{z}$), and the transformation dataset consists of collections of (another potentially unmatched set of) low resolution covariates ($y$) each matched with bags of high resolution covariates ($^{b}\bf{x}$). The latter constructions regarding the transformation dataset is what makes this a non-trivial special case due to having bagged high resolution covariates, which allows for a slightly different empirical estimator for the cross-covariance operator. This leads to an alternative conditional mean operator (CMO) which they call the conditional mean shrinkage operator. Finally, the authors then apply their work to toy experiments (swiss roll) and downscaling of atmospheric temperature (CMIP6), where to scale it they also derive a variational formulation to approximate the deconditional posterior. ","The authors consider the problem of refining low-res (LR) spatial observations using high-res (HR) covariates.   Basically, the problem is as follows. The analyst observes LR outcome Z, HR covariate X, and LR covariate Y from the process Z=E[f(X)|Y]+e. The analyst wishes to recover the function f.  In more detail: the analyst observes two datasets: D1 and D2. D1 consists of N observations (x_j, y_j) where x_j may be a bag.  D2 consists of M observations (y_j, z_j). The function f is modelled as a function in an RKHS (with Bayesian or frequentist approach).  The authors characterize the Bayesian version of this problem and derive the GP posterior. The authors characterize the frequentist version of this problem and prove minimax optimal finite sample rates. ","The paper proposes a novel Gaussian process approach for settings in which we have two datasets, D_1={(x_i, y_i)}_i=1 ^N and D_2=((y_i,z_i))_i=1^M  that are linked by the mediating variable Y. The datasets are not matched, and we want to learn a function from X to Z. In contrast to existing work, the algorithm generalizes to settings in which the resolution of the two datasets differ.",0.23529411764705882,0.27450980392156865,0.19607843137254902,0.2549019607843137,0.1412639405204461,0.1412639405204461,0.11895910780669144,0.09621993127147767,0.061855670103092786,0.1259259259259259,0.04460966542750929,0.048109965635738834,0.07407407407407407,0.16666666666666666,0.13058419243986255,0.2814814814814815,0.41025641025641024,0.2074074074074074,0.23076923076923078,0.21794871794871795,0.07500000000000001,0.08187134502923978,0.10752688172043011,0.20155038759689922,0.13571428571428573,0.18811881188118812,0.18443804034582129,0.13145539906103287,0.0975609756097561,0.1596244131455399
45,SP:773b5b6d31e6899da395933eb7f9e25a6e50c406,"This paper studies the problem of dynamic programming with continuous state and action spaces.  The authors first propose the VI which naively discretizes the state and action space and performs the classical value iteration. The authors use this method as a baseline for comparison with CVI developed in this paper.  Regarding the CVI, this algorithm performs VI in the the conjugate domain. In particular, by taking the dual of the objective function, we take the problem to the dual space. By doing so, instead of taking minimum over all the actions, the problem is reduced to a summation. Hence, the complexity of the CVI is better than the VI in the order of the cardinality of the action space.","The authors consider value iteration [TJ](x) = min_u [c(x,u) + gamma E J(x’)] for problems where the transition function and cost functions are additively separable: c(x,u)=c1(x)+c2(u) and x’=f1(x)+f2(u) + w (Assumptions 3.1). Furthermore, f1(x) is Lipschitz continuous, f2(u) is linear, c1(x) is convex and Lipschitz continuous, and c2(u) is linear in u. The disturbance w has a finite support (Assumption 2.1). The state space for x and decision space for u are continuous. Thus, the authors consider problems such that [TJ](x) = c1(x) + min_u [c2(u) + gamma sum_i  p_i J(f1(x)+Bu+w_i)]. A problem that fits this description is the stabilization of an inverted pendulum with discretized disturbances, studied in Section 4. With this choice of assumptions, and assuming the value function is convex (which holds true if f1(x) is linear or linearized, that is, if x’=Ax+Bu+w), convex duality can be applied to the minimization problem over (u,x”) given x and subject to x”=Ax+Bu, which gives another representation of the optimization problem, based on the convex conjugate of c1 and the convex conjugate of e(x”)=gamma E J(x”+w).  The authors propose and study an algorithm that relies on computing these convex conjugate functions numerically in order to provide an alternative way to the computation of the value function J. They establish error bounds (Theorem 3.13) in terms of theoretical quantities of the problem data.","This paper presents a fast method for solving certain classes of optimal control problems, by implementing a value iteration (VI) algorithm that takes advantage of convex duality.  The basic idea is to take advantage of the fact that for two functions $f_1, f_2$, we have $(f_1 \square f_2)^* = f_1^* + f_2^*$, where $f^*$ denotes the Legendre-Fenchel transform of $f$, and $(f_1 \square f_2)(x) = \inf \\{f_1(x_1) + f_2(x_2) : x_1 + x_2 = x \\} $ denotes the infimal convolution of $f_1, f_2$. Thus, the slow $\inf$ operation can be replaced with a fast addition operation. The paper provides analyses of the convergence, time complexity, and error of the algorithm. When compared to a ""naive"" VI algorithm in which each iteration takes $O(X U)$ (where $X$, $U$ are the grid sizes of the state and input spaces, respectively), the algorithm presented in this paper can achieve $O(X+U)$. Finally, the paper provides a numerical example implemented in MATLAB.","This paper proposed a new value iteration algorithm (CVI) for optimal control of stochastic system with continuous state space. The proposed algorithm discretizes the state space and performs the value iteration step in the ""conjugate domain"" to reduce one-step computational complexity. It was shown the proposed algorithm converges under conditions on the stochastic system, discretization, and etc. The proposed algorithm CVI, its variant CVI-d are compared to classical value iteration (VI) over a noisy inverted pendulum experiment.","The paper develops an approximate value iteration method for an infinite-horizon, discounted-cost Markov Decision Processes (MDPs) that satisfy a given set of regulatory assumptions. The idea is to work on a dual space that replaces the DP value function by a reformulation written in terms of biconjugate operations. The authors present an algorithm that applies the conjugate operators iteratively, and present convergence and other structural results associated with the resulting errors. Numerical results compare the proposed approach against a traditional value iteration and a variant that generated dynamic discretization grids.",0.2773109243697479,0.21008403361344538,0.2184873949579832,0.14285714285714285,0.13076923076923078,0.08076923076923077,0.09615384615384616,0.12209302325581395,0.12209302325581395,0.24050632911392406,0.12692307692307692,0.14534883720930233,0.3291139240506329,0.18478260869565216,0.19767441860465115,0.26582278481012656,0.2717391304347826,0.26582278481012656,0.22826086956521738,0.20652173913043478,0.17414248021108178,0.1718213058419244,0.2626262626262626,0.16113744075829384,0.1574074074074074,0.12389380530973453,0.14204545454545456,0.16733067729083664,0.1590909090909091,0.22222222222222224
46,SP:7b8284aa82022ce73802bfc57238b0d82031b226,"The author proposes a nested variational inference (NVI) framework that combines nested importance sampling and variational inference. This framework allows the training of the important sampling proposal by minimizing KL divergences at each level of nesting. This also provides us a way to learn intermediate densities, which serves as a heuristics for guiding the importance sampler. Empirically, the author evaluates NVI by (1) sampling from a multimodal distribution with a learned annealing path; (2) learn heuristics for future observations in the state-space model; (3) perform amortized inference in the hierarchical deep generative model.","This paper proposes an inference procedure that combines ideas from variational and nested inference, resulting in a sequence of forward and reverse proposal distributions that are optimized with local objectives that encourage the forward and backward edge marginals to be similar. This allows the objective and therefore gradients to decouple. The addition of resampling, afforded by the connection to nested inference, additionally improves sample diversity.","The authors present a method to jointly learn a series of proposals and intermediate densities for e.g. SMC, or annealed importance sampling. They use a novel objective which sums divergences between distributions over each adjacent pair of variables in the chain, and argue that this leads to lower-variance gradient estimates than prior work which uses a single objective for the entire sequence of variables. They show experimentally the benefits of this method in three different settings.","The authors introduce a new inference and approximate weighted sampling framework that combines f-divergence variational inference and nested importance sampling. An original variation sampling density is transformed through a series of weight preserving operators that map the proposal to an approximation of an unnormalized target distribution. On the other hand, reverse transformations are use to transform the target back to the sampling distribution. The transformations are trained by minimizing an f-divergence at each nesting level. ","The paper describes a framework for learning and inference in probabilistic models with structured latent spaces. It operates in the tradition of IWAE and VSMC-like methods that use importance sampling to tighten a variational bound (or equivalently, uses a variational bound as an objective for learning importance sampler proposals). Unlike methods that optimize a single global bound, NVI is defined in terms of local pairwise divergences between a sequence of target distributions, which acts to decouple the stochastic optimization, reducing gradient variance and potentially offering a strategy for parallel inference.",0.14893617021276595,0.1595744680851064,0.20212765957446807,0.19148936170212766,0.16923076923076924,0.23076923076923078,0.2,0.15384615384615385,0.19230769230769232,0.18181818181818182,0.2153846153846154,0.19230769230769232,0.24675324675324675,0.1978021978021978,0.14102564102564102,0.19480519480519481,0.14285714285714285,0.15584415584415584,0.16483516483516483,0.15384615384615385,0.1761006289308176,0.1744186046511628,0.2222222222222222,0.19459459459459455,0.15384615384615385,0.2112676056338028,0.16666666666666666,0.15483870967741936,0.1775147928994083,0.16666666666666669
47,SP:7cd593ccba4830f3383a92ef6266224cc7699706,"This submission is about multi-modal representation learning from unlabeled data (self-sup.) using Transformer. This work deals with video, audio, and text data as multi-modal data. The approach to tackle representation learning is based on Transformer + contrastive learning. The contrastive learning in this work is interesting in that 1) noisy association is considered in multiple instances learning way [64], and 2) the different level of semantic granularity is carefully considered. Also, the authors adopt a simple DropToken to improve efficiency.  The training requires very large-scale training using HowTo100M and AudioSet. The authors demonstrated its effectiveness on action recognition, audio event classification, zero-shot video retrieval, image classification.  Multi-modal data is encoded by independent feature extractors, which is a small difference from other Vision Transformers. Naturally, the authors extend the positional encoding to 3D positional encoding (horizontal, vertical, and temporal axes) with relativeness.  Overall, the technical contribution is a bit weak, but this submission contains interesting analyses that are worthwhile to report in the community and also achieve state-of-the-art in downstream tasks.","This paper describes a self-supervised pure transformer-based multimodal representation learning including video-audio-text, i.e., VATT. VATT consists of  linear projection of input for each modality, modality-specific or agnostic transformer encoder, and multimodal projection head. VATT uses NCE loss for video-audio feature learning and MIL-NCE loss for text-video features. Also, the authors proposed DropToken as an efficient method for training.  They employ HowTo1M and AudioSet datasets for pretraining and evaluate their VATT for diverse finetuning tasks including video action recognition, audio event classification, and zero-shot text-to-video retrieval. With intensive experiments and ablation studies, they provide promising results and constructive analysis.  ","The paper proposes a transformer-based architecture for learning representations from video-audio-text triplet data without manual data annotation. The paper studies modality-specific transformers (one transformer for one modality) and modality-agnostic transformers (a shared transformer for all modalities). The learned representation is evaluated on various downstream tasks on image, video, audio and video-text.","This paper concerns multimodal self-supervised learning. It adopts the now ubiquitous contrastive learning framework to learn video, audio, text representation from each raw signal in joint embedding spaces. The proposed architecture heavily relies on MMV [1], with a twist on Visual/Audio Transformer encoders and modality-agnostic Transformers. Comprehensive experimental results are conducted on four diverse video(-text) tasks across ten datasets.","This paper provides a framework for self-supervised multimodal representations from unlabeled data with Transformer backbones. The authors study two styles of Transformer encoders: modality-specific or modality-agnostic.  Finally, they achieve good performance on various downstream tasks including action recognition, audio event classification, text-to-video retrieval and image classification.",0.15168539325842698,0.08426966292134831,0.07865168539325842,0.10112359550561797,0.18181818181818182,0.13636363636363635,0.21818181818181817,0.24561403508771928,0.2982456140350877,0.19047619047619047,0.24545454545454545,0.2631578947368421,0.2222222222222222,0.35294117647058826,0.3508771929824561,0.23809523809523808,0.47058823529411764,0.2222222222222222,0.3333333333333333,0.23529411764705882,0.1875,0.1276595744680851,0.11618257261410789,0.1572052401746725,0.2395209580838323,0.17341040462427745,0.2981366459627329,0.23333333333333334,0.3148148148148148,0.21052631578947367
48,SP:7df49c554d6c9fca370f049279ef7324b6f79de9,"This paper studies the annealed important sampling (AIS) using the Hamiltonian dynamics kernels in each interpolant. To circumvent the problem that the Hamiltonian dynamics involves the non-differentiable operations, this paper proposes to discard the accept-reject operations in the kernel, and derives the resulting density ratios in a simple form related to the momentum variables. The resulting approach, named Uncorrected Hamiltonian Annealing (UHA), is a fully differentiable AIS method. This paper validates the effectiveness of UHA through extensive experiments and highlights the importance of differentiability. ","The paper propose to use uncorrected HMC kernels (i.e. HMC kernels without accept-reject steps) in AIS to make the estimate of log normalisation constant differentiable w.r.t. to various parameters (e.g. step-size for numerical integration). The author(s) name(s) the method UHA. The promise is that one can then using reparameterisation gradient to tune these parameters. Through experiments on inference tasks, the benefit of tuning parameters in UHA is demonstrated against other methods that use HMC in AIS. For experiments on VAE training, UHA with tuned parameters has shown better test ELBO than IW.","The authors introduce a variational inference method that leverages Annealed Importance Sampling (AIS) and Langevin/HMC MCMC. In particular HMC dynamics are used to target a sequence of intermediate bridging densities in order to generate approximate samples from the target posterior distribution. Importantly, since the method is uncorrected (i.e. does without a accept/reject step) the resulting lower bound is fully differentiable. This makes various hard-to-set parameters (e.g. temperatures for bridging densities) learnable. In experiments the authors demonstrate that their method, Uncorrected Hamiltonian Annealing (UHA), leads to tight lower bounds on the log evidence. ","The paper proposed to use the uncorrected HMC kernel in an AIS-type variational scheme. This enables optimizing the ELBO via reparameterization gradients for many algorithm tuning parameters, including step size, momentum covariance, and annealing schedule. The method is shown to outperform competitors in most cases. ","The paper proposes UHA, an original and clever modification of Hamiltonian AIS. The idea is to change the AIS ratio such that it becomes tunable, but can still be computed in closed form (ratios of momentum distributions). This is achieved by dropping the accept-reject step in the HMC update such that a single UHA step only involves (re)sampling momenta and leapfrog integration. This modification allows the authors to tune parameters such as the proposal distribution, the step size and damping coefficients (used in momentum resampling). Many interesting ideas for future extensions are proposed. Experiments on various models demonstrate that UHA obtains a tighter ELBO than other combinations of VI and HMC.  ",0.18604651162790697,0.23255813953488372,0.12790697674418605,0.2441860465116279,0.21,0.17,0.21,0.09183673469387756,0.1836734693877551,0.2608695652173913,0.16,0.20408163265306123,0.2391304347826087,0.18584070796460178,0.21428571428571427,0.3695652173913043,0.18584070796460178,0.1956521739130435,0.1592920353982301,0.10619469026548672,0.17204301075268816,0.21739130434782608,0.16666666666666669,0.21105527638190955,0.21212121212121213,0.2328767123287671,0.19718309859154928,0.125,0.17061611374407584,0.1509433962264151
49,SP:855dcaa42868a29a14619d63221169495ed5dd54,"The paper introduces a new type of continuous normalizing flow (CNF) for manifold-valued data. Unlike in previous works, this Moser Flow (MF) models a density as a base density minus the divergence of a neural network. The authors prove that under certain assumptions this defines a probability distribution over the manifold. This approach has a different trade-off between inference and generation from other approaches: while the model density can be evaluated very cheaply, sampling from this model requires an ODE solver. The approach is qualitatively demonstrated on toy datasets on tori and the Stanford bunny, and quantitatively evaluated on a few datasets on 2-spheres.","This paper proposes an alternative way to train a continuous normalizing flow (CNF), inspired by the Dacorogna-Moser transport. The proposed training does not require numerical integration; instead, the likelihood of the flow can be directly evaluated by computing the divergence of the mass flow rate. The idea is tested on boundaryless manifolds, such as the flat torus for toy data and implicit surfaces. ","The authors define a continuous normalizing flow on an arbitrary Riemannian manifold through the divergence of a neural network using the Moser theorem. They motivate their approach and show how this flow can be represented and learned. By applying their method to a toy distributions and a real world earth and climate dataset, they demonstrate the effectiveness of the method and that they can outperform competing procedures. Furthermore, they show that their method is much faster and more efficient than FFJORD when learning a complex two dimensional density.","This paper presents Moser Flow a new class of Continuous Normalizing Flows for Riemannian Manifolds. The main approach exploits results in differential geometry (Moser 1965) to construct a vector field that satisfies the normalizing equation given by the pullback of the volume form under $\Phi$. The approach is both sensible and provides direct advantages over Riemmanian CNF's as training does not require solving the ODE using a solver. The authors also consider Moser Flows for Euclidean Submanifolds under the Induced metric and show that Moser Flows can learn arbitrary distributions on manifolds of interest (---i.e. compact, boundryless etc...). Finally, the experiments conducted are both interesting in their variety and illuminating in that they show the effectiveness of the proposed method. Overall, this paper represents a non-trivial step forward---manifold or otherwise---for Continuous Normalizing Flow research.","The paper tackles the problem of learning flow-based generative models. The proposed approach, a new instance of continuous normalizing-flow methods, models the density as a difference between the prior and a divergence term, parameterized by a neural network.  The claims are that: * MF constitutes a universal density approximator, * MF is more efficient to train than alternative CNFs; this is demonstrated empirically and the intuition is that MF does not require invoking or backpropagating through an ODE during training (note however that solving an ODE is required for sampling), * MF improves upon alternative CNFs in terms of density estimation, sample quality, and training complexity, * MF demonstrates for the first time the use of flow models for sampling from general curved surfaces.",0.16822429906542055,0.205607476635514,0.2336448598130841,0.2616822429906542,0.25,0.3125,0.28125,0.23863636363636365,0.20454545454545456,0.17985611510791366,0.28125,0.25,0.17985611510791366,0.22950819672131148,0.18181818181818182,0.14388489208633093,0.14754098360655737,0.1510791366906475,0.14754098360655737,0.20491803278688525,0.21052631578947367,0.22564102564102562,0.20325203252032517,0.24454148471615722,0.2105263157894737,0.19704433497536944,0.1935483870967742,0.18502202643171808,0.17142857142857143,0.19157088122605365
50,SP:862223b8bd4c275f96c7e41c92daaa2ca2906194,"This work addresses the SCISR problem by combining transformers to the network architecture. The backbone of the architecture utilizes a CNN to extract feature maps, to enlarge the receptive field, an implicit transformer is used. After that the implicit position encoding is conducted via MLP. Natural images are suitable for SR but there is a lack of SR techniques that are suitable for screen content, which this paper tries to address.  ","This paper presents a novel method called implicit transformer for the task of super-resolution of screen content images. The proposed method is able to integrate the advantage of transformer in capturing relation between pixels and that of implicit neural representation in producing continuous and sharp results. The effectiveness of the proposed method is validated on both newly collected datasets w/o and w/ compression degradation, and datasets originally created for image quality assessment. Ablation study also demonstrates the role of the proposed modules.","This paper addresses the problem of arbitrary screen content image super-resolution, which is quite different from natural image super-resolution.  The author proposed two datasets specifically designed for this scenario, which can greatly motivate research  effort into this field. Besides, the authors proposed Implicit Transformer Super-Resolution Network (ITSRN) to achieve arbitrary scaling for screen content images. The ITSRN is largely inspired by LIIF, the main novelty of ITSRN includes the proposed  implicit transformer and the implicit position encoding, these schemes are empirically evaluated to show its effectiveness. ","This work presents a continuous image super-resolution based on an implicit transformer. Authors extend LIIF [6] with some modifications including transformer-like formulation in (2), scale token in (5), and implicit position encoding (7). The proposed implicit transformer learns the transformation weight from query (high-resolution) coordinate, key (low-resolution) coordinate, and scale token. A pixel intensity is then computed by transforming the pixel features (obtained from CNN backbone) with the transformation weights. The pixel intensity is further refined with the implicit position encoding, which is an adaptive weighting scheme with learned weights. Experimental results on screen content images demonstrate superior performance over existing continuous super-resolution methods [5,6].","The paper proposes a transformer-based image super-resolution method for screen content images which have many thin edges. The transformer is designed to learn the mapping from coordinates to rgb values. It additionally has a scale token representing the magnification factor. Due to targeting a new application, the paper also constructs suitable training and testing datatests.",0.16901408450704225,0.23943661971830985,0.22535211267605634,0.11267605633802817,0.20238095238095238,0.16666666666666666,0.17857142857142858,0.19101123595505617,0.14606741573033707,0.10810810810810811,0.14285714285714285,0.19101123595505617,0.14414414414414414,0.14035087719298245,0.19101123595505617,0.12612612612612611,0.2631578947368421,0.15315315315315314,0.22807017543859648,0.21052631578947367,0.15483870967741936,0.2125,0.1758241758241758,0.125,0.19653179190751446,0.14358974358974358,0.2127659574468085,0.16999999999999998,0.17808219178082194,0.14285714285714288
51,SP:8d5741aedf3125e0e790a58ec3ce81a4e2ea4dcb,"This paper proposes a unified alternating projected gradient descent-ascent (APGDA) attack by considering the min-max operation for adversarial attack settings. The proposed method can be applied in generating model ensemble attacks, universal adversarial attacks, and robust attacks over data transformations. Extensive results show that the proposed method can achieve better attack performances for these three applications.","This paper proposed a APGDA attack method, in which the model ensemble attack, universal attack, and robust attack are unified. The authors proved their APGDA's superiority in theory, ${i.e.}$, convergence rate and strong attacking ability. All of the mentioned tasks (ensemble attack, universal attack, robust attack) are investigated through experiments.","The paper provides a general min-max framework to formulate several popular problems in the literature including Ensemble attack over multiple models, Universal Perturbation over multiple examples, and adversarial attack over data transformations. For each case, a standard first-order approach converging to a stationary point of the problem is provided. The effectiveness of the min-max approach compared to the standard empirical risk minimization has been demonstrated by extensive experiments.  ","This paper adapts the min-max problem proposed for multi-domain robust optimization [45] to the problem of generating adversarial attacks. They show how several adversarial attacks scenarios can be formulated using this min-max, for example they show that this min-max formulation can be used to find successful attacks against an ensemble of models. They also show how this min-max can also be used to train robust models against multiple $\ell_p$ attacks. They show experimentally that the approach outperforms several baseline in several setting.","The work proposes a min-max framework APGDA that can take in different models related to adversarial robustness. APGDA can generate model ensemble attack, universal attack over multiple images, and robust attack over data transformations. They perform experiments to evaluate their method.",0.2413793103448276,0.20689655172413793,0.27586206896551724,0.25862068965517243,0.25,0.15384615384615385,0.23076923076923078,0.18309859154929578,0.23943661971830985,0.10227272727272728,0.2692307692307692,0.16901408450704225,0.18181818181818182,0.35714285714285715,0.18309859154929578,0.09090909090909091,0.2857142857142857,0.14772727272727273,0.40476190476190477,0.21428571428571427,0.2545454545454545,0.18604651162790697,0.2191780821917808,0.30000000000000004,0.21138211382113822,0.1142857142857143,0.25531914893617025,0.16352201257861637,0.30088495575221236,0.13846153846153847
52,SP:965413b1726617006317bbbec55673dd5d21812a,"This paper considers communication efficient algorithms for SGD. In this model, there are $n$ total workers and each worker has a local smooth convex loss function $f_i$ on $R^d$. The objective is for a coordinator to find an approximate global minimum for an objective function that represents the average loss across all workers while minimizing communication between the workers and the coordinator.   A common approach is for each worker to compute a sketch on their local batch of gradients that allows the coordinator to recover of the top $k$ gradients in magnitude, ideally improving the rate of convergence. However, the challenge with this approach is that the estimator formed by the coordinator using the sketches sent from the workers may not be an unbiased estimator of the overall gradient, which allows error to accumulate over multiple iterations. This paper introduces provable accelerated gradient-methods, in the sense of Nesterov momentum for contractive compressors, which are a general class of stochastic functions that form estimators of the gradient, including the top $k$ estimator. ","This paper presents accelerated methods for communication-efficient learning applications. In particular, a loopless Katyusha strategy is introduced to attain the O(\sqrt{L/\mu}) rate for error-compensated methods using stochastic gradient information. These methods are called ECLK. In terms of theoretical iteration complexity and empirical experiments, ECLK is explicitly shown to be more communication efficient and to have a better rate than existing error compensation methods.","This paper proposed an error compensated based Katyusha method for finite-sum convex problems. The proposed method achieves the same asymptotic convergence rate as its full precision accelerated counterpart. Compared to another related work ADIANA, the proposed method can be applied to contractive compressor. ","The authors consider accelerated training algorithms using gradient compression with error compensation. For this purpose, they incorporated gradient compression and error compensation in the Katyusha algorithm and developed ECKL. The algorithm quantizes both the SG and VR term and keeps track of the quantization error for error compensation in the next iteration.  The paper analyzed the convergence rate and iteration complexity of ECKL for the smooth convex functions and compared it with variants of DIANA both theoretically and via some simple simulations on logistic regression.","The paper introduces an error compensation variant of the loopless Katyusha, ECLK. Theoretical convergence analysis is given and accelerated linear convergence rate is obtained using contraction operators. Experimental study of ECLK is given on the logistic regression problem for binary classification.",0.09195402298850575,0.06321839080459771,0.10919540229885058,0.05747126436781609,0.11764705882352941,0.17647058823529413,0.1323529411764706,0.20454545454545456,0.1590909090909091,0.1411764705882353,0.23529411764705882,0.25,0.2235294117647059,0.24390243902439024,0.18181818181818182,0.1411764705882353,0.21951219512195122,0.10588235294117647,0.17073170731707318,0.2926829268292683,0.1322314049586777,0.10091743119266057,0.14671814671814673,0.09302325581395349,0.14285714285714285,0.1568627450980392,0.1651376146788991,0.13953488372093026,0.16470588235294117,0.19047619047619047
53,SP:97f533426dce73d27768dd7afc2ddf035cf21e61,"The paper presents an alternative approach to attention in the Transformer. There are two modeling contributions:  1. Kernelized attention that omits the typical normalization term used for softmax attention. 2. A Nystrom method approach that allows efficiently approximating the output of the attention mechanism  The contributions also include theoretical results regarding the accuracy of the Nystrom approximation, and experimental results showing better convergence, higher accuracy, and medium efficiency gains from the approach.  Below I summarize my understanding/takeaways from the two key methods; please correct me in the author response if these are inaccurate: 1. As I understand it, ""kernelized attention"" mean that target keys don't compete with each other, the only thing that matters is their distance to the query. In standard softmax attention, suppose that all key vectors are orthogonal to a query vector -- in that case, attention would weigh all values uniformly. In kernelized attention, on the other hand, if key vectors are all far away from the query vector, then all value vectors would be attended to with near-zero weight. 2. The Nystrom approximation involves sampling some queries and keys, and then computing kernels between all pairs. But whereas Nystromformer computes similarity for query+key pairs only, the proposed approach also computes kernels for query+query and key+key pairs as well.","The authors reformulate soft max structure of the self-attention mechanism in Transformers in terms of a Gaussian kernel evaluation. They claim that such a model is empirically stable during training, while allowing the use of various Kernel approximation strategies to improve the quadratic computational complexity.   In this work, approximation strategy used by the authors is the popular Nyström approximation. However, since the kernel matrix formed between the query and the key matrices is not symmetric (hence not PSD), the Nyström approximation is not directly applicable. The authors propose to form a PSD kernel matrix by first evaluating the Gaussian kernel on the row concatenated  query and key matrices which is PSD, performing the Nyström approximation and then choosing the appropriate block in the resulting matrix.  By adapting an existing theorem [Musco, Musco 17],  the authors claim that such a low-rank approximation of the kernelized attention score is bounded in terms of the relative spectral norm. This is claimed to be due to the observed fast decay of the eigenvalues in an empirical kernel matrix.   The matrix inversion required for the Nyström approximation, however is a potential issue in terms of numerical stability on a GPU. To circumvent the problem, instead of a standard conjugate gradient method, they use a Schulz type iteration which only uses matrix products, without any floating point divisions.    Empirical evaluation shows marginal improvement on most tasks on the LRA benchmark, as compared to the naive Nyström approximation [Xiong et al 2021]. However, this is at the cost of relatively larger time and memory usage. ",The paper proposes a new form of self-attention for use in transformer models using Gaussian Kernels. They show that the new attention method is comparable in accuracy to traditional softmax self-attention. They then go on to show that kernel based attention can be approximated by taking a Nystrom sketch of the kernel matrix. They give rigorous bounds on the spectral norm of the approximation (assuming that the kernel matrix has a high condition number). ,"The paper proposes a method (Skyformer) to apply Nystrom approximation to the attention matrix. It embeds the attention matrix inside a larger PSD matrix (unlike Nystromformer), allowing Nystrom method to work well. Theoretical and empirical validation shows that the method is competitive with other forms of efficient attention (e.g. BigBird, Performer, Reformer).",The author proposes a modified Nyström method named Skyformer to approximate the Kernelized Attention. They also provide a theoretical guarantee that the approximation error is small in terms of the spectral norm. Extensive experiments are also conducted to show that Skyformer achieves comparable performance to vanilla self-attention with fewer computational costs.,0.1559633027522936,0.0963302752293578,0.07339449541284404,0.0779816513761468,0.09433962264150944,0.06415094339622641,0.06415094339622641,0.15789473684210525,0.18421052631578946,0.2830188679245283,0.12830188679245283,0.27631578947368424,0.3018867924528302,0.32075471698113206,0.32894736842105265,0.32075471698113206,0.32075471698113206,0.22641509433962265,0.2641509433962264,0.2830188679245283,0.14078674948240166,0.14285714285714285,0.11808118081180811,0.12546125461254612,0.1466275659824047,0.1069182389937107,0.1069182389937107,0.18604651162790695,0.2170542635658915,0.2830188679245283
54,SP:97fac361b69ed5871a60dc40e51900747a453df9,"This paper explores jointly training generative model probes alongside a neural architecture to imbue the model with capabilities analogous to ""debugging"" in traditional software. By training the generative model probes to reproduce the model inputs, every intermediate activation can be decoded to input space (images). The authors use this (1) to interpret the partial progress of the model made at intermediate layers, (2) to restrict the model from using sensitive information from the inputs, and (3) as an interface to compose the model with itself and with other pretrained image models. The authors further use self-composition to produce an ensemble from a tree of connected classifiers, which in turn gives uncertainty measurements that enable (4) out-of-distribution detection and (5) calibration. Experimental evidence backs each of these contributions.","This paper argues for inverting intermediate latent representations of convolutional classifiers -- predicting the original input -- as a tool for improving robustness and interpretability. The ability of the model to learn invertible intermediate hidden representations acts as a regularizer during training.  This basic premise is used in several ways. For example, a recursive version of this idea (using the reconstructed input to classify, and the intermediate hiddens of that to re-reconstruct the input, adding that reconstruction loss into the overall loss calculation) leads to an interesting form of drop out: choose which reconstructions (from which layer, and which recursive depth) to use in the final output. That can be used for enhanced forms of Monte Carlo Dropout, improving uncertainty computations over regular MC Dropout.  Another use is in placing constraints on intermediate hidden layers. For a fairness goal, such a constraint might be that, given a good classifier for some protected attribute, that classifier has poor performance on the reconstructed inputs from the original model's hidden layers. In a sense, this constrains the training of the model to lose the information that would allow the external classifier to predict the protected feature.","This paper presents an approach to simultaneously train a prediction network along with a generative model to map the neural network activations back to inputs. The use cases of doing so include (1) interpreting the information encoded in an activation, (2) composing the network with itself and other pre-trained networks, which in turn provides a means to get uncertainties and to regularize the network, and (3) to assert that the network satisfies some constraints on what it can and cannot learn in the intermediate layers. The paper is evaluated on several image benchmarks and speech benchmarks and showcases all the above benefits.  ","This work proposes DecNN, and the main goal is to allow people to interpret the intermediate neural network activations. The base model is an 8-layer MLP. The core idea is to train another generative model that takes the MLP activation as the input, and the generative model aims to decode an image in the model input space. During training, the loss of the generative model aims to reconstruct the input image given the activations of all intermediate layers. They further design ReDecNN, which recursively composes DecNN by taking the output of the generative model as the input of DecNN. They demonstrate that the generative model produces interestingly interpretable outputs to explain why the classifier makes correct or wrong predictions. They also show some promising results for out-of-distribution detection, calibration, and fairness.","This paper proposes to jointly train a generative model that maps activations back to the input space. The work demonstrates several benefits of this approach.  * Probing: It provides a way to decode the activations which enables the users to make sense out of it since the decoded activations are in the input space.  * Composing networks: The decoded activations allow to compose a DecNN model with another model with the same input type.  * Data Augmentation: The DecNN model can be composed with itself. This can be viewed as data augmentation since the decoded activations are of the same ""type"" as the input and retain the features that are relevant to the prediction task. * Ensemble network. The DecNN model can be recursively composed with itself to get the “Recursively Decodable Neural Network” (ReDecNN) model. This model can be viewed as an ensemble network. The paper shows the usefulness of ReDecNN for the tasks of measuring uncertainty, OOD detection, and calibration. * Constrain the activations: The decodable activations makes it possible to specify the kind of information an activation is not supposed to capture. This provides assertion-like capability to the neural network. ",0.2,0.19230769230769232,0.23076923076923078,0.27692307692307694,0.11398963730569948,0.16580310880829016,0.17616580310880828,0.20388349514563106,0.30097087378640774,0.27611940298507465,0.13471502590673576,0.24271844660194175,0.22388059701492538,0.19047619047619047,0.21359223300970873,0.23880597014925373,0.17989417989417988,0.15671641791044777,0.164021164021164,0.19576719576719576,0.1609907120743034,0.21459227467811162,0.22727272727272727,0.225705329153605,0.14864864864864866,0.19571865443425077,0.17801047120418848,0.1772151898734177,0.21232876712328766,0.22910216718266255
55,SP:9837e0c68887cc1382aefd0ead01f72cde199e0d,"This paper focuses on semi-supervised learning with outlier unlabeled data. This problem has attracted much attention in the semi-supervised learning community. The authors propose a method that contains two parts: First, detect outliers based on the OVA classifier. Second, propose an open-set soft-consistency regularization loss that can help improve the outlier detection performance.","This manuscript introduces OpenMatch for open-set semi-supervised learning. The OpenMatch integrates a one-vs-all classifier (OVA-classifier, working as an outlier detector) and FixMatch. The main contribution should be the soft open-set consistency regularization (SOCR) in Figure 1 and the OpenMatch Framework in Alg 1. Specifically, the SOCR follows the same self-supervised framework in FixMatch but it uses OVA-classifier to output consistent anomaly score distribution. After using the model in Figure 1 to identify inliers from unlabeled data, the FixMatch is allowed to reach a higher accuracy on the OSSL tasks.","This paper tackles open-set semi-supervised learning (OSSL) where outliers exist in unlabeled data. The key idea for detecting outliers is to learn class-specific, one-vs-all (OvA) classifiers—if all classifiers produce negative outputs for an unlabeled data, the data is considered an outlier. In addition to the classification loss computed on labeled data, the OvA classifiers are also trained on unlabeled data with an entropy minimization loss and a consistency regularization loss—the latter is computed on two views of the same data. The results on CIFAR and ImageNet show that the proposed approach largely outperforms the baselines in terms of both recognition accuracy and outlier detection accuracy.","The paper proposes a model for open-set semi-supervised learning. As a semi-supervised learning model, it tackles classification where only a portion of the training data is labeled. ""Open set"" refers to the fact that the unlabeled data are noisy and can contain out of distribution examples, for which the class is not among the known classes. Out of distribution samples are present also during test, and the model has to recognize them and avoid classification on them. The proposed model builds on top of existing works, combining several loss terms and ideas such as one-versus-all classifiers and FixMatch as the main semi-supervised learning engine. The main technical contribution is a loss term enforcing the out-of-distribution score for two augmented versions of the same unlabeled example to be similar. Extensive experiments validate the proposal against recent state-of-the-art models.","The authors propose an idea to improve model's performance under the open-set semi-supervised learning setting. This work proposed to leverage OOD detector, combined with FixMatch, and soft open-set consistency regularization (SOCR) to improve the model training during open-set semi-supervised learning. I think the usage of OOD on ignore outliers is not new and an unsupervised method on learning the consistency between augmentations for unlabeled data is also not new. Thus, I am not sure if I can find too much of novelty from this work itself, but I do appreciate the author's effort in putting them together to be a complete model, which in fact make solid progress on the open-set semi-supervised learning setting. ",0.24561403508771928,0.3508771929824561,0.2807017543859649,0.2631578947368421,0.24742268041237114,0.2268041237113402,0.23711340206185566,0.26785714285714285,0.16964285714285715,0.17567567567567569,0.14432989690721648,0.17857142857142858,0.10810810810810811,0.12195121951219512,0.21428571428571427,0.14864864864864866,0.18699186991869918,0.20270270270270271,0.15447154471544716,0.21138211382113822,0.1818181818181818,0.23668639053254437,0.15609756097560976,0.16666666666666666,0.2296650717703349,0.1795918367346939,0.2090909090909091,0.23076923076923078,0.16170212765957448,0.1918819188191882
56,SP:99f226a63902863c429cb7baefab09626d13921e,"The paper studies problem-dependent sample complexity bounds for best policy identification (BPI) in finite MDPs under the infinite horizon discounted criterion. The agent interacts sequentially (online) with the MDP, a weaker assumption than the generative model required by previous work in the same setting. Its main contributions are:  (i)  A problem-dependent lower bound on the sample complexity that takes into account navigation constraints;  (ii) Since the lower bound is defined as the solution to a non-convex optimization problem, the paper uses a convex relaxation introduced by [MP20] to derive a relaxed lower bound;  (iii) An algorithm whose upper bound matches the relaxed lower bound up to a factor 2. ","The paper studies best-policy identification in discounted MDPs with online interaction. The authors first derive an information-theoretic lower bound on the sample complexity of any \delta-correct algorithm for this problem. The lower bound is given as the solution to a non-convex optimization problem for which a convex relaxation is provided. The authors then design an algorithm using the standard template for building pure exploration strategies from asymptotic lower bounds (GLR test + tracking + forced exploration). For this algorithm, the authors derive an asymptotic (as \delta -> 0) upper bound on the sample complexity that matches the value of the relaxed optimization problem up to a factor 2.","The paper studies the best policy identification (BPI) problem in Markov Decision Processes, under navigation constraints, i.e., when accessing a single trajectory from the environment, as opposed to the generative model setting. The paper focuses first on a lower bound on the sample complexity obtained by extending existing results. Then, an algorithm is introduced, and the corresponding sample complexity is analyzed. The contribution is mainly theoretical.","This paper deals with online learning of policies for MDPs. Its main novelty is considering the ""navigation constraints"" related to this online setting where, in contrast with an episodic setting, the system must learn the policy in a single episode without being able to reset to an initial state. Bounds on sample complexity are derived and an algorithm for learning the best policy by exploiting the lower bounds is proposed.  ","This work talks about best policy identification problem in discounted infinite MDP. Instead of assuming a generator, this work is on the online setting of MDP, where the agent can only collect state action pairs through online interaction with the environment. In theory, the work provides a lower bound of the BPI problem. Then the work provides a model-based algorithm MDP-NaS, which is shown to converge to the optimal policy. ",0.39285714285714285,0.22321428571428573,0.15178571428571427,0.1875,0.2018348623853211,0.1559633027522936,0.1559633027522936,0.23880597014925373,0.2537313432835821,0.21428571428571427,0.4036697247706422,0.373134328358209,0.24285714285714285,0.2916666666666667,0.3283582089552239,0.24285714285714285,0.2361111111111111,0.22857142857142856,0.2361111111111111,0.20833333333333334,0.3981900452488688,0.27932960893854747,0.18681318681318682,0.22826086956521738,0.25000000000000006,0.1899441340782123,0.1878453038674033,0.23357664233576642,0.24460431654676257,0.2112676056338028
57,SP:9dcb74bfdbc4aa1e27f5d2adb6d2abf475e9324d,"This paper studies the problem of sparse tensor PCA (a generalization of sparse PCA and tensor PCA). The main result is an algorithm that -- for the highly sparse regime in which the sparsity is at most the square root of the signal dimension -- naturally interpolates between a poly-time efficient algorithm and exponential exhaustive search. This result is complemented by lower bounds for the rather popular computational model captured by low-degree polynomials. The lower bounds match the algorithm guarantees (although for the different problem of distinguishability) in the regime of constant tensor order $p$.   The results of this paper recover several results of the literature, and provide a non-trivial extension. ","# Review for ""The Complexity of Sparse Tensor PCA""  This paper studies the ""Sparse Tensor PCA"" problem, which is a common generalization of two well-studied problems: sparse principal component analysis and tensor principal component analysis. The problem is as follows: given a ""single-spike"" tensor of the form  $T = \lambda \cdot x^{\otimes p} + W$  where $W$ has i.i.d. Gaussian entries, $\lambda > 0$ is the ""signal strength"", and $x \in R^n$ is $k$-sparse for some $k \ll n$, find $x$. (The problem can be generalized to more than one spike $x$; this is treated carefully in the paper.)  The paper contains interesting new algorithms and computational lower bounds for this problem. ","The authors propose a family of algorithms for solving the sparse tensor PCA problems, which is based on smooth interpolation between a polynomial-time algorithm and exponential-time search algorithm. Improved results are achieve for sparce PCA in the lower signal/noise ratio regime in distinct sparse signal cases, compared with existing guarantees. Lower bound analysis is also provided for the proposed algorithm.","This paper focuses on the tradeoff between computational complexity and conditions for recovery in a symmetric sparse tensor estimation problem. There has been a great deal of work on related problems recently in the case of matrices (order 2 tensors) and the case of tensors (without necessarily imposing sparsity constraints). The main achievability result (Theorem 1) provides sufficient condition for single spike model in terms of the ambient dimension, the order the tensors, the degree of sparsity, the signal strength, and an integer parameter the interpolates between a ````""low complexity"" algorithm  ""high complexity"" algorithm (essentially brute force search). Similar results of for a multiple spike model are given in Theorem 2.   Necessary conditions for a certain testing problem are considered in Theorem 3 which provides necessary conditions such that a polynomial of bounded degree can ""distinguish"" between a planted model (with a signal of a given strength) and a null mull of only Gaussian noise. Here the criterion for distinguishability is a certain L2 test.  While similar results have been obtained in the literature, the authors argue that their results improve upon the existing ones in a number of ways. ","This paper studies the estimation of a rank-one (or more generally a low-rank) tensor $x^{\otimes p}$ ($x \in \mathbb{R}^n$ is assumed to have unit norm) given $Y = \lambda x^{\otimes p} + W$, where $\lambda > 0$ and $W$ is a Gaussian noise tensor. Here the signal vector $x$ is assumed to have only $k$ non-zero entries.  The main contribution of the paper is an algorithm that recovers with high probability the support of $x$ in time $O(n^{p+t})$ provided that $\lambda \geq O(\sqrt{t} (k/t)^{p/2})$. The number $t$ can be arbitrarily chosen between $1$ and $k$, illustrating a tradeoff between statistical constraints on the signal-to-noise ratio $\lambda$ and runtime constraints on the estimation algorithm. This generalizes to the 'tensor settings' previous results obtained about sparse PCA.  The authors also prove an information-theoretic lower bound for low-degree polynomials. More precisely, they prove that no test based on polynomial of degree at most $D$ can distinguish between the planted model $Y = \lambda x^{\otimes p} + W$ and the pure noise model $Y=W$, when $\lambda$ is smaller than some quantity depending on $D, n, k, p$. This bound generalizes previously obtained results for PCA and tensor PCA. This bound is tight for low-degree polynomials. However there is a gap with the  bound $\lambda \geq O(\sqrt{t} (k/t)^{p/2})$ needed for the algorithm that recovers the support.   ",0.25892857142857145,0.1875,0.3125,0.30357142857142855,0.1391304347826087,0.23478260869565218,0.28695652173913044,0.2698412698412698,0.30158730158730157,0.20526315789473684,0.25217391304347825,0.3333333333333333,0.18421052631578946,0.13991769547325103,0.25396825396825395,0.14210526315789473,0.13580246913580246,0.08947368421052632,0.07818930041152264,0.16049382716049382,0.2555066079295154,0.24000000000000005,0.23178807947019867,0.1915492957746479,0.1797752808988764,0.17704918032786884,0.1843575418994413,0.13438735177865613,0.12418300653594772,0.18013856812933024
58,SP:9e4d04b22ce4f986aabb747a42f40c827073e39e,"This paper proposes a new strategy for reactants generation for the retrosynthesis prediction. Motivated by the fact that the graph topology of precursor molecules is largely unchanged during the chemical reaction, the authors propose to expand intermediate synthons into reactants by selecting and attaching leaving groups (molecule sub-graphs extracted from training data) to the synthons. The product molecule is transformed into synthons through graph edits. The proposed method achieves 53.7% top-1 accuracy."," This paper presents GraphRetro, a single-step retrosynthesis model that represents an advance from last years' NeurIPS state of the art model on semi-template-based modeling of the USPTO-50k dataset. GraphRetro uses a graph neural network that predicts edits to transform a target into synthons and then expands the synthons into full molecules by attaching leaving groups (with the synthons and leaving groups learned from the training set). The authors compare the predictions on the USPTO-50k to existing baselines, and show examples of predictions, including wrong ones. Because of the particular construction of the model, the authors can decompose the sources of errors as wrong edit predictions or wrong synthon completions. ",## Summary.  The authors propose a new method for single-step retrosynthesis prediction. Their method first predicts graph edits using a message passing network yielding synthons which are then completed by adding leaving groups. The leaving groups are chosen from a fixed set using another MPN. ,"This paper deals with molecular graph generation via synthon, incomplete molecular graphs.  Unlike existing works, this paper formulates the completion of incomplete molecular graphs not as a generation problem but as a classification problem to select one of a set of pre-computed leaving groups fragments. The training and evaluation are performed using the standard dataset USPTO-50k. The proposed model has high retrosynthesis performance, covering a large number of responses with a small set of leaving groups.","This paper proposes a new retrosynthetic prediction model using neural networks. The algorithm proposed to make the prediction based on breaking the target product into synthons and adding leaving groups to the synthons. The main difference of the proposed algorithm to the existing synthon-based retrosynthetic model is on introducing the vocabulary of leaving groups to complete the synthons in an efficient way.  Extensive evaluation verifies that the proposed method is competitive with the existing algorithms, and each algorithmic component plays a meaningful role.",0.28,0.14666666666666667,0.16,0.29333333333333333,0.14912280701754385,0.14912280701754385,0.21052631578947367,0.2,0.26666666666666666,0.1794871794871795,0.18421052631578946,0.24444444444444444,0.15384615384615385,0.2619047619047619,0.37777777777777777,0.21794871794871795,0.2857142857142857,0.11538461538461539,0.14285714285714285,0.16666666666666666,0.2222222222222222,0.18333333333333335,0.1568627450980392,0.2767295597484276,0.21383647798742136,0.17708333333333334,0.24242424242424243,0.14634146341463417,0.18604651162790697,0.1728395061728395
59,SP:9ed528da4b67f22678303cfd975aafe678db6411,"This paper studies the problem of multi-armed bandits under the shuffled model of DP. The authors provide two algorithms, one of which almost matches the regret of the best known algorithms for the centralized model. To do so, they give a variant of the arm elimination algorithm that leverages the private summation algorithm by Cheu et al. [9] and uses exponentially growing batches. ",The paper studies the classic multi-armed bandit problem in the shuffled model of differential privacy. Paper's first contribution is the definition of shuffled differential privacy (SDP) in the multi-armed bandit setting.  The paper's main contribution is an SDP algorithm with the same regret guarantees as the best-known multi-armed bandit algorithm in the central privacy model.,"This paper adapts the shuffle model of differential privacy to the multi-armed bandit setting, and aims to design a bandit algorithm which has privacy guarantees similar to that in the local model, while simultaneously having regret guarantees similar to the central DP model. The authors propose two arm-elimination style algorithms, which uses a private binary summation mechanism with optimal error guarantees as a subroutine, in order to obtain improved regret guarantees over the local model. In particular, they show how a simple, constant batch size policy already gets rid of the multiplicative dependence on $1/\epsilon^2$. Then, they show how to adapt this policy to exponentially increasing batch sizes, improving the additive dependence from $\approx k/\epsilon^2$ to $\approx k/\epsilon$. ","This paper studies the multi-armed bandit problem under the constraint of approximate differential privacy. Previously, multi-armed bandits have been studied in other models of privacy such as the centralized pure DP model, the centralized approximate DP model, and the local pure DP model. However, this is the first work to consider the multi-armed bandit problem under the shuffle model of privacy.  To be clear, the model that the authors consider is as follows. At each round $t$, a batch of $m$ random users are selected. An action (e.g. an ad) is then selected for each user. The reward for each user is then presented to a shuffle DP mechanism.  In terms of results, the authors prove a regret bound which is slightly weaker than the result one can obtain in the central DP model but significantly stronger than the result one can obtain the local DP model. In particular, it removes a multiplicative $1/\epsilon^2$ dependence that appears in the regret bound for the local DP model.  In terms of techniques, the authors combine some ideas from the bandit literature and the differential privacy literature. In particular, their algorithms are based on the non-private arm elimination algorithm and they show how one can use private binary summation from the shuffle DP literature to obtain a shuffle DP algorithm for MAB. The authors also give two differential algorithms. The first algorithm uses static batch sizes in each round. The second algorithm uses dynamic batch sizes and they show that this improves the regret.","The paper proposes a shuffle model of DP for multi-armed bandits. The paper proposes two algorithms, SDP-AE and VB-SDP-AE, for bandits with shuffle DP and Bernoulli rewards. Distribution-dependent and independent regret bounds are derived for both the algorithms. VB-SDP-AE achieves additive regret due to privacy which has same order of dependence on $\epsilon$ but logarithmically worse dependence on $T$ than centralised DP.",0.28125,0.34375,0.484375,0.203125,0.3114754098360656,0.4426229508196721,0.21311475409836064,0.32,0.136,0.06589147286821706,0.29508196721311475,0.176,0.12015503875968993,0.18840579710144928,0.152,0.10465116279069768,0.18840579710144928,0.15503875968992248,0.2463768115942029,0.2463768115942029,0.288,0.23280423280423282,0.19254658385093168,0.1954887218045113,0.20430107526881722,0.16927899686520376,0.2,0.20887728459530025,0.17525773195876293,0.10397553516819573
60,SP:a22a893e25ce739dc757861741014764e78aa820,"This paper focuses on the long-term forecasting problem of time series. This work introduces the traditional idea of decomposing time series into seasonality and trend-cycle components into deep Transformer architecture. This work also proposes an auto-correlation mechanism that replaces the original self-attention in Transformers.  Further, they improve the computation efficiency by computing power spectral density. Experiments on several datasets show that the proposed method achieves better performance compared to SOTA methods.",This paper presents Autoformer to perform long-term time series forecasting. The key idea is to leverage an auto-correlation mechanism to discover the sub-series similarity based on the series periodicity and aggregate similar sub-series from underlying periods. The experiment results on several datasets showed the effectiveness of the proposed method.,"This paper studies the problem of long-term forecasting for time series. There are two challenges: (1) it is difficult to directly study the entangled temporal dependencies for long time series; (2) the traditional self-attention mechanism in Transformer is computationally expensive. To address these two problems, the paper proposes a novel Autoformer with a novel auto-correlation mechanism and a series decomposition module. ","This paper studies long-horizon time series forecasting where the historical input length is shorter than the forecast horizon, i.e, output length. This approach extends the transformer by replacing the self-attention unit by autocorrelation and decomposition units.  The autocorrelation unit chooses the top $k$ highly correlated time lags from $L$ time lags between the query and key embeddings of a time series of length $L$. The normalized correlation of lag j between the query and key embeddings multiplied by the j-item rotated value embedding.  The decomposition block decomposes a time series to seasonal and trend components. The trend component is defined by using an average pooling, which is an average value of the neighbouring values. And the seasonal is then defined as the difference between the (observed) time series and the trend component. The proposed approach autocorrelation unit is compared with standard attention, logsparse attention, LSH and probsparse attention.  ","This paper introduces a new approach for long-term time-series forecasting that is based on decomposition and auto-correlation. Essentially, the authors define a series decomoposition block which extracts the mean (trend-cyclical) and subtracts it from the series, obtaining the seasonal part. In addition, the authors design an auto-correlation component that identifies local structures across periods. The method is evaluated on six benchmark datasets and in comparison to several baseline approaches. The presented results show improvements over existing work.",0.26666666666666666,0.21333333333333335,0.26666666666666666,0.22666666666666666,0.2641509433962264,0.32075471698113206,0.37735849056603776,0.265625,0.234375,0.1513157894736842,0.37735849056603776,0.25,0.13157894736842105,0.2073170731707317,0.21875,0.1118421052631579,0.24390243902439024,0.1118421052631579,0.18292682926829268,0.2804878048780488,0.3125,0.23021582733812948,0.17621145374449337,0.21656050955414013,0.23931623931623933,0.16585365853658535,0.2962962962962963,0.1574074074074074,0.2054794520547945,0.1965811965811966
61,SP:a6f1094a4c9f38df38c9710b9dcd6299f430fae2,"The paper explores a novel approach to using expert policies in RL context. The main idea is to enrich expert demonstrations by perturbing a state by Gaussian noise and querying expert policy to produce an action from the perturbed state. These additional state-action pairs are used in the policy learning algorithm. The authors show experimentally that the proposed Augmented Policy Cloning (APC) can significantly improve the quality of cloned policy, compared to Behaviour Cloning.","This paper proposes Augmented Policy Cloning (APC) approach to improve the data efficiency of expert behavior by augmenting expert trajectory data with virtual, perturbed states and the expert actions in these virtual states. This method is simple by applying the existing image-based data augmentation method, but it can increase the data efficiency of policy cloning and transfer high-DoF behaviors. The proposed method outperforms BC and Naive ABC.","This paper proposed an data-augmentation technique -- ""augmented policy cloning (APC)"" to enable efficient policy learning from parametric experts. It achieve a high level efficiency in transferring knowledge from an expert to a student policy for high Degrees of Freedom environment. The augmentation is introduce not only for the states but also to the actions of underlying policy.","The paper proposes a policy cloning method that transfers an expert to a student. In the considered setting, the expert policy is accessible at all times, while there is no access to the environment to perform RL. The proposed method leverages data augmentation to successfully train the student policy.","This paper proposes to study the non-interactive imitation learning setting where access to the parametric expert policy is available. The paper proposes to augment the logged expert data’s states with noise, and then determine then sample corresponding actions from the expert’s policy. These perturbed states and corresponding action are then use to train the agent. They show this method outperforms Behavior cloning and an approach where the logged states are perturbed but the corresponding actions are kept fixed on imitation learning tasks and RL tasks where IL is used for warmstarting. ",0.2,0.14666666666666667,0.18666666666666668,0.22666666666666666,0.2318840579710145,0.2028985507246377,0.2898550724637681,0.25862068965517243,0.2413793103448276,0.32653061224489793,0.21739130434782608,0.1896551724137931,0.2857142857142857,0.18085106382978725,0.27586206896551724,0.2857142857142857,0.2127659574468085,0.30612244897959184,0.14893617021276595,0.1702127659574468,0.20833333333333331,0.16541353383458646,0.22580645161290322,0.20118343195266272,0.25196850393700787,0.23728813559322035,0.24539877300613494,0.2803738317757009,0.18421052631578946,0.22377622377622378
62,SP:aa84981dd503ec34d9f06aa6e5f680e267f82b04,"The paper addresses the local explanation of sequence generation models, specifically under the dialogue response generation setting, and proposes local explanation of response generation (LERG) that computes the mutual interactions between input and output sequences under perturbations as the explanations. Automatic and human evaluations show that LERG is more effective than other baselines.  Contributions:  1. A new local explanation method for dialogue response generation 2. Such an explanation method could be generalized to other generation models as well 3.  A systematic framework to evaluate the dialogue model explanation quality involving both automatic evaluations and human studies.","This paper proposes a model-agnostic explanations model, local explanation of response generation (LERG), for dialogue response generation task. Due to the sequence-to-sequence natrual, previous works, which normal produces a single label as output, are no longer suitable for this task. This paper regards the explanations as the mutual interaction of segments in input and output sentences. Specifically, it views the sequence prediction as uncertainty estimation of a human response and creates explanations by perturbing the input and calculating the certainty change over the human response. The experiment shows that the proposed approach extract both explicit and implicit relations between input and output segments.","This paper studies the model-agnostic explanations of dialogue response generation and proposes a new called local explanation of response generation (LERG). LERG extracts the sorted importance scores of every input-output segment pair from a dialogue response generation model. It views the sequence prediction as uncertainty estimation of a human response and creates explanations by perturbing the input and calculating the certainty change over the human response. The authors show the proposed LERG adhere to three properties of  an ideal explanation of text generation: (1) unbiased approximation, (2) intra-response consistency and (3) causal cause identification. The experiments on a popular benchmark DailyDialog empirically verify the effectiveness of the proposed approach.","This work proposes a method to locally explain the dialog response generation process. This method is motivated by the intuition that, such method should answer the question ""which parts of the response are influenced the most by parts of the prompt"". So the importance scores of every input-output segment pairs are calculated. They also proposed two metrics to evaluate explanations: ""necessity"" and ""sufficiency"". The former is defined as the perplexity change after removing top ""salient"" input features, and the latter is defined based on the intuition a complete explanation should recover model's prediction without the original input.","The authors propose a method for “explaining” dialogue responses from sequence generation models; that is, determining what parts of the input influence or “explain” certain elements of the output. The method, LERG, is “learned” in one of two ways to assign a score for each input/output token pair indicating the measure of relevance, and ultimately to link the intent between the two. The authors propose that their method must satisfy three properties: unbiased approximation (LERG should explain benefits of picking response given the context); consistency (LERG should explain each generation step); and cause identification (LERG should sort input features by importance). The authors measure the effectiveness of the proposed method in both automatic evaluations and user studies. The automatic evaluations measure the **necessity** and **sufficiency** of the explained segments of the input text by capturing the model perplexity difference when stripping the segments and only including the segments, respectively, essentially measuring how accurate the method’s explanations are at capturing the relevant segments of the input context. Human evaluations display the segments to humans and ask if they can predict the gold response. Both evaluations show their explanation method significantly outperform both random baselines and other methods from the literature.",0.21875,0.3020833333333333,0.16666666666666666,0.22916666666666666,0.44339622641509435,0.20754716981132076,0.24528301886792453,0.20535714285714285,0.2767857142857143,0.30303030303030304,0.19811320754716982,0.25892857142857145,0.16161616161616163,0.10945273631840796,0.41964285714285715,0.2222222222222222,0.12935323383084577,0.23232323232323232,0.15422885572139303,0.14925373134328357,0.2079207920792079,0.27884615384615385,0.1641025641025641,0.14814814814814814,0.4311926605504587,0.2146341463414634,0.16938110749185664,0.21800947867298578,0.19808306709265175,0.19999999999999998
63,SP:aae8847c5e52d14820967ab39770ab4ae16df59c,"This paper proposes an efficient sparse training method to solves the problem of accelerating the training speed of deep neural networks and save memory usage.  The authors first formulate the training process as a continuous minimization problem under global sparsity constraints.  Then, separating the optimization process into two steps, corresponding to weight update and structure parameter update. A variance-reduced policy gradient estimator is proposed to update the structure parameter. Finally, the experimental results are solid and strong. The problem has lots of meanings for engineering implementation.  ","The authors propose a channel-level sparse training algorithm that can effectively utilize the channel sparsity to accelerate both forward and backward propagation process. They divide the sparse training process into weight updating step and mask updating step. And solve the problem separately. More specifically, they develop a variance-reduced policy gradient estimator to update the trainable pruning mask without the need for backpropagation, and hence a sparse computation on both forward and backward propagation.","Paper proposes a variational based pruning method where, with 2 structurally sparse forward passes and 1 sparse backward, the training can be significantly faster. Description is clear and theoretically sounds, equations are easy to follow, code is provided, results are encouraging. The paper might be a great benchmark and starting point for faster pruning-while-training with efficient inference. ",This paper addresses the topic of sparse training of neural networks. They target channel-level sparsity with the goal of realizing practical training speedups with existing software and hardware. The authors study the limitations of existing techniques in terms of their ability to exploit sparsity during training and show a wide array of empirical results with their proposed technique.,"Network sparsity has historically targeted only inference.  Recent explorations in training with sparsity fall short of their potential, though, by not fully exploiting sparsity in the forward and backward propagation steps.  The authors decompose training a channel-wise sparse network into two parts: training the weights themselves (as usual) and learning the sparse structure.  Rather than using a chain-rule based gradient step for the structure, a unique policy gradient estimator with reduced variance is used; it is composed of two forward passes, eliminating the need for the chain rule to be used to learn the sparse structure.  Experiments show competitive accuracy for saved parameters and FLOPs for a number of networks, as well as actual time saved during training with the proposed technique for VGG19 on CIFAR-10.",0.2413793103448276,0.13793103448275862,0.1839080459770115,0.26436781609195403,0.16,0.16,0.29333333333333333,0.13559322033898305,0.23728813559322035,0.2711864406779661,0.28,0.2033898305084746,0.2711864406779661,0.17829457364341086,0.2033898305084746,0.2033898305084746,0.17054263565891473,0.13559322033898305,0.10852713178294573,0.12403100775193798,0.25925925925925924,0.1643835616438356,0.2191780821917808,0.212962962962963,0.1791044776119403,0.1791044776119403,0.21568627450980393,0.13559322033898305,0.14893617021276598,0.1702127659574468
64,SP:b03063fa82d76db341076e5f282176f4c007a202,The authors provide an analysis of an entropy regularized extra-gradient method for zero sum games. The proposed algorithms have last iterate convergence guarantees to the equilibrium of the regularized game at rate that is dimension free (up to double logarithmic factors) regardless if the unregularized game has a unique equilibrium. The algorithms can be used to find approximate equilibria of the unregularized game and in Markov zero sum games.,"The paper studies two standard classes of games with entropy regularization: two-player zero-sum matrix games and zero-sum Markov games. For the regularized matrix games, the authors apply the mirror descent approach (using KL distance) to the regularized objective, and propose two first-order descent/ascent algorithms using different optimistic predictions: the Predictive Update (PU) and the Optimistic Multiplicative Weights Update (OMWU). The authors prove that both algorithms converge to the unique Nash equilibrium of the regularized game with constant stepsizes, linearly. The authors characterize the linear convergence via four measures: KL distance, infinity norm, optimality gap, and duality gap. It is featured by last-iterate convergence and almost dimension-free. For the regularized Markov games, the authors apply the proposed PU and OMWU to the $Q$-value functions at each state and prove the convergence in infinite norm to the optimal $Q$-value function of the regularized game. The convergence rate is slightly worse than the linear rate, but it is also almost dimension-free. The authors also provide computational experiments to verify the usefulness of the proposed algorithms. ","The authors propose to use mirror descent to solve classic entropy-regularized competitive games. Linear convergence rates are obtained for the proposed algorithm. In addition, the authors propose to use such an algorithm to solve the subproblem in the entropy-regularized Markov game and obtain a linear convergence rate to the regularized equilibrium.","This paper proposes to leverage entropic regularization and optimistic-type methods to solve zero-sum (ZS) matrix games and ZS Markov games. The authors begin with ZS matrix games on the simplex: they add entropic regularization, thus transforming this game into a strongly-concave/strongly-concave problem. Slight variants of Mirror-prox/extragradient and optimistic mirror descent with multiplicative updates are introduced, and the authors show that, for several performance measures, the last-iterate of these methods converge linearly to a solution of the regularized problem thanks to the added strong convexity/concavity. Their rates are (almost) dimension-free, and do not require the uniqueness of the solution. As a consequence, they explain how to obtain $\epsilon$-Nash-equilibrium with $O(1/\epsilon)$ iterations by tuning the regularization parameter. Finally, the authors propose to put to use their results to tackle ZS infinite-horizon Markov games.","In this work, the authors aim to complete the recent line of research in last-iterate convergence guarantees for saddle-point optimization (applicable to game theory, GANs, etc.) with efficient methods that converge to an approximate Nash equilibrium *without* the equilibrium uniqueness guarantee. The key is to simply apply the previously analyzed methods (OMWU in particular) on a regularized version of the payoff. The regularization ensures uniqueness of what is called QRE, quantal response equilibrium, which can be used for finding an approximate Nash equilibrium. As a bonus, the authors show that their results apply to Markov games too.",0.35714285714285715,0.22857142857142856,0.2857142857142857,0.32857142857142857,0.12087912087912088,0.2032967032967033,0.12637362637362637,0.3018867924528302,0.24528301886792453,0.17123287671232876,0.13736263736263737,0.3018867924528302,0.136986301369863,0.23232323232323232,0.41509433962264153,0.2534246575342466,0.23232323232323232,0.1095890410958904,0.13131313131313133,0.25252525252525254,0.1984126984126984,0.26016260162601623,0.18518518518518517,0.27218934911242604,0.18723404255319148,0.22560975609756095,0.16370106761565836,0.16080402010050251,0.1710526315789474,0.20408163265306123
65,SP:b04caddcb2dc9e9b365a76fdbf3d3eb4efcdffd9,"This work studied the task of detecting online drug trafficking using social media data. In particular, the authors proposed to use graph convolutional networks to model various types of entities in social media and the relations between them. Also, a meta-learning algorithm is used for the model optimization.","Summary:  The authors propose a model to detect drug-trafficker profiles on Instagram. The model consists of many steps and phases, but in short: they create a heterogeneous graph from users, keywords, and posts, and in addition to the regular cross-entropy loss they propose to add multiple regularizer terms extracted from several stages of their algorithm (i.e., a term to build the graph, a term to learn the node representations, and a term to distill the knowledge from an out-of-domain model).  To evaluate their model, the authors created a dataset and compared their model with many baselines and their combinations. They also reported several experiments, including user visualization and a case study.","This paper propose a novel framework MetaHG based on R-GCN for illicit drug trafficker detection on social media. A series of methods including meta learning(MAML), self-supervised learning(AS-SSL) and knowledge distillation(KD) are used to MetaHG, and obtain better metrics than traditional models with few labeled samples. In addition, the paper also creates a new dataset from Instagram for the task.","This paper presents a novel heterogeneous graph learning model for automatically detecting illicit drug trafﬁckers on Instagram. The proposed model addresses two challenges: 1) sparse graph structure, and 2) limited labeled samples for model training. The authors also collected a large social media dataset from Instagram and conducted a lot of experiments to evaluate the proposed model.","The paper proposes a novel model MetaHG to automatically detect illicit drug traffickers on social media. It firstly builds a heterogeneous graph based on post content and relational structure information on social media to characterize the drug trafficking system. Then it integrates graph structure learning and relational-based GCN to learn robust node embedding on HG. Afterwards, it leverages meta-learning and knowledge distillation to optimize model parameters and further to detect drug traffickers on social media. Finally, it conducts extensive experiments to validate the effectiveness of the framework.",0.22448979591836735,0.22448979591836735,0.2653061224489796,0.24489795918367346,0.1206896551724138,0.15517241379310345,0.19827586206896552,0.27692307692307694,0.2923076923076923,0.3103448275862069,0.09482758620689655,0.16923076923076924,0.22413793103448276,0.1348314606741573,0.2153846153846154,0.3103448275862069,0.25842696629213485,0.3103448275862069,0.21348314606741572,0.20224719101123595,0.13333333333333333,0.1929824561403509,0.2429906542056075,0.17391304347826084,0.15469613259668508,0.20689655172413793,0.22439024390243906,0.2926829268292683,0.24675324675324672,0.24489795918367344
66,SP:b0bf070e8d7eefdfc45f236e9ecb9edfb4816e0a,"This paper studies certified robustness from the perspective of computing Lipschitzness bounds. Prior work compute global bounds on the Lipschitz constant of the network; this paper takes an alternative approach which computes local Lipschitz bounds around a specific input. These local Lipschitz bounds are based on interval bounds for the hidden layers on each data point, and computing a tighter Lipschitz constant based on eliminating rows/columns of the weight matrices when the interval bounds indicate that a neuron is inactive.   To train certifiably robust models, the worst-case loss is optimized based on these Lipschitz bounds. There are several other ingredients for the proposed method: a modified ReLU activation which truncates when the output is a large positive value, and a sparsity-inducing regularization meant to limit the number of neurons where the upper and lower activation bounds differ. The authors compare certified robustness w.r.t. $\ell_2$ perturbations against other Lipschitzness-based baselines and demonstrate improvements. ","This paper provides a trainable local Lipschitz upper-bound for a neural network that is tighter than the global Lipschitz upper-bound computed via multiplying the Lipschitz constant of each individual layer. By making use of the interaction between the weight matrices and the piece-wise linear activation functions, the authors demonstrate that the global Lipschitz bound could be improved when the activation functions are constant locally. In addition, the authors proposed a variant of ReLU that is clipped at a certain upper threshold to increase the constant region to help achieve a tighter Lipschitz upper-bound. Empirically, the authors showed that optimizing the local Lipschitz bound, along with using the modified ReLU, improved the certified robust performance of existing algorithms on several standard image classification tasks.","Per data-example, a local Lipschitz bound on the neural network output is computed and then used to certify robustness. This bound is made tighter by exploiting invariances of the ReLU activations throughout the network under small perturbations around the given data point. The paper further increases invariances by clipping ReLU and training the clipping threshold.","This paper proposes a new method for certified robustness that tightly bounds the local Lipschitz constants for models by exploiting zero-activation of ReLU. For each data point, the proposed method first calculates the positions where feature maps become zero by ReLU. Next, since the row vector of the weight matrix before the ReLU outputs zero does not affect the output, the proposed method eliminates such row vectors and computes the Lipschitz constants of the modified weight matrix. Experiments demonstrate that the proposed method outperforms previous methods in terms of clean accuracy, robust accuracy against PGD, and certified robust accuracy. ","This paper proposes using local Lipschitz bound to obtain certified robust neural networks. The use of local Lipschitz constant strictly results in a provable tighter bound than the commonly used global Lipschitz bound. To incorporate the proposed certification method into training, the authors further proposed a modified ReLU function with a learnable upper threshold, and hinge loss to encourage the pre-activation states to be constant past ReLU function.  The proposed method is sound, numerical experiments show promising improvement over the existing certified robust training methods.",0.1949685534591195,0.09433962264150944,0.16981132075471697,0.1509433962264151,0.13385826771653545,0.1889763779527559,0.2283464566929134,0.25,0.21428571428571427,0.21,0.2440944881889764,0.26785714285714285,0.27,0.27906976744186046,0.30357142857142855,0.24,0.3372093023255814,0.14,0.13953488372093023,0.2441860465116279,0.2167832167832168,0.13953488372093023,0.20849420849420852,0.19591836734693874,0.18579234972677597,0.21145374449339205,0.2723004694835681,0.1794871794871795,0.16901408450704225,0.22580645161290322
67,SP:b1163857a6b06047c3531ab762642fcbed6dd294,"This paper investigates the correspondence between the architecture of a linear neural network and the complexity measure induced by putting $l_2$ regularization on the weights. On one hand, the authors study the complexity measure induced by fully-connected networks, diagonal networks, convolutional networks with full or limited filter width, as well as residual networks. On the other hand, the authors also present the architectures that induce $l_p$, $l_{p, q}$ as well as $k$-support norms as complexity measures.","This paper studies various ways to parameterize linear neural nets and explore the regularization on the linear mapping (in terms of the final function obtained by multiplying all weight layers in the linear net) induced by l2 regularization in parameter space.   A large number of architectures are studied -- fully connected deep networks, diagonal networks, convolutional networks, and residual nets, with a characterization of the induced regularization for each of these settings. In addition, the paper also studies how to construct architectures to induce a particular desired regularizer. First, they study \ell_p norms and show that the \ell_p norm can be the induced regularizer if and only if p = 1, 2, with structural requirements on the architecture of the network. They also analyze which architectures can induce \ell_{p, q} group norms. All of the results in this paper are for linear neural nets.","This paper studies the representation cost of linear neural networks. Considering a target linear function with parameter matrix $B$, the authors investigate the effect of $\ell_2$ regularization in the predictor space. It is shown that a fully connected network regularizes the trace norm of $B$, diagonal network regularizes the $\ell_{1,2}$ norm of $B$, convolutional network regularizes a certain norm of the discrete Fourier transform of B, etc. The authors also discuss how one can design a linear neural network architecture to achieve certain regularization effects. ","The paper studies representation costs of linear networks and their induced complexity measures. First the representation costs of some standard architecture are given (fullly-connected nets, diagonal nets, convolutional nets, and residual nets), then for shallow networks a general formula for the representation cost (and its dual norm, given that the representation cost is convex) of any network is given. The second part of the paper is dedicated to the characterization of which complexity measures can appear from the representation cost of a neural network. Though this question is not answered in general, the authors study a number of related questions: a characterization of which $l_p$ can be represented by a neural network is given, then some example architectures are given to obtain group $l_{p,q}$ norms or $k$-support norms, then it is shown that $l_{p,q}$ group norm with overlapping groups and elastic nets cannot be recovered by a neural network representation cost (though it is possible for the representation cost of a general homogeneous parametrization). ",This paper studies the representation cost in the setting of linear networks. It is shown that an l^2 regularization on the parameters corresponds to adding a penalty on the functional space governed by the representation cost. This paper shows how the representation cost depends on the architecture and how the bias depends on the representation cost. ,0.37037037037037035,0.2222222222222222,0.2716049382716049,0.2222222222222222,0.18620689655172415,0.21379310344827587,0.1310344827586207,0.2840909090909091,0.2159090909090909,0.12280701754385964,0.20689655172413793,0.20454545454545456,0.1286549707602339,0.3157894736842105,0.3068181818181818,0.18128654970760233,0.3333333333333333,0.14619883040935672,0.3333333333333333,0.3684210526315789,0.26548672566371684,0.21301775147928995,0.1746031746031746,0.2608695652173913,0.23175965665236054,0.1962025316455696,0.18811881188118812,0.19305019305019305,0.26206896551724135,0.18421052631578946
68,SP:b2eafdb24fa081ae8b37525d70fb4bc2d54518dc,"This paper describes an algorithm that trains agents through self-play with no human data and no reward shaping, and can accommodate the large action space of Diplomacy. It is an algorithm for action exploration and equilibrium approximation in games with combinatorial action spaces. This algorithm simultaneously performs value iteration reinforcement learning while learning a policy proposal network. Meanwhile, a double oracle step is used to explore additional actions to add to the policy proposals. They train an agent completely from scratch for a 2-player variant of Diplomacy and show that it achieves superhuman performance. They also train an agent for the 7-player no-press Diplomacy entirely from scratch with no human data for the first time and show that this agent differs radically from past agents that required human data. This approach therefore opens up the ability to investigate novel ways of playing the game. ","Diplomacy is a complex 7-player strategy game that poses a challenge for RL due to its simultaneous moves and combinatorially large action space. In recent years significant progress has been made on learning human-level play by starting from imitation learning on a dataset of human play from websites, and then using some policy improvement algorithms. This paper tackles the exploration problem, introducing a policy improvement algorithm that reaches competitive-quality play without requiring a dataset, using Nash Q-learning, a double oracle-like method, regret matching, and geographically local perturbations for action proposals. They also find advantage from switching to a transformer-based architecture.  Their method (DORA) exhibits strong results in 1v1 human play, as well as being the first from-scratch agent able to play on par with DipNet (an imitation baseline) in a 1v6 setting, in a metagame that DORA wasn’t trained in.  Separately, their policy improvement method on top of an imitation network beats previous SOTA (SearchBot).","The paper proposes learning methods for the No-Press variant of the board game Diplomacy.   The method uses an equilibrium search method (similar to [9]) to solve for Nash in a single turn of the game, estimating future returns with a value function one turn in the future. Then a policy is trained to predict the equilibrium found, while the value function is trained to predict the values of the Nash equilibrium, which implements value iteration.  The equilibrium search method is based on prior work [9]. This tackles the large action space by restricting search to only the most likely actions from a policy network. This is extended in this work by using Double Oracle to expand the action set, and using a Diplomacy-specific method to generate proposal actions, which exploits the graph structure of the game. The paper also introduces a transformer-based model for learning to play Diplomacy, which outperforms previous Graph-Network approaches, and advances methods to estimate the exploitability of a Diplomacy agent.  Experimental results show that this results in an agent that can defeat human opponents convincingly in a 2-player variant of Diplomacy. ",This paper builds off of Gray et. al. by swapping out the blueprint that is trained on human data with one that is trained from scratch using a deep learning variant of Nash-Q learning. The new method is able to achieve what appears to be superhuman performance in 1v1 Diplomacy and also does well but with mixed results in 6v1 Diplomacy against existing methods. ,"The paper proposes an approach called DORA for building agents for the Diplomacy board game, which is a long standing AI challenge. The key achievement in the paper is constructing agents in a way that does not rely on imitating human gameplay (as opposed to some recent works which at least in part leverages historical game data). Diplomacy is hard because it has a large action space and as it is a game with many players (7 in the full game, but only two int eh France/Austria variant). The results are very good for the two player (France/Austria) variant against people. The results are more mixed in the 7 player game - when there are many copies of DORA, it does very well, but less well when there are many copies of another bot and one DORA player. ",0.1554054054054054,0.20270270270270271,0.10810810810810811,0.12837837837837837,0.17177914110429449,0.09815950920245399,0.09815950920245399,0.1,0.15263157894736842,0.2153846153846154,0.1411042944785276,0.15789473684210525,0.24615384615384617,0.1366906474820144,0.14736842105263157,0.24615384615384617,0.11510791366906475,0.2923076923076923,0.20863309352517986,0.10071942446043165,0.14790996784565916,0.1775147928994083,0.15023474178403756,0.13240418118466898,0.15864022662889515,0.14035087719298248,0.10596026490066227,0.14901960784313725,0.1762917933130699,0.1372549019607843
69,SP:b45f6966fcc07f3a33f70a57e72507b16fc7bb24,The authors proposed  clipped-SSTM and its restart version for stochastic nonsmooth optimization with heavy tailed noise. A detailed convergence analysis shows the theoretical advantage of the proposed algorithm. Experiments on real models (Bert) show that clipped-SSTM outperforms standard SGD methods.,"The paper tackles the important problem of high-probability convergence bounds for machine learning optimisation problems. Traditional analyses are done in expectation, which have been shown to not accurately represent all possible training outcomes; hence the need for tighter studies. In this paper, in the specific setting of convex, non-smooth losses with heavy tailed noise, a new high-probability bound is introduced for two algorithms. What sets it apart from previous bounds is that there is no direct negative dependency on the confidence bound (only logarithmic ones); and that in some cases it matches the non-heavy tailed noise bound. Numerical experiments illustrating the theoretical results are presented.","This paper aims to obtain the high probability convergence for the convex stochastic optimization problem when the stochastic gradient of the objective function is not assumed to be sub-Gaussian. While this goal has been achieved in two recently proposed optimizers by exploiting the gradient clippings technique under the smoothness assumption on the objective, this paper considers the more general setting when corresponding gradient only satisfies a Holder continuity condition. This condition recovers the smooth and non-smooth settings when an extra parameter takes extreme values. In such a more general problem formulation, the authors propose new step-size schemes such that the convergence rate of the aforementioned optimizers (designed for smooth problems) can be smoothly extrapolated to the non-smooth setting.     ",This paper analyzes the clipped SGD and clipped SSTM algorithm on generalized smooth objectives with Hölder-continuous gradients. They consider the case where the assumption of sub-Gaussian noise is not needed. They modified the stepsize in the clipped SSTM algorithm to fit the Hölder-continuity assumption. Theoretical analysis is conducted with convergence rates presented. ," The submission presents convergence results for clipped stochastic gradient methods without the sub-Gaussian assumption.  The subject of the submission is of interest to the NeurIPS community. As we find that some of our most difficult problems exhibit heavy-tailed noise, how to handle it in stochastic optimization is becoming more and more relevant.   My understanding of the main contributions of the paper over existing work is that this submission considers $\nu$-Hölder continuity (interpolating between Lipschitz functions and function with Lipschitz gradients) without assuming the stochastic gradients be sub-Gaussian (but still having bounded variance) - For the case $\nu = 0$ (Lipschitz functions), recovers tighter bounds (logarithmic dependence on the confidence level $\beta$ instead of polynomial) than naïve applications of Markov's inequality to results in expectation.  - For the case of $\nu = 1$ (Lipschitz gradient), the claimed contribution over the existing results of Gorbunov et al. [14] is that the problem need only be smooth in a ball around a minimum.   ",0.23809523809523808,0.23809523809523808,0.21428571428571427,0.2619047619047619,0.1834862385321101,0.11926605504587157,0.1743119266055046,0.10655737704918032,0.19672131147540983,0.24561403508771928,0.09174311926605505,0.08196721311475409,0.15789473684210525,0.06748466257668712,0.16393442622950818,0.22807017543859648,0.1165644171779141,0.22807017543859648,0.147239263803681,0.08588957055214724,0.13245033112582782,0.12195121951219512,0.18181818181818182,0.1073170731707317,0.17316017316017315,0.1566265060240964,0.13970588235294118,0.14525139664804468,0.16842105263157894,0.12727272727272726
70,SP:b937901e3230b14e36975fbab0658a52bdac4977,"Since GNNs based on rooted subtrees are known with limited expressive power, this paper proposes to represent nodes with their rooted subgraphs. Its expressive power with respect to graph isomorphism testing is proven beyond 2-WL. Such a method is compatible to plug into popular GNNs to enhance their representation power. Enhanced GNNs show strong performances on graph classification and regression tasks.","This paper proposes Nested GNN, which encodes each node based on the subgraph rather than the subtree (as what GNN does) around it. The main difference between NGNN and GNN is that subgraph captures more information than the subtree, such as the interactions between a node's neighbors. The whole-graph representation can be pooled from each node representation, and can be applied in tasks such as graph classification. From theoretical perspective, this paper studies the limitations of expressive power of GNN and show that NGNN is more powerful. The proposed method shows good performance on multiple datasets. ","This paper presents a framework that applies GNN to subgraphs around each node independently to enhance node representations, followed by a global pooling layer to get graph-level embedding. The framework can be applied to any GNNs. The paper also demonstrates it's relative improvement over several real-world datasets, although the improvement seems marginal. From theoretical side, the paper proved formally that this framework can distinguish k-regular graphs where most traditional message passing based neural network cannot. ","This paper introduces Nested Graph Neural Networks (NGNNs), a novel kind of graph neural network that overcomes the limitations of typical message passing approaches by representing each node as a function of its nested subgraph, rather than its nested subtree.  The result is a model provably more expressive than 1-WL and 2-WL, at the cost of a constant increase in computational complexity (although this has practical limitations, as the authors point out).  NGNN works on two levels:   1. A ""base GNN"" is used to compute representations for each node, applying the GNN to the nested subgraph around the node and eventually pooling the subgraph to obtain the representation.   2. An ""outer GNN"" processes the resulting graph to obtain the final node representations, and a global pooling is optionally applied to get graph-level embeddings.   Therefore, NGNN can surpass 1-WL expressivity using only standard message-passing GNNs, making it very convenient and more computationally efficient than previous higher-order GNN variants.   The authors prove the expressive power of NGNN in distinguishing n-sized r-regular graphs.   The paper concludes with a thorough experimental analysis of NGNN on several benchmarks of graph classification and regression: QM9, ogb-molhiv, ogb-molpcba, and some TU datasets.  The method achieves state-of-the-art performance on ogb-molpcba and several QM9 subtasks. ","This paper proposes a new architecture to strengthen message passing GNNs. Since the weaknesses of GNNs usually come from  the unidentifability of nodes, the authors suggest to first preprocess given graphs and add each node a new initial attribute, and then apply the outer GNN. The new node attributes come from another message passing GNN (called based GNN) applied to a subgraph of a certain depth (or height according to the paper's terminology) around each node. Then they prove that the new architecture can distinguish regular graphs with probability $1-o(1)$ (over the choice of a random regular graph), and so the new model is more expressive than MPNNs, since MPNNs can't. They finally evaluate their model in various settings.    For me the contributions of the paper are: (1) proposing nested GNNs (NGNNs); (2) showing that NGNNs can distinguish almost all regular graphs; (3) and evaluating the new model through various experiments. ",0.16129032258064516,0.14516129032258066,0.27419354838709675,0.1935483870967742,0.14285714285714285,0.336734693877551,0.21428571428571427,0.3291139240506329,0.27848101265822783,0.1590909090909091,0.10204081632653061,0.11392405063291139,0.07727272727272727,0.07741935483870968,0.17721518987341772,0.15,0.13548387096774195,0.11818181818181818,0.14193548387096774,0.22580645161290322,0.12500000000000003,0.1276595744680851,0.12056737588652483,0.11059907834101382,0.15819209039548024,0.20754716981132076,0.1660079051383399,0.17391304347826086,0.18803418803418806,0.18666666666666665
71,SP:ba01895bf1aa07a0630b8c41fc0e91effb34b4cf,"This paper categorizes the intermediate features of a DNN into robust ones and non-robust ones. Through visualization, the non-robust ones display different semantic information from the true label, and thus potentially leads to the existence of AE.  The paper proposes a new AE generation algorithm targeting the non-robust feature, and beats the common attack baselines.","This work utilizes an Information Bottleneck (IB) to distill robust and non-robust features in neural networks (NNs). Experiments are performed to show that the distilled features are correlated with adversarial prediction and are human-perceptible. Finally, an attack mechanism intensifying the gradient of non-robust features is proposed.","The paper proposes to explicitly separate intermediate representation into robust and non-robust categories by information bottleneck, and demonstrate that the non-robust feature is related to adversarial prediction. An attack mechanism based on enforcing non-robust features gradient is proposed. The experimental results show the effectiveness of the proposed approach. ","This paper focuses on robust and non-robust features in adversarial examples. This paper proposes a method of distilling robust and non-robust features via information bottleneck. Through analysis, this paper has shown the high correlation between the distilled features and the adversarial prediction. Based on that, the authors design a new attack that intensifies the gradient of non-robust features.","This study aims at distilling feature representations (mainly the last convolution layer) into robust and non-robust features using information bottleneck. For every layer, the feature maps are partitioned into robust and non-robust for each individual example. After finding this, the paper first illustrates that selectively propagating robust features of adversarial examples built for a robust network will not degrade the accuracy but propagating non-robust features does which to some extent illustrates that the information bottleneck method has correctly identified the robust and non robust features. They also illustrate that the adversarial class label has high correlation to the Non-robust features. ",0.1896551724137931,0.2413793103448276,0.3275862068965517,0.3103448275862069,0.3469387755102041,0.3877551020408163,0.3469387755102041,0.3333333333333333,0.37254901960784315,0.39344262295081966,0.22448979591836735,0.27450980392156865,0.3114754098360656,0.17307692307692307,0.3333333333333333,0.3114754098360656,0.16346153846153846,0.2786885245901639,0.18269230769230768,0.23076923076923078,0.205607476635514,0.25688073394495414,0.31932773109243695,0.2222222222222222,0.33999999999999997,0.34545454545454546,0.2222222222222222,0.30357142857142855,0.2451612903225806,0.2909090909090909
72,SP:ba790fdcf2deef1a1b5e1961c7c4a28dd0218420,"Inspired by the analysis in [10], this paper shows bounds on multitask online convex optimization w.r.t. an arbitrary strongly convex regularizer. The task relatedness is expressed I.t.o. task variance, defined by means of a task relatedness matrix. Experiments on real data are presented at the end. ","This paper considered multitask online convex optimization (OCO), in which each of $N$ agents learns a possibly different task on a common convex decision set.  The goal of this paper is to minimize multitask regret, defined as the sum of the regret of all agents. A simple way to independently run $N$ instances of OMD  for $N$ agents can achieve a multitask regret bound of $O(\sqrt{NT})$, where $T$ is the time horizon. The main contribution of this paper is to develop multitask OMD (MT-OMD) and establish the regret bound of $O(\sqrt{1+\sigma^2(N-1)}\sqrt{T})$, where $\sigma^2$ is the task variance. If $\sigma<1$, their regret bound is better than that established by the simple way.  ","The paper presents MT-OMD and related variants on multi-task online learning with strongly convex loss functions.  The proposals can improve naive optimization when the task similarity is small measured by the distance of reference vectors. Specifically, it proves a regret bound of the form $sqrt{1+\sigma^2(N-1)}\sqrt{T}$, as opposed to the standard $\sqrt{nT}$. This $\sigma$ measures the task similarity (The smaller $sigma$ is, the closer the tasks are). ","The paper proposes MT-OMD, which allows update sharing among tasks. It is shown that it achieves a regret of O(sqrt{sigma^2(N-1)}sqrt{T}). The paper also extends the OGD and EG and obtains closed-form updates. Numerical results are presented to validate the theoretical findings. ","This paper studies the online multi-task learning setting and proposes a multi-task variant of online mirror descent that works with convex losses, a general class of Bregman divergences, and any positively weighted task-interaction matrix. They provide regret guarantees that, on two different instantiations, improve over the baseline of running independent mirror descent algorithms. The algorithms have straightforward implementations that are used on experiments on four datasets.",0.3,0.28,0.14,0.22,0.21774193548387097,0.12903225806451613,0.10483870967741936,0.25,0.17105263157894737,0.16,0.12096774193548387,0.18421052631578946,0.14,0.15942028985507245,0.35526315789473684,0.32,0.18840579710144928,0.38,0.18840579710144928,0.11594202898550725,0.1724137931034483,0.2222222222222222,0.14,0.1848739495798319,0.27,0.1839080459770115,0.13471502590673576,0.30158730158730157,0.1793103448275862,0.13445378151260504
73,SP:bd3eecb81a17af010f2d3555434990855c1810f2,"This paper studies optimization of the information theoretical generalization bounds of Stochastic Gradient Langevin Dynamics (SGLD) with respect to the noise covariance. Here are the main findings: * When updating rule is fixed and only optimizing noise covariance under the constraint that the trace of the covariance is fixed, the noise covariance of SGLD is similar to the empirical gradient covariance * When both updating rule and the noise covariance are jointly minimized, the noise covariance of SGLD is the square root of the expected gradient covariance.  The two results can potentially be used to improve information theoretical generalization bounds obtained in the literature. The theoretical results are validated by some numerical experiments.  ","From usual isentropic noise to data-dependent priors, the authors extend the existing information-theoretic analysis of SGLD. Additionally, they identify the optimal choice of prior distribution covariance. Last but not least, the paper includes empirical observations to validate its technical findings.","This interesting paper studies the connection between generalization abilities of of SGLD and the covariance structure of its noise term. It first proves that with constraint to guarantee low empirical risk and commonly used data-dependent priors, the optimal noise covariance of SGLD in terms of the bound is similar to the empirical gradient covariance. The paper further proves that if the generalization bound is jointly optimized with respect to both prior and posterior, the optimal noise covariance is the square root of the expected gradient covariance. These facts can be used to further support the belief of the superiority of SGD noise over isotropic noise.","This paper study the interplay between generalization bound and the covariance of perturbed gradient descent. The authors invoke a recent (information-theoretic) bound for stochastic optimization methods. Then, they optimize the upper bound with respect to trace constraint on the covariance of noise in each step and experimentally show that this optimization may be effective for training neural networks. ","This paper considers the problem of understanding the generalization of the SGLD algorithms using information-theoretic techniques. This line of work initiates by [27],[24], and [13]. The goal in this paper is to ""modify"" the SGLD algorithms such that it has a good generalization properties and good performance on the training set. Basically, the modification that the authors considered is to make the covariance of the Gaussian noise in the SGLD update to depend on the trajectory. Note that in the usual setting the noise is isotropic. Then, authors claim that controlling the trace of the SGLD ensures we have good performance on training set and good generalization. Then the authors provide a generalization bound which uses reverse KL between posterior and the prior distribution. I think this bound is not true as stated in my review. Since this bound has been used in the paper, I think the authors should comment on the validity of the theorem.",0.0990990990990991,0.38738738738738737,0.13513513513513514,0.2882882882882883,0.30952380952380953,0.16666666666666666,0.30952380952380953,0.18867924528301888,0.29245283018867924,0.3050847457627119,0.2619047619047619,0.4056603773584906,0.2542372881355932,0.20125786163522014,0.12264150943396226,0.11864406779661017,0.08176100628930817,0.3389830508474576,0.1949685534591195,0.11320754716981132,0.14379084967320263,0.3963133640552995,0.1764705882352941,0.23703703703703705,0.17567567567567569,0.1386138613861386,0.12935323383084577,0.24242424242424246,0.2339622641509434,0.16513761467889906
74,SP:be53bc4c064402489b644332ad9c17743502d73c,"This paper presents a method to improve beam search by learning and predicting the global attention. A global scoring function is developed to regulate beam search to generate summaries. In Phase I, the global attention distribution is predicted in order to be included as a protocol to calibrate beam search. In Phase II, a step-wise global scoring function is used to guide beam search based on the predicted global attention distribution.  Experiments on 9 datasets show that the global-aware inference improves state-of-the-art summarization models.  ","This work proposes to add a global attention feature component to the beam search scoring procedure for conditional generation, which typically just considers the fitness of successor tokens conditioned on the predicted history of tokens in the beam. This augmentation basically keeps track of cumulative local autoregressive attention on the source tokens during beam search and penalizes major deviation from the predicted desired ""global"" attention over the source tokens. Specifically, this approach proposes a finetuning step of neural language generators, which is responsible for predicting cumulative global attention on each token and the training is done via regression. During training, the ""reference"" global attention is computed by using the full reference in the decoder transformer instead of just the left prefix of the reference to compute attention.  A relatively simple scheme is proposed to measure deviation of cumulative local attention from the global attention in a decomposable iterative manner. This scheme also involves a form of length reward that encourages the generation to match the length predicted by the global attention.  Experiments are performed on the task fo summarization with pretrained summarization system on 9 datasets. The results show that the proposed beam search augmentation outperforms standard beam search in general. Most strikingly, the ablation experiment with the ""Oracle"" global attention (instead of prediction, if we had access to the actual global attention and hence the actual reference length) significantly outperforms beam search and the proposed approach demonstrating the potential of global attention.","This paper thinks that cross attention distribution in transformer’s encoder-decoder framework can help the performance of beam search. At the same time, this paper also proposes an algorithm to predict distribution to help beam search. This paper conduct experiments on 9 datasets to prove its effectiveness. ","This paper proposes a generalization of the attention coverage penalty in seq2seq models (Wu et al 2016), where instead of encouraging a uniform coverage of the source, this work first predicts the expected coverage of each source word. During beam search, beam hypotheses that violate the expected attention coverage constraints receive a penalty. Experiments on 9 summarization benchmarks show that the proposed coverage loss outperforms using existing attention coverage losses during beam search.","This paper tackles the problem of suboptimality of beam search as it is not able to have a global perspective of the probability of the generated beams due to truncated beam size (less than vocabulary size) for space and time complexity purposes. This paper proposes a global-aware beam search which is calibrated using the global attention distribution to guide the local decisions at every time step during beam search. The global attention distribution prediction is formulated as a regression task, which is then fed into a global scoring function to guide the beam search-based generation. This approach solves the mismatch between the local optimality of beam search with the global optimal generation. This modified search strategy has been shown to boost the summarization of two SOTA models BART and PEGASUS. ",0.4157303370786517,0.15730337078651685,0.20224719101123595,0.38202247191011235,0.07407407407407407,0.11522633744855967,0.15637860082304528,0.25,0.375,0.2465753424657534,0.1522633744855967,0.2916666666666667,0.2465753424657534,0.25757575757575757,0.375,0.3835616438356164,0.2878787878787879,0.1643835616438356,0.13636363636363635,0.13636363636363635,0.22289156626506026,0.20437956204379562,0.2222222222222222,0.30769230769230765,0.12371134020618556,0.17721518987341772,0.2026666666666667,0.19834710743801653,0.19999999999999998,0.17560975609756097
75,SP:c5704a709f318c6e9a5c716e5e7f250acccf46a8,"This paper explores adversarial robustness via focusing on linear sub-networks. Through back propagation on linear sub-networks of a pre-trained network, an implicit weight expression which represents approximated class-wise responses can be obtained. With this matrix, the correlation among classes can be computed for exploring the hierarchy of classes. Similarly, the feature distance for different classes aligns well with class hierarchy through empirical observations. Based on these observations, the authors propose to impose feature distance regularization based on the computed class hierarchy.","The paper analyses adversarially robust models in terms of their clustering behavior with respect to the learned weights as well as with respect to the class-wise feature representations. For this purpose, the CNNs are linearized, i.e. non-linearities (ReLUs) are removed from the trained network such that it can be represented by a single weight matrix W, where each column corresponds to one class. The paper comes to the conclusion that hierarchical clustering of these representations is an indicator for adversarial robustness. Consequently, it formulates a regularization term which encourages such clustering behavior. The resulting models are evaluated in terms of adversarial robustness and in the context of domain adaptation. ","Adversarial robustness has received a lot of attention along with the study of adversarial data. So far, almost works have shown that robust classifier not only outperform under comprehensive adversarial attack evaluations but also boost the performance in some downstream tasks. However, the underlying mechanism of adversarial robustness is still not clear.  In this paper, they investigate adversarial robustness from the perspective of linear components. From this very novel perspective, they find that there are some statistical properties for comprehensively robust classifiers. Specifically, robust classifiers show an obvious hierarchical clustering effect on their linear sub-networks. Based on the above investigation, this paper applies this on more tasks, such as robustness boosting and domain adaption.","The paper proposed a novel method of linear model exploration by extracting their implicit linear matrix expression and find the weight clustering effect. The paper also claimed that the adversarial robustness shows close relationship with such clustering effect, which enables the further understanding and improvement of various tasks in the experimental parts. Overall, I like the analysis in the paper, it provides an interesting and reasonable way to understand adversarial robustness via linearity of weights.","This paper introduces the ""clustering effect"" of linear components of adversarial robust models. To be specific, the authors propose to remove the non-linear functions in networks and further integrate all linear components into a single weight matrix W in order to directly study the effect of linearity in adversarial models. By conducting experiments with W, the authors find that adversarially trained models tend to show clustering effects in both weight and feature dimensions. This effect further benefits some downstream tasks such as adversarial attack and transfer learning and can be enhanced with additional supervision. In all, the phenomenon showed in this paper is interesting and deserves more and deeper research. ",0.15294117647058825,0.15294117647058825,0.11764705882352941,0.2,0.13392857142857142,0.16071428571428573,0.21428571428571427,0.11304347826086956,0.1826086956521739,0.25333333333333335,0.11607142857142858,0.11304347826086956,0.13333333333333333,0.15315315315315314,0.13043478260869565,0.24,0.21621621621621623,0.17333333333333334,0.1891891891891892,0.17117117117117117,0.1319796954314721,0.13,0.125,0.17346938775510204,0.13215859030837004,0.19251336898395727,0.21524663677130043,0.13684210526315788,0.18584070796460178,0.20430107526881724
76,SP:c5a59c8d6db0f5491721aaaef182609c360930d3,The paper proposes a new solution to multi-task learning  that should improve in cases with gradients conflict of a task loss and the average loss gradient. The solution optimizes for an update vector that maximizes the worst task loss relative improvement. Experiments show the superiority of the proposed solution over similar prior methods. ,"This work presents a first-order multi-task learning method which uses, in place of the average task gradient, a vector which maximises the minimum local single-task improvement in a neighborhood of the average task gradient.  In multi-task learning, the goal is to find the optimal point achieving low losses across all tasks. However, gradient descent methods commonly used for single tasks in computer vision and reinforcement learning achieve suboptimal performance when applied on the average task loss due to conflicting gradients (single tasks gradients pointing in opposite directions). Recently, several methods have proposed modification to the update direction that alleviate this problem. However, these methods are either heuristics or can converge to any point in the pareto optimal set of the task losses (e.g. MGDA [5]), which might not be a minimum of the average task loss.   The proposed method, called Conflict-Averse Gradient descent (CAGrad), introduces an additional hyperparameter $c \geq 0$ which allows to interpolate between gradient descent ($c = 0$) and MGDA ($c \to \infty$). Furthermore, CAGrad provably converges to a stationary point of the average task loss with the same rate as gradient descent (when $c < 1$) or to a pareto stationary point (when $c \geq 0$). At each step of the method, the update direction is obtained by solving  an optimization problem in $K$ dimensions, where $K$ is the number of tasks, but has an overhead comparable to state of the art multi-task learning methods of the same kind (see last plot of Figure 5). Experiments on several computer vision and reinforcement learning multi-task benchmarks, where the method is used to optimize deep network parameters, show that the method achieves state of the art performance in all the settings. ","This work proposes a method to reduce conflicting gradients during training of multi-task learning paradigms via gradient modification. Rather than simply take an average of the per-task gradients, the authors propose to learn a model-wide gradient direction $d$ to update the shared parameters by solving a dual objective to find per-task loss weights. Simply, the proposed method (CAGrad) finds a direction which maximizes the worst local improvement among all tasks, and then applies this gradient update to the shared parameters. ","Multi-task learning (MTL) is an efficient way of learning multiple tasks efficiently by training all tasks together, amortizing their cost by sharing some parameters across tasks. In order to perform this, a weighted sum of the task losses is usually optimized, which can lead to poor final results due to sub-optimal optimization, an effect produced by the competition between tasks for the shared resources. Specifically, when computing the gradient updates for the shared resources, gradients of different tasks can conflict with each other, cancelling each other out (an effect known as *conflicting gradients*).  This work introduces CAGrad, an algorithm which minimizes the average loss function (the network's loss), while maximizing the worst local improvement across all tasks, provably converging to a local minimum of the average loss. This algorithm results in a generalization of the usual gradient descent, as well as the MGDA algorithm. Empirical results show the effectiveness of the method.","Authors propose a multitask learning approach to reduce gradient conflict by minimizing harm to the worst-performing task given any gradient update. Proofs are provided for convergence and pareto optimality of the resultant weight configuration. Experiments are run on a variety of settings, including computer vision and multitask reinforcement learning, with good results throughout. ",0.46296296296296297,0.2962962962962963,0.3148148148148148,0.16666666666666666,0.10380622837370242,0.1384083044982699,0.0657439446366782,0.27380952380952384,0.13095238095238096,0.07741935483870968,0.08650519031141868,0.19047619047619047,0.10967741935483871,0.16666666666666666,0.35714285714285715,0.25806451612903225,0.35185185185185186,0.14838709677419354,0.2037037037037037,0.2222222222222222,0.14577259475218657,0.2318840579710145,0.16267942583732056,0.16666666666666666,0.16085790884718498,0.1801801801801802,0.1107871720116618,0.1924686192468619,0.15942028985507245,0.11483253588516748
77,SP:c5a5bf6e0bdebf5170c8fe3fedd2f3438e39cd21,"This paper proposes to do community detection in a variant of the stochastic block model for which nodes arrive in a streaming fashion, and there may exists noisy estimates of the real labels. They prove that if the noise render the side information uninformative, a local streaming algorithm is equivalent to a local algorithm, which cannot achieve non-trivial accuracy. If the side information is informative, they provide a belief propagation algorithm in the streaming setting which achieves comparable accuracy to offline BP asymptotically. Offline BP has been conjectured to be optimal, so their algorithm would also be optimal if the conjecture is proven (it is in special cases). They also provide another algorithm which is in practice more consistent than StreamBP.",A streaming Stochastic Block Model (SBM) is proposed as null model to analyze streaming community detection algorithms on growing graphs. A online algorithm based on Belief Propagation (BP) is proposed to estimate community membership in this setting. It is proven to achieve the same accuracy as its offline variant BP in a simplified setting. ,"This paper tackles a streaming version of community detection, where the vertices of a graph generated with the classical stochastic block model are revealed sequentially, in a random order.  The authors restrict themselves to what they call $R$-local algorithms, wherein the new information brought by the arrival of a vertex is only propagated at distance at most $R$ of this revealed vertex.  In the absence of side information (i.e. additional information correlated with the ground truth community of each vertex), they show that this class of algorithms is unable to yield meaningful reconstruction when $n$ goes to infinity. In contrast, when side information is present, they provide an algorithm (StreamBP) for community detection, and show that this algorithm matches the performance of the classical belief propagation algorithm (OfflineBP) on the whole graph.   Those results are complemented by experiments on both synthetic and real-world datasets, comparing the StreamBP and OfflineBP algorithms, as well as several alternatives : simple voting algorithms, and a modified version of StreamBP (StreamBP*), modified to better deal with real-world datasets while enjoying the same theoretical guarantees as the original algorithm.","This paper studies a dynamic version of the stochastic block model, named as streaming stochastic block model (StSBM). The authors consider a sparse regime and analyze the asymptotic behavior of the model. In particular, the authors show that without some side information about the node labels, recovery of the true labels through a R-local streaming algorithm is no better than random guessing (Corollary 1). The authors also propose a streaming R-local belief propagation algorithm (StreamBP), and show their streaming algorithm perform as good as the offline version algorithm (Theorem 2). Empirical evaluations using synthetic and real-world datasets are provided in the paper.","The paper considers the problem of recovering the communities in a streaming version of stochastic block models, using information within a bounded radius. The main technical results are the limits of recovery with no side information, and a streaming version of belief propagation which has the same reconstruction accuracy as the offline BP algorithm using side information. The algorithms are evaluated on synthetic and real networks, and show good performance.",0.13114754098360656,0.2540983606557377,0.2459016393442623,0.1721311475409836,0.2962962962962963,0.25925925925925924,0.24074074074074073,0.1827956989247312,0.13978494623655913,0.21904761904761905,0.2962962962962963,0.16666666666666666,0.2857142857142857,0.3,0.08602150537634409,0.13333333333333333,0.18571428571428572,0.3238095238095238,0.37142857142857144,0.32857142857142857,0.18181818181818182,0.20129870129870128,0.2643171806167401,0.21874999999999997,0.13333333333333333,0.1761006289308176,0.20967741935483872,0.23367697594501718,0.203125,0.2628571428571428
78,SP:c857ff674ca05c1d949337cb885f056b82d981d6,"The authors present deep Markov factor analysis (DMFA) to capture temporal dynamics in functional magnetic resonance imaging data. The method chosen by the authors is relevant since existing methods overlook the highly nonlinear and complex temporal dynamics of neural processes when factorizing their imaging data. The authors claim that their method (DMFA) is able to cluster fMRI data in its low dimensional temporal embedding, which enables validation of fMRI related hypotheses.","The paper presents a deep Markov factor analysis (DMFA), which is a generative model that employs Markov property in a chain of low dimensional temporal embeddings as well as spatial inductive assumptions in order to capture temporal dynamics in functional magnetic resonance imaging (fMRI). The paper shows that DMFA has capability to cluster fMRI data in its low temporal embedding in regards to subject and cognitive state variability. The advantages of DMFA are demonstrated both through synthetic and application data.","The paper Deep Markov Factor Analysis (DMFA): Towards Concurrent Temporal and Spatial Analysis of fMRI Data proposes a scalable approach to factorize the data of each subject into a product of a small number of spatial and temporal components. Following on the work of (Manning et al., Topographic Factor Analysis, Plos ONE 2014) on topographical factor analysis, each spatial component is given by a radial basis function. The temporal components are modeled from a set of latent satisfying the Markov property. The first latent is conditioned on the data class giving to the model clustering capabilities. Variational inference is used to derive a lower bound of the log-likelihood which is then optimized via stochastic gradient descent. In a first experiment on resting state data (Autism dataset), DMFA is used to obtain subject specific atlases that allow to seggregate ASD and control subjects with an accutacy of 60 % (it is definitely hard to read). On a second experiment (Depression dataset), MDD and controls are exposed to different musical stimuli and DMFA is able to seggregate well the data of different subjects without supervision. In some extend it gives some hint about the kind of stimuli and the conditions of the subjects but results are not so convincing (the authors are honest about this).  In a third experiment they show that DMFA gives better results than other methods in terms of held-out log-likelihood and prediction of the next time point given the history. The code for DMFA is available. Pre-trained model are given and the code to generate the figures from pre-trained model works. ","This paper introduces Deep Markov Factor Analysis (DMFA). DMFA can model spatiotemporal BOLD fMRI time series by using time-varying latent factors that govern time-varying spatial maps consisting of spatial mixtures of RBFs. Latent time series are associated to a categorical clustering variable in order to enable grouping. Certain links in the Bayesian diagram are modeled using deep neural networks. Optimization is done by a variational approach. Experiments are performed on a simulated data set with known ground truth, the ABIDE autism data set, and a Depression study data set. Some clustering of relevant clinical outcomes is observed.   ",The paper proposes deep Markov factor analysis (DMFA) that uses the Markov process to capture the temporal dynamics in the fMRI dataset and maps the high spatial dimensions to a low-dimensional feature space. DMFA can cluster fMRI responses into “low dimensional temporal embedding” based on subject or cognitive state. The empirical studies on synthetic and real fMRI datasets illustrate that DMFA generates better performance in comparison with state-of-the-art techniques --- such as NTFA and HTFA.,0.39436619718309857,0.3380281690140845,0.18309859154929578,0.30985915492957744,0.325,0.2375,0.35,0.10486891385767791,0.09737827715355805,0.16161616161616163,0.35,0.0898876404494382,0.13131313131313133,0.28205128205128205,0.09737827715355805,0.1919191919191919,0.358974358974359,0.2828282828282828,0.3333333333333333,0.20512820512820512,0.37086092715231783,0.14201183431952663,0.15294117647058825,0.2953020134228188,0.14985590778097985,0.2122905027932961,0.3544303797468355,0.15300546448087432,0.1507246376811594,0.18079096045197743
79,SP:d39075aff611dd54574e7ee1a1aeacce83fdf532,"This paper proposes a theoretical analysis of the generalization benefit obtained for some classes of problems which exhibit invariance with respect to a group action. Especially, the paper focuses on kernel ridge regression in the statistical model $Y = f^*(X) + \epsilon$ and shows that using orbit-averaging on the learnt model provide strictly positive benefit whenever $f^\star$ is invariant with respect to the group action used in avering. Some decomposition of the involved RKHSs in terms of invariance is provided, and the generalization benefit is characterized in terms of the number of samples and typical quantities related to the kernel. ","The paper aims at quantifying the possible benefits of incorporating invariances to kernel methods. The approach takes the hypothesis returned by kernel ridge regression and enforces invariance by orbit averaging relative to actions of a compact group, i.e., the test prediction at a point $x$ is the average of predictions over the orbit set $\\{ gx\ |\ g \in G \\}$, with $G$ denoting the group defining an invariance principle. The main contribution is a theoretical result showing that for target hypotheses which are G-invariant, i.e., $f(gx)=f(x)$ for all $g \in G$ and $x \in X$, the excess risk is strictly positive (relative to kernel ridge regression hypothesis) and the sample complexity when enforcing invariance can be much lower compared to pursuing standard kernel ridge regression learning (Theorem 5). The main idea is to observe that orbit averaging is a linear operator which defines a subspace of the original RKHS and by exploiting this orthogonal decomposition one gets a lower bound on the excess risk, similar to treatments in low-rank approximations via sub-space restricted inner products.","The authors present a theoretical generalization gap based on the invariance incorporated by the kernel. An orbit-averaged functional is defined with a set of invariant transformations G on data to produce an operator which maps a function to another function that averages the functions of the transformed data. The functional is used as the projection operator to produce the set of orthogonal functions to the invariant functions, and the generalization gap has been derived for kernel ridge regression using the effective dimensionality of those orthogonal functions. ","This paper proves a benefit, in terms of expected risk, of orbit-averaging the solution of kernel ridge regression (with respect to actions by a given compact group) compared to the original solution of kernel ridge regression. The extent of this benefit depends on the ""effective dimension"" of the space orthogonal to the space invariant to group action, as well as what the authors call ""differences in bias"". Finally, the authors demonstrate a simple example in which the input domain is the unit sphere in d-dimensions, and the kernel is linear. The contributions are entirely theoretical. ",This article extends to a kernel setting the idea of Elesedy and Zaidi to leverage a decomposition of L^2 into invariant and null-orbit subspaces. The authors claim to prove the benefit for generalisation of projecting the solution of KRR on the invariant subspace. The article mainly consists of the lemmas and proofs to reach the main theorem on generalisation bounds.,0.25742574257425743,0.19801980198019803,0.3069306930693069,0.19801980198019803,0.12154696132596685,0.15469613259668508,0.09944751381215469,0.22988505747126436,0.1724137931034483,0.18556701030927836,0.143646408839779,0.22988505747126436,0.31958762886597936,0.3225806451612903,0.25287356321839083,0.28865979381443296,0.2903225806451613,0.20618556701030927,0.24193548387096775,0.2903225806451613,0.18439716312056736,0.2127659574468085,0.3131313131313131,0.24539877300613497,0.16417910447761191,0.20143884892086328,0.14814814814814814,0.21739130434782608,0.20134228187919465,0.22641509433962267
80,SP:d39f1d77d9919f897ccf82958b71be8798523923,"This paper proposed a CATE estimation approach when the treatment variable $T$ is a graph. Under a separable assumption (A3) between confounders $X$ and the treatment $T$ in the outcome structural equation ($Y$), Robinson's decomposition of CATE for binary $T$ can be applied. The performance of the authors' proposal was evaluated in both synthetic experiments and real data analysis.","The paper considers the problem of estimating conditional average treatment effect when the treatment is a graph. The paper generalizes the Robinson decomposition, adapts the R-learner to this graph-treatment setting and introduces a two-stage algorithm. The performance of the proposed algorithm is compared to a few benchmarks through numerical experiments. ","This paper proposes graph intervention network (GIN) to estimate conditional average causal effects when treatments are graph-structured. GIN builds on an extension of traditional Robinson decomposition to arbitrary treatment types. In particular, GIN factorizes the outcome Y into an inner product of two terms $g(X)^\top h(T)$. During training, GIN first estimates a mean outcome model $m(X)$ and then estimate $g,h$ using the estimated $m(X)$ function. The method is evaluated on two datasets with synthetic outcome functions.","This paper studies the estimation of conditional average treatment effect (CATE) with multiple treatments that are graph structured. The proposed method extends the R-learner (Nie and Wager, 2020), which is designed for binary treatment, by learning a representation that reduces the dimension of the treatments. The representation is parametrized by a graph neural network that takes the graph structure into account. Unlike the standard R-learner that learns the nuisance components $E[Y|X]$ and $E[T|X]$ separately from the CATE, the proposed method only estimates $E[Y|X]$ separately while learns the representation $h(T)$, the propensity features $E[h(T)|X]$, and CATE jointly via gradient-based methods. ","The paper proposed a CATE estimation method for graph-structured treatment by Robinson Decomposition. It is an extension of Robinson Decomposition, and the experiment shows the effectiveness of GIN on two small world datasets. The writing is good, but some contents are missing, so that the paper is not that easy to read. My detailed comments and concerns are described in the following.",0.26666666666666666,0.25,0.26666666666666666,0.23333333333333334,0.24528301886792453,0.37735849056603776,0.22641509433962265,0.21686746987951808,0.1686746987951807,0.13392857142857142,0.3018867924528302,0.18072289156626506,0.14285714285714285,0.2222222222222222,0.1566265060240964,0.17857142857142858,0.19047619047619047,0.16071428571428573,0.2222222222222222,0.23809523809523808,0.2831858407079646,0.20979020979020976,0.18604651162790697,0.22764227642276422,0.1911764705882353,0.24242424242424243,0.2068965517241379,0.18461538461538463,0.1917808219178082,0.17142857142857143
81,SP:da92e936f88b3842ca82c2914413b129ca35890f,"The paper proposes an approach to generate rhythmic music from a human movement video. In detail, the model is three step process: 1) Video2Rhythm: Uses the patterns in the motion of human skeleton to detect a rhythm. 2) Rhytm2Drum: Convert the rhythmic patterns to drum beats and 3) Drum2Music: Use the drum beats to update the remi representation of another instrument (or multi-instrument song). These three steps are trained independently in a supervised learning paradigm. ","In this paper, the authors propose to generate music based on human motion videos. The authors propose the Video2Rhythm to capture the  rhythmic nature of free body movements. Then they use Rhythm2Drum module to generate drum. Finally, piano and guitar tracks are added to enrich the music through Drum2Music. Experiments show that they can generate plausible music that aligns with the videos.","The authors propose a RhythmicNet that can generate a musical soundtrack associating with human movements in a video. Unlike most existing works that aim to generate sync sounds of audio sources in videos, this work focuses on generating musical rhythm and beat along with visual motions. It mainly consists of three parts: Video2Rhythm, Rhythm2Drum, and Drum2Music. Experiments can validate that the proposed RhythmicNet can generate plausible soundtracks for different body movements.   ***Post-Rebuttal***  The rebuttal has successfully addressed my major concerns. Thus, I would like to keep my positive rating. The authors should revise the main paper by improving writing and adding new results and discussions provided in the rebuttal.","The paper proposes a new method to produce a rhythmic sound consisting of basic instruments such as (piano roll, guitar chords and drum beat) given an input video containing at least one human activity. The authors leverage the input human action dynamics first using a keypoint estimation network and their velocity features. The latter features as used consequently to produce a rhythmic pattern which is used to generate a sequence of drum beats. The aforementioned drum beat sequence is then used as an output or as conditioning to a late-stage generation of a piano roll or a sequence of guitar chords. The intermediate representations and the architecture choices are discussed for each staged of the process. The authors provide both qualitative and quantitative results (opinion scores, video examples) for showing the effectiveness of their proposed architecture.","The authors propose a method to generate musical soundtracks for silent videos of human activity. The method is named RhythmNet and is composed of three parts: Video2Rhythm, Rhythm2Drum, and Drum2Music. These three are sequential modules which take an input silent video and generate a musical soundtrack to accompany the video.  The Video2Rhythm component predicts musical beats given the video. It uses keypoints extracted from the video and encodes the rhythm as the beat and style. The Rhythm2Drum component uses the predicted rhythm and generates a drum pattern following the setup of GrooveVAE using a transformer-based encoder-decoder architecture followed by U-net for velocity and offset prediction. Finally, the Drum2Music component adds either piano or guitar accompaniment to the drum track to make a full musical soundtrack. Each of these individual components are independently trained. ",0.19736842105263158,0.18421052631578946,0.27631578947368424,0.3026315789473684,0.25806451612903225,0.25806451612903225,0.27419354838709675,0.17272727272727273,0.2,0.18248175182481752,0.24193548387096775,0.12727272727272726,0.15328467153284672,0.16911764705882354,0.14545454545454545,0.11678832116788321,0.125,0.1386861313868613,0.16176470588235295,0.18382352941176472,0.21739130434782608,0.15053763440860213,0.1971830985915493,0.2169811320754717,0.18604651162790697,0.16080402010050251,0.1717171717171717,0.15384615384615385,0.17886178861788618,0.18315018315018314
82,SP:db15860d08418f6bc792c2ade2eade32840a12b8,"This paper considers two forms of curriculum design, unsupervised environment design and prioritized experience replay, and highlight their complementary nature. It then considers the games induced by both these approaches and combines them into a dual curriculum game where the agent faces one teacher or the other with certain probability. Further, the paper analyzes the equilibria of this joint game and the equilibria of the two component games.  The paper then proposes two new algorithms, a robust version of PLR that does not learn on experienced trajectories but only on trajectories sampled by the PLR teacher, and a replay-enhanced PAIRED that improves the UED technique with PLR.  The various approaches are then compared on mazes and car racing domains.","In this paper, the authors propose a common framework,  Dual Curriculum Design, that augments PAIRED with a PLR-based replay mechanism, named as REPAIRED. The theory also suggests convergence to Nash Equilibrium should be assisted by training on fewer data when using PLR—namely by only taking policy-gradient updates from data that originates from the PLR buffer, and only using samples from the environment distribution to populate the buffer. The authors further conducted experiments on a maze environment and on car-racing tracks. Results showed that the proposed approaches outperformed the PLR and other baselines in general.","This paper considers a recent proposed problem, unsupervised environment design, that provides an environment selection scheme to enable the policy being trained under a curriculum learning setting. The proposed method combines two new approaches in this direction, PAIRED and PLR, where the former one learns to generate an environment while the latter one does not include a generator but instead gives a sampling scheme to choose previously encountered environments. The combined method is explained as a two-teacher dual curriculum game and explained theoretically. Experiments demonstrate the effectiveness of the combined method compared to PAIRED and PLR, respectively.","This paper studies the problem of automatically designing a distribution of environments that adjusts to the learning agent, called unsupervised environment design. Specifically, they propose Dual Curriculum Design in which two co-evolving teachers, i.e. one is a generator and another one is a replay teacher, introduce new levels/environments to the learning agent (a.k.a student) to learn a policy that can be effectively generalized to new and unseen environments. Besides, this paper proposes a new theory about PLR and REPAIRED robustness guarantees. The paper evaluates zero-shot generalization, emergent complexity, and scalability of their proposed method in multiple environments and scenarios.","This paper proposes to theoretical analysis of the Prioritized Level Replay (PLR) from prior work and proposes an environment generation framework named Dual Curriculum Design (DCD). The proposed framework is composed of teacher agents that keep generating new environments and a student agent that learns to solve the generated environments. The teacher agents are co-adapted to generate new environments by maximizing the student's agent's regret. In a grid world domain and the CarRacing domain, the proposed method outperforms previous baselines such as PAIRD.",0.16666666666666666,0.2,0.15833333333333333,0.15833333333333333,0.1836734693877551,0.19387755102040816,0.19387755102040816,0.22448979591836735,0.20408163265306123,0.21904761904761905,0.20408163265306123,0.24489795918367346,0.18095238095238095,0.22093023255813954,0.1836734693877551,0.18095238095238095,0.22093023255813954,0.20952380952380953,0.23255813953488372,0.26744186046511625,0.18348623853211007,0.22018348623853212,0.16888888888888887,0.1844660194174757,0.18367346938775508,0.18719211822660095,0.20652173913043476,0.21674876847290642,0.21739130434782608,0.2408376963350785
83,SP:dcdb9c88f61ac3caf3da8255a7953c753cf048d1,This work propose a method for learning low-dimensional binary codes for instance and classes. It is appealing in classification with large scale number of classes. The method is claimed super-efficient in learning and able to ensure nearly optimal classification accuracy. The learnt class code discovers some intuitive taxonomy over subset of classes selected from ImageNet. The method is applicable in image retrieval and out-of-distribution detection.,"Low-dimensional binary codes are important for a variety of large-scale ml tasks, especially retrieval. This paper proposed a method called LLC for learning semantially meaningful low-dimensional biary codes. Compare to the existing literature, LLC can learn both class and instance codes together without side-information:  (1) couple the learning process of both feature and class embedding and capture the sematic structure better (2) naturally benefits downstream tasks like OOD.    ","This paper studies the problem of learning binary vector representations of instances and classes. We pick a small dimension k (the paper uses k=20) and aim to learn a k-dimensional binary vector for each input and each label. Compressing the data into small-dimensional binary codes like this is challenging, but provides many benefits in terms of the space usage (the representations are very small) and the time to do lookups and find nearby neighbors.  The paper presents a new method called LLC which simultaneously finds codewords for both inputs and labels without using any side-information. They claim (and I have no reason to doubt this) that this is the first time a method for this has been designed. LLC consists of two phases:  In the first phase, the LLC method learns a codebook (low-dimensional bianry code for each label) by using the popular Straight-Through Estimator technique to do empirical risk minimization.   In the second phase, the ECOC framework is used to classify the inputs according to this codebook. The algorithm treats each of the k bits of the code completely separately, and hence solves k disjoint binary classification problems instead of one multi-class (with L or 2^k classes) problem. This gives an additive 2% improvement to accuracy over just solving the optimization problem to classify all k bits together, since out of the box optimization finds fairly suboptimal solutions when trying to classify a length k vector all at once. (In other words, the second phase uses a heuristic where sepaartely learning each of the k bits works better than learning all k at once for the current optimization software which is well-suited to doing binary classification.)  The resulting classification accuracy seems quite good: 68.82% of inputs are assigned exactly the same binary code as their label, and 74.57% are assigned a binary code which is closer to the code of their label than any other label.  The result of this binary code classification can now be used in a number of applications, including: - the binary codebook can be naturally used to make a taxonomy visualization for the labels.  - the system can be used for efficient (in terms of representation size and running time of retrieval) multi-class classification. - out-of-distribution detection can be done by seeing whether an input is mapped to the same codeword as any label. (I'm confused about how effective this can be when the original inputs are only correctly mapped to the codeword of their label 69% of the time.)","This work proposes a two-phase method for learning low-dimensional binary codes via the standard classification task without side-information. Specifically, binary codes for classes are learned via a surrogate classification task in the first phase. On top of that, instance codes are learned using the Error-Correcting Output Codes approach.","This paper gives a new empirical approach for learning schemes for compressing high-dimensional neural representations into binary codes over a small number of dimensions. Given labeled examples and a fixed neural architecture with d-dimensional output, they give a two-phase algorithm for learning weights for the network, a low-dimensional projector to a k-dimensional subspace of R^d, and a binary ""codebook"" matrix B(C) mapping the k-dimensional subspace to R^L, where L is the number of classes. The goal is to do this for k as close to log_2(L) as possible while mostly preserving test accuracy.  Concretely, the embedding g maps any input x to the Boolean vector given by the entrywise sign of the k-dimensional projection of the network's output under x, and B(C) maps any such g(x) to an L-dimensional vector corresponding to the scores of the different classes. In the first phase of the algorithm, they simply run ERM to simultaneously find some weights, projector, and codebook, using a standard heuristic to get around the fact that B(C) is discrete-valued. In the second phase, they train the weights and projector further by essentially encouraging the embedding to align with the codebook.   The distinguishing feature of this approach is that the codebook and embedding are learning in conjunction rather than separately. Empirically over ImageNet-1K, they found that under two natural decoding schemes, the resulting classifiers beat a number of baseline approaches that separately constructed a codebook and then learned an embedding. Additionally, the accuracy is only ~3% less than the standard ResNet50 baseline.  As other applications, they showed that for image retrieval, the learnt embedding can be used as a hash function, outperforming HashNet and GreedyHash. They also gave an application to out-of-distribution detection which is comparable to certain baselines but notably does not need samples from the out-of-distribution domain.",0.2028985507246377,0.42028985507246375,0.2463768115942029,0.43478260869565216,0.3055555555555556,0.20833333333333334,0.2777777777777778,0.04672897196261682,0.1705607476635514,0.40384615384615385,0.19444444444444445,0.06775700934579439,0.3269230769230769,0.09316770186335403,0.0514018691588785,0.28846153846153844,0.062111801242236024,0.38461538461538464,0.2267080745341615,0.06521739130434782,0.19858156028368795,0.11670020120724345,0.2809917355371901,0.15345268542199486,0.088,0.24193548387096772,0.10152284263959391,0.08333333333333333,0.19466666666666668,0.1122994652406417
84,SP:de2523a5fdebda3573f1063447a7818bf3ed6333,"As pointed out by the paper, threshold calibration is related with practical hospital scheduling problem, in which hospital needs to make the decision to acquire new patients based on predicted length-of-stay to the existing patients. The paper proposed an efficient and practical threshold calibration method, which calibrated the non-calibrated results based on CDF prediction, and is shown to have better calibration results as compared to average calibration and distribution calibration.  Additionally, the paper proposed an algorithm to do threshold calibration, and empirical results on real data sets shows reduced reliability gap and true decision loss. ","This paper considers the problem of calibrating the conditional CDFs from a regression model.    The authors propose a new definition of threshold calibration, which requires the conditional CDFs to have calibrated quantiles when these CDFs have a $\alpha$-quantile that are all on the same side regarding a given $y_0$ (either above or below).    The proposed definition is a stronger notion of quantile calibration in regression (called averaged calibration in this paper), and a weaker notion of distribution calibration in regression. To further justify the proposed definition, the authors consider measuring the so-called reliability gap, which is based on a given loss function and the corresponding decision rule. The authors then show that having threshold-calibrated results can ensure a 0 reliability gap. The necessity and sufficiency among different calibration definitions are later demonstrated.  On the method level, the proposed approach is hence to iteratively search for quantile levels and thresholds with large calibration errors and applies isotonic regression to calibrate the corresponding quantiles. The final calibrated model will include the uncalibrated models and a sequence of calibration maps.  Experiments are performed with real datasets with a cost-sensitive setup. The proposed method is compared with uncalibrated model, quantile calibrated model and distribution calibrated model.  ","This paper discusses calibrated regression from a decision-making perspective, by introducing the concept of 'threshold calibration'. The popular notion of calibrated regression, average calibration, is insufficient for decision-making. On the other hand, the notion of distribution calibration is sufficient for decision-making, but may be difficult to achieve. In practice, decisions based on regression predictions are often made on the basis of whether the prediction is smaller or larger than some threshold. Thus, a decision-oriented goal is to ensure calibration with respect to such a threshold, called threshold calibration. The paper proposes an algorithm to achieve threshold calibration. ","This paper focuses on the task of ""calibrating"" forecasts used in downstream decision-making tasks to ensure accurate estimation of the loss or ""cost"" of using each decision rule (i.e. the decision loss). The paper is specifically focused on forecasts of real-valued quantities (regression) and binary decisions (or actions) made by thresholding the forecast (for example, deciding whether to accept or reject a new patient based on the forecasted length of stay of a current patient being above or below some threshold).  In this setting, the paper shows that average calibration -- a common type of calibration -- does not ensure accurate estimation of the decision loss. The paper then introduces threshold calibration, proves that threshold-calibrated forecasts maximize the accuracy of decision loss estimates (and, moreover, that threshold-calibration is necessary and sufficient to maximize this accuracy), and provides an efficient algorithm to generate threshold-calibrated forecasts from a finite data sample. The paper validates the performance of their algorithm on real-world data (although with a synthetic downstream decision-making setup), and demonstrates more accurate decision loss estimates than those obtained by average and distribution calibration. The paper also derives the relationship between distribution, threshold, and average calibration in Proposition 1, which may be of independent interest.","This work applies the concept of calibrated regression into a decision making framework where the decision is confined to threshold decisions. The Bayes optimal decision w.r.t. the predicted distribution is derived, and the concept of threshold calibration is defined. Threshold calibration is a sufficient and necessary condition for the reliability gap to be 0, meaning the absolute difference between the predicted expected loss and the true expected loss is 0 for a given decision rule. Further, a simple algorithm is proposed which threshold recalibrates a distributional prediction. ",0.2653061224489796,0.25510204081632654,0.336734693877551,0.1836734693877551,0.1497584541062802,0.2222222222222222,0.13043478260869565,0.3069306930693069,0.25742574257425743,0.1339712918660287,0.12560386473429952,0.24752475247524752,0.15789473684210525,0.20224719101123595,0.3069306930693069,0.22009569377990432,0.30337078651685395,0.14832535885167464,0.29213483146067415,0.3146067415730337,0.17049180327868851,0.2512562814070352,0.21498371335504887,0.1925133689839572,0.20129870129870128,0.22115384615384615,0.18243243243243243,0.19999999999999998,0.27368421052631575,0.1879194630872483
85,SP:de4a0f5a464aa3311445cc25c4915cf0c4d975c3,"The paper proposes a new embedding model for multi-hop reasoning over knowledge graphs. The idea is to embed a complex query as n arc segments each on a 1-sphere. The paper designs several neural logic operators including the intersection, projection and complement operators. For union, the model uses the DNF technique to reorder the operators so that the union operators always appear in the last step. The authors evaluate the model on standard benchmarks and achieve better results than prior methods.   Overall the paper is clean and easy to follow. A general question I have is that the current modeling is to embed the query into several independent arc segments. Have you tried to embed the query into the surface (sphere cap) of a n-sphere?  ","The paper presents a novel geometric embeddings called cone embeddings for solving query answering. Query answering requires embeddings of queries that are represented using first order logic. This includes conjunction, disjunction, negation but excluding Universal Quantification. Given this as basis, the related work until now has focused on two different types of embeddings (1) Geometric; and (2) probabilistic query based model. The progression from Geometric based embeddings to probabilistic models was primarily due to the fact that geometric embeddings cannot handle negation.","The paper proposes a new framework for embedding first-order logic (FOL) queries over knowledge bases using region-based embeddings. The embedding space is a Cartesian product of 2D cones. Entities are embedded in the same space with 0-aperture cones (ray starting at origin).  - Authors provide the relevant foundation to cones in 2D space, the final Cartesian product space, and suggest parameterizations of projection, intersection, union, and complement operations. - The choice of using cones facilitates complement operation. - Authors demonstrate empirical improvements over past work in FOL query embedding. - While the proposed cone-based region embeddings allow for clear descriptions for intersection, union, and complement, the implementation does not strictly enforce these geometric concepts.","A recent line of knowledge graph (KG) query systems ""compiles"" the query into an embedded representation, which is interpreted as a geometric region and then used to find response entities whose embedding representations are contained within the region.  Query2box is an early example, where the regions are multidimensional boxes or rectangles.  To be useful, the regions have to be simple, closed under query operators, and capable of being characterized using a few parameters.  Union (disjunction) and negation have therefore created problem for boxes.  This paper replaces boxes with a Cartesian space of cones in 2d.  By restricting the family of permitted cones and disjunction to the last step of any query, the authors argue that their cone family is closed under query operators.  Experiments with benchmarks that have a good diversity of query graph structures show promising results. ","This paper represents a novel approach to learning embeddings for entities and relations from a knowledge base that are capable of directly encoding *reasoning* (i.e. FOL). The principal representation proposed for this representation is a *cone* (i.e. a set which is closed under multiplication by a positive scalar) which is motivated by the fact that cones are closed under intersection and complements. In practice, the authors use *sector cones*, which leads to some incongruity between the original motivation and the model in practice (eg. sector cones are not closed under intersection or union). Even so, the authors apply this embedding method to several standard logic embedding tasks and demonstrate significant performance improvements.",0.109375,0.171875,0.1875,0.15625,0.1951219512195122,0.18292682926829268,0.15853658536585366,0.18421052631578946,0.18421052631578946,0.15217391304347827,0.17073170731707318,0.19298245614035087,0.17391304347826086,0.17543859649122806,0.14035087719298245,0.10869565217391304,0.11403508771929824,0.15217391304347827,0.18421052631578946,0.18421052631578946,0.13333333333333333,0.18181818181818182,0.18045112781954886,0.1652892561983471,0.163265306122449,0.13636363636363638,0.1326530612244898,0.16666666666666666,0.18421052631578946,0.16666666666666666
86,SP:dfd740399e48b946f02efdec823b8975a900f6a3,"The paper studies the combinatorial multi-armed bandit (CMAB) problem in a setting where exactly solving the corresponding offline optimization problem is not feasible (due to its computational hardness) and the learning agent only has access to a greedy oracle which approximately solves the offline optimization problem. In this framework, the paper analyzes the behavior of a natural variant of the Thompson sampling algorithm called Combinatorial Thompson sampling (CTS). The paper first gives an algorithm-dependent and problem-dependent lower bound showing that CTS faces a fundamental limit, then provides an almost matching upper bound.","The paper studies the performance of Thompson-Sampling (TS) when applied to combinatorial multi-armed bandit (CMAB) problems with semi-bandit feedback. It is well known that the combinatorial TS (CTS) algorithm might suffer from linear regret when the combinatorial maximization is solved using an approximation oracle [30]. In this work, the authors apply CTS with a specific family of combinatorial maximization oracles – greedy oracles. They analyze the greedy regret of CTS (which compares the played actions to the greedy solution of the combinatorial problem) and derive regret upper bounds of $O(\log T/\Delta^2)$, where $\Delta$ is a suboptimality gap. They also provide a matching lower bound for CTS on a specific small-scale problem.","This paper studies a setting where Thompson Sampling with greedy approximation oracles is applied to combinatorial semi-bandit. The main contribution is to theoretically reveal how the suboptimality of greedy oracles can affect Thompson sampling in the worst case. Specifically, the greedy regret is shown to be lower bounded by $\Omega(\log T / \Delta^2)$. The authors also prove an almost matching upper bound.   --- After rebuttal ---  I appreciate the authors' kind response. Having read all the responses and review comments, I've found that the result is more significant than I thought. Therefore, I increased my score to 6.  ","The paper presents a TS algorithm that uses Greedy oracle to minimise the cumulative regret on combinatorial multi-armed bandit (CMAB) setting. beside presenting an upper bound, they have also established a lower bound (on the cumulative regret) for their approach. The paper discuss the intuition of behind the proof of their proposed analysis for upper bound assuming the ""Greedy"" step (Line 4 in  Algorithm 1) returns a unique solution, and then in section 6.2 it relaxes that assumption.  CMAB is a well-known framework in the MAB literature, that generalises probabilistic maximum coverage (PMC), online influence maximization (OIM), multiple-play MAB (MP-MAB), minimum spanning tree (MST) and many others. TS based regret-minimisation algorithms are very efficient for the family of single parameter reward distribution; there are recent studies that apply TS under the CMAB setup. Again, finding the optimal solution (in offline learning) for many problems (like PMC, OIM etc.) is NP-hard. On the other hand, Greedy oracle is a popular choice in various optimisation methods (including submodular maximisation).   Hence, the idea to attack the CMAB setup with TS using a Greedy oracle is very natural. ",The paper studies the combinatorial semi-bandit problem. It provides the first analysis of Thompson sampling (TS) with the greedy oracle. It shows instances that the TS with Gaussian priors suffers $\Omega(\log T / \Delta^2)$ regret from. It proposes a modified TS with Beta priors and shows that the proposed algorithm achieves $O(\log T / \Delta^2)$ regret for the instances. The proposed algorithm enjoys near-optimal regret for the multi-armed bandit problem.,0.2631578947368421,0.21052631578947367,0.23157894736842105,0.18947368421052632,0.2222222222222222,0.2222222222222222,0.19658119658119658,0.1919191919191919,0.20202020202020202,0.10471204188481675,0.21367521367521367,0.20202020202020202,0.11518324607329843,0.24,0.26262626262626265,0.13612565445026178,0.30666666666666664,0.09947643979057591,0.26666666666666666,0.26666666666666666,0.2358490566037736,0.20618556701030927,0.15384615384615385,0.21176470588235294,0.24074074074074076,0.1688311688311688,0.23958333333333334,0.1310344827586207,0.22988505747126434,0.15037593984962405
87,SP:e0aa68ab03a3ef396b0dc4be4190b328d72cfab0,This paper proposes NEO which extends Non-Equilibrium Importance Sampling (NEIS) to use discrete orbit and extra weights. The probability distribution and sampling process is derived based on the Jacobian determinant. This method could be applied to estimate the partition function and a biased estimation called self-normalized IS is proposed based on estimated partition function. This paper also derive upper bound for the bias and MSE. A damped Hamiltonian system is adopted to equip the original system with extra momentum and provide orbit trajectory for NEO. NEO is also combined to Sampling Importance Resampling to derive the NEO-MCMC procedure. The authors present reasonable experiments to evaluate their methods.,"The paper introduce two sampling approaches named NEO-IS and NEO-MCMC respectively. The former method aims to estimate normalizing constant for an unnormalized target distribution, and the latter method can be executed to do sampling from unnormalized distribution. Empirical experiments reveal impressive performance for both the approaches on Normalizing Constant Estimation and Sampling tasks.  Exact theoretical analysis, especially convergence guarantees are also given in this paper. ","The paper proposes a new family of importance samplers based on iterating an invertible map $T$ forwards and backwards, thus generating orbits that serve as importance samples after proper weighting. If normalized importance weights can be computed, the resulting IS estimate is unbiased. Also a self-normalized version is proposed, which is biased but still converges against the correct expectation for $N\to\infty$. Since the map $T$ is not assumed to leave the target invariant, the proposed algorithm is called non-equilibrium orbit importance sampling (NEO-IS).   The authors propose to use conformal Hamiltonian dynamics as a mapping (standard Hamilton dynamics based on the negative log target plus a friction term). The dissipative friction term allows the authors to control how exhaustively phase space is explored.  The second main contribution is an MCMC algorithm based on the ideas used in NEO-IS. NEO-MCMC applies iterative Sampling Importance Resampling (SIR) within the NEO-IS framework. NEO-MCMC jumps from one point on an orbit to a point on another orbit. Orbits are sampled according to their importance weight.  The algorithms are benchmarked on various targets (25 Gaussian mixture, Funnel) and applied to training a VAE.  ","Based on Non-Equilibrium IS (NEIS), the authors propose the new importance sampler NEO-IS. The main advantage of NEO-IS over NEIS seems to be that NEO-IS provides unbiased estimates of the normalization constant. They prove the unbiasedness and also propose an MCMC extension for sampling (which was not provided by NEIS). They empirically show that NEO-IS (and its MCMC variant) can be better that other recent methods for tasks of  (1) finding the marginal likelihood, (2) Sampling from posterior distribution, (3) Inpaiting. ","The paper puts forward a new family of algorithms, NEO, for computing normalizing constants and sampling from complex distributions. NEO-IS is an importance sampling estimator of the normalizing constant. NEO-MCMC combines NEO-IS unbiased estimator of the normalizing constant with iterated sampling- importance resampling methods.",0.12727272727272726,0.2727272727272727,0.14545454545454545,0.12727272727272726,0.22388059701492538,0.19402985074626866,0.1791044776119403,0.10714285714285714,0.09183673469387756,0.1744186046511628,0.208955223880597,0.15306122448979592,0.18604651162790697,0.2978723404255319,0.07653061224489796,0.1511627906976744,0.2553191489361702,0.2441860465116279,0.3829787234042553,0.3191489361702128,0.1581920903954802,0.19607843137254902,0.16326530612244897,0.17834394904458598,0.11406844106463879,0.16993464052287582,0.21052631578947364,0.14893617021276595,0.14814814814814814,0.22556390977443613
88,SP:e5323a171f40c109722a7ea0aebdcd53c151b72d,"This paper characterizes the offline policy evaluation (OPE) error with linear function approximation in the discounted reward setting. With certain assumptions, this paper proves that the error of Linear Direct OPE algorithm (which is equivalent to the limit of Fitted Q-Evaluation algorithm) converges to the expectation of the product of two residuals. As a corollary, when either the function class is closed or the density ratio is realizable, the asymptotic error is zero. In addition, in the same setting the paper upper bounds the OPE error for tile-coding estimator.  ","The paper consider off-policy evaluation using linear function approximation under unrealizability setting. Under such more relaxed assumption, they provide characterization of the linear direct method(DM) as an error governed by two approximation residual $\mathcal{R}_B$ and $\mathcal{R}_X$, $$     \hat{J}(\pi) - J(\pi) = \mathbb{E}[\mathcal{R}_B(s,a)\mathcal{R}_X(s,a)] + O(1/\sqrt{n}), $$ with $\mathcal{R}_B$ corresponding to Bellman residual and  $\mathcal{R}_X$ corresponding to residual of marginal density ratio. Leveraing this result, they establish a nonparametric tile-coding estimators  to solve the unrealizability though with a slower convergence.","They analyze the linear DM method in detail. They prove that the estimator has an error form, which is written as an inner product of two residual functions. One is associated with the misspecification of Q-functions. Another is related to the misspecification of W-functions.  ","In this paper, the authors analyze the off-policy evaluation error of a direct estimator with linear function approximation under unrealizability. In Theorem 6, they derive the closed form of the asymptotic bias term as the number of samples approaching \infty. Besides, in section 3.2, they study another method where the feature mappings can be selected adaptively and provide the convergence analysis for their estimation to ground-truth J(\pi).","This is a theoretical paper which addresses the RL off-policy evaluation with linear function approximation. It proves convergence results of linear function approximations and shows that the direct method (model the dynamics) is asymptotically equivalent to FQE (modeling the value function) and analyzes its convergence properties. Additionally, it proves consistency results for such methods under tile-coding, allowing for consistency (using non-parametric estimation) even under unrealizability of the linear approximators.",0.18681318681318682,0.16483516483516483,0.21978021978021978,0.23076923076923078,0.1188118811881188,0.16831683168316833,0.15841584158415842,0.2608695652173913,0.1956521739130435,0.2535211267605634,0.16831683168316833,0.32608695652173914,0.28169014084507044,0.2916666666666667,0.2608695652173913,0.23943661971830985,0.2222222222222222,0.16901408450704225,0.125,0.25,0.17708333333333334,0.21897810218978103,0.24691358024691362,0.25766871165644173,0.16326530612244897,0.19767441860465115,0.18497109826589594,0.20512820512820512,0.15254237288135594,0.2517482517482518
89,SP:e880db33ba8c305ef1808a02325e2d2b7da95e68,"The paper proposes a simple yet effective method of pretraining the feature encoder in TAL models. The motivation comes from the distribution-shift as well as the task-shift between the classical image-/action-classification pretraining and the TAL training. To make the encoder also adapt to the TAL task, the authors propose to unfreeze the encoder and pretrain under the TAL task. Due to GPU memory limit, the authors use spatially/temporally low fidelity data to pretrain the encoder. Experiments are conducted to verify the authors’ motivation and show the advantage of such a pretraining routine.","Updating after the rebuttal: The rebuttal well addressed some of my concerns. I would raise the rating to 6: Marginally above the acceptance threshold  ---  The paper presents a low-fidelity video encoder optimization approach to relieve the large memory constraints in the temporal action localization problem. The proposed approach is easy to implement and reasonable results have been obtained on ActivityNet and HACS datasets. However, the proposed approach is more like an engineering solution. The technical novelty of the proposed approach is limited. ","** Update 8/16/21 **   Thanks to the authors for their rebuttal in response to my questions/concerns. After reading the rebuttal and the other reviews, I am updating my score to 6, to better reflect the contributions made by the work.  **   The paper aims to tackle the hardware constraint for end-to-end optimization of both video encoding and TAL head models. Different from prior works that freeze the video encoding network when training the TAL head, the proposed method optimizes both of them jointly on low-resolution (spatially and temporally) video frames and then finetunes the TAL head on full-resolution videos. The main contribution of this paper is resolving the task discrepancy problem for the video encoder when training TAL models. Extensive experiments are conducted in the paper to compare the lofi setting with several state-of-the-arts, as well as similar models under different pretraining conditions. Results indicate the proposed method outperforms the baselines. ","In this paper, the authors propose a new method to allow video encoder optimization in training temporal action localization (TAL) models, which is often ignored by existing TAL methods due to GPU memory constraints. The proposed method LoFi reduces the demanding GPU memory requirement by using a lower temporal and/or spatial resolution in the mini-batch construction. The proposed LoFi technique has shown to help enhance the performance of off-the-shelf TAL models on ActivityNet and HACS-v1.1. Also, the performance improvement is universal across different types of video encoder.","Models for temporal action localization (TAL) in long, untrimmed video are typically trained in two stages, a video encoder pretrained on a auxiliary video clip classification dataset and then frozen, followed by a TAL head. End-to-end training of the encoder and TAL head is infeasible because the encoder activations for an entire, long video will not fit in GPU RAM. This paper proposes a solution: use the ideas of mulgrid training [51] to do end-to-end training of a lower resolution video encoder and TAL head. They explore strategies for cycling through regimes of lower spatial, temporal, and spatio-temporal resolution training, and demonstrate performance gains on the ActivityNet and HACS datasets, using a number of backbone networks and TAL heads.  ",0.16494845360824742,0.26804123711340205,0.20618556701030927,0.18556701030927836,0.27710843373493976,0.24096385542168675,0.18072289156626506,0.13291139240506328,0.1518987341772152,0.22580645161290322,0.1927710843373494,0.16455696202531644,0.21505376344086022,0.14516129032258066,0.14556962025316456,0.21505376344086022,0.12096774193548387,0.22580645161290322,0.1935483870967742,0.1693548387096774,0.17777777777777778,0.20392156862745098,0.2105263157894737,0.16289592760181,0.19087136929460582,0.22727272727272724,0.14492753623188404,0.16733067729083664,0.17021276595744683,0.1935483870967742
90,SP:eb86d33d5d47f1cfe2c66ca2c9f852229e32a32f,"Summary: This paper proposes a model-based method with an ensemble disagreement-based exploration bonus for learning universal goal-conditioned policies. The world model and policy learning methods are adapted from DREAMER. In addition to that, the paper first introduces an explorer to first explore the state with large uncertainties, and then train the achiever to reach the proposed goals. The use of the world model enables data-efficient learning and exploration. The paper makes solid experiments and evaluates their approach on various domains. The paper also discusses two different distance metrics for learning goal-conditioned policy on images.","This paper proposes a model based RL setting where an agent learns a task agnostic model, learns two policies to explore and reach input goal states (specified as images) respectively and is able to operate in a goal conditional mode during evaluation time.   The key thesis is to use the world model to incentivize the agent to explore the environment by maximizing expected information gain and reach input goal states by learning to reach states from its past experiences.   There have been other model free and model based approaches studying the same problem but the claim is that its the first to combine model based exploration and reachability on new benchmark environments. ","This paper proposes a method to learn goal-conditioned policies by combining ideas from goal-conditioned RL and model-based exploration. It operates by training an exploration policy within the model to maximize model disagreement (as proposed in previous works), as well as a goal-conditioned policy to reach states in the replay buffer. These are then both deployed to grow the replay buffer, and the process is repeated. The approach is evaluated on a newly-defined set of benchmark tasks based on the Deepmind Control suite, as well as simulated robotic manipulation. They report better performance compared to previous methods such as Skew-Fit, DIAYN and two others. They also investigate two different choices of distance functions for the goal-conditioned RL component, and show that the optimal one depends on the setting. ","This paper introduces a framework to train policies for visual goal oriented tasks. The framework comprises two policies, the first, an explorer, which is trained to seek out novel states (where novelty is defined as the level of agreement between an ensemble of future state predictors - an approximate measure of epistemic uncertainty), while the second, an achiever, is trained to reach these states. A model based approach to train the achiever, where the achiever is trained using trajectories generated by a learned dynamics model. The paper also introduces a new benchmark for testing goal oriented polices of this form, comprising a kitchen manipulation task, a block handling task, and a yoga task. ","This paper proposes to jointly train two agents in a differentiable world model: an *explorer* that is rewarded to explore uncertain states and an *achiever* whose task is to achieve a given goal state. After training, the *achiever* can be deployed as a goal-reaching policy without further tuning. Authors also spent time investigating how to design the loss function for the *achiever*. In the experiments, three new benchmarks are introduced and the proposed method is shown to outperform baselines. ",0.26262626262626265,0.29292929292929293,0.25252525252525254,0.20202020202020202,0.22321428571428573,0.1875,0.20535714285714285,0.16417910447761194,0.14925373134328357,0.19642857142857142,0.23214285714285715,0.21641791044776118,0.22321428571428573,0.25,0.1865671641791045,0.1875,0.2875,0.19642857142857142,0.25,0.275,0.24644549763033177,0.24892703862660942,0.23696682464454974,0.223463687150838,0.20325203252032523,0.1875,0.23958333333333331,0.17886178861788618,0.18691588785046728,0.22916666666666669
91,SP:ec12f0a05db75ac15ad22b34cdc2a0142bc2c72f,"This paper studies a problem called lattice partition recovery, where piecewise constant signals over a d-dimensional lattice are corrupted by noise and require to be recovered. A method called dyadic classification and regression tree (DCART) is studied. It is shown that DCART achieves one-sided consistency, but suffers from over-partitioning. To achieve partition recovery, this paper proposes an additional merging stage, where dyadic rectangles that are close are merged. This is shown to achieve partition recovery under mild conditions. A minimax lower bound is also given, and numerical experiments are shown to support the methodology.","This article investigates the problem of the recovery of constancy regions of a noisy high dimensional piecewise constant signal. The authors proposed to use the DCART estimator to build up a rectangular partition and proved a weak consistency result. Then, they proposed a two steps estimator based on an appropriate merging of the rectangles that DCART output. For this variant (DCARTAM), they proved consistency: the estimator converges to the ground truth partition in the sense of Hausdorff (after an appropriate normalization by the number of rectangles in the partitions).  Finally, DCART and DCARTAM were compared to the TV-based estimator empirically using two metrics. The first one is the Hausdorff distance between the estimator and the ground truth partition, and the second one is the difference between the cardinality of the estimator and the cardinality of the ground truth partition. Visually, DCARTAM seems to be superior to DCART. Moreover, DCARTAM seems to be superior to the TV-based estimator using the second distance, yet it does not show a systematic superiority if the first distance was used.","In this work the authors consider the problem of learning the partition of a piecewise constant signal supported on a $d$-dimensional lattice $\{1, \ldots, n\}^d$.  They assume access to a noisy signal $y = \theta^\ast + \epsilon$, where $\epsilon \sim \mathcal{N}(0, \sigma^2 I)$ is a Gaussian noise vector and $\theta^\ast$ is the true signal that is assumed to be piecewise constant over a rectangular partition of the latice.  The goal is to recover the underlying partition.  This work focuses on the performance of (variants of) the Dyadic CART (DCART) algorithm for the task of partition recovery.  Prior work [1] has shown that the DCART estimator achieves the optimal error for the task of recovering the true signal $\theta^\ast$.  The authors argue that the partition produced by the vanilla DCART algorithm may contain a large number of rectangles.  However, they show that inside each rectangle of the partition of the vanilla DCART, the signal is indeed almost constant.  The second result of this work proposes simple modifications for DCART so that the corresponding partition is close to the true underlying partition.  In particular they enforce a lower bound on the size of the rectangles of DCART and, at the end, merge cells that are close and have similar value.  They show that the modified DCART algorithm outputs a partition at distance roughly $\sigma^2 k^\ast \log(N) / \kappa^2$, where $N = n^d$ is the size of the grid, $\kappa$ is the minimum signal difference between contiguous cells of the true signal, and $k^\ast$ is the minimum number of dyadic cells required to create a partition consistent with the true signal.  The authors show a lower bound of $\sigma^2 \log(N)/\kappa^2$ for the error. Therefore, their upper and lower bounds differ by a factor of $k^\ast$.  Finally, the authors are able to remove the extraneous factor $k^\ast$ under the additional assumption that the underlying partition is not very dense, i.e., around every rectangle of the true underlying partition there are not many other rectangles.   [1]: Sabyasachi Chatterjee and Subhajit Goswami Adaptive estimation of multivariate piecewise polynomials and bounded variation functions by optimal decision trees","The authors consider the problem of recovering the partition underlying a piecewise constant function over a $d$-dimensional lattice, _i.e._, a signal with support $L_{d,n} = \lbrace 1, \dots, n\rbrace^d$. That is, we wish to recover the structure such that within each rectangular partition of the lattice, the function $\theta^* \in \mathbb{R}^{L_{d,n}}$ is piecewise constant, from noisy measurements ${y_i = \theta_{i}^* + \epsilon_i}$ for $i \in L_{d,n}$ where $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$ i.i.d. A straightforward formulation would be NP-hard, so they the consider the dyadic CART (DCART) algorithm, which simplifies the search space by restricting it to partitions that can be formed by repeated bisections of partitions, starting with a single partition containing all $N = n^d$ points in the lattice.  The authors provide a number of bounds of the form $\sigma^2 k_{\mathrm{dyad}}(\theta^*) \log(N) / \kappa^2$, where $\kappa$ is the minimum jump size (difference between signal in adjacent partitions) of $\theta^*$. First, they show that using DCART, the number of lattice points in recovered partitions where the true signal is not actually piecewise constant scales at most with the above expression (""one-sided consistency""). They then propose a two-step estimator that adds a step merging rectangles in recovered partitions whose measurements are ""close"" to each other, and show that under certain assumptions, the Hausdorff distance between the recovered (estimated) partition and the actual partition (accounting for the need to merge rectangles to assure definitional uniqueness) scales at most with the above expression. Finally, they provide a simple example to demonstrate an order-matching lower bound.","This paper considers a piecewise constant signal on a $d$-dimensional lattice. The observed signal is corrupted by additive Gaussian noise. The task is to recover the partition of the lattice such that the signal within a partition is constant. The paper proposes an algorithm that builds upon the scalable DCART algorithm.  The contributions of the paper are threefold:  (i)	The authors first analyze the performance of the vanilla DCART algorithm to recover the partitions. They prove the one-sided consistency of the vanilla DCART algorithm. One-sided consistency guarantees that the recovered partitions have large subsets which have constant signal, but a partition of the ground truth signal could potentially be over-partitioned by the DCART algorithm. They demonstrate by an example that it is indeed the case.  (ii)	In order to address the issue of over-partitioning, the authors propose a two-step algorithm where the first step is the vanilla DCART algorithm while restricting to partitions with size above a threshold. In the second step, the partitions which are close and whose signals have a small difference are merged. They prove that this estimator is consistent.  (iii)	They prove that the proposed 2 step estimator is minimax optimal if the number of partitions is constant. Finally, they demonstrate the efficacy of their algorithm by simulations. ",0.21649484536082475,0.38144329896907214,0.29896907216494845,0.3402061855670103,0.3220338983050847,0.24293785310734464,0.24858757062146894,0.22888283378746593,0.1989100817438692,0.20430107526881722,0.11864406779661017,0.1008174386920981,0.1039426523297491,0.15137614678899083,0.1553133514986376,0.15412186379928317,0.2018348623853211,0.3010752688172043,0.3348623853211009,0.26146788990825687,0.15328467153284672,0.15948275862068967,0.15425531914893617,0.20952380952380956,0.20955882352941174,0.1885964912280702,0.2227848101265823,0.26006191950464397,0.24957264957264952,0.2293762575452716
92,SP:ed67b2664359799a11cebb9eaba6da74ff1dd977,"The paper considers the conditions under which the solution to the classic, hard-margin SVM classifier collapses to the solution of the ordinary linear regression problem.  This is known as support vector proliferation and occurs when all training vectors for the SVM are support vectors.  SVP has been observed previously, and an upper bound placed on the dimension (relative to training set size) required to induce it given.  The paper further elaborates on these results, providing improved lower bounds on the dimension for which it occurs.  The transition region in which SVP occurs is characterised and it's width bounded.  Finally, the authors speculate as to the conditions required for SVP in the $\ell_1$ variant of the SVM, and show experimentally that SVP appears to require much higher dimension for this case.","This paper investigates the phenomenon of support vector proliferation (SVP), that is, when linear classification with minimum-$\ell_p$-norm hard-margin SVM and minimum-$\ell_p$-norm interpolation yield the same solution. A previous paper showed for $p=2$ that SVP occurs with high probability for certain distributions with (effective) input dimension $d = \Omega(n \log n)$, but not for $d = O(n)$. The authors close this gap by showing that SVP does not occur for $d = o(n \log n)$. The authors further specify a more precise bound for standard Gaussian inputs and provide empirical evidence showing similar behavior for other distributions. Finally, the authors present some other theoretical and empirical results to illuminate the behavior for different $p$.","This paper proves a super-linear lower bound on the dimension of support vector proliferation (SVP) when features are anisotropic subgaussians. The exact asymptotic threshold of the phase transition in the isotropic Gaussian distribution is also proved. Finally, this paper discussed the case of SVP phase transition for $\ell_1$-SVMs. The experiments on synthetic data sets are also conducted.","This manuscript investigates the phenomena of \emph{Support Vector proliferation} (SVP) [1,2], in which all points in the training set $x_{i}\in\mathbb{R}^{d}$, $i=1,\cdots, n$ become support vectors, i.e. satisfy $y_{i}\hat{w}^{\top}x_{i}=1$, where $\hat{w}\in\mathbb{R}^{d}$ is the SVM estimator and $y_{i}\in\{-1,1\}$ are the training labels. SVP implies that the SVM estimator coincides with interpolating least-norm linear regression, a fact which has been used in many recent works to study overparametrisation in generalised linear models. In particular, the authors focus in a data model defined by fixed labels $y_{i}$ and sub-Gaussian features $x_{i}$ with zero mean and diagonal covariance $\lambda_{k}$, $k=1, \cdots, d$ (i.e. the labels are independent of the features). The key results are:  - Different equivalent characterisations of SVP for generic $\ell_{p}$, $1< p< \infty$ norm SVM (proposition 1).   - Establishing a lower bound showing that one needs at least $d=n\log{n}$ for SVP to occur in the anisotropic model defined above and $\ell_{2}$-SVM  (Theorem 3). This result tightens the a previous bound from [2] (Theorem 1).  - Establishing a sharp transition at $d = 2n\log{n}$ for SVP in the particular case of isotropic Gaussian data $x_{i}\sim\mathcal{N}(0,I_{d})$, also for $\ell_{2}$-SVM (Theorem 4).  The authors also provide numerical simulations corroborating the theorems, and suggesting that their results apply beyond the theorem's assumptions. Finally, they also provide a conjecture for the equivalent result in the $\ell_1$-SVM case.   [1] Vidya Muthukumar, Adhyyan Narang, Vignesh Subramanian, Mikhail Belkin, Daniel Hsu, and Anant Sahai. *Classification vs regression in overparameterized regimes: Does the loss function matter?*, 2020.  [2]: Daniel Hsu, Vidya Muthukumar, and Ji Xu. *On the proliferation of support vectors in high dimensions*.  In Twenty-Fourth International Conference on Artificial Intelligence and Statistics, 391 2021.",This paper explores the generality of support vector proliferation and makes the following three contributions: (1) proving a super-linear lower bound on the dimension (in terms of sample size) required for support vector proliferation in independent feature models. (2) identifying a sharp phase transition in Gaussian feature models. (3) investigating `the phenomenon of support vector proliferation for $\ell_1$ variant of the SVM.,0.16541353383458646,0.14285714285714285,0.24812030075187969,0.18796992481203006,0.1322314049586777,0.2975206611570248,0.1322314049586777,0.4,0.4,0.08024691358024691,0.18181818181818182,0.31666666666666665,0.10185185185185185,0.390625,0.26666666666666666,0.1111111111111111,0.25,0.07407407407407407,0.375,0.40625,0.1732283464566929,0.19689119170984454,0.14442013129102843,0.25380710659898476,0.17679558011049726,0.16179775280898875,0.17297297297297298,0.125,0.38709677419354843,0.13402061855670103
93,SP:eeb2c3348de291c5eacac5d9de7b6b84ca030ad5,"Authors 1) provide a dataset of cryptic crosswords; 2) explore baselines performances on this dataset; 3) provide interesting insights on those performances and come up with a pretraining strategy that increases performances.  Briefly, cryptic crosswords are puzzles that require both mastering definitions and wordplay (i.e. reordering of letters, extracting letters, composing parts of several words to form a novel word, etc.) to be solved. Authors provide a large dataset of such puzzles (in english), that they introduce as a stepping stone to solve more complex real-life settings.  They show that carefully crafted non-neural baselines are not very good (either rule-based following previous work on this, or KNN) and that even T5 (state of the art text-to-text transformer pretrained on many tasks, such as translation, summarization, etc.) cannot be finetuned for optimal performances on this dataset. Worst, when considering adversarial splits, such that for instance all puzzles with answers starting with the same subword are found in the same split, T5 performances drop dramatically.  They hint at a solution for this problem via curriculum learning, and devise the following strategy: first pretrain T5 on a series of tasks resembling the final wordplays (e.g. unscrambling a word using its definition: ""etalp + flower part"" --> ""petal"") and only then finetune T5 on the actual cryptic crosswords dataset. T5 performances indeed increase, but authors note that they are far from human performances, or even acceptable performances for a machine. ","**What is the task?**  Cryptic crossword puzzles task  **What are the contributions of the paper?**  * Presented a dataset of cryptic crossword clues as a challenging new benchmark for NLP systems that seek to process compositional language in more creative, human-like ways.  * A novel curriculum approach, in which the model is first fine-tuned with related, synthetic tasks (e.g., an augmented word descrambling task) before tackling actual cryptic clues.  * Introduced a challenging word-initial disjoint data split to test composition and generalization and investigated model behavior by systematically perturbing the wordplay part of clues, showing that the model exhibits behavior partially consistent with human solving strategies. ","This paper describes a new corpus of cryptic crossword clues as a challenging NLP task.  Cryptic crossword clues are composed of a literal (synonym) clue and wordplay.  Cryptic wordplay has a conventionalized inventory of ways to clue an answer.  This is a compelling NLP challenge ``1) because it is hard and 2) because it requires a system to process both surface, syntactic and semantic content of the examples.  This is related to being able to understand statements like ""Al and Bob got married and bought a house together, but not in that order"".  The paper includes a curriculum training approach where a T5 model is presented with data to improve cryptic clue solving.","This paper presents a new dataset of cryptic crossword clues. The work presents an extensive evaluation study on this dataset with 3 non-neural baselines and one neural baseline, namely the T5 transformer-based model. The authors investigate as well a kind of pre-finetuning stage (a phase of finetuning before the final finetuning stage on the main dataset) as a way to improve the performance of the model on this task.  Contributions: New dataset of cryptic crossword clues that has the potential to foster more research on complex reasoning tasks  Strengths: - The writing is compelling and the paper is a very enjoyable read - The author do a detailed analysis to understand better the limitations and abilities of transformer-based models on the task, including interesting ways of looking at data splits - The authors investigate the use of a pre-finetuning stage as a way to improve the performance of the T5 model on the task - The evaluation is convincing with multiple baselines, non-neural and neural.  Weaknesses: Sometimes, the paper seemed to be a bit condensed ","The paper focuses on data and methods for studying compositional language through UK-style cryptic crossword puzzles. These puzzles contain a definition and a wordplay cipher which together read like fluent natural language. The output is a word or phrase related to the wordplay cipher for which the definition is a valid description. Expert humans typically use creativity and linguistic and world knowledge to solve this task. The paper makes two main contributions: (1) a new dataset of cryptic clues as a new benchmark for NLP systems that process compositional language, and (2) baselines and an improved curriculum learning approach in which the model is first fine-tuned on related tasks (e.g., unscrambling words). Their experiments suggest that there is significant room for improvement for future work on this new benchmark.",0.0995850622406639,0.0995850622406639,0.14937759336099585,0.11618257261410789,0.21495327102803738,0.22429906542056074,0.35514018691588783,0.2831858407079646,0.17699115044247787,0.14124293785310735,0.22429906542056074,0.21238938053097345,0.2033898305084746,0.21212121212121213,0.20353982300884957,0.13559322033898305,0.2878787878787879,0.1807909604519774,0.15151515151515152,0.1893939393939394,0.13793103448275862,0.13559322033898305,0.17224880382775118,0.15013404825737264,0.20909090909090908,0.16901408450704225,0.3179916317991632,0.2206896551724138,0.16326530612244897,0.16181229773462785
94,SP:eeb42a1e48857f976a647eb8d86d25c9012962d5,"This paper considers causal inference in the discrete case, where probability axioms can be represented with matrix equations. Specifically, the paper characterizes the relationships between certain graphically driven formulae and matrix multiplications. With such characterizations, the authors then broaden the spectrum of proxy variable-based identification conditions and further propose novel intermediary criteria based on the pseudoinverse of a matrix. ","This paper provides a graphical identification approach that combines both graphical and matrical approaches. In particular, they apply certain matrix chain-rule and inversion criteria, previously used in for example certain proxy-based approaches, to a matrix version of the C-factorization to arrive at a new causal effect identification algorithm. They show that their algorithm applies to cases that could not be identified with certain previous algorithms and thereby rendering them incomplete. ","This paper considers the causal effect identification problem, and proposes an approach making use of both graphical criteria and matrix equations. More precisely, the authors connect the graphical and matrical approaches by characterizing matrix equations of probability distributions driven by graphical constraints in a causal graph. Building on this new characterization, the authors generalize proxy-based criteria and devise novel intermediary pseudoinverse criteria so as to identify a causal effect by utilizing the general inverse of a matrix and diverse collection of distributions.","This paper presents a synthesis between literatures on using matrix equations to characterize causal effect identifiability, and using proxies/surrogates to obtain identifiability when the effect of interest is not identifiable using the canonical ID algorithm. The authors highlight examples of identifiability under the various identification paradigms. They then describe notation used for their synthesis and highlight how it applies to each of the known cases. The main results entail an algorithm for determining identification of a broad class of effects via the matrix equations paradigm. The authors show that some key existing results, which had been proven sound, are not complete and show that their approach, while not yet proven complete, generalizes the existing approaches for the literatures studied.",Two primary methods exist for graph based identification. The first relies only on the assumptions in the graph while the second exploits assumptions  between unobserved confounders and the observable variables via proxy variables. This paper develops a new approach by combining both these methods. The new approach thus developed is able to solve problems that are not solvable by any of the methods alone. ,0.16666666666666666,0.36666666666666664,0.25,0.15,0.2465753424657534,0.2328767123287671,0.136986301369863,0.20481927710843373,0.13253012048192772,0.1,0.136986301369863,0.26506024096385544,0.125,0.140625,0.21686746987951808,0.14166666666666666,0.15625,0.14166666666666666,0.171875,0.1875,0.15037593984962408,0.3076923076923077,0.16666666666666666,0.14516129032258063,0.23076923076923075,0.17616580310880828,0.145985401459854,0.16748768472906403,0.14965986394557826,0.13043478260869568
95,SP:ef342e3c6a16e898a49b700a9fd4f0ea6a069dcc,"This paper tackles the reinforcement learning problem in a multi-objective and online setting. Two different cases are considered: (i) when preferences over the multiple objectives are given at the start of each episode and (ii) when preferences are unknown and the environment needs to be explored in preparation for any arbitrary preferences. For both cases, the paper proposes optimal solutions (up to logarithmic factors, and a factor of $H$ in the second case).","This paper investigates multi-objective reinforcement learning (MORL) in the online setting and the so-called preference-free setting, where the preference vector is given by an adversary. It proposes a model-based algorithms for each setting under tabular episodic MDPs, respectively. Both algorithms are shown to attain nearly optimal regret or sample complexity bound.  "," This paper studies the multi-objective reinforcement learning (MORL) problem where the reward function is an inner product of two d-dimensional vectors, an objective vector and a preference vector. Two algorithms have been proposed for known and not known preference vectors. Both algorithms are proved to achieve sub-linear regrets.","This work studies the multi-objective RL (MORL) with unknown transition, where the reward function can be parameterized with d-dimensional preference vectors. In the beginning of each episode, an adversary selects the weight vector and reveals it to the learner, the learner then selects corresponding policy and suffers a regret comparing with the optimal policies with respect to the given preference vector.   Besides this online MORL setting, the authors further study a preference-free exploration (PFE) setting where the learner manually separates the learning and planning phases and her performance is measured by the number of samples that are required to ensure PAC-bound. Then, the authors introduce a lower bound for PFE, which shows there is only an H factor loose. ","The authors propose to study an multi-objective RL in an online, episodic and tabular setting. In each episode, there is an adversarial chosen weight vector $w^k$  revealed to the agent, whose aim is to achieve a sublinear-time regret compared to an oracle who uses the optimal policy every episode. The authors propose the MO-UCBVI algorithm, which incorporate the adversarial chosen weight vectors with the learning approach by the classical UCBVI. Then the authors harness their framework on a recent proposed reward-free exploration problem, and they show that their algorithm's performance is superior to the state-of-the-art.",0.17567567567567569,0.16216216216216217,0.22972972972972974,0.1891891891891892,0.32727272727272727,0.34545454545454546,0.2,0.43137254901960786,0.21568627450980393,0.23577235772357724,0.23636363636363636,0.23529411764705882,0.13821138211382114,0.1346153846153846,0.35294117647058826,0.15447154471544716,0.10576923076923077,0.17886178861788618,0.10576923076923077,0.27884615384615385,0.20155038759689925,0.19200000000000003,0.17258883248730966,0.15730337078651685,0.339622641509434,0.21348314606741575,0.13836477987421383,0.2528735632183908,0.14193548387096774,0.25550660792951546
96,SP:f2a77f93bdc0401bbd6162a16fba25b9f90530e2,"The authors study the problem of multi armed bandits with the goal of identifying the arm with smallest (i) CVaR (ii) VaR or (iii) conic combination of CVaR and mean. This problem has applications in finance and clinical trials and captures a notion of risk sensitivity towards undesirable outcomes. The authors show that in the parametric case where the arm reward distributions follow a canonical SPEF, the problem reduces to best arm identification.  The authors study the VaR problem without any assumptions on the distributions, and study the CVaR problem assuming that distributions satisfy bounded $(1+\epsilon)$ moments. The proposed algorithm projects the empirical distribution to the considered family of distributions and considers an exploratory transform that guides the arm sampling distribution. At each time the empirical reward distribution suggests an arm with empirical minimum CVaR - this is the null hypothesis which is tested against all alternatives using GLRT. The algorithm upon satisfying the termination condition outputs the arms with the empirical minimum CVaR.  The authors show that the proposed algorithm asymptotically achieves the optimal sample complexity as the error threshold $\delta \to 0$. The results are supported by numerical simulations demonstrating good performance on instances with Bernoulli arms. The performance of the algorithm hinges on the asymptotic convergence of the track-and-stop exploration protocol which is often fast even when the error parameter delta is moderate.","This paper addresses the multi-armed bandit best arm identification problem which aims to identify the arm with the minimum tail risk measured by VaR, CVaR, or a weighted sum of CVaR and the mean. It proposes an optimal $\delta$-correct algorithm that works with a mild restriction on the arm distributions for CVaR and works with any arm distributions for VaR. In particular, the paper develops a lower bound for the problem and shows that the proposed optimal $\delta$-correct algorithm has the sample complexity that matches the lower bound asymptotically (as $\delta \rightarrow 0$). Additionally, the paper also suggests a solution to control the trade-off between the time computational complexity and the sample complexity, which is useful in practical applications.","The paper studies the problem of identifying the arm with the minimum CVaR, VaR, or a conic combination of the mean and CVaR. It provides an \delta-correct algorithm that operates on possibly heavy-tailed arm distributions and matches the asymptotic lower bound on the expected number of samples needed as delta approaches 0. The paper also provides a result of separate interests, i.e., an anytime-valid confidence interval for CVaR estimation, which is tighter than truncation-based intervals (under certain conditions). Finally, the empirical studies show that the asymptotic sample complexity result of the proposed algorithm is indicative of its performance in practice. ",The paper studies the problem of identifying the arm with smallesst CVaR and VaR. The lower bound for the specific structured best-arm identification problem is studied. The paper also proposed an algorithm that achieves asymptotic optimality in sample size. ,"The paper considers best CVaR arm identification in a fixed confidence setting. They can also deal with conic combinations of mean and CVaR, as well as VaR based criteria.  Main contributions include a lower bound which involves optimization over reals, and an algorithm which is asymptotically optimal in terms of expected sample complexity.",0.16666666666666666,0.17105263157894737,0.10087719298245613,0.07017543859649122,0.3333333333333333,0.16260162601626016,0.13821138211382114,0.21904761904761905,0.1523809523809524,0.3,0.3089430894308943,0.37142857142857144,0.575,0.3018867924528302,0.3904761904761905,0.5,0.32075471698113206,0.575,0.3018867924528302,0.22641509433962265,0.21652421652421655,0.23423423423423423,0.17164179104477612,0.11387900355871886,0.3596491228070175,0.24539877300613497,0.19318181818181818,0.31724137931034485,0.20253164556962025,0.25806451612903225
97,SP:f3792f82b28727a7a198c6eac9511391d2045a5f,"This paper presents tight, instance dependent upper and lower bounds for certifiable zeroth-order Lipschitz function optimization. It was known from prior work that in 1-d, the optimal sample complexity is nearly proportional to the integral $\int_{\mathcal{X}} \frac{\mathrm{d} x}{\max (f) - f (x) + \epsilon}$.  This paper extends this result to dimension $d$, establishing that the DOO algorithm of Perevozchikov 1990 can be made certifiable, achieving the sample complexity $\int_{\mathcal{X}} \frac{\mathrm{d} x}{(\max (f) - f (x) + \epsilon)^d}$.  The sample complexity bound of this algorithm matches that derived by Bouttier et al (2020) for an algorithm of Piyavskii and Shubert. The bound in Bouttier et al, however is provided in terms of covering numbers of the ground set at different error scales.  The main contribution of this paper is to (i) show that the c.DOO algorithm runs in near linear time and (ii) a sample complexity bound with of the same order as that derived by Bouttier et al (ii) To relate this sample complexity bound to the quantity $\int_{\mathcal{X}} \frac{\mathrm{d} x}{(\max (f) - f (x) + \epsilon)^d}$ (iii) establish a lower bound for certifiable algorithms which matches the upper bound up to an order of $(c( 1 - \text{Lip} (f) / L ))^d$ where $L$ is a known upper bound on the Lipschitz constant of the true function.  The authors also complement these results with a sample complexity upper bound of a constant when $L = \text{Lip}(f)$ (i.e. the Lipschitz constant of the function is known) for $d \ge 2$, which surprisingly does not hold for the case of $d=1$.","The authors introduced the Certified DOO algorithm, which is a zero-order method, to find the maximal point of a Lipschitz function on a compact feasible set. The authors also provided the convergence rate of the Certified DOO algorithm and an instance-dependent lower bound for all certified algorithms. And the lower bound matches the upper bound op to a logarithm term. ","The paper studies the complexity of certifiable zeroth-order optimization of Lipschitz functions. Formally, given oracle access to evaluations of a $L$-Lipschitz function $f$ over a known compact domain $\mathcal{X}$ and an error parameter, $\epsilon > 0$, the goal is to find a point $\hat{x}$ satisfying $f (\hat{x}) \geq \max_x f (x) - \epsilon$ making as few oracle queries as possible. The paper characterizes the optimal oracle complexity of the problem in an instance dependent sense where the number of queries made to the oracle depend on the behavior of the particular function. Concretely, they show that the number of queries that necessarily must be made to the oracle is $\int_{\mathcal{X}} d \mathbf{x} / (\max(f) - f(\mathbf{x})  + \epsilon)^d$ up to constant factors depending (exponentially) on the dimension.","This paper studied the problem of zeroth-order Lipschitz optimization, and mainly showed that under mild geometric assumptions and a noise-free zeroth-order oracle, the sample complexity of finding the \varepsilon-optimal point for a function f is of the order $\int dx/(f(x^\star) - f(x) + \varepsilon)^d$ (up to logarithmic factors). More specifically, the main contributions are as follows:   1. The authors proposed a certified DOO algorithm which could provide an error certification at each step, and achieves a sample complexity provided by the sum of packing numbers S_C(f,\varepsilon), a quantity already proposed in Bouttier et al. (2020).   2. Under a mild geometric assumption, the quantity S_C(f,\varepsilon) is bounded by the integral from both above and below, thereby proving the upper bound.   3. For the instance-dependent lower bound, the authors used a simple perturbation idea to reduce to a proper packing number: if the packing number of some shell is too large, then there must be points not queried by the algorithm, and a local perturbation of the functions around the non-queried points made the certification break down. ","  In this paper, the authors consider the problem of finding global solutions   to a possibly non-convex optimization problem under possibly non-convex   constraints using only access to function values of the objective function.   In particular, they focus on certified algorithms, i.e., algorithm that   together with a solution they also output certificate of the optimality of the   solution.    Their main result is an instance optimal bound for any Lipschitz continuous   functions. In particular if f is a Lipschitz continuous function with unknown   Lipschitz constant that is less than L, then the number of zero-order queries   needed to find an $\epsilon$-approximate global optimum together with a   certificate of optimality is    $\sigma = \int_{\mathcal{X}} \frac{1}{(f(x^*) - f(x) + \epsilon)^d} dx$    where $f(x^*)$ is the value of the global optimum and d is the dimensionality   of the problem. The authors provide both an algorithm and a lower bound that   is equal to $\sigma$ up to dimension dependent constants. Surprisingly the fact   that the Lipschitz constant is not exactly known but only upper bounded is   crucial for the proof of the lower bound.",0.08695652173913043,0.17391304347826086,0.18115942028985507,0.17753623188405798,0.3225806451612903,0.3548387096774194,0.4032258064516129,0.23703703703703705,0.25925925925925924,0.22631578947368422,0.3870967741935484,0.35555555555555557,0.2631578947368421,0.2620320855614973,0.14814814814814814,0.11578947368421053,0.13368983957219252,0.16842105263157894,0.18716577540106952,0.22994652406417113,0.14201183431952663,0.23357664233576644,0.2145922746781116,0.21166306695464362,0.20304568527918782,0.1746031746031746,0.20080321285140565,0.19692307692307695,0.21739130434782608,0.22811671087533159
98,SP:f55160db59c6f3e85f6e1ea0ec32c1a0982fbc48,"This paper proposes a natural and simple (yet general) method for approximating the argmax distribution through optimizing a set of centroid points. It is also shown theoretically that under suitable assumptions such an approximation minimizes a bound based on the Wasserstein distance with the actual argmax distribution. Extensive experimentation is carried to support the usefulness of the method. The data include a toy dataset, a few shot learning task, a dialogue system task and a domain adaptation task.","The paper proposes a generic method for approximating the argmax distribution of a random function using optimized centroids without explicitly sampling from the argmax distribution. While the closest application for the method is in meta-learning and multi-task learning, the proposed method can find application as an alternative to bootstrap among other applications. In short, for a random function $f_\xi(\theta)$ (think of $\xi$ as data, $\theta$ as parameters, and $f_\xi(\theta)$ as the loss function), the method finds a set of parameters $\boldsymbol{\theta}:=\\{ \theta_i\\}_{i=1}^n$  such that it minimizes  $E_\{\xi\sim\pi\}\[ min_\{i\in\\{1,...,n\\}\} f_\xi(\theta_i)\]$. During inference and for a new task, the authors first find the appropriate parameters for the task (based on a validation set) from the set $\boldsymbol{\theta}$ and then use the corresponding model to solve the task. The method is shown to minimize a bound in Wasserstein distance between the approximated argmax distribution and the real distribution. Finally, the authors show the method's superior performance in various numerical experiments spanning few-shot supervised learning, personalized dialogue systems, and multi-target domain adaptation compared to various baselines. ",   This paper proposes optimizing centroid points to compactly approximate the argmax distribution with a simple objective function. The proposed method is theoretically minimizing a bound of Wasserstein distance between the empirical distribution of the centroids and the ground-truth distribution. Argmax centroids have many applications for machine learning tasks; the author validates the proposed method on multiple meta-learning and mult-task learning tasks.  ,"The paper proposed a method that optimizes a set of centroid points that approximates the argmax distribution p*. Rather than using the Monte Carlo sampling that draws samples randomly, their approach choose the location of each points that approximate target distribution p*.  This approach can be an alternative for bootstrap and can be applied to deep learning applications. The paper showed the effectiveness of the proposed method on few shot image classification, personalized dialogue systems and multi-target domain adaptation. The proposed algorithm boosts the SOTA performance for few-shot classification and meta learning tasks.  ","This paper proposes a method called Argmax Centroids for learning an approximation to the distribution of the minimizer of a random function. The central idea is to learn a set a particles such that the expected distance between the minimizer of a randomly drawn function and the closest particle is small. The method is shown to be connected theoretically to Wasserstein distance. Experiments on few-shot classification, personalized dialogue modeling, and multi-target domain adaptation demonstrate improvements when the technique is applied to baseline models.",0.4230769230769231,0.2692307692307692,0.2948717948717949,0.2948717948717949,0.1319796954314721,0.15736040609137056,0.20812182741116753,0.3125,0.328125,0.2631578947368421,0.16751269035532995,0.328125,0.24210526315789474,0.27058823529411763,0.40625,0.3263157894736842,0.4823529411764706,0.21052631578947367,0.24705882352941178,0.29411764705882354,0.24000000000000002,0.29577464788732394,0.2658959537572254,0.2822085889570552,0.1992337164750958,0.21232876712328766,0.29078014184397166,0.25157232704402516,0.28187919463087246,0.27777777777777773
99,SP:f6314bfd897cb996de2eaabf0d3037f41da467f3," The authors develop a fast conformal Bayesian computation approach.  The original conformal prediction method can be computationally intensive:  It often requires refitting the model for every augmented value y. The authors avoid this refitting step by using importance sampling. The authors also show the extension to conditionally exchangeable data, which is especially useful for hierarchical data. The resulted conformal interval has finite sample correct coverage and is immune to model misspecification or distribution assumptions.","This paper introduces Bayesian and importance sampling techniques into a previously known conformal prediction framework.  I had troubles identifying what exactly is the novel contribution of this paper. It could use a brief section stating ""our own contributions are A, B , C"". In my understanding the conformal prediction framework was known before and the novel items are using the Bayesian posterior predictive density as a conformity score and additionally estimating the predictive distribution given new data from a weighted importance sampling where the weights are just the likelihoods of the prameter draws based on the new data point.  There are modelling extensions from completely exchangeable models to partial exchangeability, i.e., where we have groups and complete exchangeability is still valid in the groups, but not outside the groups. From this flat hierarchical structure there is a further extension to hierarchical models that may model deeper hierarchies and via hyperpriors may share information between groups.  ","This article proposes a novel approach to constructing prediction intervals with approximately correct frequentist coverage, even on misspecified models.  The basic idea is to employ the conformal prediction technique using the Bayesian posterior predictive density as the conformity (goodness-of-fit) measure.  The main innovation of the article is to use an importance sampling approximation to the posterior predictive density at candidate values of outcome $y$.  This leads to a computationally fast and generally applicable algorithm for using samples from the standard Bayesian posterior to construct well-calibrated prediction intervals, even under misspecification of the Bayesian model.  An extension to hierachical models is also provided, and empirical results are presented demonstrating the performance of the method.","The authors present an approach to using a Bayesian model to provide predictive intervals with  frequentist coverage within the framework of conformal prediction.  This work generalizes existing Bayesian methods for conformal inference that apply only to conjugate models.  The authors provide a straightforward generalization of their approach to partially exchangeable data.  Empirical validation on several datasets, and comparison to a baseline approach is provided.","This paper proposes a scalable method for conformal Bayesian prediction, by estimating the modified posterior predictive density using ""add-one-in"" importance sampling.  On several tabular datasets with sparse and hierarchical models, estimation is shown to be efficient for non-extreme miscoverage levels, and the produced credible intervals have good coverage.  **Post-rebuttal update:** Thank you for the response.  I am keeping my score unchanged: on the plus side, the method is sensible and easy to implement; on the other hand, there are some (understandable) limitations when scaling to large datasets or applied on approximate posterior samples; and some reviewers raised questions about novelty, which I'm not most suited to judge, as I'm not an expert in this field.  In aggregate, the rating of ""marginally above the acceptance threshold"" still describes my opinions well.",0.22972972972972974,0.20270270270270271,0.20270270270270271,0.20270270270270271,0.18064516129032257,0.07741935483870968,0.14838709677419354,0.15517241379310345,0.1896551724137931,0.1875,0.10967741935483871,0.12931034482758622,0.234375,0.11029411764705882,0.2413793103448276,0.1875,0.16911764705882354,0.28125,0.16176470588235295,0.08823529411764706,0.148471615720524,0.15789473684210525,0.21739130434782608,0.14285714285714288,0.2066420664206642,0.10958904109589043,0.15807560137457044,0.2,0.1746031746031746,0.12
100,SP:f79e91e469a70b219cd4a2116d5f389842f265ec,"The paper is dedicated to the analysis of robust linear regression, where the proposed estimation is based on sparse M-estimation. The statistical criterion corresponds to a penalised M-estimation problem, where both the non-penalised loss function and penalty function are assumed convex. The contributions of the paper can be summarised as follows: - the authors provide a criterion for the optimal selection of the non-penalised loss and penalty function so that some out-of-sample distance, say D, is minimal.  - the authors quantify the behaviour of the penalised estimator \hat\beta using quantities depending on the observations only (idest no unknown quantities such as true sparse support) in a regime where p/n has finite limit. - some explicit derivative formulas of the penalised estimator are provided.  - the distribution of the estimated residuals is provided, which allows for a selection of the tuning parameter for regularization. - the authors derive an approximation formula of the distance D.  ","Finding the right parameter when doing robust estimation is a recurring problem in the robust community. This article propose to choose the parameters in a robust regularized linear regression model by minimizing a completely data-driven criterion. This criterion is shown to be a good approximation to the out of sample error, this is also illustrated on practical experiments.",This paper studies the derivatives of regularized M-estimators and distribution of the residual.  These results give rises to a new novel adaptive criterion for tuning loss and penalty function. Numerical experiments are conducted on various models to validate the theoretical result.,"This paper studies M-estimators in linear models, with convex and gradient-Lipschitz loss function and a convex penalty.   Main contributions:  1. The authors provide a criterion to select tuning parameters (the loss function and the penalty function) of M-estimators, such that minimizing the criterion provides a proxy for minimizing the out-of-sample error, since the criterion is an approximation of the out-of-sample error up to a constant shift. One advantage of this criterion is that it does not require the prior knowledge of the covariance matrix of the design and the noise distribution.  2. The authors provide simulation results that confirm theoretical findings.","The authors study M-estimators with convex penalties. They give algebraic forms for derivatives of the estimator with respect to response $y$ and the design matrix $X$. They describe the distribution of residuals or certain functions of residuals. Given a loss function and penalty (with tuning parameters) they propose a criterion that can effectively approximate the out-of-sample error. This criterion can be computed without the knowledge of the covariance matrix $\Sigma$ (rows of $X \sim N(0,\Sigma)$). They give finite sample bounds that show how fast the criterion converges to the out-of-sample error.   ",0.10828025477707007,0.10191082802547771,0.21019108280254778,0.1464968152866242,0.11864406779661017,0.2711864406779661,0.2711864406779661,0.40476190476190477,0.2857142857142857,0.26851851851851855,0.288135593220339,0.38095238095238093,0.3055555555555556,0.23469387755102042,0.16666666666666666,0.14814814814814814,0.16326530612244897,0.1574074074074074,0.12244897959183673,0.29591836734693877,0.1574074074074074,0.16080402010050254,0.24905660377358496,0.1803921568627451,0.1386138613861386,0.19161676646706585,0.2038216560509554,0.22666666666666666,0.1714285714285714,0.2815533980582524
101,SP:f8ca9d92c45adc4512381035856b445029e3080a," The paper proposes STEM for federated learning under *sample gradient smoothness condition*. By using momentum-based techniques, the proposed STEM algorithm achieves the optimal sample complexity of $O(\epsilon^{-3/2})$ and communication complexity of $O(\epsilon^{-1})$ for non-convex functions. The paper also shows how to balance the batch size and the number of local steps. ","Authors propose Stochastic Two-Sided Momentum algorithm, that utilizes certain momentum-assisted stochastic gradient directions for both the WNs and SN updates. Authors show that this method achieves near optimal sample complexity $\tilde{\mathcal{O}}\left(\epsilon^{-3 / 2}\right)$ and $\tilde{\mathcal{O}}\left(\epsilon^{-1}\right)$ communication complexity.  Also, authors provide interesting observations about trade-off between the minibatch sizes and the local update frequency.    ",This paper introduced a two-step momentum method for federated learning. The proposed method achieves the best achievable sample and communication complexities for first-order stochastic FL algorithms. The theoretical analysis provides guidance on selecting synchronization interval and batch size for achieving the nearly optimal complexities.,"The authors presented a momentum extension of the classic FedAvg method for non-convex federated learning, along with a unified framework for convergence analysis. The core result shows that the proposed method can achieve near-tight sample and communication complexities under mild conditions, whilst also revealing a trade-off between local update frequencies and local minibatch sizes. The actual performance of the proposed method was evaluated in CIFAR-10 and MNIST image classification tasks.","The paper proposes a new method to solve the finite sum problem in federated learning where each local model is an expectation function. The STEM algorithm uses momentum variance-reduced estimator in local updates (similar to STORM estimator in stochastic optimization) and also send these estimators to the server when performing server-side update. Therefore, STEM includes momentum updates for both local and server updates. Convergence analysis reveals that STEM nearly match the best known sample complexity in centralized setting and it also matches the lower bound communication complexity up to a log factor. Numerical experiments on neural network training not only show advantage of STEM compared with FedAvg and SCAFFOLD but also presenting the tradeoff between communication frequency and minibatch size.",0.3275862068965517,0.27586206896551724,0.22413793103448276,0.3103448275862069,0.1791044776119403,0.2537313432835821,0.23880597014925373,0.32608695652173914,0.30434782608695654,0.22972972972972974,0.2835820895522388,0.34782608695652173,0.17567567567567569,0.14754098360655737,0.2608695652173913,0.22972972972972974,0.13114754098360656,0.20270270270270271,0.11475409836065574,0.13934426229508196,0.304,0.3076923076923077,0.196969696969697,0.2,0.21238938053097345,0.24113475177304963,0.1693121693121693,0.25,0.16666666666666669,0.17346938775510204
102,SP:fe9c80cc5615705ef844d59b56413779c8d54a06,"This paper proposes an algorithm called SNIPS that solves noisy linear inverse problems via an approximate MMSE estimator which makes use of pre-trained Gaussian denoisers. The estimator is based on MCMC sampling which is driven by a synthetically annealed version of Langevin dynamics. The motivations and background leading up to the algorithms derivation are well discussed. Experiments show interesting results with regard to the diversity and faithfulness of the images generated.   ---Edit after author responses---  Having read the other reviews and the responses posted by the authors, I am reducing my original scores from 6 --> 4.  My main issues are that the submission lacks (i) a comparison with an experimental baseline, and (ii) clarity in explaining the technical sections of the paper.","The authors address the problem of conditional sampling using Langevin dynamics. It is known that annealed Langevin dynamics speeds up convergence, and prior work that uses Langevin dynamics for conditional sampling does not correctly model the effects of annealing. Specifically, since there is some annealing noise added to the estimate, the likelihood distribution of the measurements given an estimate will change, and the authors derive approximations to the correct functional form. Experiments show that their new estimator can be implemented in practice. ","This paper proposes a technique based on annealed Langevin dynamics to solve noisy linear inverse problems. The technique is built on top of [18, 19] and proposes to perform the Langevin dynamics in the spectral space of the linear degradation operator $H$. To improve the performance of the proposed method, the authors use coordinate wise step sizes obtained by approximating the hessian with its diagonal. Qualitative results from the proposed method are presented for compress sensing, inpainting, super-résolution and deblurring.","The paper describes an apparently new approach to solving noisy inverse problems.  It shows how the approach can be applied to three different noisy inverse problems: which it calls image deblurring, super-resolution, and compressive sensing.   It validates the approach on synthetic data which is synthesized (eg blurred and noise added) starting from publicly available imagery.  It is carefully written and I find it readable.","This manuscript describes a novel method for sampling from the posterior in a linear inverse problem subjected to noise for an arbitrary measurement matrix. This is achieved by combining a black-box prior (such as that derived from a minimum MSE Gaussian denoiser) whose score function is easily computable with an annealed Langevin dynamics framework. The novelty is the construction of the Langevin noise term, which guarantees that the conditional score function is tractable. In addition, the authors propose a heuristic for step size calculation inspired by Newton's method in optimization. The method is evaluated on a variety of linear inverse problems: image deblurring, super resolution, and compressive sensing. For each task, realistic results are achieved and the residual is shown to conform to the imposed statistical model. ",0.13821138211382114,0.2032520325203252,0.10569105691056911,0.17886178861788618,0.18292682926829268,0.10975609756097561,0.2073170731707317,0.12195121951219512,0.23170731707317074,0.2153846153846154,0.2073170731707317,0.3048780487804878,0.2,0.17054263565891473,0.18292682926829268,0.13846153846153847,0.13178294573643412,0.15384615384615385,0.14728682170542637,0.10852713178294573,0.16585365853658537,0.24390243902439027,0.13829787234042554,0.1746031746031746,0.18292682926829268,0.12244897959183675,0.16113744075829387,0.1360544217687075,0.18009478672985782,0.1443298969072165
103,SP:ff1b7a7a6295e8f40f3b5df5f6950ca9d33603e0,"This paper studies the effect of prior misspecification in Thompson sampling (TS) and related posterior sampling bandit algorithms. They are able to show that the regret due to such algorithms using a misspecified prior incurs additional regret that is linear in the total variation distance between the improper and true prior.  Additionally, the paper considers estimating such priors in a meta-learning setting, where an agent interacts sequentially with multiple bandit instances whose model parameters are sampled from the same unknown prior. The authors provide bounds on the total variation distance for the estimated priors when the prior is Beta or Gaussian. ","The paper establishes the theory for quantifying the sensitivity of a class of Bayesian bandit algorithms under misspecified prior, with Thompson sampling being a special case. It is also shown that the sensitivity bound is tight in the worst-case sense. Using the sensitivity analysis, the paper studies the sample complexity of Bayesian meta-learning in two special cases (Beta prior+Bernoulli reward and Gaussian prior+Gaussian reward). Finally, the aforementioned theory is generalized to the more general setting, the Bayesian POMDPs.  ","In this paper, the authors study how prior mis-specification would impact the performance of bayesian bandit algorithms. In particular, the authors provide an upper and a lower bound for a wide class of algorithms, which include Thompson sampling algorithms as a special case. The results are complemented by applications in meta learning and numerical experiments.","This paper focus on the performance of the Thompson sampling algorithm under the misspecification of the prior distribution. The authors propose a general family of n-Monte Carlo algorithm, which contains the canonical TS algorithm as a special case. The authors then proceed to show that the regret difference of a misspecified prior up to horizon H of an n-MC algorithm is of order H^2*eps, where eps is the amount of misspecification measured by the total variation distance. The results are applied to the meta-learning setting, in which one also aims to learn the prior. The paper concludes by a synthetic numerical experiment to show the benefit of meta-learning.","This article presents some very nice results on posterior-sampling-based bandit algorithms with mis-specified priors. The algorithms are those like Thompson sampling, in which the actions selected are functions of draws from the posterior distribution to date (an approximation of knowledge gradient is also analysed as part of a wider class of posterior-sample-based decision algorithms, and this is shown to be an improvement on TS). Results apply both to standard bandit settings and to meta-learning settings in which a series of short episodes are attempted. Theory and experiments are impressive.",0.19607843137254902,0.12745098039215685,0.28431372549019607,0.13725490196078433,0.21951219512195122,0.2804878048780488,0.17073170731707318,0.35714285714285715,0.2857142857142857,0.20175438596491227,0.24390243902439024,0.23214285714285715,0.2543859649122807,0.14736842105263157,0.32142857142857145,0.20175438596491227,0.14736842105263157,0.17543859649122806,0.16842105263157894,0.24210526315789474,0.21739130434782608,0.16455696202531644,0.26851851851851855,0.14213197969543148,0.2608695652173913,0.23469387755102042,0.15819209039548024,0.23529411764705885,0.2119205298013245,0.22009569377990432
