,paper_id,summary,summary,precision,recall,fmeasure
,,0,1,0-1,0-1,0-1
0,SP:017b66d6262427cca551ef50006784498ffc741d,"This paper presents CoDraw, a grounded and goal-driven dialogue environment for collaborative drawing. The authors argue convincingly that an interactive and grounded evaluation environment helps us better measure how well NLG/NLU agents actually understand and use their language — rather than evaluating against arbitrary ground-truth examples of what humans say, we can evaluate the objective end-to-end performance of a system in a well-specified nonlinguistic task. They collect a novel dataset in this grounded and goal-driven communication paradigm, define a success metric for the collaborative drawing task, and present models for maximizing that metric.","In this paper a new task namely CoDraw is introduced. In CoDraw, there is a teller who describes a scene and a drawer who tries to select clip art component and place them on a canvas to draw the description. The drawing environment contains simple objects and a fixed background scene all in cartoon style. The describing language thus does not have sophisticated components and phrases. A metric based on the presence of the components in the original image and the generated image is coined to compute similarity which is used in learning and evaluation.  Authors mention that in order to gain better performance they needed to train the teller and drawer separately on disjoint subsets of the training data which they call it a cross talk.",0.16161616161616163,0.12598425196850394,0.14159292035398227
1,SP:034c3bc2b2fe4991f56f168ea7b4b552c500b9ad,"It was believed that sparse architectures generated by pruning are difficult to train from scratch. The authors show that there exist sparse subnetworks that can be trained from scratch with good generalization performance. To explain the difficulty of training pruned networks from scratch or why training needs the overparameterized networks that make pruning necessary,  the authors propose a lottery ticket hypothesis: unpruned, randomly initialized NNs contain subnetworks that can be trained from scratch with similar generalization accuracy.  They also present an algorithm to identify the winning tickets.","It is widely known that large neural networks can typically be compressed into smaller networks that perform as well as the original network while directly training small networks can be complicated. This paper proposes a conjecture to explain this phenomenon that the authors call “The Lottery Ticket Hypothesis”:  large networks that can be trained successfully contain at initialization time small sub-networks — which are defined by both connectivity and the initial weights that the authors call “winning tickets” — that if trained separately for similar number of iterations could reach the same performance as the large network. The paper follows by proposing a method to find these winning tickets by pruning methods, which are typically used for compressing networks, and then proceed to test this hypothesis on several architectures and tasks. The paper also conjectures that the reason large networks are more straightforward to train is that when randomly initialized large networks have more combinations for subnetworks which makes have a winning ticket more likely.",0.2413793103448276,0.12804878048780488,0.16733067729083664
2,SP:0355b54430b39b52df94014d78289dd6e1e81795,"The authors propose a method for image restoration, where the restored image is the MAP estimate. A pretrained GAN is utilized to approximate the prior distribution of the noise-free images. Then, the likelihood induces a constraint which is based on the degradation function. In particular, the method tries to find the latent point for which the GAN generates the image, which if gets degraded will match the given degraded image. Also, an optimization algorithm is presented that solves the proposed constrained optimization problem.","This paper proposed a general method for image restoration based on GAN. In particular, the latent variable z is optimized based on the MAP framework. And the results are obtained by G(z). This method looks reasonable to achieve good results. However, the idea is very related to Yeh et al.’s work which has already published but not mentioned at all. ",0.19047619047619047,0.25806451612903225,0.2191780821917808
3,SP:0561a2174d7334e078a49ae8859a36e4d74f9b5b,"Gradient clipping has been studied as an optimization technique and also as a tool for privacy preserving, but in this paper, it studies the robustness properties of gradient clipping.  More specifically, the main question of the paper is: Can gradient clipping mitigate label noise?  The paper reveals that the answer is no, but further proposes a simple variant of gradient clipping is robust and has nice property of classification calibration.  Experiments show that the proposed variant works under label noise.",This paper studies the relationship between gradient clipping in stochastic gradient descent and robustness to label noise. Theoretical results show that gradient clipping in general is not robust to symmetric label noise. The paper then proposes a variant of gradient clipping (cl-clipping) that induces label noise robustness. Experiments support these claims on synthetic datasets and typical classification benchmarks.,0.2625,0.3559322033898305,0.302158273381295
4,SP:0841febf2e95da495b41e12ded491ba5e9633538,"This paper studies the problem of learning a better poisoned graph parameters that can maximize the loss of a graph neural network. The proposed using meta-learning to compute the second-order derivatives to get the meta-gradients seems reasonable. The authors also proposed approximate methods to compute the graph as learning parameters, which could be more efficient since the second-order derivatives are no longer computed. The experimental results on three graph datasets show that the proposed model could improve the misclassification rate of the unlabeled nodes.","This paper studied data poisoning attacking for graph neural networks. The authors proposed treating graph structures as hyperparameters and leveraged recent progress on meta-learning for optimizing the adversarial attacks. Different from some recent work on adversarial attacks for graph neural networks (Zuigner et al. 2018; Dai et al. 2018), which focus on attacking specific nodes, this paper focuses on attacking the  overall performance of graph neural networks. Experiments on a few data sets prove the effectiveness of the proposed approach. ",0.19318181818181818,0.20987654320987653,0.20118343195266272
5,SP:08a6a48b05e2c00d77a73413cbba52cda08e184c,"The paper presents a new model FlowQA for conversation reading comprehension. Compared with the previous work on single-turn reading comprehension, the idea in this paper differs primarily in that it alternates between the context integration and the question flow in parallel. The parallelism enables the model to be trained 5 to 10 times faster. Then this process is formulated as layers of a neural network that are further stacked multiple times. Besides, the unanswerable question is predicted with additional trainable parameters. Empirical studies confirm FlowQA works well on a bunch of datasets. For example, it achieves new state-of-the-art results on two QA datasets, i.e., CoQA and QuAC, and outperforms the best models on all domains in SCONE. Ablation studies also indicates the importance of the concept Flow.","In this paper, authors proposed a so-called FLOWQA for conversational question answering (CoQA). Comparing with machine reading comprehension (MRC),  CoQA includes a conversation history. Thus, FLOWQA makes use of this property of CoQA and adds an additional encoder to handle this. It also includes one classifier to handle with no-answerable questions.",0.10606060606060606,0.2641509433962264,0.15135135135135133
6,SP:08c662296c7cf346f027e462d29184275fd6a102,"This paper investigates the problem of extracting a meaningful state representation to help with exploration in RL, when confronted to a sparse reward task. The core idea consists in identifying controllable (learned) features of the state, which in an Atari game for instance typically corresponds to the position of the player-controlled character / vehicle on the screen. Once this position is known (as x, y coordinates on a custom low-resolution grid), one can use existing count-based exploration mechanisms to encourage the agent to visit new positions (NB: in addition to the x, y coordinates, extra information is also used to disambiguate the states for counting purpose, namely the current score and the state’s cluster index obtained with a basic clustering scheme). To find the position, the algorithm trains one inverse dynamics model per x, y cell on the grid: each model tries to predict the action taken by the agent given two consecutive states, both represented by their feature map (at coordinate x, y) learned by a convolutional network applied to the pixel representation. The outputs of these inverse dynamics models are combined through an attention mechanism to output the final prediction for the action: the intuition is that the attention model will learn to focus on the grid cell with best predictive power (for a given state), which should correspond to where the controllable parts of the state are. Experiments on several Atari games (including Montezuma’s Revenge) indeed show that this mechanism is able to track the true agent’s coordinates (obtained from the RAM state) reasonably well. Using these coordinates for count-based exploration (in A2C) also yields significantly better results compared to vanilla A2C, and beats several previously proposed related techniques for exploration in sparse reward settings.",This paper introduces contingency-aware exploration by employing attentive dynamics model (ADM). ADM is learned in self supervised manner in an online fashion and only using pure observations as the agents policy is updated. This approach has clear advantages to earlier proposed count based techniques where agent's curiosity is incentivized for exploration. Proposed technique provides an important insight into how to approach such challenging tasks where the rewards are very sparse. Not only it achieves state of the art results with convincing empirical evidence but also authors make a good job of providing details of their specific modelling techniques for training challenges. They make a good job of comparing and contrasting the contingency-awareness by ADM to earlier proposed methods such as intrinsic motivation and self-supervised dynamics model. Overall exposition is clear with well explained results. The proposed idea raises interesting questions for future work.,0.09183673469387756,0.1836734693877551,0.12244897959183672
7,SP:0c0f078c208600f541a76ecaae49cf9a98588736,"This paper studies a Mixed Integer Linear Programming (MILP) approach to verifying the robustness of neural networks with ReLU activations. The main contribution of the paper is a progressive bound tightening approach that results in significantly faster MILP solving. This in turn allows for verifying the robustness of larger networks than previously studied, and even larger datasets such as CIFAR-10.","The authors perform a careful study of mixed integer linear programming approaches for verifying robustness of neural networks to adversarial perturbations. They propose three enhancements to MILP formulations of neural network verification: Asymmetric bounds, restricted domain and progressive bound tightening, which lead to significantly more scalable verification algorithms vis-a-vis prior work. They study the effectiveness of MILP solvers both in terms of verifying robustness (compared to other complete/incomplete verifiers) and generating adversarial attacks (compared to PGD attacks) and show that their approach compares favorable across a number of architectures on MNIST and CIFAR-10. They perform careful ablation studies to validate the importance of the ",0.3770491803278688,0.21296296296296297,0.272189349112426
8,SP:0ceece0754a1fe9c46a978bb2854932905685fa4,"This paper proposes a Generative Adversarial Network (GAN) methodology to learn the distribution of limit orders that arrive on an equity market. The proposed approach captures the (mostly discrete) structure in the generated orders; modeling is carried out with a conditional Wasserstein-GAN with a recurrent neural networks in both the generator and critic used to capture the time dependency, and convolutional layers to capture other conditioning information. Experiments are provided on both synthetic and real data.","The objective of this paper is to use GAN for generating the order stream of stock market data.   The novelty of the paper is the formulation of the order stream and the use of GAN for generating the stock data.   This is a paper for the application of GAN and there are limited contribution to the technical aspect of machine learning.    The paper is clearly written.   There are two main assumptions used in the paper; one is the Markov chain and the second one is the stationary distribution.   In real case, both assumptions are unlikely  to be satisfied.  The orders are mostly affected by many external factors and financial data are known to be non-stationary.  The authors may have to justify these assumptions. ",0.2597402597402597,0.16129032258064516,0.19900497512437812
9,SP:0e62f75b81b696bf794932d0ceee60e9f665f1da,"Understanding the effects of over-parametrization in neural network training has been a major challenge, albeit a lot of progress has been made in the past few years. The present paper is another attempt in this direction, with a slightly different point of view: the work characterizes the impact of over-parametrization in the number of iterations it takes an algorithm to converge. Along the way, it also presents further empirical observations such as the distance between the initial point and the final point and the angle between the gradients and the line that connects the initial and final points. Even though the observations presented are very interesting, unfortunately, the paper doesn't have the level of rigor required that would make it a solid reference. ","This paper discusses the effect of increasing the widths in deep neural networks on the convergence of optimization. To this end, the paper focuses on RNNs and applications to NLP and speech recognition, and designs several groups of experiments/measurements to show that wider RNNs improve the convergence speed in three different aspects: 1) the number of steps taken to converge to the minimum validation loss is smaller; 2) the distance from initialization to final weights is shorter; 3) the step sizes (gradient norms) are larger. This in some sense complements the theoretical result in Arora et al. (2018) for linear neural networks (LNN), which states that deeper LNNs accelerates convergence of optimization, but the hidden layers widths are irrelevant. This also shows some essential difference between LNNs and (practical) nonlinear neural networks. ",0.19047619047619047,0.18045112781954886,0.18532818532818535
10,SP:0ea5b3247ce031f25b98cf7d42bd4290020fbed2,"The paper proposes a novel, feedforward, end-to-end trainable, deep, neural network for abstract diagrammatic reasoning with significant improvements over the state of the art. The proposed model architecture is reasonable and is designed to exploit the information present at multiple granularities – at the level of objects in the diagram, their relations across diagrams, and diagram subsets. As a multimodule neural pipeline, it seems a reasonable design. Further, it shows significant performance gains over the state of the art.  ","In this paper the authors solve for the task of Raven Progressive Matrices (RPM) reasoning. They do so by considering multiplexed graph networks. They present an architecture for the same. The basic premise is a combination of object level representation that is obtained by a method similar to region proposal and combining them with graph network. The approach uses gated graph networks that also uses an aggregation function. These are combined and result in node embeddings. Detailed analysis of the network is provided. This provides improved results over earlier WREN method. However, the performance is slightly lesser than another paper simultaneously submitted that achieves similar results. That approach uses transformer network for spatial attention while here the spatial attention is just based on object level representation.",0.1875,0.11904761904761904,0.145631067961165
11,SP:0f04fc2e7966f4ba53909654fc0e8b90fc405f2a,"The paper is an empirical study that looks into the effect of neural network pruning on both the model accuracy as well as the generalization risk (defined as the difference between the training error and the test error). It concludes that while some pruning methods work, others fail. The authors argue that such discrepancy can be explained if we look into the impact of pruning on ""stability"". ","This paper mainly studies the relationship between the generalization error and mean/variance of the test accuracy. The authors first propose a new score for pruning called E[BN]. Then, the authors observe the generalization error and the test accuracy mean/variance for pruning large score weights and small score weights for VGG11, ResNet18, and Conv4 models. From these experiments, the authors observe that pruning large score weights generates instable but high test accuracy and smaller generalization gap compared to pruning small score weights. The authors additionally study some other aspects of pruning (e.g., pruning as a noise injection) and conclude the paper.",0.2835820895522388,0.18269230769230768,0.2222222222222222
12,SP:0fb732fe65ef1081b046a6aa6e1972e40cfdc247,"In this paper, authors propose a probabilistic extension of classic Neural Link Prediction models, such as DistMult and ComplEx. The underlying assumption is that the entity embeddings and the relation embeddings are sampled from a prior Multivariate Normal distribution, whose (hyper-)parameters can be estimated via maximum likelihood. In this paper, authors use Variational Inference (VI) for approximating the posterior distribution over the embeddings, and use Stochastic VI for maximising the Evidence Lower BOund (ELBO) while scaling to large datasets. In Sect. 3, authors introduce the generative process, and show how MAP estimation of the embedding matrices can recover the original models. In Sect. 4, authors start from the intractable marginal likelihood over the data (Eq. 5) for deriving the corresponding ELBO (Eq. 6), which is defined over:","The paper presents a probabilistic treatment of knowledge graph embeddings, motivating it in parameter uncertainty estimation and easier hyperparameter optimisation. The authors present density-based DistMult and ComplEx variants, where the posterior parameter distributions for entity and relation embeddings are approximated by diagonal Gaussians q_\gamma. Variational EM is used to infer the variational parameters \gamma as well as the per-entity/per-relation precision (\lambda) hyperparameters. The training process proposed by the authors consists of three phases: (1) pretraining a MAP estimate that’s used as initial means of the posterior approximating Gaussians, (2) variational EM (see above) to find better hyperparameters and (3) another MAP training phase that uses the updated per-entity/per-relation hyperparameters. Finally, experimental results indicate a slight improvement in MRR and HITS@10 across FB and WN datasets.",0.1796875,0.17037037037037037,0.17490494296577946
13,SP:117b19c4163cb3d08eda6bc7af0d48ed815b519e,"This paper proposes a multi-agent hierarchical reinforcement learning algorithm so that multiple humanoid robots can navigate in multi-agent settings (e.g. avoid collisions, collaboration, chase and escape) in a physically simulated environment. The key difference of this paper with the prior work on MARL is that it used an accurate physics simulation of humanoid robots. This is the main reason of using the hierarchical RL. ",The submission proposes a method for hierarchical RL in multiagent settings. In particular it proposes to explicitly decouple training of a high-level and low-level controller with grounded the controller interface as goals in the environment to reach for the low-level controller. The model is trained via PPO with GAE and evaluated on a small set of multi agent locomotion tasks.,0.1791044776119403,0.19047619047619047,0.18461538461538463
14,SP:12e7f417a7ef1ccafccff5ffb3f8f11cd2c05b20,"This paper proposes a method for assigning values to each datum.  For example, data with incorrect labels, data of low quality, or data from off-the-target distributions should be assigned low values. The main method involves training a neural network to predict the value for each training datum. The reward is based on performance on a small validation set. To make  gradient flow through data sampling, REINFORCE is used. The method is evaluated on multiple datasets. The results show that the proposed method outperforms a number of existing approaches.",This paper proposes a meta learning approach based on data valuation for reinforcement learning tasks. The core idea is to train a second network (the data value estimator) in conjunction to a regular predictor network. The predictor is then trained with samples chosen via the data value estimation. The authors motivate this construction with the goal to filter out unreliable and corrupted data. ,0.16666666666666666,0.23809523809523808,0.19607843137254902
15,SP:1342b6e11d1ccf04ee95b63d8b7a88b184dee43e,"This paper studies predicting multi-agent behavior using a proposed neural network architecture. The architecture, called a relational forward model (RFM) is the same graph network proposed by Battaglia et al., 2018, but adds a recurrent component. Two tasks are define: predict the next action of each agent, and predict the sum of future rewards. The paper demonstrates that RFMs outperform two baselines and two ablations. The authors also show that edge activation magnitudes are correlated with certain phenomenons (e.g. an agent walking towards an entity, or an entity being “on” or “off”). The authors also show that appending the output of a pre-trained RFM to the state of a policy can help it learn faster.",This paper used graph neural networks to do relational reasoning of multi-agent systems to predict the actions and returns of MARL agents that they call Relational Forward Modeling. They used RFM to analyze and assess the coordination between agents in three different multi-agent environments. They then constructed an RFM-aumented RL agent and showed improved training speeds over non relational reasoning baseline methods. ,0.1271186440677966,0.23076923076923078,0.1639344262295082
16,SP:153fe1172e689b345729c0c848cfb38bdae0e5f7,"The recent work of Schott et al (which the authors compare results to) proposed the use of Bayes rule inversion as a more robust mechanism for classification under different types of adversarial attacks. The probabilities are approximated with variational autoencoders. During training the inference network is used, but during testing optimization based inference is carried out to compute loglikelihoods.","Authors propose a novel combination of RBM feature extractor and CNN classifiers to gain robustness toward adversarial attacks. They first train a small mean field boltzmann machine on 4x4 patches of MNIST, then combine 4 of these into a larger 8x8 feature extractor. Authors use the RBM 8x8 feature representation as a fixed convolutional layer and train a CNN on top of it. The intuition behind the idea is that since RBMs are generative, the RBM layer will act as a denoiser. ",0.15254237288135594,0.10975609756097561,0.1276595744680851
17,SP:17d8dc884e15131636a8c2490085ce42c05433c1,"In this paper, the authors studied bias amplification. They showed in some situations bias is unavoidable; however, there exist some situations in which bias is a consequence of weak features (features with low influence to the classifier and high variance). Therefore, they used some feature selection methods to remove weak features; by removing weak features, they reduced the bias substantially while maintaining accuracy (In many cases they even improved accuracy).  Showing that weak features cause bias is very interesting, especially in their real-world dataset in which they improved bias and accuracy simultaneously.  ","In this paper the authors identify a specific source of marginal class probability bias that occurs when using logistic regression models. Using synthetic and real datasets they demonstrate this bias and explore characteristics of the data that exacerbate the issue. Finally, they propose two methods for correcting this bias in logistic regression models and neural network models with logistic output layers and evaluate these methods on several benchmark datasets.",0.16129032258064516,0.21739130434782608,0.18518518518518517
18,SP:18be2cb182761b64fa232c1b7d1899882e5bcf15,"This paper proposes a strategy to generate audio samples from noise with GANs. The treatment is analogous to image generation with GANs, with the emphasis being the changes to the architecture and representation necessary to make it possible to generate convincing audio that contains an interpretable latent code and is much faster than an autoregressive Wavenet based model (""Neural Audio Synthesis of Musical Notes with WaveNet AutoEncoders"" - Engel et al (2017)). Like the other two related works (WaveGAN - ""Adversarial Audio Synthesis"" - Donahue et al 2018) and the Wavenet model above, it uses the NSynth dataset for its experiments. ","This paper proposes an approach that uses GAN framework to generate audio through modeling log magnitudes and instantaneous frequencies with sufficient frequency resolution in the spectral domain. Experiments on NSynth dataset show that it gives better results then WaveNet. The most successful deep generative models are WaveNET,  Parallel WaveNet and Tacotran that are applied to speech synthesis, the method should be tested for speech synthesis and compared with WaveNet, Parallel WaveNet as well as Tacotran.",0.16326530612244897,0.21333333333333335,0.18497109826589594
19,SP:1be944b5f82d33ab1feb5639792a4c06b8f0c85a,"The paper offers a new deep learning approach to symbolic reasoning over text. They propose using Neural Module Networks to perform explicit reasoning steps that are nevertheless differentiable. The process is separated into a semantic parsing of the question, and a resolution using MNMs. Auxiliary tasks improve performance and enable using a BERT pretrained model as a seed. The proposed model's performance surpasses previous SOTA on several question types. ","This works applies neural module network to reading comprehension that requires symbolic reasoning. There are two main contributions: (1) the authors designed a set of differentiable neural modules for different operations (for example, arithmetics, sorting, and counting) that is required to perform reasoning over a paragraph of text. These modules can be compositionally combined to perform complex reasoning. And the parameters of each module (which can be viewed as executor of each operation) are learned jointly with the parser that generates thee program composed of those modules. (2) To overcome the challenge of weak supervision, the authors proposed to use auxiliary loss (information extraction loss, parser supervision, intermediate output supervision). The model is evaluated on a subset of DROP, and outperforms the state-of-the-art models. Ablation studies supported the importance of the auxiliary losses.",0.24285714285714285,0.125,0.16504854368932037
20,SP:1c7cf7417825208feac9fe3b3488a51ad1e72270,"This paper addresses security of distributed optimization algorithm under Byzantine failures. These failures usually prevent convergence of training neural network models. Focusing on the asynchronous SGD algorithm implemented with a parameter-server, the authors propose to use stochastic line search ideas to detect whether the gradients are good descent directions or not. It applies to a general scenario including repeated and unbounded Byzantine failures. ","This paper investigates the security of distributed asynchronous SGD. Authors propose Zeno++, worker-server asynchronous implementation of SGD which is robust to Byzantine failures. To ensure that the gradients sent by the workers are correct, Zeno++ server scores each worker gradients using a “reference” gradient computed on a “secret” validation set.  If the score is under a given threshold, then the worker gradient is discarded. ",0.234375,0.23076923076923078,0.23255813953488372
21,SP:230b3e008e687e03a8b914084b93fc81609051c0,"This paper proposes training VAEs with discrete latent variables by importance sampling the expected log likelihood (ELL) term in the ELBO, which is the problematic term since it is not amenable to reparametrization gradients.  For the importance sampling distribution, they choose the variational distribution itself, making the ELL gradient E[(d q(z|x) / d \theta) \log p(x|z) / q(z|x)].  Experiments are reported for MNIST and Fashion-MNIST using Bernoulli and categorical latent variables.","In computing the gradient of the ELBO, the main challenge lies in computing the gradient of the reconstruction loss with respect to the encoder parameters. VAEs traditionally rely on reparameterization in order to obtain a low-variance estimate, but there are a number of other gradient estimators that one can apply. The authors here proprose to use a trick that is known, but perhaps not widely known: If we introduce an importance sampling distribution, then we can use samples from this distribution to compute an importance-weighted estimate of the gradient. The idea is now that we can compute the gradient w.r.t. the encoder parameters as a simple importance-sampling estimate, which obviates then need for reparameterization, or likelihood-ratio estimators. The authors then apply this trick to train VAEs with discrete latent variables.",0.19480519480519481,0.11029411764705882,0.14084507042253522
22,SP:252c20661ef36f8c32f7412db315747925d3a3d0,"This paper proposes a method for functional regularization for training neural nets, such that the sequence of neural nets during training is stable in function space. Specifically, the authors define a L2 norm (i.e., a Hilbert norm), which can be used to measure distances in this space between two functions. The authors argue that this can aid in preventing catastrophic forgetting, which is demonstrated in a synthetic multi-task variant of MNIST.   The authors also show how to regularize the gradient updates to be conservative in function space in standard stochastic gradient style learning, but with rather inconclusive empirical results.  The authors also draw upon a connection to the natural gradient.","This paper proposes first to measure distances, in a L2 space, between functions computed by neural networks. It then compares those distances with the parameter l2 distances of those networks, and empirically shows that the l2 parameter distance is a poor proxy for distances in the function space. Following those observations, the authors propose to use such constraint to combat catastrophic forgetting, and show some results on the permuted MNIST task. Finally, they propose the Hillber-constrained gradient descent (HCGD), a gradient descent algorithm that constraint movement in the function space, and evaluate it on a CNN (CIFAR10) and an LSTM (permuted MNIST).",0.21428571428571427,0.23300970873786409,0.22325581395348834
23,SP:26535b26a3178050d8aae56b7c9669c9d2408ac8,"In this paper, the authors investigate the gradient calculation in the original MAML (Finn et al. 2017) and E-MAML (Al-Shedivat et al. 2018). By comparing the differences in the gradients of these two algorithms, the authors demonstrate the advantages of the original MAML in taking the casual dependence into account. To obtain the correct estimation of the gradient through auto-differentiation, the authors exploit the DiCE formulation. Considering the variance in the DiCE objective formulation, the authors finally propose an objective which leads to low-variance but biased gradient. The authors verify the proposed methods in meta-RL tasks and achieves comparable performances to MAML and E-MAML. ","In this paper, the author proposed an efficient surrogate loss for estimating  Hessian in the setting of Meta-reinforcement learning (Finn.et al, 2017), which significantly reduce the variance while introducing small bias. The author verified their proposed method with other meta-learning algorithms on the Mujoco benchmarks. The author also compared with unbiased higher order gradient estimation method-DiCE in terms of gradient variance and average return. ",0.18181818181818182,0.29411764705882354,0.22471910112359553
24,SP:2aaddb6dda434b49487857d99c9d143e2f54d350,"This paper studies the problem of detecting and generating adversarial images using class-conditional capsule networks. Specifically, this paper first introduced a novel method that detects adversarial examples by class-conditional image reconstruction. Motivated by this defense method, this paper further proposed a novel reconstructive attack that minimizes both classification and reconstruction loss. Experimental evaluations are conducted on MNIST, FashionMNIST, SVHN, and CIFAR-10 dataset. Results demonstrate the effectiveness of the proposed defense and the novel reconstructive attack method.","This paper proposed a new defense method for capsule networks. For both white-box and black-box settings, the proposed CapNets has shown superior performance than two variants of CNNs. The visualizations of adversarial examples generated by the CapNets are more aligned with the human perception which is very insightful. On the corrupted MNIST dataset, the results show the proposed defense method can also be used well as an out-of-distribution detector. Overall the paper is clearly written and easy to follow.",0.20253164556962025,0.1927710843373494,0.19753086419753085
25,SP:2b03b7ea1264c2671d29e8fa5f3a828412ea7996,"The paper presents a model for learning conditional distribution when arbitrary partitioning the input to observed and masked parts. The idea is to extend the conditional VAE framework such that the posterior is a function of an arbitrary subset of observed variables. Accordingly, reconstruction loss only penalizes the error in the reconstruction of masked (unobserved) variables. The method is compared against 1) classical approaches in missing data imputation on UCI benchmarks; 2) image inpainting against recently proposed GANS for the similar task, as well as; 3) against universal marginalizer, which learns conditional densities using a feedforward / autoregressive architecture.","The goal of this paper is to use deep generative models for missing data imputation. This paper proposes learning a latent variable deep generative model over every randomly sampled subset of observed features. First, a masking variable is sampled from a chosen prior distribution. The mask determines which features are observed. Then, the likelihood of the observed features is maximized via a lower bound. Inference in this latent variable model is achieved through the use of an inference network which conditions on the set of ""missing"" (to the generative model) features.",0.17346938775510204,0.18681318681318682,0.1798941798941799
26,SP:2b1813a3cc39d6e1eba546b456bf8d1f9cc8657c,"This paper extends the mirror-descent and mirror-prox algorithms to infinite dimensional Banach spaces so that they can be applied to solve the mixed Nash equilibrium of the popular generative adversarial networks. The main technical results appear to be formal but straightforward extensions of existing techniques in finite dimensional spaces. A sample-based practical algorithm is proposed so that the infinite dimensional algorithms can still be computed. Experiments are a bit disappointing as the authors only used visual appeal as an evaluation criterion. (I understand why the authors chose to do so but as an algorithmic paper, resorting to an evaluation based on visual appeal is almost always unsatisfactory.)","This paper proposes to consider the mixed equilibrium objective function for GANS. The authors generalize the mirror descent/mirror prox to handle continuous games. The technical challenge is to write those algorithms in infinite dimensional spaces. This reviewer finds this however to be a mere technicality, and there seems to be no conceptual obstruction. In fact other paper have already written this, see for example ``Mirror Descent Learning in Continuous Games"" by Zhou et al. at CDC 2017 (I'm sure there are other references too).",0.16363636363636364,0.20930232558139536,0.1836734693877551
27,SP:2b4a39b997934ccf0e6b5fcb4d1e62253592b05f,"This paper proposed a feature boosting and suppression method for dynamic channel pruning. To be specific, the proposed method firstly predicts the importance of each channel and then use an affine function to amplify/suppress the importance of different channels. However, the idea of dynamic channel pruning is not novel. Moreover, the comparisons in the experiments are quite limited. ","This manuscript presents a nice method that can dynamically prune some channels in a CNN network to speed up the training. The main strength of the proposed method is to determine which channels to be suppressed based upon each data sample without incurring too much computational burden or too much memory consumption.  The good thing is that the proposed pruning strategy does not result in a big performance decrease. Overall, this is a nicely written paper and may be empirically useful for training a very large CNN. Nevertheless, the authors did not present a real-world application in which it is important to speed up by 2 or 3 times at a small cost, so it is hard to judge the real impact of the proposed method.",0.2542372881355932,0.11811023622047244,0.16129032258064516
28,SP:2b84207c0015dba126d4ef4a89ef9cc29656f2f8,"This paper studies the implicit bias of minimizers of a regularized cross entropy loss of a two-layer network with ReLU activations. By combining several results, the authors obtain a generalization upper bound which does not increase with the network size. Furthermore, they show that the maximum normalized margin is, up to a scaling factor, the l1 svm margin over the lifted feature space of an infinite-size network. Finally, in a setting of infinite-sized networks, it is proved that perturbed Wasserstein gradient flow finds a global minimum in polynomial time.","The authors claim to prove three things: (1) Under logistic loss (with a vanishing regularization), the normalized margin (of the solution) converges to the max normalized margin, for positive homogenous functions. This is an asymptotic result: the amount of regularization vanishes. (2) For one hidden layer NN, the max margin under l_2 norm constraint on weights in the limit, is equivalent to the l_1 constraint (total variation) on the sign measure (specified by infinite neurons) for the one hidden layer NN. (3) Show some convergence rate for the mean-field view of one hidden layer NN, i.e., the Wasserstein gradient flow on the measure (of the neurons). The author show some positive result for a perturbed version.",0.1956521739130435,0.15,0.16981132075471697
29,SP:2db0ece25ebfb4d5e3aa8eb145964ce4be19409f,"The authors extend neural processes by incorporating two types of attention processes: self-attention for enriching the features of the context points and cross-attention for producing a query-specific representation. By replacing MLPs and mean pooling with these attention processes, the authors resolve the underfitting problem of NPs. The experimental results show that ANPs converge better and faster than NPs.","Neural process (NP) is a recent probablistic method for modeling distributions of functions. The authors claim that one substantial weakness of NP is the tendency of under-fitting. The authors give a hypoethesize: the under-fitting behaviour of NP is because the mean-aggregation step in the encoder acts as a bottleneck, as a result, it is difficult for the decoder to learn the relevant information for a give target prediction. This paper proposes to resolve this issue by adding an attention mechanism to the deterministic path. The experimental results show that the proposed method converge faster and give better results on various tasks.",0.29508196721311475,0.17307692307692307,0.21818181818181817
30,SP:2feef921a0563d52fde1c074da754f73e6cabef8,"This paper proposes a framework for few-sample knowledge distillation of convolution neural networks. The basic idea is to fit the output of the student network and that of the teacher network layer-wisely. Such a regression problem is parameterized by a 1x1 point-wise convolution per layer (i.e. minimizing the fitting objective over the parameters of 1x1 convolutions). The author claims such an approach, called FSKD, is much more sample-efficient than previous works on knowledge distillation. Besides, it is also fast to finish the alignment procedure as the number of parameters is smaller than that in previous works. The sample efficiency is confirmed in the experiments on CIFAR-10, CIFAR-100 and ImageNet with various pruning techniques. In particular, FSKD outperforms the FitNet and fine-tuning by non-trivial margins if only small amount of samples are provided (e.g. 100).","In this paper, an efficient re-training algorithm for neural networks is proposed. The essence is like Hinton's distillation, but in addition to use the output of the last layer, the outputs of intermediate layers are also used. The core idea is to add 1x1 convolutions to the end of each layer and train them by fixing other parameters. Since the number of parameters to train is small, it performs well with the small number of samples such as 500 samples. ",0.2013888888888889,0.35365853658536583,0.2566371681415929
31,SP:304930c105cf036ab48e9653926a5f61879dfea6,"In this paper the authors introduce a new quantity, the nonlinearity coefficient, and argue that its value at initialization is a useful predictor of test time performance for neural networks. The authors conduct a wide range of experiments over many different network architectures and activation functions to corroborate these results. The authors then extend their method to compute the local nonlinearity of activation functions instead.","I do not understand the denomination of nonlinearity coefficient provided in definition 1: although the quantity indeed does equal to 1 under whitened data distribution or orthogonal matrix, the conjecture that it should be close to 1 does not seem to be close at all just under any data distribution. Using a similar construction that section 6, we can rescale a whitened input data with a diagonal matrix D with components all equal to one except for a very large one \lambda and also multiply the input weights by D^{-1} to compensate (and have a similar function). If you look at such construction for the linear case with identity initialization of A, the NLC is sqrt((\lambda^2 + n - 1) (\lambda^{-2} + n - 1)) / n which can grow arbitrarily large with \lambda *for a linear model*. However, because of its low capacity, we would expect a linear model to have reasonable generalization. This seems to compromise the initial NLC being low as a necessary condition for reasonable generalization. ",0.2153846153846154,0.08284023668639054,0.11965811965811968
32,SP:31772a9122ec998c7c829bc4813f6147cdc30145,"This paper introduces SANE, a new approach for explaining image similarity models by combining a saliency map generator and an attribute predictor. In this way, the method is not only able to highlight what regions contribute the most to the similarity between a query image and a reference image, but also predict an attribute that explains this match. During training, SANE jointly optimizes the attribute prediction of the query image and maximizes the overlap of the saliency map of the image similarity and the attribute activations.","This paper proposes a novel method for image similarity models explanation, introducing Salient Attributes for Network Explanation (SANE). The method identifies attributes that contribute positively to the similarity score, thus explaining the important image properties, and pair them with a generated saliency map unveiling the important regions of the image. The method combines three major components: ",0.2558139534883721,0.39285714285714285,0.3098591549295775
33,SP:319922e4a316a9b9e76504f806d30ea3bffa3f99,"This paper analyzes how signals propagate through randomly initialized neural networks that have undergone a kind of pruning/sparsification. The pruning method utilizes a metric called 'connection sensitivity', which has been used in prior work and which measures the infinitessimal impact of turning off specific parameters. The distribution of singular values in the layer-to-layer Jacobian matrices for pruned networks becomes increasingly pathological as the depth increases. This observation motivates the concept of 'layerwise dynamical isometry' (LDI), a slight generalization of the concept of 'dynamical isometry' that has been studied in prior work. Several methods for approximately obtaining differing amounts of LDI are investigated in a series of in-depth experiments that show a strong correlation between increased signal propagation and improved trainability of sparse networks.","In this paper, the authors studied and formalized the effect of initialization to connection-sensitivity-based pruning. The authors first pointed out that a previously studied pruning criterion -- connection sensitivity (CS) -- is a normalized magnitude of gradients. Based on signal propagation theory, to achieve a 'faithful' (with minimal amplification) CS, the gradients must be also faithful. Then by using relation of Jacobians and gradient, the authors proved that orthogonally initial weights guarantees faithful on linear networks and certain distribution property on nonlinear network can achieve layerwise dynamic isometry, which is to ensure faithful signal propagation. Based on these findings, the authors proposed an initialization setup for improving pruning performance, with the goal to ensure dynamic isometry by orthogonal initialization and approximation.",0.14173228346456693,0.1487603305785124,0.14516129032258063
34,SP:31c9c3a693922d5c3448e80ade920391dce261f9,"This paper claims to be the first to tackle unconditional singing voice generation. It is noted that previous singing voice generation approaches leverage explicit pitch information (either of an accompaniment via a score or for the voice itself), and/or specified lyrics the voice should sing. The authors first create their own dataset of singing voice data with accompaniments, then use a GAN to generate singing voice waveforms in three different settings:","This paper has set a new problem: singing voice synthesis without any score/lyrics supervision. The authors provide a significance of such a problem in section 1. Also, the authors successfully design and implement a novel neural network architecture to solve the problem. It’s also notable that the authors kindly open-source their code to mitigate the reproducibility issue. This paper may serve as baseline results for the proposed problem in the future.",0.19444444444444445,0.1891891891891892,0.1917808219178082
35,SP:35e050c84f55f30b5a958128fa5bdaa1cb3f7e90,The paper uses Generative Adversarial Networks (GAN) for unsupervised and semi-supervised clustering. Neural network based generators are used for sampling using a mixture model. The parameters of the generators are optimised during training against a discriminator that tries to distinguish between generated distributions. Experimental results on MNIST and SVHN datasets are given to motivate their models.,The paper presents a generative model that can be used for unsupervised and semi-supervised data clustering. unlike most of previous method  the latent  variable is composed of both continuous and discrete variables. Unlike previous methods like ALI the conditional probability  p(y|x) of the labels given the object is represented by a neural network and not simply drown from the data.  The  authors show a  clustering error rate on the MNIST data that is better than previously proposed methods. ,0.2807017543859649,0.19753086419753085,0.23188405797101447
36,SP:366b68d2490ea7569c74dc66ec0f83daa029ddd9,"This paper studies the asymptotic properties of action value function $Q$ and value function $V$. Specifically, the authors assume that we can collect $n$ data points $\{(s_t,a_t,r_t(s_t,a_t),s_{t+1})\}_{t=1}^{n}$. Based on the collected data, the authors calculated the sample mean of the unknown reward function $\widehat r_n$ and transition probability $\widehat{P}(\cdot|s,a)$. They further defined an estimator $\widehat Q_n$, which is the fixed point of the empirical Bellman operator $\widehat{\mathcal{T}}_n$ derived from $\widehat r_n$ and $\widehat P_n$. The authors proved under certain assumptions that $\widehat Q_n\rightarrow Q^*$ almost surely. Based on this argument, they also derived a similar convergence of value function $\widehat V_n$ in distribution. Confidence intervals can also be established based on these results.","This paper studies the inference problem of reinforcement learning. With a given exploration policy that satisfies some strong property to collect n data, the paper studies the distribution of the estimated optimal value function and Q-function when n goes to infinity. Both unique and non-unique optimal policy cases are studied. The non-unique case has a very different behavior as it is no longer Gaussian. The paper then uses these estimations to design a method that better explores and proposes a method Q-OCBA. Experiments were performed to compare this method with previous algorithms, e.g., UCRL.",0.15492957746478872,0.2222222222222222,0.1825726141078838
37,SP:3823faee83bc07a989934af5495dafd003c27921,"The paper proposes a method to augment representation of an entity (such as a word) from standard ""point in a vector space"" to a histogram with bins located at some points in that vector space. In this model, the bins correspond the context objects, the location of which are the standard point embedding of those objects, and the histogram weights correspond to the strength of the contextual association. The distance between two representations is then measured with, Context Mover Distance, based on the theory of optimal transport, which is suitable for computing the discrepancy between distributions. ","The submission explores a new form of word representation based on a histogram over context word vectors, allowing them to measure distances between words in terms of optimal transport between these histograms. The authors speculate that this may allow better representations of polysemous words. The approach is mathematically elegant, and requires no additional training on top of existing approaches like Glove. To improve efficiency, they use clustering on context vectors. They present results on various semantic textual similarity and hypernym detection tasks, outperforming some baselines.",0.15625,0.17647058823529413,0.16574585635359115
38,SP:3a1655a2efdf0246f459b6f82a2948aafc7438a9,"In this work the authors prove several claims regarding the inductive bias of gradient descent and gradient flow trained on deep linear networks with linearly separable data. They show that asymptotically gradient descent minimizes the risk, each weight matrix converges to its rank one approximation and the top singular vectors of two adjacent weight matrices align. Furthermore, for the logistic and exponential loss the induced linear predictor converges to the max margin solution. ","This paper studies the properties of applying gradient flow and gradient descent to deep linear networks on linearly separable data. For strictly decreasing loss like the logistic loss, this paper shows 1) the loss goes to 0, 2) for every layer the normalized weight matrix converges to a rank-1 matrix 3) these rank-1 matrices are aligned. For the logistic loss, this paper further shows the linear function is the maximum margin solution.",0.3835616438356164,0.3783783783783784,0.380952380952381
39,SP:3a16ffa27e7ef0684e6d0f3ee744787aef108a07,"This paper is about trying to learn a function from typed input-output data so that it can generalize to test data with an input-output type that it hasn't seen during training. It should be able to use ""analogy"" (if we want to translate from French to Spanish but don't know how to do so directly, we should translate from French to English and English to Spanish). It should also be able to generalize better by learning useful ""subfunctions"" that can be composed together by an RL agent. We set up the solution as having a finite number of subfunctions, including ""HALT"" which signifies the end of computation. At each timestep an RL agent chooses a subfunction to apply to the current representation until ""HALT"" is chosen. The main idea is we parameterize these subfunctions and the RL agent as neural networks which are learned based on input -output data. RL agent is also penalized for using many subfunctions. The algorithm is called compositional recursive learner (CRL). Both analogy and meaningful subfunctions should arise purely because of this design.","This paper proposes a model for learning problems that exhibit compositional and recursive structure, called Compositional Recursive Learner (CRL). The paper approaches the subject by first defining a problem as a transformation of an input representation x from a source domain t_x to a target domain t_y. If t_x = t_y then it is called a recursive problem, and otherwise a translational problem. A composite problem is the composition of such transformations. The key observation of the paper is that many real-world problems can be solved iteratively by either recursively transforming an instance of a problem to a simpler instance, or by translating it to a similar problem which we already know how to solve (e.g., translating a sentence from English to French through Spanish). The CRL model is essentially composed of two parts, a set of differential functions and a controller (policy) for selecting functions. At each step i, the controller observes the last intermediate computation x_i and the target domain t_y, and then selects a function and the subset of x_i to operate on. For each instance, the resulting compositional function is trained via back-propagation, and the controller is trained via policy gradient. Finally, the paper presents experiments on two synthetic datasets, translating an arithmetic expression written in one language to its outcome written in another language, and classifying MNIST digits that were distorted by an unknown random sequence of affine transformations. CRL is compared to RNN on the arithmetic task and shown to be able to generalize both to longer sequences and to unseen language pairs when trained on few examples, while RNN can achieve similar performance only using many more examples. On MNIST, it is qualitatively shown that CRL can usually (but not always) find the sequence of transformations to restore the digit to its canonical form.",0.2032967032967033,0.11935483870967742,0.15040650406504066
40,SP:40ade446aa4a700cb1519b9115e8d6cdf33db4a4,"Ullman et al. showed that slight changes in location or size of visible regions in minimal recognizable images can significantly impair human ability to recognize objects. This paper is a  follow-up of Ullman et al. paper, with focus on sensitivity of DNNs to certain regions in images. In other words, slight change of such regions’ size or location in the image can significantly affect DNN ability in recognizing them, even-though these changes are not noticeable for humans. ","This paper is a more thorough follow-up to e a previous work by Ullman et al that was comparing minimally recognizable patches by humans compared to deep neural network. This paper exhibits that a wide range of architectures features the same fragility and that these effects can combated by better training methodology and different pooling architectures. Still even with those changes deep CNNs still posses more fragile behavior than human vision. One of my criticism is that human vision is kind of different: it makes multiple passes over the same images at multiple scales, so this might contribute significantly to these differences. Still this paper makes a lot of interesting observations and analyses and represents a first methodological study of this phenomenon.",0.20253164556962025,0.13008130081300814,0.15841584158415845
41,SP:40e210d36298e2eafd06d9dc45312ea4fd586ade,"The overall goal of this paper is to solve online combinatorial optimization (OCO) problems using reinforcement learning. Importantly, the authors are not seeking to establish new results for unsolved problems, but instead they are motivated by analyzing and comparing the quality of solutions predicted by reinforcement learners with respect to the well-known near-optimal strategies for some OCO tasks. In doing so, the authors focused on an MDP framework using policy gradient and DQN methods. This framework was trained on three OCO tasks; online budget allocation, online knapsack, and the secretary problem. For each, the trained model is consistent with the near-optimal “handcrafted’’ algorithms.","This paper introduces a new framework to solve online combinatorial problems using reinforcement learning. The idea is to encode the current input, the global parameters, and a succinct data structure (to represent current states of the online problem) as MDP states. Such a problem can then be solved by deep RL methods. To train such models, the authors use a mixture of input distributions. Some come from hard distributions which are used to prove lower bounds in the TCS community, and the others are carefully constructed distributions to fool a specific set of algorithms. The authors made an important point that their algorithms are uniform in the TCS sense, i.e., the algorithm does not depend on the input length.",0.2358490566037736,0.20833333333333334,0.22123893805309736
42,SP:414b06d86e132357a54eb844036b78a232571301,"The paper proposes an imitation learning method that aims to align state distributions rather than state-action distributions to account for cases where the imitator dynamics differ from expert dynamics. They achieve this by two objectives: one local, the other global. The local objective aligns the next state to be close to the expert's next state in each transition by first training a VAE on the expert demonstrations, and using the trained VAE in conjunction with a pretrained inverse dynamics model to compute the action that the imitator needs to imitate. The global objective tries to do a global alignment of states encountered in the imitator and expert trajectories, by minimizing the Wasserstein distance between the two trajectory distributions. The paper claims that using these two objectives results in a method that outperforms existing inverse reinforcement learning and behavior cloning approaches in settings where the imitator and expert dynamics differ.",This paper seeks a solution to the problem of performing imitation learning when the dynamics of the demonstrator are different from the dynamics of the imitator. The authors present a novel approach that combines global alignment by minimizing the Wasserstein distance between state occupancies with local alignment via a state-predictive VAE and inverse dynamics model. The experimental results support the claims that the method works for different dynamics and the proposed approach usually outperforms existing imitation learning methods.,0.18543046357615894,0.35443037974683544,0.24347826086956526
43,SP:426c98718b2dbad640380ec4ccb2b656958389bc,"This paper introduces an approach to pruning the parameters of a trained neural network. The idea is inspired by the Optimal Brain Surgeon method, which relies on second derivatives of the loss w.r.t. the network parameters. Here, the corresponding Hessian matrix is approximated using the Fisher information to make the algorithm scalable to very deep networks.","The paper proposes a multi-layer pruning method called MLPrune for neural networks, which can automatically decide appropriate compression ratios for all the layers. It firstly pre-trains a network. Then it utilizes K-FAC to approximate the Fisher matrix, which in turn approximates the exact Hessian matrix of training loss w.r.t model weights. The approximated Hessian matrix is then used to estimate the increment of loss after pruning a connection. The connections from all layers with the smallest loss increments are pruned and the network is re-trained to the final model.",0.3275862068965517,0.2,0.24836601307189543
44,SP:4332dfe46b715595e9f1dd3f6a79b82a646b4c23,"This paper proposes a sequential Monte Carlo Planning algorithm that depicts planning as an inference problem solved by SMC. The problem is interesting and the paper has a nice description of the related work. In terms of the connection between the the problem and Bayesian filtering as well as smoothing, the paper has novelty there. But it is unclear to me how the algorithm proposed is applicable in complex continuous tasks as claimed.","Sequential Monte Carlo (SMC) has since its inception some 25 years ago proved to be a powerful and generally applicable tool. The authors of this paper continue this development in a very interesting and natural way by showing how SMC can be used to solve challenging planning problems. This is a enabled by reformulating the planning problem as an inference problem via the recent trend referred to as ""control as inference"". While there is unfortunately no real world experiments, the simulations clearly illustrate the potential of the approach.",0.2054794520547945,0.17045454545454544,0.18633540372670804
45,SP:4463645f1a9abfbf472935d9eb3342919aa4e0f4,"The authors proposed a method for code optimization for deploying neural networks. The main idea is to formulate it as a search task over tuning knobs in the code template, and to apply reinforcement learning to optimize the configurations for the tuning knobs with respect to a cost model. The cost model is trained based on a subset of representative samples from the RL controller and their corresponding hardware cost measurements.","This paper proposes an optimizing compiler  for DNN's based on adaptive sampling and reinforcement learning, to drive the search of optimal code in order to reduce compilation time as well as potentially improve the efficiency of the code produced. In particular, the paper proposes to use PPO to optimize a code optimization ""search"" policy, and then use K-mean clustering over a set of different proposed compilation proposals, from which to perform adaptive sampling to reduce compilation time while still keeping a high diversity of the proposed solution pools during exploration. At the same time the authors claim that using RL will learn a better search strategy compared to random search - such as simulated annealing which is used by competing methods - thus producing faster and better solutions.",0.22535211267605634,0.125,0.16080402010050251
46,SP:44e0f63ffee15796ba6135463134084bb370627b,"This paper proposed to tackle a large-scale fine-grained object classification problem by approximated CRF. The main motivation is to exploit the spatial conference of object labels to reduce noises in the instance-wise prediction. To this end, the task is formulated by sequential inference problem using CRF. To speed up training, several techniques are applied such as factorized pairwise-potential and approximation of CRF objective.  ","This paper introduces a new dataset consisting of images of various objects placed on store shelves that are labeled with object boundaries and what are described as “ultrafine-grained” class labels. The accompanying task is to predict the labels of each object given the individual images as well as their spatial layout relative to each other. To solve this task, a deep structured model is used consisting of CNN features for each image which are fed into a linear-chain CRF. To better deal with the large number of classes, pairwise potentials are represented as the multiplication of two lower-rank matrices which represent a sort of “class embedding” for each potential label. Training efficiency is improved by considering an objective based on a form of piecewise pseudolikelihood, which allows for training-time inference to be conducted with linear complexity relative to the number of labels. This objective also allows for easy use of batch normalization for the input features to the CRF model. This model/training procedure are compared against a number of models/training procedures to demonstrate its utility.",0.3283582089552239,0.12154696132596685,0.1774193548387097
47,SP:465adf302cd8b7e6b449271a91d1d2fad844aa4d,"This paper researches the pooling operation, which is an important component in convolutional neural networks (CNN) for image classification. Taking the perspective from signal processing, this paper proposes a pooling operation called frequency pooling (F-pooling). The key motivation is to make the pooling operation shift-equivalent and anti-aliasing. This paper gives an improved definition on shift-equivalent functions and shows that the proposed F-pooling is optimal in the sense of reconstructing the orignal signal. The F-pooling is then implemented with matrix multiplications and tested with recent convolutional neural networks for image classifiation on CIFAR-100 and a subset of ImageNet dataset. ","This paper proposed ""F pooling"" for Frequency Pooling, which is a pooling operation satisfying shift equivalence and anti-aliasing properties. The method is very simple: first, transform the input 1D/2D signal into the spectrum domain based on discrete Fourier transform (DFT), then cut the high-frequencies, then transform back to the time domain using the inverse DFT. The method can be implemented using FFT and auto differentiation frameworks. The method is tested on Resnet/Desnet on CIFAR-100 and subsets of ImageNet, showing better performance than the original models.",0.26666666666666666,0.3111111111111111,0.2871794871794872
48,SP:47b0c8a984480eb353b36fd877d9775213fb1a5f,This submission introduces a new method for vision+language navigation which tracks progress on the instruction using a progress monitor and a visual-textual co-grounding module. The method is shown to perform well on a standard benchmark. Ablation tests indicate the importance of each component of the model. Qualitative examples show that the proposed method attends to different parts of the instruction as the agent moves. ,"The paper considers the problem of following natural language route instructions in an unknown environment given only images. Integral to the proposed (""self-aware"") approach is its ability to reason over which aspects of the instruction have been completed, which are to be followed next, which direction to go in next, as well as the agents current progress. This involves two primary components of the architecture. The first is a visual-textual module that grounds to the completed instruction, the next instruction, and the next direction based upon the visual input. The second is a ""progress monitor"" that takes the grounded instruction as input and captures the agent's progress towards completing the instruction.",0.26865671641791045,0.15789473684210525,0.19889502762430938
49,SP:4828e4160b70ea11e364b48db24cb68cdf86edfc,"This paper performs unsupervised classification where the number of classes is unknown. The main idea is to use the CycleGAN framework such that one can reconstruct the original image by first moving to latent space that represents another class (via the connector network), then moving back to the original latent space and going back into image space using a generator. Experiments are conducted on MNIST and CIFAR.","This paper develops an unsupervised classification algorithm using the idea of CycleGAN. Specifically, it constructs a piece-wise linear mapping (the Connector Network) between the discriminator network and the generator network. The learning objective is based on the cycle-consistency loss. Experiments show that it can achieve reasonable loss. This paper addresses an important problem, namely, unsupervised image classification, and may present interesting ideas. However, the paper is not in a good shape for publication in its current form.",0.22388059701492538,0.189873417721519,0.20547945205479454
50,SP:4a1cce61f12c68846c507130bd055b3444ac8101,"Authors improve upon dynamic routing between capsules by removing the squash function (norm normalization) and apply a layerNorm normalization instead. Furthermore, they experiment with concurrent routing rather than sequential routing (route all caps layers once, then all layers concurrently again and again). This is an interesting development since provides better gradient in conjunction with layerNorm. They report results on Cifar10 and Cifar100 and achieve similar to CNN (resnet) performance.",This paper presents a new simpler routing mechanism for capsule networks and achieves good performance on real world data sets making use of this new capsule structure along with a restnet backbone. Strong performance on the cifar10 and cifar100 datasets are presented and the network outperforms earlier versions of capsule networks. This new structure also performs well on an augmented MNIST dataset of overlapping digits (similar to the one used by Sabour et al 2017). ,0.17391304347826086,0.16,0.16666666666666666
51,SP:4c2f45c7fd0cac662a33be602985cf360b45fe4d,"This paper proposes both a general meta-learning framework with approximate probabilistic inference, and implements an instance of it for few-shot learning. First, they propose Meta-Learning Probabilistic inference for Prediction (ML-PIP) which trains the meta-learner to minimize the KL-divergence between the approximate predictive distribution generated from it and predictive distribution for each class. Then, they use this framework to implement Versatile Amortized Inference, which they call VERSA. VERSA replaces the optimization for test time with efficient posterior inference, by generating distribution over task-specific parameters in a single forward pass. The authors validate VERSA against amortized and non-amortized variational inference which it outperforms. VERSA is also highly versatile as it can be trained with varying number of classes and shots.","This work tackles few-shot (or meta) learning from a probabilistic inference viewpoint. Compared to previous work, it uses a simpler setup, performing task-specific inference only for single-layer head models, and employs an objective based on predictive distributions on train/test splits for each task (rather than an approximation to log marginal likelihood). Inference is done amortized by a network, whose input is the task training split. The same network is used for parameters of each class (only feeding training points of that class), which allows an arbitrary number of classes per task. At test time, inference just requires forward passes through this network, attractive compared to non-amortized approaches which need optimization or gradients here.",0.19047619047619047,0.2033898305084746,0.19672131147540983
52,SP:4d5b993c6be6e55bdf98eca9a3b23a1bab5d2499,This paper presents 'Multimodal Factorization model' that factorizes representations into shared multimodal discriminative factors and modality specific generative factors. This work applies 'Wassertein Auto-Encoders' by Tolstikhin et al (with proofs that this setup works in the multimodal case) for handling factorized joint distributions over the multimodal space. Can this method be considered as a generalization of the wasserstein autoencoder based method with a broader application? - the authors should discuss this more broadly in the paper.,"Multimodality learning is an important topic in multimedia and human computer interaction.  How to efficiently leverage the additional information cross multimodality is the key to the task. Authors proposed the Bayesian latent variable model to factorize the multimodality representation into multimodal discriminative factors and modality-specific generating factors, which is interesting. Approximate inference is also proposed to learn this model via a generalised mean-field assumption. ",0.14473684210526316,0.16666666666666666,0.15492957746478875
53,SP:50a5e5227932ff1196706f53fb82f1785da45e2a,The paper addresses limitations of the LTSM method for modeling time series. The work is motivated by applications where multiple time series need to be combined while they may get updated in an asynchronous fashion. Authors mention IoT applications in the Intro and give examples from a power consumption data set and a churn prediction application in their numerical experiments sections. ,"This paper proposes a new type of recurrent neural network which takes into account five different features: in addition to the prevalent dense features, the author(s) also consider(s) sparse features, time features, global static and changing features. The differences in feature types are reflected in the cell state or output state update rules. Experiments on a modified UCI dataset and a proprietary dataset show that the proposed model outperforms the time-variant LSTM (TLSTM).",0.18032786885245902,0.14473684210526316,0.16058394160583944
54,SP:50f9dcac485552f2925839151da4dd8d82e35fcc,This submission belongs to the field of text-to-speech synthesis. In particular it looks at a novel way of formulating a normalising flow using 2D rather than conventional 1D representation. Such reformulation enables to provide interpretations to several existing approaches as well as formulate a new one with quite interesting properties. This submission would benefit from a discussion of limitations of your approach. ,"This paper re-organized the high dimensional 1-D raw waveform as 2-D matrix. This method simulated the autoregressive flow. Log-likelihood could be calculated in parallel. Autoregressive flow was only run on row dimension. The number of required parameters was desirable to synthesize high-fidelity speech with the speed faster than real time. Although this method could not achieve top one in ranking in every measurements, the resulting performance was still obtained with the best average results. ",0.125,0.10126582278481013,0.11188811188811189
55,SP:51810c5f8d40d9ec40469349f1612bf2eefe9aad,"In this work, the authors considers a variation of GAN by consider simultaneously decrease the probability that real data is real for the generator. To include such a property, the authors propose a relativistic discriminator which estimate the probability that the given real data is more realistic than the fake data. Numerical results are performed to show that the proposed methods are effective, and the resulting GANs are relatively more stable and generate higher quality data samples than their non-relativistic counterparts.","The paper describes an interesting tweak of the standard GAN model (inspired by IPM based GANs) where both the generator and the discriminator optimize relative realness (and fakeness) of the (real, fake) image pairs. The authors give some intuition for this tweak and ran experiments with CIFAR10 and CAT datasets. Different variants of the standard GAN and the new tweak were compared under the FID metric. The experimental setup and details are provided; and the code is made publicly available. ",0.1951219512195122,0.2,0.19753086419753088
56,SP:57538c4cac6a4510a0c79e6da3deffae4d6c3b91,"This study explores the class hierarchy to solve many-class few-short learning problem in both traditional supervised learning and meta-learning. The model integrates both the coarse-class and fine-class label as the supervision information to train the DNN, which aims to leverage coarse-class label to assist fine-class prediction. The core part in the DNN is memory-augmented attention model that includes at KNN classifier and Memory Update mechanism. The re-writable memory slots in KNN classifier aim to maintain multiple prototypes used to describe the data sub-distribution within a class, which is insured by designing the memory utility rate, cache and clustering component in Memory Update mechanism. This study presents a relatively complex system that combines the idea of matching networks and prototypical networks.","This paper presents methods for (1) adding inductive bias to a classifier through coarse-to-fine prediction along a class hierarchy and (2) learning a memory-based KNN classifier through an intuitive procedure that keeps track of mislabeled instances during learning. Further, the paper motivates focused work on the many class / few shot classification scenario and creates new benchmark datasets from subsets of imagenet and omniglot that match this scenario. Experimental results show gains over popular competing methods on these benchmarks.",0.11538461538461539,0.18518518518518517,0.14218009478672988
57,SP:5d9517fa62cd97b94ff45f645e100a8ad631e281,"The paper proposes a transformer block with higher-order interactions. More precisely, instead of computing a dot product between a query vector and a key vector, 2-simplicial attention computes scalar triple product. Instead of computing a weighted average of value vectors, 2-simplicial attention computes the weighted average of tensor products of value vectors. The resulting architecture has improved representation power which is demonstrated using experiments on bridge BoxWorld environment.","C1. Simplicialization of attention. Interpreting standard attention weights of a head as the model’s estimate of the probability of an edge = 1-simplex linking the variables encoded by 2 blocks of the Transformer, representing that the blocks stand in a binary relation encoded in the head, a generalization to 2-simplexes is made: now attention also estimates the probability of a 2-simplex indicating that three blocks stand in an arity-3 relation. ",0.14084507042253522,0.13513513513513514,0.13793103448275862
58,SP:5ec05ac5d72e8e0b39b15a0cd7b2f5a64e861024,"In the setting of online convex optimization, this paper investigates the question of whether adaptive gradient methods can achieve “data dependent” logarithmic regret bounds when the class of loss functions is strongly convex. To this end, the authors propose a variant of Adam - called SAdam - which indeed satisfies such a desired bound. Importantly, SAdam is an extension of SC-RMSprop (a variant of RMSprop) for which a “data independent” logarithmic bound was found. Experiments on optimizing strongly convex functions and training deep networks show that SAdam outperforms other adaptive gradient methods (and SGD).  ","In this paper, the authors propose a variant of Adam, named as SAdam, and establish a data-dependent O(log T) regret bound. The key idea is using a faster decaying yet under controlled step size to exploit strong convexity. Some experiments are carried out to demonstrate the effectiveness of the proposed algorithm. The idea seems interesting, the writing is well-written, and the analysis seems correct (I did not fully check all steps, but the key steps seems ok to me). ",0.1827956989247312,0.2073170731707317,0.19428571428571426
59,SP:5ff0668b433a190d87d5833d8b2a8ca04daa299c,"Sliced Inverse Regression is a well-known technique for finding EDR space in supervised dimension reduction problems, under condition that input X is normally disributed. When the number of dimensions is large and an access to observations is online, finding eigenvalues of covariance matrices (online) could become computationally costly. So, the paper focuses the problem of updating few principal components of covariance matrices as new examples come.","This paper proposes an online learning algorithm for supervised dimension reduction, called incremental sliced inverse regression (ISIR). The key idea is converting the SIR problem into PCA problem by using the inverse of covariance matrix. After the transformation, we can use incremental PCA to compute the top eigenvector and obtain the approximate solution of SIR in streaming way. The authors also extend ISIR to overlapping case.",0.16417910447761194,0.16666666666666666,0.16541353383458648
60,SP:60628f7db9cfcac3f0dbe6ce0b2a161310525ba0,"This paper is about a multi-view framework for learning sentence representations. Two objective functions (a generative one and a discriminative one) are proposed that make use of two encoders, one of them is based on an RNN and the other on a linear projection of averaged word embeddings. Each of these objective functions has a multi-view framework where their respective objective functions are in part based on making sure their is some relationship between the two different encoders. This multi-view framework is shown to be helpful over having independent encoders in their ablation study.","This paper presents a multiview framework for sentence representation in NLP tasks. Authors propose two architectures, one using a generative objective, while the other uses a discriminative objective. Both combine a recurrent based encoding function and a linear model. Large experiments have been conducted on several NLP tasks and datasets, showing improvement of the introduced frameworks compared to baselines.",0.18556701030927836,0.3050847457627119,0.23076923076923078
61,SP:614f742a75039b1509343d53e0fb4a6d4088ab3e,"This paper proposes a technique for learning a distribution over parameters of a neural network such that samples from the distribution correspond to performant networks. The approach effectively encourages sampled parameters to have low loss on the training set, and also uses an adversarial loss to encourage the distribution of parameters to be Gaussian distributed. This approach can improve performance slightly by using ensembling and can be useful for uncertainty estimates for out-of-distribution examples. The approach is tested on a few simple problems and is shown to work well.","This works propose a new approach to learn to sample (or generate) the parameters of a deep neural networks to solve a task. They propose a new architecture inspired by hyper networks and adversarial auto-encoders, where the parameters of the networks are generated from a low dimensional latent space. By using an ensemble of networks sampled with their approach they're able to get state of the art results on uncertainty estimation.",0.18681318681318682,0.2328767123287671,0.2073170731707317
62,SP:622b0593972296a95b630a4ece1e959b60fec56c,This paper proposes a novel modular neural architecture for algorithm induction. The modules are fixed and a controller policy is learned which outputs a distribution over modules and input/output locations on a memory tape. An oracle (which knows the correct answer) is necessary to decide when to stop computing. The controller is trained by a variant of REINFORCE.,"This paper proposes Modular Algorithm Induction Network (MAIN) that learns algorithms given input-output examples. MAIN is equipped with several components that make it perform better than baselines, but probably the most important part is its use of modules to break-down algorithmic tasks into simpler problems. MAIN is learned end-to-end using reinforcement learning and demonstrated to perform well in several tasks.",0.2033898305084746,0.1875,0.1951219512195122
63,SP:6306417f5a300629ec856495781515c6af05a363,"The paper is about using classical PIC/FLIP scheme in Computational Fluid Dynamics for solving the learning problem of 3D object detection and segmentation. In general, there are extrinsic CNNs like the Vox net etc. which look for global features which the authors refer to as Eulerian formulation of the data representation, and there are intrinsic CNNs like the GCN(graph convolutions), Point nets etc. which look for localized neighborhood information which the authors refer to as Lagrangian formulation. The authors acknowledge that hybridizing the extrinsic CNNs and intrinsic CNNs is not new and several works are cited. The key contribution is to look at this problem from the perspective of PIC/FLIP scheme which has been used in CFD for decades. ","The paper presents a method for point-based learning that is inspired by a hybrid Eulerian-Lagrangian fluid simulation method. The work first explains how the simulation algorithm is mapped to the learning problem: MLPs are employed to learn sets of particle based features which are mapped to a Eulerian grid. A second MLP infers a particle based velocity, which is likewise mapped to the grid and used to advect the grid quantities. This is repeated for a certain number of steps to obtain final positions. The ""warped"" features are then projected back onto the particles to solve, e.g., a classification task. In contrast to a typical flow solver, the motion can be divergent, i.e., not necessarily conserves volume.",0.18032786885245902,0.18181818181818182,0.1810699588477366
64,SP:63c452f2b2cbfeea0b45831bd7dc1ac26883fd9f,"The paper proposes a new adversarial attack for the targeted blackbox model Unlike previous approaches which use the output layer possibly with some additional terms and regularization, the proposed approaches only rely on intermediate features. In fact, the adversarial example is based on a single intermediate layer. The adversarial examples are built by training, for each target class, a binary classifier for the class based only on the features of that layer.","This paper presents an adversarial attack based on the feature representations at different layers given the classes. Instead of only looking at the final layers, class samples in intermediate feature space information is used to attack and increase transferability at the same time. Then the noise is optimized to perturb the input so that the a specific wrong output will be more likely to chosen. The paper is clear and well-written and different interesting experiments support the claims.",0.18055555555555555,0.16455696202531644,0.17218543046357612
65,SP:6ad33c6fbdee78c13d9190601637e07d20fe024f,"This work uses GANs to recover clean faces from occluded counterparts. The effectiveness of the proposed method is verified qualitatively and quantitatively on CelebA-HQ. The proposed framework can be generalized to several face-related tasks, such as unconstrained face recognition. Although the novelty of the method is not really impressive, the proposed method seems to be useful for face-related applications and the experimental results are convincing to me.","The paper proposes a complex generative framework for image completion (particularly human face completion). It aims at solving the following challenges: 1) complete the human face at both low and high resolution; 2) control the attribute of the synthetic content; 3) without the need of complex post-processing. To achieve so, this paper proposes a progressively attentive GAN to complete face image at high resolution with multiple controllable attributes in a single forward pass without post-processing. Particularly it introduces a frequency-oriented attentive module (FAM) to attend on finer details.  ",0.15714285714285714,0.12087912087912088,0.13664596273291926
66,SP:6b0e9a8f0c046a767dce8790489b3e90e12e2c46,"This paper proposes a new trick to improve the stability of GANs. In particular the authors try to tackle the vanishing gradient problem in GANs, when the discriminator becomes to strong and is able to perfectly separate the distribution early in training, resulting in almost zero gradient for the generator. The authors propose to increase the difficulty of the task during training to avoid the discriminator to become too strong.","Authors argue that the main issue with stability in GANs is due to the discriminator becoming too powerful too quickly. To address this issue they propose to make the task progressively more difficult: Instead of providing only the samples to the discriminator, an additional (processed) bitstring is provided. The idea is that the bitstring in combination with the sample determines whether the sample should be considered true or fake. This in turn requires the decision boundary of the discriminator to become more complicated for increasing lengths of the bitstring. In a limited set of experiments the authors show that the proposed approach can improve the FID scores.",0.2714285714285714,0.17757009345794392,0.21468926553672316
67,SP:6e24a1e0aff73db6ae8558f114b644965e287e36,"This paper proposed a dataset and designed a relevant network structure to analyze the function of horizontal and top-down connections for perceptual grouping. The used two datasets smartly isolate the requirements for exploiting Gestalt cues and object-based strategies. Appendix A detailed describes the cABC dataset, and the control experiments in Appendix B further validate the designing of the cABC. The proposed network flexibly integrates three types of connections and successfully solves both two challenges. The visualization results in Figure 4, S8 and S9 are insightful and also validate the intuitions. Overall the paper is clearly written and easy to follow.","The article tries to examine existing hypotheses from the neuroscience and perception literature by using neural networks as a computational model of the brain. Namely, the authors assess the efficiency of different strategies for solving two visual challenges, one of which is novel. The authors also evaluate the level of consistency between the performance of humans and different types of neural architectures.",0.14705882352941177,0.24193548387096775,0.18292682926829268
68,SP:6f94f59bc936a11d95ded7309dc2458fee6d2595,"The paper proposes a method for neural network training under a hard energy constraint (i.e. the method guarantees the energy consumption to be upper bounded). Based on a systolic array hardware architecture the authors model the energy consumption of transferring the weights and activations into different levels of memory (DRAM, Cache, register file) during inference. The energy consumption is therefore determined by the number of nonzero elements in the weight and activation tensors. To minimize the network loss under an energy constraint, the authors develop a training framework including a novel greedy algorithm to compute the projection of the weight tensors to the energy constraint.","The paper is dedicated to energy-based compression of deep neural networks. While most works on compression are dedicated to decreasing the number of parameters or decreasing the number of operations to speed-up or reducing of memory footprint, these approaches do not provide any guarantees on energy consumption. In this work the authors derived a loss for training NN with energy constraints and provided an optimization algorithm for it. The authors showed that the proposed method achieves higher accuracy with lower energy consumption given the same energy budget. The experimental results are quite interesting and include even highly optimized network MobileNetV2.",0.20754716981132076,0.21568627450980393,0.21153846153846154
69,SP:724870046e990376990ba9f73d63d331f61788d7,"DDPG is a popular RL method for continuous control problems. It is more widely applicable than traditional model-based approaches like MPC, since it doesn't require differentiable models of the dynamics. However, in many environments, dynamics are differentiable. This paper proposes a method for extending DDPG to exploit simulator gradients. In particular, the Bellman error objective (which is defined in terms of critic values) used for training the critic is augmented with additional terms defined in terms of gradients of the critic. This leads to faster convergence in practice on a range of benchmarks.","This paper studies optimal control problems where a physical simulator of the system is available, which outputs the gradient of the dynamics. Using the gradients proposed by the model, the authors propose to add two additional terms in the loss function for critic training in DDPG, where these to terms corresponding to the prediction error of $\nabla_{a} Q(s,a)$ and $\nabla_b Q(s,a)$, respectively. However, my main concern is that the form of gradient given in equation (2) might contains an error.",0.17894736842105263,0.19767441860465115,0.1878453038674033
70,SP:762729b64c1c1494de0f7410ea3662da61e93b6d,"In this paper, the authors developed a neural network architecture to address the spacial and temporal unsmoothness problem, which was claimed to be neglected by existing works. The proposed model, CGT, has an encoder-decoder structure, and is characterized by clustering modules for spacial regions based on their temporal patterns. To handle temporal unsmoothness, additivity-preserved multi-view position encoding was proposed to characterize different temporal relationships. The experimental results on real ride-hailing datasets demonstrate the effectiveness of the proposed method to some extent.","This paper proposes a clustering attention-based approach to handle the problem of unsmoothness while modeling spatio-temporal data, which may be divided into several regions with unsmooth boundaries. With the help of a graph attention mechanism between vertices (which correspond to different regions), the CGT model is able to model the (originally unsmooth) cross-region interactions just like how Transformers are applied in NLP tasks (where words are discrete). Experiments seem to suggest a big improvement when compared to baselines.",0.16470588235294117,0.1728395061728395,0.16867469879518074
71,SP:7709a8b907c5642479e7b6fb0b362efc4ead63ce,"This paper proposes to improve the previously work DARTS in terms of the training efficiency, from the large memory and computing overheads. The authors propose a partially-connected DARTS (PC-DARTS) with two components: 1. Partial channel connection 2. edge normalization. To be detailed, they sample a small part of channels to perform connection and add edge normalization to eliminate the potential optimization problem. The results on CIFAR-10 and IamgeNet show the approach is effective, especially in ImageNet, the approach achieves SOTA results. ","The authors propose with this paper a simple extension of DARTS, a popular neural architecture search (NAS) method. This extension addresses one of the shortcoming of DARTS: the immense memory cost. This achieved in a simple way. Instead of using all channels only a random subset is used. To account for that, the authors propose a method to normalizes edges.",0.14285714285714285,0.2,0.16666666666666666
72,SP:77f0f3779f9bdeb75ea5744ab494942a4943117b,"This work proposes using a randomly parameterized convolutional layer as additional processing of the input observation to provide data augmentation to make policies more robust to environments with different observation spaces. The empirical results are thorough, comparing with other regularization techniques, including dropout, L2 regularization, and batch normalization with the same policy gradient method, PPO on a variety of generalization in RL benchmarks. There are additional experiments of this method to check that it actually removes visual bias in a computer vision problem better than other methods. ","This paper proposes applying random convolutions to the observation space to improve the ability of deep RL agents to generalize to unseen environments. To encourage the learning of invariant features, the authors further include a loss term to align features of perturbed and unperturbed observations. Thorough experiments on multiple generalization benchmarks show that this method outperforms many previously used regularization and data augmentation techniques.",0.1839080459770115,0.25,0.2119205298013245
73,SP:795cdeb7e4f7285f2c1ac9b9a0fbac3039201ed5,"This paper proposes the idea of using differential privacy (DP) to improve the performance of outlier and novelty detection. Differential privacy was proposed as a privacy metric which limits the contribution of a single data point in the training set to the output. This property naturally controls how poisoned data would affect the output of the learned model. Under the assumption that a well-trained model would incur a higher loss on the outliers, the paper gives a theoretic bound on how this loss will decrease if there are poisoned samples in the training set. ","This paper leverages differential privacy’s stability properties to investigate its use for improved anomaly and backdoor attack detection. Under an assumption (called “uniformly asymptotic empirical risk minimization”), the authors show that difference between the expected loss of a differentially private learning algorithm on an outlier (where the expectation is taken over the randomness of the learning algorithm) and the expected loss of the same algorithm on data from the underlying distribution (expectation taken over data & randomness of the algorithm) is lower bounded by a (possibly/hopefully) non-negative quantity with high probability. The authors then conduct a set of experiments to show that differential privacy improves the performance of outliers, novel examples, and backdoor attack detection. ",0.23157894736842105,0.18803418803418803,0.20754716981132076
74,SP:79ece684e3c4aca516b4ec41aa8fcb7d86449784,"This paper explored the means of tuning the neural network models using less parameters. The authors evaluated the case where only the batch normalisation related parameters are fine tuned, along with the last layer, would generate competitive classification results, while using very few parameters comparing with fine tuning the whole network model. However, several questions are raised concerning the experiment design and analysis:","the paper introduces a new way of fine-tuning neural networks. Instead of re-training the whole model or fine-tuning the last few layers, the authors propose to fine-tune a small set of model patches that affect the network at different layers. The results show that this way of fine-tuning is superior to above mentioned typical ways either in accuracy or in the number of tuned parameters in three different settings: transfer learning, multi-task learning and domain adaptation.",0.2222222222222222,0.17073170731707318,0.19310344827586204
75,SP:7a0db1e8804defc5c04e0f4dd345272c6df1ff77,"To enforce sparsity in neural networks, the paper proposes a scale-invariant regularizer (DeepHoyer) inspired by the Hoyer measure. It is simply the ratio between l1 and l2 norm, which is almost everywhere differentiable, and enforces element-wise sparsity. It further proposes the Hoyer measure to quantify sparsity and applies the DeepHoyer in DNN training to train pruned models. The extension of Hoyer-Square is also straightforward. ","The paper focuses on sparse neural networks. Typically, l1 regularization is the go-to strategy, however, it is not scale invariant. That is, all weights are affected by the regularization, not only those that are being driven to 0. l0 regularization is theoretically optimal, however, it is not smooth and has no gradients almost everywhere, so it cannot be used for training. As a compromise the paper proposes Hoyer regularization, that is the l1/l2 ratio. The Hoyer regularization has the same minima structure and leads to sparse solutions while being scale invariant, that is it does not affect all weights in the process. Additionally, the paper proposes structured Hoyer regularization. Last, it employs the said regularizations in deep networks: LeNet, AlexNet and ResNet on several datasets: MNIST, CIFAR, ImageNet.",0.29850746268656714,0.15384615384615385,0.20304568527918782
76,SP:7b65eb83b0d3149f788ab11b1ab9057b440ddd57,"This papers proposed a solution to the problem of disease density estimation using satellite scene images. One common challenge in this type of applications is having a high intra-class diversity and a high inter-class similarity. The solution proposed by the authors is based on the use of siamese networks to extract features from pairs of neighbouring images, and merge the features only if they are similar. The authors claim that this approach alleviate the need of a post-classification smoothing.  ","The paper proposes to do a coupled inference over pairs of geographically close images instead of a single image for satellite imagery. The coupling is done with an average pooling of the feature vectors when the neighbouring patches are detected to be similar enough based on a threshold on the L2 distance of these features. The method is applied to tasks of estimating crowding population, and diseases density, from satellite images. ",0.17073170731707318,0.19718309859154928,0.18300653594771243
77,SP:7bf79b020c2cafaced61f2595ad17e8238c3dc5d,"In this paper, the authors propose a spatial-Winograd pruning framework, consisting of spatial structured pruning and Winograd direct pruning.  First, spatial structured pruning allows the pruned weight in the spatial domain to be kept in the Winograd domain. Then, Winograd direct pruning can further improve the sparsity in the Winograd domain. The organization of paper is OK.  The main concern is about the practical part. In the experiment, the advantage of propose framework is marginal, compared to the relevant approaches.  More comparisons with the state-of-the-art approaches should be investigated, such as light-weight design (MobileNet, ShuffleNet).  ","The paper proposes a technique (well, two) to prune convolutional layers to reduce the required amount of computation when  the convolutions are done using the winograd algorithm. Winograd convolutions first transform the image and the filter, apply a multiplication in the transformed space, and then retransform the image back to the intended image space. The transformation of the filter, however, means that sparsity in the regular domain does not translate to sparsity in the winograd domain.",0.19,0.25,0.2159090909090909
78,SP:7e70c97e9b7b182e974b071c93baafef8b11cf90,"This paper proposes guiding program synthesis with information from partial/incomplete program execution. The idea is that by executing partial programs, synthesizers can obtain the information of the state the (partial) program ended in and can, therefore, condition the next step on that (intermediate) state. The paper also mentions ensembling synthesizers to achieve a higher score, and by doing that it outperforms the current state-of-the-art on the Karel dataset program synthesis task.","This paper presents two new ideas on leveraging program semantics to improve the current neural program synthesis approaches. The first idea uses execution based semantic information of a partial program to guide the future decoding of the remaining program. The second idea proposes using an ensembling approach to train multiple synthesizers and then select a program based on a majority vote or shortest length criterion. The ideas are evaluated in the context of the Karel synthesis domain, and the evaluation shows a significant improvement of over 13% (from 77% to 90%).",0.26666666666666666,0.21978021978021978,0.24096385542168675
79,SP:7f07f3fa8a10b48bb380a7c84bc012ce3541122b,"In this paper, the authors propose a policy gradient algorithm for solving a Bayes-Adaptive MDP (BAMDP). At each iteration, the algorithm samples several MDPs from the prior distribution and simulates a trajectory for each sampled MDP. During the simulation, the algorithm uses a Bayes filter to update the posterior belief distribution at each time step. Finally, the algorithm uses the sampled trajectories and update the policy using the TRPO algorithm. ","This paper proposes a policy optimization framework for Bayesian RL (BPO). BPO is based on a Bayesian model-based RL formulation. Using a Bayesian approach, it is expected to have better trade-off between exploration and exploitation in RL, and be able to deal with model uncertainty as well. Experiments are done on multiple domains consisting both POMDP planning tasks and RL.",0.1267605633802817,0.14516129032258066,0.13533834586466165
80,SP:7f91f3805bd643e3b796e885b00f88a77aa49d15,"The main contribution of the paper is an integral model compression method that handles both weight and activation pruning. Increasing the network weight and activation sparsity can lead to more efficient network computation.  The authors show in the paper that pruning the network weights alone may result in a decrease in activation sparsity, which may not necessarily improve the overall computation. The proposed solution is a 2-stage process that first prunes the weights and then the activation. ","This article presents a novel approach called Integral Pruning (IP) to reduce the computation cost of Deep neural networks (DNN) by integrating activation pruning along with weight pruning. The authors show that common techniques of exclusive weight pruning does compress the model size, but increases the number of non-zero activations after ReLU. This would counteract the advantage of DNN accelerator designs (Albericio et al., 2016; Reagen et al., 2016) that leverage activation sparsity to speed up the computations. IP starts with pruning the weights using an existing technique to mask out weights under a threshold and then fine-tune the network in an iterative fashion to maintain the accuracy. After weight pruning, IP further masks out the activations with smaller magnitude to reduce the computation cost. Unlike weight pruning techniques that use static masks, the authors propose to use dynamic activation masks for activation sparsity in order to account for various patterns that are being activated in DNN for different input samples. In order to do this, the 'winner rate' measure for every layer (or for a group of layers in deep networks like ResNet32) is defined, to dynamically set the threshold for the generation of activation masks which eventually controls the amount of non-zero activation entries. The article empirically analyzes the sensitivity of activation pruning on validation data by setting different winner rates at every layer in DNN and decides upon a set of winner rates accordingly followed by an iteration of fine-tuning the network to maintain its performance. The authors show that their technique produced lower number of non-zero activations in comparison with the intrinsic sparse ReLU activations and weight pruning techniques. ",0.34615384615384615,0.09712230215827339,0.15168539325842698
81,SP:8188f15c8521099305aa8664e05f102ee6cea402,"This paper presents ODD, a method that rejects incorrectly labeled / noisy examples from training on the fly. The motivation is sound, that with the capacity of modern neural networks, it's easy to memorize the mislabeled data and thus hurt generalization. If we could reject such mislabeled data, we may be able to get a more generalizable model. The authors made an observation that when training with large learning rate, examples with correct labeling and incorrect labeling exhibits different loss distributions. The authors further noticed that the loss distribution of incorrectly labeled examples can be simulated using eq.(1). Therefore, by setting a threshold that corresponds to a percentile of the incorrectly labeled loss distribution, the authors are able to reject incorrect examples.","The paper aims to remove potential examples with label noise by discarding the ones with large losses in the training procedure. The idea also applies to the setting where instances may contain large noise. The proposed method may have an implicit trade-off between the robust to label noise and feature noise, which explains why the proposed method also has good performances on instance-dependent label noise. The paper is well-written and has sufficient experiments. ",0.11382113821138211,0.18421052631578946,0.1407035175879397
82,SP:81d7c60d0d12eb268d7edeebe86422991a1d4997,"This paper provides an analysis of fitted Q-iteration in the off-policy reinforcement learning setting, for the setup where the value function class of interest is a class of neural networks. The provide bounds on the rate at which fitted Q iteration converges to a near-optimal policy under the assumption that the transition dynamics satisfy a certain notion of Holder smoothness. This result is motivated by the problem of understanding why deep Q-learning works, which the authors relate to the problem above via certain simplifying assumptions. The authors also extend this result to give similar guarantees for two-player zero-sum stochastic games.","The authors provide a theoretical analysis of deep Q-learning based on the neural fitted Q-iteration (FQI) algorithm [1]. Their analysis justifies the techniques of experience replay and target network, both of which are critical to the empirical success of DQN. Moreover, the authors establish the algorithmic and statistical errors of the neural FQI algorithm.",0.16037735849056603,0.30357142857142855,0.20987654320987653
83,SP:827f95cdefae78e38a9c4b5718fcf294606a1989,"This paper studies the problem of learning the parameter of one hidden layer neural network with sigmoid activation function based on the negative log likelihood loss. The authors consider the teacher network setting with Gaussian input, and show that gradient descent can recover the teacher network’s parameter up to certain statistical accuracy when the initialization is sufficiently close to the true parameter. The main contribution of this paper is that the authors consider the classification problem with negative log likelihood loss, and provide the local convergence result for gradient descent. However, based on the previous results in Mei et al., 2016 and Zhong et al., 2017, this work is incremental, and current results in this paper is not strong enough. To be more specific, the paper has the following weaknesses:","This paper studies the problem of recovering a true underlying neural network (assuming there exists one) with cross-entropy loss. This paper shows if the input is standard Gaussian, within a small ball around the ground truth, the objective function is strongly convex and smooth if there is a sufficiently large number of samples. Furthermore, the global minimizer is actually the true neural network. This geometric analysis implies applying gradient descent within this neighborhood, one can recover the underlying neural network. This paper also proposed a provable method based on spectral learning to find a good initialization point. Lastly, this paper also provides some simulation studies.",0.1984732824427481,0.24528301886792453,0.21940928270042193
84,SP:82b8270b33110e50b5914246f3ca75d3bdbffb6e,"Batch Normalization (BN) suffers from 2 flaws: 1) It performs poorly when the batch size is small and 2) computing only one mean and one variance per feature might be a poor approximation for multi-modal features. To alleviate 2), this paper introduces Mode Normalization (MN) a new normalization technique based on BN. It uses a gating mechanism, similar to an attention mechanism, to project the examples in the mini-batch onto K different modes and then perform normalization on each of these modes.","The paper proposes a generalisation of Batch Normalisation (BN) under the assumption that the statistics of the unit activations over the batches and over the spatial dimensions (in case of convolutional networks) is not unimodal. The main idea is to represent the unit activation statistics as a mixture of modes and to re-parametrise by using mode specific means and variances. The ""posterior"" mixture weights for a specific unit are estimated by gating functions with additional affine parameters (followed by softmax). A second, similar variant applies to Group Normalisation, where the statistics is taken over channel groups and spatial dimensions (but not over batches). ",0.15476190476190477,0.125,0.13829787234042554
85,SP:845ae21e5758a8aabfa610c291fdcc5f61af7748,"This paper studies an interesting and meaningful topic that what is the potential of curriculum learning (CL) in training dnn.  The authors decompose CL into two main parts: scoring function and pacing function. Towards both parts, several candidate functions are proposed and verified.  The paper is presented quite clear and gives contribution to better understand CL in the literature of DNN.","This problem of interest in this paper is Curriculum Learning (CL), in the context of deep learning in particular. CL refers to learning a non-random order of presenting the training examples to the learner, typically with easier examples presented before difficult ones, to guide learning more effectively. This has been shown to both speed up learning and lead to better generalization, especially for more challenging problems. In this paper, they claim that their contribution is to decompose the problem of CL into learning two functions: the scoring function and the pacing function, with the role of the former being to estimate the difficulty of each training example and the latter to moderate the schedule of presenting increasingly more challenging examples throughout training.",0.3770491803278688,0.18699186991869918,0.24999999999999994
86,SP:84a83ee258d5bc613b7d73045477018b8a56c56d,"In this work, the authors suggest a new point of view on generalization through the lens of the distribution of the per-sample gradients. The authors consider the variance and mean of the per-sample gradients for each parameter of the model and define for each parameter the Gradient Signal to Noise ratio (GSNR). The GSNR of a parameter is the ratio between the mean squared of the gradient per parameter per sample (computed over the samples) and the variance of the gradient per parameter per sample (also computed over the samples). The GSNR is promising as a measure of generalization and the authors provide a nice leading order derivation of the GSNR as a proxy for the measure of the generalization gap in the model. After the derivation, experimental results on MNIST are presented and suggest that empirically there is a relation between the generalization gap of neural network trained by gradient descent and the GSNR quantity given in the paper. Next the author analyze the GNSR of DNNs as opposed with shallow models or other learning techniques and observe that the GSNR differs when using random labels (lower GSNR) as compared with true labels and exhibits different behavior along training for DNNs and gradient descent.","This paper introduces a quantity termed the ""one-step generalization ratio"" . They derive approximate relations between OSGR and GSNR then show experimental results demonstrating the validity of these approximations, thus linking GSNR and a quantity related to generalization. They investigate the empirical value of GSNR during training of a neural network on Cifar10 with real labels vs. random labels. The final section derives a relation which attempts to explain the correlation between the size of the expected gradient and the learning of features.",0.12077294685990338,0.30120481927710846,0.17241379310344826
87,SP:861c5336fda684e5bdd8a05f0af10dd442bf5339,"In this paper, the authors proposed a new format of representation called scene programs, to describe the visual scenes. To extract the scene programs from scenes, the authors exploited the off-the-shelf object detection and segmentations model, mask r-cnn to extract all objects and the corresponding attributes from the images, and then detect groups for those objects, which are then used to generate the programs which matches the input scenes. The experiments are performed on a synthetics datasets which consists of multiple shapes with different attributes. The experiments shows that the proposed model can infer more accurate programs from the scenes, and those generated programs can be used to recover the input scenes more accurately. Besides, the authors also showed that the generated scene programs can be used for image editing and making visual analogy.","This paper presents a system that infers programs describing 3D scenes composed of simple primitives. The system consists of three stages each of which is trained separately. First, the perceptual module extracts object masks and their attributes. The objects are then are split into several groups. Finally, each group is mapped to a corresponding DSL program using a sequence-to-sequence network similar to the ones typically employed in neural machine translation.",0.13138686131386862,0.25,0.1722488038277512
88,SP:868dd531fe7886b0260295d25b75cc6d6d28f12d,"This paper uses the idea from 'A Persona-Based Neural Conversation Model' by Li et al and incrementally applies it to the 'Multi-turn Dialogue Response Generation in an Adversarial Learning Framework' work-in-progress by Olabiyi et al. The paper by Olabiyi uses the idea of adversarial training to the HRED work by Xing et al (Hierarchical Recurrent Attention Network for Response Generation). The paper shows very promising results for controlling the response generation based on input attributes with adversarial training. Compared to the persona based model, this work seems to outperform that model significantly as reported in Table 1 (in terms of Perplexity/Bleu). It would have been great to see the quantitative comparison in terms of other metrics (if the authors could try to reproduce their results). There are other interesting ways to incorporate attribute information into the dialogue model such as reported in the work of Lee et al (SCALABLE SENTIMENT FOR SEQUENCE-TO-SEQUENCE CHATBOT RESPONSE WITH PERFORMANCE ANALYSIS) - since this paper is primarily about personalization of responses - a comparison to some of the methods used in Lee's work would have been very relevant and made the paper much more convincing in terms of core contributions. The model and architecture is pretty convincing but the paper lacks more in-depth analysis, comparison and evaluation of the model.","This paper proposes an extension to hredGAN, which is an adversarial framework for multi-turn dialogue model, to simultaneously learns a set of attribute embeddings that represents the persona of each speaker and generate persona-based responses. The generator of the proposed system phredGAN is conditioned on both the history utterances and the speakers’ persona by concatenating the utterance encoding with attribute embeddings. For discriminator, the authors explore two versions: 1) phredGAN_a takes attributes as inputs; 2) phredGAN_d adds a dual discriminator that predicts the attribute(s) for each utterance. ",0.09417040358744394,0.22826086956521738,0.13333333333333333
89,SP:87dc93d26ad5ad4a8dccde1780b5b127f391cfd6,"This paper proposes a new method of scaling multi-agent reinforcement learning to a larger number of agents using evolution. Specifically, the procedures (EPC) involves starting with a small number of agents, training multiple sets in parallel, and doing crossover to find the set of agents that generalize best to a larger number of agents. This is motivated by the intuition that agents that perform best in small groups may not be the ones that perform best in larger groups. These claims are empirically verified in three games based on the particle world set of environments. ","The paper proposes a kind of curriculum for large-scale multi-agent learning. The related work section mentions some obvious points of comparison (note: see also https://science.sciencemag.org/content/364/6443/859.abstract). However, the authors do not compare with ANY of this work (either in terms of algorithm design or performance). It is therefore difficult to evaluate the contribution. ",0.15625,0.24193548387096775,0.189873417721519
90,SP:8a5e86b6770a3c08f861fbf682296dc3a6c02204,"This paper studies the problem of representing data records with potentially sensitive information about individuals in a privacy-preserving fashion such that they can be later used for training learning models. Informally, it is expected from the transformed output of data record, one should be able to learn about a desired hidden variable, but should not be able to learn anything about a sensitive hidden variable. To that end, the paper proposes a KL divergence based privacy notion, and an algorithmic approach to learn a representation while balancing the utility privacy trade-off.","This paper proposes a privacy framework where a privatizer, according to the utility and secret specified by users, provides a sanitized version of the user data which lies in the same space as the original data, such that a utility provider can run the exact algorithm it uses for unsanitized data on the sanitized data to provide utility without sacrificing user privacy. The paper shows an information theoretic bound on the privacy loss and derives a loss function for the privatizer to use. It then proposes an algorithm for the privatizer, evaluates its performance on three scenarios.",0.20430107526881722,0.1958762886597938,0.2
91,SP:8ab0bb3eb38958d607fe6b6ebbd921b8abdf149d,"This paper studies the problem of generating contracts by a principal to incentive agents to optimally accomplish multiagent tasks. The setup of the environment is that the agents have certain skills and preferences for activities, which the principal must learn to act optimally. The paper takes a combined approach of agent modeling to infer agent skills and preferences, and a deep reinforcement learning approach to generate contracts. The evaluation of the approach is fairly thorough.",This paper proposes a way to train a manager agent which would manage a bunch of worker agents to achieve a high-level goal. Each worker has its own set of skills and preferences and the manager tries to assign sub-tasks to these agents along with bonuses such that the agents can even perform tasks that are not preferred by them. Authors achieve this by training a manager which tracks the skills and preferences of the agents on the fly. Authors have done an extensive analysis of the proposed approach in two simple domains: resource collection and crafting.,0.28,0.21212121212121213,0.2413793103448276
92,SP:8aeece75c839643a02d2b3b5f3aca7cb76cf1d35,"The paper proposed a adversarial learning framework that tries to align the hidden features of data with simple prior distributions.  A training strategy similar to GAN  was exploited. The proposed framework was argued that it can well deal with the adversarial perturbations. Some experiments were conducted, verifying that the proposed algorithm seems useful and robust.",This paper proposes a new regularization technique called Embedding Regularization to improve the adversarial robustness.  The idea is to use generative adversarial networks (GAN) to perform inference on the latent space by matching the aggregated posterior of the hidden space vector with a prior distribution. The proposed strategy could be combined with adversarial training to achieve state-of-the-art adversarial accuracy on several benchmark datasets. ,0.23636363636363636,0.19696969696969696,0.21487603305785122
93,SP:8cf0614f0fbd3756453304703d00776cfc9a4b9f,"This paper presents a method to speed up training of deep neural networks. The main contribution is a method to quickly identify winning lottery tickets (denoted early-bird, or EB by the authors), without running the model to convergence. The authors present interesting preliminary experiments that motivate their method, and show that it works on two image recognition datasets using two models.","The authors further study the lottery ticket hypothesis formulated by Frankle and Carbin. They demonstrate that the sparsity pattern corresponding to a lottery ticket for a given initialization can be uncovered via low-cost training. By doing so, they propose a method to: 1) first identify the lottery ticket efficiently and 2) exploit the sparsity of the resulting network to train it at a lower cost.",0.1774193548387097,0.16666666666666666,0.171875
94,SP:8df1599919dcb3329553e75ffb19059f192542ea,"This paper proposes a method for continual learning. The model has three components: a) a data generator to be used at training time to replay past examples, b) a parameter generator that takes the input observation to produce parameters for c) the actual classifier. The authors demonstrate the method on simple datasets with a stream of 2 or 3 tasks.",This paper proposes a Dynamic Parameter Generator (DPG) that given a test input modifies the parameters of a classification model. They also propose to regularize the training using a Data Generator (DG) to slow down catastrophic forgetting. DG is used to constrain the training that the internal representations of data generated by DG does not rapidly change. DG removes the need for storage of data or labels.,0.2833333333333333,0.2537313432835821,0.2677165354330709
95,SP:8fd4f3f8615c0a7a76ec7bfe996d2ead803f7828,The paper proposes to use the triplet loss as a convex relaxation of the ordinal embedding problem. The loss is solved using feed-forward neural network with the input to the network being the ids of the items encoded in binary codes. The benefit of using a deep network is to exploit its optimization capability and the parallelism on GPUs. The experiments presented in the paper include a set of simulation experiments and a real-world task.,"Many prior works have found that the features output by the final layer of neural networks can often be used as informative representations for many tasks despite being trained for one in particular. These feature representations, however, are learned transformations of low-level input representations, e.g. RGB values of an image. In this paper, they aim to learn useful feature representations without meaningful low-level input representations, e.g. just an instance ID. Instead, meaningful representations are learned through gathered triplet comparisons of these IDs, e.g. is instance A more similar to instance B or instance C? Similar existing techniques fall in the realm of learning ordinal embeddings, but this technique demonstrates speed-ups that allow it to scale to large real world datasets.",0.19480519480519481,0.11904761904761904,0.1477832512315271
96,SP:91459c66bb597751ffce8410e283ce3f094bdd5f,"The authors are proposing a method for allowing the generation of multiple objects in generated images given simple supervision such as bounding boxes and their associated labels. They control the spatial location of generated objects by the mean of an object pathway added to the architecture of both Generator and Discriminator within a GAN framework. They show generated results on Multi-MNIST, CLEVR with discussions of their model's abilities and properties. they also provide quantitative results on MSCOCO (IS and FID) using StackGAN and AttGAN models with the object pathway modifications and show some improvements compared to the original models. However it must be noted (as commented by the authors) that these models are using image captions only and do not have explicit supervision of bounding box and object labels.","The paper proposes a simple but effective method for controlling the location of objects in image generation using generative adversarial networks. Experiments on MNIST and CLEVR are toy examples but illustrate that the model is indeed performing as expected. The experiments on COCO produce results that while containing obvious artefacts are producing output consistent with the input control signal (i.e., bounding boxes). It would however have been interesting to see more varied bounding box locations for the same caption.",0.15267175572519084,0.25,0.1895734597156398
97,SP:91761d68086330ce378507c152e72218ed7b2196,"The paper proposes an a new idea of treating the back propagated gradients using chain rule as pseudo residual targets of a gradient boosting problem. Then the weight update is done by solving the boosting problem using a linear base learner. Furthermore, to reduce computational cost incurred by solving the boosting problem, an idea proposed is only keep the diagonal terms of the matrix inversion involved. ","This paper propose an extention method of SGD, deep gradient boosting (DGB), which views the back-propagation procedure as a pseudo-residual targets of a gradient boosting problem. To apply DGB to the real CNNs, DGB is simplified to a input normalization layer, conditioned on the assumption that the convolution kernels should be small. After applying the input normalization layer to CNNs, the model could achieve comparable performance to the model with BN on CIFAR-10 and ImageNet recognition.",0.30303030303030304,0.25316455696202533,0.2758620689655173
98,SP:928640a19b0a0b1e1dc0d1b07cc99e1d51a4d817,"In this work the authors point out an issue related to graph neural networks. Specifically, if two nodes, that may be far apart in the graph, may be represented as (almost) the same vector. This is simply because when no features/labels are associated with nodes, and the local structure around those two nodes is very similar then the local aggregation of information will result in a similar representation.  Therefore the authors introduce an embedding first of the graph in the Euclidean space using DeepWalk and then use this embedding in combination with the design of a CNN. The authors propose a pooling method that outperforms several state-of-the-art pooling techniques on real data. Overall, the empirical results are supportive of the fact that the proposed method can help improve the performance of GNNs. ","The authors propose in this paper to complement the node attributes in a graph with vectors obtained using a graph embedding algorithm. More precisely, they propose a graph neural network that apply several layers of graph convolution in parallel to the node attributes and to the embedding, then takes an average of the result, which is fed to another series of graph convolution. This is combined with some form of sampling which strongly resembles median based quantization but is solved with some basic heuristics and without acknowledging the resemblance (I might be missing something). ",0.14705882352941177,0.2127659574468085,0.17391304347826086
99,SP:9371d08e2b3a821e40cc9d4757c22f6cdb731b6a,"The authors demonstrated that the loss surface visualized in parameter space does not reflect its robustness to adversarial examples. By analyzing the geometric properties of the loss surface in both parameter space and input space, they find input space is more appropriate in evaluating the generalization and adversarial robustness of a neural network. Therefore, they extend the loss surface to decision surface. They further visualized the adversarial attack trajectory on decision surfaces in input space, and formalized the adversarial robustness indicator. Finally, a robust training method guided by the indicator is proposed to smooth the decision surface.","This paper argues that analyzing loss surfaces in parameter space for the purposes of evaluating adversarial robustness and generalization is ineffective, while measuring input loss surfaces is more accurate. By converting loss surfaces to decision surfaces (which denote the difference between the max and second highest logit), the authors show that all adversarial attack methods appear similar wrt the decision surface. This result is then related to the statistics of the input Jacobian and Hessian, which are shown to differ across adversarially sensitive and robust models. Finally, a regularization method based on regularizing the input Jacobian is proposed and evaluated. All of these results are shown through experiments on MNIST and CIFAR-10.",0.26804123711340205,0.23008849557522124,0.24761904761904763
100,SP:962caffd236630c4079bfc7292403c1cc6861c3b,"The authors propose a variant of gating functions for recurrent neural networks and feed-forward layers of Transformer and apply it to variety of tasks including toy tasks such as sorting, tree traversal and more realistic tasks such as machine translation. The gating function is applied recursively for N number of steps and depth of recursion is learned softly in data-driven function. Authors show similar or slightly better performance of their approach when applied to LSTM and Transformer compared to vanilla LSTM and Transformer.  ","This paper proposes a neural sequence modelling unit called METAGROSS.  In principle, the aim of this unit is to introduce recursive parametrization of  gating functions, building on the gated RNN paradigm.  The authors motivate this work by arguing that while gated-RNNs tackle vanishing gradient problems and facilitate learning long-range dependencies in sequences, improvements can be made with respect to learning on hierarchically-structured data.  The authors propose a method to do so by also learning the depth of the parametrization, and claim that the inductive bias that emerges from this configuration is beneficial to learning such tasks.",0.15294117647058825,0.13131313131313133,0.14130434782608697
101,SP:963e85369978dddcd9e3130bc11453696066bbf3,"In this work the authors tackle the problem of generating a given graph to a target output graph.  To achieve this they develop a novel deep graph generative model. The authors place a lot of emphasis on scalability. This is indeed a major computational bottleneck in prior work, allowing the deep generative models to generate graphs with few tenths of nodes.   The authors propose an architecture that consists of a graph translator, and a conditional graph discriminator. The GAN approach is able to give significant insights into the conditional distribution p(G|H) where H is the input graph. For the graph translator, the authors design novel graph encoders and decoders. The proposed encoder-decoder achieve the best possible results, compared to using established encoder/decoders as shown in ablation study.  The authors analyze the computational complexity of their work, and while they do not discuss the computational complexities of the other methods, it is clear from the experiments that their method scales better (e.g., Figure 4). To evaluate the output of the architecture, they use a variety of different graph characteristics. The proposed method outperforms the state-of-the-art. Furthermore, the proposed method is able to detect interesting anomalies as illustrated in the appendix  (hacker detection). ","This paper studies a problem of graph translation, which aims at learning a graph translator to translate an input graph to a target graph. The authors propose an adversarial training framework to learn the graph translator, where a discriminator is trained to discriminate between the true target graph and the translated graph, and the translator is optimized by fooling the discriminator. The authors conduct experiments on both synthetic and real-world datasets. The results prove the effectiveness and the efficiency of the proposed approach over many baselines.",0.1722488038277512,0.41379310344827586,0.24324324324324326
102,SP:980babd58fc2ea5f40bb22b3a9a09737f14f3f18,"This paper described the application of BERT in the field of financial sentiment analysis. Authors find that when fine-tuned with in-domain data, BERT outperforms the state-of-the-art, demonstrating that language model pre-training can transfer knowledge learned from unsupervised large corpus to new domain with minimum effort. Experiments are conducted to explore 1) the utility of different in-domain dataset for further pre-training; 2) strategies to avoid catastrophic forgetting, and 3) effectiveness of fine-tuning a subset of the full model. ","This paper proposes a domain adaptation type of task via proposing fine-tuning of pre-trained models such as BERT on data from financial domains. The paper starts off with a good motivation about requiring some kind of domain adaptation particularly when performing tasks such as sentiment analysis on data sets from the financial domain. However, there is not much novelty in this paper.",0.13953488372093023,0.1875,0.15999999999999998
103,SP:986b9781534ffec84619872cd269ad48d235f869,"This paper addresses issues with the beam search decoding algorithm that is commonly applied to recurrent models during inference. In particular, the paper investigates why using larger beam widths, resulting in output sequences with higher log-probabilities, often leads to worse performance on evaluation metrics of interest such as BLEU. The paper argues that this effect is related to ‘search discrepancies’ (deviations from greedy choices early in decoding), and proposes a constrained decoding mechanism as a heuristic fix. ","- The paper generalizes upon past observations by Ott et al. that NMT models might decode ""copies"" (of the source sentence) when using large beam widths, which results in degraded results. In particular, the present paper observes similar shortcomings in two additional tasks (summarization and captioning), where decoding with large beam widths results in ""training set predictions."" It's unclear if this observation is novel, but in any case the connection between these observations across NMT and summarization/captioning tasks is novel.",0.1794871794871795,0.1728395061728395,0.1761006289308176
104,SP:9984d73a1fcfce932cfcafb4d200f70b07723bf3,"This submission closely builds upon an earlier work (Xie et al., 2017, Gal and Ghahramani, 2016) and proposes a new data noising technique motivated by Bayesian RNNs. Specifically, the key contribution is to extend Gal and Ghahramani (2016) to word embedding noising, while drawing inspiration from trational data smoothing techniques. Some variants are discussed, including those motivated by linear interpolation and Kneser-Ney smoothing, just as in Xie et al., 2017. Empirical evaluation is performed with language modeling experiments, and the proposed methods outperforms comparable baselines. One can imagine such a technique could be useful in many other sequence tasks. ","In this submission, the authors present a variational smoothing interpretation of the data noising approach presented in (Xie et al., 2017). Although the theoretical coverage of the problem gives interesting insights. However, a comparison to related work w.r.t. alternative regularization approaches is missing. Similarly, the perplexity values reported in the experimental results on Penn Treebank are far away from state-of-the-art results published by many competitors on this task, e.g. see the current state-of-the-art results on Penn Treebank by (Yang et al., 2017, https://arxiv.org/pdf/1703.02573.pdf and references therein). It is bad practice to ignore existing work completely like this. The interesting question here would be, inhowfar the presented smoothing/regularization methods are complementary to existing approaches, and if the presented methods do provide improvements on top of these.",0.17,0.12056737588652482,0.14107883817427386
105,SP:99c10e038939aa88fc112db10fe801b42360c8dc,"The paper proposes a using pixel-adaptive convolutions to leverage semantic labels in self-supervised monocular depth estimation. The semantic features are predicted by a pretrained network rather than relying on a ground truth. Moreover, a two-stage training process in proposed in order to filter out images leading to erroneous SfM predictions. The method is evaluated with different networks on the KITTY dataset.","This work proposes to leverage a pre-trained semantic segmentation network to learn semantically adaptive filters for self-supervised monocular depth estimation. Additionally, a simple two-stage training heuristic is proposed to improve depth estimation performance for dynamic objects that move in a way that induces small apparent motion and thus are projected to infinite depth values when used in an SfM-based supervision framework. Experimental results are shown on the KITTI benchmark, where the approach improves upon the state-of-the-art.",0.296875,0.2289156626506024,0.2585034013605442
106,SP:99ca283c579152bc44b19c21392aeb7f6b76231b,"This work presented an improvement of grid search algorithm for certain hyperparameters in deep neural nets training. These hyperparameters, such as learning rate and drop out, have ""temperature"" like meaning to control the noise injected in the training. With this analogy, the author proposed to use the idea of parallel tempering in statistical physics to allow exchange these hyperparameters during the training. Their empirical results showed this improves standard grid search.","The paper proposes a new paradigm to perform hyperparameter search by proposing a way to jointly optimize over the hyperparameter space and the parameter space as opposed to the traditional way to performing these in separation (with the hyperparameter search invoking the parameter optimization) The paper’s main claim is that this allows the seach to follow non-local paths in the joint space. The main methodology proposed in the paper is inspired by the idea of parallel tempering from physics. The paper proposes to view parameter learning under a certain hyperparameter as running a langevin chain at a particular temperature. This is motivated by considering common hyperparameters as batch size, dropout rate or learning rate as inducing a specific level of noise to the training process, the variance of which is analogous to the inverse temperature in Langevin diffusion. ",0.2676056338028169,0.1357142857142857,0.18009478672985782
107,SP:99d41c8285fd0270ff16e915ef03187a0a7005b0,"This paper tackles the problem of designing neural network architectures that are robust to adversarial attacks. Several defense techniques against adversarial attacks have been proposed, mainly adversarial training (train on perturbed inputs) and introducing random perturbation to the weights or activations of the network. The paper claims that one limitation of the second approach is that it introduces artifacts (e.g. sparsity). The authors propose a simple but original idea to address this issue: parameterize the network's weight matrices as low rank tensors (in the Tucker format) and randomize the weights by sketching the core tensor of the Tucker decomposition (in effect, the sketching amounts to randomly setting fibers of the core tensor to 0). ","In this paper, the authors propose a randomization-based tensorization framework towards robust network learning. The high-level idea of this work is to reparameterize the network parameters W of each layer with low-rank tensors, where the factor matrices are injected with randomization through randomly sampled sketching matrices. Since the randomization is is done within a subspace than directly on the weight matrix itself, the authors claim that this brings certain advantages such as less sparsity.",0.16379310344827586,0.24675324675324675,0.19689119170984457
108,SP:9a4c7d9df6685347e75e0ae72928225b7622a73c,"Proposes Counterfactual Guided Policy Search (CF-GPS), which uses counterfactual inference from sampled trajectories to improve an approximate simulator that is used for policy evaluation. Counterfactual inference is formalized with structural causal models of the POMDP. The method is evaluated in partially-observed Sokoban problems. The dynamics model is assumed known, and a learned model maps observation histories to a conditional distribution on the starting state. CF-GPS outperforms model-based policy search and a ""GPS-like"" algorithm in these domains. GPS in MDPs is shown to be a particular case of CF-GPS, and a connection is also suggested between stochastic value gradient and CF-GPS.","This paper proposes a policy evaluation and search method assisted by a counterfactual model, in contrast previous work using vanilla (non-causal) models. With “no model mismatch” assumption the policy evaluation estimator is unbiased. Empirically, the paper compares Guided Policy Search with counterfactual model (CF-GPS) with vanilla GPS, model based RL algorithm and show benefit in terms of (empirical) sample complexity.",0.1588785046728972,0.27419354838709675,0.2011834319526627
109,SP:9bcb840f867f1a7108aa22a7bb14c348fda52eb0,"This paper proposes a novel MCMC algorithm (ATMC) that estimates and samples from the posterior distribution of neural network weights. The motivation for this approach is that applying Bayesian inference to deep learning should lead to less overfitting and better uncertainty-calibrated models. Unlike previous work, the proposed method scales to large models (ResNet) and data sets (ImageNet).","The authors propose the adaptive thermostat Monte Carlo sampler for feedforward neural networks. The proposed approach dynamically adjust the amount of momentum and noisy applied to each model parameter during updates. ResNet++ (ResNet without batchnorm/dropout but adding SELU, fixup and weight normalization) is introduced. Further, the authors claim that the need for hyperparameter setup is reduced provided that early stopping, stochastic regularization and carefully tuned learning rate schedules are not required.",0.13793103448275862,0.1111111111111111,0.12307692307692307
110,SP:9be782b532e64c6aad140531a17fbba1dd3342cd,"The proposed method is too simplistic, the model being succinctly described in less than one page with many errors in the given math expressions. Only the model is given. The optimization problem, as given in (1) is not explained. the authors need to stud the optimization problem, to derive its resolution, and to describe the obtained algorithm.","The authors propose a new defense against adversarial examples based on radial basis features. Prior work has suggested that the linearity of standard convolutional networks may be a factor contributing to their vulnerability against adversarial examples, and that radial basis functions may help alleviate this weakness. The current paper builds on this idea and proposes a concrete way to add radial basis features to existing convnet architectures.",0.10526315789473684,0.08955223880597014,0.0967741935483871
111,SP:9ce5b80147ea2c7d0711ec98e31f4bbb5eac534e,"The authors learn a model that predicts the state R steps in the future, given the current state and intervening actions, instead of the predicting the next time step state. The model is then used for standard model predictive control. The authors find numerically that their method, termed Plan-Conditional Predictor (PCP), performs better over long horizon times (~100 time steps), than other recent model-based and model-free algorithms. This because for long horizon time scales, the model predicting the state for the next time step accumulates error when used recursively.","The paper proposes to use a multi-step prediction model in model-based RL. The proposed model maps from current state and a sequence of actions to the state after taking those actions. The paper demonstrates on 2 tasks that in a model-predictive control loop combined with planning by cross-entropy method, this can yield better asymptotic performance than using single-step models.",0.20652173913043478,0.296875,0.24358974358974356
112,SP:9f89501e6319280b4a14b674632a300805aa485c,"The paper propose to sparsify the attention matrix to decrease memory usage and to speed up training. The authors experiment the model on multiple tasks. The model gains ~20% efficiency with ~20% decrease in memory use while maintaining comparable performance to the state of the art model. To keep the performance comparable, the authors use the same training corpus. The authors also discuss how block size could change the performance of the model. The paper is clear and well organized with good experiment results.",This paper introduces a optimisation for BERT models based on using block matrices for the attention layers. This allows to reduce the memory footprint and the processing  time during training while reaching state-of-the-art results on 5 datasets. An interesting study on memory consumption in BERT is conducted. No results are given at test time : is there also a memory and processing time reduction ?,0.16666666666666666,0.21212121212121213,0.18666666666666665
113,SP:a27f975266e990b2ab4a0ab8db1588e945d0300a,"This paper presents a new model-free + model-based algorithm, MBPGE, that trains a policy using a policy gradient algorithm on top of the learned models. Contrary to previous approaches, they use a true Bayesian distribution by means of the randomized anchorized MAP. Furthermore, they combine rollouts from the real environment and from the learned dynamics directly for the policy training, instead of relying just on the ones of learned dynamics, which induces a larger distributional shift.","This paper focuses on model based reinforcement learning (RL). Specifically, the authors consider the setting of combining model based and model free RL algorithms by using the learned dynamics model to generate new data for training the model free algorithm. In order to capture the uncertainty of the environment and the model, the author applied Baysian neural network to learn the dynamics of the environment. The authors approximated the true Bayesian inference process by keeping an anchored ensemble of neural networks, where the prior and posterior of network weights are approximately Gaussian. The ensemble of dynamics model is then used to generate data to train a PPO[1] based agent. In order to prevent the agent from exploiting the learned dynamics model, the authors propose a heuristic way of balancing the amount of real data and model generated data by comparing the rewards.",0.3116883116883117,0.16783216783216784,0.2181818181818182
114,SP:a300122021e93d695af85e158f2b402d21525bc8,"There has been a lot of work on limited precision training and inference for deep learning hardware, but in most of this work, the accumulators for the multiply-and-add (FMA) operations that occur for inner products are chosen conservatively or treated as having unlimited precision. The authors address this with  an analytical method to predict the number of mantissa bits needed for partial summations during the forward, delta and gradient computation ops for convolutional and fully connected layers. They propose an information theoretic approach to argue that by using fewer bits of mantissa in the accumulator than necessary, the variance of the resulting sum is less than what it would have been if sufficient bits of mantissa were used. This is surprising to me, as quantization is usually modeled as _adding_ noise, leading to an _increase_ in variance (Mc Kinstry et al. 2018), so this is a nice counterexample to that intuition. Unfortunately the result is presented in a way that implies the variance reduction is what causes the degradation in performance, while obviously (?) it's just a symptom of a deeper problem. E.g., adding noise or multiplying by a constant to get the variance to where it should be, will not help the network converge. The variance is just a proxy for lost information. The authors should make this more clear.","The authors conduct a thorough analysis of the numeric precision required for the accumulation operations in neural network training. The analysis is based on Variance Retention Ratio (VRR), and authors show the theoretical impact of reducing the number of bits in the floating point accumulator. And through extensive benchmarks with popular vision models, the authors demonstrate the practical performance of their theoretical analysis.",0.08482142857142858,0.30158730158730157,0.13240418118466898
115,SP:a49fd0479a977c8fb45199210f9ff7dd2c0dabaf,"Authors present a new normalization technique called Equi-Norm and experimentally show its fast convergence properties over its popular competitors Batch-norm and Group-norm. The main idea in the paper is the EquiNorm method modifies the weights of a layer before forward propagating through it such that the contribution from positive and negative kernel weights to the output is same. In the experimental section, their approach is shown to be more accurate than Batch-norm and group norm on all datasets except, Imagenet. Is there any reasoning why this method performed slightly poorly on this particular dataset.","This manuscript introduces a new layer-wise transform, EquiNorm, to improve upon batch normalization. As with batch normalization and related techniques, the idea is to introduce a simple linear transform at each layer to reduce the dependency of the features to the data. Unlike batch normalization, the procedure does not modify the inputs to the layers but rather the layer weights. For this purpose, a scaling factor and a shift is computed on a mini batch, separating positive and negative weights to compute easily both running estimates of shift and of spread (here in the l1 sense). The method is compared to BatchNorm and GroupNorm on several classic computer vision datasets. Empirically, the method converges faster in the beginning of the optimization, in the sense that in the first few epochs the test accuracy is higher than for BatchNorm. However, this benefit decreases with more epochs and when the results are close to peak performance the difference between methods is a small. In addition, test accuracy can decrease at the end of the optimization, which the authors interpret as a sign of increased overfit, and tackle with clever data augmentation. The paper reads well.",0.2653061224489796,0.13402061855670103,0.1780821917808219
116,SP:a558ffa1706ef78893528c8c23e2295a79824d2f,"This submission proposes to consider to put attention on ""phrases"" in NLP. The phrases are generated by taking consecutive words in sentences. Each phrase is treated as a ""node"" in the same way as words. Then representations of phrases are learned in the network. The algorithm is applied to two applications, translation and pos tagging. The proposed method achieved better performance than transformer. ","This paper addresses an issue of compositionality in self-attention models such Transformer. A simple idea of composing multiple words into a phrase as a hypernode and representing it using a non-linear function to capture the semantic mutation is proposed. In the machine translation and PoS tagging tasks, the proposed PhraseTransformer achieves impressive gain, especially +13.7 BLEU score compared to the Transformer.",0.25396825396825395,0.25,0.25196850393700787
117,SP:a5f0e531afd970144169823971d2d039bff752fb,"This paper focuses on the calibration for the regression problem. First, it investigates the shortcomings of a recently proposed calibration metric [1] for regression, and show theoretically where this metric can be fooled. Later, it introduces new metrics for measuring the calibration in regression problem which are instantiated from similar idea as the ECE calibration metric [2] used for classification problem. The paper defines the uncertainty as the mean square error and like the ECE idea, it divides the samples into different uncertainty bins and for each bin, it calculates RMSE of network output uncertainty. The RMSE versus variance of estimated uncertainty is depicted as the reliability diagram.","This paper is concerned with uncertainty calibration diagnostics and re-calibration methods, applied to neural network regression. It is motivated by a flaw in the diagnostic proposed by Kuleshov+ 2018 (abreviated K2018 below), as explained around eq4, and proposes a replacement diagnostic for uncertainty calibration quality (sec 3 before 3.1). It then specialises by considering the class of uncertainty prediction schemes qualified as ""direct"" uncertainty modeling (defined sec1), in which the network predicts the parameters of a parametric distribution over the target output, typically mean and variance of a Gaussian. For this class of schemes, it proposes a recalibration method (sec 3.1), which consists, as shown eq12, of rescaling (with a single parameter $s$) the square root of the variance predicted by the neural network. It then presents experiments (sec4) to demonstrate that the motivating flaw can be evidenced by their diagnostic, and fixed by their recalibration method where it makes sense (ie where predicted uncertainties are not random, i.e. statistically independent of the empirical uncertainty).",0.25,0.15976331360946747,0.19494584837545126
118,SP:a72072879f7c61270d952f06d9ce995e8150632c,"This paper studies the problem of compactly represent the model of a complex dynamic system while preserving information. The method is based on the information bottleneck method. Basically, for a dynamic system whose states changing from X_{k-1}, X_k to X_{k+1}, the ""information bottleneck hierarchy"" method learns a variable B_k and B_{k+1} such that B_k predicts B_{k+1} well, B_k predicts X_k well, and B_{k+1} predicts X_{k+1} well, while minimizing the information of X_{k-1} contained in B_k. ",This paper studied an extension of the Information Bottleneck Principle called Information Bottleneck Hierarchy (IBH).  The goal of IBH is to extract meaningful information from a Markov Chain. Then the authors studied case of the Gaussian linear dynamic and proposed an algorithm for computing the IBH. Then an experiment was conducted to show the usage of IBH to practical problems.,0.1368421052631579,0.21666666666666667,0.16774193548387098
119,SP:a7a2ded35804c381603a1196c7f7893fdf796c05,"this paper proposes a new regularized policy optimization (PO) method which is based on Wasserstein distances. Its idea is to use SGD to optimize the dual form of the WD, then used in two different policy search approaches TRPO and Evolution Strategies. The evaluations are carried out on a variety of control tasks from OpenAI Gym. ","This paper proposes using Wasserstein Distances to measure the difference between higher-level functions of policies, which this paper terms as ""behaviors"". For example, one such behavior could be the distribution over final states given the policy, or the distribution over returns given policy. Through the lens of these behavioral embeddings, this paper recovers a few important special cases that are well-known in the literature including WD-based TRPO and distributional RL. This paper shows that the dual formulation of the Wasserstein Distance gives the ability to score individual policies based on a given ""behavioral mapping"".",0.26785714285714285,0.15463917525773196,0.19607843137254902
120,SP:a8df2aa6870a05f8580117f433e07e70a5342930,"This paper focuses on the reduction of training time by various mechanisms. By introducing a time gate during training, it controls when a neuron (weights?) can be updated during training. By introducing and additional budget term in the loss function, training costs (number of computations) are reduced by one order of magnitude. ","The work takes inspiration from a recent work on phased LSTM, and proposes to add a Gaussian gate based on time to LSTM cells. With this additional gate, the network can skip updating the states by closing the time-gate, as a result enabling longer memory persistence, and better gradient flow. The authors also propose to add a budget term to force the time-gate to be closed most of the time as a way to save compute. Empirical results suggest the Gaussian-gated LSTMs perform better than regular LSTMs on tasks with long temporal dependencies. The authors also propose to use a curriculum training schedule in which the variance of the gaussian gates is continuously increased to speed up training of LSTMS.  ",0.25,0.10569105691056911,0.14857142857142858
121,SP:a99fddee87b684b2783ef3a21f8c15c19631953b,The paper describes a framework for training a self-driving policy by augmenting imitation loss with additional loss terms that penalize undesired behaviors and that encourage progress. The policy takes as input a parsed representation of the scene (rather than raw images) and outputs pose trajectories for a down-stream controller. The method is trained on simulated data that includes perturbations to improve generalizability. The framework is evaluated in simulation through a series of ablations to better understand the contribution of the different loss terms.,"The paper proposes a vehicle’s trajectory planner that iteratively predict next-step (longitudinal and latitudinal) position of an ego-vehicle. Instead of using a raw image, a set of handcrafted features (i.e., the status of traffic lights, route, roadmap, etc) are mapped onto a fixed-size of bird-eye view map, which is then fed into the recurrent neural network. Additional regularizing loss terms are explored for the robustness of the model. The effectiveness of the method is demonstrated in simulation and real-world experiment.",0.17647058823529413,0.1724137931034483,0.1744186046511628
122,SP:ae9b6f7f2bd29ad1d24c4acbe1ecd345fcd6a081,"The paper proposes a Structural-Jump-LSTM model to speed up machine reading, which is an extension of the previous speed reading models, such as LSTM-Jump, Skim-LSTM and LSTM-Shuffle. The major difference, as claimed by the authors, is that the proposed model has two agents instead of one. One agent decides whether the next input should be fed into the LSTM (skip) and the other determines whether the model should jump to the next punctuation (jump). The sentence-wise jumping makes the jumping more structural than models like LSTM-Jump, while the word-wise skipping operation has a finer skimming decision. The reinforcement learning algorithm in this paper is also different from LSTM-Jump, where LSTM-Jump uses REINFORCE, while this paper applies actor-critic approach. ","The paper presents a novel model for neural speed reading. In this new model, the authors combined several existing ideas in a nice way, namely, the new reader has the ability to skip a word or to jump a sequence of words at once. The reward of the reader is mixed of the final prediction correctness and the amount of text been skipped. The problem is formulated as a reinforcement learning problem. The results compared with the existing techniques on several benchmark datasets show consistently good improvements.",0.15503875968992248,0.22988505747126436,0.18518518518518517
123,SP:b05a6a0f05dcc63a7e17233f20c49c465c46d194,"This paper touches the signal processing/long term propagation problem in gated recurrent neural networks from the mean field theory. The paper starts from a dynamic system view of the recurrent neural networks and calculates the time scale of converging to the fixed point. In order to avoid the system to converge to the fixed point, the authors utilize some initialization strategy to keep the time scale to infinity. The authors also relate the time scale to state-to-state Jacobians. ","The aim of this paper is to suggest randomized initializations for the various weights of a recurrent neural network (GRUs and various LSTMs are covered), such that training these networks gets to a successful start, when the model is trained on long sequences. Instead of being heuristic, their approach follows first principles of analyzing signal propagation through time, using ideas from statistical thermodynamics (mean field approximations). Some experiments, on toy datasets, validate their approach.",0.12345679012345678,0.13513513513513514,0.12903225806451613
124,SP:b08dc82d5098474ddd68ab13003013ee6e7ba989,"The authors introduce a  novel  on-policy  temporally  consistent  exploration  strategy, named Neural  AdaptiveDropout Policy Exploration (NADPEx), for deep reinforcement learning agents. The main idea is to sample from a distribution of plausible subnetworks modeling the temporally consistent exploration. For this, the authors use the ideas of the standard dropout for deep networks. Using the proposed  dropout transformation that is differentiable, the authors show that the KL regularizers on policy-space play an important role in stabilizing its learning. The experimental validation is performed on continuous control learning tasks, showing the benefits of the proposed. ","This paper proposed to use dropout to randomly choose only a subset of neural network as a potential way to perform exploration. The dropout happens at the beginning of each episode, and thus leads to a temporally consistent exploration. The paper shows that with small amount of Gaussian multiplicative dropout, the algorithm can achieve the state-of-the-art results on benchmark environments. And it can significantly outperform vanilla PPO for environments with sparse rewards.",0.16842105263157894,0.21333333333333335,0.18823529411764708
125,SP:b2a8f5c3a417390582f26981fe0c81c16d2bb07d,"The paper presents a strategy for solving sparse reward tasks with RL by sampling initial states from demonstrations. The method, Backplay, starts by sampling states near the end of a demonstration trajectory, so that the agent will be initialized to states near the goal. As training progresses, the initial state distribution is incrementally shifted towards earlier steps in the demonstration, until the agent is trained starting from the original initial state. The authors further provide an analysis of the sample complexity of this method on a simple MDP. The method is demonstrated on a maze navigation task and a challenging game Pommerman.","This paper presents a method for increasing the efficiency of sparse reward RL methods through a backward curriculum on expert demonstrations. The method in the paper is as follows: assuming access to expert demonstration and a resettable simulator, the start state of the agent in the beginning of training is sampled from end of demonstration (close to the rewarding state) where the task of achieving the goal is easy. Then gradually through a curriculum this is shifted backwards in the demonstration, making the task gradually harder. ",0.2549019607843137,0.3023255813953488,0.276595744680851
126,SP:b33a6a1fe4bbae422ba001cbe656f31d07a62025,"This paper presents a PAC-Bayesian framework that bounds the generalization error of the learned model. While PAC-Bayesian bounds have been studied before, the focus of this paper is to study how different conditions in the network (e.g. behavior of activations) generalize from training set to the distribution. This is important since prior work have not been able to handle this issue properly and as a consequence, previous bounds are either on the networks with perturbed weights or with unrealistic assumptions on the behavior of the network for any input in the domain.","The fact that a number of current generalization bounds for (deep) neural networks are not expressed on the deterministic predictor at stake is arguably an issue. This is notably the case of many recent PAC-Bayesian studies of neural networks stochastic surrogates (typically, a Gaussian noise is applied to the network weight parameters). The paper proposes to make these PAC-Bayesian bounds deterministic by studying their ""noise-resilience"" properties. The proposed generalization result bounds the margin of a (ReLU) neural network classifier from the empirical margin and a complexity term relying on conditions on the values of each layer (e.g., via layer Jacobian norm, the layer output norm, and the smallest pre-activation value). ",0.23157894736842105,0.19130434782608696,0.20952380952380953
127,SP:b65eb92fcbea57626721a156be6e6cbbad3c071c,"The paper focuses on pruning neural networks. They propose to identify the nodes to be pruned even before training the whole network (conventionally, it is done as a separate step after the nn was trained and involves a number of iterations of retraining pruned nn). This initial step that identifies the connections to be pruned works off a mini-batch of data.","This work introduces SNIP, a simple way to prune neural network weights before training according to a specific criterion. SNIP identifies prunable weights by the normalised gradient of the loss w.r.t. an implicit multiplicative factor “c” on the weights, denoted as the “sensitivity”. Essentially, this criterion takes two factors into account when determining the relevance of each weight; the scale of the gradient and the scale of the actual weight. The authors then rank the weights according to their sensitivity and remove the ones that are not in the top-k. They then proceed to train the surviving weights as normal on the task at hand. In experiments they show that this method can offer competitive results while being much simpler to implement than other methods in the literature.",0.1774193548387097,0.08396946564885496,0.1139896373056995
128,SP:b7f4fda6497a1c20fd57f029be5f1b2e2780e227,"This work presents the goal-conditioned supervised learning algorithm (GCSL), which learns goal conditioned policies using only behavioral-cloning of the agent's own actions.  The intuition behind the algorithm is the goal of an observed trajectory can be identified after the fact, by simply looking at the states reached during that trajectory.  GCSL treats each executed action as a sample from the expert policy conditioned on each of the states reached after that action is taken.  Given a distribution over goal states, GCSL alternates between executing its current goal-conditioned policy on randomly selected goals, and learning to imitate the generated actions conditioned on the states they actually reached.  Experimental results demonstrate superior performance against a base (non-goal conditioned) RL algorithm (TRPO), and against another approach to learning goal-conditioned polices (TD3-HER), on a relatively diverse set of control problems.","This paper proposes a method to learn to reach goals in an RL environment. The method is based on principles of imitation learning. For instance, beginning with an arbitrary policy that samples a sequence of state-action pairs, in the next iteration, the algorithm treats the previous policy as an expert by relabeling its ending state as a goal. The paper shows that the method is theoretically sound and effective empirically for goal-achieving tasks. ",0.11888111888111888,0.22666666666666666,0.15596330275229356
129,SP:b97549a4c1f4b2407f97576fed46c25cbf669009,"This work proposes a novel analytic framework exploited on a semantic segmentation model to visualize GANs at unit (feature map) level. The authors show that some GAN representations can be interpreted, correlate with the parsing result from the semantic segmentation model but as variables that have a causal effect on the synthesis of semantic objects in the output. This framework could allow to detect and remove the artifacts to improve the quality of the generated images.","This paper provides a visualization framework to understand the generative neural network in GAN models. To achieve this, they first find a group of interpretable units and then quantify the causal effect of interpretable units. Finally, the contextual relationship between these units and their surrounding is examined by inserting the discovered object concepts into new images. Extensive experiments are presented and a video is provided.",0.18421052631578946,0.2153846153846154,0.19858156028368792
130,SP:b99732087f5a929ab248acdcd7a943bce8671510,"This paper focuses on deep reinforcement learning methods and discusses the presence of inductive biases in the existingRL algorithm. Specifically, they discuss biases that take the form of domain knowledge or hyper-parameter tuning. The authors state that such biases rise the tradeoff between generality and performance wherein strong biases can lead to efficient performance but deteriorate generalization across domains. Further, it motivates that most inductive biases has a cost associated to it and hence it is important to study and analyze the effect of such biases. ","This paper contains various numerical experiments to see the effects of some heuristics in reinforcement learning. Those heuristics include reward clipping, discounting for effective learning, repeating actions, and different network structures. However, since the training algorithms also greatly affect the performance of RL agents, it seems hard to draw any quantitive conclusions from this paper.",0.11494252873563218,0.18181818181818182,0.1408450704225352
131,SP:ba66503753b3c57781b435c55c47fc9f69450e65,"The paper aims at studying the setting of perturbed rewards in a deep RL setting. Studying the effect of noise in the reward function is interesting. The paper is quite well-written. However the paper studies a rather simple setting, the limitations could be discussed more clearly and there are one or two elements unclear (see below).","The authors present work that shows how to deal with noise in reward signals by creating a surrogate reward signal. The work develops a number of results including: showing how the surrogate reward is equal in expectation to the true reward signal, how this doesn't affect the fixed point of the Bellman equation, how to deal with finite and continuous rewards and how the convergence time is affected for different levels of noise. They demonstrate the value of this approach with a variety of early and state-of-the-art algorithms on a variety of domains,, and the results are consistent with the claims.",0.2631578947368421,0.14285714285714285,0.18518518518518517
132,SP:be0202a28bcca68edb0abe4d1c0ba1af265211e3,"This paper proposes an approach to identifying important waypoint states in RL domains in an unsupervised fashion, and then for using these states within a hierarchical RL approach.  Specifically, the authors propose to use a binary latent variable VAE to identify waypoint states, then an HRL algorithm uses these waypoints as intermediate goals to better decompose large RL domains. The authors show that on several grid world tasks, the resulting policies substantially outperform baseline approaches.","This paper proposes a novel approach to hierarchical reinforcement learning approach by first learning a graph decomposition of the state space through a recurrent VAE and then use the learned graph to efficiently explore the environment. The algorithm is separated into 2 stages where in the first stage random walk and goal conditioned policy is used to explore the environment and simultaneous use a recurrent binary VAE to compress the trajectory. The inference network is given the observation and action and the reconstruction is to, given the hidden state or hidden state+observation, reconstruct the action taken. The approximate posterior takes on the form of a hard Kumaraswamy distribution which can differentiably approximate a binary variable; when the approximate posterior is 0, the decoder must reconstruct the action using the hidden state alone. The nodes of the world graph are roughly states that are used to reconstruct the trajectories in the environment. After the graph is constructed, the agent can use a combination of high-level policy and classical planning to solve tasks with sparse reward.",0.25333333333333335,0.10795454545454546,0.15139442231075698
133,SP:be5f2c827605914206f5645087b94a50f59f9214,"This paper presents the NeuroSAT architecture, which uses a deep, message passing neural net for predicting the satisfiability of CNF instances. The architecture is also able to predict a satisfiable assignment in the SAT case, and the literals involved in some minimal conflicting set of clauses (i.e. core) in the UNSAT case. The NeuroSAT architecture is based on a vector space embedding of literals and clauses, which exploits (with message passing) some important symmetries of SAT instances (permutation invariance and negation invariance). This architecture is tested on various classes of random SAT instances, involving both unstructured (RS) problems, and structured ones (e.g. graph colorings, vertex covers, dominating sets, etc.).","This paper trains a neural network to solve the satisfiability problems. Based on the message passing neural network, it presents NeuroSAT and trains it as a classifier to predict satisfiability under a single bit of supervision. After training, NeuroSAT can solve problems that are larger and more difficult than it ever saw during training. Furthermore, the authors present a way to decode the solutions from the network's activations. Besides, for unsatisfiable problems, the paper also presents NeuroUNSAT, which learns to detect the contradictions in the form of UNSAT cores.",0.14414414414414414,0.17777777777777778,0.15920398009950248
134,SP:beb54248806f7a68beb60167c3dbbd45b34dad83,"This paper proposes the Cramer-Wold autoencoder. The first contribution of the paper is to propose the Cramer-Wold distance between two distributions based on the Cramer-Wold Theorem. More specifically, in order to compute the Cramer-Wold distance, we first find the one dimensional projections of the distributions over random slices, and then compute the average L2 distances of the kernel density estimates of these projections over random slices. The second contribution of the paper is to develop a generative autoencoder which uses the Cramer-Wold distance to match the latent distribution of the data to the prior distribution.","The paper introduces a novel regularized auto-encoder architecture called the Cramer-Wold AutoEncoders (CWAE). It's objective (Eq. 7) consists of two terms: (i) a standard reconstruction term making sure the the encoder-decoder pair aligns nicely to accurately reconstruct all the training images and (ii) the regularizer, which roughly speaking requires the encoded training distribution to look similar to the standard normal (which is a prior used in the generative model being trained). The main novelty of the paper is in the form of this regularizer. The authors introduce what they call ""the Cramer-Wold distance"" (for definitions see Theorems 3.1 and 3.2) which is defined between two finite sets of D-dimensional points. The authors provide empirical studies showing that the proposed CWAE method achieves the same quality of samples (measured with FID scores) as the WAE-MMD model [1] previously reported in the literature, while running faster (by up to factor of 2 reduction in the training time, as the authors report). ",0.27,0.16071428571428573,0.20149253731343286
135,SP:beba754d96cc441712a5413c41e98863c8abf605,"This paper first theoretically demonstrates that a commonly used reinforcement learning method for neural sequence-to-sequence models (e.g. in NMT), contrastive minimum risk training (CMRT), is not guaranteed to converge to local (let alone global) optima of the reward function. The paper then empirically demonstrates that the REINFORCE algorithm, while not subject to the same theoretical flaws as CMRT, in practice fails to improve NMT models unless the baseline model is already ""nearly correct"" (i.e. the correct tokens were already within the few most probable tokens before the fine-tuning steps with REINFORCE). In fact, some of the performance gains of using REINFORCE/CMRT can be attributed to making the model's output probability distribution more peaked, and not necessarily from making the target tokens more probable as commonly assumed.","In the context of neural machine translation, limitations of some reinforcement learning methods, in particular REINFORCE and contrastive minimum risk training (MRT), are analyzed. The authors argue that MRT doesn't optimize the expected reward. Moreover, they show that using REINFORCE, with either realistic or dummy constant rewards, may lead to a peakier distribution. Similar BLEU scores are obtained with either type of rewards, which is an interesting and perplexing result (in my opinion). For both REINFORCE and MRT, the paper shows that unless the gold token was already amongst the most probable after pre-training, it takes many samples for it to become the most likely output, which limits the usefulness of on-policy RL approaches.",0.17293233082706766,0.19658119658119658,0.184
136,SP:c210982ccdd134d4b293dbe144990398eefe1a86,"In this interesting study, the authors show that incorporating rotation-equivariant filters  (i.e. enforcing weight sharing across filters with different orientations) in a CNN model of the visual system is a useful prior to predict responses in V1. After fitting this model to data, they find that the RFs of model V1 cells do not resemble the simple Gabor filters of textbooks, and they present other quantitative results about V1 receptive fields. The article is clearly written and the claims are supported by their analyses. It is the first time to my knowledge that a rotation-equivariant CNN is used to model V1 cells.","The paper analyses the data collected from 6005 neurons in a mouse brain. Visual stimuli are presented and the responses of the neurons recorded. In the next step, a rotational equivariant neural network architecture together with a sparse coding read-out layer is trained to predict the neuron responses from the stimuli. Results show a decent correlation between neuron responses and trained network. Moreover, the rotational equivariant architecture beats a standard CNN with similar number of feature maps. The analysis and discussion of the results is interesting. Overall, the methodological approach is good.",0.17142857142857143,0.1935483870967742,0.1818181818181818
137,SP:c2a5551f229211c9aa4c43686b517fcde82bbccf,"the paper studies transfer learning, which addresses the inconsistencies of the source and target domains in both input and output spaces. usually, we only worry about the inconsistencies in the input domain but here we worry about input and output. the paper proposes adversarial inductive transfer learning which uses adversarial domain adaptation for the input space and multi-task learning for the output space.","The paper proposes an adversarial transfer learning network that can handle the adaptation of both the input space and the output space. The paper is motivated by the application of drug response prediction where the source domain is cell line data and the target domain is patient data. Patient data are usually scarce, hence motivating transferring the knowledge learned from the more widely available cell line data to improve the predictive performance based on the patient data.  The idea of making use of adversarial networks is to learn a representation of the data points that is invariant to whether the data points come from the source domain or the target domain. Experiments on real-world data over four drugs demonstrate the effectiveness of the proposed methods compared to other methods that are not specifically designed for this scenario.",0.296875,0.13768115942028986,0.18811881188118812
138,SP:c422afd1df1ac98e23235830585dd0d45513064c,"This paper proposes a layer on top of BERT which is motivated by a desire to disentangle content (meaning of the tokens) and form (structural roles of the tokens).  Figure 1 shows this clearly. The paper considers two variants of the disentangling layer (TPR), one with LSTMs (figure 2) and the other with attention (figure 3). The aim in both is to obtain a decomposition of the form x(t) = S a_s(v_t) a_r(v_t) R where S and R are shared matrices of parameters and v is the output of BERT. ",This paper proposes a fine-tune technique to help BERT models to learn & capture form and content information on textual data (without any form of structural parsing needed). They key addition to the classic BERT model is the introduction of the R and S embeddings. R &S are supposed to learn the information in text that is traditionally represented as the structural positions and the content-bearing  symbols in those positions. ,0.20833333333333334,0.28169014084507044,0.23952095808383236
139,SP:c54ee7a7d321a487257d2554c7e689967cf0ceaa,"In this paper authors present a new Probabilistic Programming Language (PPL) MXFusion. Similarly to the languages for the deep learning (TensorFlow, PyTorch, etc.), this language introduce probabilistic modules that are used as building blocks for complex probabilistic models. Introducing modularity to the probabilistic programming, raises the problem of inference for probabilistic models. Since, we cannot obtain the exact solution on practice we have to resort to approximate inference methods. The approximate inference methods can be either generic, thus, being suitable for many probabilistic models but resulting in poor approximation, or specific, thus, having good approximation quality, but only for specific probabilistic models. Authors propose to address this problem by encapsulating specific inference methods in corresponding probabilistic modules. Doing so, one can perform approximate inference for every module with the best suitable inference technique. Authors demonstrate interface of MXFusion for three well known probabilistic models: Bayesian linear regression, deep kernel learning, Bayesian Gaussian process latent variable model.","The paper presents an extension of the MXFusion language that allows the use of probabilistic modules. These modules are defined as a set of random variables and a specific probabilistic distribution. The modules also contain dedicated inference methods. Using these modules, one can use probabilistic distributions with inference methods tailored to the distribution, which are usually more efficient than generic inference systems.",0.11538461538461539,0.2903225806451613,0.1651376146788991
140,SP:c5c84ea1945b79b70521e0b73f762ad643175020,"The paper analyzes the strategy that a visual question answering model (FiLM) uses to verify statements containing the quantifier ""most"" (""most of the dots are red""). It finds that the model is sensitive to the ratio of objects that satisfy the predicate (that are red) to objects that do not; as the ratio decreases (e.g. 10 red dots compared to 9 blue dots), the model's performance decreases too. This is consistent with human behavior.","This paper studies how the FiLM visual question answering (VQA) model answer questions involving the quantifier ‘most’. This quantifier is chosen for study because it cannot be expressed in first order logic (i.e., high-order logic is required), and secondly because there are two different algorithmic approaches to answering questions involving ‘most’ (cardinality-based strategy and pairing-based strategy). Experiments are performed by designing abstract visual scenes with controlled numerosity and spatial layouts, and applying methodologies from pyscholinguistics. The paper concludes that the model learns an approximate number system (ANS), consistent with the cardinality-based strategy, with implications for understanding the conditions under which existing VQA models should perform well or badly (and possibly for improving VQA models). ",0.23684210526315788,0.15126050420168066,0.1846153846153846
141,SP:c65ea3a1cc796e65465e8b4dc05ae103316e2cb3,"For binary layers, how to calculate and backpropagate gradients is a big problem, particularly for the binary neural networks. To solve the problem, this paper proposes an unbiased and low variance augment-REINFORCE-merge (ARM) estimator. With the help of an appropriate reparameterization, the antithetic sampling in an augmented space can be used to drive a variance-reduction mechanism. The experimental results show that ARM estimator converges fast, has low computational complexity, and provides advanced prediction performance.","In this paper the authors propose a new variance-reduction technique to use when computing an expected loss gradient where the expectation is with respect to independent binary random variables, e.g. for training VAEs with a discrete latent space. The paper is interesting, highly relevant, simple to implement, suggests many possible extensions, and shows good results on the experiments performed. However the exposition leaves a lot to be desired.",0.11688311688311688,0.12857142857142856,0.12244897959183673
142,SP:c6884b04001bd0d43aa47e2d72ebbe2bbc89ab3d,"The authors propose modeling structural diversity of translations by conditioning the generation on both the source sentence and a latent encoding of the overall structure (captured by simplified part-of-speech tags). Specifically, they first train a conditional autoencoder to learn a latent code optimized towards reconstructing the tag sequence. They then prefix the inferred latent code to the target sentence before generation. A diversity metric which measures pairwise BLEU scores between beam items is also proposed. Experiments show that the latent codes lead to greater structural diversity as well as marginally improved translation results when combined with beam search.","The authors consider the problem of generating diverse translations from a neural machine translation model. This is a very interesting problem and indeed, even the best models lack meaningful diversity when generating with beam-search. The method proposed by the authors relies on prefixing the generation with discrete latent codes. While a good general approach, it is not new (exactly the same general approach that was used in the ""Discrete Autoencoders for Sequence Models"" [1] paper, https://arxiv.org/abs/1801.09797, for generating diverse translations, which is not cited directly but a follow-up work is cited, though without mentioning that a previous work has tackled the same problem). Also, the authors rely on additional supervised data (namely POS tags) which has no clear motivation and seems to cause a number of problems -- why not use a purely unsupervised approach when it has already been demonstrated on the same problem? Additionally, the authors compare to a weak translation baseline on small data-sets, making it impossible to judge whether the results would hold on a larger data-set. So the following ablations and comparison to baselines are missing:",0.2,0.10582010582010581,0.13840830449826988
143,SP:c8bbdbf038ddec801c931ae9399b8c16b08428bc,"The paper studies stochastic optimization with consistent (may not be unbiased) estimators. This problem is well-motivated through the example of learning graph representations where consistent estimators are easier to obtain than unbiased one. Under the assumption that the estimate converges to the consistent gradient exponentially fast w.r.t. the sample size, the authors give convergence rates for convex, strongly-convex and non-convex optimization. The authors validate their theory through synthetic experiments.","The authors study SGD algorithms for problems where obtaining unbiased gradients is potentially computationally expensive. In such cases while obtaining, unbiased gradients is expensive, it might be possible to establish consistent estimators of the gradient. The authors then establish that SGD algorithm when run with consistent gradient estimators (but not necessarily unbiased) have similar convergence properties as SGD algorithms when run with unbiased gradient estimators.  The example problem class considered is the problem of learning embeddings for graph problems, where the task is to get embeddings for nodes. Such embeddings can be used to do node classification or solve any other downstream task that involves the nodes of the graph. For such graph problems learning embeddings requires us  to look at the neighbours of a node, neighbours-of-neighbours and so on, which means that in the worst case calculating gradient w.r.t. a single node can be of time complexity O(N).  Consistent gradient estimators have been proposed for such graph problems in the past but this paper establishes theoretical properties of SGD with such estimators.  ",0.32432432432432434,0.1348314606741573,0.1904761904761905
144,SP:c9c7fc5288e24a54531b7063c028d307279fe2ef,"This paper provides a very simple approach to the problem of knowledge base completion. The idea is this - given a query (subject, relation), you find other entities similar to subject, see which other paths they can take to their corresponding object if they express the relation, and check if the subject express those paths. Object reached this way are candidate answers. The one with most paths reached is marked correct.","This paper proposes a non-parametric reasoning method for reasoning on incomplete knowledge bases. Specifically, for the task of finding a target entity given a source entity and a relation, since this specific relation might be missing for the source entity, multi-hop reasoning is required to get the answer. To get the reasoning paths, this paper proposes to first retrieve similar entities from the knowledge base that have the same outgoing relation, and then gather all possible reasoning paths from these retrieved entities. Finally, these reasoning paths extracted from other entities can be applied to the source entity in the query and get the answer. ",0.22857142857142856,0.1509433962264151,0.1818181818181818
145,SP:ca491b166bd8bf1a7c71657471a2f58b7fd36609,"The paper proposes the H score H(f), a quantity that measure the goodness of feature f(x) for predicting some target y. This heavily builds on Makur et al. (2015) who introduce information vectors, the error exponent, and the DTM matrix. The paper connects H(f) with these quantities to justify the proposal (e.g., H(f) is proportional to the error exponent (Theorem 1)). The actual transferability is measured by the ratio between H(f) and H(f_opt) where the latter can be computed using the approach of Makur et al. ","In this paper, the authors considered a source domain selection problem in transfer learning. Given a feature representation function f, the H-score is defined as the normalized correlation between the output f(X) and the label Y. The transferability is then measured by the ratio of H-score on the target domain and the optimal one. The authors introduced the information-theoretic and statistical meaning of the H-score. Validation of H-score was confirmed by numerical experimenters with image data. ",0.23404255319148937,0.2682926829268293,0.25
146,SP:cae76d3c3da91e50fe29cc3b6e204bb3e0793d7e,"This paper proposes  an adaptation technique for TTS using wavenet as the speech backend, with the adaptation carried out on small data. The work is extremely significant in that speech data is hard to produce  (we need many hours of speaker data), and techniques to adapt (transfer learning?) data from large networks would be quite valuable. The main idea is that we train a network containing a large amount of data, and (assuming that we have a trained model), we adapt this network to the task of generating speech from text for a much smaller dataset. ","This paper investigates speaker adaption with a few samples based on an existing (pre-trained) multi-speaker TTS system. The three approaches in this paper are almost the same as the voice cloning work in Arik et al. (2018). However, it is still very beneficial to demonstrate these approaches for linguistic feature conditioned WaveNet.",0.125,0.2222222222222222,0.16
147,SP:cf74c553bae2b1194beaba4df1545d35e66aa5b3,"This paper proposes a Projective Subspace Network (PSN) for few-shot learning. The PSN represents each support set of classes as a subspace obtained by SVD. Then the method calculates distances between a query and classes by the projection error to the subspace. Instead of using the prototype of the class center, the subspace representation is more robust to outliers. Though the contribution seems to be incremental, it is a reasonable improvement upon Matching Networks and Prototypical Networks.","This paper considers the problem of few-shot learning and proposes a new embedding-based approach. In contrast to previous work (such as Matching Networks and Prototypical Networks) where distance is computed in pure embedding space, this work proposes computing a low-dimensional subspace to represent a class and using the distance from an embedded query point to this subspace. The low-dimensional subspace for a class is computed by running truncated Singular Value Decomposition on the normalized embeddings of all points in the support set for that class and using the top n left singular vectors as the basis for the class's subspace. The authors also propose an extension to their model to the semi-supervised few-shot learning setting by incorporating masked-mean computation and zero-mean cluster for distractor items (both ideas borrowed from Renn 2017 for prototypical networks). Experiments are conducted on Mini-Imagenet in the few-shot learning setting and on Mini-Imagenet and Tiered-ImageNet in the semi-supervised few-shot learning setting.",0.32051282051282054,0.14705882352941177,0.20161290322580647
148,SP:d03aa0318f0d24a5b7c7817dfc7fba47ebec11cd,"This work proposed a distillation approach which use ASRs to generate hypotheses for unsupervised data, run a LM to get probability for the hypothesis, and perform distillation with the resulting probability. The ASRs being used for generating hypotheses can be either a model trained with the supervised data or the student model, and can switch between the two during training. In the experiments, ASR models are pre-trained with the subset of Librispeech data and use the rest of Librispeech data as unsupervised data, and the LM is trained with Librispeech LM data. The experiments shown the proposed approach improve baseline model trained with the Librispeech subset significantly.","This paper is dedicated to proposing a self-supervised objective, local prior matching (LMP), for speech recognition. This approach can take advantage of vase quantities of unlabeled speech data. What' more, the objective is simple to implement and theoretically well-motivated. In the paper, based on a supervised pretrained model, it then finetunes 360 hours with unlabeled data and LPM reduces the WER consistently. They also conduct extensive ablation experiments to show the effect of their self-supervised approach.",0.1574074074074074,0.21518987341772153,0.18181818181818182
149,SP:d0533cb69d938d4128d17b1a6d8aeb8d1ca6e3fd,"The paper presents an alternative view on the training procedure for the VQ-VAE. The authors have noticed that there is a close connection between the original training algorithm and the well-known EM algorithm. Then, they proposed to use the soft EM algorithm. In the experiments the authors showed that the soft EM allows to obtain significantly better results than the standard learning procedure on both image and text datasets.","This paper discusses VQ-VAE for learning discrete latent variables, and its application to NMT with a non-autoregressive decoder to reduce latency (obtained by producing a number of latent variables that is much smaller than the number of target words, and then producing all target words in parallel conditioned on the latent variables and the source text). The authors show the connection between the existing EMA technique for learning the discrete latent states and hard EM, and introduce a Monte-Carlo EM algorithm as a new learning technique. They show strong empirical results on EN-DE NMT with a latent Transformer (Kaiser et al. (2018)).",0.22535211267605634,0.1509433962264151,0.1807909604519774
150,SP:d16ed9bd4193d99774840783347137e938955b87,"This paper introduces two new adversarial attacks: one is generating adversarial examples by colouring the original images and the other is by changing textures of the original images. Specifically, the former one minimises the cross-entropy between the output of the classifier and the target label with the network weights of a pre-trained colourisation network. While the latter minimises the cross-entropy as well as the loss that defines the texture differences.","The paper proposes cAdv and sAdv, two new unrestricted adversarial attack methods that manipulates either color or texture of an image. To these end, the paper employes another parametrized colorization techniques (and texture transfer method) and proposes optimization objectives for finding adversarial examples with respect to each semantic technique. Experimental results show that the proposed methods are more robust on existing defense methods and more transferrable accross models. The paper also performs a user study to show that the generated examples are fairly imperceptible like the C&W attack. ",0.1643835616438356,0.1348314606741573,0.14814814814814814
151,SP:d34277109f713f78abd3b911c7a38baf18c8c8c1,"The paper presents a deep-learning-based version of the knockoff method by Candes et al. for FDR control in feature selection problems to avoid assumptions posed on the distribution of features by the original method. In a supervised feature selection setting, the goal of the knockoff framework is to select a set of input features that are statistically associated to an output variable Y, while controling the FDR. The basic idea behind knockoff is to generate artificial input feature vectors, (i.e. knockoffs) that are independent of Y, when conditioned on the real feature vector X, but after swapping arbitrary elements with X, are distributed as X. Sets of associated features and FDR estimates are obtained by contrasting suited feature selction criteria that measure associations of knockoffs and real features with the target Y.","This paper introduces a novel feature selection method by utilizing GAN to learn the distributions. The novelty of this paper is to incorporate two recent works, i.e. knockoff for feature selection and W-GAN for generative models. Compared to the latest knockoff work which requires a known multivariate Gaussian distribution for the feature distribution, the proposed work is able to generate knockoffs for any distribution and without any prior knowledge of it.",0.14814814814814814,0.273972602739726,0.19230769230769232
152,SP:d3e4e2c267fd9ae536ab1816d5c1ba8e8fec19be,"A nice paper that clarifies the difference between the clean accuracy (accuracy of models on non-perturbed examples) and the robust accuracy (accuracy of models on adversarially perturbed examples) and it shows that changing the marginal distribution of the input data P(x) while preserving its semantic P(y|x) fixed affects the robustness of the model. Therefore, testing the robustness of the model should be performed in a careful manner. Comprehensive experiments were performed to show that changing the distribution of the MINST (smoothing) and CIFAR (saturation) data could lead to a significant difference in robust accuracy while the clean accuracy is almost steady. In addition, a set of experiments were performed in an attempt to search for the criteria required for choosing a proper dataset for testing adversarial attack to measure the robustness. ","The paper is interesting and topical: robustness to adversarial input presentation (or shifts in training data itself, even those of the nature described by the authors 'semantic-lossless' shifts). Adversarial inputs are investigated under l-inf bounded perturbations, while multiclass classification on images is the target problem considered. The theoretical parts of the paper, assigning lack of adversarial robustness to the shape of the input distribution (Section 2) is the strongest part of the paper, adding some simple and important insights. Unfortunately, the empirical part of the paper is weakened by an over-reliance of (custom perturbations of ) the popular MNIST and CIFAR10 datasets (which are themselves based on larger sets). Furthermore, the basic conclusion as to causes and remedies of lack of robustness is not evident, and it is not evident that it has been sufficiently investigated. Shape yes, differences in perturbable volume not (how does that concur with Section 2?), and inter-class distance also not. Are we to base these conclusions on 2 perturbed datasets? How are readers to synthesize the final conclusion that robustness is a 'complex interaction of tasks and data', other than what they would already expect? In short, a valiant effort, and a good direction, but one that needs more work.",0.2,0.12980769230769232,0.15743440233236153
153,SP:d5126851b9e75b49522d953ee2b253e3e6c836ba,"This paper addresses an important problem of learning the random field using neural networks by using a inclusive auxiliary generator. Comparing to existing state-of-the-art methods for learning neural random fields, this paper used a the inclusive-divergence (KL divergence of the density approximate and the auxiliary generator) which avoids the intractable entropy term. SGLD/SGHMC are used to revise samples drawn from the auxiliary generator and these two sampling methods are examined theoretically.  ","The paper proposes the inclusive neural random field model. Compared the existing work, the model is different because of the use of the inclusive-divergence minimization for the generative model and the use of stochastic gradient Langevin dynamics (SGLD) and stochastic gradient Hamiltonian Monte Carlo  (SGHMC) for sampling. Experimental results are reported for unsupervised, semi-supervised, and supervised learning problems on both synthetic and real-world datasets. Specific comments follow:",0.2236842105263158,0.24285714285714285,0.2328767123287671
154,SP:d53ee573b8083ecf891d4d560eb8a54c30c5cb3a,"This paper tries to tackle the problem of searching best architectures for specialized resource constraint deployment scenarios. The authors basically take a two-step approach: First train a large network including all the small networks with weight sharing and some specially designed trick (e.g., progressive shrinking). Second, use prediction based NAS method to learn the performance/inference prediction module, from which the good sub architecture corresponding to a particular scenario is obtained. The experiments show that the proposed method is promising.","In this papers, the authors learn a Once-for-all net. This starts as a big neural network which is trained normally (albeit with input images of different resolutions). It is then fine-tuned while sampling sub-networks with progressively smaller kernels, then lower depth, then width (while still sampling larger networks occasionally, as it reads). This results in a network from which one can extract sub-networks for various resource constraints (latency, memory etc.) that perform well without a need for retraining.",0.14634146341463414,0.14457831325301204,0.14545454545454545
155,SP:d5899cba36329d863513b91c2db57675086abc49,"This paper proposes to replace dense layers with multiple sparse linear layers.  The idea is that the product ABC (for A, B, C all sparse matrices)  can accurately approximate a dense matrix D, but A(B(Cx))) requires much less work than Dx.  The paper then continues with the assumption that topology of the sparse matrices should be fixed before training, and that given this assumption we would like to find the ""best"" fixed topology to pick.  The paper introduces a new task to determine the ""best"" topology - that of reconstructing a random dense matrix.  On somewhat of a tangent the paper also introduces a minor modification to the Xavier initialization scheme that works better for deep stacks of sparse layers.","This paper tackles the problem of finding a sparse network architecture before training, so as to facilitate training on resource-constrained platforms. To this end, the authors propose to replace dense layers with series of sparsely-connected linear layers. They then study how to initialize such sparse layers to avoid gradient vanishing. Furthermore, they propose an approach to finding the best topology by measuring how well the sparse layers can approximate random weights of their dense counterparts.",0.15702479338842976,0.24675324675324675,0.1919191919191919
156,SP:d5f5f6a83f0290415ea94b3740a95360a8fa16e3,"The authors introduce a method to learn to permute sets end-to-end. They define the cost of a permutation as the sum of pairwise costs induced by the permutation, where the pairwise costs are learned. Permutations are made differentiable by relaxing them to doubly stochastic matrices which are approximated with the Sinkhorn operator. In the forward pass of the algorithm, a good permutation (ie one with low cost) is obtained with a few steps of gradient descent (the forward pass itself contains an optimization procedure). This permutation is then either used directly as the output of the algorithm or is used to permute the original inputs and feed the permuted sequence to another module (such as an RNN or a CNN). The method can easily be adapted to other structures such as lattices by considering row-wise and column-wise pairwise relations.","This paper proposed an interesting idea of learning representations of sets by permutation optimizations. Through learning a permutation of the elements of a set, the proposed algorithm can learn a permutation-invariant representation of that set. To deal with the underlying difficult combinatorial optimization problem, the authors proposed to relax the optimization constraints and instead optimize over the set of doubly-stochastic matrices with reparameterization using the Sinkhorn operator. The cost function of this optimization is related to a pairwise ordering cost, which compares the order for each pair of the elements.",0.16783216783216784,0.2608695652173913,0.20425531914893616
157,SP:d668cc809e4f6b5f3330cf75cb5f71693a123c07,The paper studies the sensitivity of a neural network with respect to quantizing its weights and activations. The idea is to use Monte Carlo Arithmetic (MCA) in order to calculate the number of significant bits in the training loss (e.g. cross entropy) that are lost due to floating-point arithmetic. The results show that the number of significant bits lost correlates with the reduction in classification accuracy when quantizing the weights and activations of the neural network.,"The authors propose a scalable method based on Monte Carlo arithmetic for quantifying the sensitivity of trained neural networks to floating point rounding errors. They demonstrate that the loss of significance metric K estimated from the process can be used for selecting networks that are more robust to quantization, and compare popular architectures (AlexNet, ResNet etc.) for their varying sensitivities.",0.19230769230769232,0.25,0.2173913043478261
158,SP:d7544bc4a0ae3237daa207e789a522363fb5170d,CAML is a gradient-based meta-learning method closely related to MAML. It divides model parameters into disjoint sets of task-specific parameters $\phi$ which are adapted to each task and task-independent parameters $\theta$ with are meta-learned across tasks. $\phi$ are then interpreted as an embedding and fed as input to the model (parameterized by $\theta$). Experiments demonstrate that this approach performs on par with MAML while adapting far fewer parameters. An additional benefit is that this approach is less sensitive to the adaptation learning rate and is easier to implement and faster to compute.,"They are proposing a meta-learning method inspired by previous method, MAML. Their idea is separating the parameters in to two groups of context and shared parameters. The context parameters are learned through back-propagation of inner-loop and represents embedding for individual task. Shared-parameters on the other hand are shared between all tasks, and are learned in the outer-loop. ",0.16494845360824742,0.25806451612903225,0.20125786163522014
159,SP:d922459581c3295ff315fda6e59b9f7e9147f22d,"The work considers the problem of efficient user and item recommendations in the warm- and cold-start settings. It aims at improving computational efficiency of the best candidate selection in these settings by utilizing binary codes representation. The transformation from an actual to a binary code representation is learned in a hybrid manner using both collaborative and content information. In order to keep such representations compact yet expressive enough, the authors impose a set of constraints that ensure balanced and uncorrelated transformations. Once binary codes are learned, the inference can be made by virtue of efficient Hamming distance computations. Moreover, the search for candidate entities can be performed via the generative step that projects binary codes onto actual feature space, where kNN-based techniques can be further utilized.",This paper introduces a collaborative generated hashing (CGH) method to learn hash funcations of users and items from content data. The approach first provides a strategy to discover potential users by the generative step and inference through adding balanced and uncorrelated constraints. The experiments demonstrates some effectiveness on improving accuracy for both warm-start and cold-start recommendations.,0.0859375,0.1896551724137931,0.11827956989247312
160,SP:da14205470819495a3aad69d64de4033749d4d3e,This paper investigates the problem of neural network quantization. The main idea is to employ an end-to-end precision highway to reduce the accumulated quantization error and meanwhile enable ultra-low precision in deep neural networks.  The experimental results on the 3- and 2-bit quantizations of ResNet-18/50 and 2-bit quantization of an LSTM model demonstrate the effectiveness of the proposed method. ,"This paper studies methods to improve the performance of quantized neural networks.  The paper is largely centered around the idea of ""precision highways"" (full-precision residual connections) that run in parallel to fully-quantized convolutions.  However, the paper also throws in a toolbox of other methods like distillation from a teacher network, a quantization method based on the Laplace distribution, and a fine tuning scheme.",0.21212121212121213,0.2153846153846154,0.21374045801526717
161,SP:da88bfbe3f59ce1a24522aa5e74c9472b079664a,"The paper studies the limiting behavior of neural tangent kernels when the depth grows to infinity. They show that the obtained limit kernels are trivial (a constant) unless one uses 'edge of caos' initialization, in which case they are close to the identity. The authors compare the convergence for different activations, showing a slower convergence (hence better propagation) for some piecewise smooth activations compared to ReLU. For residual networks, the 'edge of caos' behavior is claimed to be in place regardless of the initialization.","This paper discussed the property of the NTK with the increasing depth L with the help of the Edge of Chaos initialization. The authors show that if deep neural networks are not properly initialized, the NTK can have a large condition number, which leads to the poor performance of training and generalization. Moreover, the authors also introduce the conditions that make the neural network trainable by decreasing the convergence rate to a nearly constant kernel w.r.t the depth L by using the specific Edge of Chaos initialization as well as different activations and use residual connections. Experiment results show that the theoretical results are well aligned with the practice.",0.25,0.1891891891891892,0.2153846153846154
162,SP:dba3f5ec3af2a4a67ed4fc36b0f37fe556354177,This paper borrows the idea of word-to-vector from NLP and applies it in reinforcement learning based Neural Architecture Search (NAS). It suggests a pretrained encoder to transform the search space to a dense and continuous architecture-embedding space. First it trains the architecture-embedding encoder and decoder with self-supervision learning like Auto-Encoder.  Then it performs reinforcement learning based Neural Architecture Search(NAS) in the architecture-embedding space.,"The paper proposes an interesting idea to perform Neural Architecture Search: first, an auto-encoder is pre-trained to encode/decode an neural architecture to/from a continuous low-dimensional embedding space; then the decoder is fixed but the encoder is copied as an agent controller for reinforcement learning. The controller is optimized by taking actions in the embedding space. The reward is also different from previous works which usually only considered validation accuracy but this work also considers the generalization gap.",0.30985915492957744,0.2682926829268293,0.2875816993464052
163,SP:dbb06f953788696f65013765f0a4e6967444fa0f,"This paper proposed how to learn multi-class classifiers without multi-class labels. The main idea is shown in Figure 2, to regard the multi-class labels as hidden variables and optimize the likelihood of the input variables and the binary similarity labels. The difference from existing approaches is also illustrated in Figure 1, namely existing methods have binary classifiers inside multi-class classifiers while the proposed method has multi-class classifiers inside binary classifiers. The application of this technique to three general problem settings is discussed, see Figure 3.","The work is a special case of density estimation problems in Statistics, with a use of conditional independence assumptions to learn the joint distribution of nodes. While the work appears to be impressive, such ideas have typically been used in Statistics and machine learning very widely over the years(Belief Propagation,  Topic modeling with anchor words assumptions etc...). This work could be easily extended to multi-class classifications where each node belongs to multiple classes. It would be interesting to know the authors' thoughts on that. The hard classification rule in the paper seems to be too restrictive to be of use in practical scenarios, and soft classification would be a useful pragmatic alternative. ",0.15555555555555556,0.12280701754385964,0.13725490196078433
164,SP:dc48dbfb8f4f25d3ceb7be607e8f2e0bc8f99f14,"This is a very interesting piece of work. We know from cognitive science literature, that there are 2 distinct modes of decision making - habit based and top-down control (goal directed) decision making. The paper proposes to use this intuition by using information theoretic objective such that the agent follows ""default"" policy on average and agent gets penalized for changing its ""default"" behaviour, and the idea is to minimize this cost on average across states.","This paper studies how to use KL-regularization with information asymmetry to speed up and improve reinforcement learning (RL). Compared with existing work, the major novelty in the proposed algorithm is that it uses a default policy learned from data, rather than a fixed default policy. Moreover, the proposed algorithm also limits the amount of information the default policy receives, i.e., there is an ""information asymmetry"" between the agent policy and the default policy. In many applications, the default policy is purposely chosen to be ""goal agnostic"" and hence conducts the ""transfer learning"". To the best of my knowledge, this ""informationally asymmetric"" KL-regularization approach is novel.",0.21333333333333335,0.14814814814814814,0.17486338797814208
165,SP:dc7dfc1eec473800580dba309446871122be6040,"This paper provides a theoretical analysis for batch normalization with gradient descent (GDBN) under a simplified scenario, i.e., solving an ordinary least squares problem. The analysis shows that GDBN converges to a stationary point when the learning rate is less than or equal to 1, regardless of the condition number of the problem. Some practical experiments are carried out to justify their theoretical insights. The paper is in general easy to follow. ","The author analyze the convergence properties of batch normalization for the ordinary least square (OLS) objective. They also provide experimental results on the OLS objective as well as small scale neural networks. First of all, understanding the properties of batch normalization is an important topic in the machine learning community so in that sense, contributions that tackle this problem are of interest for the community. However, this paper has a significant number of problems that need to be addressed before publication, perhaps the most important one being the overlap with prior work. Please address this point clearly in your rebuttal.",0.1917808219178082,0.14,0.16184971098265896
166,SP:dd59b897384c52c20d62be73fc33184c8c226f4b,The paper proposes a new sentence embedding method. The novelty is to use dependency trees as examples in the self-supervised method based on contrastive learning. The idea to use linguistic knowledge in the design of sentence embeddings is attractive. The sentence representation is computed by a bi-LSTM and dependency tree representations are computed by Tree LSTM. The softmax classifier is trained using the negative log-likelihood loss.,"This paper describes a self-supervised sentence embedding approach that incorporates a different view from plain text where some extent of linguistic knowledge is incorporated through the application of tree LSTM. The training procedure is standard contrastive framework where the model is encouraged to distinguish between context sentence (sentences appearing close to the target sentence) and negative samples. Evaluations are conducted on 1) downstream tasks, but with a simple logistic regression model on top of sentence embeddings; 2) probing tasks that more focus on surface information prediction, syntactic and semantic tasks; and 3) qualitative analysis with nearest 5 sentences.",0.2028985507246377,0.1414141414141414,0.16666666666666666
167,SP:df038354c6a7638116a98d150aa4a8f5f2b0a2da,"This paper proposes a new set of heuristics for learning a NN for generalising a set of NNs trained for more specific tasks. This particular recipe might be reasonable, but the semi-formal flavour is distracting. The issue of model selection (clearly the main issue here) is not addressed. A quite severe issue with this report is that the authors don't report relevant learning results from before (+-) 2009, and empirical comparisons are only given w.r.t. other recent heuristics. This makes it for me not possible to advice publication as is.","This paper presents a method for distilling multiple teacher networks into a student, by linearly combining feature representations from all networks at multiple intermediate layers, and gradually forcing the student to ""take over"" the learned combination.  Networks to be used as teachers are first pretrained on various initial tasks.  A student network is then trained on a target task (possibly different from any teacher task), by combining corresponding hidden layers from each teacher using learned linear remappings and weighted combinations.  Learning this combination allows the system to find appropriate teachers for the target task; eventually, a penalty on the combination weights forces all weight onto the student network, resulting in the distillation.",0.13978494623655913,0.11607142857142858,0.1268292682926829
168,SP:df8483206bb88debeb24b04eb31e016368792a84,This paper studies the certifiable bounds for adversarial perturbations in \ell_2 radius for top-k predictions instead of top-1 predictions.  The paper obtains a certifiable radius of \ell_2 perturbations in the case of top-k predictions (Theorem 1) and shows that the bounds are tight (Theorem 2). The result thus generalizes the results obtained in Cohen et al. (2019) by setting k=1.,"The paper proposes an extension to the work of Cohen et al. where a certified radius is deduced using a randomized smoothing approach. In particular, the authors show the radius at which a smoothed classifier g at under Gaussian perturbations is certified for the top k predictions. That is to say that the prediction will remain within the top k predictions of g. Setting k=1, one recovers Cohen et al. results. The authors show that the derived radius is tight.",0.25757575757575757,0.20987654320987653,0.23129251700680273
169,SP:e2c3374629cfd654b7b35e88507e65646d70470e,"The paper studies the mean and variance of the gradient norm at each layer for vanilla feedforward, ResNet and DenseNet, respectively, at the initialization step, which is related with Hanin & Ronick 2018 studying the mean and variance of forward activations. They show that ResNet and DenseNet preserve the variance of the layer gradient norm through depths. In comparison, for the vanilla feedforward network, although the mean of the gradient norm is preserved if  is properly initialized, the variance of the layer gradient norm increases over depths, which may explode or decay the gradient at deeper layers. ","This paper studies the effects of residual and dense net type connections on the moments of per-layer gradients at random initialization. In particular, using duality, bounds on the variance of the square norm of Jacobian (with respect to the randomness of random initialization) are derived for vanilla networks. By noticing that connections that bypass a specific layer does not affect the expected square norm of the gradients of a particular layer, the paper continue to characterize the bounds for residual networks and densely connected networks that have special skip connections. In particular, with properly chosen initialization scales for each layer, the architectures with skip connections can be initialized so that the gradient norm does not explode with increasing depth.",0.2604166666666667,0.20833333333333334,0.2314814814814815
170,SP:e2e5bebccc76a51df3cb8b64572720da97174604,"The work proposes to learn neural networks using homotopy-based continuation method. The method divides the parameter space into two groups (extendable to multiple groups) and introduces a homotopy function which includes the original optimization problem as an extreme case.  By varying the homotopy parameter, one can construct a continuous path from a supposedly easier to solve optimization problem to the problem of interest. The authors prove convergence in the non-convex case, the existence of solution path in the convex case and demonstrate the effectiveness of the proposed method on synthetic and real datasets.","In this paper, the authors propose the Homotopy Training Algorithm (HTA) for neural network optimization problems. They claim that HTA starts with several simplified problems and tracks the solution to the original problem via a continuous homotopy path. They give the theoretical analysis and conduct experiments on the synthetic data and the CIFAR-10 dataset. ",0.15789473684210525,0.2727272727272727,0.19999999999999998
171,SP:e39bcc2ee6db054f0f1d8e8d04291a78488886ae,"There has been recent interest in using statistics and information summary measures to evaluate what deep nets are trying to do. Following the line of work, the paper suggests to use mean and variance of Z-scores accumulated across all layers/channels as features to distinguish ID and OOD samples. Simple idea but needs some work in its current format. ",The authors present a simple algorithm based on the statistics of neural activations of deep networks to detect out-of-distribution samples. The idea is to use the existing running estimate of mean and variance within BatchNorm layers to construct feature representations that are later fed into a simple linear classifier. The authors demonstrate superior performance over the previous state-of-art in the standard evaluation setting and provide fascinating insights and empirical analysis of their method.,0.23333333333333334,0.18181818181818182,0.20437956204379562
172,SP:e6af249608633f1776b608852a00946a5c09a357,This paper introduces a new method for training a classifier that simultaneously optimizes for a fairness criterion and robustness to data poisoning. The method is shown to increase measures of fairness and reduce inaccuracy on poisoned data relative to classifiers that only consider accuracy or fairness. Extensive results are shown for both synthetic and real benchmark data sets.,This paper combines adversarial fair training with adversarial robust training. The basic idea is that a classifier is combined with two adversaries: one tries to predict the sensitive attribute $Z$ from the output of the classifier (essentially the approach by Edwards&Storkey 2015) and the other adversary tries to recognize if a label was predicted or is from a clean hold-out dataset. The latter is intended to harden the classifier against data-poisoning of the training set.,0.20689655172413793,0.15384615384615385,0.17647058823529413
173,SP:e80d6118fc3b9ff3195fea2f6adac88e59d350c2,"The paper considers the problem of robust high dimensional estimation in Huber’s contamination model. The algorithm is given samples from a distribution (1 - eps) * P + eps * Q, where P is a “nice” distribution (e.g. a Gaussian), eps is the fraction of contaminated points, and Q is some unconstrained noise distribution. The goal is then to estimate parameters of P as well as possible, given this noise. The settings they primarily consider in this paper are when P is a Gaussian with unknown mean and identity covariance, or when it is a Gaussian with unknown covariance. Classical estimators such as Tukey depth or matrix depth for these problems achieve optimal minimax rates, but are computationally expensive to compute. However, recent work of [1,2] propose efficient estimators for this problem that (nearly) achieve these rates.","This paper considers the robust estimation problem under Huber’s \epsilon-contamination model. This problem is a hot topic in theoretical statistics and theoretical computer science community in recent 3 years.  From theoretical statistics community, the main approach is through depth functions. Solving the robust estimation problem can be reduced to solving a min-max problem. While the formulation is clean and can achieve the optimal statistical rate, solving the min-max problem is computationally intractable in general. On the other hand, approaches from TCS community are more involved and sometimes cannot achieve the optimal statistical rate (especially for the general distribution). ",0.16911764705882354,0.22549019607843138,0.19327731092436976
174,SP:e8a3a0f77dab336ce50c9dc941f7350173916e04,"This paper presents White Box Network (WBN), which allows for composing function blocks from a given set of functions to construct a target function. The main idea is to introduce a selection layer that only selects one element of the previous layer as an input to a function block. This allows for both introducing function priors as well as interpreting the learned function. The paper also presents a setting where each function block is a neural network that can be learned end-to-end using a PathNet style setting and shows positive transfer across MNIST and CIFAR classification tasks.","This paper investigates the question of identifying concise equations from data to understand the functional relations. In particular, a set of base functions are given in hand and the goal is to obtain the right composition of these functions which fits the target function. The main contribution of the paper is to introduce a selection layer, which enhances sparse connections in the network. Several experiments are conducted to show the effectiveness of the method. ",0.2222222222222222,0.2972972972972973,0.2543352601156069
175,SP:e98ec7fd9c27eabd7f5bf3429f984034c2d355a2,"The paper investigates data poisoning type of attack. In such attacks, an adversary can alter/flip the labels of some of the training examples. The paper proposed a new approach towards certified robustness against this type of attack. In particular, the new classifier will output a prediction along with a certificate in which the prediction would not change if certain number of labels in the training data were flipped.","This paper proposes a certifiable defense against data poisoning attacks by using a randomized smoothing approach. An adversary in such a setting is permitted to flip any r labels from a dataset of size n. The smoothing procedure (stated roughly) is to train on a dataset with ""noisy"" or ""smoothed"" labels, obtained by flipping each label with some probability q. The authors obtain a lower bound on r in terms of q. Directly using this technique requires training multiple classifiers on multiple noisy datasets. To show that this method is useful, the authors study the effectiveness of this model against a classifier that performs linear regression on a pre-trained feature extractor. ",0.2463768115942029,0.15178571428571427,0.1878453038674033
176,SP:eaeee88e0717cda8d6f3d8ff83ebe594eba44f29,"Overall, I'm not quite convinced this method would be worth the trouble to implement. On the more realistic benchmarks, they need to keep ~80% of the total dataset size and the claimed ""improvement"" is rather small (less than 0.6% absolute gain in accuracy, e.g. from 81.86% to 82.37% on CIFAR100 and from 72.33% to 72.78% on ImageNet). There is no runtime comparison, there are missing baselines, and most of the method development seems guided by trying out many options instead of taking a principled approach. Without these, the paper is just not ready for a top conference like ICLR.","This work makes use of uncertainty estimation methods from active learning to select a subset of training data that produces models with similar (or better) performance compared to models trained on the full training set. It proposes a way to improve the Monte Carlo estimation of model uncertainty by including multiple checkpoints that are generated ""for free"" during a training run, thereby increasing the number of samples from 5-10 in previous work to 100 in this work. It compares several initialization schemes for the subset model using mutual information as the acquisition function, finds that a ""build-up"" approach (based on Chitta et. al 2018a) works best, and uses that for the rest of the studies. It then compares several acquisition functions, using the build-up approach, finds that variation ratio performs best, and uses that for the rest of the studies. Next, it compares the Top-1 accuracy on ImageNet obtained by evaluating the ensemble models produced by different ensembling schemes, and finds that ensembling 20 checkpoints from 5 training runs with different random seeds work best. Then, it uses acquisition models that use ensembles from each ensembling scheme to select subsets of the ImageNet data to be used for training the subset model, and then compares the performance of the subset models. Finally, it demonstrates this method of selecting a subset of the training data works even if the subset is used to train a model with a different architecture from the acquisition model.",0.22641509433962265,0.09716599190283401,0.1359773371104816
177,SP:eda1d368aa3b4d806020c4c430a173d1ddd13d0d,"The paper claims that it identifies a fundamental issue in model-based reinforcement learning methods. The issue is called objective mismatch, which arises when one objective is optimized (for example, model learning objective) without taking into consideration of another objective (for example policy optimization). The author shows several experiments to illustrate the issue and proposes a method to mitigate it by assigning priorities to samples when training the model. ","This paper discusses the old problem of mismatch between the ultimate reward obtained after optimizing a  decision (planning or control) over a probabilistic model (of dynamics) and  the training  objective for the model (log-likelihood). Experiments highlight that the NLL and reward can be very poorly correlated, that improvements in NLL initially improve reward but can later degrade it, and that models with similar NLLs can lead to very different rewards. A  reweighting trick is proposed and summarily evaluated.",0.18840579710144928,0.16455696202531644,0.17567567567567566
178,SP:ef1c6403597c3a6083c1ad4256449325ac99416c,"This paper proposes a new gradient descent methods for training deep neural network which can take the adaptive step size with only one hyper-parameter to tune -- the maximum learning rate -- and achieve comparable results to stochastic gradient descent (SGD) on various tasks and models. In order to achieve that, they develop a stochastic extension of the Polyak step-size for the non-convex setting, namely the adaptive learning-rates for interpolation with gradients (ALI-G), in which the minimal value of the objective loss is set to 0 due to interpolation in neural networks and the learning rates are clipped by a chosen maximal value. The problem is formulated clearly, and the review on the Polyak step-size and related works are well done. Another main contribution of the paper is to provide the convergence guarantees for ALI-G in the convex setting where the objective loss is Lipschitz-continuous (Theorem 1 in the paper). Their theorem also takes into account the error in the estimate of the minimal value of the objective loss. In addition, they derive the connections between  ALI-G and SGD and show that compared to SGD, ALI-G take into consideration that the objective loss is non-negative and set the loss to 0 when it is negative. They perform empirical study to compare their algorithm with other methods including Adagrad, Adam, DFW, L4Adam and SGD on learning a differentiable neural computer, object recognition, and a natural language processing task. Their experimental results show that ALI-G performance is comparable with that of SGD with schedule learning rate.","This paper proposes a new adaptive learning rate method which is tailored to the optimization of deep neural networks. The motivating observation is that over-parameterized DNNs are able to interpolate the training data (i.e. they are able to reach near-zero training error). This enables application of the Polyak update rule to stochastic updates and a simplification by assuming a zero minimal training loss. A number of proofs for convergence in various convex settings are provided, and empirical evaluation on several benchmarks demonstrates (a) ability to optimize complex architectures, (b) performance improvements over, and (c) performance close to manually tuned SGD learning rates.",0.12121212121212122,0.3047619047619048,0.1734417344173442
179,SP:efd68097f47dbfdd0208573071686a62240d1b12,"The paper proposes a new joint learning algorithm that works for two tasks, NER and RE. The model is based on a pre-trained BERT model, which provides the word vectors of the input word sequence. Then it solves two tasks with two network branches: the first branch minimizes the loss for NER, and the second branch minimizes the loss for RE. The second branch uses entity labels predicted by the first branch, so joint learning may benefit both tasks. ","The paper proposes an end-to-end joint model for named entity recognition (NER) and relation extraction (RE), using pre-trained language models. The model is very simple, with the key is to use BERT and take NER output as input to RE. The experimental results show the model, without the need for handcrafted features, get state-of-the-art results on five datasets. ",0.225,0.28125,0.25
180,SP:f167ad4bb1e140f692ec71c8baf0a59bff7bbc6f,"This submission proposes a reinforcement learning framework based on human emotional reaction in the context of autonomous driving. This relies on defining a reward function as the convex combination of an extrinsic (goal oriented) reward, and an intrinsic reward. This later reward is learnt from experiments with humans performing the task in a virtual environment, for which emotional response is quantified as blood volume pulse wave (BVP). The authors show that including this intrinsic reward lead to a better performance of a deep Q networks, with respect to using the extrinsic reward only. ","Starting from the hypothesis that humans have evolved basic autonomic visceral responses that influence decision making in a meaningful way and that these are at work in driving a car, the authors propose to use such signals within the RL framework. This is accomplished by augmenting the RL reward function with a model learned directly from human nervous system responses. This leads to a ",0.12903225806451613,0.1875,0.15286624203821655
181,SP:f17090812ace9c83d418b17bf165649232c223e3,"This paper continues the study of the signSGD algorithm due to (Balles & Hennig, Bernstein et al), where only the sign of a stochastic gradient is used for updating. There are two main results: (1) a slightly refined analysis of two results in Bernstein et al. The authors proved that signSGD continues to converge at the 1/sqrt(T) rate even with minibatch size 1 (instead of T as in Bernstein et al), if the gradient noise is symmetric and unimodal; (2) a similar convergence rate is obtained even when half of the worker machines flip the sign of their stochastic gradients. These results appear to be relatively straightforward extensions of those in Bernstein et al.","The authors present a distributed implementation of signSGD with majority vote as aggregation. The result is a  communication efficient and byzantine robust distributed training method. This is an interesting and relevant problem. There are two parts in this paper: first the authors prove a convergence guarantee for signSGD, and then they prove that under a weak adversary attack signSGD will be robust to a constant fraction of adversarial nodes. The authors conclude with some limited experiments.",0.1565217391304348,0.23684210526315788,0.18848167539267016
182,SP:f2c3dd2b485d6307847c759a5609b7ebe24b7058,"In this paper, the authors provide a new neural-net model of logical formulae. The key feature of the model is that it gathers information about a given formula by traversing its parse tree top-down. One neural net of the model traverses the parse tree of the formula from the root all the down toward the leaves, and generates vectors for the leaves of the tree. Then, another RNN-based neural net collects these generated vectors, and answers a query asked for the formula, such as logical entailment. When experimented with Evans et al.'s data set for logical entailment queries, the authors' model outperforms existing models that encode formulae by traversing their parse trees bottom-up.","In this paper the authors propose a neural model that, given a logical formula as input, predicts whether the formula is a tautology or not. Showing that a formula is a tautology is important because if we can classify a formula A -> B as a tautology then we can say that B is a logical consequence of A. The structure of the formula is a feedforward neural network built in a top-down manner. The leaves of this network are vectors (each of them represents a particular occurrence of an atom) which, after the construction of the formula, are processed by some recurrent neural networks.",0.23728813559322035,0.26666666666666666,0.25112107623318386
183,SP:f2f01c7c4fb68c25d6e5ac56cbf79615ed1ee9ee,"This paper aims to address the problem of lacking sufficient demonstrations in inverse reinforcement learning (IRL) problems. They propose to take a meta learning approach, in which a set of i.i.d. IRL tasks are provided to the learner and the learner aims to learn a strategy to quickly recover a good reward function for a new task that is assumed to be sampled from the same task distribution. Particularly, they adopt the gradient-based meta learning algorithm, MAML, and the maximal entropy (MaxEnt) IRL framework, and derive the required meta gradient expression for parameter update. The proposed algorithm is evaluated on a synthetic grid-world problem, SpriteWorld. The experimental results suggest the proposed algorithm can learn to mimic the optimal policy under the true reward function that is unknown to the learner. ","This paper attempts to the solve  data-set coverage issue common with Inverse reinforcement learning based approaches - by introducing a meta-learning framework trained on a smaller number of basic tasks. The primary insight here is that there exists a smaller set of unique tasks, the knowledge from which is transferable to new tasks and using these to learn an initial parametrized reward function improves the coverage for IRL. With experiments on the SpriteWorld synthetic data-set, the authors confirm this hypothesis and demonstrate performance benefits - showcasing better correlation with far fewer  number of demonstrations.",0.1865671641791045,0.2631578947368421,0.21834061135371177
184,SP:f46f0cb43274fb20cba91ef7318305f668bc6928,"This paper proposes to use 8/4-bit approximation of activations to save the memory cost during gradient computation.  The proposed technique is simple and straightforward. On the other hand, the proposed method only saves up to a constant cost of the storage. With the constant factor (4x, 8x) depending on whether fp16 or fp32 is used during computation. Notably, there is a small but noticeable accuracy drop in the final trained model using this mechanism.","The authors detail a procedure to reduce the memory footprint of deep networks by quantization of the activations only on back propagation. While this scheme does not benefit from computational speedups of activation quantization on both passes (and indeed has a slight computational overhead), the authors demonstrate that for common convolutional architectures it nicely preserves the accuracy of computation by computing the forward pass at full accuracy and limiting propagation of errors in the backward pass. This is possible because the majority of errors are introduced in gradient calculation of the weights and not the inputs each layer. The authors also wisely perform quantization after batch normalization and use the known mean and variance of the activations to scale the quantization and reduce errors. They demonstrate very slight drops in performance accuracy for ResNets on Cifar10, Cifar100, and ImageNet with memory compression factors up to 8. They also point to natural future directions such as using vector quantization to better leverage the activation statistics. The paper is also very clearly written with appropriate references to the relevant literature. ",0.21052631578947367,0.0898876404494382,0.12598425196850394
185,SP:f4a914d3df1a5a21a7365ba78279420f39210884,"This paper proposes a classifier-agnostic method for saliency map extraction. In order to address the dependence of saliency map extraction on the classifier, the authors propose to learn a saliency mapping by considering all possible classifiers (i.e., a certain classifier structure w.r.t. the space of all its parameters). The goal is to find the relevant features in the data that work with all possible classifiers. The proposed framework is formulated as a min-max game between two players: a mask m corresponding to the saliency mapping, and a function f sampled from a set of classifiers with the same structure but different parameters. The mapping m is optimized to maximize the masked-out classification error (such that m captures all relevant features whose removal can maximally confuse the classifier), while f is optimized to minimize the mask-out classification error.","This paper focuses on the extraction of high-quality model-agnostic saliency maps. The authors argue that when an extracted saliency map is directly dependent on a model, then it might not be useful for a different classifier and thus not general enough. To overcome this problem, they consider all the possible classifiers weighted by their posterior probabilities. This problem cannot be solved explicitly, and the authors suggest a scheme to approximate the solution using two networks. That is, pretrain an initial classifier and then, following an adversarial training procedure, one network is trying to confuse the classifier and the other one to maximize its accuracy. Using this formulation, the authors report state-of-the-art results for salience map extraction.",0.1875,0.2231404958677686,0.20377358490566036
186,SP:f5be102f16ed9ac70a2e9e2580111226fb0d8b71,"The paper presents a method for identifying and selecting the most informative subset of the training dataset in order to reduce training time while maintaining test accuracy. The method consists of training a proxy model that is smaller and has been trained for fewer epochs, and which can optionally be ensembled. Experiments show promising results, indicating that some datasets can be reduced to half the size without impacting model performance.","This paper studies a very simple and intuitive method to boost the training speed of deep neural networks. The authors first train some light weighted proxy models, using these models to rank the data according to its uncertainty, and then pick the most uncertain subset to train the final model. Experiments on CIFAR10/SVHN/Amazon Review Polarity demonstrates the effectiveness.",0.17142857142857143,0.2,0.18461538461538463
187,SP:f5da908b5f6c19a059d2447b9cda15af5e12dc55,"This paper studies distributed optimization in the presence of straggling computing nodes. In a synchronous distributed optimization approach, the stragglers delay the entire computation as the synchronization operation cannot be performed till every computing nod has completed its task. This paper aims to mitigate the effect of stragglers by proposing Anytime MiniBatch (AMB) approach, where each computing node is allowed to process the different number of samples between two synchronization steps. In particular, each node is given $T$ unit time to process as many samples as it can. After that, the nodes are allowed to aggregate the information among themselves through a consensus mechanism for another $T_c$ unit time. In contrast with this, the usual Fixed MiniBatch (FMB) approach requires each node to process a fixed number of samples before invoking aggregating step. The presence of stragglers can significantly increase the time between two synchronization step and slow down the overall optimization process. ","The paper considers the problem of online stochastic convex optimization in a fully distributed topology. In particular, the authors focus on the synchronous setting and to avoid the slow progress that can be obtained by slow nodes, called stragglers, they propose an online distributed optimization method called Anytime Minibatch (AMB). In the update of AMB rather than fixing the minibatch size, they fix the computation time in each epoch. This characteristic prevents the stragglers from holding up the entire network, while allowing nodes to benefit from the partial work carried out by the slower nodes. ",0.16233766233766234,0.2631578947368421,0.20080321285140562
188,SP:f63e4ed39d577b50eab4f4b6d08ef912a69840ef,"This paper investigates the use of a simple architecture for entity disambiguation: encode the mention and its context with BERT, use an MLP over the mention's fenceposts to compute an embedding, then compare that embedding with embeddings of entity candidates and take the one with the highest dot product. Notably, it uses a transformer pre-trained on Wikipedia to do entity resolution, but does *not* use the BERT model or its pre-trained parameters directly.  The paper deals with several design decisions along the way: how to pre-train this model on Wikipedia, how to generate candidates at train and test time, whether or not to mask the input as in BERT, and other hyperparameters. Results show state-of-the-art performance on CoNLL (with a good candidate set) and TAC-KBP, as well as good performance on end-to-end entity linking (detecting and linking mentions).","The paper describes an evaluation of several pre-training strategies for the task of entity linking, using the AIDA and TAC-KBP baselines. In particular, the authors look at the impact of entity candidate selection strategies, adding noise during pre-training, and context selection methods. The model employed for entity disambiguation is a 4-layer transformer for the language representation, with an MLP final layer to perform disambiguation. The analysis of the pre-training strategies is detailed, and could be interesting for others using the transformer architecture to perform entity linking. Minor issue, but the paper is missing a conclusion section - this could be used to discuss how these results can generalize to other methods for entity linking.",0.17567567567567569,0.22033898305084745,0.19548872180451127
189,SP:f66721bf3eccf2e36444c2c41303e97745f10f0e,"This paper proposes to employ conditional variational autoencoder (CVAE) to estimate the geometry of 2D rotations of objects given images partially labeled. Here, the label represents the geometry of the 2D rotation. The proposed method introduces two latent representation. z is the ordinal latent variable and r a latent representation for the rotations where the latent variable is defined in the 1-dimensional circle in R^2 so that it can naturally represent a hyperspherical latent space. ","This paper presents a semi-supervised approach to learn the rotation of objects in an image. The primary motivation is that for rotation estimation datasets may not always be fully labeled, so learning partially from labeled and partially for unlabeled is important. The approach is to use a CVAE with a supervised loss and an unsupervised loss and to jointly train the network. Limited experiments that show performance are presented.",0.18181818181818182,0.2,0.1904761904761905
190,SP:f6cb7efaef82aff9849c8e157bfe5db5092a6271,"> Even though the paper details the underlying Markovian setup in Section 2, it is unclear to the reader how this knits with the FFNN architecture, for example what are the Markovian functions at hidden layer and output layer. Are they all conditional probabilities? How do you prove that this is what occurs within each node?","This paper tackles the important challenge of making sense of temporal measurements made in biological systems. Among other, those have the peculiarity that they are not independent but with a dependency structure, which can be encoded as a graph or a network. The authors claim that their approach, DyMoN is adapted to the many challenges of biological high-throughput data sets: noise, sparsity and lack of temporal resolution. The paper presents three very different use of the method in complex biological systems in Section 3: (i) Calcium imaging of visual cortex neurons, (ii) T--cell development in the thymus, and (iii) Human embryonic stem cell differentiation. Section 4 assesses the performance of the method on simulated data sets as well as on a face-recognition data set. Moreover, the authors demonstrate how the features of the NN can be interrogated to shed new insight about the process under scrutiny. They also show the gain in running time a comapred to other approaches.",0.18181818181818182,0.06172839506172839,0.09216589861751151
191,SP:fb726f0fea2ed1a009b3aacf74ac149bcf988cdd,"The paper introduces an approach to answering queries on knowledge graphs, called Query2Box. The idea is to work with the embeddings of the vertices of the knowledge graph as if they were kind of sets. In this way, from a set, called box, of entities embeddings it is possible to project them to find other boxes using the relations specified by the query (these boxes contain the embeddings of the entities linked with those of the previous box by the relation specified in the query), or to intersect them to find the common entities.","This paper proposes a method to answer complex logical queries in large incomplete knowledge bases (KB). Specifically it considers the class of existential first-order logical queries (EPFO) which includes the logical and, or and existential operator.  The key contribution of this paper is to represent sets of entities via regions, more specifically as boxes or hyper-rectangles. This is well motivated because such logical queries often involves working over sets of entities at once and involves applying set based operators. Previous work which represented queries as a point in vector space are not well suited for these queries.",0.18085106382978725,0.1717171717171717,0.1761658031088083
192,SP:fbb7bb8b4f75715f139c702750b28e7e87aa0e1f,"The authors study building models for edits in source code. The application is obvious: a system to accurately predict what the next edit should be would be very valuable for developers. Here, edits are modeled by two types of sequences: one that tracks the state of all edits at each time step (and is thus very long), and one that contains the initial step and a changelist that contains the minimal information required to derive the state at any time. The authors train models on top of both of these representations, with the idea being to match the performance of the explicit (heavy) model with the implicit model. This is shown to be challenging, but a clever model is introduced that achieves this, and is thus the best of both worlds. There are synthetic and real-world code (text) edit experiments.","The paper provides good baselines for predicting edits in a text (evaluated on source code) learned from a history of changes. This is an interesting problem that has not beed systematically studied in literature, with the exception of several sporadic works from the software engineering community. Fully predicting the code text writing process as opposed to the code itself is an interesting task with possible big impact, IF the accuracy of this edit model manages to significantly outperform simple left-to-right code text prediction techniques.",0.15602836879432624,0.2558139534883721,0.19383259911894274
193,SP:fbfe2c90a70a6adf39fa4d4a3c28f6b5adbc6c06,"The paper proposes SOLAR a model based RL algorithm that learns a low dimensional embedding such that the dynamics within the latent space are linear. Within this latent space the linear dynamics  are learned using a Bayesian regression. In addition, a quadratic cost function is approximated. The learned dynamics and the cost function are used to update the policy, while simultaneously bounding the change in policy by a KL-bound.  In contrast to other model-based RL algorithms the learned dynamics are not used for planning or imaginary roll-outs and are only used to improve the policy.","In this work the authors propose an end to end approach for model based reinforcement learning from images, where the main building blocks are locally-linear dynamical systems and variational auto-encoders (VAE). Specifically, it is assumed that the input features (i.e., the images) are generated from a low dimensional latent representation mapped through parametric random functions; the latter are modeled via neural networks. A recognition model based on convolutional neural networks operates on the reverse way and is responsible for projecting the input features to the latent space, in order to proceed with the reinforcement learning task. The variational framework is employed in order to jointly learn the VAE and the linear dynamics on the latent state. As a final step, once the model is fitted a linear quadratic system (LQS) is solved in order to learn the cost function and the optimal policy. ",0.25510204081632654,0.17123287671232876,0.20491803278688528
