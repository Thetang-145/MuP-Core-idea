,paper_id,summary,summary,precision,recall,fmeasure
,,0,1,0-1,0-1,0-1
0,SP:0007ee9ce7dfaf12a7dff4aa2979403aed9397d7,"This paper proposed a novel benchmark for relation extraction from very long documents and a new method -- KnowFi to deal with the problem. The dataset is constructed from Wikia containing long fictional texts. The method, KnowFi, generally contains two modules -- passage ranking and multi-context neural extraction. They first rank the source passages via a similarity function and then feed the top-$k$ passages to a BERT-based multi-context neural extraction module to get its relation. Experiments showed that KnowFi achieved strong performance on this new benchmark and two conventional short-text benchmarks.","The paper focuses on the relation extraction task from long fictional texts (i.e., book-level RE), which is an important step towards KB construction from books. The authors present a neural architecture to address the challenges such as sparsity, distant-supervision, size limitation, etc. Although the proposed method is not particularly novel, the paper presents a nice first work in this direction. The authors also provide a new benchmark LoFiDo for evaluating different methods, which is also a great contribution.",0.1702127659574468,0.19753086419753085,0.18285714285714283
1,SP:001a31f7a439ab22943dedb4fa4d46e3dd56e603,"This paper is an interesting exploratory study analyzing the ability of language models to track the state of a chessboard. The authors adopt a clever chess notation which allows them to probe the language model's state tracking ability by looking at its next word prediction (akin to probes in [1]). Quite remarkably, language models finetuned on chess data store a very accurate state representation, and predict legal moves over 90% of the times even without a visual representation of the board.","This paper explores learning chess from raw notation as a benchmark for the ability of language models to track world state. Chess is an interesting benchmark, as a set of moves can be unambiguously linked to a world state, there are large amounts of data available and the model can easily be probed for its board tracking abilities. The contributions of this paper are twofold: (i) introducing blindfolded chess as a benchmark for grounded language learning and world state tracking, as well as a suite of probing tasks to evaluate models; (ii) empirical evidence that transformer language models can learn both the rules of the game and to track board state.",0.2926829268292683,0.21621621621621623,0.24870466321243523
2,SP:001e57e71bafdb52d6511bdd6aa73b78d60248f2,"The manuscript considers the problem of imitation learning when the system dynamics of the agent are different from the dynamics of the expert. The paper proposes Indirect Imitation Learning (I2L), which aims to perform imitation learning with respect to a trajectory buffer that contains some of the previous trajectories of the agent. The trajectory buffer has limited capacity and adds trajectories based on a priority-queue that prefers trajectories that have a similar state distribution to the expert. Similarity is hereby measured by the score of a WGAN-critic trained to approximate the W1-Wasserstein distance between the previous buffer and the expert distribution. By performing imitation learning with respect to a trajectory buffer, state-action trajectories of the agent's MDP are available, which enables I2L to apply AIRL (Fu et al. 2017). By using those trajectories for the transition buffer that have state-marginals close to the expert's trajectory, I2L produces similar behavior compared to the expert. I2L is compared to state-only GAIL, state-action-GAIL and AIRL on four MuJoCo tasks with modified dynamics compared to the expert policy. The experiments show that I2L may learn significantly better policies if the dynamics of agent and the expert do not match.","The paper proposes an imitation method, I2L, that learns from state-only demonstrations generated in an expert MDP that may have different transition dynamics than the agent MDP. I2L modifies the existing adversarial inverse RL algorithm: instead of training the disciminator to distinguish demonstrations vs. samples, I2L trains the discriminator to distinguish samples that are close (in terms of the Wasserstein metric) to the demonstrations vs. other samples. This approach maximizes a lower bound on the likelihood of the demonstrations. Experiments comparing I2L to a state-only GAIL baseline show that I2L performs significantly better under dynamics mismatch in several low-dimensional, continuous MuJoCo tasks.",0.15121951219512195,0.29523809523809524,0.2
3,SP:004f41dfc870c5a9b347d118d7e41d7c3db77b91,"This paper uses pruning and model distillation iteratively to reduce the model sizes. The pruning step is based on Molchanov et al. (2017). This is followed by a hints step that minimizes the feature map difference between student and teacher. Finally, a reconstruction step is used to restore original weights. Results are shown on CIFAR-10, Imagenet and COCO datasets for classification and pose estimation tasks where PWH reduces model costs with a small loss in accuracy.","This paper proposes a new framework which combines pruning and model distillation techniques for model acceleration. Though the ``pruning” (Molchanov et al. (2017)) and hint components already exists, the authors claim to be the first to combine them, and experimentally show the benefit of jointly and iteratively applying the two techniques. The authors show better performance of their new framework over baseline, pruning only method and hint only method on a few standard Vision data set.",0.23376623376623376,0.23684210526315788,0.2352941176470588
4,SP:00578dd55a640c10dbf22f647b736e49f6ee3c32,"The authors introduce CP-Flows, a way to parameterize normalizing flows by constructing an input-convex neural net with softplus-type activation functions and considering its gradient as the flow. They add a quadratic term to ensure invertibility. Using convex optimization techniques their method only needs access to convex optimization solvers. They show that this architecture is universal (that is, starting from a measure $\mu$, there is a sequence of CP-Flows converging weakly to a desired distribution $\nu$). They also prove that the constructed flow converges pointwise to the optimal Brenier map for Euclidean cost. They perform a set of experiments on synthetic and real-world datasets, and show their method delivers its promises.","This paper proposes the flow based representation of a probability distribution so that the corresponding density remains tractable. In particular, the push-forward map that generates the desired distribution is characterized by the gradient of a strongly convex potential function. The invertability of the mapping as well as the Jacobian of the mapping is hence guaranteed by such a convexity property of the potential function. The proposed CP-flows are proved to be universal density approximators and are optimal in the OT (2-Wasserstein) sense.",0.12173913043478261,0.16470588235294117,0.14
5,SP:006c2334ad366e0c4558bcfccdd89f993fb8bba7,"The paper proposes a method for exploiting structure in locomotive tasks for efficiently learning low-level control policies that pass through waypoints while achieving some goal (typically 3D Cartesian position). This is in contrast to goal-conditioned RL policies that sample random goals during training and are thus sample inefficient, which are trained to execute one policy at a time. In particular, the paper proposes the notion of generalized experiences, where new trajectories are generated from existing trajectories, in such as a way that they are equivalent to each other (in this case translation and orientation invariant) with respect to actions.  ","This paper proposes a method to learn locomotion and navigation to a goal location or through a set of waypoints for simulated legged robots. The contributions of this paper include 1) generalized experience, which is a data-augmentation technique to add more orientation-invariant experience, and 2) a latent representation to encode the state, the current location and the goal location. The paper compares the proposed method with a few baselines and demonstrates better performance.",0.15841584158415842,0.21333333333333335,0.18181818181818182
6,SP:00a3a2ca6324e5f2db45bbad11bf97491037c26c,"The proposed method exploits the randomized smoothing techniques for a certified watermark of neural networks. The idea itself is novel and interesting. To the best of the reviewer's knowledge, no one has ever used randomized smoothing for neural network watermark. Different from the defense against adversarial example, in the case of watermark detection, not only the detection accuracy but false detection of non-watermarked models should be considered. If my understanding is correct, the proposed method does not give certification on the false detection.  Since the proposed method is quite close to adversarial training, one concern is that models trained with adversarial training might be falsely detected as the watermarked model. ","This paper present the first certifiable neural network watermark method. By extending method proposed by Chiang et.al. [1] to the watermark embedding and extraction process, it is possible to ensure that the watermark is robust to watermark removal when the network parameters are modified by less than a certain calculated value. Specifically, the proposed method adds Gaussian noises to parameters instead of images. Overall, the idea of making a provable model watermark is novel. ",0.14285714285714285,0.21333333333333335,0.17112299465240643
7,SP:00af76b0f241598c5d3c11fc330d6426a1dcd473,"The authors proposed graph deconvolution layers (GDNs) and employ GDNs to learn graph embedding in a encoder-decoder framework. The authors performs inverse signal recovery in spectral domain and then conducts a de-noising step in wavelet domain to remove the amplified noise. The proposed method can outperform baseline methods on graph classification and social recommendation. However, there are some issuses should be solved.",The main contribution of this paper is that the authors design a graph deconvolutional network that combines inverse filters in the spectral domain and de-noising layers in the wavelet domain. Further graph autoencoders are proposed based on the graph convolutional networks and the graph deconvolutional networks. Many experiments are done and many previous methods are compared to show the effectiveness of the proposed networks.,0.28125,0.27692307692307694,0.27906976744186046
8,SP:00b48a43a5037915e21ddb2f0941cdd26a69d44d,"In this paper, the authors propose a new method of self-supervised feature learning from videos based on learning future frame prediction. The idea is similar as BERT like NLP tasks, but for videos, the computational cost and memory cost could be very large. To solve this problem efficiently, the authors adopt several existing techniques such as pixel shuffle layer, 3D-CNN,  ConvRNN and Attention module to efficiently and effectively capture video information. Experiments on several datasets are conducted to show the effectiveness of the proposed method.","This paper introduces Conditionally Reversible Network (CrevNet) that consists of the invertible autoencoder and a reversible predictive module (RPM). The two-way autoencoder is an invertible network that preserves the volume with no information loss while reducing memory consumption by using bijective downsampling. The RPM is a recurrent extension of two-way autoencoder that provides the reversiblity in temporal domain. The experiments on Moving MNIST, Traffic4cast, KITTI, and 2D object detection on KITTI show the improvement compare to other state-of-the-art models. ",0.1724137931034483,0.17857142857142858,0.17543859649122806
9,SP:00e138bcd2ec3bc1fd4566af8434acf78e6f16be,"To generate a sequence of high-level visual elements for recreation or translation of images, the authors propose differentiable ""canvas"" networks and ""drawer"" networks based on convolutional neural networks. One of the main ideas is the replacement of the ""canvas"" networks instead of non-differentiable ""renderer"" to end-to-end train the whole model with mean-squared error loss. It seems to be a novel approach to optimize drawing actions. It is reasonable to use separate networks to approximate the behavior of renderer and to fix the parameters of the ""canvas"" networks to maintain the pretrained rendering capability.","This paper presents an unsupervised method for generating images in a high-level domain (brush strokes and geometric primitives). The proposed system is comprised of two neural networks: the drawer D and a forward model C of an external renderer R. The latter is trained on the rollouts produced by sending random actions to R. The forward model is then freezed and used to train D, i.e., the network that repeatedly interacts (sends commands) with the C to produce a desired image. Since everything is differentiable, D can be optimized via regular gradient descent.",0.19387755102040816,0.2,0.19689119170984457
10,SP:00f68b4f5ceeddc2e6b93cfdf1a75599bffd2acb,"At its heart, the paper explores which inductive biases (and image representations) enable CNNs to generalize better across 2D transformations including rotations, translations and scale variations. The paper starts by proposing a methodology for generating a controlled dataset of binary masks consisting of random polygons. All training and testing is conducted on this dataset. After showing that convolutions and high data diversity enable better generalization across these transformations, the paper proposes two additional ways to improve performance. Firstly, their approach transforms input images into log-polar space, as object rotations in the original space is equivalent to translations in this space, and thus convolutions on log-polar space are equivariant to rotations in the original pixel space. Secondly, the paper proposes an iterative approach to model transformations, where output mask generated by their Encoder-Decoder model is fed back into the network as an input. The motivation behind this iterative approach is that these transformations form a symmetric group, and so the output after k iterations is still a member of the set which can be reached via a single transformation. The motivation is that such training would force the network to preserve the shape being transformed across iterations. The paper shows that networks trained with these inductive biases and training methodologies do indeed generalize better across these 2D transformations.","The authors trained autoencoders and variational autoencoders in cartesian space, as well as autoencoders in log-polar space, with generated data representing a range of interesting transformations. They then tested the ability of the models to extrapolate beyond the learned transformations in pixel space. The authors find that iterative training, data diversity, convolutions, and transformation to log-polar space all improve the generalization performance. ",0.08181818181818182,0.28125,0.1267605633802817
11,SP:00fed729e27d8c9d2a3d96fdb7e54c3e5cc0a94d,"The paper proposes a generative model for images. There's a probability mask per-pixel per-component (which yields mixing probabilities), and then a set of latents per-component that yield an image. The system is tested on a set of scenes like the GQN dataset, stacks of blocks, and the multi-dsprites dataset. The system is better than MONet, although there are a few lingering questions.","The authors propose a probabilistic generative latent variable model representing a 2D image as a mixture of latent components. It formulates the scene generation problem as a spatial Gaussian mixture model where each Gaussian component comes from the decoding of an object-centric latent variable. The contribution of the proposed method from previous works is the introduction of an autoregressive prior on the component latents. This allows the model to capture autoregressive dependencies among different components and thus help generate coherent scenes, which has not been shown in the previous works. In the experiments, the authors compare GENESIS with MONet and VAEs qualitatively and quantitatively and show that the model outperforms the baseline in terms of both scene decomposition and generation.",0.2537313432835821,0.14049586776859505,0.18085106382978722
12,SP:0119dbfec5c29bceae3332c902780f1e8319504a,"This paper proposed Neural Hyperlink Predictor (NHP) to perform link prediction based on graph convolutional network (GCN). Following prior work, the hyperlink prediction is perform in the dual hypergraph, where each node represents a hyperlink in the primal hypergraph. The original problem is then equivalent to a simple node classification problem. To deal with directed hyperlink, a separate term is added to distinguish heads from tails.",This paper proposed to use graph convolutional neural networks for link prediction. The authors proposed to use the dual graph to simultaneously learn node and edge embeddings. The label of the edges (positive or negative) are used as supervised signal for training the GCNs. Experiments on a few small data set prove the effectiveness of the proposed approaches.,0.19696969696969696,0.22413793103448276,0.20967741935483872
13,SP:012aea2b0a756ae1714eb20ac4fdb723a644ee8f,"In this paper, the authors studied the role of loss landscape in training certifiable robust models. The authors reviewed linear relaxation based methods, and showed that Interval Bound Propagation (IBP) is a special case of linear relaxation based methods. Although linear relaxation based methods have a tighter bound on worst case loss with adversarial perturbations than IBP based method, the authors found in numerical studies that towards the end of training, IBP outperforms linear relaxation based methods. The authors hypothesized that this was because IBP loss landscape was more smooth, which helped optimization. The authors demonstrated in a theorem that IBP loss was indeed more smooth under certain assumptions. Based on this insight, the authors proposed a favorable landscape method. The authors showed in numerical studies that the sum over the worst-case margin for each class is lowest for their method. The loss of their method is also the most smooth among competing methods. Their method achieved a consistent performance in a range of perturbations, which is not achieved in competing methods.","This paper studies why training with looser bounds (IBP) can outperform tighter linear relaxation based methods in certified defense. The authors argue that this is because IBP has a smoother loss landscape compared to linear relaxation based methods. Then the paper proposes to optimize the lower bound in the CROWN relaxation for unstable ReLU neurons during training, for tighter bounds and a smoother loss landscape.",0.14450867052023122,0.38461538461538464,0.21008403361344538
14,SP:0134f562a484fc11e69847eb132d866e55fad86f,"In this paper, the relationship between the Jacobian (the gradient of the final activation w.r.t parameters) and the Hessian is analyzed for the softmax cross-entropy loss. As a key tool, the approximation of the Hessian with the probability vector (the softmax output) is used, which suggests connections with several optimization (and generalization) concepts such as sharpness v.s. flatness of the loss landscape and the oscillation on the optimization path at GD/SGD. ","The authors study the largest eigenvalue and eigenvector of the Hessian of the loss function. The authors approximate the Hessian matrix by a low-dimensional matrix, which is a rank-one modification of a diagonal matrix. The eigendecomposition helps to explain how the sharpness influences the gradient descent method and the generalization properties. They show that GD has implicit regularization effects on the Jacobian norm weighted with the impurity of the probability output, which is also related to the Fisher information matrix. ",0.23684210526315788,0.21951219512195122,0.2278481012658228
15,SP:0147099ac2866672f507e5e37383fa4f50addd0e,The authors target the unsupervised reinforcement learning problem. An opposite idea from the existing approaches by maximizing state entropy is adopted to minimize state entropy. It is interesting that such an idea has achieved good performance in unstable environments. A state distribution is fitted during the interaction with an environment and the probability of the current state is used as a virtual reward. The parameters or sufficient statistics are also applied to the policy. The motivation is clear and verified. It is generally a good paper.,"This work proposes an RL approach SMiRL that is able to learn effective policies in unstable environments without the need for external reward. The idea at a high-level is almost the opposite of intrinsic motivation RL approaches, which encourage novelty-seeking behaviors. The proposed method instead aims to minimize surprise or state entropy. To train the agent, rewards come from state marginal estimates, but because this distribution is changing, the authors create an augmented MDP. Through experiments on game domains and robot control tasks, the authors show that SMiRL outperforms intrinsic motivation methods. The authors also show that SMiRL can be used to do imitation and can be combined with regular reward signals.",0.23255813953488372,0.17543859649122806,0.2
16,SP:014ffcb32f734eb84c89fb83ed2b62098fde89f9,"This paper develops an analogy between Transformer networks and dynamical systems of multiple interacting particles. They follow the work of Lu et al. 2019 using Lie-Trotter splitting scheme to derive differential equations approximating terms corresponding to operations that compose the Transformer network internals, namely multi-head self-attention and feed-forward transformation.   This paper develops the described technique beyond previous work by noting their analogous dynamical system motivates architecture choices that would require many fewer parameters than the associated Transformer. The authors investigate performance and memory gains by exploiting time-dependence in the dynamical transformation, achieving similar results to analogous weight-sharing between layers. ","This paper introduces TransEvolve, a new efficient transformer architecture that approximates the multi-headed self-attention and point-wise feed-forward transformations in the standard transformers.  Drawing from recent work by Lu et al., 2019 which established the connection between transformers and modeling the dynamics of a multi-particle dynamic systems, TransEvolve approximate multiple layers of the transformer with a temporal evolution scheme that bypasses costly dot product operations.  Experiments on encoder-decoder tasks show TransEvolve to be competitive with vanilla transformers while being slightly more efficient.  On encoder-only tasks, TransEvolve yields better predictive performance with half as many parameters.",0.17142857142857143,0.1782178217821782,0.17475728155339804
17,SP:0152425d154c3a8120602f5d9e2eaf4e3d664632,"The authors study the dynamics of accelerated gradient methods applied to two prototypical, non-convex problems: recovering the ground state of a mixed p-spin model, and recovering a planted signal from a spiked matrix-tensor model. The two models are defined according to the following loss function  $$ \mathcal{L}(x) = - \eta_p(\Delta_p) \cdot \sum_{i_1, \ldots, i_p}^N T_{i_1, \ldots, i_p} \cdot x_{i_1} \ldots x_{i_p} - \eta_2(\Delta_2) \cdot \sum_{i,j}^N Y_{i,j} \cdot x_{i} x_{j} $$  where $T \in (\mathbb{R}^N)^{\otimes p}$ is a tensor, $Y \in \mathbb{R}^{N \times N}$ is a matrix and $\eta_p(\Delta_p)$ and $\eta_2(\Delta_2)$ are normalization constants dependent on $\Delta_p$ and $\Delta_2$ respectively. When $T$ and $Y$ possess entries that are i.i.d Gaussians with mean 0 and variance $\Delta_p$ and $\Delta_2$ respectively, we have the mixed $p$-spin model. When $T$ and $Y$ are given by a Gaussian perturbation of vector $x^*$ on the $\sqrt{N}$ radius $N$-dimensional sphere, we have the spiked matrix-tensor model. Finding the ground state for mixed $p$-spin, and recovering the planted signal from the spiked tensor model then correspond to finding $x$ which minimizes loss $\mathcal{L}$. Note in the latter case that $x$ which minimizes loss will also have a large overlap with $x^*$ hence why one considers this problem as recovering a planted signal.  This work uses the cavity method to derive mean dynamics for iterates produced by accelerated gradient methods. They construct a sequence of equations that track correlation between iterates maintained by Nesterov’s acceleration and Polyak’s Heavy Ball Momentum. These equations are parameterized by different time steps of the algorithm; for example, the equation for $C_x[t, t’]$ corresponds to the overlap of $x$ at time $t$ with that at time $t’$.  The dynamic mean field equations can be used to heuristically determine computational thresholds for statistical signal recovery in the following sense. For an instance of finding a planted signal from a spiked matrix-tensor model given by samples of $T$ and $Y$, consider the instance’s signal-to-noise ratio $\frac{\Delta_p}{\Delta_2}$. For a fixed value of $\Delta_p$ and as one increases $\Delta_2$, it becomes increasingly difficult to recover the planted spike $x^*$. At a certain value of $\Delta_2$, say $\delta^*$, an iterative method solving the instance may exhibit a phase transition: for $\Delta_2 < \delta^*$ the method will find $x$ that has large overlap with $x^*$, while for $\Delta_2 > \delta^*$, the method only converges to $x$ that has vanishingly small (w.r.t. $N$) overlap with $x^*$.   The authors use the mean dynamic equations to compute statistical recovery thresholds for Nesterov acceleration and Heavy Ball momentum. The cavity method calculations are heuristic, and so the authors support their estimates with experiments that suggest the true threshold for these two methods are very close to their estimates. The results also suggest that the threshold for accelerated methods align closely with the threshold achieved by vanilla gradient descent. As a separate results, the authors demonstrate an equivalence between the dynamics of Polyak’s Heavy Ball Momentum and the dynamics of a massive particle under the effect of a certain potential field.","This work studies two types of high-dimensional non-convex optimization problems: (1) the mixed p-spin model; (2) the spiked matrix tensor model. Authors studied a high-dimensional, mean-field type limit of momentum-accelerated optimization dynamics solving these two types of non-convex problems. Mean-field type dynamical equations for Polyak's heavy-ball and Nesterov's method are derived.",0.053475935828877004,0.4838709677419355,0.09630818619582664
18,SP:01813ebeda8ca73bca2bb3f50a3afefd1a04643b,This paper studies the use of meta learning and adversarial training to defend against universal perturbations. This approach tries to learn a set of perturbations through meta-learning and train the model to defend against such attacks. Experimental results on Tiny ImageNet and the Bosch small traffic lights dataset show the method is effective in defending against universal patch-based attacks. ,"The authors propose a novel meta adversarial training method. In particular, to improve the robustness against digital domain attacks, the proposed meta adversarial training (MAT) combines adversarial training and meta-learning, which reduces the computing cost compared with adversarial training by generating a set of stronger perturbations. The proposed approach sounds with extensive experimental results.",0.21311475409836064,0.23636363636363636,0.22413793103448273
19,SP:01d9dfdff7250ca7703a05aa98105d0307f3d899,This paper proposes a novel NAS method that searches the model architectures by grows the networks. This searching strategy determines the channel and layer configurations by assigning a binary learnable parameter m for each channel or layer. The objective is to optimize a trade-off between the model performance on the given task and the regularization on the binary indicator m.,"This paper proposes a new principled approach to growing deep network architectures based on continuous relaxation of discrete structure optimization combined with a sparse subnetwork sampling scheme. It starts from a simple seed architecture and dynamically grows/prunes both the layers and filters during training. Through extensive experiments, the authors show that this method produces more efficient networks while reducing the computational cost of training, still maintaining good validation accuracy, compared to other NAS or pruning/growing methods. ",0.18032786885245902,0.14102564102564102,0.15827338129496402
20,SP:0228dd243b9ca1b38e728d54f5d000858f959ea4,"The paper proposes a method for overcoming the long-term memory bottleneck of transformers. The idea is to assign a value (expire-span) to each formed memory, which indicates how long the memory should be stored and be available for the transformer to access it. The authors demonstrate the performance of their approach on a set of","To help Transformer learn long sequence efficiently, the paper performs attention on selective timesteps that have high expire-span scores. For each timestep, the expire-span score is computed by mapping the corresponding hidden feature to a number, which is learnt during training. Soft masking is applied to make the learning differentiable. An additional loss is introduced to reduce the average span, making the attention sparse. The proposed attention is integrated into each layer of Transformer and tested on several synthetic tasks and two language modelling datasets, yielding promising results. ",0.24561403508771928,0.15555555555555556,0.19047619047619047
21,SP:023f656e324a7c753e79703a9e9ff7638990a11c,"The authors propose a new model that consists in transforming decision trees by seeing such models as a sequence of ""layers"" made of all nodes at the same tree depth. Each layer is then modelled as a stochastic decision (multiplication by a stochastic matrix) which can mimic the behaviour of both standard decision tree and stochastic trees (among others). Their idea is to keep the layer decomposition as it is to be able to understand/interpret each layer as pieces of the bigger picture (i.e., the interpretation of the model itself). ","The authors propose Decision Transformer Networks (DTNs): a model that generalizes decision trees to deep network style decision graphs. Structurally, DTNs are similar to deep neural networks with layers of nodes operating as stochastic decision functions and which output probabilities of an input vector belonging to each sub-network. The probabilistic predictions of the decision nodes in a layer are aggregated in a ""transition matrix"" and passed to the next layer until the leaf layer is reached where the final classification decision is made. The goal of DTNs is to improve the representation power of tree models by transforming (exponentially large) trees to compact graphs without losing its interpretability power. The authors propose special scoring functions to explain the decisions made by  each layer as well as the model. On a diverse set of datasets ranging from small (<1K) to large (>10K), DTNs (dense and sparse) with softmax and spherical-softmax decision nodes, attained better accuracies than MLPs, conventional decision trees and their soft versions. ",0.32608695652173914,0.18181818181818182,0.23346303501945528
22,SP:0241b8a73225e20c6d486355f34f267d87ef1f44,"The paper proposes to make any neural network equivariant by symmetrizing over a subset of the group, rather than over whole group. If the subset selection F(X), depending on input X, is equivariant (gFX=FgX), then the symmetrization is equivariant. The authors furthermore prove: 1)	When interested in invariant prediction, the subset can be chosen in the quotient G/G_X, where G_X is the stabilizer subgroup of X. 2)	When symmetrizing with a random subsample of F(X), the probability of a particular subsample that deviates from symmetrizing with all of F(X) by less than some epsilon, is bounded below. 3)	When using the symmetrization of a universal model, the resulting model class is universal in the class of equivariant functions. ","**Summary and Contributions**:  The paper introduces a framework called Frame Averaging (FA) that can adapt existing backbone architectures to become invariant/equivariant to new symmetry types. It achieves this by averaging over an input-dependent frame which outputs a subset of groups. Frame averaging is often much more efficient to compute than averaging over the entire group, while at the same time, guarantees exact invariance/equivariance.  On the technical side, the paper also proves that FA-based models have the same expressive power as the original backbone architectures.  On the empirical side, the paper provides new classes of models using FA such as universal Euclidean motion invariant point cloud networks / Message Passing GNNs, and demonstrates their practical effectiveness on several tasks. ",0.184,0.19008264462809918,0.1869918699186992
23,SP:0249d3ffcb3333fe857d83bae77e709a2f997956,"The submission performs similar foreground-background analysis for object recognition as in [1], but with more modern networks in mind. As such, the main takeaways indicate that this phenomenon still exists - networks today continue to suffer from background bias as they did four years ago with AlexNet, although maybe to a lesser extent. This submission curates more careful evaluation setups by using segmentation of foreground objects, tiled backgrounds to create multiple datasets that serve to illustrate the trends in a more disambiguated way. ","The authors presented a comprehensive study on the role of background in image classification. They designed a new set of data and a lot of experiments to find answers to the following questions: (1) How much decrease in classification accuracy if the background signal is removed? (2) Can a model successfully classify an image solely based on its background? (3) Will an image be misclassified if the image's background is replaced by a different background? (4) With the advance of the model architecture, are the more advanced models like ResNet more robust to background effect? ",0.14457831325301204,0.125,0.13407821229050276
24,SP:027dfebf9732ce68cb3985ef873b00d65e6e7205,"In this paper, the authors present a new adversarial training algorithm and apply it to the fintuning stage large scale language models BERT and RoBERTa. They find that with FreeLB applied to finetuning, both BERT and RoBERTa see small boosts in performance on GLUE, ARC, and CommonsenseQA. The gains they see on GLUE are quite small (0.3 on the GLUE test score for RoBERTa) but the gains are more substantial on ARC and CommonsenseQA. The paper also presents some ablation studies on the use of the same dropout mask across each ascent step of FreeLB, empirically seeing gains by using the same mask. They also present some analysis on robustness in the embedding space, showing that FreeLB leads to greater robustness than other adversarial training methods","-	This paper modifies and extends the recent “free” training strategies in adversarial training for representation learning for natural language.  The proposed “Free” Large-Batch Adversarial Training is well motived, in comparison with plain PGD-based adversarial training and the existing methods like FreeAT and YOPO, which virtually enlarges the batch size and minimize maximum risk at every ascent step. The contributions are solid. ",0.11811023622047244,0.23809523809523808,0.15789473684210525
25,SP:02802f3805d0c51d2a2d3105f7beeb620999bd66,"This paper proposes a method to improve the generalization of deep networks when the input is applied strong augmentations, i.e. mixup, resulting in large data bias. The authors proposes theoretical foundation behind their two methods, AugDrop and MixLoss and show their effectiveness on CIFAR10/CIFAR100 datasets. Although the paper has technical novelty and it only provides incremental gains on relatively small-size dataset. Below, you can find some of my comments/questions about the paper.","In this work, the authors first prove a deep model can benefit from augmented data when the data bias is small. Then they propose two methods, namely ""AugDrop"" that corrects  and ""MixLoss"", that correct data bias by ""constrained optimisation"" and ""modified loss function"" respectively. Finally they show that these two methods can be combined and further improve the performance.",0.21052631578947367,0.2711864406779661,0.23703703703703702
26,SP:02c82e31ddcff1990d5cb3f8ecbb44392cb02892,"The paper proposes a framework for efficient architecture search for graphs. This is done by combining a differentiable DARTS-like architecture encoding with a transfer learning method, that searches on smaller graphs with similar properties, and then transfers to the target graphs. The experiments show that EGAN matches or exceeds both hand-designed and NAS-designed GNNs. Moreover, the method is very fast to run.","This work proposes an efficient graph neural architecture search to address the problem of automatically designing GNN architecture for any graph-based task. Comparing with the existing NAS approaches for GNNs, the authors improves the search efficiency from the following three components: (1) a slim search space only consisting of the node aggregator, layer aggregator and skip connection; (2) a one-shot search algorithm, which is proposed in the previous NAS work; and (3) a transfer learning strategy, which searches architectures for large graphs via sampling proxy graphs. However, the current performance improvement over the human-designed models is marginal, which diminishes their research contribution.",0.23076923076923078,0.14285714285714285,0.17647058823529413
27,SP:02f8d54dc4416c5994bcef9f276ed7881246bef7,"Brief summary: This work proposes a way to perform imitation learning from raw videos of behaviors, without the need for any special time-alignment or actions present. They are able to do this by using a recurrent siamese network architecture to learn a distance function, which can be used to provide rewards for learning behaviors, without the need for any explicit pose estimation. They demonstrate effectiveness on 2 different locomotion domains. ","This paper aims to imitate, via Imitation Learning, the actions of a humanoid agent given only video demonstrations of the desired task, including walking, running, back-flipping, and front-flipping. Since the algorithm does not have direct access to the underlying actions or rewards, the agent aims to learn an embedding space over instances with the hope that distance in this embedding space corresponds to reward. Deep RL is used to optimize a policy to maximize cumulative reward in an effort to reproduce the behavior of the expert.",0.18309859154929578,0.14772727272727273,0.16352201257861637
28,SP:030b2045318e6e4189685793b5eab37ffb8b1a82,"The paper provides a new gradient-based algorithm. The algorithm is based on the observation that a loss function for a single sample can be written as composition of two functions (the logits and the actual loss function). It computes the direction by means of solving a quadratic MSE problem. They provide a convergent analysis of the algorithm (there is a version where the quadratic problem is solved explicitly through a closed form expression and a version where gradient descent is applied to solve the problem approximately). There are no computational experiments.   The main contributions are in the algorithms themselves and the accompanying analyses. It's unclear how novel are the proof techniques since everything resembles second order algorithms. The authors also claim the actual reformulation to be a novel contribution however such a formulation is straightforward and used in many contexts (some of my lecture slides from years ago show the formulation used by authors as a possible formulation for the overall loss function). Despite of this, the design of the algorithm should get credit. ","This paper presents a new optimization method for finding global minima of nonconvex finite sum problems. In particular, the summands are functions of the form $\phi_{i}\circ h$ where $\phi_{i}$ is convex and Lipschitz smooth, while $h$ is nonconvex. Each iteration of the method consists of solving an auxiliary regularized least squares (RLS) problem, followed by a gradient step. Additional analysis is given for when the RLS problem is solved inexactly. Finally, a claimed $\tilde{O}(\varepsilon^{-3})$ complexity is established under strong boundedness assumptions on various solution sets.",0.11931818181818182,0.23076923076923078,0.15730337078651688
29,SP:0337a1d600cc90bd0591d8792102a4486dc03d91,"The paper proposed a deep generative model named iterative refinement graph neural network to generate antibody CDR for Y-shaped antibodies. Specifically, it sequentially generates the CDR residue sequence and refines the global structure iteratively. Empirical results show superior performance compared with baselines. ","This paper proposes a joint generative model (co-designing the sequence and the structure at the same time) for the CDRs of antibodies, with the goal to enhance binding specificity or neutralization capabilities.   The proposed method and two existing baselines are evaluated on 1) perplexity on hold-out set; 2) perplexity and sequence recovery on known antigen-antibody complexes; and 3) redesign CDR-H3 of existing antibodies for coronavirus neutralization as measured by a given neutralization predictor. RefineGNN, the proposed method, shows improved performance in all three tasks.",0.2558139534883721,0.125,0.16793893129770993
30,SP:03577eb6fb5a3b9ac15af04673f905565c57d425,"This paper talks about the problem of off-policy or batch learning in the contextual bandit setting without the complete support assumption. This problem setting is very realistic and encountered in most problems, especially in temporally extended settings, such as reinforcement learning. They compare three approaches for the same: restricting action selection, learning extrapolated reward models, and by restricting the policy class. They derive a SNIPS style estimator for the support constraint in the final approach. The approach with restricting the policy class demonstrates decent empirical results although the direct method is very much comparable.","This work addresses the problem of off-policy evaluation in the presence of positivity violations, i.e. some actions are not observed in the logged policy. As the paper points out, positivity violations can lead to unboundedly bad estimates when employing IPS. The authors propose three methods to deal with this problem. The first uses only the observed actions, the second and third use extrapolation and augmentation to provide an approximation to the off-policy problem. ",0.17894736842105263,0.2236842105263158,0.19883040935672514
31,SP:0365e3071ba7036ff25566c543c65cfc92531674,"The paper proposes a new task in Graph Learning. Basically, the idea is the following: suppose we have a node classification model trained on a Graph G, suppose we have a new node (not present in G) and we want to classify it. Given that the new node has no connections with G’s other nodes we cannot leverage any structural information to run the classifier. This is an issue that authors present it as cold-start in semi-supervised graph learning. The solution, even if simple, is very effective and for this reason even more interesting. Basically, they start with a retrieval step (they call it link prediction) that is trained using a link reconstruction loss and it’s based on dot-product to make the link prediction phase scalable. After those links are reconstructed they run a node classification step (based on GCN, GraphSAGE, or GAT) on G plus the new node and the predicted links.  The results obtained in the experiments are really encouraging with improvements ranging from 15 to 25% over a baseline that does not consider the link prediction phase.","This paper is about the cold-start problem for representation learning on dynamics graphs. More specifically, the proposed method (ColdExpand) uses convolutional networks and multi-task learning (node classification loss and link prediction loss) to learn embeddings for new unseen nodes in the graph, i.e., nodes that we only know their features and not their connectivity to the existing graph. Such a problem is useful for applications of the link prediction problem and more specifically, recommendation tasks or graph completion tasks. The authors test their technique using three benchmark datasets (Cora, CiteSeer and PubMed) and by using building blocks of existing works they create some baselines to compare. They claim to be the first study for semi-supervised learning to unseen nodes. However, there are a couple of works in this field already, as for example the GraphSAGE model that they cite in this paper (see below for more). ",0.14054054054054055,0.17333333333333334,0.15522388059701495
32,SP:0370e68af5e82fcbde2ca16e57721e455620a1fe,This paper proposes a method for inverse reinforcement learning that incorporates a differential planning module. Explicit transition dynamics modeling with inverse value iteration is added to promote meaningful reward learning. Empirical evaluations on several high-dimensional Atari environments and 2 continuous control environments are provided which show improvements over existing inverse reinforcement learning baselines when given only one-life demonstrations. Some visuals are also presented to show that the proposed method is able to learn more meaningful reward maps than previous methods.,"This paper assumes no access to the reward values and attempts to learn a policy by starting just with one demonstration to define the reward. For obtaining the reward, the authors rely on the ideas from Value Iteration Networks (VIN) method and they add the modules that help to deal with cases with complex transition dynamics. The resulting method is tested on atari domain and on continuous control tasks.",0.15853658536585366,0.18840579710144928,0.17218543046357618
33,SP:03927e9924258d065475e45ebeedc315e8f7e325,"This paper uses federated machine learning for predictive maintenance on optical networks. Federated learning provides a number of advantages, including security, privacy, and accuracy. The accuracy claims are motivated by having a broader set of failure examples to draw from, addressing a known issue in predictive maintenance. Privacy and security claims are important in predictive maintenance, but were less novel or well supported - they felt more like off the shelf methods applied in a new domain.   Their primary comparison was against a global model.",This paper designs a maintenance prediction framework for key optical network components based on federated learning. The designed framework can resist malicious environments and several kinds of attacks. The paper uses simulation data to verify that the proposed method has good predictive ability and can withstand the designed simulation attack.,0.14285714285714285,0.24,0.1791044776119403
34,SP:03a357be8e34c07221c6f2829928bf733428f0e3,"The paper introduces 3 new variants of Anderson Mixing methods relying on very limited short term memory. This makes these methods more attractive for usual machine learning workloads. The paper also provides detailed analysis of the performance of each of these AM algorithms, as well as thorough experiments, showcasing improved performance of select neural network training.","The paper proposes a new class of memory-efficient Anderson mixing (AM) methods. Compared with classical Anderson mixing which requires saving m historical iterates, the new variants require only storing two historical iterates while keeping good performance. Convergence analyses are given to the proposed variants showing a variant for strongly convex quadratic problem enjoys the same guarantee as full-memory AM, and another variant converges with a similar convergence rate as SGD (O(1/\sqrt{number of iterations})) on nonconvex problems. Experiments on MNIST, CIFAR-10, and PENN TREEBANK with some popular deep models validates the superior performance of one of the proposed method.",0.25,0.1346153846153846,0.17500000000000002
35,SP:03a7c25f464f8e293bf300d897342f5f82a51f28,"This paper considers federated learning with straggling and adversarial devices. To tackle stragglers, the paper proposes semi-synchronous averaging wherein models with the same staleness are first averaged together, and then a weighted average of the results with different stateless is computed. To mitigate adversaries, the paper proposes to first perform entropy-based filtering to remove suspected outliers, and then compute loss-weighted average. The server is assumed to have some public data, which is used for entropy-based filtering. Together, the proposed algorithm is called semi-synchronous entropy and loss based filtering (Sself). ","The paper claims to propose the first algorithm that can handle adversarial machines and stragglers simultaneously in the federated learning setting. To handle stragglers, the paper takes a semi-synchronous approach by taking a weighted sum of gradients depending on staleness. To handle adversarial machines, the algorithm uses an entropy based filtering and a loss based averaging strategy. Note that to handle the adversaries, the algorithm needs a public dataset at the server, using which it can evaluate the entropy and loss scores of each gradient.",0.2765957446808511,0.3023255813953488,0.2888888888888889
36,SP:03b7bce7c88de2434b54fc0483d8905aa04203e9,"The paper presents a generalization of classical definitions of entropy and mutual information that can capture computational constraints. Intuitively, information theoretic results assume infinite computational resources, so they may not correspond to how we treat ""information"" in practice. One example is public-key encryption. An adversary that has infinite time will eventually break the code so the decrypted message conveys the same amount of information (in a classical sense) as the plaintext message. In practice, this depends on computational time. ","The paper introduces a framework for quantifying information about one random variable, given another random variable (“side information”) and, importantly, a function class of allowed transformations that can be applied to the latter. This matches the typical scenario in machine learning, where observations (playing the role of side information) can be transformed (with a restricted class of transformation-functions) such that they become maximally predictive about another random variable of interest (“labels”). Using this framework, the paper defines the notion of conditional F-entropy and F-entropy (by conditioning on an empty set). Interestingly, both entropic quantities are shown to have many desirable properties known from Shannon entropy - and when allowing the function class of transformations to include all possible models F-entropies are equivalent to Shannon entropies. The paper then further defines “predictive F-information” which quantifies the increase in predictability about one random variable when given side information, under a restricted function-class of allowed transformations of the side information. Importantly, transformations of side information can increase predictive F-information (which is the basis for the notion of “usable” information), which is in contrast to the data processing inequality that applies to Shannon information and states that no transformation of a variable can increase predictability of another variable further than the un-transformed variable (information cannot be generated by transforming random variables). The paper highlights interesting properties of the F-quantities, most notably a PAC bound on F-information estimation from data, which gives reason to expect F-information estimation to be more data-efficient than estimating Shannon-information (particularly in the high-dimensional regime). This finding is confirmed by four types of interesting experiments, some of which make use of a modified version of a tree-structure learning algorithm proposed in the paper (using predictive F-information instead of Shannon mutual information).",0.275,0.07213114754098361,0.11428571428571431
37,SP:0423364bd06f7fe3ef17328f83a5eb99db6459af,"This paper proposes a new objective function for training regression networks with prediction intervals. The goal is to provide tight confidence bounds to accompany predictions, which is of course important for practical deployments of ML systems where uncertainty quantification is critical. Previous work has largely assumed that uncertainty is symmetrical, or even Gaussian distributed, which is often not the case in practice. The innovation of this work is to simultaneously predict the bounds for a given confidence level and a point prediction within those bounds, which is not necessarily the mean. It is accomplished by predicting 3 values: an upper bound, a lower bound, and a mixing parameter that allows making the point estimate as a weighted sum of the bounds. Experimental results are provided on 3 datasets, with 2 baseline methods compared against.","The submission considers the continuous real-valued regression problems and how to obtain accurate point predictions (specific value prediction in the text) and prediction intervals (the uncertainty of the predictions, given by [lower bound LB, upper bound UB]). The paper proposes a loss function which is the weighted combination of (i) the coverage constraint [proportion of outputs that fall between LB and UB] so that the coverage meets a required level, (ii) the prediction interval width [for those that satisfy (i), their prediction intervals should be tight], and (iii) the prediction loss [which makes sure the predictions match the outputs]. The LB, UB and predictions are parameterised using three separate heads: one for LB, one for UB and one for the prediction weight (which makes sure the prediction stays in between LB and UB. The proposed loss function and parameterisation architecture are evaluated on UCI regression datasets and two age prediction problems using image inputs. ",0.1791044776119403,0.15483870967741936,0.16608996539792387
38,SP:043898419d6f33939bdbe62f59f05e2c78d4b61c,"This paper proposes a method of discretizing communication between different modules in a network of specialists in order to improve generalization. They propose using a common codebook of discrete symbols shared by all network components that can be used to share information between modules. They propose a method of discretization based on the VQVAE architecture called Discrete-Valued Neural Communication (DVNC), in which a continuous vector is partitioned into ""discretization heads"", each of which is then mapped to its nearest neighbour among a set of learned latent vectors that are shared between modules. Gradients are propagated through the discretization using a straight-through estimator. The authors provide theoretical analysis to argue that DVNC improves sample efficiency and robustness to noise, while decreasing intrinsic dimensionality. They also provide experiments with a number of different tasks and architectures to show that their method of discretization improves performance on out-of-distribution samples at inference time.","The submission discusses discrete communication between neural network components and proposes 'discrete-valued neural communication (DVNC)', i.e. discretization of continuous representations in neural networks. The key contribution is a segmented discretization of vectors (see Eq. 1), in contrast to a joint discretization in a prior work (Oord et al., 2017).",0.11764705882352941,0.35294117647058826,0.17647058823529413
39,SP:044d99499c4a9cb383f5e39a28fc7ccb700040d1,"The paper proposes an ensemble method for reinforcement learning in which the policy updates are modulated with a loss which encourages diversity among all experienced policies. It is a combination of SAC, normalizing flow policies, and an approach to diversity considered by Hong et al. (2018). The work seems rather incremental and the experiments have some methodological flaws. Specifically the main results (Fig. 4) are based on a comparison between 4 different codebases which makes it impossible to make meaningful conclusions as pointed out e.g. by [1]. The authors mention that their work is built on the work of Hong et al. (2018) yet the comparisons do not seem to include it as a baseline. I'm also concerned about how exactly are environment steps counted: in Algorithm 1 on line 27, it seems that the fitness which is used for training is evaluated by interacting with the environment yet these interactions are not counted towards total_step.","RL in environments with deceptive rewards can produce sub-optimal policies. To remedy this, the paper proposes a method for population-based exploration. Multiple actors, each parameterized with policies based on Normalizing Flows (radial contractions), are optimized over iterations using the off-policy SAC algorithm. To encourage diverse-exploration as well as high-performance, the SAC-policy-gradient is supplemented with gradient of an “attraction” or “repulsion” term, as defined using the KL-divergence of current policy to another policy from an online archive. When applying the KL-gradient, the authors find it crucial to only update the flow layers, and not the base Gaussian policy.",0.11949685534591195,0.1792452830188679,0.14339622641509434
40,SP:044eb7985596e0b826f3628855c2fb2913907cc7,"A great recommender system relies on great training set. However, at the beginning, there is no such data availability. This paper tries to solve the zero-shot recommendation problem where there is no user or item overlaps. The two challenges are generalize to unseen users and to unseen items. For unseens users, sequential recommendation represents users as a sequence of their interacted items. As long as the items are seen before, the users can be represented. As for items, the unique ids are not useful. However, the attributes such as natural language description can be universal. This paper proposed an approach based on hierarchical Bayesian model. The item universal embedding is using pre-trained BERT network with a single layer neural network. Extensive experiments are carried out to demonstrate the effectiveness of the proposed approach.  ","This paper studies ""zero shot recommendation"" where source and target domain have no overlap in terms of user and items. The paper proposes to use item content features, such as leveraging BERT on descriptions, instead of IDs. Experiments are conducted on two offline datasets.",0.11851851851851852,0.36363636363636365,0.1787709497206704
41,SP:045b9cae56d226a23b9a080ecf5b548670a73328,"The paper proposes a generative network capable of generating variations of a given input, conditioned on an attribute. Earlier papers generated variations of the input in the presence of the attribute and this attribute was assumed to be known during training. This paper proposes to automatically discover these attribute and thus work to produce variations even in the absence of known attribute information.","This paper introduces a new framework for learning an interpretable representation of images and their attributes. The authors suggest decomposing the representation into a set of 'template' latent features, and a set of attribute-based features. The attribute-based features can be either 'free', i.e. discovered from the data, or 'fixed', i.e. based on the ground truth attributes. The authors encourage the decomposition of the latent space into the 'template' and the 'attributes' features by training a discriminator network to predict whether the attributes and the template features come from the same image or not.",0.23809523809523808,0.15463917525773196,0.1875
42,SP:048d4b0525787b7a697c5608f0dd20ef84ebe339,"PointNet (Qi et al, 2017) and Deep sets (Zaheer et al, 2017) have allowed to use deep architectures that deal with point clouds as inputs, taking into account the invariance in the ordering of points. However, existing results on their approximation abilities are limited to fixed cardinalities. This paper removes the cardinality limitation and gives two kinds of results:",This work examines the fundamental properties of two popular architectures -- PointNet and DeepSets -- for processing point clouds (and other unordered sets). The authors provide a new universal approximation theorem on real-valued functions that doesn't require the assumption of a fixed cardinality of the input set. They further provide examples of functions that can't be mutually approximated by PointNets and DeepSets.,0.1694915254237288,0.15873015873015872,0.16393442622950818
43,SP:04982111c9f052a633c1cacb113263af408e6a24,"Texture vs shape sensitivity is a basic and important question in understanding how deep convolutional nets work. This paper investigates this question by asking how CNNs represent shape versus texture information internally.  Using a (texture-vs-shape) stylized imagenet pioneered by Geirhos (2018), the paper applies a dimensionality estimation method of Esser (2020) and a segmentation-readout method for quantifying and visualizing the encoding of shape information in networks.  Several different network architectures and layers are compared; and results are compared to baselines from previous papers as well as natural lower- and upper-bounds.  The presentation is clear.","The method provides two measures for assessing the degree at which shape is represented in CNNs. The first measure attempts to asses, within a given representation layer, the dimentionality required to encoder shape information. The second, evaluates the per-pixel shape representation, by attempting to generate the input's segmentation mask from the given representation (activation of the image at that layer). ",0.1326530612244898,0.20967741935483872,0.1625
44,SP:051dd7bc82951cead504d0861e2048c99d20dbe8,"The authors explore how well model extraction works on recent BERT-based NLP models. The question is: how easy is it for an adversary model to learn to imitate the victim model, only from novel inputs and the corresponding outputs? Importantly, the adversary is supposed to not have access to the original training set. The authors state that this is problematic because such techniques could be used in order to gain information about (potentially private!) training data of the victim model.","This paper studies the effectiveness of model extraction techniques on large pretrained language models like BERT. The core hypothesis of the paper is that using pretrained language models, and pretrained contextualized embeddings, has made it easier to reconstruct models using model stealing/extraction methods. Furthermore, this paper demonstrates that an attacker needn't have access to queries from the training set, and that using random sequences of words as a query to the ""victim"" model is an effective strategy. They authors also show that their model stealing strategies are very cost effective (based on Google Cloud compute cost). ",0.25925925925925924,0.21428571428571427,0.2346368715083799
45,SP:055233a234a97d1e4a37a02b1740303eb41a3dc5,"This paper proposes a method for fair clustering (where a clustering is considered fair when each protected group is present in every cluster in the same proportion as in the population) using deep neural networks.  The method works by training a neural network for clustering using the deep clustering with virtual adversarial training approach proposed by (Hu et al., 2017) and then refining (retraining) the network by adding a fairness term to the loss function (where the fairness term is the cross entropy loss between the current networks prediction and the fair assignments obtained using an LP solver on a constraint matrix that enforces the group fairness/balance constraints).  It also presents some experiments that demonstrate the method is more effective at finding high quality fair clusterings than existing deep clustering, fair clustering, and deep fair clustering methods. ",This paper proposes a fair clustering algorithm that uses DL models to map the data into deep representations. The authors also show the equivalence between the practical fairness measure and the balance measure. The algorithms can be concluded as two steps:  1) find fair assignments $\hat y$ based on $y$; 2) tune the latent representations and $y$ according to the pseudo-label $\hat y$. ,0.13768115942028986,0.296875,0.18811881188118812
46,SP:0553795288c6d9054e7434cb31762664b6c29aaf,"Graph Neural Networks (GNNs) have been attracted much attention very recently because of surprising results in many applications. In general, GNNs assume that the training node labels follow the i.i.d. property. However, in practice, the labels could be very biased. To deal with the biased training nodes, the authors propose regularization methods that consider feature distance between training nodes and i.i.d sampled unlabeled nodes. CMD and KMM are key components of the regularization: CMD measures the distance between train nodes and general nodes, and KMM computes balanced weights of training loss functions. SR-GNN is the main framework that includes both CMD and KMM ideas. The experimental section shows that the biased data can hurt the performance, and SR-GNN can mitigate performance degradation.","Distributional shift is a common issue in machine learning. In this paper, the authors study this topic in graph representation learning and also found the similar phenomenon. They propose a framework called SR-GNN that is able to reduce influence of biased training data. The authors have also conducted evaluation based on some benchmark datasets to show the effectiveness of the proposed method.",0.1015625,0.20634920634920634,0.13612565445026178
47,SP:05977d1cb6550b36bb633626b45f69652bca2ac5,"Aiming at exploiting the benefits of population based policy optimization and policy gradient, this paper proposes a novel framework that combines these two techniques. The authors claim that the previously proposed frameworks that combines evolutionary approaches and policy gradient approaches uses actor critic approaches in the policy gradient part, and that it is important to be able to incorporate value-based methods instead of actor critic approaches since the value based approach sometimes outperforms the actor critic approaches. The proposed framework is designed to be capable of combining evolutionary policy search approaches with ANY deep reinforcement learning algorithms. The framework is simple and relatively easy to combine with different deep reinforcement learning algorithms. However, in two instantiation of the proposed framework presented in this paper, the authors tune the details for each of these two. For one cases the authors obviously exploiting the structure of the combined reinforcement learning algorithm (existence of the target network and update the target network only), which is not possible in general. ",The paper introduces Supe-RL that intermingles off-policy reinforcement learning with periodic beam search operations. The method makes a greedy selection between the rl-solution that it had and the best produced by the beam search using Polyak update to update the incumbent rl-solution if the one suggested by beam search is better. Experiments in robotics simulation benchmarks show that Supe-RL improves over prior hybrid methods. ,0.09580838323353294,0.2318840579710145,0.13559322033898305
48,SP:05a329e1e9faa9917c278dd2ba1eb5090189bdf9,"This paper presents a method for single image 3D reconstruction. It is inspired by implicit shape models, like presented in Park et al. and Mescheder et al., that given a latent code project 3D positions to signed distance, or occupancy values, respectively. However, instead of a latent vector, the proposed method directly outputs the network parameters of a second (mapping) network that displaces 3D points from a given canonical object, i.e., a unit sphere. As the second network maps 3D points to 3D points it is composable, which can be used to interpolate between different shapes. Evaluations are conducted on the standard ShapeNet dataset and the yields results close to the state-of-the-art, but using significantly less parameters.","This work is focused on learning 3D object representations (decoders) that can be computed more efficiently than existing methods.  The computational inefficiency of these methods is that you learn a (big) fixed decoder for all objects (all z latents), and then need to apply it individually on either each point cloud point you want to produce, or each voxel in the output (this problem exists for both the class of methods that deform a uniform distribution R^3 -> R^3 a la FoldingNet, or directly predict the 3D function R^3 -> R e.g. DeepSDF). The authors propose that the encoder directly predict the weights and biases of a decoder network that, since it is specific to the particular object being reconstructed, can be much smaller and thus much cheaper to compute.",0.18181818181818182,0.16666666666666666,0.17391304347826086
49,SP:05b195c7ce6d65c3a48ac79b6fe9d511ae5a3b5d,The paper presents a method for Bayesian meta-learning. This method combines a NN feature extractor with a Gaussian Process on top. The GP kernel is linear. The information bottleneck is used to motivate a choice of approximate posterior. Using MAML to adapt the NN feature extractor weights improves performance of the composite model for few-shot learning.,"The paper derives a meta-learning framework based on the information bottleneck principle. By adapting the variational approximation proposed in [1] to the meta-learning setting, the authors come up with a tractable objective that generalises both gradient based and memory meta-learning methods. Based on this framework, the authors proposed a new memory based meta-learning algorithm by using a GP with a deep kernel and an extension that combines this memory based method with MAML. The authors show that the method outperforms MAML in several standard meta-learning  tasks, especially in regression and many shots classification problems.",0.27586206896551724,0.16161616161616163,0.2038216560509554
50,SP:05e0d4b6ccaac1bdf0ffa78bad02722d4dfd4659,"This work proposes the Neural Shuffle-Exchange Network to capture both local and global dependencies for 2D data. The idea extends the 1D Neural Shuffle-Exchange Network to its 2D application. The proposed method first converts 2D data to 1D following the Z-order, then apply several Quaternary Switch and Quaternary Shuffle layers, and finally convert the data back to 2D space. The experimental results show that the proposed method can obtain better performance with reasonable computational cost. ","The paper proposes a network architecture called Matrix Shuffle-Exchange (Matrix-SE) that can learn many logical reasoning tasks on 2D data and graph. It has complexity O(n^2 log n) for 2D input of size n x n, which is much smaller than the complexity of naive attention applied to 2D data (O(n^4)). The proposed architecture is an adaptation of the Neural Shuffle-Exchange network architecture (Freivalds et al., 2019), moving from 1D to 2D data. This adaptation is done by using a Z-order iteration of the 2D input, then performing radix-4 shuffle and radix-4 exchange, instead of radix-2. This model is shown to be able to solve several hard tasks on 2D data, such as inferring algorithms on binary matrices (transpose, rotation, bitwise XOR, matrix squaring), graph operations (component labeling, triangle finding, transitivity), and solving Sudoku puzzles. The experiments show impressive results and the model's ability to generalize to test inputs of larger sizes than those in the training set.",0.3333333333333333,0.15294117647058825,0.20967741935483872
51,SP:05e114ff99351e68ad8c16f0655335d183262296,"The paper analyzes if enforcing internal-consistency for speaker-listener setup can (i) improve the ability of the agents to refer to unseen referents (ii) generalize for different communicative roles. The paper evaluates a transformer and arecurrent model modified with various sharing strategies on a single-turn reference game. Finally, the paper claims that results with self-play suggest that internal consistency doesn’t help (i) but improves cross-role performance for (ii).","This paper investigates the question of internal consistency in emergent communication. In other words, the paper aims to answer the question ‘how is emergent communication improved if we enforce the constraint that an agent must speak in the same way that it listens?’ The paper explores three methods of enforcing internal consistency: self-play, shared embeddings, and symmetric encoding/decoding. They find that, while internal consistency does not help generalization to unseen objects, it does allow agents to generalize over conversational roles (i.e. to perform well as a speaker despite only being trained as a listener).",0.2054794520547945,0.15463917525773196,0.1764705882352941
52,SP:060eedc158b8ebcd2a593500513c1055e1ca158b,"The authors propose a new set-up for reinforcement learning which considers undiscounted episodic returns and introduces a loop-penalty to ensure that all episodes terminate and that the returns are bounded. In the tabular case, the loop-penalty zeros out the reward if a loop is detected in the current episode. For continuous state-spaces, the authors propose to detect loops using methods that estimate state-similarity.","This paper proposes an alternative surrogate objective for optimizing success rate in episodic tasks with bounded time horizon. Rather than optimize a discounted 0-1 loss (say with discount factor 0.99), the authors suggest to optimize the undiscounted 0-1 loss where reward is counted only for trajectories that do not contain loops. They call this a loop penalty, and show that it can work in 3 appropriate environments. ",0.14705882352941177,0.14285714285714285,0.14492753623188406
53,SP:0612639384f7b7766e8838d47a3ac973a6df0e1e,This paper studies classification problems via a reject option. A reject option could be useful in prediction problems to handle Out-of-distribution examples. The classification procedure studied in this paper builds on three components 1. An auto-encoder that obtains a latent low-dimensional representation of the data point 2.  A generative model that models the class-conditional probability model and 3.  a margin based loss function that learns a classifier that provides a large probability mass to the class-conditional distribution corresponding to the correct class.  The final decision procedure is to reject an input if the best class conditional probability is small and to use the class corresponding to the best class conditional probability otherwise. ,"The paper proposes a scalable approach to train generative classifiers using information maximizing representation learning, with the motivation that generative classifiers could be more robust to adversarial attacks than discriminative classifiers. An off-the-shelf mutual information maximizer (MINE, DIM) is used to learn low-dimensional representations of images. Then, class-conditioned generative models of the representations are learned avoiding full generative modeling of the images. An additional loss is used to train the generative classifier which maximizes likelihood margins. Finally, percentile-based thresholds of the class log-probabilities is proposed to be used to reject classification for out-of-manifold inputs.",0.1694915254237288,0.19607843137254902,0.18181818181818182
54,SP:062377d8728ec1cc76ecd9a32deddaf1fcd58763,"This paper presents a new method called ""Space2Vec"" to compute spatial embeddings of a pixel in a spatial data. The primary motivation of Space2Vec is to integrate representations of different spatial scales which could potentially make the spatial representations more informative and meaningful as features. Space2Vec is trained as a part of an encoder-decoder framework, where Space2Vec encodes the spatial features of all the points that are fed as input to the framework. ","The paper introduces Space2Vec, a space representation learning model. The work is motivated by the biological grid cell’s multi-scale periodic representations and the success of representation learning of NLP. So, the key idea behind the model is two-fold. On one hand, utilize the position information and the context associated with the position. On the other hand, the authors build a multiscale point space encoder based on Theorem 1 (in the paper), which was previously proved by Gao et al. (2019).",0.16216216216216217,0.14457831325301204,0.15286624203821655
55,SP:06417327dae11b539a7e6087a8d792ccd729a74a,"The authors provide a novel combination of known architectures to an important use case of reducing the density of required  measurements in sensor-fusion based temporal multi-class inference tasks. This has implications in energy consumptions of wearable sensors.  but could even generalise to measurement timings in clinical care to make the work of nurses more efficient, and reduce the stress caused by some medical procedures..","This paper proposes an RNN model for adaptive dynamic feature selection, for efficient and interpretable human activity recognition (HAR). From the intuition that human activity can be predictable by using a small number of sensors, the paper introduces an l0-norm minimization problem with parameter regularization, and provide a logic on formulating a dynamic feature selection model with relaxations. The difficulty of the discrete optimization problem is solved by differentiable relaxation, which is known as Gumbel-Softmax reparameterization techniques. The formulation is naturally led to an RNN model that uses histories as input with an additional sigmoid unit for adaptive feature selection. ",0.12121212121212122,0.0784313725490196,0.09523809523809525
56,SP:064409e33595c152d0f0185b80eb9d533c2d85ce,"This paper proposes a domain invariant adversarial training (DIAL) method, which learns the feature representation that is both robust and domain invariant.  Apart from the label classifier, the model is equipped with a domain classifier that constrains the model not to discriminate between natural examples and adversarial examples, thus achieving a more robust feature representation. Extensive experiments on image classification benchmark the robustness compared to other state-of-the-art methods. ","The paper describes an adversarial training approach that, in addition to the commonly used robustness loss, requires the network to extract similar representation distributions for clean and attacked data. The proposed method is inspired by domain adaptation approaches that require a model to extract domain invariant/agnostic features from two domains. In the context of this paper, the two domains are the clean and adversarially perturbed images, and the network is required to extract domain invariant representation. To achieve domain invariance, the authors propose a domain classifier ( i.e., an adversarial network) that discriminates the representations from clean and attacked images. The feature extractor is then required to generate features that fool the domain classifier. The authors then provide extensive experiments on small-scale benchmark datasets (SVHN, CIFAR10, CIFAR 100, and MNIST in the supplementary material ) to show the robustness of their proposed approach against the state-of-the-art robustness methods under white-box and black-box attacks. The authors show that their proposed method provides: 1) higher accuracy on attacked data (more robustness), and 2) higher accuracy on clean data, closing the gap between the performance on clean and attacked data. In addition, the paper provides insightful experiments on robustness to unforeseen adversaries, robustness to unforeseen corruptions, transfer learning, and ablation studies.  ",0.4225352112676056,0.14018691588785046,0.21052631578947367
57,SP:066ab85834cd54a685a860021521eb1ffe35e60f,"In previous federated learning literature, people usually assume there is only one cloud server communicating with all edge nodes/clients. However, since each server has its own coverage in practice, the latency between the server and clients out of the coverage can be pretty long. This paper focuses on reducing the communication cost in this practical setting. The authors propose to use multiple edge servers, which have overlapped coverages. The clients in the overlapping areas will receive model parameters from multiple server and return the average model back. This can help to mix the information between different edge servers. Experiments on MNIST, EMNIST, and CIFAR10 datasets validate the effectiveness of the proposed algorithm: FedMes.","This paper considers federated learning for edge devices with multiple wireless edge servers. The paper proposes FedMes to leverage devices in overlapping areas covered by multiple edge servers. In particular, in FedMes, if a device is in the coverage area of multiple edge servers, the device receives current models from all the edge servers covering it. Each device uses a (weighted) average of the models it receives as a starting point, and performs local updates (using SGD). A device broadcasts the updated model to multiple edge servers that cover the device. The key idea is that these devices in the overlapping coverage area act as ‘bridges’, and communication between edge servers is not required (until the final averaging step). The authors carry out experiments to evaluate FedMes, and compare against hierarchical federated learning of (Liu et al., 2019).",0.21929824561403508,0.18115942028985507,0.1984126984126984
58,SP:068af1ac91bf95242facb5e429fd18a71ffdd2ef,"The authors look at the problem of exploration in deep RL. They propose a “curiosity grid” which is a virtual grid laid out on top of the current level/area that an Atari agent is in. Once an agent enters a new cell of the grid, it obtains a small reward, encouraging the agent to explore all parts of the game. The grid is reset (meaning new rewards can be obtained) after every roll out (meaning the Atari agent has used up all its lives and the game restarts).","This paper proposes use of intra-life coverage (an agent must visit all locations within each episode) for effective exploration in Atari games. This is in contrast of approaches that use inter-life coverage or curiosity metrics to incentivize exploration. The paper shows detailed results and analysis on 2 Atari games: Montezuma’s Revenge and Seaquest, and reports results on other games as well.",0.12359550561797752,0.171875,0.14379084967320263
59,SP:06bbc70edab65f046adb46bc364c3b91f5880845,This paper presents a semi-supervised classification method for classifying unlabeled nodes in graph data. The authors propose a Graph Inference Learning (GIL) framework to learn node labels on graph topology. The node labeling is based of three aspects: 1) node representation to measure the similarity between the centralized subgraph around the unlabeled node and reference node; 2) structure relation that measures the similarity between node attributes; and 3) the reachability between unlabeled query node and reference node.,"This paper proposes to leverage the between-node-path information into the inference of conventional graph neural network methods. Specifically, the proposed method treats the nodes in training set as a reference corpus and, when infering the label of a specific node, makes this node ""attend"" to the reference corpus, where the ""attention"" weights are calculated based on the node representations and the between-node paths. (The paper used different terms about the ""attention"".)",0.24358974358974358,0.25675675675675674,0.25
60,SP:06c25da862ae69fa7cd0f87ea0b125243ea86f5f,"In this paper, the authors release a new dataset -  Spoken-CoQA which includes an ASR based version of the popular CoQA dataset. The dataset has been created by running the Google TTS system followed by ASR using CMU Sphinx, to create a speech-transcribed versions of the dataset. The dataset includes the corresponding TTS audio recordings. Since the transcribed dataset has transcription errors, existing reading comprehension models do not work well. Thus, the paper introduces a joint audio-textual model for QA on the Spoken-CoQA dataset that uses TTS recordings its corresponding ASR output. ","This paper proposes a new task: spoken conversational question answering, which combines conversational question answering (e.g. CoQA) with spoken question answering (e.g. Spoken-SQuAD). The task is to answer a question (in written text) given a question that is given in both audio form and text form. They create a dataset for this task by combining CoQA with some off-the-shelf text-to-speech and speech-to-text models. They then propose a new model, DDNet, which obtains improved performance on their dataset.",0.18947368421052632,0.20930232558139536,0.19889502762430938
61,SP:06e17ef81ccba1f4406589bdf7b47780f06be8d9,"The paper proposes a generally applicable modification to experience sampling in the context of actor-critic algorithms using a Q function as a critic. The modification is called ""Likelihood-free Importance Weights"" (LFIW). The authors describe the approach in Appendix A in the form of pseudocode.  Comparing to a generic actor-critic algorithm, the changes include the keeping of two replay buffers (""fast"" and ""slow"") and inclusion of an additional re-weighting function w which in turn is used in the update of the Q function. The paper includes a thorough performance comparison on MuJoCo and DM Control Suite. ","This paper is on an experience replay approach, as applied to deep RL methods, that uses a density ratio between on-policy and off-policy experiences as the prioritization weights. The objective is to find appropriate bias-variance trade-offs for importance sampling from the replay buffer. In particular, there's the bias issue from replay experiences of other policies, and the variance issue from the recent on-policy experiences. ",0.16161616161616163,0.22857142857142856,0.1893491124260355
62,SP:06f1aeb9546000b8a91dd6fbdf94d3113466f9fe,The paper focuses on the instability phenomenon happening in the fine-tuning of BERT-like models in downstream tasks. The reasons of such instability were assumed to be catastrophic forgetting and the small size of datasets on which being fine-tuned in previous literature. The authors conduct experiments on several sub tasks of GLUE in an attempt to show the aforementioned two assumptions cannot explain the instability of fine-tuning. Instead they claim that the real reasons are gradient vanishing and the lack of generalization and subsequently propose a set of training hyperparameters to improve the stability.,"This paper considers the stability of fine-tuning BERT-LARGE models, with considerations for RoBERTa and ALBERT. In particular, it aims to demonstrate that previously identified reasons, catastrophic forgetting and small fine-tuning datasets, fail to explain the observed instability. Instead, it posits that the instability is caused by optimization difficulties that lead to vanishing gradients.",0.21649484536082475,0.375,0.27450980392156865
63,SP:06fe119d437e7f517496d554a091979ff74c9431,"The authors train a neural net to predict responses of mouse V1 L2/3 neurons to visual stimulation. The NN has a ""core"" that is shared between all neurons, and a neuron-specific readout. They train the core on multiple animals and find that it can generalize well: it can be used in a new animal and (with sufficient training of the readouts) achieve high performance. They also use a neat approach of constraining the readout weights (receptive field location) using the known retinotopy of V1. Finally, they show that their network outperforms task-trained ones at predicting V1 responses.","The authors adopt a data-driven approach to neural system identification. They train a neural network consisting of a ""core"" and a ""readout"" in an end-to-end fashion to learn stimulus (visual inputs) -- response (single neuron activity) pairs. Since the core is shared across neurons, these stimulus-response pairs can be learnt in a massively parallel manner. In particular, they propose a novel readout mechanism that is parameter efficient and drives the core to learn better and generalizable features of the visual inputs. They find that their representations are more suited to predict neural responses in the mouse visual cortex when compared to representations derived from task-driven learning, especially in the context of transfer to previously unseen animals. Lastly, they also observe that the combination of their core+readout is more sample efficient than other naive alternatives.",0.27,0.19424460431654678,0.22594142259414227
64,SP:0706a81690b0a5309c00632dd76f8d62290c7e9e,"In this paper, the authors proposed a new clustering method called deep amortized clustering (DAC). Inspired by Lee et al 2019, the authors exploited a transformer to gather the contextual information across different dataset points and then predict the cluster label for each data point. The main difference from Lee et al is that the proposed DAC sequentially estimate the cluster labels for the data points and thus more flexible to estimate the number of clusters in the whole dataset. Based on the proposed DAC method, the authors evaluated the performance on both unsupervised clustering and supervised clustering tasks. it turns out the proposed method has achieved better or comparable performance to previous work on various datasets while hold less computational cost. ","The paper presents an amortized clustering method, called DAC, which is a neural architecture that allows efficient data clustering using a few forward passes. The proposed method is essentially based on the idea behind set-input neural networks [1], which consists of modeling the interaction between instances within a given dataset. Compared with the previous work [1], the main difference is that DAC does not need to specify the number of clusters, as in the case of Bayesian nonparametrics, making it more flexible for clustering complex datasets. It is empirically shown that DAC can efficiently and accurately cluster new datasets coming from the same distribution for both synthetic and image data.",0.21311475409836064,0.23423423423423423,0.22317596566523606
65,SP:070b00b3bd28545b1bbdf3f6884e748756fb3101,The paper presents an experimental evaluation of simple pruning techniques applied to modern architectures that are designed to be inherently resource-efficient. It is shown that pruning large models in the FBNetV3 family achieves better accuracy-FLOPS trade-offs than smaller models in the FBNetV3 family. It is also shown that pruning large models is faster than performing NAS to find the smaller models directly.,"This paper applies conventional pruning-and-finetuning techniques to further compress the networks searched by NAS. The experiments and evaluations are based on the family of FBNetV3. The authors show that by pruning large FBNetV3 model to small one, the accuracy of pruned model may be slightly better than the original target (small) model, achieving better tradeoff between computational complexity and accuracy. Also, the authors show that pruning is more training-efficient than searching by NAS to achieve a compact FBNetV3 model. ",0.2923076923076923,0.23170731707317074,0.25850340136054417
66,SP:071496c3043bf470c2b03888971f2d453e3493b3,"This paper proposes a novel dynamic batch normalization and relay (DNR) approach regarding the sequential information in videos. The authors have demonstrated extensive experiments and shown the effectiveness of the proposed DNR for a number of advanced backbones for video action recognition.  Apart from some technical confusions and questions, it is an interesting paper and the idea of dynamic batch normalization may be useful to the community.","The method proposes a module to dynamically scale the tensors within a temporal action recognition model that can act as a drop-in addition to existing models. To achieve this, the per-frame input tensors are pooled into vectors, and a LSTM is used to condition the linear scaling of the tensor depending on the (avgpooled) representation of the current frame, but also previous predictions. This is also extended to include the predictions from the previous layer. There are also a couple of tweaks to the LSTM to improve performance.",0.22388059701492538,0.16666666666666666,0.19108280254777069
67,SP:072d9da072c1ef224e3cfb6f67ef7c0e78e456af,"This paper (ZARTS) proposes to apply gradient-estimation-based zero-order optimization methods to tackle neural architecture search (NAS). Two major contributions are made by this paper: (1) it is the first to borrow the methods of zero-order optimization to solve NAS  problem; (2) it shows that zero-order optimization methods can greatly avoid the training instability of first- or second-order optimization NAS methods like DARTS (which sharpens the loss landscape). Moreover, this paper also provides an explanation on how ZARTS is connected with DARTS. Extensive experiments demonstrate the efficacy of ZARTS.","This paper presents ZARTS, a zero-order optimization method for DARTS, to search without enforcing the approximation of the network weights. It conducts in-depth analysis on the first/second order approximation in DARTS, and points out that such approximation leads to bias and instability. Then the work proposes three zero-order optimization methods to solve the issue.",0.20212765957446807,0.3275862068965517,0.24999999999999994
68,SP:07440014f05a06c121a4e56f6af6e31b2190dc70,"This paper proposed a context-agnostic learning approach that combines an object area and a context image (s.t. background image) to generate input synthetic image and train the model as context-independent. The proposed method is made more efficient by including this generation process in the training loop, compared to a exhaustive sampling method that randomly selects from a set of combinations of object areas and context images. When applying this method on the task of traffic sign recognition, character recognition, it provides enhanced performance in a setting where model is trained using synthetic data and evaluated on real-world dataset.","The paper defines the task of context-agnostic learning and proposes an algorithm to solve the problem while assuming the ability to sample objects and contexts independently. They propose to decompose factors contributing to the risk into two, context bias and object error. Based on this interpretation, an algorithm is designed to 'greedily correct bias' while employing adversarial training (or robustness training) for 'local refinement'. The method achieves high accuracy on two synthetic visual tasks, digits and traffic sign classification, when a model is trained using one sample per class from the source domain and tested on an unseen target domain.",0.22549019607843138,0.22772277227722773,0.2266009852216749
69,SP:0754d0dac07aed6b6672a6b0393087d90a5fe535,"In this paper, the authors propose a set of benchmarks for evaluating different aspects of reinforcement learning algorithms such as generalisation, exploration, and memory. The aim is to provide a set of simple environments to better understand the RL algorithms and also to provide a set of scores that summarise the performance in each respect. The code of the benchmark is also released.","This paper presents the « Behavior Suite for Reinforcement Learning » (bsuite), which is a set of RL tasks (called « experiments ») meant to evaluate an algorithm’s ability to solve various key challenges in RL. Importantly, these experiments are designed to run fast enough that one can benchmark a new algorithm within a reasonable amount of time (and money). They can thus be seen as a « test suite » for RL, limited to small toy problems but very useful to efficiently debug RL algorithms and get an overview of some of their key properties. The paper describes the motivation behind bsuite, shows detailed results from some classical RL algorithms on a couple of experiments, and gives a high-level overview of how the code is structured.",0.31746031746031744,0.16260162601626016,0.21505376344086022
70,SP:075aa882a64acdb6d7c9486c235ef657b7afb104,"This work proposes a technique for iterative structured pruning, without necessarily requiring too much manual human intervention. There are two parts to this paper that are important:  1. It is argued that we should prune channels based on the activation maps generated, rather than focusing on the weights of the channel. 2. They propose an iterative procedure that automatically backtracks if it has made a poor pruning decision.","This paper proposes iterative structured pruning methods using activation-based attention feature maps and an adaptive threshold selection strategy. Inspired by attention transfer, Activation-based attention feature maps are constructed as the important evaluation of filters in each layer. Adaptive threshold selection strategy decides the number of removed filters, which satisfies one of three adaptive pruning policies. Experimental results on CIFAR-10 and ImageNet with ResNet architectures show performance gains over several state-of-the-art methods.",0.17647058823529413,0.15584415584415584,0.16551724137931037
71,SP:076e7698bb0dbd1917516c5c8445d79bf7fead7f,"The author proposes different approaches to the problem of  ""warm-started"" neural networks. Models trained from scratch on the whole dataset have better performance than ""warm-started"" models, which are trained with weights initialized from training using part of the available data.  The authors change hyperparameters like batch size and learning rate and demonstrate a tradeoff between generalization performance of the model and time, required for its training. We can also see that the choice of hyperparameters, necessary for the best performance, levels benefit in time from ""warm starting.""","This paper examines the problem of warm-starting the training of neural networks. In particular, a generalization gap arises when the network is trained on the full training set from the start versus being warm-started, where the network is initially (partially) trained on a subset of the training set, then switched to the full training set. This problem is practical, as it is often preferable to train online while data is collected to make up-to-date predictions for tasks (such as in online advertising or recommendation systems), but it has been found that retraining is necessary in order to obtain optimal performance. The paper also mentions active learning, domain shift, and transfer learning as two other relevant and important problems.",0.21348314606741572,0.1557377049180328,0.18009478672985782
72,SP:0783e842aa0246f8c1726f19d3f36e3abe6b3654,"This paper presents a new contrastive representation objective that has good training stability, minibatch size sensitivity, and downstream task performance. This objective is a generalization of Chi-square divergence, the optimal solution is the density ratio of joint distribution and product of marginal distributions, the estimation is consistent and its variance goes to 0 as sample size goes to infinite, so the paper is theoretical sound. The authors conduct comprehensive experiments to show that the training based on this objective is stable, not sensitive to batch size and leads to good downstream task performance  in vision and phoneme and speaker classification. ","This paper proposes a new objective for self-supervised contrastive learning. In the general framework proposed by Tsai et al. (2020b), the proposed method boils down to using a divergence related to $\chi^2$-divergence. Compared to other objectives for contrastive learning, the authors illustrate the advantages of the proposed one in training stability (or easiness to train), sensitivity to batch size, and downstream task performance. However, introducing three new hyperparameters is a cause of concern since they make it more difficult to select optimal hyperparameters. Also, some important details of the experiments are missing. For example, how many runs to obtain the results shown in Tables 2 & 3? What's the confidence interval on the results? Any test to establish the statistical significance? What are the settings for supervised training? When the authors compare the results among different methods, did they select the optimal hyperparameters (e.g., learning rate) separately for each method?",0.2376237623762376,0.15584415584415584,0.18823529411764703
73,SP:078840d88e800658a0df9afe19d0a0593f259060,"This work presents a quantitative and qualitative analysis and evaluation of the self-attention (Vaswani et al., 2017) mechanism combined with relation network (Santoro et al., 2017) in the context of model-free RL. Specifically, they evaluated the proposed relational agent and a control agent on two sets of tasks. The first one “Box-World” is a synthetic environment, which requires the agent to sequential find and use a set of keys in a simple “pixel world”. This simplifies the perceptual aspect and focuses on relational reasoning. The second one is a suite a StarCraft mini-games. The proposed relational agent significantly outperforms the control agent on the “Box-World” tasks and also showed better generalization to unseen tasks. Qualitative analysis of the attention showed some signs of relational reasoning. The result on StarCraft is less significant besides one task “Defeat Zerglings and Banelings"". The analysis and evaluation are solid and interesting. ","The authors present a deep reinforcement learning approach that uses a “self-attention”/“transformer”-style model to incorporate a strong relational inductive bias. Experiments are performed on a synthetic “BoxWorld” environment, which is specifically designed (in a compelling way) to emphasize the need for relational reasoning. The experiments on the BoxWorld environment clearly demonstrate the improvement gained by incorporating a relational inductive bias, including compelling results on generalization. Further experimental results are provided on the StarCraft minigames domain. While the results on StarCraft are more equivocal regarding the importance of the relational module—the authors do set a new state of the art and the results are suggestive of the potential utility of relational inductive biases in more general RL settings.",0.18421052631578946,0.23140495867768596,0.20512820512820512
74,SP:078c421b5a61a3a21dd61b4aa0383436ee157605,"The authors propose a new approach to perform deterministic variational inference for feed-forward BNN with specific nonlinear activation functions by approximating layerwise moments. Under certain conditions, the authors show that the proposed method achieves better performance than existing Monte Carlo variational inference. This paper is interesting since most of the existing works focus on Monte Carlo variational inference. The main contribution of this paper is to perform Gaussian approximation. The authors show that for specific activation functions, the Gaussian approximation is reasonable. The main concern is the cumulative error due to the Gaussian approximation. Since the authors argue that the proposed method fixes the issues of stochastic VI for BNN, the authors should also investigate/clarify the following cases. ","This work is tackling two difficulties in current VB applied to DNNs (""Bayes by backprop""). First, MC approximations of intractable expectations are replaced by deterministic approximations. While this has been done before, the solution here is new and very interesting. Second, a Gaussian prior with length scales is learned by VB empirical Bayes alongside the normal training, which is also very useful.",0.08333333333333333,0.16129032258064516,0.10989010989010987
75,SP:07924615714b3ca8e074692d1c0552c700951574,"The paper proposes to improve the exponential sample complexity of finding a coordinated multi-agent strategy by learning an exploration policy for each agent that conditions on a shared goal. The exploration policy is mixed with the normal RL policy according to a parameter alpha, which is scaled down over time. The shared goal that agents pursue is selected by using an explicit counter mechanism over objects in the environment. ","The paper introduces an exploration bonus tailored to multi-agent learning in the CTDE (centralized training, decentralizing execution) setting. The bonus works by: 1) dividing up the observation space into subspaces (in this case, corresponding to the entities, pairs of entities, triplets of entities, etc), 2) maintaining running counters within each subspace of every possible configuration within that subspace, 3) identifying the lowest entropy subspace, 4) sampling the replay buffer to find a rarely occurring (but importantly, reachable) “goal” state within the lowest entropy subspace, and finally, 5) rewarding the exploration policy for visiting the goal state. The authors test their method in two domains: 1) a series of coordinated multi-agent exploration challenges in grid worlds, and 2) the Starcraft Multi-Agent Challenge (SMAC). They demonstrate much faster learning over a series of baselines.",0.24285714285714285,0.1259259259259259,0.16585365853658535
76,SP:07bb9747aaae728b6e29880610dc5173af0f9e01,"The idea of learning representations from video rather than single images is an appealing one with many favorable properties to allow a system to get direct signal on appearance of objects under various natural transformations (occlusion, lighting, etc). Combining instance discrimination ideas of loss based on unlabelled images for which it is known whether they are similar or not, with the idea of curating the images from video is hypothesized to yield learned representations that capture properties enabling improved performance across a variety of single image tasks. The authors create a dataset based on video with positive pairs for noise contrastive estimation, conduct fairly comprehensive experiments and promise to make their newly constructed dataset available. The experiments showcase this type of learned representation outperform alternatives not based on videos on a variety of tasks. ","This paper incorporate the popular contrastive with unsupervised learning from video. Specifically, multiple frames from the same video is used as positive pairs and frames from different videos is viewed as negative pair.  The author also proposed a simple and effective ways to collect class-balanced and diverse video frame dataset from Youtube.  The author conducted extensive evaluation experiments on both video recognition and image recognition downstream tasks. Extensive ablation experiments demonstrated the effectiveness  of utilizing multiple frames and the balanced data collection algorithms. ",0.11940298507462686,0.19047619047619047,0.14678899082568808
77,SP:07e42db34b99c1c6bd5c7c5823db9f0bffe5ecdb,"This paper introduces EinStein VI: a lightweight composable library for Stein Variational Inference (Stein VI). The library is built on top of NumPyro and can take advantage of many of NumPyro's capabilities. It supports recent techniques associated with Stein VI, as well as novel features. The paper provides examples of using the EinStein VI library on different probabilistic models. ","The paper shows how a particle-based nonparameteric Variational Inference methodology known as Stein Variational Inference is integrated in a full-featured Probabilistic Programming Language, NumPyro. The paper goes into a fair amount detail describing a number of enhancements that have been made into numpyro using the general technique of particle-based representation of non-parameteric approximating distributions. They describe how geometric transforms of the parameter space can fit into their scheme, how matrix-valued kernels can be integrated. Also, they describe a new variant of Stein VI which they call ELBO-within-Stein. This introduces a new line of research for Stein VI. They also describe a Stein Mixture extension to Deep Markov Models (SM-DMM) and demonstrate on a very large dataset for the latter method.",0.25,0.1171875,0.1595744680851064
78,SP:07ed349309fb6c81f6b2f61c769c5e097988064f,"Quality: This submission claims to present a model that can control non-annotated attributes such as speaking style, accent, background noise, etc. Though empirical evidence in the form of numerical measurements is presented for some controllable attributes more evidence other than individual samples and authors claims is needed. For example a reliable numerical evidence is needed on page 4 following ""We also found..."", page 5 following ""We discovered...."", page 5 following ""It clearly presents..."", page 5 following ""Drawing samples..."" evidence is given only for 1 dimension, page 6 following ""Figure 7(b)..."". ","The authors describe the conditioned GAN model to generate speaker conditioned Mel spectra. They augment the z-space corresponding to the identification with latent variables that allow a richer set of produced audio. In a way this is like a partially conditioned model that has ""extra"" degrees of freedom. It looks that the ""latent"" variables are just concaneted to the ""original"" set of z-values (altough with particular conditions to maximize independence). The conditioning of the z-space has originality in it and may provide interesting to the audience. Ultimately one coud think about z-space direction being totally mapped to specific features of the produced signal.",0.07608695652173914,0.06542056074766354,0.07035175879396983
79,SP:082a02221a8515ae6c08356eeae7ca4412bd2e1f,"- The paper introduces the notion of ""orthogonal classifiers"": classifiers that rely on orthogonal variables. It starts with the simple linear case, and adds a definition that also applies to the non-linear case. - The paper proposes two methods to identify a classifier orthogonal to a given one. - It then describes 3 use cases: style transfer, domain adaptation, and fairness. ","The paper presents classifier orthogonalization technique that works for non-linear classifiers. The idea is to find a method that orthogonalizes the full classifier w.r.t. the principal classifier so that the resulting classifier is statistically orthogonal to principal classifier. The algorithm turns out to be very simple, only requiring access to the full classifier $P(Y|x)$ and the principal classifier $P(Y|z(x))$, where $z$ is a control variable you want to orthogonalize against. The paper also discusses an alternative method of classifier orthogonalization using importance sampling.   The effectiveness of the proposed classifier orthogonalization technique has been demonstrated through 3 applications: controlled style transfer, domain adaptation, and classifier fairness. For controlled style transfer, authors modified the CycleGAN's generator update step by orthogonalizing discriminator w.r.t. the controlled style variable. For domain adaptation, they modified VADA, an adversarial domain adaptation approach, by orthogonalizing discriminator based on the label-based principal classifier, so that discriminator wouldn't discriminate the domain based on the frequency count of labels from each domain. For fairness, full classifier is orthogonalized by the sensitive attribute classifier.",0.3389830508474576,0.10810810810810811,0.1639344262295082
80,SP:08350406f571056b5652cff2e4b0c5ed7ccb13c8,"This paper is aimed at tackling a general issue in NLP: Hard-negative training data (negative but very similar to positive) can easily confuse standard NLP model. To solve this problem, the authors first applied distant supervision technique to harvest hard-negative training examples and then transform the original task to a multi-task learning problem by splitting the original labels to positive, hard-negative, and easy-negative examples. The authors consider using 3 different objective functions: L1, the original cross entropy loss; L2, capturing the shared features in positive and hard-negative examples as regularizer of L1 by introducing a new label z; L3, a three-class classification objective using softmax.","This paper proposes to improve performance of NLP tasks by focusing on negative examples that are similar to positive examples (e.g. hard negatives). This is achieved by regularizing the model using extra output classifiers trained to classify examples into up to three classes: positive, negative-easy, and negative-hard. Since those labels are not provided in the original data, examples are classified using heuristics (e.g. negative examples that contain a lot of features predictive of a positive class will be considered as hard-negative examples), which are used to provide distant supervision. This general approach is evaluated on phrase classification tasks, one information extraction task, and one MRCQA task.",0.21428571428571427,0.21621621621621623,0.21524663677130043
81,SP:08608681039257cdec8796e4721dcb2306816a8c,"Winning tickets can often be costly to discover, so this paper explores the issue of copyright protection for winning tickets -- protecting against IP infringement on the owners of a winning ticket. Namely, this paper studies “lottery verification” by analyzing sparse topology of a winning lottery ticket network with the use of several graph-based signatures (i.e., verifiable patterns that can be embedded into the weights/predictions of the winning ticket). Further, these attacks are robust to fine-tuning and extra pruning, which is extremely important for robust validation of winning tickets.While this area has been extensively studied for neural networks in general, this paper seems to be the first to study ownership verification for winning tickets/sparse neural networks. They propose three separate methods for ownership verification: key masks, embedded signatures, and trigger-based methods. Each of these methods are evaluated empirically on the CIFAR datasets using ResNet model variants.","Finding a special sparse subnetwork (winning ticket) from an overparameterized network is an expensive process. Due to the cost involved in obtaining this ticket, its owner might be interested in protecting it. This paper proposes graph-based signatures to perform lottery verification. Their method can work in both white-box and black-box settings. They show that due to the extremely sparse structure of the winning ticket, it can partly claim its ownership, without any specific protection mechanism. They give a mask embedding method to embed ownership signatures in the subnetwork. They claim such signature is robust to pruning, fine-tuning attacks. These claims are backed by experiments on ResNet models. ",0.1513157894736842,0.2072072072072072,0.17490494296577946
82,SP:08773cf78eb6d5f7b0a57c5f2d94b08766a25212,"This paper provides an interesting model that can be used for a meta-learning situation where both data distribution and the number of features vary across tasks. The proposed model referred to as ‘Distributed Embedding Network (DEN)’ transforms features to belong to the same distribution family, learn distribution embedding with them and process variable-length inputs by using DeepSets. Through experiments on binary classification tasks, this paper shows applying the proposed method on the problems outperforming meta-learning baselines. ","The authors proposed a method for meta-learning that produces a distributional embedding of the task, and then uses this information to perform few-shot classification. The method decouples feature extraction from feature aggregation & few-shot reasoning within the given task. The authors conduct experiments to show that their method is competitive with a few other methods from the literature on a number of datasets.",0.12658227848101267,0.15384615384615385,0.1388888888888889
83,SP:0884761fc60276d6d151552118758b07cd50a24e,"The paper proposes a model-based reinforcement learning method. The method builds a partial model of the environment through learning inverse dynamics, which is the distribution of action sequences that would bring one state to another state. Through training the model with an iterative relabeling scheme, the model is able to learn to reach goals in a subset of DM Control and Atari domains. ","The author proposes Goal-Conditioned Latent Action Models for RL (GLAMOR) a novel approach to learn latent world models by modeling inverse dynamics. The proposed approach learns to track task-relevant dynamics for a diverse distribution of tasks and provide a strong heuristic that enables efficient planning. GLAMOR demonstrates good performance against its baselines in terms of achieving accurately goals, sample efficiency and effective planning.",0.1875,0.18461538461538463,0.18604651162790697
84,SP:08889d3b0659e76092dbb9a9fd2825701cebda44,"This paper is motivated by an observation that maximization-based decoding approaches such as beam search can lead to incoherent and repetitive sentences when open-ended long-form text generation based on neural language model such as GPT-2 is performed. To solve the problem, this paper proposes a sampling method called Nucleus Sampling. Similar to Top-k sampling, Nucleus Sampling truncates the probability distribution of the words in the vocabulary. Instead of re-normalizing the probabilities for the top-k words, Nucleus Sampling re-normalizes the original probabilities for the words with values above a pre-chosen threshold p. Some quantitative and qualitative results show that the proposed sampling method can generate long-form texts with some nice properties.","This paper studies an important problem, i.e., how to find a good decoding strategy for open-ended text generation. To this end, the authors provide a deep analysis of the most common decoding methods, and propose Nucleus Sampling, a very simple yet effective method to generate higher-quality text. Compared with top-k sampling, the key idea behind the proposed method is to sample from the dynamic nucleus of tokens containing the majority of the probability mass. Experiments demonstrate that nucleus sampling is an effective decoding strategy in practice. ",0.20833333333333334,0.2777777777777778,0.2380952380952381
85,SP:08957836ae755ff67421cbefd5e48859bd403a83,"This paper proposes a technique called Adversarial AutoAugment which dynamically learns good data augmentation policies during training. An adversarial approach is used: a target network tries to achieve good classification performance on a training set, while a policy network attempts to foil the target network by developing data augmentation policies that will produce images that are difficult to classify. To train the policy network, each mini-batch is augmented multiple times with different policies sampled from the policy network. Each augmented mini-batch is passed through the target network to produce a corresponding training loss, which is used as the training signal for the policy network. Experimental results are shown for CIFAR-10, CIFAR-100, and ImageNet datasets, where Adversarial AutoAugment outperforms competing methods (AutoAugment and Population Based Augmentation) on a variety of model architectures.","This paper describes a method to learn data augmentation policies using an adversarial loss. It builds on the AutoAugment method. In AutoAugment, an augmentation policy generator is trained by reinforcement learning. At each iteration, a classifier network is trained from scratch based on the current augmentation policy, and its validation accuracy is used as the reward signal. This is extremely costly because it requires to train a complete network for every training step of the policy generator. Instead, the current paper proposes to train the policy generator and the classifier simultaneously. The policy generator is trained adversarially to find augmentation policies that increase the loss of the classifier. This leads to a significant speedup compared to classic AutoAugment.",0.2074074074074074,0.23728813559322035,0.22134387351778656
86,SP:08c1cbc07686b1f7b7fa01246b72929858c3846a,"In real-life applications of predictive models, predictions often form a step of the process. Changes in the predictive model often need to be validated end to end using methods such as A/B tests before they can be used in production. Thus for certain class of problems, there is a need to control the churn or the difference in the predictive model due to retraining of the model towards a more robust pipeline. The authors present an approach to control this churn via a simple distillation method. They also show that their distillation method, under certain assumptions, is equivalent to a constrained optimization problem that explicitly constrains the ""churn"" without the added complexity of constrained optimization. They validated their method by conducting experiments on a number of baselines on a wide range of datasets and model architectures. ","This paper explores the relationship between the low-churn problem and distillation. The authors show that there is an equivalence between those two methods and that distillation performs particularly well on low-churn dataset tasks. The authors propose a novel churn reduction algorithm based on distillation which involves the training of a classifier by minimizing a distilled loss and solving a convex program. The authors  provide theoretical guarantees for the proposed algorithm and explain the advantages of the proposed approach compared to the anchor loss, another churn-reduction method.   The authors validate empirically their approach on 12 OpenML datasets, 10 MNIST variants, CIFAR10, CIFAR100 and IMDB.   ",0.14492753623188406,0.18867924528301888,0.16393442622950818
87,SP:08d227e9382cb5eb359462f2e75cca62f3457cf0,"The line of reasoning and analysis followed in the paper is mostly sound. The paper claims that the use of (state-action) occupancy measure make IL and IRL methods brittle due to the high variance of these measures and their inability to transfer to other domains. These two claims are neither properly defined and grounded in the literature, nor are they isolated experimentally. It is important to show clearly that a) these are problems, b) hitherto unaddressed in the research landscape, and that the proposed methods and techniques address these problems specifically. ","This paper builds on a recent inverse-RL method, AIRL. The authors argue that the rewards learned by AIRL are potentially inefficient since they depend on the ratio of state-action visitation distributions of the expert and the policy. To resolve this, CAIRL derives rewards that excludes these visitation distributions; this is realized in practice by employing another discriminator to approximate the state-visitation distribution ratio. The paper further proposes a mechanism to handle the reward-bias issue in IRL. Experiments with the MuJoCo locomotion tasks show that CAIRL is a competitive algorithm for imitation learning and can also handle dynamics mismatch between the expert and the learner.",0.21739130434782608,0.18518518518518517,0.19999999999999998
88,SP:08dbd0677de078598537324299a1495f34aa5bc2,"The paper proposes LAMP, an importance score for unstructured pruning that incorporates layerwise statistics such that the resultant scores for each connection can be compared globally, cutting down on the hyperparameter space for magnitude pruning from the relatively standard practice of requiring hand-specified layerwise pruning rates. LAMP is motivated with a distortion analysis: LAMP is shown to be equivalent to minimizing an upper bound on the supremum of the change in model predictions of unit vectors. LAMP is compared against layerwise pruning rates obtained by standard uniform layerwise and global pruning, along with the less standard Erdos-Renyi kernel method, showing that LAMP can achieve higher accuracy for equivalent pruning rates in a specific experimental setup across several different networks.","This paper presents a novel technique  (layer-adaptive magnitude based pruning, or LAMP) for pruning neural network weights (pruning can be beneficial in terms of overfitting prevention as well as other practical considerations).  LAMP evaluates weights in each layer in terms of the ratio of the magnitude of the weight to the sum of magnitudes of all surviving weights in the layer. The weight which evaluates as least important across all layers is pruned and then the process is repeated until the desired sparsity is achieved. The method is motivated theoretically as minimizing the distortion in the input/output mapping implemented by the weights of the layer. Experimental results on several benchmarks are presented.",0.1652892561983471,0.17543859649122806,0.1702127659574468
89,SP:090ef046e93df4bd358e4e2831132b018407556e,"This paper proposes an efficient pessimistic-optimistic algorithm for stochastic linear bandits with general nonlinear constraints. The authors give a later-constant-dependent regret that, compared to the unconstrained case, achieves a similar complexity order in terms of T but higher-order dependence on d. This algorithm also achieves zero-constraints violation after a certain time \tau, where $\tau$ is independent.  Besides the main results, the author also gives several side results including a high probability bound on sample-path version of the constraints and abound for linear cost when the cost is revealed after the learning taking actions (so it's also bandits).","This paper proposes a learning algorithm for a stochastic linear bandits with constraints. At each decision step, the decision maker can choose between J actions. Each action A_t then provides a context-dependent reward $r(C_t, A_t)$ and contributes a $W_k(C_t, A_t)$ to the ""constraint k"". The goal of the learner is to maximize the reward provided that the K constraint $\sum_{t=0}^\tau W_k(C_t, A_t) \le 0$ are respected.  The authors present an algorithm that guarantees a sublinear regret in $O(\sqrt{T})$ while respecting constraints for all time-steps except at most O(1) time-steps.  After presenting the algorithm, most of the paper is devoted to a careful analysis of the theoretical properties of the algorithm. No application nor experimental results are presented. ",0.25,0.18840579710144928,0.21487603305785125
90,SP:09784594743442e7d357697bd4fd0c370df170c3,"In this paper, the authors consider a notion of statistical/probabilistic robustness which does not require a model to be robust to all inputs in a specified set, only a certain, high-probability subset of these inputs. The authors rely on a bound propagation methodology to compute the the probability that a given input property is violated. In particular, the authors expand a known methodology (PROVEN) for computing probabilistic robustness and show that in many cases their methodology is better than that of PROVEN. ","This work considers problem of local robustness where each input is perturbed according to some probability distribution (e.g. uniform distribution over the L-infinity ball). Proposed approach is based on extending an approach proposed by prior work which uses linear bounds to compute bounds on the output of the network. The key contribution is computing the probabilistic bounds for inner layers, and not only the final one as was done in prior work. Authors show that their approach improves over prior work on MNIST and CIFAR-10 datasets. ",0.21428571428571427,0.20224719101123595,0.20809248554913296
91,SP:0a036636575bd445f18928c438a9fb063f11b012,"This paper proposes to improve the learnability of the gating mechanism in RNN by two modifications on the standard RNN structure, uniform gate initialization and refine gate. The authors give some propositions to show that the refine gate can maintain an effective forget effect within a larger range of timescale. The authors conduct experiments on four different tasks and compare the proposed modification with baseline methods.","This paper introduces two novel techniques to help long term signal propagation in RNNs. One is an initialization strategy which uses inverse sigmoid function to avoid the decay of the contribution of the input earlier in time and another is a new design of a refine gate which pushes the value of the gate closer to 0 or 1.  The authors conduct exhaustive ablation and empirical studies on copy task, sequential MNIST, language modeling and reinforcement learning. ",0.2727272727272727,0.23376623376623376,0.2517482517482518
92,SP:0a155411707f21e84ec5d4ec1d53e29d5a622074,"This paper proposes an active learning and active search approach that targets samples for rare classes in very large unlabeled datasets with highly imbalanced class distributions. This is a common scenario in real-world applications, where these rare situations can be critical to accurately categorize - ie endangered species. The authors propose an approach that targets these rare cases while reducing the number of overall examples sampled, and that scales with the amount of labeled data as opposed to the amount of unlabeled data which allows them to consider datasets up to billions of examples.","This paper proposes a new method (SEALS) to accelerate the active learning and active search with the skewness of the cardinality of rare class compared to the large-scale datasets. To leverage this skewness, the authors restrict the candidate pool for labelling mainly from the nearest neighbours of the currently labelled set (except the initial set). The authors conduct very detailed experiments on the tasks of active learning and active search over three large-scale data sets to validate the efficiency and effectiveness of SEALS. ",0.23404255319148937,0.25882352941176473,0.2458100558659218
93,SP:0a31bc4cda9cbbfc9b5ab0e951eb529579842300,"> Summary: This paper proposes some changes to the classical Transformer architecture to address its major limitations, such as limited access to higher-level representations. It specifically introduces recurrence to the Transformer architecture by feeding the activations of all previous time steps to a later time step (in the form of self-attention). Empirical results on language modeling and small-scale RL tasks seem to suggest the usefulness of doing do.","This paper modifies transformers with feedback memory. Specifically, for each timestep, it merges hidden representations of all layers into a high-level single vector and stores it in memory. For the current timestep, it attends past memory vectors. The authors claim that in this way, low layers of the current timestep can utilize high-level representations of past timesteps. The authors show that the proposed models with shallow layers can achieve stronger performance than comparable transformers. However, it seems that the models need a much longer time to train.",0.15714285714285714,0.12359550561797752,0.13836477987421383
94,SP:0a399b8240f6ee31ae85525c0a5133181cb842e9,"In this paper, the authors consider the task of learning a single ReLu neuron with bias using gradient descent, which has a significantly different behavior than the unbiased case. For example, adding a bias leads to examples where gradient descent fails to find the global minimum with probability $1/2$, whereas GD succeeds wp 1 with no bias. This is explain by GD getting stuck at critical points which are characterized in Section 4. The authors then show that if the GD is initialized at a point with loss better than the trivial loss, then it converges to the global minimum. This good start happens with high probability for standard symmetric initialization (and 0 bias initialization), and can be shown to converge at linear rate. Finally, in section 6, they provide an alternative set of assumptions that leads to linear convergence, with rate that do not depend on initialization (but with lower probability on initialization).   --- after rebuttal ---  I am satisfied with the authors response. I am keeping the same rating.","The work considers learning a single ReLU with the bias term using gradient based methods (and more specifically with gradient flow and gradient descent - which falls in the infinite data regime). Whereas previous works mostly considered this problem without the bias term, it (the bias term) is essential in a lot of practical applications. The paper considers gradient descent/flow with respect to standard squared error, which is practically relevant.   First, it is shown (Section 3) that learning a single ReLU with bias via. gradient based methods is much harder than without by constructing specific negative examples. Then, under natural assumptions on the data distribution, the stationary points of the loss function is characterized and it is shown that it is a cone in Section 4 (rather than a finite set as is the case when there is no bias). The  subsequent sections explore several assumptions under which convergence can be guaranteed with high probability and with random initialization.   ",0.2,0.2138364779874214,0.2066869300911854
95,SP:0a4cf8c20a5ac64540faf909d0e6d3af34e4036c,"The paper proposes a new model for numerical reasoning in machine comprehension. Given a passage and a query, the model outputs an arithmetic expression over numbers/dates in the passage (e.g. max(23, 26, 42)). The model is trained with weak supervision in the form of numerical answers only. This weak supervision is used to define reward for reinforcement learning training. A key claimed advantage of the model compared to the prior art is that it trains end-to-end from the rewards as the only form of supervision. This is contrasted to  neural module networks, which require program supervision for good performance, as well as GenBERT, which requires additional synthetic training data for pretraining. Two key quantitative results include: ","This paper proposes a neurosymbolic module network that predicts a program structure following a dependency parse, populates that program's arguments, and executes it to answer numerical reasoning questions over text.  They claim that compared to Gupta et al. (2020), this approach doesn't require as many domain-specific heuristics to find gold programs or as much precomputation -- it is learned with weak supervision only (just the answers). The model has a number of pieces allowing the model to reference entities, numbers, and dates in a cross-attentive fashion. Results show that on numerical questions from the DROP dataset, the model outperforms that of Gupta et al. and is competitive with other approaches when appropriate assumptions are made.",0.19008264462809918,0.19491525423728814,0.19246861924686195
96,SP:0a51115327ce08990aa3517ae1d20e88e80d6d65,"This paper proposes a new continuous-time formulation for modeling recurrent units. The particular form of the recurrent unit is motivated by a system of coupled oscillators. These systems are well studied and widely used in the physical, engineering and biological sciences. Establishing this connection has the potential to motivate interesting future works. The performance of the proposed recurrent unit is state of the art.","Firstly, this paper conducts the rigorous analysis of the coRNN via the formula deduction to verify the bound. Then the coRNN is proved to mitigate the exploding and vanishing gradient problem and this is also validated in a series of experiments. Also, the performance of the coRNN is comparable or better compared to state-of-the-art models. This paper provides a new idea to address the exploding and vanishing gradient problem, which hinders the development of deeper neural networks tremendously. In my opinion, this coRNN model is meaningful for practical application, especially for the extension of more complicated neural networks. ",0.27692307692307694,0.1782178217821782,0.21686746987951805
97,SP:0a523e5c8790b62fef099d7c5bec61bb18a2703c,"The authors propose to use a non-end-to-end approach to the problem of multi-modal I2I. Firstly, a metric learning problem is solved to embed images into space, taking into account the pairwise style discrepancy (style is defined, e.g., based on VGG Gramians). As the notion of style is universal for similar datasets, this step further is shown to be generalizable. Secondly, the generator is trained on a supervised image translation tasks: the original image and the style, extracted from the target image, are fed to the generator, and the output is a translated image. Thirdly, style encoder and generator are simultaneously finetuned.","In this paper, the authors tackle the problem of multi-modal image-to-image translation by pre-training a style-based encoder. The style-based encoder is trained with a triplet loss that encourages similarity between images with similar styles and dissimilarity between images with different styles. The output of the encoder is a style embedding that helps differentiates different modes of image synthesis.  When training the generator for image synthesis, the input combines an image in the source and a style embedding, and the loss is essentially the sum of image conditional GAN loss and perceptual loss. Additionally, the authors propose a mapping function to sample styles from a unit Gaussian distribution.",0.2641509433962264,0.24778761061946902,0.2557077625570776
98,SP:0a53cecba6b2eda47d14aacdd8e9873c8c1cce5b,"This paper proposes a non-smooth method to enforce individual fairness in gradient boosting. To deal with the non-smoothness of the model, it restricts the optimal transport distance to that defined on an augmented training support set and thus reduces the search of a worst-case distribution to solving an LP problem, where an approximate solution can be found efficiently by SGD on the dual space. The authors provide convergence and generalization properties of the algorithm, and demonstrate its improvement of group and individual fairness metrics in several numerical experiments.","The authors presented in the submission a thorough study on enforcing the aggregated individual fairness with non-differentiable ML models. The proposed method generates individually fair and robust ML models in a minimax fashion among all possible samples that are close to the true distribution w.r.t. a given fair metric. They introduce the augmented support and transfer the standard gradient descent to a gradient descent in the functional space anchored by the augmented support to optimize the adversarial risk function with non-smooth ML models, e.g. decision trees. Solid theoretical guarantees and convincing empirical study results are provided to support their claims. The paper is highly completed, well-structured (though a bit dense given the page limit) and well-written - a clear accept.",0.1978021978021978,0.14285714285714285,0.1658986175115207
99,SP:0a5525d1cbaa4856f6556e1426a1236b73cfc8d3,"This paper proposes a data augmentation strategy for a class of problems that the amount of labelled data is limited while the evaluation procedure is easier. Specifically, they are able to incorporate some of the model’s output into training data to guide the training procedure. The idea is quite simple and effective according to empirical results.","This paper proposes a training scheme to enhance the optimization process where the outputs are required to meet certain constraints. The authors propose to insert an additional target augmentation phase after the regular training. For each datapoint, the algorithm samples candidate outputs until it find a valid output according the an external filter. The model is further fine-tuned on the augmented dataset. In experiments, the authors evaluated the proposed training scheme on two datasets: molecular optimization and program synthesis. Results show that the proposed training algorithm improves the success rate and the diversity among generated targets.",0.2807017543859649,0.16494845360824742,0.20779220779220778
100,SP:0a87278c0da53a0b1989fad7932566b8ddd8634b,The paper describes a technique based on the modified generalized gradient descent for finding multiple high-quality local optima of deep neural networks. The search method does not require re-initialization of the model parameters and can be carried out in a single training session. Identified local optima are then used to build model ensembles which appear to outperform several other ensembling approaches.,"This paper proposes a new method for applying the TRUST-TECH method to the ensemble of deep neural networks (DNNs). When applying TRUST-TECH to a deep neural network, it is difficult to determine the direction and exit point. This paper introduces Dynamic Searching Paths (DSP) to solve these problems. The proposed method can apply TRUST-TECH method to DNNs using Stochastic Gradient Descent (SGD) with minor memory overhead. ",0.1746031746031746,0.15942028985507245,0.16666666666666666
101,SP:0a93f0ca52d6a7b39a82c3a9e3199255a4fa4c84,"Federated learning has emerged as a promising approach to training models at the edge devices. This paper makes an observation that most algorithms used within federated learning, including the popular FedAvg, could be cast as instances of EM methods. The paper then continues to propose FedSparse, a federated learning framework imposing sparse priors (specifically Bernoulli-Gaussian priors), and concludes with some experimental results on FedSparse.","The paper proposes to re-interpret federated averaging (FedAvg) as a version of the expectation-maximization (EM) algorithm under a particular probabilistic model. Further, the authors propose to use spike-and-slab sparsity inducing priors over the local model parameters to sparsify the learned models (the corresponding method is called FedSparse), which naturally reduces the communication cost (only non-zero parameters need to be sent over the network). Improvement in communication efficiency is showcased on a few standard federated datasets.",0.18461538461538463,0.15,0.16551724137931034
102,SP:0ae436583d8ace9acd5810d146933893f229ba9b,"This paper proposes a new architecture search method called ""DARC"" that utilizes a differentiable objective function. Since a naive formulation of architecture search is reduced to a combinatorial optimization which is not differentiable, the optimization requires much computational cost. To overcome this difficulty, this paper proposes a L1-norm relaxation and apply such relation in a layer-wise manner. The method shares a similar spirit with NAS, but the proposed model is more like ""model selection"" from a fixed candidates, and thus there is a Rademacher complexity guarantee. The effectiveness of DARC is justified by thorough numerical experiments.","The authors proposed a new gradient-based architecture search method that tries to find more efficient alternatives starting from the pre-trained model. The approach is similar to DARTS (Liu et al., 2019) with a budget constraint, such as size and throughput. One major difference is to modify the update of architectural parameters, i.e., mixing weights of all candidate operations, to induce the sparsity rather than to keep the weighted sum of all possible operations. Another difference is that it starts from a well-defined architecture with pre-trained weights. It is simple to apply, but hard to tell. The recognized strengths and concerns are as follows.",0.19387755102040816,0.17592592592592593,0.18446601941747573
103,SP:0af1989b2e643d013174489704d0a052bad77f95,"This paper presents a new kind of adversarial attacks, named hypocritical attack. It is a reverse version of the original adversarial attack. It tricks a model into classifying data correctly with a perturbation. This can be a problem since it can make people satisfy the model performance, but the model is not robust on the real test dataset. The authors review the adversarial attack and define the new hypocritical examples and risk. The authors also show the simple results why hypocritical attach is a critical issue by a Naive model that is initialized randomly. It shows high performance on the hypocritical examples but low on the clean test data. They also investigate the algorithms that improve model robustness, THRM, and TRADES. Experiments show a trade-off between original classification loss and hypocritical risks, and THRM is a tight upper bound against the TRADES.","1. The premise of the paper is that the adversary can perturb the *test* set so that the model is shown to perform better that it really is capable of. And in Section 7 (Conclusion) the paper claims that it exposes this new risk. However, remember that this risk is already mitigated in practice by keeping the test data *independent* of the model/classifier (e.g., see Kaggle competitions where the test set is hidden). Therefore, the perceived risk is not even present. In the context that the technique has been introduced, it seems like the [malicious] actor would only be fooling him/her self rather than fooling the model/classifier.",0.14685314685314685,0.1891891891891892,0.16535433070866143
104,SP:0b0db4cedc3aec32ff2221bb626e1c74bd757b4d,"This paper proposes a learning-based algorithm for reducing the planning time for collision-free robot motion planning problems. The author rightly notes that the bottleneck for motion planning is collision checking, especially along the vertices on the edges of a search tree, and proposes to learn a function, called GNN Path Explorer, that prioritizes the edges to check collisions. Based on this priority information, the algorithm builds a path from a start to a goal, while checking collisions only on the edges that have the highest priority out of the ones that have not been considered so far. This tree is then fed to a GNN Path Smoother, which processes the path and modifies it to one that has a lower cost. Training data is generated by past planning experience, in which the oracle is used to compute the optimal path on the current search tree. It is demonstrated on several domains, ranging from 2D environments with narrow passages and a point robot, to domains with high dimensional configuration spaces (c-space).  ","At a high-level, this work proposes GNNs as models for biasing the sampling of edges and nodes to connect in a random geometric graph. The chief goal is to reduce the amount of collision-checking necessary to plan a path from a start to a goal. Two models are presented: one that performs the above, and another that then smooths the returned path in order to further reduce path cost.  Specifically, the proposed approach first constructs a random geometric graph (RGG) by sampling points from free space. Then, a GNN-parameterized policy iteratively guides the selection of RGG edges for collision-checking. A collision-free path is found when the start and goal nodes are connected on the RGG. The algorithm then leverages another GNN to smooth the solution path. Both GNNs are learned by imitating the solutions of existing oracles. The proposed approach achieves higher success rates, lower collision checks, and comparable path costs on a set of benchmark motion planning tasks compared to existing traditional and learning-/sampling-based algorithms.",0.2138728323699422,0.2138728323699422,0.21387283236994217
105,SP:0b1459e58145faa54216d433648da41f64c39a23,"This paper studies how to build semantic spatial maps for the purpose of navigation in 3D environments. The paper presents a differentiable policy network that pastes together semantic map predictions into a spatial map. Information is read out from this map using a global read operation (that looks at the entire map) and a self-attention read operation. This information is used to produce actions. The paper presents experimental results in 3D VizDoom scenarios and reports improvements over a vanilla LSTM, and another spatial memory based method (Neural Map).","The paper proposes a novel architecture for spatially structured memory. The main idea is to incorporate inductive bias/invariance derived from projective geometry arguments. The experiments seem to clearly show that this new architecture improves previous approaches to tasks which require spatial reasoning and memory, and the ablations studies and visualizations provide useful insights into the workings of the agent. One thing I'm missing is an experiment showing that this inductive bias also doesn't degrade performance on tasks where spatial reasoning is not necessary (as compared to vanilla GRU/LSTM).",0.14606741573033707,0.14130434782608695,0.143646408839779
106,SP:0b1b75d262ebdb85947d961ce6d24ef181874042,"This paper looks at ways to improve memory-writing in memory augmented neural networks. Authors proposed two methods to compare against ""regular writing"" method as well as compare against each other, namely ""uniform writing"" and ""cached uniform writing"". Latter one attempts to utilize a small size memory efficiently by introducing memory overwriting in other words ""forgetting"".","This paper deals with Memory Augmnted Neural Networks (MANN) and introduces an algorithm which allows full writes to the dense memory to be only exectued every L timesteps. The controller produces a hidden output at most timestps, whih is appended to a cache. Every L steps, soft attention is used to combine this cache of N hidden states to a single one, and then this is used as the input hidden state for the controller, with the outputs performing a write in the full memory M, along with clearing the cache.",0.16071428571428573,0.0989010989010989,0.12244897959183672
107,SP:0b2aca080ef8e9de0369bda44f3f417c3f8e96bb,"The authors propose a low-memory gradient computation algorithm for the linear transformer architecture. Their algorithm allows the user to control the trade-off between computational efficiency and memory by specifying how many tokens of the input sequence should be processed at once in the forward pass. At the extreme, the memory consumption can be reduced to a single token (+model parameters +some overhead) They empirically demonstrate that a) the obtained gradient is correct even considered finite-precision arithmetic, b) the actual memory consumption of their implementation aligns with the claims of their analysis, c) the trade-off between memory and compute can be dynamically adjusted during training to allow for fine-tuning on low-memory devices. ","This paper studies a time and memory trade-off for training Performers with the linear attention mechanism. The goal of the paper is to study this trade-off under memory constrained setting, and propose a memory efficient performer training algorithm at the cost of runtime. The contributions of the paper are:  1. Given a sequence of length L, the authors proposed a dynamic programming algorithm which can process the sequence as a collection of segments of length C (the segments are coupled). This reduce the training memory for performer from O(L) to O(C) without any approximation. The intuition here is that the information across segments only flow through certain partial sums over tensors associated with each token in the sequence.  2. The authors analyzed the memory / time trade-off in the proposed algorithm (including extremal cases).  3. Empirically, the authors shows that 1) by controlling the segment length C, the proposed algorithm indeed present a trade off between runtime and memory; 2) The gradient for performer models only have minimal / negligible difference when using the conventional and the proposed algorithm; 3) A large performer model pretrained with the conventional algorithm can be finetuned via the proposed algorithm with small segment lengths; this achieves accuracy matching the conventional algorithm with less memory.  ",0.2905982905982906,0.1596244131455399,0.20606060606060603
108,SP:0b2f9008cd16f792368bbccb68b17d8bf9cf63c5,"This paper provides a novel theoretical account of generalization for kernel regression. To do so, the authors study a matrix built out of the kernel eigensystem evaluated on the training set that they call the ""learning transfer matrix,"" and which relates the decomposition of the true function in the eigenbasis to the decomposition of the learned function in the eigenbasis. In other words, this matrix characterizes the kernel regression solution in the eigenbasis. By making a number of approximations, they are able to find a closed-form expression for this matrix and study its first and second order statistics. A main conclusion from this analysis is that functions are more learnable by kernel regression if they have more weight in higher eigenvalue modes.  Moreover, the authors also introduce a new metric, which they call ""learnability,"" that they use to prove a new no-free-lunch theorem whose content is that when averaging over a complete basis of functions the learnability is independent of the kernel. This means that the choice of kernel should be tailored to the details of the function being learned in order for kernel regression to succeed. A related result is that there are some functions for which the kernel regression solution generalizes worse than simply outputting ""0"" on data outside the training set, i.e. for which the solution fails to generalize at all. ","The paper examines the eigenvalues of a neural network’s “Neural Tangent Kernel” to analyze its generalization performance in the infinite-width regime. It conjectures that the same results will also apply in the finite width regime as well. By analyzing kernel regression and by defining a measure as the “learnability” of a given target function, the paper proves a “no-free-lunch” theorem which implies that improving a network’s or kernel's generalization for a given target function must worsen its generalization performance for its ""orthogonal functions"". The paper then analytically predicts two phenomena: worse than chance generalization for hard functions and non-monotonic error curves in a small data regime. It also provides some simulations to corroborate the analytic results.",0.14035087719298245,0.2601626016260163,0.18233618233618235
109,SP:0b31a46fda77a01e02a6a94c52381af4aa759743,"This paper considers the effect of label noise on stochastic gradient descent. The setup is that there is a vector $v \in R^d$. We observe samples from $v^2\cdot x$. We only have $n < d$ samples but $v$ is $r$-sparse for $r < n < d$ which makes recovery possible information theoretically. The main result is that stochastic gradient descent with label noise, and without any explicit regularization will recover the ground truth. whereas adding spherical Gaussian noise does not.",This paper considers the implicit regularization of stochastic gradient decent (SGD). The authors analyze SGD with label nose in the quadratically-parameterized model and prove that it converges to the sparse ground-truth even if started with large initialization. The authors also prove that SGD with Gaussian noise (Langevin dynamics) does not converge to the ground truth at zero under the overparameterized regime.,0.2222222222222222,0.2857142857142857,0.25
110,SP:0b3653c04024ddae217d91fdf4bec5f3a1250453,"The paper proposes stochastic prototype embeddings (SPE) for few-shot learning. The method is an extension of Prototypical Networks (PN, [1]) with Gaussian embeddings. The idea is to take representation uncertainty into account when classifying objects which makes the model more robust to input and label noise. The authors propose an efficient sampling algorithm to train SPE which outperforms naive Monte Carlo sampling. They conduct a range of experiments on few-shot learning tasks on a synthetic dataset, Omniglot and N-digit MNIST and compare to Prototypical Networks and previous stochastic embedding state-of-the-art method HIB [3]; SPE was shown to outperform prior work in most settings. The authors also plot interpretable disentangled representations learned in 2D embedding space. ","By extending prototypical networks, this paper proposes a probabilistic model, i.e., stochastic prototype embedding, that treats embeddings as random variables. The model is very straightforward and easy to understand. The authors make a few assumptions to simplify the problem. For example, the distance between every instance $z_i$ of class $y$ and the class embedding $\rho_y$ follows a Gaussian distribution, and the a softmax prediction for a query embedding also follows a Gaussian distribution. Combining these, the authors give the class posterior for the query. Since the class posterior involves an integral, the paper employs a naive samplying and an intersection sampling. The intersection sampling seems a bit interesting in the sense that the sampler focuses on the intersection of the input distribution and the class distribution and it is more sample-efficient.",0.17355371900826447,0.15555555555555556,0.1640625
111,SP:0b4c5468fbb7f0caaf2645c6d5c0a2159aec311d,"In this paper, the authors proposed to utilize variational lower bound of mutual information for learning representations in Reinforcement learning. To optimize the proposed variational lower bound with a more flexible encoding network, the author proposed to utilize stein variational gradient descent (or amortized svgd). Instead of learning the representation separately, the authors incorporate the framework into PPO or A2C, which yields a joint training framework for policy optimization.","This paper proposes a representation learning algorithm for RL based on the Information Bottleneck (IB) principle. This formulation leads to the observed state X being mapped to a latent variable Z ~ P(Z | X), in such a way that the standard loss function in actor-critic RL methods is augmented with a term minimizing the mutual information between X and Z (which can be seen as a form of regularization). This results in a loss that is difficult to optimize directly in the general case: the authors thus propose to approximate it through a variational bound, using Stein variational gradient descent (SVGD) for optimization, which is based on sampling multiple Z_i’s for a given state X, so as to compute an approximate gradient for the parameters of the function mapping X to Z. Experiments show that when augmenting the A2C algorithm with this technique, (1) the mutual information I(X, Z) decreases more quickly (better « compression » of the information), and (2) better sample efficiency is observed on 5 Atari games (with also encouraging results with PPO on 3 Atari games).",0.3188405797101449,0.12087912087912088,0.1752988047808765
112,SP:0b81356b614ae533e975718f34af62efcf7a7bb9,"The paper studies the convergence of Monte Carlo Exploring Starts (MCES), in which the Q-function is estimated by averaging Monte Carlo returns and the policy is defined as the greedy policy w.r.t. this Q-function. The authors provide a technically simple proof of the convergence under different assumptions on the underlying MDP: (i) stochastic feed-forward MDP (in which states cannot be re-visited in an episode); (ii) optimal policy feed-forward (in which under the optimal policy states are not re-visited); (iii) finite-horizon MDPs. Given these additional assumptions, the analysis relaxes other assumptions employed in previous convergence proofs. Finally, experimental results to validate the considered set of assumptions is provided.","This paper studies Monte Carlo with exploration starts algorithm for solving the reinforcement learning problem. The writing is clear and I enjoyed reading this paper. As for the results, asymptotic convergence of the algorithm is established without needing strong assumptions in related literature. As pointed out by the authors, the result resolves an important open problem in RL. The proof is simple and intuitive. Numerical experiments corroborate theoretical findings.",0.16379310344827586,0.2753623188405797,0.20540540540540542
113,SP:0b92f455d4643fb63c1d5885558545674bf120ee,"This paper proposes MQES, a Max-Q entropy search for policy optimization in continuous RL. The authors propose to combine advantages of the information-theoretic principle and distributional RL, in which epistemic and aleatoric uncertainty are estimated using similar entropy-search acquisition functions in the Bayesian Optimization (BO). As said, this is a new method to introduce a more efficient exploration strategy. As a result, policy improvement is formulated as a constraint optimization problem where a next exploration policy can be solved in a closed-form. The proposed method is evaluated on Mujoco tasks and compared against other off-policy approaches, SAC, and DSAC. The results show MQES outperforms other methods in domains where exploration is needed.","This work introduces max-Q Entropy Search (MQES) exploration principle  for continuous RL algorithms. MQES addresses the exploration-exploitation dilemma that constitutes a fundamental RL problem. Actually, MQES defines an exploration policy able to explore optimistically and avoid over-exploration. One of the main advantages of MQES is its ability to recognise the epistemic and aleatoric uncertainty. Empirical analysis has been conducted on Mujoco, showing that the performance of MQES is comparable to  those of other state-of-the-art algorithms.",0.18803418803418803,0.2716049382716049,0.2222222222222222
114,SP:0b9ca8ea62df97ffbdae1028e156966f82edd366,"The paper proposed a novel simulation based testing procedure for conditional independence: X\perp Y | Z. The testing procedure incorporate the techniques of GAN, which is especially useful for dealing with high-dimensional data. The testing procedure first learn the generative adversarial network that is able to simulate the conditional distribution of X|Z and Y|Z and check a particular kernel-based independence criteria presented in Eq.(4). Instead of kernel-based method that takes the supreme over a class of RKHS functions, the proposed testing procedure searches the maximum ""discrepancy"" over a class of neural network function by simulation. Empirical results show a well controlled type-I error and better test power performances compare to existing methods and a cancer data application is discussed.","This paper considers the problem of conditional independence testing, especially when the variables are high-dimensional. The authors proposed a double GAN based algorithm. Two GANs are designed to learn the conditional probability distributions P_{X|Z} and P_{Y|Z}, then used to generate samples to compute the test statistic. It is proved that the error of the test statistic is O_p(n^{-2k} \log n) when the total variation error of the GANS is O(n^{-k}). So to ensure that the test statistic converges, only o(\log^{-1/2} n) rate is required for the total variation error of the GANs.",0.19047619047619047,0.22857142857142856,0.2077922077922078
115,SP:0bc330ce227c2df862d82847ba8a57e822c0aeb7,"This paper focuses on the anomaly detection of continuous-time event sequences with temporal point processes and proposes to leverage the idea of goodness-of-fit testing to check whether sequences follow the in-distribution. Consider the limitation that the current statistics are not sensitive to the event number N, this paper proposes a new statistic called sum-of-squared-spacings (3S) to check the fitness of the sequence. The experimental results show the effectiveness of the proposed statistic for anomaly detection.","This paper addresses an anomaly detection problem for event sequences as temporal point process (TPP), where they formalize the problem as out-of-distribution (OoD) detection in a batch scenario. The authors proposed using goodness-of-fit (GoF) statistics to determine whether a sequence is OoD or not, which provides vast options for this purpose to us than an ordinary OoD procedure just using log-likelihood. They make it possible to use GoF statistics designed for known standard Poisson process by using Neural TPP fitted to training sequences. We can convert a random event sequence distributed according to an arbitrary TPP into a realization of the standard Poisson process with a compensator derived from the fitted Neural TPP. They also propose a sum-of-squared-spacings (3S) statistic that can detect anomalies w.r.t. the event count N, which is difficult to detect by Kolmogorov–Smirnov (KS) statistic, as well as anomalies w.r.t. the distribution of the arrivals or inter-event times. Experimental results demonstrate that the proposed statistic performs better than either other statistics or log-likelihood-based OoD.",0.4024390243902439,0.18032786885245902,0.24905660377358493
116,SP:0bd5556d83764d1445a07e46ea5fcd074789b6e0,"This paper introduces a deep learning-based adaptation for the RLVSI algorithm, where the agent uses the representation learned by the deep neural network-based RL agent (DQN). They use the last layer of DQN as a state representation for RLSVI.  In order to work with the changing representations of the deep agent, they propose a likelihood matching mechanism. The approach is applied to two tasks: a) A toy modified n-chain experiment and b) set of 5 Atari games. They show that their method outperforms the DQN with naive exploration. ","The paper proposes to extend the popular linear-control algorithm, RLSVI, to utilize learned representations. This is done by adapting a work from bandit literature that utilizes BLR with representations that are learned via a DNN. The proposed solution is then compared to DQN with fixed epsilon as the exploration strategy in a chain MDP, and to the Rainbow agent and DQN in 5 selected Atari games to show sample-efficiency improvements.",0.21978021978021978,0.2777777777777778,0.245398773006135
117,SP:0bdb98fe98774d51720fc496211dad5fb54b2999,"This paper claims to apply two Transformer variants to a data-driven operator learning problem, where the mappings between infinite-dimensional spaces of functions are learned. However, this paper only discusses the uniform grid problem setting, which can be regarded as 0D/1D/2D time series forecasting problem. After applying an interpolation-based CNN network (CiNN) to get $n_c \times n_c \times d$ features, the authors use their proposed Fourier or Galerkin Transformer variants to encode the features and use another CiNN as a decoding regressor. Compared to the previous work FNO, the novelty of the paper comes from using Transformers to encode features instead of applying convolutions by FFT/iFFT. However, the use of Transformers makes the proposed method hard to conduct a zero-shot super-resolution prediction, which can be regarded as the merit of the neural PDE solvers. ","In this paper, they propose a general operator learner based on a simple attention mechanism to remove the softmax operation in standard scaled dot product attention. which is regarded as a PDE-related operator. They also introduce a new scale-preserving layer normalization module to better support their operator learning. Combing with  Fourier Neural Operator, the proposed model obtains great performance on some benchmarks with superior memory and time efficiency.",0.09090909090909091,0.18571428571428572,0.12206572769953052
118,SP:0bdb9aa34e57b33cc411fd2f5ae54623c9ac0159,"In this paper, the author proposes RNNLogic for learning FOL rules from the knowledge graph. The proposed method assigns embeddings for each relation type and uses RNN module to generate chain-like rule candidates. Candidates are evaluated with a separate evaluation module that computes the scores. The rule scores are then taken to update the generator module using EM.","There is a lot of recent work on link-prediction in knowledge graphs. One approach is based on embedding entities and relations in a knowledge graph into vector spaces, and the other is based on finding rules that imply relations, and then using these rules to find new links or facts. This paper takes the latter approach. Within the area of rule-based methods, a number of recent papers have used neural network methods to simultaneously generate rules and to find rule-weights or other related parameters (indicating how important individual rules are). Simultaneously solving for rules and rule-weights is a difficult task. In this paper, the authors propose a method where they separate the rule generation process from the weight/parameter calculation process. More importantly, they add a feedback loop from the weight calculation routine (""reasoning predictor"") to the rule generation routine (""rule generator""), which in my opinion is novel, even though there have been a few recent attempts (Xiong et. al. 2017) to use reinforcement learning to search for rules. The rule generator in this paper uses a recurrent neural network (RNN) and the parameters of this RNN are modified by the reasoning predictor. In other words, the iterative process has the feature that new rule generation is influenced by the calculated weights of previously generated rules. The authors perform numerical experiments on 4 standard knowledge graphs to demonstrate the performance of their method",0.3050847457627119,0.0759493670886076,0.12162162162162163
119,SP:0c0df2e874c35381bda95487f3278aea4ae0922f,"This paper is motivated by that most existing text-to-image methods suffer from three limitations and solutions are proposed to address the different limitations.  Firstly, it introduces multi-tailed word-level initial generation to enhance global sentence representation with distinct n-gram word presentation.   Second, the spatial dynamic memory module is proposed to create a separate region-contextualized text representation for each image region.   Finally, it introduces an iterative multi-headed mechanism to make multiple distinct modifications to the prior image features.","The paper proposed a new method to tackle text-to-image generation challenge. In the paper, authors introduced a potential problem that current methods only use sentence embedding at beginning of the network to generate initial images, where different attributes may be entangled and are hard to be refined during following states. Based on this, authors proposed three components to address this limitation.",0.12048192771084337,0.15873015873015872,0.136986301369863
120,SP:0c4124acde5770c92f5afb3a0f12d2f70eead48d,This paper aims to take insight from human language acquisition and the importance of empathic connection to learn better models for emergent language. The authors propose an approach to introduce the notion of empathy to multi-agent deep RL by extending existing approaches on referential games with an auxiliary task for the speaker to predict the listener’s empathy/mind. Experiments show that this gives some improvement with faster convergence.,"This paper takes the reference-game setup of Lazaridou et al. (2018), as a means of enabling emergent communication, and adds an auxiliary task to demonstrate that this helps with language emergence. The auxiliary task is to enable the speaker to predict the hidden state of the listener, after the message has been received. This is (not unreasonably) likened to providing the speaker with some empathy, in that it enables the speaker to try and predict what the effect of the message will be on the listener.",0.2571428571428571,0.20689655172413793,0.22929936305732485
121,SP:0c654d1ec408359642e987d4e84a445fbd2d41fb,"This paper proposes a false classification detection method. The proposed method first trains an autoencoder using uncorrupted data to obtain a decoder to define a generative model. The generative model is then exploited for quantifying the uncertainty of the model. Using MGVI, the generative model infers the posterior distribution of the corresponding latent vector for each data. The latent space can explain the model uncertainty, which can be measured by the Mahalanobis distance. From experiments, it is shown that the proposed method can detect corrupted data more accurately compared to MC dropout and EDL for MNIST dataset.  ","This paper presents a method that simultaneously classifies corrupted data and quantifies uncertainty, despite the model being fitted only on uncorrupted data. The idea is to fit a semi-supervised autoencoder. Then, the encoded representation $h$ is fed into a decoder $g$, and the output $g(h)$ is augmented with various perturbations (additive noise, blur, and masking), resulting in a corrupted image $d$. Lastly, the method of MGVI is used to estimate $P(h \mid d)$, which is then used both to classify $d$ and to estimate the uncertainty. In experiments, the authors show the advantage of this method over baseline methods. ",0.20618556701030927,0.19607843137254902,0.20100502512562812
122,SP:0c6c9db564f0029c12c1a1e16373970eeeb800d4,"This paper introduces a novel method for an adversarial attack named mixup inference (MI).  Most of the work focuses on embedding mixup mechanism in the training phase, but MI uses the mixup in the inference phase. MI method has two main effects for the adversarial attack: one is perturbation shrinkage, and the other one is input transfer because MI can exploit","This paper proposes a novel use of mixup, which is originally a data augmentation method incorporating two training samples and their corresponding labels. The authors utilize mixup not for training but for inference (MI; Mixup Inference). Experimental results on Cifar 10, and Cifar 100 show that MI can boost the classification performance in combination with interpolated AT (Adversarial  Training) and mixup.",0.26229508196721313,0.26229508196721313,0.26229508196721313
123,SP:0c710260fb97364904bda22065ae07915a850b1b,"The paper proposes to modify the ""Dual Learning"" approach to supervised (and unsupervised) translation problems by making use of additional pretrained mappings for both directions (i.e. primal and dual). These pre-trained mappings (""agents"") generate targets from the primal to the dual domain, which need to be mapped back to the original input. It is shown that having >=1 additional agents improves training of the BLEU score in standard MT and unsupervised MT tasks. The method is also applied to unsupervised image-to-image ""translation"" tasks.","The authors propose an extension of dual learning (DL). In DL, one leverages the duality of a dataset, by predicting both forward and backward, e.g. English to German, and German back to English. It’s been shown that training models using this duality is beneficial. This paper extends DL by introducing multiple models for the forward and backward, and using their output to regularise the training of the two main agents.",0.1839080459770115,0.2222222222222222,0.2012578616352201
124,SP:0c846c2c569a61b5677f5852a5c6bcfba1944d51,"The paper proposes a nonuniform sampling design scheme chosen using training data to reduce the computation of compressed sensing acquisition. The use of learning methods such as back propagation for the nonuniform sampling design problem is interesting. However, compressive sensing approaches in practice do not perform computation to obtain the measurement vector; instead, the sensors rely on custom hardware (such as the single pixel camera or the modulated wideband converter) to have the hardware act on the discretized signal according to the matrix design. Thus, considerations of the ""sensing complexity"" are moot in those cases, and the approach provided in this paper is only relevant in cases where custom sampling schemes can be designed (e.g., when the referred imaging sensors are used).","The paper proposes a framework for jointly optimizing a selective sensing operator and a neural network for reconstruction. The motivation is to alleviate the quadratic (in dimensions) complexity associated with standard compressive sensing by using a dimension-free selective sensing approach, which can be jointly optimized with the decoder while guaranteeing that the relevant information is preserved. As this formulation yields a mixed discrete-continuous optimization, the authors propose a standard relaxation of the discrete constraints using interpolation. ",0.13008130081300814,0.20512820512820512,0.1592039800995025
125,SP:0caffdb2e566a7b43ac5fdfd8f70fca2ba66d2a8,"The paper discusses the inductive biases in generative models that tend to assign higher likelihoods to ""less complex"" images. In particular, a likelihood based generative model (like Glow or PixelCNN++) trained on a particular dataset has significantly higher likelihood for data that have lower compression ratios (e.g  with PNG). The authors propose a simple approach based on the likelihood ratio between a trained model and a ""prior"" model (based on existing compression methods) and demonstrate that this improves unsupervised OOD detection on certain dataset pairs. The idea is quite simple (and surprising it seems to work!), but it seems that better understanding of the proposed method could be achieved.","This paper analyzes the peculiar case that deep generative models often assign a higher likelihood to other datasets than they were trained on. The running hypothesis here is, that input complexity plays a central role. Measuring a proxy for input complexity shows that it is tightly anticorrelated with likelihood and therefore seems to describe the trend well. A new OOD detection score is introduced based on these insights.",0.17272727272727273,0.27941176470588236,0.21348314606741572
126,SP:0cfa52672cf34ffafece1171e48d6c344645dcf3,"Training and deployment of DRL models is expensive. Quantization has proven useful in supervised learning, however it is yet to be tested thoroughly in DRL. This paper investigates whether quantization can be applied in DRL towards better resource usage (compute, energy) without harming the model quality. Both quantization-aware training (via fake quantization) and post-training quantization is investigated. The work demonstrates that policies can be reduced to 6-8 bits without quality loss. The paper indicates that quantization can indeed lower resource consumption without quality decline in realistic DRL tasks and for various algorithms.","This paper investigates the impact of using a reduced precision (i.e., quantization) in different deep reinforcement learning (DRL) algorithms. It shows that overall, reducing the precision of the neural network in DRL algorithms from 32 bits to 16 or 8 bits doesn't have much effect on the quality of the learned policy. It also shows how this quantization leads to a reduced memory cost and faster training and inference times.",0.15789473684210525,0.20833333333333334,0.17964071856287425
127,SP:0d10eeb943cf56da483878662ceeb5c6ec09df2c,"This paper is an extension of the Contextual Graph Markov Model, a deep unsupervised probabilistic approach for modeling graph data. The key idea is to leverage Hierarchical Dirichlet Processes, which enables the proposed approach to automatically choose the size of each layer’s latent representation. The authors conduct experiment on graph classification tasks, and the results are quite promising. ","In this paper, the authors propose a mechanism to automate the size selection of each latent representation layer of the Contextual Graph Markov model. The model automatically adjusts the size of the model parameters mitigating the expensive model selection. Moreover, the authors introduce some techniques to scale the  proposed solution.",0.2711864406779661,0.32,0.29357798165137616
128,SP:0d7b31f997fb88fad3c01a6d7e74e1f8227b02b0,"This paper proposes a method for unpaired image-to-image translation, where the target domain explicitly contains some additional information than the source domain. The authors use auto-encoders to separate the common and specific representations and to generate masks, which seems to be related to [1]. The authors empirically show the proposed method can be used for image translation, attribute editing.","This work proposed a mask based approach for instance-level unsupervised content transfer, which is an extension of the disentanglement work in (Press et al., 2019) and the attention guided translation (Chen et al., 2018, Mejjati et al., 2018). Unlike the disentanglement work, the introduced mask allows the adaptation to focus on the relevant content which substantially reduce the complexity of the generation. On the other hand, the proposed method extends the attention guided translation from the domain level to the instance level which allows more specific and diverse translations. Experiments on benchmark data shows both improved qualitative and quantitative results comparing to existing methods. It is really nice that the authors also considered the situation of generalization to out of domain images.",0.24193548387096775,0.12195121951219512,0.16216216216216214
129,SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695,"This paper presents a RNN-RL based method for the symbolic regression problem. The problem is new (to Deep RL) and interesting. My main concern is about the proposed method, where the three RL related equations (not numbered) at page 5 are also direct copy-from-textbook policy gradient equations without specific adaptation to the new application considered in this paper, which is very strange. The two conditional probability definitions considered at page 3 are not mentioned in later text. These are only fractions of the underlying method and by reading the paper back and forth several times, it is not clear of the basic algorithmic flowchart, let alone more detailed description of the related parameters. Without these information, it is impossible to have a fair judge of the novelty and feasibility of the proposed method. The empirical results are also limited in small dataset, which makes it hard to verify the generality of the superior claim.","This paper presents deep symbolic regression (DSR), which uses a recurrent neural network to learn a distribution over mathematical expressions and uses policy gradient to train the RNN for generating desired expressions given a set of points. The RNN model is used to sample expressions from the learned distribution, which are then instantiated into corresponding trees and evaluated on a dataset. The fitness on the dataset is used as the reward to train the RNN using policy gradient. In comparison to GP, the presented DSR approach recovers exact symbolic expressions in majority of the benchmarks.",0.1592356687898089,0.2631578947368421,0.19841269841269837
130,SP:0d9e9fe6ec0465324c838ffc4174b29f6f2f0d82,"In this paper the authors propose optimizing for adversarial examples against black box models by considering minimizing the distance to the decision boundary.  They show that because this gives real valued feedback, the optimizer is able to find closer adversarial examples with fewer queries.  This would be heavily dependent on the model structure (with more complex decision boundaries likely being harder to optimize) but they show empirically in 4 models that this method works well.","This paper addresses black-box classifier attacks in the “hard-label” setting, meaning that the only information the attacker has access to is single top-1 label predictions. Relative to even the standard black-box setting where the attacker has access to the per-class logits or probabilities, this setting is difficult as it makes the optimization landscape non-smooth. The proposed approach reformulates the optimization problem such that the outer-loop optimizes the direction using approximate gradients, and the inner-loop estimates the distance to the nearest attack in a given direction. The results show that the proposed approach successfully finds both untargeted and targeted adversarial examples for classifiers of various image datasets (including ImageNet), usually with substantially better query-efficiency and better final results (lower distance and/or higher success rate) than competing methods.",0.2,0.11029411764705882,0.14218009478672985
131,SP:0da601e4f94d2853b05ff6361ad387cc61b293a7,"The paper proposes a new approach based on Tweedie's formula to perform self-supervised image denoising. The proposed approach has two steps: (1) learn the score function or gradient of density of the noisy images, and (2) use Tweedie's formula to compute a denoised image using the learned score function. The proposed approach builds on multiple relevant work in the literature, and is well motivated. The model is tested on Gaussian, Poisson and Gamma noise removal tasks on natural images and achieves competitive results. ","This paper considers the problem of image denoising using deep learning. Traditionally, deep denoisers are trained in a supervised way using pairs of noisy and ground-truth images. Recent methods, such as Noise2Noise and those based on SURE, are used to train deep denoisers without ground truth.  This paper proposes Noise2Score as an alternative to existing methods. The idea of Noise2Score is to pre-train a denoising autoencoder (DAE) and use it as an estimator of the score function within the Tweedie’s formula. The key observation is that the pre-training stage of DAE doesn't explicitly need to know the true noise statistics. On other hand, the Tweedie’s formula enables the adaptation of the DAE to specific noise statistics.  The main conceptual contribution of the paper is that it establishes a formal link between the usage of DAEs for approximating score functions and image denoising. The empirical results show the competitive performance of Noise2Score against several well known image denoising methods, including Noise2Noise and SURE.",0.2558139534883721,0.13095238095238096,0.17322834645669294
132,SP:0de748131383ac3425179fa9b34e7593c25fd8bd,"This paper proposes a method to generate molecular graphs with multiple optimized properties. Molecular graphs are constructed/edited by the iterative addition and removal of molecular fragments. A MCMC search procedure, guided by a learned graph neural network that proposes good graph edit actions, is used to sample molecules with optimized properties. The proposed model is compared with some baselines on a few multi-objective optimization tasks and shows good performance.","The authors propose a novel way to generate molecules with specified objectives, named MArkov moleculaR Sampling (MARS). The idea of MARS is based on generating the chemical candidates by iterative editing fragments of molecular graphs. To transform a molecule x into another molecule x′, the authors considers two sets of graph editing actions fragment adding and fragment deleting, where fragments are connected components in molecules separated by single bonds. To generate the molecules with desired objectives, MARS is using Markov chain Monte Carlo sampling with specified annealing scheme, together with graph convolutional neural network. The results reported in the following paper are very promising and show that this could be a good direction in the area of multi-objective molecules optimization.",0.29577464788732394,0.17355371900826447,0.21875
133,SP:0e00204408c0655e6f5a5c5823a0df36fe72b871,"This paper proposes DeepTLF, a new framework for prediction tasks using tabular data. DeepTLF first trains gradient boosted decision trees (GBDT) using the entire tabular training samples. Then it uses node values as the input the neural network predictor (e.g. classifier or regressor) for the actual prediction phase. In essence, the authors rely on GBDT's capability to handle heterogeneous tabular data with potentially many missing values to derive a binary representation of the given sample, and feed that representation to a downstream neural network. DeepTLF was able to demonstrate superior performance in real-world tabular datasets.","For the problem of learning (supervised classification and regression) on tabular data, the authors propose to used the decision functions of tree based ensemble methods as input features for a deep neural network (DNN). Tabular data is typically heterogenous, that is the data come from different modalities (continuous, categorical, missing values). As decision trees are very well tailored to such data the authors show that with their method (DeepTLF) no further preprocessing or data cleansing is necessary (apart from what's being performed in the decision tree). On numerous experiments on 7 public tabular datasets, they show that their method outperforms different baseline and competitive approaches, thereby supporting the claim that the tree based input features preserve sufficiently rich information of the input data. ",0.19387755102040816,0.1532258064516129,0.1711711711711712
134,SP:0e0cd81235620120d8704263c96e625b58b7d0ac,"Quality: The paper proposed a new method to learn some physics prior in an environment along with a new SpatialNetwork Architecture. Instead of learning a specific dynamics model, they propose to learn a dynamics model that is action-free, purely learning the extrinsic dynamics.  They formulate this problem as a video prediction problem. A series of experiments are conducted on PhysWorld (a new physics based simulator) and a subset of Atari games.","A method for learning physics priors is proposed for faster learning and better transfer learning. The key idea in learning physics priors using spatial net, which is similar to a convolutional LSTM model for making predictions. Authors propose to improve the sample efficiency of Deep RL algorithms, by augmenting PPO’s state input with 3 future frames predicted by the physics prior model. ",0.16666666666666666,0.19047619047619047,0.17777777777777778
135,SP:0e1607f0f226624429ad959c1f1ee2960fc7de53,"This paper proposed an optimized version of depth separable convolution. Optimal separable convolution reduces the model size by replacing both depth-wise and point-wise convolution with group convolution. Furthermore, they allow overlapped channel between group convolution and this was swept to show ablation comparisons. The authors showed that the combination of group convolution methods outperformed the previous ones when the volumetric receptive field (RF) conditions were met.","The convolution operator is the fundamental unit of most modern DNNs. This paper summarizes the existing (efficient) convolution operators and formulates an optimization problem to choose a few important parameters for the convolution. The authors show that their convolution under certain constraints requires fewer parameters and operations compared to the commonly used operators. They evaluate their proposed operator on CIFAR10, CIFAR100, and on ImageNet.",0.16176470588235295,0.171875,0.16666666666666669
136,SP:0eb1faf1d1b44c5c80745824ae303ee086eae8a4,"Model performance inference is a key challenge in neural architecture search. This paper introduces GradSign, an accurate, simple, and flexible metric for model performance inference. GradSign approximately analyzes the optimization landscape of different networks at the granularity of individual training samples using the gradients evaluated at a random initialization state. Experimental results show that GradSign can generalize well to real-world networks and outperform state-of-the-art gradient-based methods for model performance inference.","This work discusses the problem of neural architecture search. While existing gradient methods are based on heuristics, this work proposes a metric called Gradsign for model performance inference, which provides some theoretical guarantees and performs well in practise.   Authors compare gradsign to a number of state of the art methods using 3 benchmarks involving CIFAR10, CIFAR100, and ImageNet16-120 datasets. Gradsign shows better performance compared to these methods. ",0.22666666666666666,0.25,0.23776223776223773
137,SP:0ec9a162aba8bbd0d7d0eb165271c07877ac6452,"The paper presents a method for estimating causal effects (or more generally non/parametric functions) under conditional moment restrictions, focusing in this case on nonparametric IVs. The main idea is casting these conditional restrictions to an unconditional version through importance resampling using a conditional density estimator (e.g. based on a least-squares method with a NN). The paper also provides a theoretical analysis of the estimation error, providing am error bound (Thm1). The method is evaluated based on three econometrics datasets from literature, showing a smaller MSE than the compared methods.","The present paper proposes an importance weighting approach to address the issue of regression under conditional moment restrictions in the context of non-parametric instrumental variables. The authors provide error bounds on the learned structural function. They show that their approach has a convergence rate of $\mathcal{O}(1/\sqrt{n})$. The main contributions of this work are presented in Sections 4 and 5, where they first introduce their method based on re-weighting by an estimated conditional density ratio function and then provide an estimation error analysis. The theoretical results are complemented with two synthetic experiments which show that the proposed method can compete with and in certain cases improves upon state of the art.",0.1956521739130435,0.15517241379310345,0.17307692307692307
138,SP:0edafd92d3e0c42274852ec5c726e65cc79b0931,"To tackle situations where compositionality is mostly required at inference time, the paper proposes a novel data augmentation method with an RNN based generator (recombination); to make the generator generate highly compositional patterns, the paper proposes a resampling method. The methods have been tested on two benchmarks focusing on the issue, SCAN and morphological analysis. The system performs on par with recently proposed GECA for SCAN and favorably to GECA on morphological analysis. ","This paper presents a prototype-based method for data augmentation based on a generative model without rule/template based requirements. The generative model creates new input-output pairs from training fragments (recombination: rewrite model conditioned on multiple examples), and samples in low-density places (rare words) of the training data (resampling). Empirical results show that the in combination recombination and resampling perform on par with a recently introduced rule-based method, GECA.",0.2054794520547945,0.20833333333333334,0.20689655172413793
139,SP:0edea0200b34d109c964bc9b15e5a4dac5578515,The authors consider approximation and learning by deep neural networks in the setting with an infinite dimensional input space. They provide nice rates for approximating and learning functions with mixed or anisotropic smoothness. The networks studied in the paper include fully connected ReLU networks and those generated by linear convolutional layers followed by a fully connected layer. ,"The paper studies non-parametric regression for functions defined on infinite-dimensional input data (such as signals in $\ell^2$), using fully-connected networks or dilated convolutional networks (in the CNN case, convolutional layers are followed by a fully-connected network). The authors consider certain smoothness classes similar to mixed or anisotropic smoothness but extended to infinite-dimensional input data, which requires per-coordinate smoothness orders ($a_i$ in Definition 2) that are non-decreasing or increasing with some rate. For such classes, the authors obtain rates that only depend on $a_1$ for the mixed smoothness case, or $\sum_i a_i^{-1}$ for the anisotropic case, for the ERM under certain classes of FNNs or CNNs. Notably, CNNs avoid the need to selecting specific finite subsets of variables as inputs (needed by FNNs), and dilated CNNs additionally allow some adaptivity to sparsity in the $a_i$, in particular, by avoiding dependence on the specific order of the $a_i$ (the growth condition is on the sorted values instead of the unsorted ones for the non-dilated case with a single convolutional layer).",0.3157894736842105,0.09782608695652174,0.14937759336099588
140,SP:0f030ce39a4263996a15486f1914f7ffb7718040," The authors extensively analyze the training of Restricted Boltzmann Machines (RBMs). They show that there is definite room for improvement in training RBMs in terms of  - *Evaluation:* The authors show that despite its popularity, log likelihood is not the only metric which should be tracked while training the RBM and show that bad machines can have a deceptively good log likelihood but not be able to generate good samples and vice versa. - *Methods:* Despite their popularity, both CD-k and PCD-k can be outperformed in terms of the quality of generated samples by Rdm-k which uses chains started at uniformly sampled states to compute the negative statistics  Moreover they empirically show that for Rdm-k, smaller values of k lead to models which memorize data (Figure 2A $\Delta S$) and a larger k leads to generalization (likelihood of generated samples is close to that of the data) (Figure 2A $\mathcal{L}$).","The paper discusses about some important factors affecting the results of RBMs.  1. The choice of mixing time.  2. The mixing time and the number of steps(k) affect two regimes of RBMs, namely equilibrium and out-of-equilibrium.  3. How to choose the number of steps(k). (A) short k for convincing samples in short learning times (B) large k for learning the correct equilibrium distribution of the RBM.",0.12418300653594772,0.2714285714285714,0.17040358744394618
141,SP:0f0d7119df7043ccea815c96e8896114210290f0,"This paper proposes a new constraint for constrained MDP, based on k-shortest path, which helps improve sample efficiency for (model-free) RL algorithms in sparse-reward MDP, while theoretically proving that the constraint retains the same optimal policy in the original MDP. Intuitively, for sparse (positive) reward setting, the optimal policy should reach the positive reward states with the shortest path (as it has the lowest discounting). The relaxed form of the constraint considers the that the distance between two states is less than $k$, rather than being optimal length (which the optimal policy still also satisfies). The constraint is then converted into its Lagrangian form as a cost term to the reward (i.e. a type of reward shaping). Practically, this requires a k-reachability network (RNet), which is a binary distance discriminator judging whether the distance between two states are reachable within $k$ steps. This network is trained with contrastive loss, similar to prior work SPTM by Savinov et al., 2018. However, SPTM uses RNet for graph-based planning (i.e. the local distance between states), while this paper uses RNet as the cost/constraint on the policy objective function. Experiments were conducted in several maze navigation environments (2D grid world MiniGrid, to first person 3D maze environments in DeepMind Lab), showing promising results compared to several baselines which use intrinsic curiosity. Several ablations were performed on the hyperparameters ($k$, and tolerance $\delta t$ on the constraint), as well as some qualitative examples of the policies learned compared to novelty reward shaping.","This paper proposes the k-Shortest-Path (k-SP) constraint to restrict the agent’s trajectory to avoid redundant exploration and thus improves sample efficiency in sparse-reward MDPs. Specifically, k-SP constraint is applied to a trajectory rolled out by a policy where all of its sub-path of length k is required to be a shortest-path under the π-distance metric. Instead of a hard constraint, a cost function-based formulation is proposed to implement the constraint. The method can improve the sample efficiency in sparse reward tasks and also preserve the optimality of given MDP. Numerical results in the paper also demonstrate the effectiveness of k-SP compared with existing methods on two domains (1) Mini-Grid and (2) DeepMind Lab in sparse reward settings.",0.13333333333333333,0.265625,0.17754569190600522
142,SP:0f0e048d70d90c7b55524e88954e71efb168cee9,"The paper proposes an interpretable architecture for image classification based on a scattering transform and sparse dictionary learning approach. The scattering transform acts as a pre-trained interpretable feature extractor that does not require data. A sparse dictionary on top of this representation (the scattering coefficients) is learnt to minimize the classification error. The authors cast the dictionary learning as a classical CNN learning approach and implement an efficient solution via homotopy learning (given that some assumptions are fulfilled). The scattering transform approach is not new (as the authors mention in the paper, it was published in Oyallon et al., 2019). The main novelty comes from applying a previously published dictionary learning approach (as the authors mention in the paper, it was published in Jiao et al., 2017) on top to boost the performance. As a second contribution, the authors extend the exponential convergence proof of ISTC (Jiao et al., 2017) and ALISTA (Liu et al., 2019). In the experiments, they show that the proposed architecture, despite its simplicity, outperform AlexNet in the ImageNet classification problem.","The paper proposes a network architecture composed of three interpretable components followed by a simple MLP classifier. It first applies a scattering transform followed by a learned linear projection (to reduce dimensionality). A sparse representation of these coefficients is then obtained using dictionary learning. The projection, dictionary and MLP classifier are jointly trained to minimize the classification loss. Results show that the model outperforms AlexNet on the Imagenet benchmark.",0.14204545454545456,0.36231884057971014,0.20408163265306126
143,SP:0f44e739c4536b6b955b11f47a2d16b2326926ce,"The authors study the role of the biologically realistic divisive normalization computation in the context of deep learning models trained to perform image classification tasks. The authors compare divisive normalization (scaling neuronal response by exponentially weighted sum of its neighbors) with those normalization techniques commonly used in machine learning models (such as batch normalization, layer normalization etc) and find that their implementation of divisive normalization provides improved image recognition performance. The authors perform a range of analyses to representationally understand why divisive normalization provides the above-mentioned increase in classification accuracy.","The authors study the effect of divisive normalization on AlexNet. They show that, when combined with standard normalization schemes, it increases performance. They also investigate the filter shapes, manifold capacity and (adversarial) robustness of the learned representations.  Following the authors' response I have increased my score form 5 to 6.",0.15384615384615385,0.28,0.19858156028368795
144,SP:0f566a0c7fbad17455e65c8befd25b317f67e177,"In this paper, the authors introduce a region-based approach for unsupervised scene decomposition. It extends the previous MONet by introducing the region-based self-supervised training. Instead of purely generating foreground masks in an RNN, they simultaneously predict the bounding boxes and segmentation masks using a Faster-RCNN-based framework. The supervision comes from the object reconstruction loss and the self-supervised loss of classification and regression of anchors in the RPN module. The experiments and comparisons are only conducted on the synthetic CLEVR and Multi-dSprites dataset. ",This paper presents a variation of the MONet model where an additional Region Proposal Network generates bounding boxes for various objects in the scene. An additional loss is introduced during training to make the segmentations produced by the MONet segmenter consistent with the proposed bounding boxes. Results are demonstrated on multi d-Sprites and CLEVR with modest performance gains.,0.1797752808988764,0.2711864406779661,0.21621621621621623
145,SP:0f655731e050572011b5ac4f394d725e1b35fc56,"This paper proposes Generative Adversarial MDP Alignment (GAMA) for imitation learning. Given a set of paired MDPs, GAMA learns a state mapping f and an action mapping g such that one MDP can be reduced to another. For a new test MDP pair (x,y) where expert demonstrations are available for y, GAMA can use f to map a state of x to a state of y, mimic the expert behavior, then use g to map the expert action back to an action in x. The reduction is theoretically motivated, the optimization is based on adversarial learning and finally, experiments on common Gym environments show that GAMA can achieve effective transfer.","The paper proposes a learning approach for zero-shot imitation learning in an RL setting across domains with different embodiments and viewpoint mismatch. The proposed approach involves two steps, alignment and adaptation. In contrast to previous work, the alignment between domains, represented as MDPs, is learned from unpaired, unaligned samples from both domains. The paper presents a theoretical formulation of the cross-domain imitation learning problem, and presents an algorithm for training alignment and adaptation from data. ",0.11711711711711711,0.16883116883116883,0.13829787234042554
146,SP:0f69223447458f0a0a6248e4b79c1628dabbbe47,"This paper introduces KS-GNN, Keywords Search GNN over Incomplete Graphs. More specifically, KS-GNN employs joint training on autoencoder (dimension deduction), keyword-based node similarity in subgraphs, and keyword frequency regularization to facilitate a complex keyword search task on incomplete graphs (missing keywords in node attributes and edges). Experimental results have proven the effectiveness of the proposed KS-GNN over multiple baseline approaches compared to various standard benchmarks.","This paper addressed an important problem that can answer queries in graph where some information is missing(edges and nodes). The proposed solution is based on auto-encoder and GNN. Here, the auto-encoder learns a low dimensional embedding for the node which was used to compute the score top-N ranked candidates based on similarity scores. Their method shows results better than other methods in the experiments. ",0.13043478260869565,0.1323529411764706,0.1313868613138686
147,SP:0fa4963f1d57d48a6271fe726358d204b1e286e8,"This paper theoretically studies the benefits of representation learning in linear bandit problems. The key assumption is the existence of a common linear feature extractor. Two different setting are studied. In the finite-action setting, the authors provide the MLinGreedy algorithm that achieves matching upper and lower bounds (up to polylog factors). In the infinite-action setting, the authors provide the $E^2TC$ algorithm that can achieve lower regret than the naive method when the number of tasks is large. Experiments on both synthetic and real-world data are conducted, which confirm the theoretical results.","This paper studies the benefits of learning a low-rank feature extractor in multi-task linear bandits. Specifically, the paper studies the setting where an unknown common linear feature extractor $B \in R^{d \times k}$ maps the original $d$-dimensional contexts $x$ to a $k$-dimensional representation. Essentially, for multi-task linear bandit problem $r_t = \theta_t^T x$, this paper assumes the matrix of model parameters $\Theta \in R^{d\times T}$ is low-rank and be factorized as $\Theta = BW$ with rank k. The paper proposed algorithms to estimate both $B$ and $W$ in finite actions setting and infinite actions setting. In finite action setting, the proposed solution is a greedy algorithm while in infinite actions setting, the proposed solution is a explore-the-commit method. Theoretical result shows that the regret is $O(T\sqrt{kN} + \sqrt{dkTN})$ and matches the lower bound. Simulation result shows that the algorithm outperforms baselines running independent linear bandit algorithms. ",0.3368421052631579,0.19875776397515527,0.25
148,SP:0fa59beb93e339dc3612719931b206653916b8b5,"This paper proposes a novel model integrating both causal inference and structure-aware counterfactual training to enhance the long-tail performances of information extraction. The causal mechanism considers a structured causal model that takes into account all possible cause-effect relations for the final predictions, including contexts, target representations, POS tags, NERs, etc. They also implement counterfactual training strategy by selecting the most important factors and wipe off the side effects to enhance the long-tail situations.","The novelty of the paper seems to be in application of the counterfactual analysis to address the long-tailed IE issues, which might be interesting to the IE researchers. Overall, more theory about the counterfactual generation for IE task should be added, for this is what the novelty of the paper; also, for the rebalancing learning for slide effect and counterfactual, the theory appears to be not enough. The weak of this work is the theoretical and conceptual underpinnings of the proposed methodology. ",0.18181818181818182,0.1686746987951807,0.175
149,SP:0fa6e1dfa434bfef4c0071572e60dbafa0d65d4e,"1.	In the introduction, the author separately pointed out the issues of DUQ and DKL. However, these issues are not convincing as no citations or theoretical proof is provided in this paper. The notations in the intro are also not well-defined. X, x, x* are used without difference, which however should be clearly defined as vectors or matrices.","This paper proposes variational deterministic uncertainty quantification (vDUQ), which adopts the stochastic (sparse) variational deep kernel learning (DKL) method to enable uncertainty estimations for deep models. To avoid uncertainty collapse, the deep neural network in the GP kernel is regularized with spectral normalization, which ensures a bi-Lipschitz constraint. Experiments show that vDUQ is effective in uncertainty quantification tasks.",0.1016949152542373,0.1016949152542373,0.10169491525423731
150,SP:0fd58ad8e49120d88bdf5fe2b7c0b6cf8d11b789,"This paper proposes to combine the continuous optimization-based causal discovery approach from notears with flow-based function learning. An extension is given to data missing (completely) at random. Also, a unifying framework is presented facilitating the comparison and exchange of ideas between different continuous optimization-based causal discovery methods, viewing all in terms of flows.","This paper proposes a general flow-based approach to learn DAGs from data which provides a unified view of existing continuous optimization methods for structure learning. As a side benefit, the authors demonstrate that the proposed method could naturally be modified to handle missing data. The authors provide empirical studies to show that their proposed method outperforms the other baselines.",0.21428571428571427,0.2,0.20689655172413796
151,SP:0fdb3d5169a5c900e3bc0c496d656c5d3395c710,"This paper investigates different choices of designing the planning model which predict the next state on the observation space. The paper compares (1) prediction with deterministic or stochastic models, (2) using 1-step forward prediction loss or multi-step forward prediction loss to train the model, (3) prediction with single network or network ensemble, and (4) using perfect observation or add gaussian noise to the observation.  Through the above experiments, the paper suggests that deterministic models should be trained with multi-step loss, while stochastic models work better when the 1-step log-likelihood loss is used and noise is added to the observation space. In both cases, ensemble networks tend to show better performance. ","This work ablates some of the design choices that go into learning a dynamics model for control-based environments. They ablate 4 choices: use of deterministic vs. stochastic models, multistep losses, network ensembles, and input noise. The authors study this in a few of the DeepMind control suite environments.",0.10434782608695652,0.24489795918367346,0.14634146341463414
152,SP:1009c2803013c67812574a32d8e31a0061f61a3d,"This work gives an indepth analysis to the sufficient conditions on the generalization of invariant risk minimization (IRM) in classification setting. Authors show that in order to guarantee good generalization, the support overlap condition of invariant features is required. Further, authors also show and validated that if the support overlap condition does not satisfied for spurious features, the combination of IRM objective and information bottleneck regularization (i.e., minimzing the mutual information $I(X; \Phi(X))$) is a reliable remedy.  ","This paper investigates the conditions that are needed to provably generalize OOD in the linear classification tasks. Comparing with the linear regression tasks, linear classification tasks need more strong conditions to guarantee the OOD generalization.   The paper first proposes the overlap assumptions on both invariant and spurious feature and analyze the OOD generalization guarantee under these assumptions. The theorem shows that only both two types of features satisfy the support overlap assumption can we expect the IRM to solve the OOD generalization problems. Then the paper study the possibility of solving the problem only with the support overlap assumption on the invariant features. The proposed method uses both information bottleneck and invariance constraints. Theoretical results show that the proposed IB-IRM can successfully solve the problem in both fully and partially informative invariant features situations. The experiment results are consistent with the theoretical results. ",0.275,0.1527777777777778,0.19642857142857142
153,SP:100cf7f4d36ee8e916f222d3b0fffd619b8ec78e,"The paper studies the problem of adversarial examples generation. The authors phrase the following problem: given a set of models  C, we want to find an adversarial perturbation that maximizes the loss on an ensemble of models. However, the ensemble weights are chosen by the learner. In the case that we have one example, this is equivalent to asking that the same adversarial perturbation (or distribution over perturbations) fools all the individual models in my collection. This is a reasonable phrasing of the problem, though it seems different from versions studied in literature. In particular, previous works used uniform ensembles.","This paper is concerned with the problem of finding adversarial examples for an ensemble of classifiers. This is formulated as the task of finding noise vectors that can be added to a set of examples in such a way that, for each example, the best ensemble element performs as badly as possible (i.e. it’s a maximin problem).",0.16,0.2711864406779661,0.20125786163522016
154,SP:102f337fcdb0455ef7da2fe20f8684cb61a54314,"Gradient Descent and related variants are the defacto standard algorithms for optimizing empirical risk functions. Since published models have been shown in the literature to leak private information, the problem of performing gradient descent under privacy constraints is an important one. Given a fixed privacy budget R, private gradient descent adds noise to the gradients at each round, ensuring overall privacy budget R by composition. However, this still leaves the question of what privacy schedule is best open, since any schedule whose privacy budgets sum up to R achieves the privacy objective. In this paper they compute the optimal privacy schedule from an accuracy perspective via a novel analysis of the convergence of private gradient descent on loss functions that satisfy the PL condition, which turns out to be exponentially decaying noise (increasing privacy budget for each round). These results extend to a privatized variant of the momentum-based gradient descent algorithm, although the dynamic privacy schedule has less improvement there. Experimental results show that dynamic privacy schedules lead to enhanced accuracy even absent convexity. ","The paper studies private gradient descent when the noise added to each of the iteration is dynamically scheduled. Prior to this work, the work of Zhou et al. tries to achieve the same for DP-SGD and they analyze their algorithm for many variants of adaptive gradient descent based method. The difference with Zhou et al. is that they do not gradient norm and the generalization property of DP. As a result, the authors claim that Zhou et al. achieves suboptimal utility guarantee. ",0.12571428571428572,0.26506024096385544,0.17054263565891475
155,SP:10438f48109affe9343f5de1f022dbfe23742cc6,"The paper builds upon prior work on MLPs with ReLU activations that leverage the insight that ReLUs are either linear or zero to formulate a MILP to solve the problem of _exact compression_, i.e., the process of reducing neurons in the networks while exactly preserving the output of the network for the input domain. The compression hinges on the insight that if a ReLU neuron is always activated it becomes an affine function while if it's always inactive it's simple zero and does not contribute to the output.  Their main contribution over prior work is a simple, but elegant insight on the problem formulation for the MILP that avoids solving the MILP exactly for each neuron in the network and instead solving it approximately at most N times (N = # neurons) while simplifying the problem (i.e. removing decision variables pertaining to neurons that are not stable) at each step so that only during the final call the MILP has to be solved exactly. The resulting exact compression problem thus has significantly reduced runtime compared to prior work leading to the ability to scale to larger networks (up to 2x800 or 5x100 in their experiments compared to 2x100 in prior work).","This work proposes a modified Mixed-integer linear programming (MILP) to compress a feed-forward deep neural network. The proposed algorithm seems to be work if some of the network neurons are stable. The authors evaluated the algorithm with several small datasets (MNIST, CIFAR-10, and CIFAR-100). ",0.07389162561576355,0.3125,0.11952191235059761
156,SP:1043d665e76e18b5418a66868d36575363717444,"The paper suggests using PHATE, a modern dimensionality reduction method, for visualizing the training trajectories of deep networks. It argues that PHATE visualizations can bring to light interesting aspects of the training dynamics that are missed by other dimensionality reduction algorithms because PHATE does a better job at preserving both local and global structure in the data. This is not the first application of PHATE in the context of deep learning, but to my knowledge it is the first application to deep learning trajectories.","This paper uses PHATE to visualize the progression of neural net parameters during learning in neural networks to provide insight into generalizable vs. non-generalizable minima, and the behaviors of different optimization algorithms.  PHATE is an improvement over previous visualization techniques due to its approach to finding a manifold, allowing it to plot in two dimensions multiple trajectories that do not otherwise share a plane.  This is then used to plot trajectories in ""jump and retrain"" experiments, in which a minimum is found, and then perturbations made to the network parameters, before restarting training.  It is shown that in the networks experimented on, minima with good test set performance reliably funnel the new learning trajectories into the same minimum, while minima with poor test set performance see the perturbed initializations find other minima, thus demonstrating the ""flatness vs sharpness"" of minima.  Trajectories produced by SGD, SGD with momentum, and Adam are also compared.  Adam is shown to travel further, but along a smoother trajectory.",0.23809523809523808,0.12195121951219512,0.16129032258064516
157,SP:10461f5707fe6a701045ed1c3a96c22ceb858960,"The paper addresses the problem of sample-efficient inference for symbolic physical rules. In the literature, there exists neural-network based models for learning a physical engine which have good predictive accuracy but poor sample efficiency, as well as symbolic models which are highly sensitive to deviations from their fixed physics engine. To be able to overcome issues as such, authors propose a generative model along with a symbolic regression framework, in which forces are produced from a probabilistic context free grammar that is designed to mimic simple Newtonian physics. This particular grammar is parameterized by a few latent variables related to unobserved properties of the physical environment, such as mass and charge. Finally, they develop an Expectation-Maximization algorithm, in order for estimating these latent variables as well as inferring the underlying physical laws of the system.","The paper proposes an Bayesian-symbolic physics (BSP), an intuitive physics model that jointly infers symbolic force laws and object properties (mass, friction coefficient). The inductive bias is force summation, F=ma, and a grammar of force laws to express object interactions. The inference is done via an EM method that alternates between object property estimation (E-step) and force law induction (M-step), using techniques like symbolic regression and Hamiltonian Monte Carlo (HMC). Some preliminary experiments are shown for the method's effectiveness and data efficiency. ",0.09420289855072464,0.14942528735632185,0.11555555555555555
158,SP:105266467c5692d681190e94f26a01f6cf0705ee,"The paper describes a limited memory quasi-Newton method based on SR1 updating using a variant on the adaptive regularized cubic (ARC) approach to globalization.  The algorithm is applied to training deep neural networks for image classification and autoencoding, and compared to L-BFGS and various SGD variants.  The authors claim the main contributions to be the different optimizer ingredients (L-SR1, ARC safeguarding, and the particular shape-changing regularizer) as well as computational complexity similar to L-BFGS.","This paper investigates the application of a certain Quasi-Newton algorithm, the Limited-Memory Symmetric Rank-1 (L-SR1) algorithm, in deep learning problems. The benefit of this technique over similar more widely investigated methods that use a positive definite approximation of the Hessian, such as stochastic L-BFGS, is the fact that the L-SR1 approximation is not guaranteed to be definite, and thus has the potential to have a more accurate approximation of the true Hessian. Since in this case line-search methods may return ascent directions, authors propose a specific form of Adaptive Regularization using Cubics (ARC) as an alternative. Numerical simulations are provided comparing the performance of the proposed algorithm to SGD, adaptive methods such as Adam and a naive L-BFGS implementation.",0.24050632911392406,0.14960629921259844,0.18446601941747576
159,SP:10884b56b4745dacc61afa80933661fd3786a4cc,"In this paper, the authors introduce ClimateGAN, a framework for the generation of images of flooded scenarios in order to raise climate change awareness and prompt action. In particular, the authors consider the realistic case of scarcity of training data and propose and unsupervised approach. An evaluation of each ClimateGAN components is performed, both quantitative (through metrics) and qualitative (through human feedback). ClimateGAN is also compared against other generative modeling frameworks. ","This paper proposes to generate images of floods, that is, simulate photo-realistic floods, with a model named ClimateGAN, which consists of a Masker to generate masks for floods and a Painter to draw floods on images. The proposed ClimateGAN is a two-stage solution for generating flood masks on input images and painting the images with floods respectively, and each stage (Masker and Painter) is designed based on many popular related techniques, like DADA for depth-aware semantic segmentation, SPADE for injecting extra information into cGANs, and WGAN as well as TV, BCE and EM losses. For training ClimateGAN, this work also collects a real dataset with street-level floods and generates a simulated dataset using Unity3D. The outputs of Masker and Painter are evaluated separately compared to several previous image-to-image translation methods, also the ablation study is conducted to validate the effectiveness of each component in ClimateGAN.",0.22535211267605634,0.10596026490066225,0.14414414414414414
160,SP:109fe1cb9ca66cf3798027270177016092554ad8,This paper proposed a novel neural network backbone architecture for 3D point cloud processing that focuses on reducing the repeated computation inside the grouped neighborhood. The author proposed a nice technique to decompose the learning of the relative 3D coordinate values and the learning of features from previous layers so that the majority of repetitive computation can be saved. The experiments are done on several classification and segmentation benchmarks.,"In this paper, the authors present PointNetV3, which is a faster and more accurate version of PointNet++.  The authors first analyze the latency bottleneck of PointNet++ and find that computation takes up to 70% of total latency, and then propose to reduce the computation cost via several techniques. Namely, separate SA modules are used to reduce the computation cost of vanilla SA (since MLP after reduction is much more efficient); Anisotropic reduction is applied to achieve higher accuracy (original PointNet++ shares conv. weights for all neighbors, which is suboptimal). The authors also analyze the effectiveness of width and depth scaling to improve the efficiency-accuracy tradeoff of PointNetV3 models. Experiment results on S3DIS, ModelNet40 and ShapeNet Part are impressive.",0.2318840579710145,0.13445378151260504,0.1702127659574468
161,SP:10a07fea63ed49543987705eaaa7dfae231de545,"This paper introduces a novel GAN training method, named InsGen. This work effectively overcomes the performance degradation problem of GAN training with a small amount of the train dataset. The main idea is to train a discriminator by assigning an instance discrimination task as well as a bi-classification task (e.g. real or fake). The experimental results show that, with the smaller amount of data used, the synthesized image quality of InsGen outperforms the images from SOTA methods. ","This paper propose to add instance discrimination (aka contrastive learning) objective for training generative adversarial networks. Specifically, (a) instance discrimination among real samples & (b) instance discrimination among fake samples are used as two axillary objectives. In addition, noise perturbation whereby the method uses z & z+epsilon to create two views needed for contrastive learning. (conventional contrastive learning uses 2 different augmentations of an image to create 2 views). Experimental results show that the proposed method InsGen outperforms prior methods that use data augmentations for training image GANs.",0.21518987341772153,0.19540229885057472,0.20481927710843373
162,SP:10c1db18ba9a4ee43ab04f5d2fab030c6e8aecb3,"The authors frame the bivariate causal discovery problem in terms of the analysis of a dynamical-system. They use results from the field of optimal transport to interpret additive noise models from this framework. They also develop a novel criterion and a causal discovery algorithm based thereupon, and compare their results with previous methods used in bivariate causal discovery.","The paper tackles the problem of causal discovery in the basic case where a pair of variables is considered. In particular, it is concerned with Functional Causal Models and how to establlish the causal direction for a pair of continuous variables. It motivates the contibution by poiting out thet the performance of availabel algorithms is sensitive to the model assumptions, which makes it difficult for practitioners to use them in real settings. Then, the main contibution is a novel dynamical-system view of Functional Causal Models which aims to identify the causal direction in the case of pairs of variables. The paper exploits connection between functional causal models and optimal transport. Then, the paper studies the problem of optimal transport by taking into account the constraint originating from the considered functional causal model.",0.288135593220339,0.12781954887218044,0.17708333333333331
163,SP:10d0f62a5d727e263760bd8f775c2a5479477ccc,"The paper proposes using structured matrices, specifically circulant and diagonal matrices, to speed up computation and reduce memory requirements in NNs. The idea has been previously explored by a number of papers, as described in the introduction and related work.  The main contribution of the paper is to do some theoretical analysis, which is interesting but of uncertain impact.","In this paper, the authors prove that bounded width diagonal-circulant ReLU networks (I will call them DC-ReLU henceforth) are universal approximators (this was shown previously without the bounded width condition). They also show that bounded width and small depth DC-ReLUs can approximate deep ReLU nets with row rank parameters matrices. This explains the observed success of such networks. The authors also provide experiments to demonstrate the compression one can achieve without sacrificing accuracy.",0.15254237288135594,0.11842105263157894,0.13333333333333333
164,SP:10eb3473230595eec1d5056bdc904d1852f791a0,"This paper considers MCTS with learned search guidance, as in AlphaZero, MuZero, etc. The work proposes several adjustments to the prior works, particularly regarding the way in which actions are selected at the root and non-root nodes, at training and during evaluation; and also the way in which the policy is updated after search. In a simplified bandits setting, the authors point out that the previous method of performing policy updates is not guaranteed to result in a policy improvement, and they propose using a Gumbel reparameterization trick to overcome this limitation. Experiments in Go, Chess, and Atari show that the adjustments are beneficial in the regime of low simulation count.","The paper proposes a number of principled algorithmic modifications to state-of-the-art planning algorithms (AlphaZero, MuZero) for improving performance in settings with many actions and a relatively small computation and / or sample budget. The main contributions are algorithmic and empirical. The key ideas include the use of the Gumbel-max and top-k tricks along with the use of sequential halving to improve online planning. The paper also proposes a planning-learning loop wherein a policy using the estimated (completed) Q values is learned as well as a different selection policy at non-root nodes. The experiments show that the Gumbel variants of AlphaZero and MuZero perform well in low search budget settings in the domains of Go, Chess and Atari.",0.23214285714285715,0.21138211382113822,0.2212765957446809
165,SP:10eba7b266e4d1443975f23593beae81e49a5051,This paper proposes a modification of the Independent Learners trust region policy optimization method in general sum games. The modification consists of first forming a “meta game”—ie. the matrix game in which each agent’s options are his previous policy and his independent trust region optimized policy—-and then interpolating between the two for each agent according to a Nash equilibrium of the meta game. The paper shows that this algorithm results in each step generating a “weak stable fixed point”. The paper concludes by showing a number of experimental results indicating the convergence and overall performance of the method as compared with relevant baselines in a number of different games.,This paper presents a new trust-region method for multi-agent reinforcement learning (MARL). This approach extends ideas from single-agent trust-region methods to construct a smaller meta-game representing possible policy changes for each agent. The meta-game can then be solve to provide policy updates for the agents. Theory is provided for the meta-game (and corresponding restricted underlying game) and experimental results are shown with a number of baselines. ,0.21428571428571427,0.3287671232876712,0.2594594594594595
166,SP:10ed123c525d3bfe20ef1682e8b97bff162cfd1b,"The paper presents two user studies to quantify the impact of explanations on Human-AI teaming. The first study experiments with varying cobot (AI) policies to understand how well humans can create a mental model and situational awareness. Results from this study show that explanations can assist mental model creation. The second study instead also explores how human expertise and ability impacts this process. Results from this study show that for novice users there is a clear benefit from XAI but for expert users such benefits degrade due to the extra cost that humans have to pay to process the AI/XAI information.  The formalization of situational awareness in 3 levels (perception, comprehension, projection) is interesting and potentially reusable for other RL applications.   Results are clearly presented and sufficient information is included for clarity and reproducibility.","This paper presents a study on the effect of two types of interpretable/explainable model in human-machine teaming. By varying the type of explanation (showing the model for human intention recognition used by the robot and showing the robot's action-selection model), the authors conclude that showing both models increased participants' situation awareness, but that only the human intention recognition model decreased the overall task completion time. For 'expert' participants, the performance degraded with ",0.125,0.2236842105263158,0.16037735849056603
167,SP:110494ad2fb7ac26180ed3199b538e34285fa565,"This paper defines a new setting generalizing existing work on establishing _data minimization_ as motivated by the GDPR. Unlike previous work, this work considers testing for data minimization in a black-box setting (previous work assumes access to model internals). Within this setting, the data minimization problem is defined according to a measure of model instability when certain features are replaced by constant imputation (as is often done for missing values in data preprocessing). Further, the problem of auditing a model for data minimization at a certain level (according to a metric the paper introduces) is framed as a pair of near-dual bandit problems: one which establishes the optimal auditing strategy to achieve a certain confidence that the metric is not violated, and another which assigns a fixed query budget in an expected-optimal way.","The authors explore means for the blackbox auditing predictive models in line with data minimisation concerns. The key focus is on the role of particular features, i.e. whether they are necessary for the model or not.   Towards this, the paper describes an instability-based data minimisation metric, based on various feature imputations, as well as a probabilistic measure of uncertainty (termed a data minimisation guarantee).   Given imputations can be expensive (require many queries), approaches considering query-budgets are described, where bandit frameworks are used for considering the greatest data minimisation level satisfied given a fixed query-budget, and whether a particular level of minimisation is satisfied using the minimum number of queries.   The approach and efficiencies of the query budget are demonstrated across three real-world datasets.",0.16911764705882354,0.1796875,0.17424242424242425
168,SP:111b19c01327c2eb1211e8ce7861378e76a64877,"This paper proposes ANT to solve the problem of learning Sparse embeddings instead of dense counterparts for tasks like Text Classification, Language Modeling and Recommendation Systems. When the vocabulary size |V| runs into several 100Ks or millions, it is impractical to store one dense vector per label. Hence the paper proposes to only store a few anchor/latent vectors (the matrix is A with |A|<<|V|). All label vectors are expressed as linear combinations of a 'few' anchor vectors. To train this end-to-end, we need a transformation matrix T such that T*A = E (E is V\times d embedding matrix). T has to be structured, i.e., each row of T has to be sparse and positive only (although negative weights are also fine, I'm not sure if weight redundancy is that important). ","In this paper, the authors proposed a method to learn efficient representations of discrete tokens. They took a two step approach: in step 1, they learn ""full fledged"" embeddings for a subset of anchor tokens. In step 2, they learn a sparse matrix that is used to relate all tokens to the set of chosen anchors. This two-step approach reduced the overall number of parameters. The sparse matrix T can also encode domain knowledge (e.g. knowledge graphs). In the experiment section, the authors showed that their approach has good performance on several language tasks, with far fewer parameters.",0.13138686131386862,0.18,0.1518987341772152
169,SP:1164e721c240bb98c36386b627d10626a63c1f94,"The authors proposed an interesting method for zero-shot learning. In particular, the authors adopted an attention mechanism from the input feature in the semantic to visual mapping, to introduce intra-class variations in the visual space. They also propose a process to synthesize ""fake"" class representations such that a classifier for unseen classes can be trained.  Combining these two the authors demonstrated significant results on benchmark zero-shot learning datasets.","The paper proposes a framework for the GZSL using the meta-learning and attention mechanism. The image-guided attention on the semantic space helps to adapt the better class specific semantic information. The modified semantic space projected to the visual space and in the visual space, cosine similarity is measured. The paper learns separate expert for the seen and unseen classes. The unseen class expert is trained with the pseudo negative samples with pseudo negative labels. Meta-learning based training helps to learn the model when only a few examples per class are available.",0.28169014084507044,0.2127659574468085,0.24242424242424243
170,SP:11684e08a288b62b3952baf4c8bf385be83b858d,"This paper proposes to enable GAN based TTS in the time domain with the careful designs of the (non-autoregressive) generator and discriminator. There have been various trials of GAN-TTS but not so many success and I'm glad to hear that the proposed method seems to enable GAN-TTS with fast inference thanks to the non-autoregressive property. The method also proposes new objective measures inspired by the image recognition network based on the high-level features generated by end-to-end ASR, which is also another important contribution of this paper. ","I want thank the authors for solving this long-standing GAN challenge in raw waveform synthesis. With all due respect, previous GAN trials for audio synthesis are inspiring, but their audio qualities are far away from the state-of-the-art results. Although the speech fidelity of GAN-TTS is still worse than WaveNet and Parallel WaveNet from the posted sample, it has begun to close the significant performance gap that has existed between autoregressive models and GANs for raw audios. Overall, this is a very good paper with significant contributions to the filed.",0.18085106382978725,0.18085106382978725,0.18085106382978725
171,SP:11763efc3e362e7b3a565f2c85e9eb1a03afda8f,"This paper overall presents a model that defines the multi-person activities using logic expressions and uses neural logic models to generate recognitions and predictions over events. Specifically, the model follows the neural logic machines (Dong et al.) to define the operations in the networks. Authors demonstrate their model under two tasks, trajectory-based soccer event detection, and robot object manipulation event understanding. Using their self-generated datasets from simulators, the authors found that their model performs better than other baselines.","This paper proposes TOQ-Nets which is a structured neural network that learns to describe complex activities over entities and time. The model leverages relational reasoning layers which are the Neural Logic Machines (NLM) to capture the spatial information. To further capture the temporal information, this paper proposes temporal reasoning layers.The results show that their method outperforms conventional graph neural networks with high accuracy and generalization with a large margin.",0.2222222222222222,0.2535211267605634,0.23684210526315788
172,SP:119ec5a7b1bc981afd4d248e4643a0f0b3d49c3c,"A method is proposed, which learns to reason on physical interactions of different objects (solids like cuboids, tetrahedrons etc.). Traditionally in related work the goal is to predict/forecast future observations, correctly predicting (and thus learning) physics. This is also the case in this paper, but the authors explicitly state that the target is to evaluate the learned model on downstream tasks requiring a physical understanding of the modelled environment.","The paper presents a platform for predicting images of objects interacting with each other under the effect of gravitational forces. Given an image describing the initial arrangement of the objects in a scene, the proposed architecture first detects the objects and encode them using a perception module. A physics module then predicts the final arrangement of the object after moving under the effects of gravity. A rendering module takes as input the predicted final positions of objects and returns an image. The proposed architecture is trained by using pixel labels only, by reducing the gaps between the predicted rendered images and the images returned by the MuJuCo physics engine. This error's gradient is back-propagated to the physics and perception modules. The proposed platform is also used for planning object placements by sampling a large number of object shapes, orientations and colors, predicting the final configurations, and selecting initial placements that lead to final configurations that are as close as possible to given goal configurations using the L2 norm in the VGG features. Experiments performed in a simple blocks world show that the proposed approach is not only useful for prediction, but can also be used for planning object placements.",0.24285714285714285,0.0845771144278607,0.12546125461254615
173,SP:11a15c3a8b83e911ab4ce1193871b468656a63ac,This paper focuses on polymer retro synthesis problem. This is a novel problem and is very challenging because of the very small amounts of training data available (<100). They use reaction templates collected from small molecule reactions and formulate polymer retrosynthesis as a constrained optimization problem. The authors claim that this is the first learning method that takes constraints in polymer retrosynthesis problem.,"This paper proposes a method for the retrosynthesis prediction of polymers. A challenge in this problem is the lack of synthetic data for polymers. The method attempts to leverage models for small molecule retrosynthesis predictions (where there is more abundant data), as well as domain specific constraints derived from the chemistry of a particular class of polymerization reactions. The method is shown to outperform some baselines that are commonly used in small molecule retrosynthesis.",0.2857142857142857,0.24324324324324326,0.2627737226277372
174,SP:11a1972c3e8ea1c2dda4776b0d751fd47300ae29,"The present paper proposes an alternative to imputation or list-wise deletion in the context of neural networks and incomplete features. Missing values are replaced by a data-specific numerical representation that is learned at the same time as the rest of the network. The handling of the missing values is located in the neurons of the first layer and each missing value is ""replaced"" by a neuron-specific neutralizer in its activation function. They empirically show that their approach is comparable to several imputation techniques. In a clinical application they show that their model becomes indecisive as the amount of missingness (in terms of missing features) increases, which is a potentially interesting feature for clinical prediction models.","In this paper, the authors propose a method titled PROMISSING; this provides a new approach to handling missing data. Rather than imputation, a complete-case analysis, or inverse probability weighting, among other methods, the authors advocate for learning a problem-specific numerical representation for unknowns. The approach is interesting, and the experiments and data analyses are a good start at understanding the method.",0.1271186440677966,0.23809523809523808,0.16574585635359115
175,SP:11a4f15893b32b9391d04a507bed8528a130f533,"The authors of this manuscript proposed a generative dynamics system for the modelling and generation of 3D conformations of molecules. Specifically, there are three components: (1) conditional graph continuous flow (CGCF) to transform random noise to distances,  (2)a closed-form distribution p(R|d, G), and (3) an energy-based tilting model (ETM) to capture long-range interactions and correct the position matrix distribution. The proposed framework was compared with two deep learning methods for conformation generations -- CVGAE & GraphDG, as well as the computational chemistry tool RDKit on GEOM-QM9, GEOM-Drugs, and ISO17 data sets. Comparisons in terms of COV and MAT scores show that the proposed method (particularly the one enhanced with ETM) can outperform baselines. Further comparisons of distances densities show that CGCF (but without ETM) worked best over baselines. ","This paper presents an approach to generate diverse small molecule conformations given its graph by combining a conditional flow-based model with an energy-based model. Sampling is performed in two separate stages: 1) a normalizing flow produces a distribution over interatomic distances (which is then postprocessed into cartesian coordinates), 2) sampled coordinates are refined by Langevin dynamics with gradient signal produced from an energy-based model. The models are trained separately.",0.08208955223880597,0.1527777777777778,0.10679611650485438
176,SP:11a82dec01285aa5bb80e1e320c41eed36c27a91,"This paper demonstrates that a left-to-right language model suffers a high entropy rate when generating a long-term sequence of words. Then the authors claim that this is because of entropy rate amplification, which could be mitigated by 'calibration'. With local entropy rate calibration, a language model could achieve lower perplexity generating shorter and concise sequences of words.","This paper highlights and studies the problem of ""entropy rate drift"" for language models: the entropy rate of the language generated by a trained model is much higher than the entropy of ground truth sequences and this discrepancy worsen with the length of generation. The authors interestingly claim that the well-known lack of coherence in long-term model generations is due to this entropy rate drift. Valuably, the entropy rate drift is characterized mathematically. The authors propose a calibration method and prove that their method can interestingly reduce *both* the entropy rate drift and the perplexity of a miscalibrated model, *even though* they assume a rather simplistic model of miscalibration (one that leaks a small amount of mass to all the sequences of a given length). The author quantitatively show that their calibration method reduces the entropy rate drift and qualitatively show that their generations ""make sense"" in the long-term. As an auxiliary result, they show that a similar calibration method can be used to quantify the past information used by the model by upper-bounding the mutual information between the current prediction and the long-term past, given the short-term past, e.g. I(W_t | W<{t-\tau} | W_{t-\tau:t-1}).",0.35,0.10096153846153846,0.15671641791044777
177,SP:11ab8f635d8d593fe0187875679a36257360bf66,"This work presents a method to efficiently sample from a pre-trained DDPM by solving a dynamic programming problem that can maximize the log likelihood of the data samples given a fixed computational budget. This is done by defining a least-cost path problem to select a reduced set of time steps among a full grid of potential time steps across different possible step budget sizes, where the ELBO is used as the cost function. The authors show that their method can identify DDPM schedules that can achieve significantly higher log likelihood (i.e. lower bits/dim) than prior DDPM schedules in the regime where about a hundred steps or fewer are used.","Samples are generated from DDPMs by solving an SDE (often in ""discrete time"", which is used to refer to specifically the Euler--Maruyama discretisation). This necessitates a choice for where to make numerical steps. Each choice of step locations has a corresponding ELBO. This paper demonstrates that (on a pretrained model) the optimal ELBO may be obtained via a dynamic programming algorithm for the location of the steps.",0.13274336283185842,0.22058823529411764,0.16574585635359118
178,SP:11e711f93423bcab7a9bad9c9bfd969519b09eb2,"This paper is on building binary network. The steps for building binary network takes several components: traditional strategy to binary/optimize a model (like data augmentation,  binary initialization using 2-stage optimization, etc), real-to-binary attention matching that tries to match the output of real values and binarized model, and data-driven channel rescaling to better approximate real convolutions. All these components together makes a strong binary network.",This paper studies the problem of training binary neural networks. The authors first provide a strong baseline by assembling a group of training techniques that appeared in recent work that achieves state-of-the-art performance. Then the authors proposed two methods to further boost the performance gain. The first method is to use a teacher-student mechanism that uses a fully real-valued network to teach a binary network. The process is divided into three stages involving two intermediate models to reduce the gap within each teacher-student pair. The second method is to learn a re-scale factor for binary activations using real-valued activations from the previous block. Experiments show that the proposed methods improves the performance on ImageNet and CIFAR-100.,0.2028985507246377,0.112,0.1443298969072165
179,SP:11f0323635f0647b3407ac61faad5b149754b06c,"The authors propose a so called data matrix that is induced in the input space of a deep neural network classifier. This matrix is similar to the Fisher-Rao metric, but for the input and not the parameters of the model. The analysis of this matrix shows that the classifier induces in the input space a specific structure, which the authors study. Constructive experiments are used in order to empirically verify the claims.","In this work, the authors showed that deep ReLU networks can model the low dimensional manifold structure of the dataset. The authors first define a local data matrix G which is analogous to Fisher matrix. Then they proved that the tangent space of the data manifold is spanned by the eigen vectors of G corresponding to non-zero eigen values. The authors visualize this data manifold on MNIST data. ",0.2328767123287671,0.2463768115942029,0.23943661971830985
180,SP:120a40819527a564d4d1f66b2d138f849e44ed26,"The paper proposes and analyses a distributed learning algorithm for training with Stochastic Gradient Descent a global model on a regular graph, that allows for local and asynchronous gradient updates. Nodes continuously update their local models $X^i$ by gradient descent, while they communicate with their peers (a peer at a time) and update their local model with the pair model average $\frac{X^i + X^j}{2}$. Three extensions of the algorithm are also proposed to relax different constraints, while maintaining the convergence guarantees:","This paper combines the existing scaling techniques to reduce the communication cost of distributed SGD among a large number of computing nodes. These techniques include asynchronous, decentralized, or quantized communication. The authors prove that this combined algorithm converges to a local optimal point. In the experiments, this algorithm also successfully converges and scales for big data. The authors claim that this is the first work to consider decentralization, local updates, asynchrony, and quantization in conjunction. ",0.11764705882352941,0.13333333333333333,0.125
181,SP:120ee3d5236a4194fc1318fef1c3f54d2065ffbc,"In this paper, the authors consider model personalisation as an important aspect of federated learning. Based on an impossibility result, the authors are motivated to learn a mixture model $p(y|x)=\sum_m^M\pi_m p(y|x, \theta_m)$ as opposed to a single mapping $p(y|x,\theta)$. As opposed to standard FedAvg approaches, the mixture weights $\pi_m$ are local, i.e. specific to each client $t$.  The authors propose an EM-type algorithm for learning the parameters $\theta_m$ and $\pi_{m,t}$ in a federated environment, coining their algorithm FedEM. Furthermore they propose a decentralised variant of FedEM.  The authors show convergence proofs under appropriate assumptions and show that FedEM and D-FedEM are special cases of  more general federated surrogate optimization.  == after rebuttal ==  I have read the rebuttal and raised my score accordingly",The authors propose a new approach for personalized federated learning (PFL) by formulating PFL as multi-task learning (MTL). by assuming that each local data distribution is a mixture of unknown underlying distributions the model aims to learn a linear combination of clients' models based on their data distribution.  The authors claim the following contributions: -  Showing that federated learning (FL) is impossible without assumptions on local data distributions - Proposing FedEM and D-FedEM an expectation-maximization (EM) based approaches for PFL - The proposed methods achieve better accuracy and generalize better than SOTA PFL methods.    ,0.14184397163120568,0.2127659574468085,0.17021276595744683
182,SP:121b6641093615ae9740da48399381c9ce68092e,"In this paper, the authors recognized the function of unique relevance (UR) of features for optimal feature selection and augmented the existing mutual information based feature selection (MIBFS) methods by boosting unique relevance (BUR). As a result, they proposed a new criterion called MRwMR-BUR. Experimental results are provided to show that MIBFS with UR consistently outperform their unboosted conterparts in terms of peak accuracy and number of features required. ","This work suggests improving mutual informaton based feature selection methods with an extra term (i.e., the unique relevance (UR)), and introduces a hyper-parameter $\beta$ to weight the UR. The work is easy to follow. However, the perspectives and methods are not novel. And there is a technical flaw in the analysis. ",0.17142857142857143,0.22641509433962265,0.1951219512195122
183,SP:12245a2fc4c66444b674020204eef54b7320c371,"This paper proposes a sequence-to-sequence model whose main building block is a linear layer called LSSL based on a standard dynamical system in control theory, including an internal ODE. LSSL is shown to implement both a convolutional and recurrent network, and, conversely, to be able, when stacked, to approximate any convolution and recurrent network with gating mechanisms, making the proposed model expressive. By endowing LSSL with the preexisting memory mechanism HiPPO, the resulting model MLSSL, and its counterpart SLLSSL that learns this operator, become computationally tractable and avoid gradient vanishing issues. The models are empirically validated on a number of regression and classification tasks showing their computational and performance advantages.",This paper suggests learning a proxy to continuous linear dynamical system. The paper discusses the tradeoffs and considerations and shows that the computations can be made efficiently. The paper demonstrates comprehensive empirical evaluation for the suggested method. ,0.10714285714285714,0.32432432432432434,0.1610738255033557
184,SP:123d38f124b95d956b18e6906a2e26171fb94224,"This paper mainly studies the index structure problem.  Existing learned index methods use a fixed value for all the learned segments. In this paper, the author contributes a deeper understanding of how the impacts the index performance, and enlightens the exploration of fine-grained trade-off adjustments by considering data local characteristics.  Experiments with real-world datasets and several state-of-the-art methods demonstrate the efficiency, effectiveness, and usability of the proposed framework.","This paper considers learning based methods for constructing index structures, a fundamental data structure.  Recent work has given learning based index structures which guarantee a maximum error of $\epsilon$ in the predicted index.  At a high level, this is done by breaking up the data set into several segments, and then a linear function is fitted to each segment, while maintaining the $\epsilon$ error guarantee.    The main idea behind this paper is to allow $\epsilon$ to vary across the different segments.  This is motivated by the fact that answering a query must first find the correct segment via a binary search, and then perform another binary search within the segment using the fitted linear function.  The runtime of the first step depends on the number of segments and the runtime of the second step depends on the prediction error.  By allowing the prediction error of some segments to go above $\epsilon$, the number of segments can be decreased, allowing for better trade-offs in some cases.  The main conceptual contribution is a method for tuning $\epsilon$ across different segments, which can be plugged directly into pre-existing learned index methods.    The authors give a theoretical analysis based on a stochastic analysis of the MET algorithm from prior work which is then leveraged to design their method for tuning $\epsilon$ across different segments.  An empirical study of their algorithm is performed on standard datasets for this area, comparing to several baselines from recent work in this area which use a fixed $\epsilon$.  The results show that the proposed $\epsilon$ tuning method can improve several learned index methods from prior work.",0.35135135135135137,0.09665427509293681,0.15160349854227406
185,SP:12411220098647e9bc26769218f2f64d82867493,"The paper is concerned with neural ODE-based networks, specifically their robustness. While ODEs are a classical subject in mathematics with many applications in the sciences and beyond, neural ODEs are a recently proposed family of models for nonlinear mappings in the context of machine learning systems. There they show promise and are an active field of research.","This paper investigates the robustness of Neural Ordinary differential equations (ODEs) against corrupted and adversarial examples. The crux of the analysis is based on the separation property of ODE integral curves. The insights from empirical robustness evaluation show that controlling the difference between neighboring integral curves is able to improve neural ODE's robustness. In general, neural ODE is a hot research topic in recent years, and a paper advancing knowledge in this area about understanding its various characteristics is certainly welcome. The paper is well motivated and clearly written. One aspect that confuses me a little originally is the different effects of getting ridding of the dependency on the time t and adding the steady state regularization. It would be nice to elucidate which part makes more contributions? Furthermore, to compare the robustness of the new approach with CNN, the input data consists of original images and their Gaussian-noise based perturbed samples. Since the paper already involves the evaluation using adversarial examples, it will make the paper much more stronger to show that when training both the new approach and the CNN with adversarial training, the proposed regularization can still lead to better robustness. ",0.27586206896551724,0.08163265306122448,0.12598425196850394
186,SP:12662df99ee1d902bbc54c3b14c3e14ddcf3bcca,"This paper proposes a recursive convolutional block design for compact CNNs with efficient training. The convolutional filters (across all layers) are decomposed into shared basis filters and non-shared expanding coefficients, both of which are trained in an end-to-end manner. To avoid vanishing/exploding gradients, orthogonality regularization is imposed, and the efficacy of which is shown through both theoretical analysis and empirical verification. The proposed architecture consistently outperforms the corresponding baseline in terms of accuracy with a reduced model size.","This paper describes a method to share parameters between iterations of a residual block.  Rather than sharing all parameters or none, a filter basis W_basis and mixture coefficients alpha are defined; the basis is shared between layers, while the coefficients are unshared.  A theoretical argument shows a potential cause of training instability due to repeated application of a shared weights term; an orthonormality regularizer is applied to the weights basis, to help alleviate vanishing/exploding gradients.  Measurements are performed on ImageNet, CIFAR and COCO, applied to a variety of resnets and mobilenet.  The resulting model uses about half as many parameters (though similar number of FLOPs) as a baseline model, and achieves similar or slightly better accuracy. ",0.2804878048780488,0.19491525423728814,0.23
187,SP:1271a6e23216cd2d164fbcd03cf473a4bb570396,"The authors of this paper propose a point process model that uses wavelet reconstruction to capture complicated dependencies between events. They motivate this approach using experiments in the medical domain, which show how certain dependencies between events is better captured by their proposed model. The primary contribution of the paper is novel and could be useful in medical settings where predicting occurrence of important events such heart attacks could be challenging with alternative methods.","This paper centers around efficient estimation of the kernel function for the Hawkes process and relaxation of the “linearity” assumption in the original Hawkes process. They rely on a classical sparse generalized linear model using the wavelet basis set and Hawkes loss function to estimate a shallow kernel function. This approach is opposite to the deep function estimation approach which does not rely on a predefined basis set [e.g. see [Du et al, 2016]]. However, it can have an advantage that the learned functions are interpretable, thought the authors never demonstrate it in the paper.",0.17567567567567569,0.13541666666666666,0.15294117647058825
188,SP:127bd212f3ecf32342b3750125f3e4ab41eb9d54,"The paper suggests a new training technique for neural networks, where each parameter is broken down into multiple parameters, representing its sign, sparsity, and magnitude (or shift). They explain why this new technique is useful for overcoming vanishing gradients and sign-freezing. They show that this training can produce a network with 3 bits weights, with the same quality as the standard fp32 network.","This paper proposes a new weight re-parametrization technique $S^3$ for training low-bit shift network. It claims that this new re-parametrization technique is weight-initialization insensitive and accuracy persistent compared with previous methods. In ImageNet, it achieves comparable top-1 accuracy with 3-bits, less than previous methods requires at 5-bit weight representation. Additionally, they also design two indices of weight dynamics to illustrate the mechanism of how $S^3$ works.",0.234375,0.2,0.2158273381294964
189,SP:1287f348b9093c99568d04a5b183a8aac669dca4,"This paper presents a sensory neuron architecture as a layer in a neural network trained for reinforcement learning and claims that this sensory neuron makes a network generally permutation-invariant. There is an extensive related-work section covering examples of sensory modality adaptation in neuroscience, cellular automata, meta-learning, and attention, setting up the presented approach which uses collective intelligence of only distributed modules with only local awareness, self-organization through attention, and adaptation of an existing policy to be permutation invariant. The paper then presents a mathematical formulation for the AttentionNeuron architecture, including its temporal memory, to be used as the first layer in an RL agent. The paper next tests its approach on four different tasks, some with multiple environments and concludes with some discussion of the results which appear to be robust to permutation of the input vector unlike the baseline feedforward network. ","This work investigates the problem of shuffled or dropped out sensory inputs for reinforcement learning agents. The authors propose AttentionNeuron, a permutation-invariant attention layer operating on neurons which independently process the input currently present at its location. Each neuron utilizes its past context and the past action to interpret the seen input, and the attention mechanism combines the outputs of each neuron to generate a globally-aware embedding to be used for a standard policy architecture. The authors show that (1) AttentionNeuron is robust to shuffled and noisy observations on CartPole, (2) performing behavior cloning with an AttentionNeuron architecture can yield a policy robust to shuffling on Ant, (3) AttentionNeuron is robust to patch-level shuffling and dropouts on Pong, (4) AttentionNeuron improves robustness to drastic background changes on CarRacing, and (5) AttentionNeuron is robust to shuffling within a single episode.",0.1643835616438356,0.16901408450704225,0.16666666666666666
190,SP:12cbd1f5f6063b50f666b56a3ced7a050b4f0b57,This paper explores how discriminators can be designed against certain generator classes to reduce mode collapse. The strength of the paper is on establishing the sample complexity bounds for learning such distributions to show why they can be effectively learned. The work is important in understanding the behaviour of GANs. The work is original and significant. A few comments that need to be addressed are listed as below:,"This paper analyzes that the Integral Probability Metric (IPM) can be a good approximation of Wasserstein distance under some mild assumptions. They first showed two theorems based on simple cases (Gaussian Distribution and Exponential Families). Then, they proved that, for an invertible generator, a special designed neural network can approximate Wasserstein distance with IPM. The main contribution is that, for a stable generator (i.e., invertible generator), a discriminator can reversely “re-visit” inner status of the generator, then use this information to make a decision. ",0.19117647058823528,0.1511627906976744,0.16883116883116883
191,SP:13071dbb937ba7f7c7cbeade305f6d59635dabdf,This paper develops an efficient self-supervised vision transformer for learning visual representations. It introduces a multi-stage architecture with sparse attentions to reduce computation complexity and proposes a new pretraining task of region matching to capture fine-grained region dependencies. The results on the ImageNet and 18 small datasets or downstream tasks are good and compared with other state-of-the-art approaches. ,"The paper investigates how to use self-supervised learning for multi-stage visual transformer models. Previous works have shown that SSL can learn image correspondences and lead to performant pre-trained models, while the multi-stage models can reduce the computation cost dramatically. This work tries to merge these two trends together. The solution is a new region-based loss that can be applied to the local features. The comprehensive experiments show the advantages of the resulting models on multiple tasks.",0.265625,0.20987654320987653,0.23448275862068965
192,SP:1308445195928727c5d0818757098800ec0c8591,"The paper proposes to extend the objective function for KG-embedding learning with a term that predicts the relation (predicate) given two entities. This extension is well motivated and the experiments show that it leads to small but consistent improvements. While the technical contribution of the paper is rather small, the experimental setup is sound and there are many interesting results and analyses. Especially the clear statement and answer of the research questions is nice.","The paper introduces a new self-supervised objective for improving link prediction in knowledge graphs. The idea presented in the paper naturally extends previous self-supervised objectives (e.g., TransE, CP, DistMult, etc.) by adding a training objective to predict the relation given the head and the tail entity in a knowledge graph triplet. The idea is really simple and it is surprising that previous works haven't tried this loss in addition to predicting the head/tail entity given the relation and the other entity. ",0.21333333333333335,0.18604651162790697,0.19875776397515527
193,SP:133403fbbb8b1195da7a017675d19d3b7b270811,"This paper investigates the impact of implementation ""details"", with existing implementations of TRPO and PPO as examples. The main takeaway is that the performance gains observed in PPO (compared to TRPO) are actually caused by differences in implementation, and not by the differences between the two learning algorithms. In particular, adding to the TRPO code the same implementation changes as in PPO makes TRPO on par with (and possibly even better than) PPO. The clipping objective of PPO is also found to have no significant impact on its performance. This calls for more careful comparisons between algorithms (by minimizing implementation changes and more in-depth ablation studies) than has typically been done until now in the RL research community.","This paper calls to attention the importance of specifying all performance altering implementation details that are current inherent in the state-of-the-art deep policy gradient community. Specifically, this paper builds very closely on the work started by  Henderson et al. 2017, building a conversation around the importance of more rigorous and careful scientific study of published algorithms. This paper identifies many ""code-level optimizations"" that account for the differences between the popular TRPO and PPO deep policy gradient algorithms. The paper then subselects four of these optimizations and carefully investigates their impact on the final performance of each algorithm. The clear conclusion from the paper is that the touted algorithmic improvement of PPO over TRPO has negligible effect on performance, and any previously reported differences are due only to what were considered unimportant implementation details.",0.20168067226890757,0.17518248175182483,0.1875
194,SP:133e984aa4736226e82246f3937b0a08cd8beb68,"The paper proposes a few new techniques: 1) A new video modeling architecture that uses a pre-trained VQ-VAE to tokenize frames, followed by a transformer encoder that aggregates the features and produces the final action class label. 2) Pre-training such an architecture using self-supervision by a) Masked prediction: Authors mask out blocks of tokens and predict them using the context (akin to BERT) and b) contrastive learning: Authors use the representation for two clips from same video as a positive match and otherwise negative match. The final model is trained with a linear combination of the masked prediction and contrastive losses, and finally finetuned for downstream tasks. The model is pretrained on HowTo100M dataset, and finetuned on multiple downstream datasets, where it obtains gains on more temporal datasets like SS-v2.","This paper proposes a new video pretraining method by combining masked token prediction and contrastive learning. Off-she-shelf VQ-VAE is used in this paper for discrete video tokens generation. In order to make the masked token prediction more effective, the authors proposed a block mask strategy where spatial-temporal neighboring video tokens are masked together. Experimental results are shown to validate its effectiveness.  ",0.14074074074074075,0.2923076923076923,0.18999999999999997
195,SP:1370baa1ac8b5530a26058d36be82ecf0e97cc98,"The authors tackle the exploration problem by introducing SIM (Sequence-level Intrinsic exploration Module). In most existing literature, intrinsic motivation bonuses are scored based on individual states or transitions, and not over multi-step trajectories. SIM predicts novelty bonuses based on the prediction error of an open-loop forward dynamics model - the model consumes as input a sequence of observations (without paired actions) followed by a sequence of actions (without paired observations) to predict a feature vector associated with the next state. The error between this feature vector and the RND embedding of the true observation is used as a novelty bonus. ","This paper extends the prediction-error based model by Pathak et. al., 2019 by learning a forward (and inverse) dynamics model for predicting a state feature multiple steps into the future (say, K-steps) given an open loop sequence of K actions as opposed to 1 step into the future, with the caveat that instead of using learnable state features, a random network is used for computing state features, similar to Random Network Distillation (RND) by Burda et. al., 2019. Also, their inverse dynamics models predicts the entire sequence of actions up to K steps. Experiments on VizDoom point-navigation tasks show that the proposed model does better than baselines as rewards get sparser. Ablations are provided to justify the choice of K in multi-step prediction, the choice of inverse dynamics and the choice of RND state features.",0.19607843137254902,0.14388489208633093,0.16597510373443983
196,SP:138632d011d3fcc86cff90f9e2fa8b1929d008cb,"This paper focuses on signSGD with the aim of improving theoretical understanding of the method. The main contribution of the paper is to identify a condition SPB (success probability bounds), which is necessary for convergence of signSGD and study its connections with the other conditions known in the literature for signSGD analysis. One important point here is that the norm in which the authors show convergence now depends on SPB, meaning that the probabilities in SPB are used to define the norm-like function they use in the theorems.",The paper presents an improved analysis of the signSGD gradient estimator. The authors propose to relax the requirements on the gradient estimator in Bernstein (2019). The only requirement imposed on the gradient is that it should have the correct sign with probability greater than 1/2. In particular this approach allows the gradient estimate to be biased as opposed to Bernstein (2019) which requires unbiased gradients. The authors also show this condition to be necessary by a small counterexample.,0.19101123595505617,0.21518987341772153,0.20238095238095238
197,SP:139a4db0a387a52eebf873a8f37f974492aa0d2f,"This paper introduces IMPACT which is a distributed RL algorithm that shortens training time of RL systems while maintaining/ improving the sample efficiency. It is built on top of the famous PPO algorithm (https://arxiv.org/abs/1707.06347). The authors break down the novel component of their model into three categories: target network, circular buffer, and importance sampling. They evaluate the effectiveness of each component through different experiments. ","Reinforcement learning (RL) training speed is broadly evaluated on two dimensions:  sample efficiency (the number of environment interactions required) and wall-clock time.  Improved wall-clock training time has been achieved through distributed actors and learners, but often at the expense of sample efficiency.  IMPACT repurposes successful concepts from deep RL - the target network, importance sampling and a replay buffer to demonstrate improvements on both axes in on three continuous environments and three games from the Atari Learning Environment.",0.17391304347826086,0.1518987341772152,0.16216216216216214
198,SP:13a80bac25725069db6041c3ab4bc2dc343cdcca,"This paper presents a new variational inference algorithm for Bayesian neural network models where the prior is specified functionally (i.e. through a stochastic process) rather than via a prior (e.g.) over weights. The paper is motivated by the maximization of the evidence lower bound defined on stochastic processes, which is itself motivated as the minimization of the KL between the approximate posterior and the true posterior processes. ","The primary contribution of this paper is the presentation of a novel ELBO objective for training BNNs which allows for more meaningful priors to be encoded in the model rather than the less informative weight priors featured in the literature. This is achieved by way of introducing a KL measure over stochastic processes which allows for priors to take the form of GP priors and other custom variations. Two approaches are given for training the model, one inspired by GANs, and a more practical sampling-based scheme. The performance of this training scheme is validated on a variety of synthetic and real examples, choosing Bayes by Backprop as the primary competitor. An experiment on contextual bandit exploration, and an illustrative Bayesian optimisation example  provided in the supplementary material showcase the effectiveness of this method in applications where well-calibrated uncertainty is particularly pertinent.",0.2898550724637681,0.13986013986013987,0.18867924528301888
199,SP:13d8b88675da21a709b023c18bf47d6fc2c12924,"This paper proposes MPO, a policy optimization method with convergence guarantees based on stochastic mirror descent that uses the average of previous gradients to update the policy parameters. A lower-variance method, VRMPO, is then proposed that matches the best known convergence rate in the in the literature. Experiments show that (1) MPO converges faster than basic policy optimization methods on a small task, and (2) VRMPO achieves a performance comparable to, and often better than, popular policy optimization methods (TD3, DDPG, PPO, and TRPO) on MuJoCo.","This paper proposed a variant of policy gradient algorithm with mirror descent update, which is a natural generalization of projected policy gradient descent. The authors also proposed a variance reduced policy gradient algorithm following the variance reduction techniques in optimization. The authors further proved the convergence of the proposed algorithms and some experiments are conducted to show the effectiveness of their algorithms. The paper is not written in a very good way due to many typos and misleading notations. Moreover, there seem to be some technical issues in the proofs of both main theorems.",0.22988505747126436,0.2127659574468085,0.22099447513812154
200,SP:13d9cb4549113d278e5b7e6fe8185002137e0671,"In this paper, the authors consider the neural amortized inference for clustering processes, in which the number of cluster can be automatically adapted based on the observed samples. The proposed algorithm largely follows the standard variational auto-encoder. The major contribution of the paper is the design of the posterior parametrization so that the posterior satisfies the permutation invariant within a cluster, between clusters, and unassigned data, based on the DeepSet method. The model can be incorporated into random communities models. Finally, the authors apply the algorithm for neural spike sorting problem. ","This paper introduces a novel deep learning architecture for efficient amortized Bayesian inference over mixture models. Unlike previous approaches to amortized clustering, the proposed method allows us to treat local discrete labels of data points and infer the unbounded number of mixture components, making it more flexible as in the case of Bayesian nonparametrics. It is shown that the resulting algorithm can be parallelized and applied to both conjugate and non-conjugate models. The authors also suggest an extension to models of random communities and a novel approach to neural spike sorting for high-density multielectrode arrays based on the proposed method.",0.22826086956521738,0.20588235294117646,0.21649484536082475
201,SP:13f139ef162bb961229b0917b6e0c8706d574f3e,"A multi-agent pure-distributed (no shared data) algorithm for the stochastic Multi Armed Bandit setting is presented and analyzed. Regret bounds for different agents connectivity schemes are provided, incorporating the related quantities, namely the diameter for strongly connected graphs and the number of each agent neighbors for undirected graphs. Experiments are conducted to illustrate the superiority of the algorithms and the related bounds over the single-agent UCB1 algorithm performance and the qualitative difference of the performance of the agents in the different connectivity settings.","The paper considers a multi-agent cooperative bandit system, where the agents are connected on a graph and can share messages. The arm-pulls of each agent does not interfere with that of the others, but agents can speed up learning by communicating. The paper proposes a parameter-free (no information on the global system) algorithm that each individual agent executes locally. if the graph is strongly connected, the per-agent regret is shown to be strictly better than that of vanilla UCB. If the graph is undirected, the regret of an agent is inversely proportional to the number of neighbors it can share information with. The key algorithmic innovation is to ensure that the number of times an arm is pulled by all agents are within M (a constant which is a hyper-parameter) of each other. This enables agents to arrive at consensus and get low regret",0.26744186046511625,0.15436241610738255,0.1957446808510638
202,SP:140100004dc307efd67790ef58f67929d3403c67,"This paper proposed a new approach for modeling multi-domain dialogue state tracking by incorporating domain-slot relationship using a pre-trained language encoder. The proposed approach are based on using special tokens to mode l such relationship. Two kinds of special tokens are proposed to represent domain-slot pair, DS_merge token for each specific pair, and tokens for every domain and slots separately ","In this paper, the authors proposed a multidomain state-tracking model that leverages the relationship among different domain-slot pairs. This is done by leveraging the full-attention step over the [CLS] special token and by providing all the domain-slot pairs as a special token to a pre-trained language model (Figure 2 is very clear). To predict the value of the slot $D_{i,j}$, the author concatenates the representation of the [CLS] token, share among all the domain-slots, and the $D_{i,j}$, provided as input, and use a gating mechanism, by only using $D_{i,j}$ representation, to decide whether require as value (i.e., prediction) or not (e.g. None). \",0.2923076923076923,0.16379310344827586,0.20994475138121546
203,SP:140a3d3a8f884cfb4ef8e6542812947017a0888c,This paper introduces a knowledge-graph enhanced recommendation method for healthcare platforms. The authors use user profile information to select entity neighbors for user modeling. Experiments on a nudge CTR prediction dataset show some improvements brought by the proposed method.,This paper proposes a graph-based recommender system for diabetes self-care management. The proposed method bases on the knowledge graph embeddings techniques. The proposed method shows better performance compared with two baselines on metric AUC. ,0.25,0.2777777777777778,0.2631578947368421
204,SP:141200456d0b5c1970dcb11c11acefca7717cf1b,"Neural Networks (NN) have been shown to be susceptible to various adversarial attacks i.e. if we perturb the ""x"" just a little, the output prediction changes. So, there has been much research devoted to how we can make NNs robust to such attacks. Typically, the adversarial examples that are used to train adversarially robust methods are generated from the correctly classified examples. ","The paper improves adversarial training by introducing two modifications to the loss function: (i) a ""boosted"" version of the cross-entropy loss that involves a term similar to a large-margin loss, and (ii) weighting the adversarial loss differently depending on how correctly classified an example is. When put together, these modifications achieve state-of-the-art robustness on CIFAR-10, improving over the previously best robust accuracy by about 3.5%. The authors perform multiple ablation studies and demonstrate that their modified loss function also improves when additional unlabeled data is added (again achieving state-of-the-art robustness).",0.15873015873015872,0.1,0.1226993865030675
205,SP:1415d403cc5b85e50a37458d786bf31d01045f60,"The paper introduces a new neural network layer that enables training NNs with quantized activations using reduced bit-width accumulators. The cyclic activation layer makes overflows smooth, instead of being discontinuous and this enables achieving better accuracy on quantized networks on reduced bit-width accumulators. They also introduce overflow and carry penalties to dissuade the training regime from reaching overflow states.","This paper explores to solve an often ignored issue in quantization: accumulation precision. As the bit-width of input scales down, the area/energy cost of the accumulator starts to dominate.  The cyclic method proposed by the authors at the first glance is not intuitive. However, it's surprising that the surveyed models could be tuned to live with significant overflows---as long as it can be tuned, which is enabled by the ""differentiable overflow"" brought by the cyclic method.  There are several issues to be addressed before the paper can be accepted:",0.14754098360655737,0.0967741935483871,0.11688311688311688
206,SP:14192d7b4acedfc6802000031e9d2608985e10b9,"The paper considers the problem of generating sequences that have label values higher than those observed in training. An approach is proposed to encode information about the attribute to be optimized into the latent vector of an autoencoder through joint training with a discriminator and a cycle consistency objective. The model is evaluated on two different datasets, one on sentiment in movie reviews and the other on protein stability.","The paper describes GenEnhance, a method for generating sequences with attributes that do not exist in the training distribution. GenEnhance is based on a discriminator / generator architecture trained with a cycle consistency loss similar to existing methods. The main innovation of GenEnhance is that the discriminator is trained with a contrastive loss for learning to rank generated samples by their attribute.  The paper is well written and combining a contrastive loss with a cycle consistency loss for controllable generation is new as far as I know. However, it is unclear how the cycle-consistency loss performs relative to regression losses and how GenEnhance performs relative to existing methods for model-based optimization in the visible and latent space.",0.30434782608695654,0.17796610169491525,0.22459893048128346
207,SP:14225666046a7ccbd2cdf7229fb7ba89a849e5ee,"The paper proposes a new tapered precision numerical format (EFloat) where the exponent of floating value is represented by Variable Length Huffman coding (The maximum of bit-width is limited). Since the Huffman coding was designed based on the probability of exponent occurrence, the most frequent exponent values are presented by fewer bits, which free some bits to be allocated for precision. The vector embedding benchmarks are used to evaluate the efficacy of the new numerical format compared to other numerical formats such as BFLOAT16 and FP16. Based on the metric represented in the paper, such as RMSE and NDCG, the EFloat is better than BFLOAT16 and comparable with FP16. ","This paper introduces EFloat, a domain-specific entropy-encoding numerical format targeted for NLP applications. EFloat takes advantage of clustered values in parameter distributions to allow Huffman coding to compress the average bitwidth. The authors propose this method as a means of compressing parameters to save memory and IO bandwidth in deep learning models. They further introduce the vector embedding model, describe the algorithms for encoding and decoding EFloat, and evaluate EFloat against IEEE FP16 and BFloat. ",0.18181818181818182,0.2597402597402597,0.21390374331550802
208,SP:142a01056d20ddab91353b9d2ec07925f82d10ea,"Aim to improve the interpretability and the accuracy of the neural network, this paper takes a step further on the integration of NN with a decision tree. It will replace the final linear layer of the NN with a decision tree induced by pre-trained model weights. It takes advantage of both hard and soft decision trees and designs suitable tree supervision loss thereon. Extensive experiments verify the design choice of the proposed components. On both small-scale and large-scale datasets, it beats the decision tree counterparts. Also, on the aspects of generalization and interpretability, it shows the strength compared to NN.","The paper proposes a method to make neural networks more accurate and interpretable by replacing their final layers with a probabilistic decision tree. As a result, the network can produce a sequence of decisions that leads to the final classification result, given an input image. The method is trained with soft decisions by assigning probabilities to each leaf, which are associated with a single class. The tree decision hyperplanes are constructed automatically from the backbone networks final dense layer and finetuned. The fact that decisions are soft solves the differentiablility problem of decisions as in various other similar papers, cited or uncited (more below).",0.18446601941747573,0.18269230769230768,0.18357487922705315
209,SP:142f883313e89c9f27904da7aa5e3e7063dffc4d,"This paper attempts to infer a network's accuracy at initialization without training it, which can speed up neural architecture search and greatly reduce the search cost. Specifically, they propose a metric based on the Jacobian of the loss with respect to a minibatch of input data. The authors show that with this metric, they can find architectures with reasonable accuracy on CIFAR-10/CIFAR-100 in the NAS-Bench-201, while using much less search cost compared to previous NAS methods.","The paper mainly introduces a metric to benchmark the performance of neural networks without training – the correlation of Jacobian subject to different augmented versions of a single image. The key motivation is, high-performance networks tend to represent data of small perturbations with different hyperplanes at initialization, so that the distinguishing capability may also be stronger. The divergence of the hyperplanes can be efficiently estimated via the correlation of the Jacobian, thus quantified by the score in Eq. 2. The effectiveness of the proposed metric is mainly verified in two NAS benchmarks (NAS-Bench-101 and NAS-Bench-201), whose correlation to the actual accuracy is relatively significant (Fig 3). Compared with existing NAS frameworks, the proposed method is very efficient, moreover, able to obtain competitive performance.",0.23170731707317074,0.14960629921259844,0.18181818181818182
210,SP:1435c726085b9c1702767584ad83f17e5a23beaa,"While the machine learning community has given much attention to the LQR problem, much less attention has been given to more sophisticated control problems. This work takes a step in this direction by studying the sample complexity of derivative-free methods applied to the Linear Exponential Quadratic Gaussian (LEQG) and LQ Disturbance Attenuation problems. To solve these problems, they show a reduction of each to the LQ game setting, then propose and analyze the convergence rates and sample complexity of a derivative-free optimization (DFO) algorithm.","This article studies the convergence of double-loop policy gradient methods for finite-horizon two-layer zero-sum LQ game arising from the risk-sensitive control problems. It shows that, for suitable choices of the initial guess of the outer iteration, both the natural gradient method and the Gauss-Newton method converge to the unique Nash equilibrium. The authors then extend the algorithm to derivative-free methods based on observed state trajectories. To the best of my knowledge, this is the first theoretical result on convergence of gradient-based methods for competitive multi-agent RL problems. ",0.1744186046511628,0.15625,0.16483516483516483
211,SP:1442b188a5bac1931c3023a5529fa366f22bd8e6,"This paper addresses the important question of improving the robustness of deep neural networks against adversarial attacks. The authors propose a surprisingly simple measure to improve adversarial robustness, namely replacing typical activation functions such as ReLU with a k-winners-take-all (k-WTA) functions, whereby the k largest values of the input vector are copied, and all other elements of the output vector are set to zero. Since the size of input and output maps varies drastically within networks, the authors instead use a sparsity ratio \gamma that calculates k as a function of input size. k-WTA networks can be trained without special treatment, but for low \gamma values the authors propose a training schedule, whereby \gamma is slowly reduced, then re-training takes place, until the desired value of \gamma is reached. The presented effect is backed up by extensive theoretical investigations that relate the increased robustness to the dense introduction of discontinuities, which makes gradient-based adversarial attacks harder. A small change in an input signal can change the identity of the ""winning"" inputs, and thus in a sub-sequent matrix multiplication make use of other rows or columns, thus allowing arbitrarily large effects due to small input variations. Empirical evaluations in CIFAR and SVHN for a variety of attacks and defense mechanisms demonstrate the desired effects, and illustrate the loss landscapes due to using k-WTA.","The authors propose using k-winner take all (k-WTA) activation functions to prevent white box adversarial attacks. A k-WTA activation functions outputs the k highest activations in a layer while setting all other activations to zero. The reasoning given by the authors is that k-WTA activation functions have many discontinuities with respect to the input space. This makes it more difficult for attacks to use gradient information. The authors note that networks with k-WTA activation functions are still easy to train because, for a given input, the sub-network that is activated becomes more stable as training progresses. Therefore, it is not as discontinuous in the parameter space.",0.13852813852813853,0.2857142857142857,0.18658892128279883
212,SP:144d9252aed93d5c8d70c689277531450061951a,"This paper studies the generalization of neural networks trained using stochastic gradient descent (SGD) using information-theoretic bounds. It builds upon existing work that bounds the generalization error using the average square root of the mutual information of the weights with each training datum and related work by Neu 2021 [49] that refines this bound using quantities that correspond to the local gradient sensitivity, the variance/dispersion of the mini-batch gradients, and a stability term that captures the loss at the terminal weights on independent test data. The main contributions of this manuscript are as follows.  1. The paper introduces a coupled auxiliary weight process which refers to the weights updated using additive noise in the gradient descent direction calculated by SGD using the original weights. This allows the authors to study the mutual information of the descent direction with a particular datum in Lemma 5. 2. Theorem 1 establishes that the gradient sensitivity term can be eliminated using an application of Otto and Villani’s HWI inequality that relates the entropy of the weight posterior with the Wassserstein distance and the Fisher information. Theorem 2 and Corollary 1 expand on this result. The main conclusion is that the generalization error can be broken down into two terms, one that depends upon the ratio of the learning rate and batch-size and another that depends upon the stability term referred to above (bounded in Corollary 1 using the trace of the Hessian). 3. The bound in Theorem 2 is verified using a fully-connected network on MNIST and a convolutional network on CIFAR-10.  4. The paper also develops a loss function that training neural networks that averages the loss of the network across different perturbations of the weights by Gaussian noise. This new loss function is evaluated on MNIST, CIFAR-10 and CIFAR-100."," This paper considers the important problem of understanding the generalization of the SGD algorithm. This paper is a follow up on this paper:   G. Neu. “Information-theoretic generalization bounds for stochastic gradient descent”.  To analyze the generalization, the authors use the mutual information framework of Russo-Zou and Xu-Raginsky where the expected generalization error is upper bounded using mutual information (MI) between output and training set. The main issue with analyzing SGD with MI is that it leads to vacuous bounds due to the fact that there is only degenerate noise in SGD. To circumvent this issue,  the authors use the idea of analyzing a “surrogate algorithm” from Neu’ 21 paper. The surrogate algorithm is a noisy version of the SGD, and instead of analyzing the SGD we can analyze the generalization of the surrogate algorithm. At the end we need to add “pay” for the difference between the output of the surrogate algorithm and SGD.    ",0.1568627450980392,0.3057324840764331,0.20734341252699784
213,SP:14a10829b5d4b5fcdf1c02720b767e6af2733a48,"This paper studies the transferability in multi-task learning. They propose a metric, transference, to evaluate how tasks affect each other during multi-task training, and a method called IT-MTL which utilizes this metric to compute and improve lookahead loss changes. Although the proposed metric and method are interesting from a scientific point of view, there are a few key downsides (as the author themselves summarized in the conclusion) that require further investigation/improvements.","[Summary] This paper studies the problem of task relationship/transference in multi-task learning, by introducing a quantifiable measurement based on relative loss updates.  A (nonsymmetric) task transference between task $i$ and task $j$ then can be computed by measuring the relative change of training loss of task $j$, with the updated shared parameters from the training loss of task $i$. By finding a subset of tasks that achieves maximal total transference over every single task, multi-task learning performance can be further improved.",0.25333333333333335,0.2261904761904762,0.23899371069182387
214,SP:14c3434519fa9e757c4c5e6869c7c3cb07511f24,"The authors present a new scheme for compressing gradients for use in distributed training. In addition to the previously proposed techniques of sending the sign of the gradient components along with the scale, and the use of error feedback (each sender tracks the error introduced by quantization, and adjusts future gradient updates using it), the authors also propose to exploit the temporal correlation of gradient values (i.e., over successive steps). They do so by computing the delta between two steps, and then use a hyperparameter $\alpha$ to keep only a fraction of the deltas and that is sent losslessly.","This paper proposed an extension of blockwise scaled sign compressor in Zheng et al. (2019). The proposed method exploits the temporal correlation between two consecutive gradients. The authors show that one can have a higher compression rate by inserting distortion to the compressed gradient. A tighten bound is provided such that the asymptotic rate (including constant) is exactly the same as the full-precision counterpart. The experiments show that the proposed compressor can achieve additional 40%-50% reduction on communication compared to the scaled sign. Overall, the reviewer thinks the idea is interesting. The reviewer has a few comments:",0.15,0.15151515151515152,0.15075376884422112
215,SP:14c8ee6cc91f94c22b9cd29c98be73e551677937,"This paper addresses challenges faced in the multi-task learning (MTL) models used in analyzing multimodal conversational data. The main challenge paper is trying to solve is on how to select relevant auxiliary tasks that avoid negative transfer. The authors explore how the preprocessed data used for feature engineering can be re-used as auxiliary tasks in the model. The authors identified sixteen relevant auxiliary tasks, identified a method to distribute learning capacity between primary and auxiliary tasks and proposed a relative supervision hierarchy between primary and auxiliary tasks. An extensive set of experiments are conducted to show the effectiveness of the approach. ","This paper studies how the preprocessed data can be reused as auxiliary tasks in primary multi-task learning (MTL) for the multimodal emotion detection task. The authors propose and test three hypotheses for primary MTL. Two different hierarchical-level models, FLAT-MTL hierarchical attention model and HAN-Rock model, are proposed to improve the performance of the primary MTL.     ",0.22330097087378642,0.3898305084745763,0.28395061728395066
216,SP:14da0ec3ce7769bf3e3371097ae805909a1b636d,The main topic of this paper is generalized zero-shot learning. This paper modifies traditional VAE method with attribute matching prior to release the hidden features from original regularization. This paper also proposes a domain discriminator to enhance class-separability of learned features to avoid unseen classes to be covered by seen classes. Experiment results show their efficiency under relation-based setting.,"This paper proposes a relation-based ZSL model which can effectively alleviate the domain bias problem. To this end, first, the paper claims that a good relation-based ZSL model should consider two requirements -- modality invariance and class separability. And the paper designed Modality-invariant and Class-separable Multimodal VAE (MCMVAE) based on VAEs to meet the two aforementioned requirements. Next, the paper hypothesizes that the domain bias problem is due to the overlap between seen and unseen classes in the shared space, and explicitly introduced a discriminator to separate the two domains. The paper performs experiments on ZSL benchmark datasets and shows that the proposed method outperforms other relation-based methods. Besides, the domain discriminator which can be applied to other models demonstrates its effectiveness in reducing domain bias given the experimental results.",0.24193548387096775,0.11194029850746269,0.15306122448979592
217,SP:14dca47a505818106502978bddde5a7f294bfeeb,"This paper developed a novel layerwise adaptation strategy, LAMB, that allows training BERT model with large mini-batches (32k vs baseline 512). This significantly speeds up the status quo in training BERT model, and effectively reduces the training time from original 3 days to only 76 minutes. In addition to demonstrating superior results across various tasks in practice, the paper also provides theoretical convergence analysis on LAMB optimizer.  ","This paper proposes a learning rate adaptation mechanism, called LAMB, for large-batch distributed training. The goal is to stabilize the training as the batch size increases. The idea is simple and straightforward -- there should be a layerwise learning rate adjusted by normalizing the layer weights and gradients at each layer so that layers with larger weights take larger learning steps, and vice versa. The authors perform empirical studies on BERT-large and ResNet to conclude that LAMB can scale up training batch size while still being able to converge in time with comparable accuracy.",0.19117647058823528,0.1368421052631579,0.15950920245398775
218,SP:14efc52bb1949c529498fea95f1f5e94710c85a5,"This paper proposes a general framework for so-called ""out-of-distribution generalization"" that can handle non-linear associations and causal links between variables. It provides proofs for identifiability and generalization. It proposes a general causal model that is sensible for many prediction problems. It proposes a conditionally non-factorized prior. It provides a tractable method that can be used in practice.",This paper proposes invariant Causal Representation Learning (iCaRL) for OOD generalization in the nonlinear setting. The work extends iVAE to a somewhat more general setting and shows the direct cause of the target can be discovered. iCARL is then developed based on the direct cause. . Extensive experiments verify the effectiveness of the proposed method.,0.16129032258064516,0.18518518518518517,0.17241379310344826
219,SP:14f7771d7e9c3d3f728ae24720d22847b08ac7a1,"This paper studies to predict future state density function by using an indirectly method via classification. The main idea is to sample the future state from two sources: 1) from replay buffer, 2) the actual next state in the trajectory (in off policy setting we only need the next state) and then use a classifier to distinguish them. By Bayesian rule we can recalculate the conditional density function by the ratio of the classifier. The paper compare this method with several baseline and find that they can predict the conditional density function very close to reality.","The authors propose a new algorithm, called C-learning, which tackles goal-conditioned reinforcement learning problems. Specifically, the algorithm converts the future density estimation problem, which goal-conditioned Q learning is inherently performing, to a classification problem. The experiments showed that the modification allows a more precise density estimation than Q-learning, and in turn, a good final policy.",0.09375,0.15254237288135594,0.11612903225806451
220,SP:14fa0894cc0b4dd4bdb51c089cf5511c89de8b4f,"This paper presents a way to view contrastive divergence (CD) learning as an adversarial learning procedure where a discriminator is tasked with classifying whether or not a Markov chain, generated from the model, has been time-reversed. Beginning with the classic derivation of CD and its approximate gradient, noting relevant issues regarding this approximation, the authors present a way to view CD as an extension of the conditional noise contrastive estimation (CNCE) method where the contrastive distribution is continually updated to keep the discrimination task difficult. Specifically, when the contrastive distribution is chosen such that the detailed balance property is satisfied, then the CNCE loss becomes exactly proportional the CD-1 update with the derivation further extended to CD-k. Practical concerns regarding lack of detailed balance are mitigated through the use of Metropolis-Hastings rejection or an adaptive weighting that arises when deriving the gradient of their time-reversal classification loss.  A toy example providing empirical support for correcting the lack of detailed balance is included.","To implement the contrastive divergence (CD) algorithm in practice, an intractable term is typically omitted from the gradient. This leads to an approximation. This work shows that the resulting algorithm can in fact be viewed as an exact algorithm targeting a different, adversarial objective. The derivation in this paper also shows how Markov chains which are not reversible w.r.t. the posterior distribution of interest can be employed within the algorithm. Effectively, this assigns an importance weight to each sample which akin to the acceptance ratio which would be needed for a Metropolis--Hastings type correction.",0.1317365269461078,0.2268041237113402,0.16666666666666666
221,SP:1510815ddfb253f977b3ce9b53ea02b4044ffb90,"The paper proposes an extension of the performance improvement bound, introduced for the first time by Kakade & Langford (2002), to the case of average reward performance index instead of discounted return. The paper starts with a theoretical contribution in which all the steps of the original derivation are adapted for the new setting, leading to a new performance improvement bound. Then, this theoretical achievement is employed to derive the corresponding adaptation of TRPO (called Average Reward TRPO) and CPO (called Average Cost CPO). Finally, an experimental evaluation on some Mujoco domains is provided.","This paper advocates for the use of the average reward objective in long horizon, continual reinforcement learning settings, and it examines whether a limiting argument for the discount is sufficient for extending theoretical results from the discounted setting to the average-reward setting. In the case of policy optimization, the paper shows the monotonic improvement bound from Schulman et al. (2015) becomes vacuous as gamma approaches one. The rest of the paper presents theory to support a new, non-vacuous bound, which leads to a new algorithm analogous to TRPO (A-TRPO). The paper additionally shows how their main theorem can be applied to constrained MDPs in Section  5.2. Empirical results are provided in three MuJoCo domains modified to provide non-episodic experience.      ",0.25806451612903225,0.1935483870967742,0.22119815668202764
222,SP:152f5c76e34d2b7acdafa37763be4bb51aa9ce6f,"This paper proposes/adopts a simple positive sampling scheme in metric learning: only sampling the easiest positive for each anchor. Authors give a theoretical analysis of how the proposed sampling scheme can reduce class collapse. Experiments on fine-grain retrieval datasets show the effectiveness of the sampling scheme. Using the sampled easiest positive, nearly all current metric learning methods got improved performance.","The authors find that the popular triplet loss will force all same-class instances to a single center in a noisy scenario, which is not optimal to deal with the diverse and distinct sub-classes. After some analyses, the authors propose a simple sampling strategy, EPS, where anchors only pull the most similar instances. The method achieves good visualization results on MNIST and gets promising performance on benchmarks.",0.14516129032258066,0.1323529411764706,0.13846153846153847
223,SP:15529a4159e8db5b440a0040fd431cedabb12ff4,"Following recent works studying the effect of model scaling on tasks such as transfer learning, this paper asks whether scaling up the size of a pretrained network also helps alleviate or minimize catastrophic forgetting. The authors use split CIFAR-10/-100 datasets (early experiments on NLP tasks are also included) and demonstrate the accuracy lost by a pretrained network when learning a set of tasks sequentially reduces with increase in model size. This result is shown to hold for both ResNets and Vision transformers. The topic is timely and the paper is well written. My main apprehensions relate to the experimental setup--due to the use of only CIFAR datasets for evaluation, which have significant class overlap with ImageNet, it may not be justified to think of learning a subset of CIFAR classes as a new task. Overall, I believe some claims are not completely validated yet, but this can be addressed by using a more appropriate experimental setting.","The paper explores the effect of scale on catstrophic. They conduct several different experiments (for both ResNets and Vision Transformers) showing: - the size of the model for pretrained models reduces forgetting  - (Longer) pretraining reduces forgetting - More pretraining training data size reduces forgetting - A metric used to measure overlap between model representations showed that pretraining results in more orthoganal representations between classes.  - The length of finetuning isn't as impactful on pretrained models as randomly initialized models They perform the majority of their experiments on a two task, task incremental Split CIFAR-10 dataset. Some experiments were done on 2-task class incremental and 10-task task incremental Split CIFAR-100. They also conduct a brief set of experiments showing that scaling model size  reduces forgetting for language as well.",0.14465408805031446,0.17829457364341086,0.15972222222222224
224,SP:1572adb9d8abb9edd60d11e7cdd0e48cfdf5bd4b,"This paper gives a nice interpretation why recent works that are based on variational lower bounds of mutual information can demonstrate promising empirical results, where they argue that the success depends on ""the inductive biasin both the choice of feature extractor architectures and the parametrization of theemployed MI estimators."" To support this argument, they carefully design a series convincing experiments which are stated in full in Section 3. Moreover they show some connection to metric learning. ","The paper addresses a question on whether mutual information (MI) based models for representation learning succeed primarily thanks to the MI maximization. The motivation of the work comes from the fact that although MI is known to be problematic in treatment, it has been successfully applied in a number of recent works in computer vision and natural language processing. The paper conducts a series of experiments that constitute a convincing evidence for a weak connection between the InfoMax principle and these practical successes by showing that maximizing established lower bounds on MI are not predictive of the downstream performance and that contrary to the theory higher capacity instantiations of the critics of MI may result in worse downstream performance of learned representations. The paper concludes that there is a considerable inductive bias in the architectural choices inside MI models that are beneficial for downstream tasks and note that at least one of the lower bounds on MI can be interpreted as a triplet loss connecting it with a metric learning approach.",0.25,0.1111111111111111,0.15384615384615383
225,SP:1585c85c36d252c0d9f3d321a7ae59f12ea60dbd,"This paper introduces a new distributed value-based multi-agent reinforcement learning framework to solve problems faced by multi-agent tasks. It divides the system into two parts, multiple containers, and one centralizer. Containers are trained with trajectories generated by their own actors interacting with the environment. In contrast, the centralizer is trained with high-priority samples sent by all containers, easing the demanding data transfer. Besides, this paper designs a multi-queue manager between actors and replay buffer to avoid inter-process communication blocking. Furthermore, this paper proposes a new loss function encouraging different containers to be diversified to promote exploration. Finally, it achieves better results on both Google Research Football and StarCraft II micromanagement benchmark.","This paper focuses on an interesting and important question: how to perform distributed multi-agent deep reinforcement learning? The author first proposed three challenges to be considered: 1) Demanding data transfer. 2) Inter-process communication. 3) Effective Exploration. Further, the author proposed a container-based distributed marl framework, by placing the part that interacts with the environment in the container relieves the pressure of the cpu, and at the same time encourages different containers to have different policies and uses PER to select high-value samples, thereby improving training efficiency.",0.1794871794871795,0.23333333333333334,0.20289855072463772
226,SP:158dd8882013a9a5efa7fd4579ad3900ca76a4b5,"This paper suggests an approach for learning how to sparsify similarity search graphs. Graph-based methods currently attain state of the art performance for similarity search, and reducing their number of edges may speed them up even further. The paper suggests a learning framework that uses sample queries in order to determine which edges are more useful for searches, and prune the less useful edges. This is a sensible and potentially useful approach in line with the recent flurry of work on improving algorithms with tool from machine learning.","This paper studies the problem of improving proximity graph for nearest neighbor search. It formulates the task of pruning the graph as a problem of learning annealable proximity graph. A hard pruning processes is used after the learning process, and the results shows that the proposed method can reduce 50% of the edges and speed up the search time by 16-41%.",0.15730337078651685,0.22580645161290322,0.18543046357615894
227,SP:15ebeef5c445120900b9c94bbcd6a997bfb92899,"This paper proposes to use **active set** of causal edges, instead of auxiliary context variable or domain index to characterize nonstationary causal relations in data. In addition, the authors propose Sufficient Activated Mechanisms (SAM) to replace Sparse Mechanism Shift (SMS) as the inductive bias (assumption) for causal discovery and inference.   Developing a principled way to characterize mechanism shifts in causal settings is definitely an interesting idea and potentially publishable. However, this paper introduced merely a conceptual framework instead of a working system with theoretical guarantees and contained a few unsupported claims which I feel not confident to justify their correctness. I strongly recommend the authors code the proposed meta-SCM and SAM in a training architecture and validate their correctness in both theoretical and empirical perspectives and submit the to future venues. ","This paper presents a new lens on causal graphical models from a lens of fuller generality. Rather than considering models under assumptions such as acyclicity or other constraints that enable tractable modeling, the authors consider the notion of a meta causal model which, when indexed, includes SCM as one possible snapshot. The authors give two additional assumptions (1) sparse mechanism shift and (2) sufficient activated mechanisms, and describe the implications.",0.12121212121212122,0.22857142857142856,0.15841584158415842
228,SP:15f1f17659b0f5d0b5a71f32a3c1ca918d54cc3d,"The paper presents Fourier Flows (FF), which is a time series generative model in the frequency domain. It shows that the Jacobian of the DFT is equal to 1, which means that DFT does not add too much overhead. The results on the real-world datasets are encouraging and expected because the predictive results mainly rely on the overall trend of the time series. By analysis in the frequency domain, we usually can capture the main trend accurately. The main concerns for the paper are the computational overhead on the proposed algorithm on non-periodic, long, and variable-length time series.","The paper introduces a new convolutional flow architecture that uses the DFT to convert the generated time series to the frequency domain. Convolutions are performed by multiplication in the frequency domain through a spectral affine layer that transform the even or odd part of the signal using a data dependent filter. The resulting time-domain convolution has input dependent weights, an interesting and original approach clearly different from other convolutional flow such as [1]. ",0.18811881188118812,0.25675675675675674,0.21714285714285714
229,SP:163928606a3e1ba4e1cf225d107b231c31d40ad5,"This paper tries to quantify how ""dense"" representations we need for a specific task -- more specifically, how many dimensions are needed from a given representation (for a given task) to achieve a percentage of the performance of the entire representation. The second thing the paper tries to quantify is how well representations learned for one task can be fine tuned for another. Experiments are conducted with 4 different representation technique on a dozen or so tasks.","This paper proposes simple metrics for measuring the ""information density"" in learned representations. Overall, this is an interesting direction. However there are a few key weaknesses in my view, not least that the practical utility of these metrics is not obvious, since they require supervision in the target domain. And while there is an argument to be made for the inherent interestingness of exploring these questions, this angle would be more compelling if multiple encoder architectures were explored and compared. ",0.14473684210526316,0.1375,0.14102564102564102
230,SP:16392bc9174dde6ad7b569f3f40fa14a4ed48831,The paper introduces a new condition for showing the existence of the solution of a deep equilibrium model (which defines an implicit mapping via the fixed point). The new formulation also comes with a convenient and accurate Lipschitz bound. The proposed condition can be satisfied via reparameterizing an unconstrained set of trainable parameters. ,"> Summary: This paper studies a new and more general way of parameterizing the simplest equilibrium network of the form $\sigma(Wz+Ux+b)$, a form that has been tackled by works like (Winston & Kolter 2020)and (El Ghaoui et al. 2019). The authors provide a computationally (relatively) efficient way of computing Lipschitz-bounded equilibrium networks and a detailed analysis of how the network should be constructed, along with the proof of the existence and uniqueness of the fixed point (and with less restrictive conditions when compared to MON). The empirical results on adversarial robustness shows that the proposed approach is a bit more robust than prior layer-based networks and other implicit networks, and validates most of the theoretical claims made by the authors.",0.2830188679245283,0.12096774193548387,0.16949152542372883
231,SP:163b6f1e8787eb5d48bf477b3ef3c0a00d41a937,"Two methods are proposed in this paper. They are Transferable Attack using Integrated Gradients on Straight-line Path (TAIG-S) and Transferable Attack using Integrated Gradients on Random Piecewise Linear Path (TAIG-R). Compared with typical gradient-based attack methods, the TAIG-S uses integrated gradients to update adversarial examples, and TAIG-R uses random path integrated gradients to update adversarial examples. Experiments on ImageNet can prove the effectiveness of these methods.","In practice, adversarial examples are generated in three ways, i) solving a standard optimisation problem, ii) leveraging the salient regions of an image, or iii) smoothing the decision surfaces. The authors propose a simple technique named Transferable Attack based on Integrated Gradients (TAIG) that combines all these three approaches. Unlike the existing systems, which leverages other methods by adding additional terms to the objective function, TAIG integrates them into a single objective.",0.1527777777777778,0.1527777777777778,0.1527777777777778
232,SP:1640224fbb539102c940e326404114dfdd4abf98,"This paper uses CycleGAN to map neuronal activities of mice (as measured by Calcium traces) pre- and post-learning. The main contributions are (1) empirical results of using CycleGAN to learn the pre- and post-learning mapping look promising. (2) using both attention mask (which is for gating residual concatenations) and Grad-CAM to help with interpretation. (3) sorting neurons with an autoencoder’s reconstruction error, essentially sorting them based on their importance.","This paper presents a new method for learning the transformation in neural population activity that takes place during task learning. The method is based on CycleGAN, but includes additional modifications related to neural data and the manner in which it is collected. The paper also presents visual interrogations of the learned model to better understand details of the learning process.",0.136986301369863,0.16666666666666666,0.15037593984962408
233,SP:164da37f418e9f6ce0470a329ed41e35f9ac1260,"The aim of this work is to make deep learning classifiers more interpretable by ""projecting"" each input sample into a small collection of prototype examples (with some weighting over those) and then basing the decision on a combination of the latent representations of the chosen prototypes. In this way, the chosen category can be justified as the input being similar to the selected prototypes. Additionally, this approach makes it possible to obtain a confidence score at test time.","This paper presents a sample-based self-explaining method for image classification. The basic idea is adopt the attention mechanism to learn the relation between the latent representation of the query sample and training samples, and identify the training samples with higher similarity as the prototype. The classification decision is based on the label consistency between the identified prototypes (with the relation score in attention mechanism as the weight of different prototypes in determining the  label agreement)",0.19230769230769232,0.19480519480519481,0.1935483870967742
234,SP:166a31355f4b6ef5d0b2594b01eea5229ef03a4a,"This paper generalizes a family of score-based generative models that rely on sequences of noise scalings of the data and extends them to the continuous domain, which leads to an SDE-based framework. By using score-matching, the forward SDE, which transforms data into a tractable noise distribution, can be reversed and thus used as a generative model. This is then improved by employing a two-phase algorithm with a prediction step, followed by a tunable number of correction steps. Further, reformulating the problem as a neural ODE allows for exact likelihood computations and reduces the number of required function evaluations. The framework enables unconditional, as well as conditional samples.","This paper presents a generative model based on stochastic differential equations (SDEs), which generalizes two other score-based generative models score matching with Langevin dynamics (SMLD) and denoising diffusion probabilistic modeling (DDPM). The recipe to sample from the data distribution is based on (i) the observation that both SMLD and DDPM can be formulated as the discretization of an SDE, (ii) the finding from Anderson (1982) about the reverse of an Ito process, (iii) a score model. A novel aspect of the presented technique is the use of the score model as ""predictor"", which gives the initial sample from the MCMC sampler that serves as ""corrector"". Finally, the Ito process induced by the reverse SDE is formulated in a deterministic manner, leading to a neural-ODE based generative model.",0.23423423423423423,0.20155038759689922,0.21666666666666667
235,SP:168f23644e133a08f2e16ee31b0a8f0620aea96d,"This paper presents an approach to distill a model-based planning expert into a policy to enable real-time execution on robotic systems. An improved version of the Cross-Entropy Method, iCEM is used to generate trajectories via model-based optimisation where the forward model is the ground-truth simulator dynamics. The expert is further improved by warm-starting using the learned policy. The policy is learned via imitation learning of trajectories from the expert. Several approaches for this step are presented, including the vanilla approach of behaviour cloning (BC), dataset aggregation (DAGGER) to reduce covariate shift and Guided Policy Search (GPS) where the planner is encouraged to keep close to the policy distribution via a trust region KL loss. The paper discusses the merits of each approach and proposes Adaptive Policy Extraction (APEX), an approach that learns the policy from the expert through a combination of DAGGER and GPS where the tradeoff between the cost terms on planner exploration and policy trust region KL is set adaptively. This approach is tested on four continuous control tasks and achieves good performance compared to baselines — the learned policy gets significant improvements compared to the baselines. Additionally, a study that ablates different parts of the APEX algorithm is also presented.","In summary, this paper combines GPS and DAgger to learn a policy network by imitating a model-based controller, which uses iCEM as the optimizer. Their approach uses both the iCEM controller and the learned policy with DAgger-like relabeling to collect data and then train the network with behavior cloning. An auxiliary loss inspired GPS, which encourages the consistency between the expert controller and the learned policy, together with an adaptive weighting method, is added to reduce the multi-modal issue. The experiment results show promising results.",0.1346153846153846,0.3181818181818182,0.18918918918918917
236,SP:16cb7d0da739f1e6a72efb9b18399d2d8b69f540,"This paper proposes to apply the Neural ODE framework (Chen et al 2018) for image segmentation. The method relies on contour delineation through Level Sets. Since contour estimation requires to solve an ODE, this naturally allows to apply the work presented in (Chen et al 2018). The method is here applied in two segmentation tasks: kidney segmentation and salient object detection.",This paper proposes to utilize Neural ODEs (NODEs) and the Level Set Method (LSM) for the task of image segmentation.  The argument is that the NODE can be used to learn the force function in an LSM and solve the contour evolution process. The authors propose two architectures and demonstrate promising performance on a few image segmentation benchmarks. ,0.2459016393442623,0.25862068965517243,0.25210084033613445
237,SP:1707af8ace423f653ad0355d3a363fa1af8c7daf,"Paper summary: This paper proposes a new normalization technique specially designed for settings with small mini-batch sizes (where previous methods like BatchNorm are known to suffer). The approach aggregates mean/variance statistics from previous iterations, weighted based on the Taylor expansion, to get a better estimate of population statistics. The authors evaluate their approach on ImageNet classification, and object detection and instance segmentation on the COCO dataset.","This paper proposes a novel Cross-Iteration Batch Normalization (CBN) to address the limitation of BN in the case of small mini-batch sizes. Different from existing methods, CBN exploits the statistics cross different iterations to obtain more accurate estimates of the data statistics. Specifically, the proposed CBN uses Taylor polynomials to approximate the statistics using the information of multiple recent iterations. The experiments on both image classification and object detection tasks demonstrate the effectiveness of the proposed method.",0.35294117647058826,0.3037974683544304,0.326530612244898
238,SP:1729cec6853e24f07e2dbb98b9323be61dc7a155,The paper proposes a method to find adversarial examples in which the changes are localized to small regions of the image. A group-sparsity objective is introduced for this purpose and it is combined with an l_p objective that was used in prior work to define proximity to the original example. ADMM is applied to maximize the defined objective. It is shown that adversarial examples in which all changes are concentrated in just few regions can be found with the proposed method.,"The paper proposes a novel approach to generate adversarial examples based on structured sparsity principles. In particular the authors focus on the intuition that adversarial examples in computer vision might benefit from encoding information about the local structure of the data. To this end, lp *group* norms can be used in contrast to standard global lp norms when constraining or penalizing the optimization of the adversarial example. The authors propose an optimization strategy to address this problem. The authors evaluate the proposed approach on real data, comparing it against state-of-the-art competitors, which do not leverage the structured sparsity idea.",0.26506024096385544,0.21568627450980393,0.23783783783783785
239,SP:1741e81fd3c843daf88493f2272185aa6dd67db8,"Normalization methods are effective optimization hacks that allow training deep neural networks. In this paper, different normalization methods for training neural networks are collectively studied. The focus of the paper is mostly on designing experiments that show how normalization methods allow faster training for deep neural networks.  In particular, they are studied from two main aspects:  1. The change of gradient norm (at the random initialization) when the network grows in depth.  2. The similarity of hidden representations when weights are initialized randomly.    (1) It is experimentally and theoretically shown that the normalization method can be classified into two groups: one suffering from the exponential gradient vanishing, while the other group is more robust against in terms of the norm of the gradient (in presence/absence of residual connections).    (2) First it is shown that the similarity of hidden representation (measured by pair-wise cosine similarity of inputs) is well correlated with the optimization speed. Therefore, one can predict the performance of optimization methods by this metric. Recent results confirm that BN provides distinctive features when the weights are initialized randomly. Here it is experimentally shown that this results in more normalization techniques such as group normalization.  Finally, the issue of the decay of norm of gradient is more carefully studied where it is shown that the norm of gradient although do not exponentially decay (or explodes), yet may decay through the layers which decay rate determines the optimization speed of normalization methods. ","This paper summarizes multiple aspects of a variety of normalization schemes and what makes them work or not work. Specifically, the authors analyze properties that prior works have found to be critical in BatchNormalso in the context of other normalizers (like GroupNorm), thus arguing for a more unified understanding and insight towards these normalization components. The discussion and thus contribution can be broken into three parts: stable activation, discriminative representation and gradient explosion analysis.",0.06584362139917696,0.21621621621621623,0.10094637223974763
240,SP:175791387c30347cc7f014645095f3a2c82a6c32,"This study deals with the issue of interpretability in the analysis of time series data using deep learning models. Six metrics for evaluating interpretation methods are introduced and nine existing interpretation methods are evaluated. One of these metrics is proposed by the author. One of the metrics is based on an experimental evaluation, which shows that none of the methods is superior in all the metrics.","This paper studies deep neural network (DNN) explainability methods in the context of time-series data. Several metrics exist for evaluating the validity of DNN explainability methods on computer vision tasks. However, it is not clear whether these metrics are reliable when applied to DNN explainability methods on time-series data. This paper conducts experiments to compare 6 of those metrics on time-series classification and segmentation tasks. ",0.24242424242424243,0.23529411764705882,0.23880597014925375
241,SP:175cebd43567cc9d427396e2726aca35543c9b28,"This paper presents an LSTM-based model for bug detection and repair of a particular type of bug called VarMisuse, which occurs at a point in a program where the wrong identifier is used. This problem is introduced in the Allamanis et al. paper. The authors of the paper under review demonstrate significant improvements compared to the Allamanis et al. approach on several datasets.","This paper considers the problem of VarMisuse, a kind of software bug where a variable has been misused. Existing approaches to the problem create a complex model, followed by enumerating all possible variable replacements at all possible positions, in order to identify where the bug may exist. This can be problematic for training which is performed using synthetic replacements; enumeration on non-buggy positions does not reflect the test case. Also, at test time, enumerating is expensive, and does not accurately capture the various dependencies of the task. This paper instead proposes a LSTM based model with pointers to break the problem down into multiple steps: (1) is the program buggy, (2) where is the bug, and (3) what is the repair. They evaluate on two datasets, and achieve substantial gains over previous approaches, showing that the idea of localizing and repairing and effective.",0.328125,0.14583333333333334,0.2019230769230769
242,SP:17933143c0bc4e7957ce9ea48d8b50d55dd98570,"This paper focuses on the pseudo-labeling bias issue in semi-supervised object detection (SS-OD), and proposes an Unbiased Teacher framework to address this issue. More specifically, the unbiased teacher framework combines the Mean Teacher model for semi-supervised image classification (Tarvainen and Valpola 2017) and Focal Loss (Lin et al. 2017) for fully supervised object detection to address the bias issue. Experiments on COCO and PASCAL VOC show that the proposed method obtains the state-of-the-art semi-supervised object detection results.","This work tackles the task of semi-supervised object detection via a teacher-student method. The authors introduced a training regime where a teacher and student network, who share the same initial weights pre-trained on labeled data, jointly learns on unsupervised data. They find that label imbalance in the object detection task can lead to inefficient pseudo-label training under the usual SSL training pipeline, and therefore proposes to train the teacher network via exponential moving average to avoid bias in pseudo-labels.",0.18823529411764706,0.19047619047619047,0.1893491124260355
243,SP:17b190a22502276c14bd0c82c5bcbe854a7afcbe,"Knowledge Graph Embedding (KGE) methods solve link prediction problems by learning node embeddings and a score function such that the correct triples are ranked the highest. On the hand, AnyBURL is a symbolic alternative which learns rules for ranking triples. The paper proposes a simple aggregation approach for combining the ranking results from KGE methods with those from AnyBURL. The motivation of this approach is to ultimately harness the strengths of both symbolic and sub-symbolic methods. The method is evaluated by studying the improvement in link prediction performance using benchmark datasets.","The paper presents a comparative study on symbolic methods and embedding methods for knowledge graph completion. From the manually observed ranking results of two kinds of approaches, the authors find that rule-based method AnyBURL tends to perform well on complicated rules that express transitivity of multiple relations, and that KG embedding methods sometimes will output meaningless result due to its learned similarity measure, which may be remedied by rule-based methods. Accordingly, a simple aggregation reranking approach is also proposed, and it shows promising performance gain for several embedding approaches in the KG completion task. ",0.15217391304347827,0.14583333333333334,0.14893617021276595
244,SP:1811e49ae2fadeeb486fb1058875193137f20675,"The paper is concerned with the non-asymptotic analysis of SDE-based sampling algorithms and has two main contributions. Firstly, it improves upon the general framework of [Li et al. (2019)](https://proceedings.neurips.cc/paper/2019/hash/7d265aa7147bd3913fb84c7963a209d1-Abstract.html) and, in particular, does not require uniform boundedness assumptions for the local strong/weak errors. This means their first result, Theorem 3.3, is easier to apply to numerical schemes for contractive SDEs and can already be seen to unify previous works (such as the analysis of KLMC in [Dalalyan et al. (2020)](https://projecteuclid.org/journals/bernoulli/volume-26/issue-3/On-sampling-from-a-log-concave-density-using-kinetic-Langevin/10.3150/19-BEJ1178.short)). Secondly, the authors consider the Unadjusted Langevin Algorithm (ULA) and derive a 2-Wasserstein bound of $\mathcal{O}(\sqrt{d} h)$, which has optimal dependence on both the dimension $d$ and step size $h$. To achieve this, they impose an additional smoothness condition on $f$ that is less restrictive than having the Hessian $\nabla^2 f$ Lipschitz continuous. The authors support this theory with numerical examples, where they demonstrate that a lower bound on the 2-Wasserstein error scales as $\mathcal{O}(\sqrt{d})$ and $\mathcal{O}(h)$.","The manuscript considers the unadjusted Langevin Monte Carlo (LMC) algorithm, and performs non-asymptotic analysis of its convergence with respect to the 2 Wasserstein distance. The main contribution is a mixing time bound of O(d^0.5/\epilson), which improves upon the existing O(d/\epsilon) bound of Durmus and Moulines. The O(d^0.5/\epilson) is also shown to be optimal for the classes of probability distributions considered. ",0.10194174757281553,0.29577464788732394,0.15162454873646208
245,SP:1816aac16c30b8d1893f7477073c258e17d4e924,"This articles provides bounds for both average case and worst case complexity (in terms of number of linear regions and related measures) for max-out networks. I found the article to have a few results that were interesting (to do with the difference between ReLU and max-out), a few results that were correct but rather incremental (average case analysis of number of regions for max-out networks), and one result whose proof I cannot understand (though it may well be true).   After rebuttal: I am satisfied with the replies of thr authors and am raising my score by 1.","EDIT: I have read the authors' response and decided to keep my (positive) score.  The paper studies the problem of expressivity of feedforward neural networks with maxout (multi-argument) activation functions. Maxout units compute parametric affine functions followed by a fixed multi-argument activation function of the form (s1, . . . , sK)→max{s1, . . . , sK}.  A special case of course is ReLU nets, and many prior results have been obtained, showing how the activation patterns and linear regions of the network depend on the architecure of the network, mainly the depth and the width. For example, Telgarsky's ""Benefits of depth in neural networks."" paper, shows how depth in neural nets can be exponentially more efficient that width in representing certain functions like the triangular wave and compositions with itself.   The question that is raised here however is how do the linear regions of maxout nets look like for ""practical"" neural nets. Practical here, just means networks initialized with a multitude of different distributions that are common in practice. The importance of this question is motivated by understanding average case performance instead of worst-case performance. This reflects an approach originally put forth by two works of Hanin and Rolnick.  Briefly, the main results of the paper generalize prior results for ReLUs to the case of maxout networks. For example, the main result of the paper is Theorem 9 and 10 that state that for most parameter settings in the network, the expected number of activation regions is polynomial in the number of units. This comes in contrast with Telgarsky's and follow-up works that give exponential bounds for deep ReLU nets.    ",0.24,0.08856088560885608,0.12938005390835577
246,SP:1825c30065e8b8629156aacad3503cdbcd12a9a2,"This paper proposed a preconditioned gradient descent (PreGD) method for low rank matrix factorization. In practice, the true rank r* of the matrix is unknown. To be conservative, people usually choose an over-estimated r to start with. However, in such case, the convergence of local search algorithms falls from a linear rate (r=r*) to a sublinear rate (r>r*). The PreGD method proposed in this paper restores the linear convergence rate for the r>r* case. Numerically, it is also found that the PreGD method works well in restoring the linear convergence for some variants of the problem.","The authors consider low-rank matrix recovery problems, where the $n\times n$ matrix variable $M$ is factorized as $M=XX^T$, for some $X$ of size $n\times r$, with $r\ll n$. It is known from previous work that, although they are typically non-convex, these problems can oftentimes be solved through simple gradient descent over $X$, applied to a suitable loss function.  However, gradient descent tends to converge very slowly when either the ground true matrix is ill-conditioned, or the problem is overparameterized (that is, $r$ is strictly larger than the rank of the ground true matrix). In Reference [11], Tong, Ma and Chi have proposed a gradient preconditioner which solves the slow convergence issue when it is due to ill-conditioning. However, the method does not work when the problem is overparameterized.  In this article, the authors propose a refined preconditioner, which accommodates both ill-conditioning and overparameterization. In the particular setting of RIP matrix sensing with least-squares cost, they show that, with this preconditioner, gradient descent converges linearly in a neighborhood of the solution, up to the unavoidable statistical error.",0.24,0.12834224598930483,0.1672473867595819
247,SP:182b04893072dc8b62cf379b19fb8fdec105b516,The authors of this article experimentally investigate whether flatness of the loss surface can be a good measure for generalization capabilities of neural networks. They present theoretical reasoning that suggests that weight regularization can lead to sharper local minima and better generalization although it is expected that flatter minima generalize better. Several experiments are conducted that support this interplay of weight regularization with sharpness. Finally it is demonstrated that also different optimization techniques lead to results that question the validity of purely flatness based measures.,"This paper argues that as the cross-entropy loss goes to zero, since the correct logit increases in magnitude the entries of the Hessian diminish to zero. Such overfitting on the training set and a small spectral norm of the Hessian should result in poor generalization error. Motivated by this, the paper experimentally evaluates the effect of weight decay on the Hessian controls the magnitude of weights, increases the spectral norm of the Hessian and improves the generalization.",0.1411764705882353,0.15384615384615385,0.147239263803681
248,SP:1830f1de980c64c2437f40e155e0c272be063043,"This paper proposes a framework for contractive active inference, leveraging contrastive learning to improve active inference in a self-supervised manner. Experiments in goal-conditioned tasks show the proposed algorithm works comparably with reward-based reinforcement learning methods and outperforms the non-contrastive variant of its own. Experiments in an image-based learning task show the proposed method can reach the desired goal despite visual differences in background.","This work proposes an active inference implementation that scales in high dimensional observations and continuous actions spaces. To achieve this the authors propose to replace the reconstruction required to optimize the free energy objective with the contrastive loss which aims to maximize the mutual information between the state and the observation at each timestep and is more robust under distractors and low capacity models. They show comparable performance to state of the art model-based RL baselines (dreamer, CVRL) and they demonstrate robustness under distractors setting. Also, the provided code is great and that would make a very nice contribution as well (the existing implementations of AIF are too difficult to parse I think)",0.19117647058823528,0.11403508771929824,0.14285714285714282
249,SP:183f775e3c461066fc88446883bb458fb8d6d607,"This paper is introducing a learning method which combines both Imitation Learning and Reinforcement Learning, such that an autonomous learner can leverage prerecorded expert knowledge. In comparison to previous work, this model has an expert cost function which gives priority to the expert behavior, not only using the expert demos (like in DQfD), but also with a model trained with those demos using  behavioral cloning, such that it could be evaluated in states that were not visited during the demonstrations. Additionally, new executions of the learner that have high performance are included in the buffer for training the policy imitating the expert, since they can also be considered new better demonstrations.","This paper proposes integrating deep Q-learning from dynamic demonstrations with a behavioral cloning model (DQfDD-BC). Compared with DQfD, the proposed approach introduces a behavior cloning model, which was first pre-trained by leveraging historical demonstrations and then updated using generated dynamic demonstration. The BC model is used in the expert loss function, where the DRL model's actions are compared with those obtained from the BC model for policy improvement guidance. The experimental results in OpenAI Gym environments show that the proposed approach adapts well to different demonstrations' imperfection levels and accelerates the learning processes. The ablation study also indicates that the new method improves the learning convergence performance compared with the original DQfD model.",0.1891891891891892,0.1794871794871795,0.1842105263157895
250,SP:1879f9692f92bb2249772e14f27839d9e426f9b3,"This paper provides an interesting application of GAN which can generate the outlier distribution of training data which forces generator to learn the distribution of the low probability density area of given data. To show the effectiveness of the method, the author intuitively shows how it works on 2-D points data as well as the reconstructed Mnist dataset. Additionally, this approach reaches a comparable performance on semi-supervised learning and novelty detection task.","This paper proposed DSGAN which learns to generate unseen data from seen data distribution p_d and its somehow “broad” version p_{\hat d} (E.g., p_d convolved with Gaussian). The “unseen data” is the one that appears in p_{\hat d} but not in p_d. DSGAN is trained to generate such data. In particular, it uses samples from p_d as fake data and samples from p_{\hat d} as the real one. ",0.1891891891891892,0.18421052631578946,0.18666666666666668
251,SP:189665e20164d1d5e70e4185afca18b2d0f8bdb9,"This paper proposes to use auto-encoder for inverse reinforcement learning. The main goal of using the auto-encoder, is to use it as the reward function, which takes the auto-encoder reconstruction error to provide reward signals for the agent. The authors claim that such approach provides more informative signal than existing works, especially adversarial imitation learning approaches. Their experiments demonstrate that this method has a better performance over other baselines, and more robust to demonstration noise.","This paper proposes the Auto-Encoding Inverse Reinforcement Learning (AEIRL) method for better imitation learning, especially in the presence of noisy expert demonstrations. The paper’s key insight is that auto-encoders can eliminate the effects of noise from expert demonstrations and provide a more stable reward signal based on the auto-encoder error. The experiments feature extensive analyses across standard benchmarks compared to a large number of baselines. ",0.2692307692307692,0.30434782608695654,0.28571428571428575
252,SP:18ce50996a98836e07d8cb448adbff5cb039b285,"This paper analyzes the side effect of knowledge distillation in NAT where the lexical choice errors on low-frequency words are propagated to the student model from the teacher. Tackling on this, the paper then proposes to expose raw data to restore such information. In my view, the submission is well motivated and the designed experiments and results are meaningful and convincing which deserves an accept. However, as the paper focuses on analyzing a specific point (lexical choice) in a very constrained setting (NAT), the overall contribution might be incremental compared to other works in general at such a venue like ICLR.","This paper follows up on the work (Zhou et al.) on establishing the importance of knoweldge distillation (KD) from a pretrained autoregressive translation model (AT) to train effective non-autoregresstive translation (NAT)  models. Specifically, KD is helpful because it reduces the data complexity which allows successful training of NAT models. This paper shows that KD has an undesirable effect on training of NAT models in terms of poor performance on translation into infrequent tokens and further suggests a remedy for regularizing the NAT training with an additional lexical translation loss based upon a prior translation table obtained via word alignment.",0.1568627450980392,0.16,0.1584158415841584
253,SP:18ddfe1194f8f8c208068c83157cb7935b962c7a,"The paper proposes to use graph neural networks (GNN) for inference in MLN. The main motivation seems to be that inference in traditional MLN is computationally inefficient. The paper is cryptic about precisely why this is the case. There is some allusion in the introduction as to grounding being exponential in the number of entities and the exponent being related to the number of variables in the clauses of the MLN but this should be more clearly stated (e.g., does inference being exponential in the number of entities hold for lifted BP?). In an effort to speed up inference, the authors propose to use GNN instead. Since GNN expressivity is limited, the authors propose to use entity specific embeddings to increase expressivity. The final ingredient is a mean-field approximation that helps break up the likelihood expression. Experiments are conducted on standard MLN benchmarks (UW-CSE, Kinship, Cora) and link prediction tasks. ExpressGNN achieves a 5-10X speedup compared to HL-MRF. On Cora HL-MRF seems to have run out of memory. On link prediction tasks, ExpressGNN seems to achieve better accuracy but this result is a bit difficult to appreciate since the ExpressGNN can't learn rules and the authors used NeuralLP to learn the rules followed by using ExpressGNN to learn parameters and inference.","This paper proposes a framework for solving the probabilistic logic reasoning problem by integrating Markov neural networks and graph neural networks to combine their individual features into a more expressive and scalable framework. Graph neural networks are used for learning representations for Knowledge graphs and are quite scalable when it comes to probabilistic inference. But no prior rules can be incorporated and it requires significant amount of examples per target in order to converge. On the other hand, MLN are quite powerful for logical reasoning and dealing with noisy data but its inference process is computationally intensive and does not scale. Combining these two frameworks seem to result in a powerful framework which generalizes well to new knowledge graphs, does inference and is able to scale to large entities. ",0.11467889908256881,0.1937984496124031,0.1440922190201729
254,SP:18de04936d8fc216f861fd000e156957311ea391,This paper presents experimental data supporting the claim that the under aggressive hyper-parameter tuning different optimizers are essentially ranked by inclusion --- if the hyper-parameters of method A can simulate any setting of the hyper-parameters of method B then under aggressive hyper-parameter tuning A will dominate B.  One way to achieve this rather trivially is to do a hyper-parameter search for B and then set the hyper-parameters of A so that A is simulating B.  But the point here is that direct and feasible tuning of A with dominate B even in the case where A has more hyper-parameters and where hyper-parameter optimization of A would seem to be more difficult.  An important conclusion is that without loss of generality one can always use Adam even in vision where SGD is currently the dominant optimizer used in practice.  Another important conclusion is that quasi-random hyper-parameter optimization is quite effective.,"The paper provides an empirical comparison of a set of first-order optimization methods for deep learning models. Those optimizers include stochastic gradient descent, momentum  method, RMSProp, Adam, Nesterov, and Nadam, which arguably covers all popular variants used in the literature. Although it is not the first empirical study on this topic, its conclusion differs slightly. The conclusion is a rather intuitive one: With proper parameter search, the 'richer', more powerful optimizers tend to work better, regardless of the downstream tasks. ",0.10759493670886076,0.20987654320987653,0.14225941422594143
255,SP:18de06d24b04d5bda2a3f7d6c3cd4f28076cfee5,"This paper revisits the Lottery Ticket Hypotheis (LTH), where aggressively pruning a neural network in a smart way allows it to retain its convergence properties, at a lesser computational cost.  The authors advance an explanation relating this LTH to expanders, graphs that have the property that information circulates really well between the vertices, and then to Ramanujan graphs. They then propose an algorithm built on this premise, that prunes the graph as long as the ramanujan property is still satisfied.  Finally, a wealth of experiments is shown, showing the relation between the Ramanujan property and the performance of the pruned network. The authors also test the performance of their Ramanujan pruning algorithm against the same datasets.","In this paper, the authors study the properties of the subnetworks in lottery ticket hypothesis (LTH) from the perspective of the spectral graph theory. They argue that the pruned network in LTH remains a Ramanujan graph. The performance of the subnetworks begins to degrade with the loss of Ramanujan graph property. To this end, they propose an eigen-bound based network pruning algorithm to preserve the graph property. Extensive experiments are conducted to demonstrate the effectiveness of the proposed method.",0.21551724137931033,0.3125,0.25510204081632654
256,SP:18e3aa22c55669fd93fff33b31cb023cc5a4e9f6,"This paper presents a new method called Fourier temporal state embedding. The motivation for this approach is unclear and should be appropriately justified. In the abstract and introduction, the claim appears to be that previous methods are not time nor memory-efficient, and therefore FTSE is proposed. But this is obviously not true. So it is unclear what this new approach offers compared to the state-of-the-art. In Table 1, why not report performance for more standard baselines like CTDNE? The clarity and writing of this work require significant improvement. There are many incomplete and incorrect sentences throughout the paper that make it difficult if not impossible to understand. In the problem formulation, CTDG and DTDG were originally introduced in the CTDNE paper, but instead a more recent 2020 paper is referenced. Many of the ideas are never fully explained properly. The labels in nearly all the figures need to be appropriately sized, as they are impossible to read. ","The article presents a new approach for learning representations of dynamic graphs. The method is based on Fourier Transform of edges over time, and separate GCNs are used for each Fourier mode (N FTSE) to stain temporal embeddings. Numerical results illustrate the performance of the method on there graph tasks, namely link prediction, node and edge classifications.",0.08695652173913043,0.24561403508771928,0.12844036697247704
257,SP:18e66c7bb3cdc322261ebc06a7efc1e059d28603,"The paper provides a nearly optimal bound for consistency of kernel $k$-means clustering and gives an approximation scheme based on the Nystrom method that allows one to perform scalable data quantization. More specifically, a new upper bound in $\sqrt{\frac{k}{n}}$ is obtained for the excess risk in kernel $k$-means, which improves the state-of-the-art excess risk bound in $\frac{k}{\sqrt{n}}$. The same bound for the Nystrom approximation of the algorithm are also provided.","In this paper, the authors provide a near-optimal risk bound for kernel $k$-means, namely $\tilde{O}(\sqrt{k/n})$, which improves upon the existing risk bound $O(k/\sqrt{n})$, and nearly matches the lower bound $\Omega(\sqrt{k/n})$, where $k$ is the number of clusters and $n$ is the size of the training set. They first derive a near-optimal risk bound for the empirical risk minimizer (ERM) and then extend it to general cases beyond ERM and $k$-means++. For efficiency, the authors also provide near-optimal risk bounds for Nyström kernel $k$-means for the case of using $\tilde{\Omega}(\sqrt{n})$ sampling points. The authors have performed numerical experiments to validate their theoretical findings. ",0.3333333333333333,0.22131147540983606,0.2660098522167488
258,SP:18f1b4ab7592fdcc814514e832b766dbb196d2b4,Abstract: The paper proposed a way to learn unbiased (debiased) concept-based explainable models in the presence of unobserved confounders by the use of labels as instrumental variables. The proposed algorithm has 3 main steps: (1) regresses concept labels from the final labels (2) replace the original concepts with the learnt concepts and learn a model of debiased concepts as a function of features (3) predict label as a function of debiased concepts. The authors show in the experimental section that their training method captures the most salient concepts using the ROAR (Remove and Retrain) evaluation framework much better than the vanilla (non de-biased) approach. ,The focus of the work is on model interpretability using concept-based explanation. The authors consider the issue of concepts being correlated with confounding information in the features. They propose a causal graph for representing the system and use instrumental variable methods to remove the impact of unobserved confounders. The proposed method is evaluated on synthetic and real data.,0.14150943396226415,0.2542372881355932,0.18181818181818182
259,SP:19147e08c4a7343bee155f8e74362d8214bb35e1,"The paper proposes a new Graph Neural Network (GNN) architecture that uses Feature-wise Linear Modulation (FiLM) to condition the source-to-target node message-passing based on the target node representation. In this way, GNN-FiLM aims to allow a GNN's message propagation to ""focus on feature that are especially relevant for the update of the target node."" The authors clearly describe prior GNN architectures, showing that the do not incorporate such forms of message propagation. The authors then describe several intuitive ways of adding such a form of message propagation, before describing why those approaches do not work in practice. Finally, the authors introduce GNN-FiLM, which is computationally reasonable and works well in practice, as evaluated according to several GNN benchmarks. The GNN-FiLM model is also quite simple and elegant, which makes me think it is likely to work on more tasks than the authors experiment on.","This paper introduces a new type of Graph Neural Network (GNN) that incorporates Feature-wise Linear Modulation (FiLM) layers. Current GNNs update the target representations by aggregating information from neighbouring nodes without taking into the account the target node representation. As graph networks might benefit from such target-source interactions, the current work proposes to use FiLM layers to let the target node modulate the source node representations. The authors thoroughly evaluate this new architecture — called GNN-FiLM—-on several graph benchmarks, including Citeseer, PPI, QM9, and VarMisuse. The proposed network outperforms the other methods on QM9 and is on par on the other benchmarks. ",0.23684210526315788,0.34285714285714286,0.2801556420233463
260,SP:191deadf446a81f8f373cb3766616501d75c0bb9,"The authors present a VAE for multivariate time series generation. The authors add additional decoder building blocks modelling level, trend and seasonality components of time series. Their method, named TimeVAE, is evaluated on four different datasets. Performance measures of generated samples are the similarity to real samples and the predictive quality of generated, “future” time steps. ","This work proposes a generative model architecture for time-series that is trained using the variational auto-encoder framework. The main motivation for this model is (a) to obtain a more sample efficient model compared to comparable models based on generative adversarial networks (GANs), and (b) optionally incorproate domain knowledge in its design. The authors design a fairly general-purpose VAE architecture which can also incorporate intepretable decoder blocks. Results are carried out on a number of new datasets and compared to the aformentioned GAN based time-series models. The authors use two different metrics to evaluate the mismatch between genereated and real samples, and show that their TimeVAE performs better than the alternative models.",0.30357142857142855,0.14782608695652175,0.19883040935672516
261,SP:19318b52fa22d612f81c72457f9876d9abe7d701,"In this paper, the authors apply the Nesterov Accelerated Gradient method to the adversarial attack task and achieve better transferability of the adversarial examples. Furthermore, the authors introduce a scale transformation method to provide the augmentation on the model, which also boosts the transferability of the attack method. Experiments are carried out to verify the scale-invariant property and the Nesterov Accelerated Gradient method on both single and ensemble of models. All experiments turn out to be a positive support to the authors' claim.","This paper studies how to generate transferable adversarial examples for black-box attacks. Two methods have been proposed,  namely Nesterov Iterative Fast Gradient Sign Method (NI-FGSM) and Scale-Invariant attack Method (SIM). The first method adopts Nesterov optimizer instead of momentum optimizer to generate adversarial examples. And the second is a model-augmentation method to avoid ""overfitting"" of the adversarial examples. Experiments on ImageNet can prove the effectiveness of the proposed methods.",0.2261904761904762,0.2602739726027397,0.24203821656050953
262,SP:193d12eb279ffa266a2cba713e440c45d35bf0d6,"This work is motivated by some shortcomings of the classical pinball loss used to learn quantile models, like the required differentiability of the models and miscalibration issues. The pinball loss is also not naturally suited to build centered intervals. This work proposes alternatives ways for learning quantile models, addressing these shortcomings. Four methods are proposed: - Model Agnostic QR: it is a generic method based on conditional density estimation and standard regression. Therefore it is not particularly tied to differentiable models and doesn't use the pinball loss. - Combined calibration loss: a loss to be used instead of the pinball one, with the advantage of explicitly balancing  sharpness and calibration of the predictions. - Centered intervals: an alternative loss based on the Winkler score is proposed to train models providing centered intervals. - Group batching: a heuristic replacing uniform sampling for batch-based based methods, aiming at better individual calibration.","The authors propose a new quantile method called MAQR for uncertainty quantification. This method is based on estimating empirical CDFs for residuals locally and therefore suffers from the curse of dimensionality. To address the issue, the authors further propose an NNs based solution, where the proposed loss consists of a convex combination of two terms. The first term encourages average calibration and the second term encourages sharpness. Thus allowing the user to control the balance between the two. The paper also provides a theoretical result stating that the first term is indeed minimized by the true quantile function. The authors also propose a version of the method for estimating centered intervals as well.  The paper is concluded with a rather extensive empirical evaluation. ",0.1564625850340136,0.18699186991869918,0.17037037037037037
263,SP:1947cb313bad9ec8dfb9e00106e098872c2d07e9,"This paper proposes a robust training and defending method RGN by applying control gates with binary status. During the training, the proposed method generates adversarial examples in a clean-label attack manner and mitigates the adversarial perturbation through training on another path. During the inference, RGN finds a subnetwork to defend against adversarial attacks.","This paper proposed a new way to generate an ensemble of networks against adversarial attacks. Different from other methods, which train different sub-models, the proposed method repeats convolution layers multiple times and controls them with random gates.  The experiment demonstrates that it outperforms other ensemble training with a smaller computational overhead. ",0.18518518518518517,0.19230769230769232,0.18867924528301885
264,SP:19627e8bf14c8e3df33a53f02a2dd1469ef95132,"The paper proposes Variational Structured Dropout, an extension to variational dropout that uses a full covariance matrix to model the posterior at the pre-activations. This covariance matrix, after spectral decomposition, is parameterized as the product of T Householder matrices.  The new parameterization of the posterior does not suffer from the singularity issue of Variational Dropout. When using a diagonal posterior approximation, the singularity issue is that the approximate posterior has zero measure, which results in the KL-term being undefined. VSD avoids this by using a full covariance matrix thus ensuring that the approximate posterior has non-zero measure.  To train the model using the new parameterization, the authors optimize a new variational lower bound. This lower bound is a lower bound to the ELBO.  Regarding the prior, the paper advocates for using a hierarchical prior distribution where the prior is a zero mean Gaussian distribution over the weights, with the hyperprior determining the standard deviation.  The experiments first examine the impact of T, the number of matrices used to parameterize the approximate posterior. Next, large scale experiments on deep neural networks demonstrate the performance of VSD against a number of baseline Bayesian inference methods measuring both predictive performance and predictive entropy (for OOD detection). ","This paper introduces Variational Structured Dropout (VSD), a scalable method building on previous Variational Dropout methods, and with a structured representation of the variational noise. The paper derives the method, introduces a hierarchical prior, and provides results on many benchmarks while comparing to many baselines. VSD performs reasonably well in all benchmarks on uncertainty metrics and accuracy. VSD also performs well on out-of-distribution uncertainty experiments.",0.09223300970873786,0.2835820895522388,0.1391941391941392
265,SP:19ad4889e4e13927f7a6e5ab01d0b0e1ef925337,"The paper considers the expressivity and approximation properties of machine learning models where a parameterized quantum circuit is used to 'accelerate' a classical neural network. The results consider a model with a date encoder, a quantum circuit, and then a classical feedforward neural net for post-processing. To make the results non-trivial only models with asymptotically similar classical and quantum complexity are considered.","The problem studied in this work is of interest in the quantum machine learning community, as the power of small and noisy quantum computers for machine learning problems is far from being understood. Therefore, it is important to study the expressivity of quantum neural networks as function approximators. This work uses the model introduced by Tensorflow Quantum, where different neurons can be implemented on either quantum or classical computers.",0.1875,0.17391304347826086,0.18045112781954886
266,SP:19da05364c011428ab35e62ad40cebee6a1d10b5,"In this paper, the authors study the problem of ""calibration"" of long-tail object detection models. To be specific, they take an existing pre-trained object detector and modify its logits according to the number of samples in each class to obtain better logits/scores for each class. They demonstrate on the long-tailed LVIS dataset with different models that this significantly and consistently improves the performance of methods (in terms of both precision and recall). ","This paper presents a normalized calibration method for long-tailed object detection and instance segmentation task. Experimental resutls show that separately treating the background class and normalizing the scores over classes for each proposal are keys to achieving superior performance. Experiments are conducted on the LVIS dataset with diverse evaluation sets. Results shows that consistent improvement can be achieved by the proposed scheme, and  extensive analysis and ablation studies are provided. ",0.2631578947368421,0.28169014084507044,0.272108843537415
267,SP:19e84ea0dc79d30cfbdb25c0b768536f38820885,"This paper proposes a method that can deal with an active-learning scenario for the recently proposed semi-supervised learning method: MixMatch.  More specifically, the proposed method considers uncertainty measures to choose samples and a diversification step to ensure diversity within the sampled batch.  For uncertainty measures, the paper considers the simple maximum confidence and the gap between two most likely classes.  Additional augmentation techniques inspired from MixMatch are used.  For diversification, a clustering method and an information density method are considered.  Furthermore, the paper proposes a cost analysis model to compare labeled and unlabeled samples.  Experiments demonstrate the behavior of the proposed method.","The paper proposes to combine active learning techniques with MixMatch for semi-supervised learning. First, they review active learning and semi-supervised learning, especially MixMatch. Instead of traditional semi-supervised learning with a fixed set of labeled examples, they incrementally grow the labeled set as the training process goes on. They consider several different choices in active learning strategies: uncertainty measure and diversification. Diversification methods are used to balance the samples in different classes and ensure diversity. The cost analysis of adding labeled vs unlabeled data looks interesting. They perform an empirical evaluation on image benchmarks and improve over MixMatch.",0.21153846153846154,0.22,0.2156862745098039
268,SP:1a02536d11f939c007732cb7b8619107170e8c64,"The paper proposed an adaptive learned bloom filter. Rather than setting a threshold of prediction score, the paper partitions the score into several intervals; for query insider each interval, the paper either uses a group of independent hash functions to hash the query in one unified bloom filter or introduce an independent bloom filter. The paper proposes efficient ways to tune the hyper-parameters, and provides the analysis of the error. Experiments on two applications show the effectiveness of the proposed methods. ",This paper extends the Bloom filter learning by using the complete spectrum of the scores regions. It uses multiple thresholds and then varies the number of hash functions among different scores regions to obtain better trade-off. Detailed theoretical analysis provides guaranteed superiority over learned Bloom filter under some conditions. The experiments also show the two proposed methods outperform learned Bloom filter in FPR and memory usage.,0.21951219512195122,0.26865671641791045,0.24161073825503357
269,SP:1a3b5863b4113fd70eb6e9d252b555f58c7414b9,The paper presents a method to automatically select parameters to share between layers. It proposes to use a shape shifter network to either increase or decrease the number of parameters in the model. The parameters are mapped into parameter groups through a preliminary training step and k-mean cluster the layers. Layers in the same group share parameters. It will generate weights by downsampling or upsampling depending on the layer needs. The method is tested in Low Budget and High Budget regimes and on different tasks. It also shows that the method can be used together with distillation and pruning. ,"Parameter sharing can reduce memory footprint of neural networks and memory bandwidth requirements, but existing methods require manually tuning the sharing strategy. This paper uses a small phase of training to cluster the learned layer representations by groups. This allows networks to be scaled from small to large parameter counts (to be clear, number of trainable parameters) without changing the model architecture. Importantly, this procedure does not change the number of FLOPs in the model.   Experiments across a wide set of tasks and networks compare this approach with either (1) SWRN from Savarasese & Maire, 2019), or (2) existing hand-tuned parameter scaling from families of networks such as EfficientNet, DenseNet, or ALBERT.  ",0.17,0.15178571428571427,0.16037735849056603
270,SP:1a3c7f6292f21f226bb340e5b7193fce0a9e02ef,"This well-written paper addresses the restrictions imposed by binary communication channels on the deployment of latent variable models in practice. In order to range code the (floating point) latent representations into bit-strings for practical data compression, both the sender and receiver of the binary channel must have identical instances of the prior despite non-deterministic floating point arithmetic across different platforms. The authors propose using neural networks that perform integer arithmetic (integer networks) to mitigate this issue.","The paper presents a very important problem of utilizing a model on different platforms with own numerical round-offs. As a result, a model run on a different hardware or software than the one on which it was trained could completely fail due to numerical rounding-off issues. This problem has been considered in various papers, however, the classification task was mainly discussed. In this paper, on the other hand, the authors present how the numerical rounding-off issue could be solved in Latent-Variable Models (LVM).",0.11392405063291139,0.10344827586206896,0.10843373493975904
271,SP:1a3ec03a440c32b86c334c3d9ada7b63718ceb1e,"The reviewed paper considers the problem of 2D localization of an observer on a given topological map. A data-driven approach is proposed to solve the problem. While the topological map of the environment is required, no prior information is needed about the nature of the input signal. Moreover, no supervision (in terms of pairs of signal measurement and observer's location) is needed.  The work formulates the localization problem as the problem of learning a low-dimensional manifold, representing the input in their intrinsic space and then transport them to the given topological map by inferring correspondences between the two spaces. The work is built on two intuitions: 1. that the transformation from high-dimensional input to the intrinsic space can be modeled as a mapping that can be learned through a neural network; 2. temporal data is subject to gradual changes as the observer moves, suggesting that the data reside on a smooth, locally connected manifold;  Results from experiments on three different environments (and different sensory inputs) support the claims. ","This paper presents a new method for localization while being agnostic to input measurement signal's modality. Assuming a map is given, localization inside the map is formulated as a deep manifold learning problem, without needing the supervision of ground truth positions for each input measurement. The method utilizes differentiable optimal transport to solve the correspondence challenge in this formulation. The method is tested on several simulated image datasets and one real-world WiFi dataset.",0.11627906976744186,0.26666666666666666,0.16194331983805668
272,SP:1a784c5f8dbb82fdc12917a5789966a6ce1c6b09,This paper proposed a predictor based on the Transformer architecture to predict the performance of neural architectures in NAS. It proposed to use Laplacian matrix based positional encoding strategy to better represent the topology information to model the neural architectures. It also proposed a model-agnostic self-evolution framework that can fully utilize temporal information as guidance.,"This work leverages a transformer-based predictor network to approximate the accuracies of unseen architectures from a search space, for the purpose of NAS. The authors further proposed a ADMM-based method to accelerate the convergence of the predictor training. Experiments are conducted on NAS benchmarks and DARTS spaces.",0.22807017543859648,0.2653061224489796,0.24528301886792453
273,SP:1a9ccd94a645d76c015a116960899f08d3faaefe,The paper investigates the representation of modern neural networks from the perspective of kernels by extracting features from pre-trained network models. The authors show the effectiveness of the proposed neural fisher kernel (NFK) for both unsupervised and supervised learning tasks. A low-rank approximation strategy of NFK is adopted to reduce computational burdens.,"The paper proposes a new strategy for extracting compact and intuitive representations of the data from a neural network. The approach exploits the feature map associated with the kernel representation of a neural network. In particular, the authors consider the Neural Fisher Kernel and propose a series of linear approximations to make their approach scalable. ",0.3148148148148148,0.3090909090909091,0.3119266055045872
274,SP:1ac8384ea71a1d51086464a466cd3167da4336c1,The authors study the phenomena of self-introduced distributional shift. They define the term along with the term hidden incentives for distributional shift. The latter describes factors that motivate the learner to change the distribution in order to achieve a higher performance. The authors study both phenomena in two domains (one being a prisoner dilemma and the other a recommender system) and show how meta-learning reveals the hidden incentives for distributional shift. They then propose an approach based on swapping learners between environments to reduce self introduced distributional shift.,"The main idea of the paper: When using meta-learning there is an inherent incentive for the learner to win by making the task easier. The authors generalise this effect to a larger class of problems where the learning framework induces a set of Hidden Incentive for Distributional Shift (HIDS) and introduce Context Swapping, a HIDS mitigation technique. In the experimental section, the authors propos a HIDS unit test which then they employ to show that PBT (Population Based-Trainng), a popular meta-learning algorithm exhibits HIDS ant that context swapping helps fixing it. ",0.2222222222222222,0.2127659574468085,0.2173913043478261
275,SP:1ad6564eb0646836b013dfb9362b1cffd6136806,"This papers looks into stochastic gradient methods with the goal of avoiding saddle points in nonconvex optimization. The main contribution of this work is a *perturbed* stochastic gradient framework (called ""Pullback"") which, by using a particular normalization scheme, finds an $(\epsilon, \epsilon_H)$-approximate local minimum (that is, an $x$ s.t. $||\nabla F(x)|| \leq \epsilon$ and $\lambda_{\textrm{min}}(\nabla^2 F(x)) \geq -\epsilon_H$) in $\tilde{O}(\epsilon^{-3} + \epsilon_H^{-6})$ stochastic gradient evaluations. When $\epsilon_H = \sqrt{\epsilon}$ (referred to as the ""classic setting"" in the paper), their method results in a total of $\tilde{O}(\epsilon^{-3})$ stochastic gradient evaluations, which improves upon all previous perturbed methods. This rate also matches (in the classic setting) the rate previously attained by SPIDER-SFO+ (+Neon2) (though this previous method requires an additional negative curvature search routine).","The paper proposes a new approach called ""Pullback"" for escaping saddle points and finding local minimum that matches the same complexity as SGD. The approach perturbs a stochastic gradient estimators (SARAH/SPIDER) and STORM by an element uniformly on the ball of radius $r$. The proposed method is able to find an $(\varepsilon, \sqrt{\varepsilon})$-approximate local minima within $\mathcal{O}(\varepsilon^{-3.5})$ stochastic gradient evaluations. This is the fastest known algorithm achieving the optimal rate of $\mathcal{O}(\varepsilon^{-3})$. The proof techniques appear to be similar to previous works and the gradient estimator used to achieve this result is known. ",0.1702127659574468,0.23300970873786409,0.1967213114754098
276,SP:1b32bd6b0a6c8672c109415f6fcbbad4c13c40f4,"This paper presents a novel deep anomaly detection model. It combines two existing models: B-VAE and t-SNE. The B-VAE is trained unsupervised and learns an encoder and decoder which provide both an embedding and a reconstruction. Using t-SNE to reduce its dimensionality, the embedding is projected into a 2 dimensional space. An anomaly score function is defined that combines the reconstruction error and the distance in t-SNE space to the K nearest neighbor(s). Experiments are conducted with several image datasets (MNIST,FMNIST,CIFAR10,SmallNORB) and one timeseries dataset (Arrhythmia). For the image sets, the B-VAE model is implemented with a CNN, while for timeseries, a TCN is used. Comparisons are conducted showing the approach to be beat other SOT unsupervised methods, AnoGAN and ADGAN, by 63% and 22% respectively for MNIST and 8% and 2% for FMNIST (in terms of error reduction). For CIFAR-10 and FMNIST it is even demonstrated to beat a supervised SOT method CapsNET. Another experiment shows that t_SNE dramatically improves the performance over B-VAE alone. For the timeseries, the approach is not compared to other SOT approaches as the authors only provide an experiment showing that TCN beats CNN and LSTM for the implementation of the B-VAE. In addition the authors study the effect of the various parameters of the system, in particular the effect of the B in B-VAE and of alpha, the mixing factor between reconstruction error and kNN distance in t_SNE. 3D plots give a good idea on how to select optimal values for the various datasets. The impact of B is also shown on the t-SNE map for MNIST. Finally an ablation studies compares on MNIST the performance of the approach with t-SNE alone, reconstruction alone, and latent distance. On average over 4 digits taken as anomaly, the proposed approach dramatically outperforms the others.","In a paper a new way to compute anomality score (for a test point) is suggested. A paper is purely experimental, based on existing techniques to dimension reduction (beta-VAE and t-SNE). Given trained beta-VAE, latent vectors, obtained for training set, are feed into t-SNE algorithm. The overall anomality score for a test point is combined from 1-NN distances on t-SNE plot and reconstruction error of beta-VNE. ",0.07255520504731862,0.3150684931506849,0.11794871794871796
277,SP:1b41929d9d98d6c198b688533d8066bd53ad085c,"I machine learning, we often have training data representative of an underlying distribution, and we want to test whether additional data come from the same distribution as the training data (e.g. for outlier/anomaly detection, or model checking). One way to do this is to learn a model of the underlying distribution, and test whether the additional data fall within the typical set of the model. This paper points out that the typical set of the model may be very different from the typical set of the underlying distribution if the model is learned by maximum likelihood, in which case a test of typicality with respect to the model would be a poor test of typicality with respect to the underlying distribution. The paper shows theoretically that the intersection of the typical sets of an ensemble of models lies within the typical set of the underlying distribution, provided that (a) each model is a good enough approximation to the underlying distribution, and (b) the models are all sufficiently different from each other. Based on that, the paper argues that a better test of typicality would be to test whether the additional data fall within the intersection of the typical sets of the ensemble of models.","This paper analyzes and extends a recently proposed goodness-of-fit test based on typicality [Nalisnick et al., ArXiv 2019].  Firstly, the authors give bounds on the type-II error of this test, showing it can be characterized as a function of KLD[q || p_true] where p is the true data generating process and q is an alternative generative process.  The paper then shifts to the main contribution: an in-depth study of a Gaussian mixture simulation along with accompanying theoretical results.  The simulation shows that maximum likelihood estimation (MLE)---due to it optimizing KLD[p_true || p_model]---does not penalize the model for placing probability in places not occupied by p_true.  This means that while samples from p_true should fall within the model’s typical set, the model typical set may be broader than p_true’s.  Table 1 makes this clear by showing that only 30-40% of samples from the model fall within the typical set of p_true.  Yet >93% of samples from p_true fall within the models’ typical sets.  The paper then makes the observation that the models do not have high overlap in their typical sets, and thus p_true’s typical set could be well approximated by the intersection of the various models’ typical sets.  Applying this procedure to the Gaussian mixture simulation, the authors observe that ~95% of samples drawn from the intersection of the ensemble fall within p_true’s typical set.  Moreover, ~97% of samples from p_true are in the ensemble (intersection) typical set.  The paper closes by proving that the diversity of the ensemble controls the overlap in their typical sets, and hence increasing diversity should only improve the approximation of p_true’s typical set.             ",0.2766990291262136,0.1945392491467577,0.22845691382765532
278,SP:1b467d99fd9fb26c374247e68873d34596705f75,"The paper provides a theoretical analysis on the OGD based continual learning method. The method is in fact proposed by a previous paper (Farajtabar et al. 2019) and the current paper shows a generalization bound for the regression case. The result (Thm 3) compares the generalization bounds between SGD and OGD and shows OGD leads to a tighter bound. The theorem is also based on the bound on the Rademacher Complexity (Lemma 1).  The paper also suggests OGD+, which stores some data points from past tasks. They also present some experimental results on small benchmark datasets, and show OGD+ outperforms SGD and OGD.","The authors use a Neural Tangent Kernel (NTK) approximation of wide neural nets to establish generalization bounds for continual learning (CL) using stochastic gradient descent (SGD) and orthogonal gradient descent (OGD).  In this regime, the authors prove that OGD does not suffer from catastrophic forgetting of training data.  The authors additionally introduce a modification to OGD which causes significant performance improvements in the Rotated MNIST and Permuted MNIST problems.  OGD involves storing feature maps from data points from previous tasks.  The modified OGD method (OGD+) additionally stores feature maps from the current task.  ",0.1650485436893204,0.1827956989247312,0.17346938775510207
279,SP:1b47be635b5e4482f07bd7b811b9c60c3926c0f3,"This paper introduces a deep learning approach for physical simulation. The approach combines two networks for synthesizing 4D data that represents 3D physical simulations. Here the first network outputs an initial guess, and the second network adds details. The first network utilizes a set of precomputed deformations, while the weights can be set to generate different output shapes. The precomputed deformations are applied in a recurrent manner. The second network is a variant of STN. ","This is an application paper on dense volumetric synthesis of liquids and smoke. Given densely registered 4D implicit surfaces (volumes over time) for a structured scene, a neural-network based model is used to interpolate simulations for novel scene conditions (e.g. position and size of dropped water ball). The interpolation model composes two components -- given these conditions, it first regresses weights combining a set of precomputed deformation fields, and then a second model regresses dense volumetric deformation corrections -- these are helpful as some events are not easily modeled with a set of basis deformations. ",0.2,0.15789473684210525,0.17647058823529413
280,SP:1b685c4f7f4b3f02bda928ec42ae68d43d0e2668,"This paper proposes a scalable and efficient approach for finding adversarial physical modification to the video inputs of autonomous driving. Assuming the perturbations are in form of a collection of several rectangles, the model parameterizes the physical modifications. By simply ignoring the closed-loop of viewpoint sequence and frames, the model directly creating adversarial frames with compositing methods. Some approximated algorithms are used to ensure the model can be optimized by the gradient-based method. With the improvement above, the iteration speed of the model is greatly improved.","The paper proposes an end-to-end differentiable method for finding adversarial patterns to be added to the environment for autonomous driving. It utilizes image composition with homography thus it can compose the adversarial pattern into the image frames of all image frames of a driving sequence. Combined with a neural-network based controller which outputs the steering angle, the proposed method can find adversarial examples more efficiently comparing to a Bayesian optimization(BO) based baseline while resulting in trajectories with greater deviation.",0.20454545454545456,0.21686746987951808,0.21052631578947367
281,SP:1b7f475ba4940437760afea98ef7a455ba107109,"This paper focuses on how to fine-tune Contrastive Self-supervised Learning (CSL) models. In particular, it proposes a new fine-tuning method based on a hard-pair mining strategy. The authors provide a theoretical analysis to justify the benefits of supervised contrastive loss and then demonstrate empirically.  ","This paper proposes a fine-tuning method called core-tuning for Contrastive Self-supervised Learning (CSL). Core-tuning employs contrastive loss as a regularizer for preserving intra-class features and further improves the finetuned performance. Besides, hard sample mining, focal loss, and mixup are integrated to further boost the performance. The contributions are 1. explore the fine-tuning problem for CSL. 2. provide the theoretical analysis 3. good experiment result.",0.3333333333333333,0.22857142857142856,0.2711864406779661
282,SP:1b85502dd0f530ab9e7cff434190e1bf1bcdfab1,"The paper considers multi-task RL under the offline setting where the underlying system dynamics is the same but different task has a different reward function. Through experimental analysis, the authors argue that naive data sharing, while intuitive, can potentially degrade the performance due to distributional shift. To address the issue, this work proposes a simple, conservative data sharing scheme that only shares data among tasks that could potentially have a higher conservative Q-value estimate. Experimental results on several tasks validate that the scheme can often be effective.",This paper proposes a data-sharing strategy called CDS to tackle the distributional shift of the offline RL algorithm in the multitask setting. The authors reveal the problem of naive sharing strategies experimentally and theoretically. CDS achieves an overall advantage against naive sharing strategies in various multitask offline environments.,0.10112359550561797,0.1836734693877551,0.13043478260869568
283,SP:1b88352ce2990c6f3b996803f80cac7cfaabcfc3,"In this manuscript, the authors propose an approach that combines random search with the surrogate gradient information. To this end, the proposed method samples from the subspace of the surrogate gradients. This subspace is constructed by storing the previous surrogate gradients. After several assumptions, the authors also a give a discussion on variance-bias trade-off as well as a discussion on hyperparameter optimization. The manuscript ends with numerical experiments.","The paper proposes a method to improve random search by building a subspace of the previous k surrogate gradients, mixing it with an isotropic Gaussian distribution to improve the search. Results reported shows are good compared to other approaches for learning weights of neural networks. However, paper lacks clarity and is quite hard to follow.",0.14285714285714285,0.18181818181818182,0.16
284,SP:1bc27efda9dd80ce3cfabd6a1e16a904c85f37fc,"CCA is a generative model that learns a shared subspace based on  two (or multi) views of the data. Being generative, it might not have strong discriminative power for some downstream classification tasks. Previous approaches to infuse discriminative power into the shared subspace estimated by CCA are linear. So, this paper proposes to learn 1) non-linear 2) discriminative subspaces for CCA. The paper accomplishes this by simply adding a task specific term to the optimization objective of DeepCCA (Andrew et. al. 2013), which involves just adding a task-specific MLP on top and minimizing the associated loss-function. ","This paper addresses the problem of jointly performing CCA with task labeling. The problem is timely and important as it is challenging to perform CCA jointly with the task classification (see below) and hence previous work typically perform this in a pipeline - that is, first projecting the data using a pre-trained CCA and then training a task classifier using the projected representation. As the authors note, this may be problematic as CCA may delete important information that is relevant for the classification, if training is not done jointly. ",0.12121212121212122,0.1348314606741573,0.12765957446808512
285,SP:1bc5cf890e7e8ff9921c1754e3013df7223caa1d,"The paper achieves high probability excess risk bound with rate O(1/n) w.r.t n for DP models via uniform stability by using Generalized Bernstein condition under G-Lipschitz, L-smooth, and PL condition. Then the authors expand the result to a more general case, only requiring α-Ho ̈lder smoothness, Polyak-Łojasiewicz condition, and generalized Bernstein condition. But the result is worse than before, so in order to get a better result, they propose m-NGP algorithm to achieve O(1/n) high probability bound w.r.t n under α-Ho ̈lder smoothness, Polyak-Łojasiewicz condition, and generalized Bernstein condition. The authors also show the experimental better accuracy results of m-NGP compared to traditional gradient perturbation method on real datasets.","This paper analyzes the utility bounds of the gradient-perturbation based DP algorithm. They first provide DP by previous result (it is not the key point in this paper). Then, by applying the Generalized Bernstein condition, they give $O(p^{0.5}/(n\epsilon))$ high probability excess population risk bound under the properties Lipschitzness, smoothness, and PL condition. Furthermore, under the more general assumption (Holder smoothness), they analyze the utility bound but the result is not so good as before. So they propose an algorithm (called m-NGP) to improve it under the assumption Holder smooth, and it is claimed that the utility bound can be improved to $O(p^{0.5}/(n\epsilon))$. Their results are sharper than previous analyses in different settings: previous results require convex assumption but this paper requires PL condition. Moreover, experiments are performed to evaluate the accuracy of m-NGP.",0.2764227642276423,0.2328767123287671,0.2527881040892193
286,SP:1bd140af937b949ece558c8978306e3e04d02169,"This paper presents a new mechanism, called HIRE, to extract more information from the intermediate layers of pre-trained models, which will be further fused with the last layer of pre-trained models. The main contribution of this work is the newly proposed dynamic feature extractor HIRE and the fusion network. Experiments confirmed the effectiveness of the proposed method, and some interesting observations on the importance of different layers for different tasks were given (i.e. Figure 2). ","The paper proposes a method to improve the downstream performance of a pretrained Transformer on NLP tasks. The core idea is to not only use the output of the last Transformer layer for prediction, but let the model decide how to fuse the information from intermediate layers as well. To dynamically decide which intermediate layers to use depending on the input example, the model uses a mechanism conceptually similar to self-attention, which yields a normalized importance score for each layer. The importance-weighted sum then yields a complementary representation to the last layer. Lastly, another network produces a final, integrated representation from the output at the last layer and the complementary representation, which is then used for prediction.",0.23076923076923078,0.15126050420168066,0.18274111675126906
287,SP:1c0bc1ab70b7607f52d991c48ddad1c6b998a702,"This paper proposes a distillation method for BERT. The work is based on two-fold main ideas. First, as the student model is usually smaller in the number of parameters, the model capacity is limited. The authors propose to stack the layers that share parameters to counter this limitation. Second, the authors argue that the initialization of the student model is crucial, so they propose an pre-training strategy for boosting the student's performance.","This paper proposed a framework for knowledge distillation with smaller number of parameters.The authors proposed a new parameter sharing method that allows a greater model complexity for the student model. Another contribution is that a KD-specialized initialization method named Pretraining with Teacher’s Predictions can improve the student's performance. The author combined these two methods to improve the performance of the student model on existing tasks, which has surpassed the existing knowledge distillation baseline.",0.26666666666666666,0.2597402597402597,0.26315789473684204
288,SP:1c1b27e49b3df07bb7da0440a4ab0018d9d8440d,This paper explores a well motivated but very heuristic idea for selecting the next samples to train on for training deep learning models. This method relies on looking at the uncertainty of predictions of in the recent history of statements and preferring those instances that have a predictive uncertainty over the recent predictions.  This allows the training method to train on instances that are neither too hard nor too easy and focus on reducing the uncertainty whenever it has the greatest potential gain to do so.,"This paper proposes Recency Bias, an adaptive mini batch selection method for training deep neural networks. To select informative minibatches for training, the proposed method maintains a fixed size sliding window of past model predictions for each data sample. At a given iteration, samples which have highly inconsistent predictions within the sliding window are added to the minibatch. The main contribution of this paper is the introduction of sliding window to remember past model predictions, as an improvement over the SOTA approach: Active Bias, which maintains a growing window of model predictions. Empirical studies are performed to show the superiority of Recency Bias over two SOTA  approaches. Results are shown on the task of (1) image classification from scratch and (2) image classification by fine-tuning pretrained networks. ",0.22093023255813954,0.1484375,0.17757009345794394
289,SP:1c1c3b2f49eedccaf92dd4237203148995f41a92,"This paper proposes a new method to simulate the real-world noisy images, which seems further improve the performance of current deep denoiser. A slight and effective generator is elaborately designed, and may facilitates the research of noise generation. Besides, the proposed method combines lots of existing deep learning technologies, and surpasses the current SoTA by a large margin.",The authors propose a pixel-level noise-aware generative adversarial network (PNGAN). They improve the denoising performance by generating more realistic noisy images.  Quantitative experiments prove that the performance of the existing denoising model can be significantly improved after being trained with the synthetic realistic noisy images.,0.1694915254237288,0.2127659574468085,0.18867924528301885
290,SP:1c1dfcfd223ed681844ad09249052a51a6c1fcb0,"This paper proposes a new method for discovering the causal graph from time-series data when the time-series are generated by a non-stationary process. The method relies on previous work from Lowe et al, 2020 and proposes to condition the causal summary graph driving the (causal) edge generation between variables by a categorical state variable. The method is defined within a variational inference framework, where edges are state-dependent latent variables, based on which one can generate/reconstruct future observations and/or state variables. Results are shared on two synthetic datasets with promising performances.","This paper aims to solve the problem of causal summary graph extraction and time series reconstruction at the same time. They propose a conditional VAE based model. The model is conditioned on state variables $s$, which makes it different from a normal VAE. Experiments on two datasets show the method outperforms ACD on linear data and its performance drops as number of states increase with spring data. ",0.19791666666666666,0.2835820895522388,0.2331288343558282
291,SP:1c4488d4b73efbed04b1045b425d7804b405ce1f,"This paper proposes to treat the encoding and the decoding pairs symmetrically as a solution to OT problems. SWAE minimizes $p(x_d, z_d)$ and $p(x_e, z_e)$ in a jointly manner and shows better latent representation learning and generation. Moreover, the symmetric treatment for encoding and decoding shows an advantage in data denoising. ","This works proposes an new auto-encoder variant based on an Optimal Transport (OT) penalty.  While there are many such previous works of OT and auto-encoders, this work proposes a joint OT penalty on data and latent space. As the scalability of computing OT penalties in high dimensions is a concern, the authors address this by restricting to deterministic encoders and decoders in Theorem 1, an extension to joint distributions of Theorem 1 of Tolstikhin 2018. The resulting algorithm amounts to a loss involving L2 penalties for (1) the reconstruction loss (2) decoded latents (conditional on ""pseudo-inputs"") and real samples (3) encoded samples and the conditional latents. Next experimental results are shown on small-scale datasets (MNIST, Fashion-MNIST, Coil20, subest of CIFAR-10) and compared against the VAE, WAE-{GAN,MMD}, VampPrior, and MIM.",0.22807017543859648,0.0948905109489051,0.13402061855670103
292,SP:1c4adc8ff01ce8ca27baf0d7e438634fa84e26e7,"The paper proposes a method for learning partial orders based on learning fuzzy pairwise comparisons (smaller/greater/approximatively equal to), and the retaining of a set of representants in each chain in order to allow consistent result by consistency maximization. The method is applied to the problem of estimating the age based on faces. Extensions proposed are the learning of multiple disjoint chains on this dataset, manually partitioned or learned through an iterative assignment algorithm that has similarities with a soft expectation-maximization principle. Extensive experiments are done on the age estimation problem with comparison to exisiting approaches, and an application to aesthetic assessment is proposed in appendix.","This paper presents an order learning method and applies it to age estimation from facial images. It designs a pairwise comparator that categorizes ordering relationship between two instances into ternary classes of greater than, similar, and smaller than. Instead of directly estimating the class of each instance, it learns pairwise ordering relationship between two instances.",0.08333333333333333,0.16363636363636364,0.11042944785276074
293,SP:1c95e241fb7fd4765404c2a693e357f0302d878d,"This paper provides a general asymptotic characterization of the solution that comes from learning a mixture of K Gaussians under a supervised learning setting with arbitrary convex loss and regularization. The technique for proving the characterization is novel. Specifically, it constructs an approximate message passing sequence that admits state evolution equations, whose fixed point satisfies the optimality condition of the original problem. Equipped with the theoretical tools, the authors study both synthetic data (sparse Gaussian mixture and general K Gaussian mixtures) and real datasets to further understand (1) $\ell_{1}$ and $\ell_{2}$ regularization for sparse mixture models; (2) separability transition; and (3) quality of Gaussian mixtures as surrogate model. Interestingly, the experiments exhibit a high agreement between the theoretical and numerical values. ","The paper provides precise asymptotic solutions for learning Gaussian mixtures using generalized linear models. This work generalizes and extends previous works in this direction by allowing any means/covariance of each Gaussian component, any convex loss and any regularization. Beyond the theoretical analysis, the paper also studied several examples, including comparing Lasso and Ridge regression, comparing the theoretical vs practical learning curves on real data. ",0.12195121951219512,0.23076923076923078,0.1595744680851064
294,SP:1caa49bf9bbdaef9e62b26735be3698f25a13ca1,"The authors propose to perform joint inference over the depth and effective width of a deep neural network. The depth is modelled as a stochastic process (in particular a Beta process), which allows for the depth to be infinite in theory. Given a fixed maximum width, the effective width is determined using a conjugate Bernoulli distribution which models the dropout probability for each neuron in each layer.  ","The paper proposes a comprehensive but effective method to simultaneously perform inference for the NN depth and width. As the idea might not be new, the execution of the method is solid. The methodology is also linked to Bayesian information criterion with a theorem.",0.208955223880597,0.3181818181818182,0.2522522522522523
295,SP:1ccaa054dc814a12e6cea27fdc8cdd0d53b25794,"In this paper, the authors developed graph scattering transforms (GST) with a pruning algorithm, with the aim to reduce the running time and space cost, improve robustness to perturbations on input graph signal, and encourage flexibility for domain adaption. To this end, pruned graph scattering transform (pGST) was proposed based on the alignment between graph spectrum of the graph filters and the scattering feature. The intuition is to consider tree nodes as subbands in the graph spectrum and prune tree nodes that do not have sufficient overlap with the graph spectrum of a graph signal. The pruning problem was formulated as an optimization problem, and a solution was developed with theoretical analysis. Moreover, the analysis on the stability and sensitivity to perturbations were provided. Overall, the algorithm development is solid. The experimental results demonstrate the proposed pGST can outperform GST on graph classification task with less running time. Comparing with some supervised GNN methods, the proposed pGST can still achieve comparable results on several datasets.","A scattering transform on graphs consists in the cascade of wavelets, modulus non-linearity and a low-pass filter. The wavelets and the low-pass are designed in the spectral domain, which is computationally extensive. Instead to compute any cascades of wavelets, this paper proposes to prune scattering paths which have the lowest energy. This is simple, and numerically efficient.",0.09696969696969697,0.26666666666666666,0.14222222222222222
296,SP:1d0977845884e1768b8a853e0c13fa71619f8164,"This paper presents POPLIN, a novel model-based reinforcement learning algorithm, which trains a policy network to improve model-prediction control. The paper studies extensively how to utilize the policy, by planning in action space or planning in parameter space and how to train the policy, by behavioral cloning, by GAN or by averaging the results of CEM. The experiments show that the proposed algorithm can perform very well in MuJoCo tasks. ","This work provides a novel model-based reinforcement learning algorithm for continuous domains (Mujoco) dubbed POPLIN. The presented algorithm is similar in vein to the state-of-the-art PETS algorithm, a planning algorithm that uses state-unconditioned action proposal distributions to identify good action sequences with CEM in the planning routine. The important difference compared to PETS is the incorporation of a parametric state-conditioned policy (trained on real data) in the planning routine to obtain better action-sequences (CEM is used to learn the ""offset"" from the parametric policy). The paper presents two different algorithmic ablations where CEM either operates in action space or parameter space (POPLIN-A and POPLIN-P respectively), in combination with different objectives to learn the parametric policy. The method is evaluated on 12 continuous benchmarks and compared against state-of-the-art model-based and model-free algorithms, indicating dominance of the newly proposed method.",0.4166666666666667,0.19736842105263158,0.26785714285714285
297,SP:1d0c0485f95d6cf21922e0ac949333e58cc87bdf,"This paper presents a new view on policy gradient methods from the perspective of ranking. The end goal in policy learning is to achieve the right ranking of actions at a state (in the case when deterministic policies are optimal), and the paper proposes a method of doing this inspired from the work on learning to rank. They further argue that in the case with stochastic optimal policies, REINFORCE with softmax policies is rank wise optimal, which is not surprising, but at the same time interesting as well. The other main part of the paper is casting off-policy RL as supervised learning similar to work on self-imitation learning and reward weighted regression methods. This section is presented differently from the past analyses of self-imitation methods and requires the existence of UNOP, which seems like a strong assumption. They then instantiate the framework with GPI based exploration, and show that it achieves better performance than IQN and Rainbow on a subset of atari games.","This work first establishes the connection of maximizing the lower bound of accumulated reward and supervised learning on near-optimal policies. Then it proposes a general framework for policy learning: during the exploration stage, the agent will collect near-optimal trajectories while in the exploitation stage, the agent will perform supervised learning on the collected data. Under this framework, the author argues that the ranking loss could outperform the state-of-the-art on the Atari benchmark.",0.13855421686746988,0.2987012987012987,0.18930041152263372
298,SP:1d64230e66c28b4a8a20459f1336b66b5e64e137,"The paper describes the first algorithms for coresets for k-means clustering with missing data coordinates for some points in d-dimensions, with provably guarantees.  The algorithm runs in linear time O(nd) times factor depending only on j (most possible missing values per coordinate) and k (number of allowed clusters).  A SODA 2021 paper provides a PTAS for this problem, but it has worse dependence on j, k, epsilon and has a base cost of O(n^2 d), so quadratic in n.  This paper demonstrates their approach is implementable, and practical.   ","The paper provides the first coreset for clustering tasks, where each of the input d-dimensional points might contain up to j missing values. The coreset construction time is near-linear. The main technical result of the paper is a reduction from the above problem, to the problem of computing a dynamic coreset for the k-center problem with missing values. The authors utilize the sensitivity sampling framework for this task. Using this coreset, the authors improve the running time of an existing PTAS for the problem, from quadratic, to near-linear time. The authors provide experimental results which demonstrate the effectiveness of the coreset in practice, as compared to a uniform random sample.",0.1935483870967742,0.15789473684210525,0.17391304347826086
299,SP:1d9409b7e7670ef4b1083ebf80e9d2d83259467b,"The normalizing flows (NF) are among popular generative models, as they have the capability of converting a simple base distribution to complex distributions by successively applying change of variable formula. More importantly, NFs let us do inference by maximizing exact likelihood functions instead of other approximate functions like ELBO in VAEs. NFs have the invertibility constraints which make the calculations of their Jacobean determinants computationally prohibitive and require some tricks that make them easier to compute. All these tricks, among them affine coupling layers are of great popularity, come at the price of losing expressiveness. Therefore, we might need more layers (deep) to compensate for that. However, we lack a theoretical understanding of how much deep is enough to guarantee best results.  ","The paper gives very thorough mathematical representation for two challenges related to normalization flows, namely model’s large depth and conditioning which relates to the smallest singular value of the forward map. Topic is presented in a very orderly and comprehensive manner. All variables and concepts are explained and presentation is clear. Text and appendices give proofs for everything that has been discussed and appendices extensive presentation of experiments. ",0.09016393442622951,0.15942028985507245,0.11518324607329844
300,SP:1d98df05bd885aff11b20cd016d822e970752dec,"The paper is concerned with fairness in recommendations. Specifically, there are groups of users and groups of items. Previous work has modelled fairness as the constraint of all user groups having the same accuracy or as the prediction probability being independent of the item group or the user group. In this work, the notion is generalized so that the prediction is independent of both the item and user group. Optimization algorithms are shown to solve this problem along with experimental results.  ","The presented study argued that a fair recommendation should be independent of both user and item. Therefore, the study introduced a new fairness notion, i.e., equal experience, and further incorporated this fairness notion as a regularisation term in the matrix completion framework to construct a fair recommender system. The proposed method was evaluated with three datasets (one synthetic and two real datasets). ",0.12345679012345678,0.15873015873015872,0.13888888888888887
301,SP:1da35440d501c36cb1a46e431a3d9de0288933c8,"The paper proposes a new approach for abstract reasoning and explores it in the context of the RPM task. In contrast to other competing approaches, the authors seek to build into the model as few assumptions as possible to keep the model general and not specific to the specific problem or to particular annotations or supervision signals. The general capability that they seek to incorporate into the model is the ability to effectively compare and contrast candidates in tasks that require choosing the best fit. ","The paper proposes a neural network based approach called Dual-Contrast Network (DCNet) to solve Raven’s Progressive Matrices (RPM). The approach consists of a rule contrast module that compares the latent rules between the unfilled (third) row/column and the filled (first and second) rows/columns, a choice contrast module that helps in picking the correct choice among the given eight choices, and finally uses a 2-layer MLP to predict scores for the choices. Different from previous approaches, the only supervision used in the proposed approach is the ground-truth choice. The approach achieves state-of-the-art performance on RAVEN and PGM datasets.",0.2235294117647059,0.1792452830188679,0.19895287958115185
302,SP:1da5462c07b876b2d4bf89747046de5ac8e591f5,"This paper proposes a new ""global"" pooling approach that aims at preserving detailed/fine-grained information from the representation. The proposed approach is based on Fractal Encoding that are implemented such that the overall representation is still trainable. The proposed approach is tested on the task texture representation.","The authors propose complementing global average pooling in convolutional networks with another pooling method that aims at better representation of texture. This pooling method builds on fractal geometry and is implemented by a fractal encoding module. The module first locally estimates fractal dimension, the estimates are binned and inside each bin the fractal dimension estimation is applied again. This results in pooling of one input channel into a fixed-sized vector. The operations, such as binning and counting, are adapted to make the module differentiable. The experiments show that both types of pooling modules are required for good performance.",0.2916666666666667,0.1414141414141414,0.1904761904761905
303,SP:1dade549a14dc9c41f2d16be1e405be113c611fd,"The paper presents multiple dataset generation and testing procedures for linear temporal logic and propositional logic satisfiability. They are then used to train Transformers with tree positional encoding. The approach amounts to imitation learning based on existing solvers for satisfiability for the considered logics. In contrast to previous work, the approach supports logical formulas of arbitrary shape. The experiments demonstrate successful generalization for multiple approaches to dataset generation.","The paper explores the application of modern learning techniques (transformers and tree positional encodings) to the task of producing valid traces for a given LTL specification. A series of experiments are conducted to explore the generalization power of the proposed approach, both in terms of formula size and style of constraint. The work follows a recent trend of the application of deep learning techniques to logic-based settings, and the authors present (to the best of my knowledge) the first attempt of applying deep learning techniques to this particular task.",0.23529411764705882,0.17777777777777778,0.20253164556962028
304,SP:1dae5dd9635962d35767ee1a5a4da01170e18029,"This manuscript proposes a general framework to learn non-Euclidean distances from data using neural networks. The authors provide a combination of theoretical and experimental results in support of the use of several neural architectures to learn such distances. In particular, the develop “deep norms” and “wide norms”, based either on a deep or shallow neural network. Metrics are elaborated based on norms by combining them with a learnt embedding function mapping the input space de R^n. Theoretical results are mostly application textbook results and intuitive, the overall work forms a coherent line of research bridging theory and applications that sets well justified reference approaches for this topic.","This paper proposes a modeling approach for norm and metric learning that ensures triangle inequalities are satisfied by the very design of the architecture. The main idea is that convexity together with homogeneity imply subadditivity, so starting from an input-convex architecture and using activations that preserve homogeneity implies the resulting model is sub-additive at every point. This architecture is used to model a norm, and in conjunction with an embedding - a metric. The authors also propose a mixture-based approach that combines a given set of metrics into a new one using a max-mean approach. Universal approximation results are presented for both architectures. The results are illustrated on a few mostly synthetic examples including metric nearness for random matrices, value functions for maze MDPs and distances between nodes on a graph (some problems here are sourced from open street map).",0.1834862385321101,0.13986013986013987,0.15873015873015872
305,SP:1db20b6170874b3c477e7429d5d6e853680b6e5b,"This work uses imitations learning (from synthetic data) to train a deep model which takes a natural language instruction, and a visual representation of a robot's environment, and outputs a trajectory for the robot to follow which executes this instruction.  The work focuses on a robotic pick-and-place task, where the instruction indicates which of the available bins an item should be placed in.  In addition to the trajectory model, a second model is trained which allows the agent to predict whether a given command is actually feasible (i.e. whether the target bin exists).  Empirical results show a reasonably high success rate in placing objects in the bin specified by the instruction, though there is still room for improvement in cases where the shape o a combination of features is important to the selection of the correct bin. ","The paper addresses the problem of using multiple modalities for learning from demonstration. Approaches that take in task or joint space data to learn a policy for replicating that task are numerous. Doing the same with multiple modalities involved, in particular vision, language and motion, has only been recently considered, so this is a timely paper. ",0.07801418439716312,0.19642857142857142,0.11167512690355332
306,SP:1dc91a34747e3a4a9665a8d09103455737516565,"The paper proposes a new way to generate adversarial images that are perturbed based on natural images called Shadow Attach. The generated adversarial images are imperceptible and have a large norm to escape the certification regions. The proposed method incorporates the quantities of total variation of the perturbation, change in the mean of each color channel, and dissimilarity between channels, into the loss function, to make sure the generate adversarial images are smooth and natural. Quantitative studies on CIFAR-10 and ImageNet shows that the new attack method can generate adversarial images that have larger certified radii than natural images. To further improve the paper, it would be great if the authors can address the following questions:","The paper presents a new attack, called the shadow attack, that can maintain the imperceptibility of adversarial samples when out of the certified radius. This work not only aims to target the classifier label but also the certificate by adding large perturbations to the image. The attacks produce a 'spoofed' certificate, so though these certified systems are meant to be secure, can be attacked. Theirs seem to be the first work focusing on manipulating certificates to attack strongly certified networks. The paper presents shadow attack, that is a generalization of the PGD attack. It involves creation of adversarial examples, and addition of few constraints that forces these perturbations to be small, smooth and not many color variations. For certificate spoofing the authors explore different spoofing losses for l-2(attacks on randomized smoothing) and l-inf(attacks on crown-ibp) norm bounded attacks. ",0.21367521367521367,0.17482517482517482,0.1923076923076923
307,SP:1dd38a42ac3a5b8a7b555b8fde614f036853bec3,The authors address the Neural Architecture Search problem. At the core of their contribution is an architectural improvement; performance prediction of a considered architecture is much better when using a particular graph neural network on (softened) architecture topology. The rest of the NAS pipeline is naturally built around this observation and the final performance looks quite strong.,"This work propose Graph Optimized Neural Architecture Learning, that uses a differentiable surrogate model to directly optimize the graph structures. More specifically, the surrogate model takes a graph structure as the neural architecture embedding and predicts a relative ranking, then applies gradient descent on the input graph structure to optimize the neural architecture. GOAL demonstrates superior performance compared to SoTAs.",0.17543859649122806,0.16666666666666666,0.17094017094017094
308,SP:1ddcef5a08ed53d730119a0b591e2cb092c422eb,"The authors propose an opponent modeling in 1-vs-1 games called the Learning to Exploit (L2E) framework, which exploits opponents by a few interactions with different opponents during training so that it can adapt to new opponents with unknown styles during testing quickly. In particular, the authors propose Opponent Strategy Generation (OSG) that produces effective opponents for training automatically through adversarial training for eliminating its own strategy’s weaknesses and diversity-regularized policy optimization to improve the generalization ability of L2E. Experimental results of two poker games and one grid soccer game indicate that L2E quickly adapts to diverse styles of unknown opponents.","This paper proposes the Learning to Exploit (L2E) framework that can quickly adapt to diverse opponent's unknown strategies. The main contributions of L2E include: 1. learning of the base model based on the optimization similar to MAML (Finn et al., ICML-17) to adapt to a new opponent after a few learning iterations (Section 2.1), 2. the generation of the hard-to-exploit opponent to robustly train the base model (Section 2.2), and 3. the generation of diverse opponent policies using the maximum mean discrepancy (MMD) metric (Section 2.3). Empirical results show that L2E can exploit diverse opponents in the Leduc poker, BigLeduc poker, and Grid Soccer domains. ",0.21153846153846154,0.19642857142857142,0.2037037037037037
309,SP:1e02044f7efd966cd9845385fa1392226ef183eb,"This paper proposes a new approach to enforcing disentanglement in VAEs using a term that penalizes the synergistic mutual information between the latent variables, encouraging representations where any given piece of information about a datapoint can be garnered from a single latent.  In other words, representations where there is no information conveyed by combinations of latents that is not conveyed by considering each latent in isolation.  As the resultant target is intractable to evaluate, a number of approximations are employed for practical training.","The paper proposes a new objective function for learning disentangled representations in a variational framework, building on the beta-VAE work by Higgins et al, 2017. The approach attempts to minimise the synergy of the information provided by the independent latent dimensions of the model. Unfortunately, the authors do not properly evaluate their newly proposed Non-Syn VAE, only providing a single experiment on a toy dataset and no quantitative metric results. Furthermore, even qualitatively the proposed model is shown to perform no better than the existing factor-VAE baseline.",0.20481927710843373,0.18888888888888888,0.19653179190751444
310,SP:1e09b69a3d713355bd967d8205fde97a911042e7,"The present work proposes to combine GANs with adversarial training replacing the original GAN lass with a mixture of the original GAN loss and an adversarial loss that applies an adversarial perturbation to both the input image of the discriminator, and to the input noise of the generator. The resulting algorithm is called robust GAN (RGAN). Existing results of [Goodfellow et al 2014] (characterizing optimal generators and discriminators in terms of the density of the true data) are adapted to the new loss functions and generalization bounds akin to [Arora et al 2017] are proved. Extensive experiments show a small but consistent improvement over a baseline method.","Developing stable GAN training method has gained much attention these years.  This paper propose to tackle this issue via involving distributionally robust optimization into GAN training. Its main contribution is to combine Sinha et al with GAN, proposing a new GAN training method on the basis of vanilla GAN. Relative theory results are proved and detailed experiments are conducted. ",0.12149532710280374,0.22033898305084745,0.1566265060240964
311,SP:1e0fa3e10b19c54a0271b7cd2528ac8a3a51686a,"This paper proposes MIGE---a novel estimator of the mutual information (MI) gradient, based on estimating the score function of an implicit distribution. To this end, the authors employ the spectral Stein gradient estimator (SSGE) and propose its scalable version based on random projections of the original input. The theoretical advantages of the method are presented using a toy experiment with correlated Gaussian random variables, where both the mutual information and its gradient can be computed analytically. In this setting, MIGE provides gradient estimates that are less biased and smoother than baselines. The method is also evaluated on two more complicated tasks: unsupervised representation learning on Cifar-10 and CIfar-100 via DeepInfoMax (DIM) and classification on MNIST with Information Bottleneck (IB), where MIGE outperforms all baselines by a significant margin.","This paper works out estimators for the gradient of Mutual Information (MI). The focus is on its recent popular use for representation learning. The insight the authors provide is to see encoding the representation as a ‘reparametrization’ of the data. This insight enables mathematical tools from the literature on ‘pathwise derivatives’. With gradients on the MI, one can estimate models that aim to maximize this quantity. For example in unsupervised learning one can learn representations for downstream tasks. This is shown in Table 1. Another application in supervised learning is the Information Bottleneck. This shown in Table 2.",0.17557251908396945,0.23469387755102042,0.20087336244541482
312,SP:1e1a6d0bb0dc9352227b3cade1e3b88096a544b5,"The paper proposes a method for noise robustness based on scaling gradients of examples. By choosing the proper scaling parameters (alpha and beta), the method recovers standard losses such as CCE, MAE, and GCE, while also recovering other losses. The method is strongly related to reweighting training examples, where alpha and beta define the shape of this weighting as a function of the model's prediction (i.e., p_i). Experiments show that the proposed method achieves competitive results on several standard benchmarks for noisy-labelled data.","This paper presents Gradient Rescaling (GR) for robust learning to combat label noise. They propose to treat each data sample with different significance scores: some samples are important to learning, and some examples are insignificant (or even detrimental) to learning. So they desire to weight each samples according to their significance. They propose the notion of emphasis focus (When learning, whether we should put emphasis on learning “hard” examples or “easy” examples) and emphasis spread (the variance of these significance weights). The authors propose that this “difficulty” of samples are proportional to their network output logit values.",0.12643678160919541,0.1134020618556701,0.11956521739130435
313,SP:1e3aaad289327b3b42e37189a988115797c988db,"In this paper, the author extends Capsule Network on the task of face verification to solve the problem of learning from only few examples and speeding the convergence. They propose a Siamese Capsule Network, which extends Capsule Networks to the pairwise learning setting with a feature l2-normalized contrastive loss that maximizes inter-class variance and minimizes intra-class variance. Here is a list of suggestions that will help the authors to improve this paper.",Authors present an adaptation of Capsule Networks for pairwise learning tasks. The pose vectors of final capsule layers for each tower is concatenated and passed through a fully connected layer to calculate the embedding for each tower's input. Then a contrastive loss based on a distance metric is optimized for the embeddings. An interesting regularizer (?) is used which is a dropout based on Capsule activation for connecting last layer capsules to the fully connected layer. ,0.17333333333333334,0.17105263157894737,0.17218543046357618
314,SP:1e4528da1811d90afd1c6484f475f7d5eb49a6f0,"This paper tackles the problem of learning dynamics of non-rigid objects in a physics simulator. This learned dynamics can then be used for planning later. The non-rigid objects are represented via a particle-based system. The dynamics model is learned using NVIDIA's particle-based simulator ""Flex"". The main idea is to adapt Interaction Networks [Battaglia, 2016] which was earlier proposed for rigid-body simulators to particle-based simulators. Instead of maintaining interactions at the level of objects as in [Battaglia, 2016], the proposed approach models interaction at the level of particles.","The authors present an algorithm for learning the dynamics prediction of deformable and fluid bodies by modeling them as (potentially hierarchical) systems of many interacting particles.  This model applies a shared encoder to the particle states (positions and velocities), a shared relation network to nearby pairs, and a shared propagator network to the summed relation network outputs.  In some cases this process is applied in a multi-scale hierarchical fashion.  The authors demonstrate accurate rollouts of system dynamics and usefulness for manipulative control of deformable objects.",0.14893617021276595,0.16279069767441862,0.15555555555555556
315,SP:1e4d48aca131f5ff12775ba51dd1176397038d59,"This paper studies the problem of exploration in reinforcement learning. The key idea is to learn a goal-conditioned agent and do exploration by selecting goals at the frontier of previously visited states.  This frontier is estimated using an extension of prior work (Pong 2019). The method is evaluated on two continuous control environments (2D navigation, manipulation), where it seems to outperform baselines.","This paper proposes a new exploration algorithm by proposing a new way of generating intrinsic rewards. Specifically, the authors propose to maintain a ""novelty frontier"" which consists of states that have low-likelihood under some likelihood model trained on their replay buffer. The authors propose to sample from the novelty frontier using a scheme similar to a prior method called Skew-Fit, but replace the VAE with a kernel-based density model. To construct an exploration reward, the authors estimate the KL divergence between the resulting policy state distribution and the desired `state distribution, where the desire state distribution is a Gaussian centered around a point sampled from the novelty frontier.",0.2222222222222222,0.12612612612612611,0.16091954022988506
316,SP:1e88ff3d6daf6ca26d2f9d504c5ff282af5d3659,"In this paper the author proposed an MPC algorithm in which both the dynamics function and the Lyapunov function are parameterized with neural networks.. Specifically leveraging the results of Lyapunov networks (2018 CORL paper: https://arxiv.org/abs/1808.00924) for learning Lyapunov functions, the authors derived an MPC algorithm for quadratic cost/reward problems and also proved the stability, robustness, and sub-optimality performance. To demonstrate the effectiveness of the algorithms, the authors also evaluated this approach on the simple inverted pendulum and car kinematics tasks. ","This paper addresses the question of how to stabilize a system in a vicinity of an equilibrium. While the majority of reinforcement learning algorithms rely on trial and error, which may damage the system, the authors introduce an algorithm for safe exploration and control. A traditional approach in model-based RL is to use MPC with a surrogate forward model to minimize a planning objective comprising a sum of stage costs along with a terminal cost, often chosen as an approximated value function -i.e. the optimal expected cost-to-go- which can be learned by a Bellman equation. Instead, this work is placed in the framework of Robust MPC, where this value function is replaced by a Luyapunov function $V$, which is related to the notion of stability and is only constrained to decrease along trajectories. Such a Luyapunov function, when available, provides both a safe region, defined as a level-set of V, and a MPC policy for which stability analyses have been developed: the authors extend a result from Limon et al. (2003; 2009) to show that this MPC policy enjoys asymptotic stability in general, and input-to-state stability in the presence of small enough model errors. Accordingly, the authors propose a scheme allowing to learn a Lyapunov function $V$ from demonstration data only, through a loss function that penalizes increments of $V$ along one-step transitions. A regularization parameter $\alpha$ of this MPC, which balances stability with constraints satisfaction and stage costs, is also learned jointly by an alternative training procedure. This approach is evaluated empirically on two standard constrained non-linear continuous control tasks.",0.3218390804597701,0.1037037037037037,0.15686274509803924
317,SP:1e8a3732ecec3487984655db61d6d56e3f4e0426,"### What is the Problem / Question? Pre-training has not been thoroughly explored within RL, so it is unknown how effectively task-free unlabeled datasets can be used for PT in an RL context. The authors present a simple strategy for such PT for RL that shows benefits with limited reward annotations.  ### Why is it impactful? RL is a famously expensive discipline of ML which nonetheless has huge application areas and potential in theoretial and deployment contexts. Being able to translate the improvements offerred by pre-training to the RL context would help empower this already important technique significantly.  ### Why is it hard? Why have previous approaches failed? There are several previous approaches to this problem, including some the authors readily identify in their study, such as the CQL+BC method which uses unlabeled data to perform semi-supervised offline RL by adapting policy prior data via unlabeled data.   ### How do they solve it? The authors propose using the (already published) decision transformer model, but pre-training that model first on a dataset with only action sequences, without any reward information.  ### How do they validate their solution? The authors compare their proposed framework against existing models, including both the traditional DT, a BC baseline, and the CQL and CQL+BC methods (the latter of which is a semi-supervised approach). They find slight improvements over existing methods in the extreme few-shot settings (10 observed trajectories at FT time), with further reduced gains at larger #s of observed trajectories, culminating in worse performance than traditional methods at full data scale. ","This paper presents Pre-trained Decision Transformer (PDT) for semi-supervised offline reinforcement learning. PDT first pre-train a decision transformer model on the trajectory dataset without rewards, and then fine-tune on a smaller dataset with reward annotations. Empirically, PDT achieves compatible performance with offline reinforcement learning baselines. ",0.05791505791505792,0.30612244897959184,0.09740259740259741
318,SP:1e92779dd25fcac41115f5771712163690fcc2eb,"This paper studied an important topic in the field of data synthesis: how to train a private deep generative model without reusing the original data. In this paper, the authors proposed a new framework that uses deep generative models to synthesize data in different private ways. Unlike popular gradient cleaning methods, the framework proposed in this paper does not incur additional privacy costs or model constraints. In addition, in order to avoid the problem of reduced privacy guarantee as training iterations increase, this paper used feature functions and adversarial re-weighting objectives to solve the above problems. Both theory and extensive case studies verify the performance of the proposed framework. ","In this paper, the authors propose a novel differentially private approach to generate both continuous as well as discrete valued synthetic data. The authors utilize a one shot approach to providing the privacy, by first generating privatized embedding of the sensitive dataset. The privatized embeddings are then iteratively compared against the synthetic samples generated by the generator module using the characteristic function distance. The approach is similar to and can be considered a generalization of another new approach DP-MERF and seems to compare favorably in empirical experiments against DP-MERF and DP-GAN (two popular alternative approaches). ",0.15454545454545454,0.17346938775510204,0.16346153846153846
319,SP:1ea373170ff80da65268e36e30370f2116fa4ed3,"The paper presents a new model for the task of language modeling especially suited for longer sequences. This new model dubbed as Memformer consists of Transformer encoder-decoder and a memory module to store the past information from the encoder outputs. The encoder bidirectionally attends to the immediate previous sequence/segment information and to the memory module, which is designed to capture useful information from the past history of the full sequence. The idea is that by bidirectionally attending simultaneously to the previous input segment and to a memory module, the decoder should be able to improve its generation capabilities.","This paper proposes a new style transformer with external memory, which is updated and used through an attention mechanism. They also propose a new algorithm to train the memory, Memory Replay Back-Propagation (MRBP). The memory consists of key-value pair data and is recurrently updated after the segment encoding. Through this memory, it can attend the past knowledge without the limitation of the maximum temporal range. The MRBP algorithm trains the memory through the local back-propagation of loss to reduce memory overhead.",0.21,0.25,0.2282608695652174
320,SP:1eae7d672cd3f9a61f41af1cd46082370ee5b666,"This submission proposes to offer a better initialization by using image pyramids and Q-learning (top-down manner) for the original recurrent visual attention (RAM) model (bottom-up manner). Two new constraints are also proposed for better exploration for RAM. The proposed method has been tested on several image classification datasets, including MNIST, cluttered translated MNIST, SNHN (sequential multi-digit recognition). They also test the robustness to adversarial attack (PGD attack) on CIFAR10.","This paper extends the recurrent attention model(RAM) with another extra top-down attention. Specifically, they exploit image pyramids and Q-learning to select regions-of-interest first in the top-down attention mechanism, and then follow RAM to use policy gradient to find the patch in the bottom-up attention. Meanwhile, they also propose two loss constraints to further boost the performance of bottom-up recurrent neural networks. The proposed framework is an end-to-end framework. Experiments on three datasets (MNIST, CIFAR 10, and SVHN) have demonstrated the effectiveness of the proposed model.",0.273972602739726,0.21052631578947367,0.23809523809523808
321,SP:1eb66a8cc370cb0a84c08a12a7a8842e785f5d6f,"This paper is very well-written and combines the state-of-the-art NLP model and the domain knowledge in retrosynthetic reaction predictions.  The authors propose pre-training models to help improve the model's generation to rare reactions. In addition, a discrete latent variable model is used in the model to encourage the model to produce a diverse set of alternative predictions.  The experiments in the paper also show the effectiveness of the two main contributions.","Given a target compound, the authors suggest a method to predict likely chemical reactants to produce the target. The authors provide a transformer based model to predict the reactants. Existing methods do not generalize well for rare reactions and the training data has only one reactant set for each target even though that may not be the only way to synthesize the compound. To solve this problem, the authors use a pretraining method similar to BERT. Instead of just using token masking, they provide alternate proxy decompositions for a target molecule by randomly removing bond types that are likely to break and by transforming the target based on known templates.",0.19480519480519481,0.13636363636363635,0.16042780748663102
322,SP:1edc10bfb658acb2df0babf5924a35267bf1636f,"The authors show how to solve the Rubik cube using reinforcement learning (RL) with Monte-Carlo tree search (MCTS). As common in recent applications like AlphaZero, the RL part learns a deep network for policy and a value function that reduce the breadth (policy) and depth (value function) of the tree searched in MCTS. This basic idea without extensions fails when trying to solve the Rubik cube because there is only one final success state so the early random policies and value functions never reach it. The solution proposed by the authors, called autodidactic iteration (ADI) is to start from the final state, construct a few previous states, and learn value function on this data where in a few moves a good state is reached. The distance to the final state is then increased and the value function learn more and more. This is an interesting idea that solves the Rubik cube, but the paper lacks a more detailed study. What other problems can be solved like this? Would a single successful trajectory be enough to use it in a wider context (as in https://blog.openai.com/learning-montezumas-revenge-from-a-single-demonstration/) ? Is the method to increase distance from final state specific to Rubik cube or general? Is the training stable with respect to this or is it critical to get it right? The lack of analysis and ablations makes the paper weaker.","This paper introduces a deep RL algorithm to solve the Rubik's cube. The particularity of this algorithm is to handle the huge state space and very sparse reward of the Rubik's cube. To do so, a) it ensures each training batch contains states close to the reward by scrambling the solution; b) it computes an approximate value and policy for that state using the current model and c) it weights data points based by the inverse of the number of random moves from the solution used to generate that training point. The resulting model is compared to two non-ML algorithms and shown to be competitive either on computational speed or on the quality of the solution.  ",0.13983050847457626,0.2773109243697479,0.18591549295774648
323,SP:1f15c0a7d7bdf113c303a89650afb22f9d56abad,"This paper proposes KALM - a knowledge-aware language model that incorporates entity information. Specifically, the method involves using a dictionary lookup to match n-grams to entities from a database. Then, each token is embedded into two vectors — one using the surface form, and one using the entity ID it is matched to (if there is a match). These embeddings are then added and passed into a Transformer model to predict the next word given the context. Experiments compare the model to GPT-2 and T5 (two state-of-the art Transformer-based LMs) and demonstrate the benefit of adding entity information. ","This paper presents a knowledge-aware language model pretraining method without changing model architecture. Specifically, they add entity prediction task along with language modeling task to make the model aware of knowledge. Experiments show improved results on the LAMA knowledge probing task compared to GPT-2 models. They also show comparable results on zero-shot question answering task, even with only 2% transformer parameters compared to GPT-2 17B.",0.16666666666666666,0.2463768115942029,0.19883040935672516
324,SP:1f205607623dfcb3aa5e21f7d13d3182ba29bad5,"The authors proposed a self-explainable deep net architecture that could be used for text categorization. The main idea is to force the network to extract ""excerpts"", from the input text, each corresponds to a concept, which are also learned for interpretation. The classification is finally made based off of the learned concept, which is a binary vector. All three steps are learned in an end-to-end manner. The learning of concepts is regularized to make sure the concepts are consistent and non-overlapping. The idea sounds interesting and the experimental results support the usefulness of the proposed method on a variety of datasets. My sole concern is about the sensitivity analysis of the explanation, i.e. how robust is the explanation with respect to the perturbations that do not change the classifier prediction. It has been discussed in the literature that many explanation methods suffer from this sensitivity issue. ","The paper introduces a new concept-based interpretability method that lies in the family of self-interpretable models (i.e. it's not a post-hoc method). Self-interpretability is achieved by a two-stage model: First, a concept-extractor finds the related pieces of consecutive words (excerpts) in a given text that are related to a concept among a set of given concepts (if any), then the model makes its predictions solely based on the presence or absence of concepts (binary).  The most useful part of the algorithm is that there is no need for concept annotations. The work then experimentally shows that their method, although does not outperform a non-self-interpretabile baseline but has better performance and interpretation compared to rival methods.",0.17218543046357615,0.208,0.1884057971014493
325,SP:1f35871b8ec295dd84e991fdc57a45024bc07607,"The paper proposes a method that, from a simple encoding of sequences of actions that have equivalent outcome in an MDP, allows to compute a local policy for local high-quality exploration (it replaces the random action of $\varepsilon$-greedy with an action that maximizes the entropy of future visited states). Full algorithmic details about how to do that are given in the paper, and experiments on a few environments show that the method is promising. The Freeway experiment is particularly interesting, as it shows that a (small) benefit can be obtained from the method even on an Atari game, with minimal domain knowledge (only a few equivalent action sequences are encoded), and using a slightly modified DQN algorithm.","In the context of reinforcement learning, authors propose an exploration strategy based on environment-specific prior knowledge of action equivalence. An example of such equivalence is rotating 180° twice in a grid world, as the agent comes back to the same original state: the action sequence forms an identity in this case. The proposed exploration, instead of picking a random action with probability (\epsilon)/(number of actions), builds an abstracted lookahead tree of specified depth that merges equivalent action sequences and adjusts the distribution of \epsilon over them. Authors demonstrate this i) increases the number of unique state visitations in grid-world examples, and ii) DQN with their exploration strategy achieves a higher reward faster than the baseline. ",0.15966386554621848,0.16101694915254236,0.16033755274261602
326,SP:1f5df656d73634346199738039c56f47b211d8c5,"The authors propose an approach called the Laplace Bridge to approximate predictive uncertainty in Bayesian neural networks. The approach is essentially based on first a change of variable, followed by a Laplace approximation. They provided a theoretical result for this approach, which essentially shows that for \alpha_k large enough, the variance of \pi_k given \alpha is increasing with the variance \Sigma_kk.  They performed some experiments to essentially show the computational speedup of Laplace Bridge against more cumbersome MC based competitors. ","This article improves the efficiency of Bayesian neural networks (BNNs). It follows the sampling-free solutions within Bayesian deep learning (Wu et al., 2018; Haussmann et al., 2019, etc.). The difference is the proposed Laplace Bridge that approximates the  full distribution over the softmax outputs of a neural network. The Laplace Bridge tackles the problem of approximating the distribution over the softmax outputs of the ubiquitous Gaussian-approximated BNNs without any additional training  procedure. This allows the Laplace Bridge to be used with pre-trained networks and emphasizes its non-invasive nature.",0.1927710843373494,0.17391304347826086,0.18285714285714286
327,SP:1f83dea3eb2ba809f1ce7f12bbdebc29ca4d700d,"In this paper, authors proposed an ensemble approach for query reformulation (QR).  The basic idea is that 1) train a bunch of models/sub-agents on subsets, e.g., randomly partitioned, of the training data; 2) and then train an additional meta model/meta-agent to aggregate the results from the step 1).  They conduct experiments on document retrieval and question answering tasks to show the effectiveness of the proposed model.","The authors proposed a variant of ensemble method in reinforcement learning for query reformulation. They train multiple specialized sub-agents on disjoint partitions of the training data, and use a meta-agent, which can see all the training data, to decide the final answer. This can speed up the training thanks to parallelization. They observed that this can improve the diversity of learnt reformulations and the overall performance in some cases. ",0.3380281690140845,0.3380281690140845,0.3380281690140845
328,SP:1f8bcc87aaf36e270df1c64d840809dd85f2ee75,"This work presents an analysis of the amount of hidden units needed for convergence of a 1 hidden layer neural network to a global minimum under gradient descent (and gradient flow).  In particular, this work establishes a bound of $\tilde{\Omega}(n^{\frac{3}{2}})$ parameters for linear convergence.  Importantly, this work analyzes convergence in a 1 hidden layer network in the case where both weight matrices are trained.  The results also hold for a range of initialization schemes including the Kaiming Normal Initialization.   ","In this paper, the author focus on the theoretical framework of minimizing training risk when the loss satisfy PL conditions. They prove the linear convergence in subquadratically over-parameterized shallow networks with smooth activation functions. They conduct experiments on different initialization to support the theory. The theory also provides insights toward avoiding lazy training.",0.10714285714285714,0.16666666666666666,0.13043478260869565
329,SP:1f95868a91ef213ebf3be6ca2a0f059e93b4be37,The paper proposes to use autoencoder for anomaly localization. The approach learns to project anomalous data on an autoencoder-learned manifold by using gradient descent on energy derived from the autoencoder's loss function. The proposed method is evaluated using the anomaly-localization dataset (Bergmann et al. CVPR 2019) and qualitatively for the task of image inpainting task on CelebA dataset.,This paper discusses an important problem of solving the visual inspection problem limited supervision.  It proposes to use VAE to model the anomaly detection. The major concern is how the quality of f_{VAE} is estimated. From the paper it seems f_{VAE} is not updated. Will it be sufficient to rely a fixed f_{VAE} and blindly trust its quality?,0.16393442622950818,0.16393442622950818,0.16393442622950818
330,SP:1faa70e8c6e079b89ba7336c0c1fc66713e29248,"Comparing the performance of different RL algorithms can sometimes be difficult because algorithmic contributions can be confounded with differing implementational choices between the agents. This paper attempts to examine the relative contributions of algorithmic vs implementational choices in a series of inference-based, off-policy actor-critic algorithms -- MPO, AWR, and SAC. The authors' starting point is a unified view of these algorithms from the perspective of control-as-inference. In this framework, policies as cast as posterior probabilities that a given action in a given state will be optimal. The authors derive an ELBO for this posterior that, when optimised, yields an approximate optimal policy. The authors then describe how optimization can be approached in two ways: an EM approach (where both a prior and posterior policy are optimized) and a KL approach (where only the posterior policy is optimized). MPO and AWR belong to the EM family of algorithms, while SAC belongs to the KL family. The authors further detail how these algorithms fit into their unified framework.  In the second half of the paper, the authors focus on the implementational differences between these algorithms. They focus specifically on four choices: clipped double q-learning, tanh-squashing in the policies, the choice of activation function and layer norm, and the network size. Specifically, through a series of ablation studies, the authors examine how critical some of these choices are to specific algorithms and which of these can be transferred to other algorithms.","This paper fits in the category of survey/review paper. While this kind of paper is not common at Neurips, it doesn't mean that it should be disregarded. It does a good job at trying to unify a popular body of work on policy gradient methods under the umbrella of ""control as inference"". The paper is well-structured: it defines a taxonomy which differentiates between ""EM-based"" methods and those based on ""direct KL minimization"". The paper focuses on four algorithms: Maximum a posteriori Policy Optimisation (Abdolmaleki et al. 2018), Advantage-Weighted Regression (Peng et al. 2019), Soft Actor-Critic (Haarnoja et al. 2017) and Relative Entropy Policy Search (Peters et al. 2010). The  paper starts by explaining how the RL problem can be cast as a probabilistic inference problem and tries to explain how an evidence lower bound can obtained. It then goes into the specifics of each algorithm and how each either parametrizes the prior or the posterior and whether  it uses hard constraints (with closed-form expressions) or soft/regularized re-formulations.   The empirical section then compares the raw performance three of those algorithms (SAC, MPO and AWR) on six Mujoco environments.   Regarding the ""co-adaptation"" expression in the title, I wouldn't say it defines the paper. The ""co-adaptation"" findings really pertain to the impact of specific implementation details on the final performance in those six Mujoco environments. More specifically, the authors study the impact of double-q learning + clipping, ELU activations vs ReLu, network size and layer normalization. The empirical findings are nicely summarized through tables. ",0.1885245901639344,0.17490494296577946,0.1814595660749507
331,SP:1fc0dee5fc3408ae717010debd346f9d2aff2c52,"The manuscript entitled “Hyperrealistic neural decoding: Linear reconstruction of face stimuli from fMRI measurements via the GAN latent space” utilizes a GAN-based network structure for generating faces that are presented to the subjects during fMRI acquisition. The acquired fMRI signals are then used to predict latent vector in GAN, where the predicted vectors (rather than the original, trained vectors) are used to generate “fMRI-derived” faces in turn. This work proposed a novel perspective to the field of cognitive neuroscience and human brain mapping in functional neuroimaging studies. It is an indirect yet highly effective way for modeling brain functional signals, and representing how the visual encoding-decoding actually works in human brain. Similar schemes of investigation can be easily developed based on the proposed work (e.g. analyzing correspondence between EMG and fMRI during motor tasks), which will bring significant value to the community.","The paper proposes to reconstruct images of faces from fMRI measurements, using GANs. The authors collected a new dataset, showing static faces generated by a GAN model to human subjects, and recording their brain BOLD responses with MRI. Then, they learned a model to reconstruct the stimulus based on the brain responses. The authors demonstrate the high quality of the reconstructed faces, comparing with other recent methods.",0.1232876712328767,0.26865671641791045,0.16901408450704225
332,SP:1fcf3b2eec374cb379819564c4dbf5cfabe3ff8a,"   The authors consider the problem of estimating average treatment effects when observed X and treatment T causes Y. Observational data for X,T,Y is available and strong ignorability is assumed. Previous work (Shalit et al 2017) introduced learning a representation that is invariant in distribution across treatment and control groups and using that with treatment to estimate Y. However, authors point out that this representation being forced to be invariant still does not drive the selection bias to zero. A follow up work (Hassanpour and Greiner 2019) - corrects for this by using additional importance weighting that estimates the treatment selection bias given the learnt representation. However, the authors point out even this is not complete in general, as X could be determined by three latent factors, one that is the actual confounder between treatment and outcome and the other that affects only the outcome and the other that affects only the treatment. Therefore, the authors propose to have three representations and enforce independence between representation that solely determines outcome and the treatment and make other appropriate terms depend on the respective latent factors. This gives a modified objective with respect to these two prior works.",The paper proposes an algorithm that identifies disentangled representation to find out an individual treatment effect. A very specific model that tries to find out the underlying dynamics of such a problem is proposed and is learned by minimizing a suggested objective that takes the strengths of previous approaches. The method is demonstrated in a synthetic dataset and IHDP dataset and shown to outperform other previous methods by a large margin.,0.10204081632653061,0.28169014084507044,0.149812734082397
333,SP:1fe299c89ca18eb48bc9492ea31e482fdd73e1c8,"This paper proposes an adaptive sampling scheme to construct the training dataset which allows us to learn classifiers that are fair in a minimax sense. They proved theoretical results on the excess risk of their algorithm, and also proposed heuristic extensions of the algorithm to be applicable to real-world large scale problems. They validate their algorithm on a series of synthetic and real-world datasets, showing an improved performance over empirical/uniform sampling schemes, which also verified their theoretical findings. ","The paper exploits active sampling methods to construct a training dataset that yields fair classifiers in a minimax sense: minimising the maximum risk of any of the groups of interest. The proposed method constructs a dataset iteratively by drawing samples from the group with highest upper confidence bound (UCB) for the predictive risk of the current classifier. At each iteration, the classifier is retrained (updated) on the extended dataset, and the process is repeated until a sampling budget is exhausted. The authors provide theoretical bounds for the convergence of the algorithm, which are proven to be tighter than those of previous $\epsilon$-greedy approaches.",0.2716049382716049,0.21153846153846154,0.23783783783783782
334,SP:1feae47cc68e37f008c8358ed960afa41f9c0019,"This paper aims at addressing both  secure training and inference of DNNs. The proposed method relies on securely off-loading the compute-intensive part of the operations from a trusted CPU environment which has low-performance, to an untrusted high-performance gpu. Their suggested method builds on SOTA, Slalom, but is shown to have less memory over-head. Also, they point-out that their proposed scheme supports training phase as well, as opposed to Slalom which targets inference. For off-loading the computation to the untrusted GPU they propose some matrix blinding techniques.",The paper builds on previous work like Slalom to propose a new secure training and inference protocol in the TEE+GPU paradigm. The main technical contribution of this work is a new blinding algorithm that dramatically reduces the memory required to store the blinding parameters (decoupling it from the input/model size). The authors then build on this to extend their blinding scheme to the training use-case.,0.17204301075268819,0.23529411764705882,0.19875776397515527
335,SP:1feb0867aa91170a2b8b63a00dc356455525d85d,A new method for defending against label noise during training of deep neural networks is presented. The main idea is to “forget” about wrongly labeled examples during training by an ascending step in the gradient direction. This is a meta-approach that can be combined with other methods for noise robustness; the detection of the noisy examples is specific of the base method utilised. Experimental results are promising.,This paper presents a meta algorithm to improve the robustness of learning methods under noisy labels. The idea is to squeeze out the negative effects of noisy labels actively. The paper trains deep neural networks by stochastic gradient descent on “fitting” labels; while trains deep neural networks by scaled stochastic gradient ascent on “not-fitting” labels. Experimental results show the improvement on robustness. ,0.17647058823529413,0.19047619047619047,0.18320610687022898
336,SP:2003bbcbbf2f16f6e54353a8b6f58c613343ecc0,"This paper presents a method to train a neural network to predict the time-dependent costs, and start and goal states needed to run time-dependent shortest-path planning in a dynamic 2-D environment. The non-differentiability of the path planning is handled by recent work on differentiating through blackbox combinatorial solvers from [1]. The method is trained in a supervised manner from expert trajectories. Evaluations are presented on 2-D time-varying games where the addition of the path-planner is shown to improve performance over an imitation learning and PPO baseline.",This work proposes a novel neuro-algorithmic policy architecture for solving discrete planning tasks. It takes a high-dimensional image input and processes it through modified ResNet encoders to obtain a graph cost map and a start/goal heatmap. This is fed into a differentiable Dijkstra algorithm to obtain the shortest trajectory prediction which is trained using an expert-annotated trajectory via a Hamming distance loss. This module is evaluated in two dynamic game environments demonstrating generalization to unseen scenes.,0.14893617021276595,0.175,0.16091954022988506
337,SP:200c0434743be81f22477f5dfc16e1a06bfe283e,"In prior deep learning papers it has been observed that ReLU networks are positively scale invariant due to the non-negative homogeneity property of the max(0, x) function. The present paper proposes to change the optimization procedure so that it is done in a space where this invariance is preserved (in contrast to the weight space, where it is not). To do so, the authors define the group G of positive scaling operators, and note that the ""value of path"" (product of weights along the path) is G-invariant and together with ""activation status of paths"" allows for the definition of an equivalence class. They then build a G-space which has fewer dimensions than the weight space, and proposed g-SGD to optimize the network in this space. In g-SGD gradients are computed normally, then projected to G-space via a sparse matrix in order to update the values of paths. The weights are then updated based on a ""weight allocation method"" that involves the inverse projection.","The paper proposes SGD for ReLU networks. The authors focuses on positive scale invariance of ReLU which can not be incorporated by naive SGD. To overcome this issue, a positively scale-invariant space is first introduced. The authors show the SGD procedure in that space, which is based on three component techniques: skeleton method, inverse-chain rule, and weight allocation.",0.10588235294117647,0.3,0.15652173913043477
338,SP:200f79d7a66aa5ffdaf5f302c564b1567d3e1589,"The authors argue that the popular benchmark datasets, Omniglot and miniImageNet, are too simple to evaluate supervised few-shot classification methods due to their insufficient variety of class semantics. To validate this, the authors proposed clustering-based meta-learning method, called Centroid Network. Although it does not utilize supervision information during meta-evaluation, it can achieve high accuracies on Omniglot and miniImageNet. The authors also proposed a new metric to quantify the difficulty of meta-learning for few-shot classification.","The paper is concerned with few-shot classification, both its benchmarks and method used to tackle it. The scope of the few-shot classification problem can be set relatively widely, depending on what data is available at what stage. In general few-shot classification is an important ability of intelligent systems and arguably an area in which biological systems outperform current AI systems the most.",0.15,0.18461538461538463,0.16551724137931034
339,SP:201070333d2ca3ad49d9f4783d190e2c1772afe9,"This submission introduces a metric, termed stiffness, to evaluate the generalization capability of neural networks. The metric is novel and straightforward, it measures how stiff a network is by looking at how a small gradient step on one example affects the loss on another example. The authors study several configurations  on three small datasets. They demonstrate that stiffness is a useful concept for diagnosing and characterizing generalization. ","This paper introduces “stiffness”, a new metric to characterize generalization in neural networks. Stiffness is a pretty simple concept and is relatively straightforward to compute. The authors evaluate this metric on standard datasets using two relatively small neural networks. On the whole, the paper is written clearly and explains its methodology in simple language.",0.2537313432835821,0.3148148148148148,0.2809917355371901
340,SP:201c4028ac02743edfeb90aca191850f67d61445,"In this papar, the authors formulated a new objective function for HBO, which included an additional regularization term based on the dataset similarity. The authors used the distance between the meta-features of selected datasets to measure this dataset similarity and assumpted that similar datasets should have similar hyper-paprameters.  The experiments are complete and demonstrate the advantages of using this new optimization formulation.",The authors propose a new zero-shot hyper-parameter optimization method based-on the meta-learning framework. The proposed method incorporates two ideas from the meta-learning framework namely the task similarity based on the meta-features and the dataset identification. The former idea is used to achieve the requirement that responses to similar data sets should be similar.The latter idea has the role of preventing data of dissimilar tasks from being embedded in close proximity in the meta-feature space.,0.3125,0.24390243902439024,0.273972602739726
341,SP:2020439f6e52ec592e2fbc454633c1613e8a82c1,"This work proposes a multi-task learning architecture for neural processes termed the Multi-task process (MTP). The MTP model conditions task-specific latent variables on a global latent variable that is responsible for information sharing between the tasks, and is able to handle both the isotopic and the heterotopic cases. The model was instantiated with an attentive neural process architecture and the generative model of the MTP was shown to correspond to a stochastic process by a Kolmogorov Extension Theorem argument.",The paper presents a novel model for multi-task learning with missing data based on Neural Processes (NP). Inter-task correlations are modelled via a shared latent variable. The model has been tested on 1 synthetic and 2 real-world datasets and is experimentally shown to perform better against 4 baselines including 2 naive extensions of NP to the multi-task setting and 2 multi-output Gaussian process models (with spectral kernels).,0.2073170731707317,0.2361111111111111,0.22077922077922074
342,SP:2029b7b6e7019ff35141132b4c4586223770523c,Words have implicit hierarchy among themselves in a text. Hyperbolic geometry due to the negative curvature and the delta-hyperbolicity is more suitable for representing hierarchical data in the continuous space. As a result it is natural to learn word representations/embeddings in the hyperbolic space. This paper proposes a promising approach that extends the approach presented in [1] to implement a GLOVE based hyperbolic word embedding model. The embeddings are optimized by using the Riemannian Optimization methods presented in [2]. Authors provide results on word-similarity and word-analogy tasks.,"This paper adapts the Glove word embedding (Pennington et al 2014) to a hyperbolic space given by the Poincare half-plane model.  The embedding objective function is given by equation (3), where h=cosh^2 so that it corresponds to a hyperbolic geometry. The author(s) showed that their hyperbolic version of Glove is better than the original Glove. Besides that,  based on (Costa et al 2015), the author provided theoretical insights on the connection between hyperbolic embeddings with Gaussian word embeddings. Besides, the author(s) proposed a measure called ""delta-hyperbolicity"", that is based on (Gromov 1987) to study the model selection problem of using hyperbolic embeddings vs. traditional Euclidean embeddings.",0.18681318681318682,0.15178571428571427,0.16748768472906403
343,SP:202c1ae8c7f18f8cc234f8c8cc5d9f89ae9f43d0,"The present work considers the problem of multi-agent trajectory prediction. Its main contribution is incorporating generative augmentation losses for improving the quality of a trajectory predictor. This is achieved by allowing trajetcory predictors to model intent as an unobserved latent variable in the model and using this to generate trajectories corresponding to different intentions. The work also proposes to use a descriminative loss encouraging diversity of the intents and an additional ""hallucination"" loss that allows for modelling mixed intents.","The paper designed a framework for motion forecasting (trajectory prediction), with emphasis on multimodal distribution modeling and generalization. Specifically, they use latent code to model agent's intents. This latent code combined with historical trajectories and map were used to generate future trajectories, which were further judged by a discriminator. Besides, they added latent code classification and hallucinative data augmentation for performance boosting. ",0.1625,0.20634920634920634,0.1818181818181818
344,SP:2034dffa26a8e68c466d835ada625fe635a71b66,"Motivated by recent development of attack/defense methods addressing the vulnerability of deep CNN classifiers for images, this paper proposes an attack framework for adversarial text generation, in which an autoencoder is employed to map discrete text to a high-dimensional continuous latent space, standard iterative optimization based attack method is performed in the continuous latent space to generate adversarial latent embeddings, and a decoder generates adversarial text from the adversarial embeddings.  Different generation strategies of perturbing latent embeddings at sentence level or masked word level are both explored. Adversarial text generation can take either a form of appending an adversarial sentence or a form of scattering adversarial words into different specified positions. Experiments on both sentiment classification and question answering show that the proposed attack framework outperforms some baselines. Human evaluations are also conducted.","This paper proposes a new attack framework AdvCodec for adversarial text generation. The main idea is to use a tree-based autoencoder to embed text data into the continuous vector space and then optimize to find the adversarial perturbation in the vector space. The authors consider two types of attacks: concat attack and scatter attack. Experimental results on sentiment analysis and question answering, together with human evaluation on the generated adversarial text, are provided. ",0.2,0.36486486486486486,0.2583732057416268
345,SP:2036673d54d07683d1dfdad4567ea18029344359,"The paper presents a method of scaling up towards action spaces, that exhibit natural hierarchies (such as a controllable resolution of actions), throughout joint training of Q-functions over these. Authors notice, and exploit a few interesting properties, such as inequalities that emerge when action spaces form strict subsets that lead to nice parametrisation of policies in a differential way. The evaluation is performed in simple toy-ish tasks, and in micro-management problem in 5 scenarios in the game of SC2.","This paper proposes a method to progressively explore the action space for RL. The proposed method is called “growing action spaces”. The basic idea is that actions can usually be grouped by a hierarchical structure: the lowest level is the coarsest and higher levels gradually refine the action partition. This method effectively captures many RL settings, including multi-agent learning. One effective approach is to apply the action hierarchy. ",0.14634146341463414,0.17391304347826086,0.15894039735099336
346,SP:206cbbc17b4ff8eb365bd77120d35bb2eefcb531,"The core question studied in this paper is how to choose a best performance measure (termed as ""index"" by the authors) in all situations for binary and multiclass classifications. To answer this question, the authors define several properties that are important for considerations when one wants to choose a good index. Then many common indices (performance measures) in classification tasks are analyzed to see if they satisfy each of the properties defined, including Accuracy, F-measure, and others. A impossibility theorem is proved to show that some desirable properties cannot be satisfied at the same time for a given index. With this theorem, a family of indices is proposed that satisfies all good properties except one.","This paper proposed a systematic approach to choosing a suitable validation index for classification tasks. The authors considered several binary and multiclass indices, including new ones. They examined the indices with five sets of properties based on the study [6,18_Supplementary]. For each index and each property, they formally proved or disproved that the property is satisfied. They also presented the impossibility theorem for classification. ",0.1724137931034483,0.30303030303030304,0.21978021978021978
347,SP:2093f2f9d4bf15531dd76e02f8d36cddf6961352,"In the paper, the authors present a new algorithm for training neural networks used in an automated theorem prover using theorems with or without proofs as training data. The algorithm casts this training task as a reinforcement learning problem, and employs curriculum learning and the Proximal Policy Optimization algorithm to find appropriate neural network parameters, in particular, those that make the prover good at finding long proofs. The authors also propose a new dataset for theorems and proofs for a simple equational theory of arithmetic, which is again suitable for improving (via learning) and testing the ability of the prover for finding long proofs. The proposed prover is tested against existing theorem provers, and for the authors' dataset, it outperforms those provers.","This work introduces a method for learning to prove theorems which can leverage prior proving experience in order to discover very long proofs. At its core it works by inputting a corpus of training problems (which can also be annotated with solutions i.e. proofs), training a policy to solve these training problems by curriculum learning. The curriculum works by first supervising on the trace of an entire solution, and then once the system can solve a particular problem, decreasing the amount of the trace that it supervises on. The authors claim that this is a kind of analogical reasoning, because the system's policy is implicitly learning to represent the state/action space on the basis of prior experience.",0.1721311475409836,0.175,0.17355371900826444
348,SP:20b1c29036733dee134d3dfa245e574aa82b7d3d,"This paper proposes the use of hyperdimensional (HD) vectors to represent n-gram statistics. The HD vectors are first generated from the whole corpus. Then, it is aggregated or bundled to a vector for each sample as an input of a classifier training. The evaluation is conducted on four datasets: Chatbot, AskUbuntu, WebApplication and 20 News Group using a bunch of classifier including KNN, Random Forest, MLP etc.",This paper introduces a technique to project n gram statistic vectors into a lower dimensional space in order to improve memory efficiency and lower training time. The paper is motivated by the important problem of trying to improve efficiency of existing language models which can be extremely resource intensive. The authors then compare the performance of n gram statistics with HD vectors on 4 datasets to demonstrate that embedding into HD vectors can preserve performance while reducing resource utilization.,0.19117647058823528,0.16455696202531644,0.17687074829931973
349,SP:20b3645f16dca8252b31b43661e565d180529a4e,"This paper proposes a decentralized adaptive method for distributed deep learning, termed DAG-Adam. Convergence results are provided for smooth non-convex objectives under a bounded gradient assumption. Numerical experiments are conducted on Image Classification (CIFAR10, ImageNet-1k) and Language Modelling (fine-tuning pre-trained BERT models on SQuAD).","This paper developed a new decentralized adaptive gradient descent method to address the data heterogeneity problem. The motivation is clear and the experimental results show improvement over existing methods. However, the theoretical analysis is not  solid. ",0.14285714285714285,0.19444444444444445,0.16470588235294115
350,SP:20b37598155521a49e41e344d8ddf8c8567cde1b,This paper proposes a learning to hash attention (LHA) to learn sparse attention for Transformer. The proposed LHA addresses the limitation of ANN-based sparse attention method by separate learnable hash functions for queries and keys and utilizes kernelized techniques for efficient approximation of attention utilities.  Experiments on several applications validate the effectiveness of the proposed LHA.,"This paper introduces a new method based on learnable hash functions to reduce the O(N^2) cost of self-attention in transformers to O(N^1.5). As previously known for bucket-based approaches, this cost is only achieved when buckets are balanced. The paper investigates the effectiveness of related approaches regarding bucket imbalance issues by showing statistics for several attention heads of a pre-trained transformer.  A precise metric is designed to quantify this notion of efficiency (""attention utility""), and later this metric is optimized by learning separate parameterized hash functions for queries and keys. To be able to optimize this metric, the authors use the unbiased approximation to the softmax function proposed by Performer (Choromanski et al., 2020) as a regularization term. Experiments on several NLP and CV tasks show that the proposed method achieves better results than previous fast-transformers while being faster than a standard transformer. ",0.43859649122807015,0.16556291390728478,0.24038461538461536
351,SP:20cb2ff80149c31964ada69503cdebf166fb6ce2,"This paper proposes a new architecture for graph convolutional network based on graph powering operation which generates a new graph based on the shortest distance between pair of nodes.  Its main motivation is to overcome the dominance of the first eigenvector in the existing GCN architectures based on the graph Laplacian operator. The theoretical evidence for the robustness is provided based on the signal-to-noise (SNR) ratio of the simplified stochastic block model (SBM). Two versions of the algorithms are proposed, namely the robust graph convolutional network (r-GCN) and variable power network (VPN). First, r-GCN is based on augmenting the graphs with graph powering operation. Next, VPN replaces the adjacency matrix of the graph convolutional operator by the newly proposed variable power operator. An additional sparsification scheme is proposed since the graph powering operation densifies the original graph.  ","This paper proposes a graph convolutional operator based on graph powering and applies it to GCN architecture to improve the performance and robustness. This work is mainly motivated by the paper (Graph powering and spectral robustness, Abbe et al., 2018). The authors introduce the graph powering to graph convolution neural network domain to replace the original Laplacian operator. They further propose a graph sparsification/pruning strategy on the powered adjacency matrices in order to reduce the complexity and increase the robustness against adversarial attacks. They also provide theoretical analysis to prove that the proposed powering operator and subsequent methods have some spectral properties and theoretical feasibility. However, some conclusions are limited to the ideal situations or seem subjective. Extensive experiments are conducted to show better or comparable performance in both benign and adversarial situations. ",0.20567375886524822,0.21641791044776118,0.21090909090909088
352,SP:20e36f18fdbe55fab55bc32d0332d00b061b58f8,"The work proposes NeuBoots: a new ensembling method for neural networks inspired by bootstrapping estimation. The method is simple and involves training one neural network to simultaneously represent a whole family of models; each such model is scored during training with a loss where different training objects have different weights. These models are obtained from the base model with a single multiplication of weights of training objects (or, more precisely, weights of sets of training objects) and representations in the final part of the network. During testing, models are ensembled for multiple random weightings for training objects. The authors validate the method on computer vision tasks and synthetic data. It is concluded that the method is superior to other bagging methods on various metrics related to uncertainty estimation such as active learning performance or out-of-distribution detection metrics and is more computationally efficient.","This work advances an approach for generating bootstrapped neural networks through a single training run, instead of training individual networks for each bootstrap subsets of the dataset. The method, dubbed Neural Bootstrapper (NeuBoots), can be seen as a last-layer approach for uncertainty quantification with an adaptive bootstrapping block at the end. This bootstrapping block borrows ideas from random weight bootstrapping, generative bootstrap samplers and block bootstrapping. In detail, groups of samples are given the same bootstrapping weight (sampled from a Dirichlet distribution randomly initialized at each epoch), with this weight used for perturbing the penultimate layer features and to ponderate the loss for each corresponding sample. Multiple predictions can be obtained from different samplings of the bootstrap weights applied again to the penultimate layer features leading to computationally efficient bagging. NeuBoots is evaluated on an array of datasets against MC-Dropout and DeepEnsembles, displaying interesting results. ",0.1597222222222222,0.1564625850340136,0.15807560137457044
353,SP:2112a176f4ade9d808d78e1795701da15a5c146a,"This paper empirically investigates two crucial factors: affinity and diversity in useful data augmentation strategies. Through extensive experiments on existing image augmentation methods, it demonstrates that a good augmentation practice should bring high affinity and diversity for validation and training data. Specifically, it uses the accuracy gap between augmented and clean validation data to measure affinity. The diversity is measured by final training loss with the augmentations used in training.","This paper studies the problem of data augmentation that obtains new training examples by modifying existing ones. Data augmentation is popular in machine learning and artificial intelligence since it enhances the number of training examples. However, its effect on model performance remains unknown in practice. An augmentation operator (e.g. image rotation) can be either helpful or harmful. This paper introduces two novel metrics, named affinity and diversity, to quantify the effect of any given augmentation operator. The authors find that an operator with high affinity score and high diversity score leads to the best performance improvement. ",0.21428571428571427,0.15463917525773196,0.17964071856287425
354,SP:21296aeb09e1d3d7ca0a729f1ab614f15b12960d,"In this paper, the authors introduce a method for missing flow estimation. These method has potential to address some important applications in transportation, power systems and water management. One major difference compared with the previous work is that edge features are incorporated into the optimization process so that the model has a better chance at learning edge-specific patterns. The experimental results have shown some success of the proposed method in traffic and power datasets.","The authors propose a parametric regularizer for estimating unobserved flows in networks, incorporating edge features and other side information. The parameters of the regularizer are learned by means of minimizing the empirical cross-validated MSE. Regularization is necessary because the basic problem, while convex, typically is under-constrained; resulting in a infinite space of solutions which match the observed data.  ",0.17333333333333334,0.21666666666666667,0.1925925925925926
355,SP:213a295549ebc49eda533baf77de2e0aed81cbb1,"The paper defines a new measure of distance between a hypothesis $h$ and a point $x$, which is the probability mass of the smallest (by probability mass) disagreement region (induced by the other $h' \in \mathcal{H}$) containing $x$. In general this is intractable so the authors offer two assumptions about the relationship between this measure and more tractable quantities (one being the distance between the model parameters of those hypotheses, and the other being what the authors call the 'variation ratio'). The reasonability of these assumptions is then assessed, and the algorithm is tested on a variety of dataset and against several reasonable competitors. ","This paper is motivated by the idea that unlabelled samples near the estimated decision boundary show to be very informative/useful in an active learning setting. However, measuring the distance between an instance and the decision boundary is a non-trivial task in numerous machine learning algorithms, especially in deep learning. The paper proposes a (theoretical) sample distance to the decision boundary that relies on the least probable disagreement region (LPDR) that still contains the sample. The paper makes two assumptions to evaluate the proposed distance empirically: (1) closeness of the parameters of two hypotheses implies closeness of these hypotheses as defined by the probability of the disagreement region and (2) the variation ratio of labels obtained by evaluating a set of hypotheses sampled around the decision boundary is a proxy for the proposed distance. Considering these assumptions, hypotheses are sampled around a given decision boundary by adding gaussian noise to the parameters of the fitted model. Both assumptions are validated empirically on different datasets and varying levels of variance of the noise term to show the effect on the variation ratio and distance respectively. Consequently, an iterative active learning algorithm is proposed which adapts the variance of the noise term in order to select the predefined number of samples. Extensive experimental results indicate that LPDR outperforms other uncertainty based active learning algorithms on various datasets or is at least on par with them. ",0.3047619047619048,0.13675213675213677,0.18879056047197643
356,SP:214f7d764cebce811e175531d0b2e7f0c8dc18c3,"This paper proposes a hybrid VAE-GAN model, called the latent space renderer-GAN (LSR-GAN), with the goal to “imagine” the latent space of a VAE, and to improve the decoding and sampling quality of a VAE. First, a VAE-like model is trained, after which the encoder weights are frozen, and the decoder is trained as the generator of a GAN (together with an auxiliary discriminator). The generator loss also contains a reconstruction-like term in the latent space, described by the negative log density of the encoding distribution of the original latent conditioned on the output of the generator: -log q(z|g(z)). ","The paper proposes a new method for improving generative properties of VAE model. The idea is to train VAE in two stages: at first, train the vanilla VAE, then at the second stage freeze the encoder part and train the decoder part as a GAN generator with an additional regularizer which encourages cycle consistency in the latent space. Also the authors claim that other VAE-GAN hybrids which try to improve VAE model are “misguided” and poor samples and reconstructions of VAE are the consequence of minimum description length problem. ",0.2616822429906542,0.3111111111111111,0.2842639593908629
357,SP:21726ae5d1bf57c0e73a5b584475409de91f1214,Image augmentations have recently become a standard component of deep RL algorithms.  Previous work has enforced consistencies at a sample-level.  This paper proposes to look at the distribution of statistics at a minibatch-level in order to enforce consistencies.  Paper shows results on standard benchmarks in discrete and continuous control (Atari and DMC).,"This paper proposes a regularization method for reinforcement learning that encourages the Q-value of the original image (i.e., original state) and the Q-value of the transformed image (new state) to be the same. This method enhances the robustness of RL methods against environment variation. This paper introduces the background and the motivation of the proposed method. Discussion and comparison of the difference between related works, such as SAC and DrQ, is also provided. Experiments show that the proposed method can improve the performance of image-based methods, even outperforming several state-based methods.",0.16666666666666666,0.09375,0.12000000000000002
358,SP:21921e3032fd96cb1ed6c602cfe914ba15097c7f,"This paper investigates linearly nearly Euclidean metrics on Riemannian manifolds under the Ricci flow. Analysis, focusing on the stability and convergence of the evolution of such metrics, is presented. In addition, the utility of the analysis for measuring the approximation of gradient flow in the context of training neural networks is demonstrated.",The paper concerns the Ricci flow and surgery to handle singularities occuring during the Ricci flow. The authors propose linearly nearly Euclidean metrics that they prove are stable under the Ricii-DeTurck flow. The authors use this to approximate steepest descent gradient flows in information geometry and state that they obtain a new method for geometric optimization on manifolds.,0.21153846153846154,0.1864406779661017,0.19819819819819823
359,SP:2194acbf643b821c3c8e83481ff8af8a43e6fa83,"This paper proposes a variant of local SGD, post-local SGD, for distributed training of deep neural networks. It targets to mitigate the generalization gap caused by large batch training. The idea is straightforward and easy to understand-- start the training with standard mini-batch SGD and later switch to local SGD. The rationale behind this scheme is that switching to local SGD helps the training converge to flatter minima compared to using large-batch SGD, which correlates with sharper minima, and that helps close the generation gap. Switching to local SGD at the second phase also helps improve communication efficiency by reducing the amortized communication volume. The authors perform empirical studies using ResNet and DenseNet to conclude that post-local SGD outperforms large-batch SGD in terms of generalization performance while also with improved communication efficiency. ",This paper proposes a new distributed computation technique for SGD training of deep neural networks. The proposed method is a modification of the local SGD which updates models distributed to several workers in a parallel way and synchronize the model parameters at every few epochs. The local SGD shows a nice performance but it is not robust against large mini-batch size. The proposed method is called post-local SGD that starts the local SGD after some epochs of standard mini-batch SGD. This modification makes the local SGD robust against the large mini-batch size. The authors conducted thorough experiments to investigate the performance of the proposed method. The experiments reveal that the proposed method gives better performances than the mini-batch SGD and the vanilla local SGD.,0.25547445255474455,0.2713178294573643,0.2631578947368421
360,SP:21bfc8550e9a1a5ee3a68130c98e793a412241c3,"This paper studies whether observational data can be used to estimate the outcomes of certain interventions. This is especially important since cost of interventions can be high and in some cases irreversible. This paper empirically demonstrates the effectiveness of using the M-information flows framework for neural networks to assess different kinds of information flows in the network, and then measuring the change in outcome by intervening on different types of flows. They consider fairness in ML as a case study where there are two types of distinct information flows: the label flow and the bias flow. By intervening on paths (by pruning nodes or edges or reducing weights of edges) which contribute to bias in the outcome, the authors show that they can achieve the desired effect of reducing bias. Thus, the paper shows that information flows can offer useful information about where to intervene to achieve certain outcomes.","The paper studies the possibility of using the measures of information flows to intervene with ANN for reducing bias while improving/maintaining accuracy. It adopts the M-information flow framework proposed by Venkaatesh et al., and proposes a quantitative notion of information flow and a method for estimating such flows. The magnitude of information flows can then be used to understand and compare the impact of different pruning strategies on the outputs, as well as their fairness-accuracy tradeoffs. ",0.14666666666666667,0.27848101265822783,0.19213973799126635
361,SP:21ca077ce1d33a7fe8becb70da2715b3ab5cf6bb,"The paper investigates quantum kernels and learning with them, and whether it can be advantageous over using classical computations. A lemma is proposed which bounds the eigenvalues of the integral operator of a quantum kernel, and a theorem which shows how the empirical risk of the KRR solution with certain kinds of quantum kernels is bounded from below. Further, a biased quantum kernel is introduced for which the integral operators are also investigated. From these results (and experimentally verifying the last of them) the authors conclude that the advantage of learning with quantum kernels is restricted to very particular functions.","This article studies the learnability of functions using quantum kernels. More precisely, it investigates the potential advantages in learning that quantum kernels may offer compared to classical ones. The focus was put on ridge kernel regression as a running example of a learning task. In this case, the analysis boils down to two ingredients: 1) the spectral properties of the corresponding integration operator 2) the alignment of the function to learn with the first eigenfunctions of the integration operator. The contribution of this work is to highlight the fact that, under some assumptions, the class of functions for which quantum kernels would have an advantage over classical ones is very restricted: the functions that belong to RKHSs associated with the so-called biased kernels.",0.27,0.21774193548387097,0.24107142857142855
362,SP:21d29b68bb3e7cf18e699a98f7be35f9e12bdaaf,"This paper proposed a new regularization method via patch level interpolation.  During the training,  images within a batch will be used to construct an image graph. For example, for a certain image, its nearest neighbors in the feature spaces will be used.  Then patches from its neighbors will be used to interpolate to each patch in that given image.  Thus a straightforward application for such regularization is semi-supervised training.  Moreover, in this paper it has demonstrated such regularization can be extended with virtual adversarial training and mixup training. ","The paper proposes a general regularizer called the Patch-level Neighborhood Interpolation (Pani) that constructs patch-level graphs at different levels of neural networks. Specifically, it is based on the k-nearest patch neighbors at each layer and linear interpolation for each patch. By applying this proposed regularizer framework into two special cases and get Pani VAT and Pani MixUp. Numerical experiments are comprehensive and convincing. ",0.14606741573033707,0.19696969696969696,0.16774193548387098
363,SP:21d5838371c68811775cd8bcf04b2374d427fe86,This paper propose two methods for improve deep image compression performance: (i) Global Reference Module and (ii) Mean-shifting GDN Module (GSDN). (i) Global Reference Module searches over the decoded latents to find the relevant latents to the target latent for improve accuracy of entropy estimate. Authors extended Yang et al. 2020 method to using masked patch. (ii) GSDN extends GDN to use subtractive operation.,"The paper presents a learning-based approach for image compression. To reduce the compression rate, it describes two novel extensions, one to take the global context into account and an improved version of the commonly used GDN layer. Their advantage has been shown in a thorough ablation study. Overall, the method achieves superior performance compared to standard codecs as well as other state-of-the art learning-based method on the evaluated dataset (from Kodak).",0.16923076923076924,0.14666666666666667,0.15714285714285714
364,SP:21f870f084d0b9b91f258cf893c66fd207570236,"This paper introduces potential use of intermediate structured representation of input space called “concepts” which are most likely human-interpretable. This intermediate space is then used for few-shot learning instead of using only the input space. This leads to better classification performance on the task, and it shows that injecting human-interpretable structured representation into task correlates with better performance (as one would hope). The paper uses datasets from different domains and shows improvement over approaches that don’t use the above defined “concepts”.","The paper presents a knowledge-driven prototypical learning strategy for few-shot classification tasks. The main idea of this work is to introduce a set of concepts defined in the subspaces of inputs and represent each class as a group of concept prototypes for few-shot learning. Following the prototypical networks, the method first computes the concept embeddings of an input, and then takes the summation of the distances between those embeddings and their corresponding concept prototypes in each class to estimate the class probability.  The experiments validates the proposed methods on 4 benchmarks in three different domains, including vision, language and biology. For the biology task, the authors also develop a new benchmark on cross-organ cell type classification. ",0.2,0.14166666666666666,0.16585365853658537
365,SP:22065b789e9ea434dcfae0443f24f1bbd95e116f,"The paper introduces a variational model for text to image and image to text mappings. The novelty consists in separating the modeling of text and image latent representations on one hand and the modeling of a shared content representation on the other hand. Priors for text, image and shared representations are generated through an invertible – flow model. The motivation for this is to allow for complex priors. Training for the shared component is supervised using aligned text and image data, while training for the residual text and image components is unsupervised. Experiments are performed for text and image generation, using training data from the COCO dataset.",This paper addresses the problem of many-to-many cross domain mapping tasks (such as captioning or text-to-image synthesis). It proposes a double variational auto-encoder architecture mapping data to a factored latent representation with both shared and domain-specific components. The proposed model makes use of normalizing flow-based priors to enrich the latent representation and of an invertible network for ensuring the consistency of the shared component across the two autoencoders. Experiments are thorough and demonstrate results that are competitive or better than the state-of-the-art.,0.20754716981132076,0.2391304347826087,0.22222222222222224
366,SP:221f1dde4d5baeae63e928e94f8759a7b4b1c926,This paper considers the problem of calibrating quantiles outputted by a regression model. The data is assumed to draw from a non-iid source (e.g. time series with distribution shift). The paper proposes a method that adjusts the output quantiles to be better calibrated for a less-restricted definition of b-calibrated. Some further methods are also proposed to ensure the quantiles are monotonic and stable. Experiments are conducted to compare the proposed method with uncalibrated models and conformal predictions.,"For real-world applications where ML models are used, quantifying predictive uncertainty is an essential task as, for example, in safety-critical applications misclassification might have disastrous consequences. On the theory side, the analysis is typically performed under the i.i.d. assumption which could be unsatisfactory as deployed models inevitably encounter changes in the data generating distribution and/or certain dependencies that invalidate the results established for the i.i.d. setting. Focusing on regression, the authors design an adaptive (to distribution shifts) procedure that satisfies a certain calibration guarantee. The authors study the empirical performance of the proposed procedure on a collection of time-series and regression datasets.",0.14814814814814814,0.10909090909090909,0.12565445026178013
367,SP:22238bda86b9ade5ef7574767f30a6dd644d40c9,"The paper proposes a two-stage approach to learning with noisy labels (LNL). 1. a. Clean sample selection based on cosine similarity with k nearest neighbors in embedding space: the average of class distribution of those neighbors should be consistent with the label for sample to be selected.       b. Noisy sample relabeling using temporal self-ensemble: the prediction is defined is average over last L epochs. The sample is relabeled if the confidence of the prediction is higher than some threshold. 2. Training with self-consistency regularization: the regular training with mixup regularization is performed on selected and relabeled samples, with consistency regularization in form of cosine similarity. The paper tests the performance of method on multiple datasets both with synthetic and real-life noise.","This paper proposes ""S3"" framework for learning with noisy labels. Specifically, S3 consists of two stages. In the first stage, a relabelling approach and normalized neighboring voting are utilized to guide efficient sample selection; in the second stage, supervised loss (Mixup) and self-consistency loss are used to train networks on selected samples. S3 can be applied to both close-set label noise and open-set label noise and exhibit good performance on several benchmark datasets. ",0.152,0.25,0.18905472636815918
368,SP:2237245aeb115eb318e447d63ab3a4614d8eec06,"This paper investigates a so-called ""compressive transformer"" approach. The idea is to compress distant past memories into a coarse-grained representation while keeping a fine-grained representation for close past memories.  A variety of compression techniques and training strategies have been investigated in the paper and verified using tasks from multiple domains including language modeling, speech synthesis and reinforcement learning. Particularly, the authors propose a new benchmark PG-19 for long-term sequence modeling.  ","This paper proposes a way to compress past hidden states for modeling long sequences. Attention is used to query the compressed representation. The authors introduce several methods for compression such as convolution, pooling etc. The outcome is a versatile model that enables long-range sequence modeling, achieving strong results on not only language model tasks but also RL and speech. For testing and evaluating the modeling of really long context sequence modeling, the authors introduce PG-19, a new benchmark based on Project Gutenberg narratives. ",0.24,0.21176470588235294,0.22499999999999998
369,SP:223bbaf9169ba486cbfbc0d8c35d662ea211c358,This paper presents a learning framework for a hard attention mechanism. The glimpses captured by the attention mechanism are guided by the goal of minimizing output uncertainty for a downstream task such as classification. The authors pose this problem in a probabilistic framework which is based on Bayesian optimal experimental design (BOED). They devise a tractable approximation to the entropy over images and glimpse sequences and search for the glimpse sequences which minimize the output entropy of a recurrent classification model.,"The paper trains hard attention for image classification. The network is partially supervised by attention locations proposed to maximally reduce the entropy of the image label distribution. To propose these locations, the method needs an already trained image classifier conditioned on glimpses and their locations. Additionally, the method needs a generator of images, conditioned on the glimpses and their locations. This generator is approximated by searching a set of 1.5 million pre-generated images for close matches.",0.18518518518518517,0.19230769230769232,0.18867924528301885
370,SP:228d410d5d9e184b9c920f56f0a6011db801b77b,"This paper tackles the task of closed loop 6-DOF grasping of objects in simulation. The learned policy is a closed-loop policy, in that the gripper pose is continuously adjusted as the gripper approaches the object. The paper employs a combination of imitation learning, reinforcement learning, and auxiliary losses for training this policy. The policy operates upon information from point clouds as observed from a wrist-mounted camera.","The paper targets the problem of closed-loop 6D robotic grasping with a parallel gripper based on RGB-D in-hand-camera images. The policy takes an aggregated point cloud (computed from image history) as input (using a PointNet++) and outputs the pose transformation of the gripper. There are several contributions in the specifics of the proposed method. The policy is pretrained using behavioral cloning and DAGGER on known object models, where the expert is composed by a grasp pose sampler and the OMG grasp trajectory planner. Subsequently, the pretrained policy is improved using TD3. Actor and critic networks are each regularized via a loss for solving the auxiliary task of (independently from each other) predicting the final grasping pose. As the goal poses are only available for the expert demonstrations goals are added for the policy roll-out in hindsight, similar to hindsight experience replay, which does not require access to an object model. The approach is evaluated in simulation for grasping YCB and ShapeNet objects with a Franka Emika Panda robot. The evaluation covers ablations of several algorithmical and architectural choices.",0.34782608695652173,0.13114754098360656,0.19047619047619047
371,SP:228fd66964ccbf61d40a38bd12db78cad1401136,"In this paper, the authors consider stochastic optimization in the setting where a validation function is used to guide the termination of the algorithm. In more details, the algorithm terminates if the gradient of the validation function at an iterate is smaller than a threshold. In this framework, the authors consider several variants of SGD, including distributed variant and SVRG, for each of which the authors study the expected number of iterations for a prescribed accuracy under an assumption between the training and validation set.","This paper proposes an optimization approach in which the optimizer computes the gradient on a given function yet uses another to decide a stopping time. Conceptually those functions are empirical errors on train and validation folds in the most common setting, although the authors seem to use other settings later in the paper to consider decentralized optimization schemes. The authors introduce a bound on the Wasserstein distance between the train and validation distributions in their analysis which plays a crucial role in their results. The authors use these results to motivate variants of existing optimization algorithms. ",0.24705882352941178,0.21875,0.23204419889502764
372,SP:22aa0e4ed150eb964537313068e43b8b32e26a51,"The paper investigates a pure deep learning architecture for Univariate time series analysis by simply ensembling feed-forward networks, along with the residual stacking mechanism for fluid learning. Each of the generic block consists of 4 FC layers followed by the use of forward and backward predictor to have forecast and backcast output of the original input. These blocks forms the stacks, where each stack provides the residuals and the forecast responses further to the next stacks, which ultimately provide the global forecast. To make the internal stack outputs interpretable, assumptions are imposed on the trend model, which follows a polynomial function of time vector, and seasonality model which follows periodic Fourier series. Further, the ensembling of models based on different metrics and input windows is used for better accuracy.    ","The paper proposes a DL architecture that achieves better performance on time series prediction. The proposed architecture is relatively straightforward and composes residual blocks. While the paper does achieve superior results, a lot of the text is devoted to comparing to prior work and arguing that DL approaches can do better than hand-crafted approaches, instead of focussing on the importance of specific technical contributions made in the paper. ",0.13846153846153847,0.2608695652173913,0.18090452261306533
373,SP:22b6740eb3b2977aaffb8919aee4883f62af815f,"The paper studies an off-policy evaluation (OPE) problem for Markov decision processes (MDPs). It suggests an optimization-based method that can construct a non-asymptotic confidence interval, for a given confidence level, for the value function of a policy starting from a fixed initial distribution. The paper builds on the works of Feng et al. (2019, 2020); the main advantages of the current work with respect to the previous methods are that the suggested approach guarantees a faster convergence rate, it does not require full independence between transition pairs, and it does not need the global optimal solution of the underlying optimization problem, in order to construct guaranteed confidence intervals. The authors present some theoretical results about the construction, including a discussion on the special case of using RKHS approaches, and also present numerical experiments on benchmark problems, such as the inverted-pendulum, cartpole and type-1 diabetes.","This work constructs non-asymptotic confidence intervals for off-policy evaluation. This is achieved by assuming that the reward at any given time only depends on the state action pair, leveraging that assumed structure to define the difference between the empirical and estimated bellman residual operators as a Martingale difference sequence. This, in turn, then allows the authors to apply a Hoeffding-like concentration inequality which applies to Hilbert spaces. The authors then provide a derivation of the confidence bounds by considering the divergence between policies. The work improves on the rate of prior work from $O(n^{-\frac{1}{4}})$ to $O(n^{-\frac{1}{2}})$ and allows for estimation without the need of global optimality via the dual formulation, both of which are very nice additions to the literature. Experimental evaluation backs up the authors’ claims, showing very strong performance with respect to prior art. ",0.15436241610738255,0.1564625850340136,0.1554054054054054
374,SP:22c51358e79eeee073c17182afec21de4f57148a,"A knowledge distillation framework is proposed for efficient object recognition. In this framework, the teacher network (TN) performs high accuracy prediction while two student networks (SN) mimic the prediction from TN. The first SN learns from TN while the second SN is a binarized form (BSN) of the first SN.  The design is made for online inference is that the BSN first recognizes the image, leaving the rare category objects to be recognized by the TN. Furthermore, an attention supervision scheme is proposed to enhance the CNN prediction by focusing on meaningful image content.  The proposed method has been validated on CIFAR-100 and Tiny-Imagenet.",The proposed work trains a teacher-student network using an online distillation paradigm. The student is a binarized network (BSN) trained to be accurate on frequent classes. An attention triplet loss is employed to improve the accuracy of the BSN and its ability to detect outlier classes. Faster convergency of BSN vs Real Valued Student network is claimed. A new metric to evaluate the actual gain in network efficiency is proposed. ,0.16037735849056603,0.23943661971830985,0.19209039548022597
375,SP:22eafda74c0a1a8184893a5ed47a36cfab1c361e,"This paper identifies a type of implicit under-parameterization phenomenon in deep RL methods that use bootstrapping.  It is found that after an initial learning period, the effective rank of the feature matrix keeps decreasing. This implies that the representational power of the network is not fully utilized. The authors call it a type of implicit under-parameterization.  Moreover, the emergence of this under-parameterization strongly correlates with the poor performance.  Some preliminary theoretical analyses are provided to explain this phenomenon. ","This paper discusses a phenomenon wherein the feature vectors of the learned value function in reinforcement learning (RL) lose their diversity as training progresses. The paper analyzes the rank of the final hidden layer in the model parameterizing the value function and shows experimentally that for offline-RL and online-RL setups on Atari and Gym benchmarks, this rank collapse occurs with a drop in the average return. The paper further develops two models for understanding this phenomenon, (i) where the value function is modeled using the neural tangent kernel, and (ii) where the value function is modeled using a deep linear network. The paper argues that bootstrapping results in reduction of the rank of the feature matrix as training progresses for these models. A regularization term that equalizes the singular values of the feature matrix is used to mitigate this rank collapse and experimental results on Atari benchmarks are shown with this regularizer.",0.2839506172839506,0.14935064935064934,0.19574468085106383
376,SP:22ec87bbcb57e40a3485af92cb5aa5f6ab8968f6,"The paper provides a budget-aware regularizer method to train the network to be pruned. Existing methods based-on the regularizer method suffer from satisfying the user-specified constraints and resort to trial-and-error approach. The authors leverage logistic function and continuous heaviside function for continuous relaxation of the discrete variable to select the channels to be pruned.  There are four types of budget constraints (channel, volume, parameter, FLOPs).  ","This paper presents a new method for structure pruning called ChipNet. The ChipNet employs continuous Heaviside function with commonly used logistic curve and crispness loss to estimate sparsity masks. A combination of above three components is helpful to obtain approximately discrete solutions for a continuous optimization scheme.  As a result, it is possible to get a highly sparse network out of an existing pre-trained dense network. Experimentally, ChipNet outperforms other previous structured pruning methods by a large margin. ",0.15714285714285714,0.13924050632911392,0.1476510067114094
377,SP:22f0d88501a4d3cbaed9e347b94d600da992876f,"This paper discusses several protocols including data augmentation, point distribution, loss function, ensemble scheme, and testing models, which serves as a kindly reminder that the training protocol matters. As claimed, earlier work like PointNet++ can still achieve comparable performance to more recent methods. Such observations are useful, as different methods are supposed to be developed and measured under a unified setting. Moreover, the authors investigated a new projection-based SimpleView method by converting point clouds into depth images, achieving SOTA performance without pretrained CNNs.","In this paper, the author(s) do a careful analysis on the classification performance of various modern point cloud processing networks and show empirically that with evaluation protocol set the same for different models, PointNet++, which is a relatively old model, has similar or better performance than newly proposed methods. The author(s) also show a simple projection based baseline SimpleView that can work surprisingly well on point cloud classification task. They evaluate methods on ModelNet40 and ScanObjectNN datasets.",0.17857142857142858,0.189873417721519,0.18404907975460125
378,SP:230eeb76bd4370e4820aa5978d1d3080cbb27d6f,"This work presents several enhancements to the established Model-Agnostic Meta-Learning (MAML) framework. Specifically, the paper starts by analyzing the issues in the original implementations of MAML, including instability during training, costly second order derivatives evaluation, missing/shared batch normalization statistics accumulation/bias, and learning rate setting, which causes unstable or slow convergence, and weak generalization. The paper then proposes solutions corresponding to each of these issues, and reports improved performance on benchmark datasets.          ","In the work, the authors improve a simple yet effective meta-learning algorithm called Model Agnostic meta-learning (MAML) from various aspects including training instability, batch normalization etc. The authors firstly point out the issues in MAML training and tackle each of the issue with a practical alternative approach respectfully. The few-shot classification results show convincing evidence.",0.21333333333333335,0.27586206896551724,0.2406015037593985
379,SP:2335481648e1f24c1da00afb90176e0c5ab0ea2b,"This paper proposes a method for Distributionally Robust Optimization (DRO). DRO has recently been proposed (Namkoong and Duchi 2016 and others) as a robust learning framework compared to Empirical Risk Minimization (ERM).  My analysis of this work in short is that the problem that this paper addresses is interesting and not yet solved. This paper proposes a simple and efficient method for DRO. However, convergence guarantees are weak which is reflected in their weak experimental results. And for a 10-page paper, the writing has to improve quite a lot.","This paper studies the Distributionally Robust Optimization (DRO), in the sense that the weights assigned to the training data can change, but the training data itself remains unchanged. They demonstrate that SGD with hardness weighted sampling is a principled and efficient optimization method for DRO in machine learning and is particularly suited in the context of deep learning. On the theoretical side, they prove the convergence of our DRO algorithm for over-parameterized",0.2222222222222222,0.273972602739726,0.24539877300613497
380,SP:2335d2a4b9c3c1bb740563cee4bf529f32400772,"This paper introduces the multistage optimization technique for federated learning applications. Specifically, multistage optimization first uses federated optimization algorithms like FedAvg and SCAFFOLD and converges to some budget, and then uses minibatch algorithms like SGD or accelerated SGD in order to converge faster to a point with very small error. Because centralized methods are optimal when data are heterogeneous and local methods are optimal when data are purely homogeneous, using a multistage optimization technique can incorporate the benefits from both sides.  The theoretical part is relatively easy. The proof is to choose an appropriate error budget to which federated optimization algorithms converge, and then choose the hyperparameters for the federated optimization algorithms in the first stage and the minibatch algorithms in the second stage, e.g. learning rate, momentum, etc. The theoretical part only includes the convergence results for the strongly convex case.  The empirical part includes two experiments: logistic regression and neural network, which belongs to strongly convex case and nonconvex case respectively. For each experiment, the authors compare different minibatch algorithms like SGD, AGD, different local methods like FedAvg, SCAFFOLD, and some multistage procedures that combine local methods with minibatch methods. For the convex setting, multistage procedures perform the best, and for the nonconvex setting, multistage algorithms also perform generally the best.  ","It is known that if the level of heterogeneity is sufficiently high, then accelerated minibatch SGD is optimal for federated optimization matching the known lower bound of (Woodworth et al., 2020a). On the other hand, when the level of heterogeneity is very low, then FedAvg/LocalSGD outperforms the former in terms of communication complexity and needs only a few communication rounds given enough local computation. This paper *proposes* a multi-stage optimization procedure and *claims* that it nearly matches the lower bound for all heterogeneity levels.",0.09345794392523364,0.23255813953488372,0.13333333333333333
381,SP:235671d38b4e5b8b3d978b285ffc60f22f30889b,This paper provides a new technique to adapt a source neural network performed well on classification task to image segmentation and objective detection tasks via the author called parameter-remapping trick. The parameter remapping uses weights from the source neural network to the two-stages: architecture adaption phase and parameter adaption phase. The technique results in improvements in both performance and training time.,"The paper proposes a method called FNA (fast network adaptation), which takes a pretrained image classification network, and produces a network for the task of object detection/semantic segmentation. The process consists of three phases: Network Expansion, Architecture Adaptation and Parameters Adaptation, and uses the developed parameter remapping scheme twice. Experiments show that it outperforms recent other NAS methods for these two tasks with same or less computation.",0.1746031746031746,0.16176470588235295,0.16793893129770993
382,SP:23726c6ff50e4ff1beb7f21e31a9f6286a656b1e,"This paper studies how to improve the multi-task learning from both theoretical and experimental viewpoints. More specifically, they study an architecture where there is a shared model for all of the tasks and a separate module specific to each task. They show that data similarity of the tasks, measured by task covariance is an important element for the tasks to be constructive or destructive. They theoretically find a sufficient condition that guarantee one task can transfer positively to the other; i.e. a lower bound of the number of data points that one task has to have. Consequently, they propose an algorithm which is basically applying a covariance alignment method to the input. ","This paper analyzed the principles for a successful transfer in the hard-parameter sharing multitask learning model. They analyzed three key factors of multi-task learning on linear model and relu linear model: model capacity (output dimension after common transformation), task covariance (similarity between tasks) and optimization strategy (influence of re-weighting algorithm), with theoretical guarantees. Finally they evaluated their assumptions on the state-of-the-art multi-task framework (e.g GLUE,CheXNet), showing the benefits of the proposed algorithm.",0.15789473684210525,0.2222222222222222,0.18461538461538463
383,SP:23746625f66c6cd7b2a4cc8e0e452d81a948d34b,"The paper proposes methods to address churn in deep neural networks for classification, defined as the extent of disagreements in predictions of two models trained on the same data with the same algorithm. In addition to an existing measure of churn that is based on exact match of predicted classes, the paper introduces a soft measure of churn that measures disagreement by comparing the two models' class probability distributions. The paper proposes three regularization terms that can be added to the primary loss function used during training to reduce churn: two single-model regularization terms (based on cross entropy and KL divergence respectively) that encourage the model to output a more uneven probability distribution for an example, and a divergence-based term that is used by training two models simultaneously and that imposes a KL-divergence-based penalty that encourages the two models to output probability distributions that are as similar as possible. Experiments with ResNet architectures on CIFAR-10/100 and ImageNet indicate that the proposed approaches and their combination indeed reduce churn and do so to a larger extent than the two-model divergence-based approach applied in conjunction with cross-entropy that was proposed in work by Anil et al. in 2018 (although the improvement seems quite minor on ImageNet).","The paper investigates two methods to reduce churn in neural network classification prediction. Churn is when two networks trained on the same data produce outputs that disagree, due to randomness in the training process. The authors identify several sources of randomness, from underlying hardware differences to parameter initialization and more. The authors propose two ways to mitigate churn. One is to use entropy minimization to favor more confident predictions. The second is to use co-distillation, a form of online ensemble learning. The authors show that both together do a good job of reducing churn on three data sets.",0.14553990610328638,0.31313131313131315,0.1987179487179487
384,SP:237b129348ea81633989e45c3db9b6e8ef6fdfa2,"This paper studies multi-task learning (MTL) from the deep learning perspective where a number of layers are shared between tasks followed by specific heads for each task. One of the main challenges in this problem is to decide the best configuration among a large number of possible ones (e.g., the number of layers , number of neurons, when to stop the shared part of the network). In this paper, the authors fix the network architecture, and learn which filters (among the already learned ones) should be dedicated to (and hence fine-tuned for) a specific, and which ones should be shared between multiple tasks. ","This paper proposes a framework for learning multi-task convolutional neural networks. For each layer of the network, the proposed algorithm assigns a subset of the layer's channels to each of the tasks. This is in contrast to existing methods that assign whole layers to tasks. There are two key ideas here: (1) instead of searching in the space of binary assignments of layers to tasks, search in the continuous space of fractions of channels assigned to each layer, subject to some consistency constraints; this allows for using finite differences for gradient estimation which can be fed into a black-box optimization procedure; (2) the use of distillation to estimate the performance of a given assignment, rather than retraining many models. Experimentally, the proposed framework performs relatively well on the Visual Decathlon benchmark.",0.23809523809523808,0.1865671641791045,0.20920502092050208
385,SP:23873ae412ac3528036025fc3f53896c220984b4,"This paper proposed a new contrastive learning method called CLOOB, which minimized the leave-one-out upper bound (InfoLOOB) on mutual information with the modern Hopfield networks. Concretely, Hopfield networks replace the original embeddings by retrieved embeddings in the InfoLOOB objective.  The retrieved embeddings are more robust as they capture the common covariance structure of all sample embeddings, leading to a stable performance of InfoLOOB. Extensive experiments on several zero-shot datasets show that the proposed CLOOB method outperforms the well-known CLIP model across all considered architectures.","By using the InfoNCE loss for model training, CLIP has achieved great success. In this paper, the authors propose CLOOB, short for ""Contrastive Leave One Out Boost"", where modern Hopfield networks are used together with the InfoLOOB objective. InfoLOOB is a leave-one-out upper bound of mutual information, and modern Hopfield networks replace the original embeddings by retrieved embeddings. Results show that CLOOB outperforms CLIP at zero-shot transfer learning across multiple architectures and datasets. ",0.3181818181818182,0.3684210526315789,0.3414634146341463
386,SP:23a43ab91a13463f9b5185d5bb0ab328ea6eb0c7,"The authors propose a method for learning macro-actions in a multi-step manner, where Sequitur, a grammar calculator, is leveraged together with an entropy-minimisation based strategy to find relevant macro-actions. The authors propose a system to bootstrap the weights of these macro-actions when increasing the policy's action space, and a system to increase the amount of data (and bias it towards macro-actions) used to learn a policy for when conditioned on this increased action-space. The authors test against a subset of the Arcade Learning Environment suite.","This paper introduced a way to combine actions into meta-actions through action grammar. The authors trained agents that executes both primitive actions and meta-actions, resulting in better performance on Atari games. Specifically, meta-actions are generated after a period of training from collected greedy action sequences by finding repeated sub-sequences of actions. Several tricks are used to speed up learning and to make the framework more flexible. The most effective one is HAR (hindsight action replay), without which the agent's performance reduces to that of the baseline.",0.17204301075268819,0.17582417582417584,0.1739130434782609
387,SP:23a6cf043248b37fc8b792217c58a97697d56290,"This paper extends the existing line of research of the dynamics of multiplicative weights update and similar algorithms for games.  It shows that for zero-sum two-player games and for population games satisfying certain conditions, that the entropy increases linearly as long as the strategies are far from the distribution; this implies that the strategies concentrate near the boundary in the long-run, in a sense that the paper formalizes.  Compared to previous work, this analysis applies to games that are not zero-sum--specifically, population games that satisfy a certain condition on the payoffs.","The paper studies the evolution of uncertainty in multi-agent game dynamics. More specifically, it studies how the probability distribution over the players' cumulative payoffs evolves as players use typical online learning algorithms to play the game.  The game uncertainty is quantified by the notion of Differential Entropy (DE) of such distribution, a quantity related to the Jacobian of the game dynamics. Authors show that DE increases linearly with time for a set of games including two-player zero-sum, coordination games, and population games, confirming the negative convergence results obtained in past works.",0.19791666666666666,0.20212765957446807,0.19999999999999998
388,SP:23c0b97268ae96bfb6f18bbefe9d3f208ce8170f,"This paper aims to achieve a better understanding of GAN fine-tuning. A synthetic experiment demonstrates that pretrained discriminators improve the quality of the initial gradients, and pretrained generators help with improving mode coverage. Transfer learning experiments on real image datasets reveal that pretraining primarily improves mode coverage rather than sample fidelity, and that datasets containing a diverse set of images are best suited for transfer.","This paper performs a large-scale study of transfer learning in GANs. It proposes a way to understand the relevance of a pre-trained generator and discriminator, as well as heuristics to select good source/initialization dataset and even a training snapshot. All of this is very valuable for the practitioners.",0.18181818181818182,0.23529411764705882,0.20512820512820512
389,SP:23d329d9d5208e429f714761d33eb48498700153,"The paper proposes a novel method for predicting multiple answer spans in question-answering (QA) tasks. When the Span-Image technique is applied to a base BERT model, the authors show performance gains on a single-span dataset (SQuAD) and substantial improvements on a multi-span dataset (an internal Amazon dataset). The authors propose that the method is both model-agnostic and can eliminate common post-processing steps via built-in architecture design choices.","This paper introduces a new QA model based on BERT, which is called Span-Image Network. The paper first points out that previous span extraction models model independent probability of the start and the end of the span, making the extension to multi-span extraction harder. Span-Image Network model the joint probability of the start and the end by deploying a 2-D convolution, enabling multi-span extraction.",0.17567567567567569,0.18840579710144928,0.18181818181818182
390,SP:240313e3722a62fac70228911f264ae16190fef6,"This paper proposes an extension of the attention module that explicitly incorporates phrase information. Using convolution, attention scores are obtained independently for each n-gram type, and then combined. Transformer models with the proposed phrase attention are evaluated on multiple translation tasks, as well as on language modelling, generally obtaining better results than by simply increasing model size.","This work aims to incorporate phrase representation into attention mechanism. The proposed method is straightforward (which is good): a convolution window with size n is used to calculate representation for an n-gram, which then replaces the token representation in a standard attention model. The paper implements the multihead version of the proposed phrase-based attention, more specifically, in a transformer model. Experiments with machine translation and language modeling show that it outperforms the token attention counterpart.",0.22413793103448276,0.16883116883116883,0.1925925925925926
391,SP:2416c3d070cc9b54e096cc57687749731f3b9193,"This paper demonstrates and proposes a solution for a new problem in continual learning which is the inverse of catastrophic forgetting. Compared to prior work, they study problems where the data distribution changes much more rapidly. They demonstrate that backpropagation based optimization loses its ability to adapt when tracking these rapidly changing continual learning problems.  They show a degradation in performance over time on permuated MNIST, non-stationary RL problems, and the bit-flipping problem. They propose a solution to this problem by reinitializing some portion of the weights of every layer. They propose a utility function to choose which layers to reinitialize based on a combination of adaptation-utility and contribution-utility. They demonstrate that utilizing this method, they can achieve better performance that does not degrade over time and that it works in more cases than l2 weight decay.","This paper investigates the problem of fast adaptation in a non-stationary online continual learning(CL) setting. It argues that keeping weight randomnization is important to fast adaptation in CL. However, current CL methods only performs weight randomization in the beginning of the algorithm; the weights loss randomness overtime, leading to degraded model performance. The paper presents a continual weight reinitialization algorithm to overcome the issue. In particular, it proposes to evaluate the utility of each hidden unit -- including importance to the current task and adaptation capability. Then selects a set of hidden units with low score and resets their incoming and outgoing weights. The authors conduct experiments to evaluate the performance of the proposed method.  ",0.15602836879432624,0.1896551724137931,0.17120622568093385
392,SP:24243429012ab70e9638a009b78e5a9a5b8d73be,"This paper proposes an algorithm for training networks with sparse parameter tensors. This involves achieving sparsity by application of a binary mask, where the mask is determined by current parameter values and a learned threshold. It also involves the addition of a specific regularizer which encourages the thresholds used for the mask to be large. Gradients with respect to both masked-out parameters, and with respect to mask thresholds, are computed using a ""long tailed"" variant of the straight-through-estimator.","This paper presents a novel network pruning algorithm  -- Dynamic Sparse Training. It aims at jointly finding the optimal network parameters and sparse network structure in a unified optimization process with trainable pruning thresholds.  The experiments on MNIST, and cifar-10 show that proposed model can find sparse neural network models, but unfortunately with little performance loss.",0.13580246913580246,0.19642857142857142,0.1605839416058394
393,SP:243e8027661d500c99d0e2633726895f32141b9e,The paper proposes a scalable approach via intention propagation to learn a multi-agent RL algorithm using communication in a structured environment. An agent encodes its policy and sends the “intention” to the neighboring agents with the assumption that only the closest agents would be the affected by it. The approach involves using techniques from the embedded probabilistic inference literature using mean-field variational inference. The joint-policy is estimated using the mean-field approximation that is obtained via propagating intents in an iterative manner. So this approach helps in avoiding the need to factorize the value function explicitly.,"The paper considers the cooperative multiagent MARL setting where each agent’s reward depends on the state and the actions of itself and its neighbors The paper has a theoretical claim that, for such reward structure, the optimal maximum entropy joint policy in the form that can be factored into potential functions, one for each agent. In particular, if the sum of all agents’ rewards is a function on pairwise actions, those potential functions are one for each agent and one for each pair of actions (i.e. the equation after Proposition 1).",0.15151515151515152,0.16129032258064516,0.15625
394,SP:244188d1cd932f3a06ce09157bb1206b62becfb0,"This paper described an interesting idea to leverage massively pre-trained models (specifically CLIP-based models) to infer offensiveness in images. The authors first gave detailed literature review regarding a recently raising concern about inappropriate images in computer vision datasets, and also performed several finetuning/probing baseline experiments to illustrate the feasibility to detect such inappropriate contents. Next the authors explored the possibility to mitigate the potential risk by utilizing the implicit knowledge learned by CLIP-based pre- trained models. Lastly the authors choose ImageNet for a proof-of-concept validation and show that the proposed approach can discover previously neglected offensive images.","The paper constructs a classifier of whether or not an image is offensive. This is operationalized by finding a dataset from the psychology community of a few thousand images and ordinal judgements of 'morality' from a study. Prediction of these judgements is predictably hard, in no small part because the data is small. To combat these issues, the paper uses CLIP and soft-prompt tuning. Soft-prompt tuning appears to be very effective for CLIP in this context reaching accuracies of over 95%, where baseline fine tuning only gets about 85%. ",0.11650485436893204,0.13186813186813187,0.12371134020618557
395,SP:244bbe4a2152e42292a91a9a05290205ee8deb5f,"This paper proposes a visualization method to reveal the class-specific discriminative patterns of DNNs in the input space. When added to images from another class, such patterns can lead the DNN to classify the images into the pattern's class. From the experimental results, the authors conjecture that images trained on natural data can have backdoors. It also claims that the method reveals the trigger patterns of backdoor attacks, that adversarially trained models learn simplified shape patterns, but an intentionally-perturbed robust dataset improves model robustness by sacrificing its ability to represent shapes. ","The papers proposes a simple method for visualizing the patterns learned by deep neural networks in the supervised classification setting. Informally, suppose you have an image x that is ""representative"" of the class y and let X be a set of images that belong to other classes. The authors propose an optimization problem that looks for a mask (i.e. set of pixels) along with values of those pixels such that when this pattern is added to any image in X, the model will predict the new image to have the label y. This optimization problem can be solved using iterative thresholding and one may control the level of sparsity as the authors studied. Despite its simplicity, it can reveal clear patterns, particularly on high resolution images, such as ImageNet. The authors, then, show how this method can be used to interpret neural networks, detect backdoor attacks during training, and verify robustness.",0.23404255319148937,0.14473684210526316,0.17886178861788618
396,SP:24573aabc247456e2c8f00de434d586a8c18fb26,"Global convergence of NNs is an important research direction in deep learning. There have been significant progresses in this direction since last year. Most noticeable, the Neural tangent kernels (NTK) [1], which shows in the infinite width setting, NTK is deterministic and remains almost constant during gradient descent. NNs are essentially the same as kernel methods. Proofs of global convergence of NNs (without normalization) are built on this intuition. ","This paper presents a general proof of the convergence of two-layer ReLU networks with weight normalization trained with gradient descent. Weight normalization re-parameterizes the weights to decouple the directions and lengths of kernels. Depending on the lengths of kernels the training process can be divided into two regimes, corresponding to updates of lengths and directions, respectively. One of the regimes naturally corresponds to lazy training where the directions remain stable. And there are transitions from one regime to the other when the lengths gradually change during the training process.",0.13043478260869565,0.0989010989010989,0.11249999999999999
397,SP:24819c1c943d8b83dd7e048a5bb4cf66fc5cc43e,"In various machine learning problems which can be formulated as a bilevel optimization problem and solved using gradient-based methods, the computation of hypergradients is necessary. However, the involved inverse Jacobian matrix in the hypergradient has been a computational bottleneck in high-dimensional settings. This paper proposes to use quasi-Newton matrices from the forward pass to approximate this inverse Jacobian matrix in the direction needed for the gradient computation which appears in the computation of hypergradients. The proposed algorithm is applied to both hyperparameter optimization and deep equilibrium models for CIFAR-10 and ImageNet, showing that it reduces the computational cost of the backward pass by up to two orders of magnitude. ","In implicit deep learning such as deep equilibrium models, computing the inverse Jacobian for the forward pass is computationally expensive. This paper propose an interesting approach to combine the information from the forward and backward pass to make an efficient estimate of the Jacobian inverse. In one approach, they propose to replace the Jacobian in the backward update with the quasi-Newton matrix, which is being already used/estimated in the forward pass solved by quasi-Newton method. Additionally, they propose an iterative update to the quasi-Newton matrix such that to helps its estimate toward the direction useful in the backward pass (they call this outer problem awareness).  They provide theoretical analysis of their proposed method and show that under certain conditions/assumptions, the forward pass still converges to the desired solution and the sequences of backward estimates converges to the loss gradient of needed to parameter updates. They provide numerical results in bi-level optimization (regularized logistic regression) and training DEQ for classification. In certain settings (bi-level optimization), they show that they outperform Jacobian-free and have similar performance to the state-of-the-arts but it is faster than all. For DEQ, they show similar performance to Jacobian-free.",0.3008849557522124,0.16748768472906403,0.2151898734177215
398,SP:249e30ce0a36a34eadd0026bb14048b8496d4b1a,"In this, paper a GANs-based framework for additive (image) denoising and demixing is proposed. The proposed methodology for denoising largely relies on the Ambient GAN model and hence the technical contribution of the paper in this task appears to be limited. Regarding demixing, as explained in the comments below, the proposed model appears to be superficial in the sense that neither theoretical analysis nor thorough empirical evaluation is provided. The proposed method is evaluated on both tasks (i.e., denoising and demixing) by conducting toy experiments on handwritten digits (MNIST).","This paper proposed two new GAN structures for learning a generative modeling using the superposition of two structured components. These two structures can be viewed as an extension of AmbientGAN. Experiments results on MNIST dataset are presented. Overall, the demixing-GAN structure is relatively novel. However, the potential application seems limited and the experiment result is not sufficient enough to support the idea. Detail comments are as following,",0.14285714285714285,0.19117647058823528,0.16352201257861634
399,SP:249f8a78affc76e690b74ebe05057bb1c30df872,"This paper structures how latents are used in an autoencoder to improve its performance. They are motivated by causal structure and independence of latent variables. They also sample using a sort of discrete mixup between latent codes from pushing forward data, and show various improvements there.","This paper presents a hierarchical latent variable model and accompanying sampling procedure for learning disentangled representations. Rather than a latent feature map/vector, the latent variables are used to condition affine transforms in the decoder. The authors combine this with a ‘hybrid’ sampling strategy, effectively sampling from the aggregate approximate posterior. Comparing with several baselines, the authors compare their model in terms of FID and various disentanglement scores. The authors also investigate generalization.",0.1956521739130435,0.1232876712328767,0.15126050420168066
400,SP:24a82292d86bf8f75e14cf09ac7c2e3af812df6e,"The author proposed the concept of function identification to address the limitation of parameter identification in the over-parameterized setting. The function identification states that the outputs of quadratic neural networks with the empirically minimized parameters and the true parameters have bounded difference with high probability. The reason to adopt the definition of function identification analysis is that it is hard ti make parameter identification with neural networks which usually are over-parameterized. The main theoretical result is Theorem 3.6, which is directly used in Corollary 3.7 to derive a robust generalization error bound, i.e., the loss function is evaluated on an arbitrary distribution. The robust generalization error bound is then used for three cases: (1) the upper bound of the regret of quadratic neural bandits, (2) bounds for transfer learning, and (3) generalization bounds for neural module networks.","The paper considers uncertainty estimation in overparameterized shallow neural networks with quadratic activation function. In particular, the paper assumes a non-linear regression model where labels are generated by an aforementioned neural net f* and noise is bounded. Then, uncertainty estimation is in giving a confidence interval around f*(x) for any given x. This differs from the usual uncertainty estimation in the linear regression, where one is concerned with deviation of parameters. The bound is a combination of the uniform convergence type bound on the excess risk and an interesting observation about strong convexity of the risk in the parameters of the network. The strong convexity here combined with Lipschitzness of the predictor allows to ""convert"" excess risk bound into the deviation between predictors.  The uncertainty estimation developed here is later used to give an explore-then-commit type of bandit algorithm with $T^{\\frac{2}{3}}$ regret.",0.176056338028169,0.16778523489932887,0.17182130584192443
401,SP:24ab2bc38257c8fa9f358d7a36d52663d7769e70,"This study aims to estimate the daily infection rate and individual risk of hospitalization through offering a modeling of COVID-19 pandemic. They find correlations between the individual characteristics (e.g., age and race) with the community neighborhood. They have use real-world data of NYC cases during the 2020 pandemic.","This work proposes (a) a community-transmission model, and (b) an individual risk-assessment model for COVID-19. The model is general enough to be applicable to any infectious disease. The model for (b) is enriched by inferred variables from (a) by (i) using them as covariates and (ii) addressing the selection bias in the data used for (b).   ### community-transmission model  First, this work links the temporal model for forecasting the number of infectious cases with a spatial model to account for disease propagation between regions.  The connection is made via modelling the relative infection rate as a Gaussian Process parameterized by a covariance matrix that depends on the expected number of infectious cases in the neighbouring regions.  The simulation results in the Appendix demonstrate that the model is able to uncover the true underlying parameters.  This spatiotemporal model is then fitted to the reported number of daily COVID-19 cases in NYC from March to July, and the results show a substantial spatial correlation in disease propagation.   ### individual risk-assessment model  Finally, an individual risk-assessment model is constructed using the inferred variables from the above fitted spatiotemporal model. The data used to build this model is from two hospitals in New York.  The authors addressed the issue of selection bias in the data via subject-specific weights by making the sample representative of true underlying prevalence and spatial population. The results seem to suggest a superior fit to the data compared to the unweighted model.   ",0.29411764705882354,0.06048387096774194,0.10033444816053512
402,SP:24d509d2318c32e01958afb57b50ec166fdb872f,"The author(s) posit a Mixture of Gaussian's prior for a compressed latent space representation of high-dimensional data (e.g. images and documents). They propose fitting this model using the Variational Information Bottleneck paradigm and explicate its derivation and tie it to the variational objective used by similar models. They empirically showcase their model and optimization methodology on the MNIST, STL-10, and Reuters10k benchmarks.","This paper considers the autoencoder model combining the usual information bottleneck and the Gaussian mixture model (GMM). Using an approximation to deal with GMMs, the authors derive a bound on the cost function generalizing the ELBO. The performance of the proposed method is tested on three benchmark datasets and compared with existing methods combining VAE with GMM.",0.16417910447761194,0.19298245614035087,0.17741935483870966
403,SP:24d65e5364becd291d2930cc18649c2aa4d44812,"The paper proposes the notion of ""neural persistence"", i.e., a topological measure to assign scores to fully-connected layers in a neural network. Essentially, a simplicial complex is constructed by considering neurons as 0-simplices and connections as 1-simplices. Using the (normalized) connection weights then facilitates to define a filtration. Persistent homology (for 0-dim. homology groups) then provides a concise summary of the evolution of the 0-dim. features over the filtration in the form of a barcode. The p-norm of the persistence diagram (containing points (1,w_i)) is then used to define the ""neural persistence""  NP(G_k) of a layer G_k; this measure is averaged over all layers to obtain one final neural persistence score. Thm. 1 establishes lower and upper bounds on N(G_k); Experiments show that neural persistence, measured for small networks on MNIST, aligns well with previous observations that batch-norm and dropout are benefical for generalization and training. Further, neural persistence it can be used as an early stopping criterion without having to rely on validation data.","This paper proposes to analyze the complexity of a neural network using its zero-th persistent homology. Each layer is considered a bipartite graph with edge weights. As edges are being added in a monotonically decreasing order, each time a connected component is merged with others will be recorded as a new topological feature. The persistence of each topological feature is measured as the weight difference between the new edge and the maximal weight (properly normalized). Experiments show that by monitoring the p-norm of these persistence values one can stop the training a few epochs earlier than the validation-error-based early stopping strategy, with only slightly worse test accuracy.",0.15,0.24324324324324326,0.18556701030927836
404,SP:24fb2650085abd5599f3dcd187a62a514608423a,"This paper aims at improving the computational cost of variance reduction methods while preserving their benefits regarding the fast provable convergence. The existing variance reduction based methods suffer from higher per-iteration gradient query complexity as compared to the vanilla mini-batch SGD, which limits their utility in many practical settings. This paper notices that, for many models, as the training progresses the gradient vectors start exhibiting structure in the sense that only a small number of coordinates have large magnitude. Based on this observation, the paper proposes a modified variance reduction method (by modifying the SpiderBoost method), where a 'memory vector' keeps track of the coordinates of the gradient vectors with large variance. Let $d$ be the size of the model parameter. During each iteration, one computes the gradient for $k_1$ coordinates with the highest variance (according to the memory vector) and an additional $k_2$ random coordinates. ","The author(s) provide a method which combines some property of SCGS method and SpiderBoost. Theoretical results are provided and achieve the state-of-the-art complexity, which match the one of SpiderBoost. Numerical experiments show some advantage compared to SpiderBoost on some deep neural network architecture for some standard datasets MNIST, SVHN, and CIFAR-10. ",0.08,0.21428571428571427,0.11650485436893206
405,SP:2507072848691b088371848b15b76b8e52827447,"This paper identifies bias of commercial Face detection API (Microsoft, Google, Face++, IBM) by sending face images generated from AirSim, in which different face attributes (e.g., skin color, age, face orientation, lighting conditions, etc) can be controlled and explored. The paper shows that for darker skin color and old age, the classifier tends to have a higher false negative rate (miss the face more). This is in particular more apparent if Bayesian Optimization is used to explore the parameter space based on the previous detection results to find the failure cases. ","The paper uses a proof-of-concept Bayesian parameter search-based simulation in virtual environment to probe biases of an already trained model towards specific categories that may have been sparsely represented in the training set. Understanding bias in trained models, especially in models involving end-to-end deep neural networks learners, is of high importance in machine learning. More specifically, probing the source of unintentional bias introduced as a result of skewed distribution in the training set and dissecting the biased performance is important for many applications such as surveillance, criminal profiling, medical diagnosis and predicting creditworthiness of a person. ",0.13043478260869565,0.1188118811881188,0.12435233160621761
406,SP:25106cb1a3e5ead20e58b680eeb6aa361c07e1ff,"In ES the goal is to find a distribution pi_theta(x) such that the expected value of f(x) under this distribution is high. This can be optimized with REINFORCE or with more sophisticated methods based on the natural gradient. The functional form of pi_theta is almost always a Gaussian, but this isn't sufficiently flexible (e.g. multi-modal) to provide a good optimization algorithm. In response, the authors advocate for using a flexible family of generative neural networks for pi_theta. Using NICE as a generative model is desirable because it maintains volumes. This means that we can adjust volumes in latent space and this directly corresponds to volumes in x space. Doing so is useful to be able to tune how concentrated the search distribution is and to explicitly reason about the mode of the search distribution.","As the title of the paper states, this paper tries to improve evolution strategies (ES) using a generative neural network. In the standard ES candidate solution is generated from a multivariate normal distribution, where the parameters of the distribution are adapted during the optimization process. The authors claim that the gaussian distribution, i.e., the ellipsoidal shape of the sampling distribution, is not adequate for the objective functions such as multimodal functions or functions with curved ridge levelsets such as the well-known Rosenbrock functions. The motivation is clearly stated. The technique is interesting and non-trivial. However, the experimental results are not very convincing to conclude that the proposed approach achieves the stated goal. Moreover, this paper may fit more to optimization conferences such as GECCO. ",0.1619718309859155,0.18110236220472442,0.17100371747211898
407,SP:25274bb362e98c010d0caa4849ac064586e19a0a,"In this paper, the authors propose ICLA, an approach to tackle the problem of incremental and continual learning. By keeping track of a model's ""internal"" representations of data, they identify and overcome the ""drift"" issue (as in continual learning). Particularly, they adopt an encoder-decoder style architecture to learn an embedding space that serves two purposes. (i) The embeddings from the encoder serve as an ""internal"" representation of data whose distribution is explicitly estimated using a Gaussian Mixture Model. (ii) By sampling embeddings from this GMM and passing them through the decoder, they turn this into a generative framework to support memory replay to overcome forgetting. When new classes are incorporated (as in incremental learning), additional components are added to the parameterization of the GMM. The authors provide some theoretical guarantees for error bounds and conduct empirical evaluations on MNIST and FMNIST.",This paper proposed an algorithm for learning concepts incrementally taking inspiration from Parallel Distributed Processing and Complementary Learning Systems. The core idea is to use Gaussian Mixture Models and update them incrementally plus exploit a generative model to perform pseudo-rehearsal. The paper presents a methodology and follow-up experimental results that are shown to perform well. ,0.11888111888111888,0.2982456140350877,0.16999999999999998
408,SP:25502178fec50290fe1b6f1fa099df8e5d5d6751,"This paper studied the generalization power of CNNs and showed several upper bounds of generalization errors. Their results have two characteristics. First, the bounds are in terms of the quantity that is independent of the input dimension (size-free). Second, the upper bounds involve the distance between initial and learned parameters. These results improved the upper bounds that we can derive by naively applying the results of Bartlett et al. (2017) or Neushubar et al. (2017), because the dominant term of the existing upper bounds contained $l_{2, 1}$ or $l_2$ norms, which could depend on the input dimensions in the worst case. The authors empirically showed that there is a correlation between the generalization error of learned CNNs and the dominant term of the upper bound (i.e., the product of the parameter size and the distance from the set of initial parameters).","The paper describes new norm-based generalization bounds that were specifically adapted to convolutional neural networks. Since convolutional neural networks do not explicitly depend on the input dimension, these bounds share the same property. Further additional improvement over Bartlett et al. ‘17 bound, is that this new bound depends on the sum of the operator norms of the parameter matrices, rather than the product.",0.14482758620689656,0.328125,0.20095693779904306
409,SP:2565120a71aa1a9ff3677a993bb3bbd8c2271273,"The authors propose an approximate of the natural gradient under Wasserstein metric when optimizing some cost function over a parametric family of probability distributions. The authors leverage the dual formulation and restrict the feasible space to a RKHS. The authors show a trade-off between accuracy and computational cost with theoretical guarantees for the proposed method, and empirically verify it for classification tasks.","Natural gradient has been proven effective in many statistical learning algorithms. A well-known difficulty in using natural gradient is that it is tedious to compute the Fisher matrix (if one is using Fisher-Rao metric) and the Wasserstein information matrix (if one is using Wasserstein metric). It's important to be able to estimate natural gradient in a practical way, and there have been a few papers looking at this problem but mostly for the case with a Fisher-Rao metric. This paper takes a different and general approach to approximate natural gradient by leveraging the dual formulation for the metric restricted to the Reproducing Kernel Hilbert Space. Some theoretical guarantees of the proposed method is established together to some experimental study.",0.2698412698412698,0.13821138211382114,0.1827956989247312
410,SP:256b4cc8d05297bb43d7259d1af082452f937024,"This paper studies the domain adaptation problem when the source data comes from multiple domains continuously and the test domain for adaptation is unknown. The assumption used for domain shift is that the domain label would change the features but not the labels. So the main idea is to learn invariant representations across all the domains and avoid spurious correlation on the domain label. The proposed method then involves a multiplayer minimax game. The adversaries are the domain discriminator for each class, which tries to maximize the domain discrepancy. The minimizer player is the representation learner. The paper introduces two discrepancy measure based on the Jensen-Shannon divergence and the one dimensional Wasserstein distance. In the experiment, the data set for continual learning is constructed using domain shift data such that it mimics the online learning setting. The results are competitive in comparison with a limited set of baselines.","This paper investigates continual learning under domain shift and proposes a conditional invariant experience replay (CIER) method accordingly. CIER aims to retain old knowledge, acquire new information, and generalize to unseen domains. In particular, CIER uses adversarial training to correct the domain shift. Experimental results on three benchmark datasets are reported and discussed.",0.09395973154362416,0.2641509433962264,0.1386138613861386
411,SP:25b1fea3f749269f86cbe68d4b9ee8ec0d960560,"This paper attempts to establish a notion of thermodynamics for machine learning. Let me give an attempt at summary. First, an objective function is established based on demanding that the multi-information of two graphical models be small. The first graphical model is supposed to represent the actual dependence of variables and parameters used to learn a latent description of the training data, and the model demands that the latents entirely explain the correlation of the data, with the parameters marginalized out. Then, a variational approximation is made to four subsets of terms in this objective function, defining four ""thermodynamic""  functionals. Minimizing the sum of these functionals puts a variational upper bound on the objective. Next, the sum is related to an unconstrained Lagrange multiplier problem making use of the facts (1) that such an objective will likely have many different realizations of the thermodynamic functionals for specific value of the bound and (2) that on the optimal surface the value of one of the functional can be parametrized in terms of the three others. If we pick the entropy functional to be parameterized in terms of the others, we find ourself precisely in the where the solution to the optimization is a Boltzmann distribution; the coefficients of the Lagrange multipliers will then take on thermodynamic interpretations in of temperature, generalized chemical potentials, etc. At this point, the machinery of thermodynamics can be brought to bear, including a first law, Maxwell relations (equality of mixed partial derivatives), etc.","This paper builds on the (Alemi et al 2018) ICML paper and presents a formal framework for representation learning. The authors use a graphical model for their representation learning task and use basic information theoretic inequalities to upper-bound their measure of performance which is a KL divergence. The authors then define the optimal frontier which corresponds to the lowest possible upper-bound and write it as an optimization problem. Written with Lagrange multipliers, they obtain several known cost functions for different particular choices of these parameters.",0.09274193548387097,0.26436781609195403,0.1373134328358209
412,SP:260b7b1c20744fac6ded99fc14f6459fb06a2e2e,"The papers studies neural network-based sparse signal recovery, and derives many new theoretical insights into the classical LISTA model. The authors proposed Analytic LISTA (ALISTA), where the weight matrix in LISTA is pre-computed with a data-free coherence minimization, followed by a separate data-driven learning step for merely (a very small number of) step-size and threshold parameters. Their theory is extensible to convolutional cases. The two-stage decomposed pipeline was shown to keep the optimal linear convergence proved in (Chen et al., 2018). Experiments observe that ALISTA has almost no performance loss compared to the much heavier parameterized LISTA, in contrast to the common wisdom that (brutal-force) “end-to-end” always outperforms stage-wise training. Their contributions thus manifest in both novel theory results, and the practical impacts of simplifying/accelerating LISTA training.  Besides, they also proposed an interesting new strategy called Robust ALISTA to overcome the small perturbations on the encoding basis, which also benefits from this decomposed problems structure. ","The paper raises many important questions about unrolled iterative optimization algorithms, and answers many questions for the case of iterative soft thresholding algorithm (ISTA, and learned variant LISTA). The authors demonstrate that a major simplification is available for the learned network: instead of learning a matrix for each layer, or even a single (potentially large) matrix, one may obtain the matrix analytically and learn only a series of scalars. These simplifications are not only practically useful but allow for theoretical analysis in the context of optimization theory. On top of this seminal contribution, the results are extended to the convolutional-LISTA setting. Finally, yet another fascinating result is presented, namely that the analytic weights can  be determined from a Gaussian-perturbed version of the dictionary. Experimental validation of all results is presented.",0.13253012048192772,0.16666666666666666,0.1476510067114094
413,SP:26369f7db26705f4f172a38ba17240f9a32e5c0d,"The paper proposes a two-stage distillation framework to improve inference efficiency and reduce the dependency on large teacher models. The goal of this framework is to only use the large/teacher model for difficult and rare examples and to use the student, smaller model for the more frequent easy examples. The procedure is composed of a training phase and an inference phase. During the training phase, the dataset is separated into two subsets: one containing the hard/difficult examples and one containing the easy examples. Using a loss incorporating a combination of label-smoothing and distillation, the student model is taught to be certain on the easy examples (by using distillation of the large model) and to be less certain on the hard/difficult examples. During the inference phase, in order to route the hard examples to the larger teacher model, several possible methods are proposed relying in particular on whether the margin of the student’s softmax is higher or lower than a threshold.   The authors validate their two-stage framework empirically on three benchmark image datasets (CIFAR-100, ImageNet-1k and ImageNet-21k) and two benchmark NLP datasets (SQuAD and MNLI). ","This paper studies efficient inference problem for large models. It proposes to train a small student model, and performs inference for easy data on the student model, and for hard data on the original large model. Experiments show the proposed method performs better than the simple baseline of standard distillation model.",0.10824742268041238,0.4117647058823529,0.17142857142857146
414,SP:264e8676eea93e3f351c395c7165d754db4bd07e,"The manuscript introduces a definition of provablely-robust adversarial examples, a set of examples that are verified to be classified as different labels compared with the input of interest. The main idea of the technique is to shrink a box-like region from an over approximation to a verifiable smaller sub-region such that a robustness verifier will return robust for all points in that particular sub-region. In the evaluation part, the author demonstrates the effectiveness of the approach with several experiments, i.e. robustness against intensity transformation and randomized smoothing defense.  ","This paper presents a novel algorithm for identifying ""provably robust adversarial examples"": large regions in the input space that provably contain only adversarial examples.  Each region corresponds to a single adversarial example $\tilde{x}$ found in the center of the region, along with all the points that can be generated by applying a sequence of transformations to $\tilde{x}$. The transformations considered in the paper are semantically meaningful changes to the original image. Critically, we can be guaranteed that $\tilde{x}$ will be misclassified even if _it_ is perturbed.  The paper demonstrates that the algorithm can generate regions of non-trivial size on networks of non-trivial size. For example, for a CIFAR10 classifier with 6 layers and ~62k neurons, it finds axis-aligned regions containing a median of $10^{573}$ adversarial examples. In addition, the paper shows that provably robust adversarial examples can be used to create adversarial examples to $L_2$-smoothed classifiers that are more robust to $L_2$ noise as compared to adversarial examples generated directly via PGD attacks.",0.22580645161290322,0.12138728323699421,0.15789473684210523
415,SP:265254f820e23f0ccc344a78330bf0361b4e0499,"The paper proposes a Deep RL approach called Auto-Deferring Policy (ADP) to learning a policy for constructing solutions for the Maximum Independent Set (MIS) problem. Rather than constructing a solution one variable per episode step, the policy can make decisions about multiple variables per step, as well as defer decisions to later steps. At each step the MIS constraints of a valid solution are checked and decisions that violate the constraints are reverted, and any additional decisions that are automatically implied by the decisions so far and the MIS constraints are taken. The policy and value function are parameterized as a graph convolutional network to make use of the graph structure of the problem. A diversity regularizer that encourages the policy to generate diverse final solutions is used for training. Results show that the approach is able to match the objective value of the state-of-the-art solvers on several datasets, and is able to outperform S2V-DQN on several datasets when neither approach is trained on them.","This paper aims at solving graph-based combinatorial optimization problems using a new paradigm for Deep Reinforcement Learning. In contrast with standard Markov Decision Processes used for combinatorial DRL, the authors advocate the use of “deferred” MDPs capturing more complex actions (which can choose a subset of nodes), and more sophisticated transitions, which combine an update phase together with a cleanup phase. For the DRL architecture, an Actor-Critic framework is trained using a proximal policy optimization approach. The paper specifically focuses on the Maximum Independent Set (MIS) problem. Comparative results on various instances reveal that this approach clearly outperforms the S2V-DQN algorithm and is competitive with some usual combinatorial solvers (CPLEX, ReduMIS).",0.12941176470588237,0.19298245614035087,0.15492957746478872
416,SP:2656017dbf3c1e8b659857d3a44fdbb91e186237,"This paper proposes a neural network architecture to classify graph structure. A graph is specified using its adjacency matrix, and the authors prose to extract features by identifying temples, implemented as small kernels on sub matrices of the adjacency matrix. The main problem is how to handle isomorphism: there is no node order in a graph. The authors propose to test against all permutations of the kernel, and choose the permutation with minimal activation. Thus, the network can learn isomorphic features of the graph. This idea is used for binary graph classification on a number of tasks.","This paper proposes a new neural network architecture for dealing with graphs dealing with the lack of order of the nodes. The first step called the graph isomorphic layer compute features invariant to the order of nodes by extracting sub-graphs and cosidering all possible permutation of these subgraphs. There is no training involved here as no parameter is learned. Indeed the only learning part is in the so-called classification component which is a (standard) fully connected layer. In my opinion, any classification algorithm could be used on the features extracted from the graphs.",0.21649484536082475,0.22105263157894736,0.21874999999999997
417,SP:266023140bbd3039a0bc65c2f59f3edcf34ed58b,This paper proposes to use the well-known Double Oracle methods for solving large scale games for computing the equilibrium in GANs. The main idea of a mixed strategy being a mixture over generators (and mixture over discriminator for toher player( is from Hsieh et al. The double oracle approach is shown to yield superior results on three image datasets.,"This paper applies Double-Oracle (DO) / PSRO to training a GAN, a 2-player zero-sum game. DO cannot be applied directly ""out-of-the-box"". Instead of an exact oracle, the generator and discriminator are trained using local gradient optimizers for a finite number of steps. Also, in DO, the meta-game matrix can grow very large and maintaining and training against a large population of neural networks is expensive, so the population is pruned throughout training.",0.2,0.15384615384615385,0.17391304347826086
418,SP:26734ce3b17851304312b1211ff74e054046d1d3,"This paper presents a new reading comprehension dataset for logical reasoning. It is a multi-choice problem where questions are mainly from GMAT and LSAT, containing 4139 data points. The analyses of the data demonstrate that questions require diverse types of reasoning such as finding necessary/sufficient assumptions, whether statements strengthen/weaken the argument or explain/resolve the situation. The paper includes comprehensive experiments with baselines to identify bias in the dataset, where the answer-options-only model achieves near half (random is 25%). Based on this result, the test set is split into the easy and hard set, which will help better evaluation of the future models. The paper also reports the numbers on the split data using competitive baselines where the models achieve low performance on the hard set.",This paper presents a machine reading comprehension dataset called ReClor. It is different from existing datasets in that ReClor targets logical reasoning. The authors identified biased data points and separated the testing dataset into biased and non-biased sets. Experimental results show that state-of-the-art models such as XLNet and RoBERTa struggle on the non-biased HARD set with poor performance near that of random guess.,0.183206106870229,0.35294117647058826,0.24120603015075376
419,SP:267db579f7976de868dd0e26aee37ce5dda5c43d,The authors suggest the use of Random Noise Defense (RND) to protect deep learning models from black-box query-based attacks. The authors motivate their proposal via both theoretical and experimental validation -- where RND is a lightweight defense that augments random noise to input queries. The paper further proposes RND-GF that is trained to be robust (smoothened) to random noise -- in order to further improve the adversarial robustness.,"This paper proposes a simple but theoretically supported defense method against query-based black-box attack, called as Random Noise Defense. The core idea is to add Gaussian noise to a given input image at each query so it can be considered as quite simple. However, this paper shows theoretical analyses of RND against zero-order optimization, adaptive and search-based attacks. The overall finding through each theoretical analysis is that the number of queries for successful attacks by an attacker changes with the ratio of nu/mu. To overcome trade-off between clean accuracy and larger nu, the authors propose Gaussian augmentation fine-tuning for the target model. From the extensive experiments using CIFAR-10 and ImageNet against various black-box attacks, the authors demonstrated that, not only the results of theoretical analysis are confirmed by experiments but RND achieves the superior performance. Also, they showed RND can be easily combined with other defense methods and it achieves the state-of-the-art defense performance when it is combined with the adversarially-trained model.",0.2463768115942029,0.09714285714285714,0.13934426229508196
420,SP:26ad0ca3f299e8f729aaf9cf5543c45a2c5bba20,"This paper studies the interpretability of neural networks. Specifically, the authors use four approaches with different objectives and regularizations and use cMLSGA, a genetic optimization method to optimize these problems. Eventually, the authors conduct experiments to validate that Fit to Median Error measure possesses better interpretability compared to L1, L2 and dropout regularizations since it regularizes the learnt input-output relationships to the conditional median. ","The paper claims that building ML models through automation can become a black-box approach that results in lower errors but also lower interpretability. Also, minimizing traditional error measures cannot guarantee an accurate approximation of the ground truth. The paper studies using fit to Median Error measure to produce better model with regard to interpretability of models.   The paper uses ship power prediction problem that aims to reduce fuel consumption, a challenging regression problem, as an application where fit to Median Error measure is used. The paper compares four different genetic algorithms settings: minimizing the Maximum Absolute Error of the networks, minimizing the Maximum Absolute Error and minimizing the Mean Fit to Median.   The experiment results demonstrate that all four settings produced similar Mean Absolute Errors from networks on their Pareto fronts. But the Mean Fit to the Median setting obtained much better interpretability (fit to the ground truth).  ",0.27692307692307694,0.12080536912751678,0.16822429906542058
421,SP:26b729f3285115b1d27edd56ffb846ab9d895ac4,"The paper proposed a defensive mechanism against adversarial attacks using GANs. The general network structure is very much similar to a standard GANs -- generated perturbations are used as adversarial examples, and a discriminator is used to distinguish between them. The performance on MNIST, SVHN, and CIFAR10 demonstrate the effectiveness of the approach, and in general, the performance is on par with carefully crafted algorithms for such task. ","The paper ""A Direct Approach to Robust Deep Learning Using Adversarial Networks"" proposes a GAN solution for deep models of classification, faced to white and black box attacks. It defines an architecture where a generator network seeks to produce slight pertubations that succeed in fooling the discriminator. The discriminator is the targetted classification model. ",0.16417910447761194,0.2037037037037037,0.18181818181818182
422,SP:26e8b2aa5dd4391723debdf5af6add655c7a3586,"This paper introduces the free algebra, a classical mathematical concept as a generic tool to represent sequential data of arbitrary length. The proposed method has attractive theoretical property, such as preserving universality of static feature mapping, and convergence in the continuous setting. The author further proposes using stacked rank-1 projection of the free algebra as an approximation to the sequence representation in order to make it computationally feasible neural networks layers. The author illustrated the flexibility and effectiveness of the proposed method by combining the NN implementation with FCN to benchmark on multivariate time series classification problem, and GP-VAE model to benchmark on sequential data imputation problem. The proposed methods shows improved results over previous state-of-the-art. ","This paper proposes to embed static feature maps into a larger linear space and shows that the proposed method achieves good performance on standard benchmarks. Detailed proofs and theoretical results are given in the appendices. The use of free algebras in ML seems novel and under-explored, although it is classical in mathematics. This paper shows that algebraic structure can significantly elevate the performance of existing models empirically. ",0.1322314049586777,0.23529411764705882,0.1693121693121693
423,SP:27323749bf12c16851d7a9653232e7006e82e1a2,"It is a good article that makes a significant contribution to the RL domain. It not only identifies the line of thought that hampers the development of RL-based solutions but also proposes the solution. The article makes a comparison of other approaches to their framework to a significant level of detail. Nevertheless, there are some flaws. ","This manuscript proposes AnonFlow, a set of dataflow abstractions that allow for easy specification and implementation of distributed RL algorithms. AnonFlow consists of several composable dataflow operators/iterators implemented on top of RLlib. The manuscript discusses the implementation of several popular RL algorithms and quantifies the effectiveness of AnonFlow in terms of LoC and overall system performance.",0.17543859649122806,0.17543859649122806,0.17543859649122806
424,SP:2751ee96a99e75fd0cb6210a9de9b96bb4c14ef1,"This paper studies the dynamics of the parameters while training a neural network via SGD. SGD is not studied directly but three continuous time approximations of SGD are considered: the classical gradient flow, a stochastic differential equation of Langevin type, and a ""modified"" gradient flow whose derivation has roots in the literature. For each dynamics, the authors show that some invariant properties of the loss function (which are often satisfied in practice) imply some invariant quantities for the dynamics.  ","The current work studies the implications of continuous symmetries of a DNN on its weight dynamics. Specifically, they consider linearly realized symmetries (such as a shift/translation to the logits), and use the fact that the loss/hessian/mini-batches, are insensitive to such shift to decouple their dynamics. They do so both in the continuous/vanishing-learning-rate case and for small learning rates and manage to provide accurate quantitative predictions for the dynamics of these quantities.",0.21518987341772153,0.21794871794871795,0.21656050955414013
425,SP:276a1974451e9740ff761c45ff63de47aabe0534,"This paper proposes a new stochastic normalized gradient descent method with momentum (SNGM) for large batch training. They prove that unlike mometum SGD (MSGD), SNGM can adopt larger batch size to converge to the epsilon-stationary point with the same computation complexity (total number of gradient computation). The paper shows that SNGM with large batches is comparable to MSGD with small batches for training ResNet on CIFAR10 and ImageNet. The paper also shows that SNGM outperforms LARS on CIFAR10.","Large batch training has been observed to not only significantly improve the training speed but also lead to a worse generalization performance. This paper considers how to improve the performance of MSGD in large batch training. They propose the so called normalized MSGD where instead of the gradient, the algorithm uses the normalized gradient to update the momentum. They also provide theoretical justification of this change by considering smooth and relaxed smooth function. O(1/\epsilon^4)  convergence rate is established.",0.16455696202531644,0.16049382716049382,0.16249999999999998
426,SP:276b6721d8cad9d323908d8677706c8ad1668c95,"This paper tries to provide a deeper understanding of the training dynamics of GANs in practice via characterizing and visualizing the rotation and attraction phenomena nearby a locally stable stationary point (LSSP) and questions the necessity to access a differential/local Nash equilibrium (LNE). In particular, this paper first discusses the difference between LSSP and LNE and formalize the notions of rotation and attraction around LSSP in games. Then, this paper proposes the path angle to visualize the rotation and attraction nearby an LSSP. The path angle is a function that maps linearly distributed points in the line, which is determined by an initial parameter set and a well-trained parameter set, to the angles between the line and the gradient of a given point in that line. The rotation and attraction phenomena can be observed in the plot of the path angle as  ""a quick sign switch"" and ""a bump"" nearby 1, respectively. The experiments empirically demonstrate that: 1. rotation exists in the training dynamics of practical GANs; 2. GANs often converge to an LSSP than an LNE, but still, achieve good results.","This paper proposes visualization techniques for the optimization landscape in GANs. The primary tool presented in this paper is a quantity called path-angle, which looks at the angle between the game vector field and the linear path between a point away from a stationary point and a point near a stationary point. The paper present examples of the visualization for dynamics with pure attraction, pure rotation, and a mix of attraction and rotation. Along with this, the authors propose to look at the eigenvalues of the game Jacobian and the individual player Hessian’s to evaluate convergence in GANs. The paper presents application of the tools on GANs trained with NSGAN and WGAN-GP objectives on a mixture of Gaussians, MNIST, and CIFAR10. The primary observation is that the generator performance is good, but the algorithms converge to non-Nash stable attractors. Moreover, it is shown using the path-angle plots that GANs exhibit rotational behavior around stable points.",0.20108695652173914,0.23125,0.21511627906976744
427,SP:278819106a3ae8c15442e56994fb175a0cad70dd,"The paper proposes a method, LayerDrop, for pruning layers in Transformer based models. The goal is to explore the stochastic depth of transformer models during training in order to do efficient layer pruning at inference time. The key idea is simple and easy to understand: randomly dropping transformer layers during training to make the model robust to subsequent pruning. The authors perform empirical studies on several sequence modeling task to conclude that the proposed approach allows efficient pruning of deeper models into shallow ones without fine-tuning on downstream tasks. There are also empirical experiments done to demonstrate that the proposed approach outperforms recent model pruning techniques such as DistillBERT under comparable configurations. ",This work explored the effect of LayerDrop training in efficient pruning at inference time. The authors showed that it is possible to have comparable performance from sub-networks of smaller depth selected from one large network without additional finetuning. More encouraging is that the sub-networks are able to perform better than the same network trained from scratch or learned based on distillation.,0.1504424778761062,0.2698412698412698,0.19318181818181818
428,SP:279681eb1d988af6639673c37b26588f620e18c7,"The paper provided a novel connection between the well-known adversarial training problem and a statistical problem over perturbation distributions. The former requires obtaining worst-case adversarial perturbations of a neural network as an inner optimization procedure, which has been known as a challenging task. The later can avoid this but needs to solve a new inner optimization over perturbation distributions instead. The authors demonstrated that the statistical problem recovered several existing adversarial training problems with sub-optimal perturbation distributions. Inspired by this connection, the paper introduced an alternative adversarial training algorithm that used a smoothed version of the optimal perturbation distribution and showed that the proposed algorithm can achieve competitive or even better performance compared to previous approaches in terms of empirical adversarial robustness (evaluated using empirical attacks) on image classification tasks such as MNIST and CIFAR-10.","This paper studies the adversarial robustness through semi-infinite optimization and non-convex duality theory. By leveraging tools from constrained optimization and duality theory, the authors find the adversarial training formulation is equivalent to learning from a perturbation distribution. The authors propose a constrained learning problem for achieving model robustness while maintaining the nominal performance on clean samples. The authors propose an unconstrained saddle point reformulation for solving the constrained optimization problem via duality, and develop an LMC-based algorithm. Empirically, the authors find the new algorithm can achieve better performance on some standard benchmark tasks.",0.17266187050359713,0.25,0.20425531914893616
429,SP:27b73923af173446aa087b192767dedd7119231b,"This paper designs a set of dynamics for learning in games called follow-the-ridge with the goal of finding local stackelberg equilibria. The main theoretical results show that the only stable attractors of the dynamics are stackelberg equilibria. Moreover, the authors give a deterministic convergence rate for the vanilla algorithm and a convergence rate using momentum. Empirical results show the learning dynamics cancel out rotational components and drive the vector field to zero rapidly, while reaching good performance on simple GAN examples.","The present work proposes a new algorithm, ""Follow the Ridge"" (FR) that uses second order gradient information to iteratively find local minimax points, or Stackelberg equilibria in two player continuous games. The authors show rigorously that the only stable fixed points of their algorithm are local minimax points and that their algorithm therefore converges locally exactly to those points. They show that the resulting optimizer is compatible with heuristics like RMSProp and Momentum. They further evaluate their algorithm on polynomial toy problems and simple GANs.",0.25301204819277107,0.24705882352941178,0.24999999999999994
430,SP:27b73a836058b5e3cf5430f5c64fec2d1475da1b,"The paper studies batch meta learning, i.e. the problem of using a fixed experience from past tasks to learn a policy which can quickly adapt to a new related task. The proposed method combines the techniques of Fujimoto et al. (2018) for stabilizing batch off-policy learning with ideas from Rakelly et al. (2019) for learning a set invariant task embedding using task-specific datasets of transitions. They learn task-specific Q-values which are then distilled into a new Q function which is conditioned on the task embedding instead of the task ID. The embedding is further shaped using a next-state prediction auxiliary loss. The algorithmic ideas feel a bit too incremental and the experimental evaluation could be stronger--I'd recommend trying the method on more complicated environments and including ablation studies.","This paper studies the meta-RL problem in the off-policy, batch learning setting. Batch-RL is the setting in which a policy is learned entirely offline, that is, without interaction with the environment and given only trajectories collected by some policy. Compared to RL, Meta-RL involves the additional challenge of task-inference; the goal of Meta-RL is to train a policy that can generalize to a distribution of tasks (i.e. a distribution of MDPs), without actually being given a description of the task (unlike contextual multi-task policy learning). A simple approach for solving the meta-RL problem thus might be to first perform task inference by encoding data from some task into a task description, and then condition a contextual policy on this task description. ",0.17647058823529413,0.18461538461538463,0.18045112781954886
431,SP:27b9449427c427bbb7eef7e71961e0ed426f3ddb,"The paper studies the ""optimal task tracking"" problem under the training setting where we use the ""weight decay"" regularization. More specifically, the paper studies the relationship between plasticity-stability tradeoff and shows that a consequence of training with (large enough) weight decay is the ""mutually frozen"" weights that can damage the plasticity of the network. Moreover, the paper introduces an intervention to reset the mutually frozen weights and improve the performance.","In this paper, the authors present a mechanistic phenomenon linked to plasticity problems incurred in sequential task learning. They call this phenomenon ""mutually frozen weights"", describing a situation where triples (or higher order tuples) of weights that multiply each other in a system, all end up with zero value, which prevents error gradients from influencing their value when learning new tasks. They then argue that such a situation arises in real world setting, and explain how weight decay can promote such a situation. They also demonstrate that such frozen weights play a role in input invariance, and thus should be considered in a tradeoff perspective. Finally, the present a ""resetting"" method that helps mitigate the problems brought by mutually frozen weights, and perform some numerical experiments to demonstrate the efficacy of their method.",0.2535211267605634,0.13533834586466165,0.17647058823529413
432,SP:27c37d99f580a50522aa11b228ea9ec7f2ab68ff,"This paper proposes to integrate a combination of rule learning and data learning in the deep neural networks. The core motivation is to introduce prior knowledge and/or other learning methods and learning how to ""balance"" the pure data-driven part of the neural network with its rule learning component. The final neural network has two components: the rule-based encoder and the data-driven encoder that are combined by a parametrized convex combination. The loss function has also a counterpart that captures the traditional loss function with penalizations on the rule violations. The second part is similar to the Lagrangian approach to training neural networks subject to constraints that has been used successfully in prior (mostly cited) work. The novelty is the introduction of the rule encoder inside the neural network, as examplified by the third application. The paper also proposes an interesting perturbation approach to capture some of the rule behavior. ","This paper proposes DeepCTRL, a method for infusing domain knowledge in the form of rules into the representation learning models. The method independently encodes the input instance and the supplied rule and couples the input and rule encodings where the coupling is controlled by a parameter \alpha. Training the model involves a task-specific loss function and a “rule-satisfaction” loss function which are again coupled by the same parameter \alpha. Experiments on three tasks related to Physics, Forecasting, and Health domain demonstrate several benefits of the proposed approach which include (i) ability to specify the domain knowledge, (ii) More control on coupling the information from rule and data during the test time (iii) More interpretability.  However, the experiments in this paper seem to be very simplistic and lack exhaustive comparisons with the prior work and thus it’s difficult to judge the practical utility of the proposed method (E.g. all the experiments involve just one rule).  ",0.24183006535947713,0.23417721518987342,0.2379421221864952
433,SP:27c38ce6b2f00125dbdc35262deb8e02899d1542,"The work answers an interesting question: Given two cyclic conditional distributions, under which condition there exists a compatible joint distribution, and when the compatible joint distribution is unique.   From the theory the authors propose a generative framework called CyGen. CyGen is trained using maximum likelihood based on modelings of the conditional probabilities. Sampling from the marginal distribution modeled by the two conditional distributions is also not straightforward. Luckily this has been investigated before and there are practical MCMC based procedures that converge to the marginal distribution.  The authors also show some experimental results that the proposed CyGen is able to generate more realistic samples compared to VAE or DAE. ","Notes:    -Model the joint p(x,z) by modeling p(x|z) and q(z|x) to form a cycle.     -Many existing techniques use an uninformative prior p(z).     -Compatibility and determinacy criterions.     -Use parameterized density models p(x|z) and q(z|x).     -Define r(x,z) = log(p(x|z) / q(z|x)) and make the loss the norm of the jacobian, computed over samples from p(x)*q(z|x) (real data / inferred latents).      -Jacobian is intractable, so instead approximate by taking gradient wrt. x, then multiplying by random vector eta, then taking gradient wrt z.     -Sample using stochastic gradient langevin dynamics.  ",0.08256880733944955,0.08571428571428572,0.08411214953271028
434,SP:27c8b1b419259661fd5388f4a53055f90fe0b4f9,"**Summary.** This paper proposes a generalization to the typical geometric discounting scheme in reinforcement learning. In particular, a new _delayed_ discount criterion is proposed (Equation 1) that captures traditional geometric discounting when $D=0$, but also allows for other kinds of temporal preferences. Figure 2 provides a clean visual illustrating the different kinds of discounting afforded for different settings of $D$. Following this, several natural questions emerge: What happens to the $\gamma$-contraction in repeated application of the Bellman Operator? Proposition 1 addresses this question by stating that a $\gamma_D$-contraction is still guaranteed. How might typical reinforcement learning algorithms handle this new discounting scheme? The paper addresses this question by introducing two new algorithms. The first (Algorithm 1) is a generalization of Soft Actor Critic, while the second (Algorithm 2) is a policy-based algorithm that approximates the finite horizon problem. The first set of experiments focus on three maze problems. Estimates of the expected returns of learned stationary policies are reported for Algorithm 1 under four conditions as the depth $D$ is changed from 0 up to 8. The main finding is that as $D$, returns do tend to increase up to a certain point, at which point it drops (around when $D = 6$ or $7$). Further experiments inspect the performance of Algorithm 2 in a similar way (Figure 5), and contrast the performance of Algorithm 1 with typical SAC on continuous control games like Ant-v2. On the chosen four games (Figure 6), the average reward of GSAC improves over SAC slightly, though the variance is arguably slightly higher.","The paper proposes an optimality criterion for RL that is generalizes the standard exponential discount commonly used in a large volume of RL research. In particular, the paper proposes substituting the standard discount term $\gamma^t$ by a generalized discount term $\Phi_D(t)$ built from a set of discounts $\gamma_0,\ldots,\gamma_D$. The discount terms $\Phi_D$ can be defined recursively as   - $\Phi_0(t)=\gamma_0^t$ (corresponding to the standard exponential discounting); - $\Phi_D(t)=\sum_{k=0}^t\gamma_D^k\Phi_{D-1}(t-k)$  The consideration of non-uniform discounting implies that the resulting optimal policies may, in general, be non-stationary. Nevertheless, the paper introduces an equivalent to the $Q$-functions in the standard RL formulation and shows that these functions can be computed using standard dynamic programming. Letting  $Q_d^\pi(s,a)=E\left[\sum_{t=0}^\infty\Phi_d(t)r_t\mid s_0=s,a_0=a\right]$,  it follows that $Q_0^\pi$ corresponds to the standard $Q^\pi$ with discount factor $\gamma_0$, and each $Q_d^\pi$ can be computed from $Q_{d-1}^\pi$ using a dynamic programming operator $T_\pi^d$ that has $Q_d^\pi$ as its unique fixed point. These functions can also be computed using existing RL algorithms as part of a generalized policy iteration cycle that---upon convergence---may yield an ""optimal stationary policy"" (convergence is not guaranteed, though).  The paper also proposes an approximate policy that breaks down the value function for the problem into two terms---one that accounts for the rewards in the first $H$ steps and the other for the remaining steps. Under mild conditions on the discounts $\gamma_0,\ldots,\gamma_D$, the latter term can be approximated by the standard optimal value function (with standard exponential discounting) for large $H$, allowing for the computation of an approximate (non-stationary) policy.",0.16730038022813687,0.13793103448275862,0.15120274914089346
435,SP:27d5ff5c5032974b4cc0c6af29e414d496d99dfd,"This paper introduces a structured drop-in replacement for linear layers in a neural network, referred to as Kaleidoscope matrices. The class of such matrices are proven to be highly expressive and includes a very general class of sparse matrices, including convolution, Fastfood, and permutation matrices. Experiments are carried in a variety of settings: (i) can nearly replace a series of hand-designed feature extractor, (ii) can perform better than fixed permutation matrices (though parameter count also increased by 10%), (iii) can learn permutations, and (iv) can help reduce parameter count and increase inference speed with a small performance degradation of 1.0 BLEU on machine translation.","The authors introduce kaleidoscope matrices (K-matrices) and propose to use them as a substitute for structured matrices arising in ML applications (e.g. circulant matrix used for the convolution operation). The authors prove that K-matrices are expressive enough to capture any structured matrix with near-optimal space and matvec time complexity. The authors demonstrate that learnable K-matrices achieve similar metrics compared to hand-crafted features on speech processing and computer vision tasks, can learn from permuted images, achieve performance close to a CNN trained on unpermuted images and demonstrate the improvement of inference speed of a transformer-based architecture for a machine translation task.",0.17757009345794392,0.17757009345794392,0.17757009345794392
436,SP:27e02b3c5e475b0491bd12b40bf75e9c8070930a,"This paper shows through a set of experiments that the common belief that a large neural network trained, then pruned and fine-tuned performs better than another network that has the same size of the pruned one, but trained from scratch, is actually false. That is, a pruned network does not perform better than a network with the same dimensions but trained from scratch. Also, the authors consider that what is important for good performance is to know how many weights/filters are needed at each layer, while the actual values of the weights do not matter. Then, what happens in a standard large neural network training can be seen as an architecture search, in which the algorithm learns what is the right amount of weights for each layer. ","This paper reinvestigate several recent works on network pruning and find that the common belief about the necessity to train a large network before pruning may not hold. The authors find that training the pruned model from scratch can achieve similar, if not better, performance given enough time of training. Based on these observations, the author conclude that training a larger model followed by pruning is not necessary for obtaining an efficient model with similar performance. In other words, the pruned architecture is more important than the weights inherited from the large model. It reminds researchers to perform stronger baselines before showing complex pruning methods. ",0.20155038759689922,0.24761904761904763,0.2222222222222222
437,SP:27e5d87807bde38fd23e80517608417aaaf724f3,"The paper proposes a new task for text style transfer, based on the idea that the the surrounding context of a sentence is important, whereas previous such tasks have only looked at sentences in isolation. Two new crowd-sourced datasets are created, and a combination of now fairly standard neural components is shown to outperform some strong baselines on the new datasets, on a variety of evaluation metrics. An ablation analysis of the components - including some auto-encoding auxiliary losses  - shows that all the various parts are helpful to performance.","The authors propose the task of contextual text style transfer: transferring the style of one text into another (i.e., informal to formal, or offensive to non-offensive), when the text is present within some larger, provided context. The authors propose a model (CAST) which takes advantage of the additional context to perform the style transfer. CAST outperforms previous style transfer models according to several automatic metrics, as well as human evaluation.",0.16666666666666666,0.20833333333333334,0.1851851851851852
438,SP:2804cf2bf050088d72442c477eda685382fd2db0,"This paper proposes a two-stage non-autoregressive (NAR) transformer-based approach for multi-modal conditional image generation in the discrete latent space of a pretrained VQGAN, called UFC-BERT. More specifically, the proposed model draws inspiration from BERT [1] and Mask-Predict [2] and uses masked language (token) modeling to (i) incorporate bidirectional context and (ii) significantly speed up generation over autoregressive baselines. Sampling from the masked model is performed via an extension of the progressive mask-predict algorithm, where two newly introduced discriminative heads of the transformer model guide the sampling process to generate samples that are consistent with the given conditioning and have high fidelity.","### Summary The paper works on conditional image synthesis using a transformer-based network. The proposed method uses one network to combine multi-modal conditional signals, such as textual information and visual information, for image generation. The proposed non-autoregressive training strategy is validated on two datasets, the collected clothing dataset and Multi-Modal CelebA-HQ, and shows better results than GAN-based methods and a transformer-based method.  ### Strengths - The proposed method can utilize multi-modal controls for image synthesis and show convincing synthesized images containing input condition information. The image generation results conditioned on multi-modal inputs are interesting and inspiring. - While recent autoregressive-based methods demonstrate good text-to-image generation results using transformers, the paper shows that non-autoregressive transformers (e.g., BERT used in the paper) can also be trained for generating a sequence of image tokens. - The careful design of the relevance and fidelity estimation tasks is novel and helps the training of the network. ",0.23148148148148148,0.15625,0.18656716417910446
439,SP:281bc59d639aa76d84921b3ec4ce1ee8f1ba5b51,"The authors propose a method to tackle a new problem setting of semi-supervised learning, called an open-world semi-supervised learning, where the model is required to accurately discriminate known-class data as well as to appropriately discover unknown classes contained in an unlabeled dataset. The objective function to be minimized in the proposed method comprises three terms: unsupervised loss, supervised loss with uncertainty based adaptive margin, and entropy regularization. The experimental results with several datasets have validated the advantage of the proposed method.","The paper considers open-world SSL settings  where the model recognizes previously seen classes, and detects novel classes which are not present in the labeled dataset. The method contains three losses to train a model in this setting: a) supervised loss on labeled data, b) unsupervised loss on unlabeled data from pseudo-labels obtained  from confident pairwise similarities, and c)  regularization term that avoids assigning all the unlabeled samples to the same class. Then the paper evaluates the effectiveness of the  method on CIFAR-10/100 and ImageNet-100 datasets.",0.24705882352941178,0.23333333333333334,0.24
440,SP:283b7ebcc54991836055c604e3fae24aac9286b9,"This paper deals with the problem of obtaining user representations from behavior sequences and proposes a method introducing the idea of a ""bag of features"" and multi-head attention. More specifically, a behavior sequence is expressed by a sequence of multi-dimensional vectors and a fixed-length segment of the sequence is converted to a histogram, where each bin corresponds to a cluster of vectors. Each is then fed to a multi-head attention module to obtain a segment representation and all the segment representations are aggregated into a single vector through a time aggregation module. Experimental evaluations for several downstream tasks demonstrate the effectiveness of the proposed method against several simple baselines.","This paper introduces a universal user representation learning approach based on self-supervised learning on long-term user behaviors. The authors first represent user behaviors into sparse vectors, and then encode them into multiple vectors to represent users in different aspects. The authors further study using different time aggregation strategies to tradeoff accuracy and computational cost. Experiments on two datasets show the effectiveness of the proposed approach.",0.1415929203539823,0.23880597014925373,0.17777777777777776
441,SP:28475d91bb10fb0a3a8add77cca7505a839e145d,"This paper proposes a novel lambda layer to capture long-range interactions by transforming available contexts into linear functions, termed lambdas and applying these linear functions to each input separately. The proposed Lambda Network achieves good performances on ImageNet Classification, COCO object detection and instance segmentation tasks. The proposed lambda convolution is much more dense than the attention-based layer thus reducing parameters and complexity. However there are still several weaknesses in this paper. 1) Generalization of the proposed lambda convolution layer. For example, how about the performance of the lambda layer when combined with the lighter convolutional networks, e.g. mobilenet ? How about the performance when much deeper networks for the highest performance?  2)The source code is suggested to be released for more details. 3) Check the typos in the paper. ","This paper presents an efficient method to model long-range interaction. The proposed lambda layer removes the nonlinearity of the original attention operation and makes the matrix multiplication independent of the context, hence skipping expensive computation and storage of large attention maps. Two kinds of lambda functions in lambda layer, i.e., content lambda and position lambda,  allows the model to capture both dense content and long-range interaction.  In addition, the lambda layer can be further extended to working with local context and to being more efficient by docomposing a query into multiple short ones. Its effectivess has been demonstrated on extensive experiments on different backbone network architectures and tasks. Its speed-accuracy tradeoff perform very favorably against SOTA methods.",0.17293233082706766,0.19008264462809918,0.18110236220472442
442,SP:28739f0fcb4a9fb3c661dee4008443d34c25d6d6,"This paper proposes adding an additional loss term to instance classification, within the context of self-supervised pre-training.  Specifically, in addition to the standard classification loss term that views each image (and its augmentation) as a separate category, a second loss term is added, which is 1 minus the inner product of the representations for two augmentation views of the same image.  In a sense, this is incorporating an aspect of the contrasting learning approach, as two views of the same image are being explicitly pulled toward one another due to the consistency loss.  ","This paper studies the instance classification solution for an unsupervised representation learning problem. Particularly, this paper proposes an additional consistency loss that is simultaneously optimized with classification loss, in order to penalize feature dissimilarity between augmented views of the same instance. Such consistency loss makes classification loss optimization easier and avoids large batch size. Extensive experiments on downstream tasks, e.g., segmentation and detection, show the effectiveness of the proposed method.",0.16842105263157894,0.22535211267605634,0.1927710843373494
443,SP:28771bff00a6b7124ef7f7de9050725d062bc3bb,"The reviewer feels that the paper is hard to follow. The abstract is confusing enough and raises a number of questions.  The paper talks about `""local maxima"" without defining an optimization problem. What is the optimization problem are we talking about? Is it a maximization problem or minimization problem? If we are dealing with a minimization problem, why do we care about maxima?","In this paper, the authors focus on the task of learning the value function and the constraints in unsupervised case. Different from the conventional classification-based approach, the proposed algorithm uses local maxima as an indicator function. The functions c and h and two corresponding generators are trained in an adversarial way. Besides, the authors analyzed that the proposed algorithm is more efficient than the conventional classification-based approach, and a suitable generalization bound is given. Overall, this work is theoretically complete and experimentally sufficient.",0.19047619047619047,0.1411764705882353,0.16216216216216214
444,SP:28830a229473469ffa922da0e97fd3ef3871862f,"This paper presents a simple offline RL method that only requires a few lines of changes in code. The authors add a BC loss as the regularization to the standard policy update objective while also normalizing the states. The authors also normalize the coefficient of the BC loss with the average Q values in the dataset to balance the policy update objective and the BC loss. Through experiments, the proposed method appears to perform comparably to the best-performing prior offline RL approaches despite being simple and requiring lower tuning complexity.","The authors revisit addition of a behavior regularization term for offline reinforcement learning but with minimal change to existing RL approach, namely TD3. They showcase their approach in D4RL gym environments. The results are surprisingly good for such a small change and  are competitive with SOTA for the most part.  ",0.0989010989010989,0.18,0.1276595744680851
445,SP:288991f341afc67f98e6318d17b06902b5488f15,"This paper focuses on reinforcement learning in partially-observable environments, and revisits the approach that consists of extending the agent with an external memory. The main contribution of the paper is the proposal (and evaluation) of adding an action to the agent, that allows it to push its current observation (and previous action is some cases) in a k-sized queue. The observation of the agent is extended with the contents of the queue. The main argument of the authors is that learning ""when to push"" is easier for the agent than learning ""what to push"" (as done with Neural Turing Machines and memory-bit external memories), and being able not to push the current observation allows the agent to remember past observations for longer durations, as opposed to k-step observation windows approaches.",The paper extends the agent actions with an ability to write to an external memory. The paper does a nice survey of the previous approaches. The paper explains the difficulties with bootstrapping and policy improvement in POMDPs. The paper proposes simple memories for storing a buffer of k observations. The agent has the ability to push or not to push the current observation to the buffer. The whole content of the external memory is visible to the agent at each time step.,0.22388059701492538,0.36585365853658536,0.2777777777777778
446,SP:28a2ee0012e23223b2c3501a94a5e72e0c718c66,The authors propose to use dynamic convolutional kernels as a means to reduce the computation cost in static CNNs while maintaining their performance. The dynamic kernels are obtained by a linear combination of static kernels where the weights of the linear combination are input-dependent (they are obtained similarly to the coefficients in squeeze-and-excite). The authors also include a theoretical and experimental study of the correlation.,This paper proposed dynamic convolution (DyNet) to accelerating convolution networks. The new method is tested on the ImageNet dataset with three different backbones. It reduces the computation flops by a large margin while keeps similar classification accuracy. The additional segmentation experiment on the Cityscapes dataset also shows the new module can save computation a lot while maintaining similar segmentation accuracy.,0.14705882352941177,0.16666666666666666,0.15625
447,SP:28a8d17fa8de3d51a3837f4e306facaafd416768,"This paper proposes a new training method for wait-k simultaneous translation. Rather than training on prefix pairs where the target prefix lags the source by k tokens, it uses an RL controller to determine an optimal lag for each sentence pair. The controller uses a small set of features intended to capture training progress, and is trained with REINFORCE to minimize wait-k loss on a validation set, in alternation with main training steps. This method shows consistent gains over various wait-k training heuristics, and some gains over other approaches that adapt the lag at inference time.","This paper proposes a training strategy for simultaneous translation to choose appropriate amount of look-ahead information for each decoding. Based on the observation that the wait-k method can be improved by training with longer information, the method introduces a function to determine its length given the current example (source x, target y, and the translation model f). It is used as only a guidance during training, and it remains the same decoding criterion at inference.",0.23232323232323232,0.2987012987012987,0.26136363636363635
448,SP:28b164b471496b8f4c07128fa107df88a9dac3e9,"The paper proposes a practical asynchronous stochastic gradient descent for Byzantine distributed learning where some of transmitted gradients are likely to be replaced by arbitrary vectors. Specifically, the server temporarily stores gradients on multiple  (namely $B$) buffers and performs a proper robust aggregation to compute a more robust from them. When $B = 1$,  BASGD is reduced to ASGD. They also conduct experiments to show the performance of BASGD. ","Review: This paper proposes BASGD which uses buffers to perform asynchronous Byzantine learning. In each SGD step, all workers compute gradients and send them to the server where their ad buffer is updated. When all of the buffers are updated, the server performs an model update. When a worker send a gradient to the server, it also pulls the latest model and compute the gradient on it no matter the server update the model or not. The main contribution in this paper is to introduce a new approach to do asynchronous Byzantine learning without storing training samples on the server like zeno++.",0.2647058823529412,0.17647058823529413,0.21176470588235294
449,SP:28bc18e507ae19516afe5a73fbc8dfa9196036b1,This paper proposes a surprisingly simple technique for improving the robustness of neural networks against black-box attacks. The proposed method creates a *fixed* random mask to zero out lower layer activations during training and test. Extensive experiments show that the proposed method without adversarial training is competitive with a state-of-the-art defense method under blackbox attacks.,The authors propose a simple method for increasing the robustness of convolutional neural networks against adversarial examples. This method is simple but seems to achieve surprisingly good results. It consist in randomly remove neurons from the network architecture. The deleted neurons are selected before training and remain deleted during the training and test phase.  The authors also study the adversarial examples that still fool the network after applying their method and find than those examples also fool human. This finding raises the question of what is an adversarial example if both humans and networks are fooled by the same example. ,0.3389830508474576,0.2,0.25157232704402516
450,SP:28bc3fd396fa163cc305d22c09572e5c10cb50df,"This paper presents actor-critic methods for offline RL. Specific aspects of the problem addressed by the paper include being able to achieve pessimism without adding in pessimism based bonuses or through defining absorbing states. This allows the approach to work with the original value function class without modifications. The paper also presents distinctions between standard assumptions used in both online/offline RL literature relating to low rank MDPs, restricted closeness, and linear Q^\pi assumption.","The paper presents a theoretical study on -- quote – “Do actor-critic methods provably offer any advantage in offline RL?” This is a fundamental question to offline RL, and the authors give a positive answer to that question. Compared to Jin et al. 2020b which uses value-based RL method (PVEI), the main result of the paper is i) a tighter gap between the lower and upper bounds of the value functions obtained by their proposed Pessimistic Least Square Policy Evaluation method and ii) relaxed assumptions about the MDP (restricted closeness vs linear MDP). Actor critic RL is a predominant method in RL, and thus the new findings in this paper are really impressive and encouraging.",0.23684210526315788,0.1565217391304348,0.18848167539267016
451,SP:28c833ad9939bcc4e355254536b610da50731d76,"The authors use decentralized MARL for networked system control. Each agent might control a traffic light (exp 1) or a car in traffic (exp 2). Some features of their approach are a spatial Markov assumption (only neighborhood matters), a spatial discount factor, and NeurComm: a general message passing scheme between agent policies. The authors compare their method with CommNet (averages messages before broadcast), DIAL (small-scale direct communication), etc.","This paper is concerned with network multi-agent RL (N-MARL), where agents need to update their policy based on messages obtained only from neighboring nodes. This is done under sensible restrictions on the state transition distribution, which can be claimed to hold true in realistic networked settings. The authors argue that introducing a spatial discount factor (along a temporal one), where neighboring nodes have a small distance, stabilizes learning. Also, they provide a way of learning a networked communication protocol. Experiments are done on somewhat realistic simulations of traffic.",0.14492753623188406,0.1111111111111111,0.12578616352201255
452,SP:28fa8254eddb2362bd1015b861efaf8c58edf29f,"This paper tackles the problem of learning with noisy labels and proposes a novel method CDR which is inspired by the lottery ticket hypothesis. In particular, the proposed method categorizes the parameters into two parts, including critical parameters and non-critical parameters, and applies different update rules to these parameters. Using comprehensive experiments on synthetic datasets and real-world datasets, the authors verify that the proposed method can improve the robustness of the classifiers against noisy labels.","This paper aims to exploit the early stopping method to solve the problem of learning with noisy labels. Specifically, this paper finds that only partial parameters (critical parameters) are important for fitting clean labels and generalize well; while the other parameters (non-critical parameters) tend to fit noisy labels and cannot generalize well. Based on this observation, this paper proposes to divide all parameters into the critical parameters and non-critical ones, and perform different update rules for the two types of parameters, in each iteration. Extensive experiments on benchmark-simulated and real-world label-noise datasets demonstrate the effectiveness of the proposed method.",0.42857142857142855,0.3173076923076923,0.3646408839779005
453,SP:29055a8942a29012f6557147de1f231f46fb8e09,"This work proposes an approach to learning against non-stationary opponents, where the non-stationarity comes from the learning dynamics in contrast to previous work which assumes a set of possible strategies over the opponents.  The opponent model is learned with Dirichlet Process and from it it's used together with a previous work (RNR) and meta learning  to produce a safe strategy.  The approach seems novel and improving previous works. I have some questions about experiments and limitations. ","The paper proposes to use the Dirichlet process for opponent modelling in games. It argues that the approach is particularly suitable for non-stationary opponents. It then proposes an algorithm to compute a counter-strategy to the model based on the restricted Nash response. Empirical evaluation on Kuhn poker shows that this approach can exploit a non-stationary learning opponent similarly to one of pre-existing methods, while maintaining relatively slow exploitability.",0.1518987341772152,0.16666666666666666,0.15894039735099338
454,SP:290d8d09e111375530a9e2871b3487265ae94309,"Motivated by the connections between PDEs and conventional convolutional networks, this paper proposes the view of graph convolutional networks (GCNs) as discretizations of PDEs on manifolds. Using this view, the authors propose a a family of graph convolutional architectures that utilize discrete graph operators as their basis and argue that this approach can address existing issues with graph convolutional networks, such as over-smoothing. Moreover, the authors also argue that this approach can have a more even performance accorss a diverse range of tasks, instead of being specialized to only a specific type of problem.","The authors propose a new class of graph neural networks motivated by numerical methods for solving PDEs on manifolds. The idea is that there is a correspondence between specific GNNs (e.g., GNNs that learn the weight of edges such as GATs) and discretized PDEs on manifolds. Here, the discretization is spatially. For time (i.e., the depth of the GNN) one can use numerical solvers for PDEs similar to what was proposed by the original Neural ODE paper. The main motivation is that there are types of PDEs that do not suffer from the oversmoothing problem and, therefore, that their discretized versions might be a better fit for some problem domains where oversmoothing is a problem. ",0.2,0.1623931623931624,0.1792452830188679
455,SP:291bb805fd27e09408f36ac44529a4e399838004,"The paper proposed a strong adversarial attack, i.e., an attack that can generate strong adversarial examples and thus can better evaluate the adversarial robustness of given deep learning models. Compared with the SOTA attack, the proposed attack is much faster and thus easier to be applied in practice. The idea is novel and the results are solid. ","This paper proposes a minimum-margin (MM) attack to evaluate defenses. The authors report detailed results on the effects of different loss functions. Experiments are done on CIFAR-10/100 and SVHN, against the adversarially trained models.",0.13793103448275862,0.21621621621621623,0.16842105263157894
456,SP:2936aeafd7df52098ee3dab3b2b2c46d7708e02c,"This paper proposes a variant of multi-instance learning (MIL) for biomedical entity extraction called abstractified multi-instance learning (AMIL), which uses entity type information to construct bags of instances. In the paper, the authors first point out that a long-tail distribution of fact triples (i.e., (entity1, relation, entity2)) diminishes the advantage of the standard MIL since many bags might end up with duplicated instances (i.e., heavy upsampling is required to fill all the bags). This is particularly a problem in the biomedical data given that 50+% of fact triples appear in less than three sentences in PubMed. Instead, AMIL groups training instances by UMLS semantic types, which are shared across different entities. This approach results in more diverse instances in the bags, maximizing the benefit of MIL. For evaluation, the authors construct their own training/dev/test split from PubMed and UMLS. The BioBERT-base RE models are trained with AMIL and compare with the prior work (Amin et al., 2020) retrained on the same data. The main results show that AMIL models outperform the baseline by large margin. The authors further investigate performance on rare/common triples and 17 different relationship representations.","The paper presents explores the benefits of abstractifying relationships, i.e., taking into account the type signatures of its instances, to improve relation extraction from biomedical text corpora. The paper applies this technique on a state-of-the-art method for relation extraction based on BioBERT. The experimental evaluation on a handful of relation representations suggests that abstractified multi-relational extraction with middle mention attention pools and entity end markers outperforms the state of the art, and is particularly useful for tail relationships, i.e., relationships for which there are not many sentences that assert them. The results show that for those triples, both the aforementioned techniques provide a performance boost (Table 3).",0.13705583756345177,0.23893805309734514,0.17419354838709677
457,SP:29443825c6ffa0774dd93b485c4a2a1cc48cd0d3,"This submission proposes a method to combine the benefits of model-based RL and Imitation Learning (IL) for navigation tasks. The key idea is to i) learn a prior over trajectory distributions from a fixed dataset of demonstrations, and ii) use this learned dynamical model for path planning via probabilistic inference. Reaching target waypoints is done by maximizing the trajectory likelihood conditioned on the planning goal. The prior is learned using R2P2 on LIDAR features and past positions. Experiments using the CARLA driving simulator show that this method can outperform standard control, IL, and model-based RL baselines, while flexibly incorporating test-time goals and costs thanks to its probabilistic formulation.","The paper takes a model-based approach to ""imitation learning"". It first learns a (flow) ""model"" to assign likelihoods to trajectories being expert-like as well as sample expert-like trajectories. This is then combined with an estimate for trajectories being certain goal conditioned, where the goals come from a route planner. Results are shown in the context of autonomous driving in the CARLA simulator with a PID controller tracking the open-loop plan from the planner.",0.12612612612612611,0.18181818181818182,0.14893617021276595
458,SP:29537439a3017e0d6982b9b819dd83ea0c3b20ab,"This paper introduces a fairness perspective on accuracy performance among distinct classes in the context of adversarial training. It makes an observation that adversarial training algorithms (Madry et al. 2017, Zhang et al. 2019) yield biased performances on CIFAR 10. It also offers a theoretical study under a Gaussian mixture setting that respects Eq. (1). Three versions of fair robust algorithms are proposed and evaluated on CIFAR 10.","The authors study adversarially trained classifiers and observe that the accuracy discrepancy between classes is larger than that of standard models. They then propose a theoretical model where this phenomenon provably arises. Finally, they propose a method to reduce the (standard and robust) accuracy discrepancy between classes, by adapting existing methods from the non-adversarial setting.",0.10294117647058823,0.125,0.11290322580645161
459,SP:2997e3ea21f2a8a5dbb7952ecabcc70dfc1e0c57,"This paper proposes to change the perturbation budget for adversarial attacks to a non-uniform setting where differet input pixels have different perturbation budgets. To achieve this, an additional network is trained to learn the perturbation budget for each part of the input. The approach seems to perform better than a uniform perturbation budget and also learns semantically meaningful budgets for the input.","This paper address the problem of training robust neural networks with non-uniform perturbation budgets on different input pixels. In practice, a perturbation budget generator is introduced to generate the context-aware perturbation budget (i.e. conditioned on the input) for each pixel of the input image. A “robustness volume” constraint on generated perturbation budgets to control the robustness intensity is also proposed. Extensive experiments on MNIST and CIFAR10 demonstrate the proposed outperform SOTA method under various uniform perturbation budgets.",0.3492063492063492,0.275,0.3076923076923077
460,SP:29d472b7efdb02e3449a9edebeb54165b5f2becd,"The paper investigates the exploration-exploitation problem in meta-learning. The authors explain the problem of coupled exploration and validate it through a toy example. To overcome this issue, the paper introduces DREAM, a meta-algorithm decoupling exploration and exploitation. In the first step, DREAM learns an exploitation policy and a task embedding by maximizing the cumulative reward of the given task (task identifier is known at train). In the second step, DREAM learns an exploration policy that is ""compatible"" with the embeddings generated by the exploitation policy. DREAM outperformed the state-of-the-art algorithms in several experiments.","This paper introduces DREAM, a meta-RL approach that decouples exploration from exploitation. An exploitation policy learns to maximize rewards that are conditioned on an encoder that learns task relevant information. Then an exploration policy learns to collect data that maximizes the mutual information between the encoder and explored states. The work is compared against multiple baselines in simple tasks.",0.20202020202020202,0.3333333333333333,0.25157232704402516
461,SP:29f19f93648edfbc8c30536e8e99a4437c560993,"The authors aim at improving the canonical VAE model by replacing the standard iid Gaussian likelihood with a multivariate Gaussian with (low-rank + diagonal) covariance.  In applications to CelebA and a brain MRI dataset from UK Biobank, the authors compare the proposed structured-observation-space VAE with a canonical VAE, showing that the samples from their model have lower Fréchet Inception Distance (FID) scores than both means and samples from the canonical VAE. The authors then evaluate the expressiveness of the representations learned in the observation space by visually evaluating interpolations in the observation space, and images obtained by rescaling the principal components of the observational covariance matrix. Finally, the authors show how their model can be used for interactive editing—i.e., editing a small number of pixels and using the conditional distribution to infer coherent edits in the remainder of the image.","In the standard Variational Autoencoder framework the statistics of the decoder output are assumed to be pixel-independent Gaussian which can lead to problems when sampling from the model when covariances are missing. To overcome these limitations, the authors propose to use the network architecture proposed by Monteiro at al. 2020 in the decoder of a variational autoencoder. In the approacah of  Monteiro at al. 2020, the output distribution is modeled as low-rank multivariate normal. Qualitative results on the CelebA dataset demonstrate that samples from the proposed modified variational autoencoder capture covariances between different parts of the image.",0.15862068965517243,0.23232323232323232,0.1885245901639344
462,SP:29fb7c33be08a95d52a417d92b28fd8750a1944b,"In this paper, authors focus on the problem of efficiently embedding Knowledge Graphs in low-dimensional embedding spaces, a task where models are commonly evaluated via downstream link prediction and triple classification tasks. The proposed model - Riemannian TransE, based on TransE [Bordes et al. 2013] - maps entities to points in a non-Euclidean space, by minimising a loss based on the geodesic distance in such space. This paper is especially interesting, since extends previous approaches - such as Poincare embeddings - to the multi-relational setting. Results look promising on WN11 and FB13, but authors mention results on the more commonly used WN18 and FB15k are less accurate than those obtained by the baselines (without reporting them). It is worth mentioning that WN18 and FB15k were found to be solvable by very simple baselines (e.g. see [1]). Furthermore, authors do not report any finding on the geometry of the learned spaces.","The paper proposes a new approach to compute embeddings of multi-relational data such as knowledge graphs. For this purpose, the paper introduces a variant of TransE that operates on Riemannian manifolds, in particular, Euclidean, Spherical, and Hyperbolic space. This approach is motivated by the results of Nickel & Kiela (2017), who showed tha  Hyperbolic space can provide important advantages for embedding graphs with hierarchical structure.",0.1,0.23076923076923078,0.13953488372093023
463,SP:2a2479eb3132e7dc81fb86619d9075d0d7fb5f58,"This paper considers the multiview graph clustering problem where the goal is to find a cluster given multiple networks. The paper integrates the self-expression strategy and contrastive learning mechanism into a unified framework to perform graph learning. Besides, graph filtering is designed to recover a clean data in advance. An optimization algorithm is developed to solve the objective function. The paper compares the effectiveness of their method with other deep methods and demonstrates that the proposed method is competitive and promising.","This paper proposes a multi-view clustering method. They first use graph filter to generate a new node representation for input, and then do self-expression in a linear combination of various views. Afterwards, they propose a graph contrastive regularizer, which mimics the contrastive learning given the nearest neighbors as positive samples and any others as negative ones. Experiments compared with recent works and ablation studies are presented.",0.15853658536585366,0.19117647058823528,0.1733333333333333
464,SP:2a27fbff52cc7fc6b5f2791ed55f46321c451f53,"This paper proposes a client-based defence in federated learning against attacks which have already broken through server-side defences and which would otherwise persist through subsequent rounds after the adversarial attack has taken place. They place, under certain assumptions, theoretical bounds on the effectiveness of their approach and on its convergence. Experiments support the approach used.","The paper proposes White Blood Cell for Federated learning (FL-WBC) -- a client-based defense that can mitigate model poisoning attacks that have already polluted the global model.  The authors claim that strong model poisoning attacks that can circumvent server-based defenses can continue to impact the global model even if there are no subsequent attacks. Towards this end, the paper identifies the attack effect on the parameter space (AEP) and observes that the parameter subspace used for the attack is both inaccessible to the server and remains hidden in the kernel of the Hessian matrices on benign agents. Thus, they propose a client-based optimization that is designed to minimize the loss on the benign task while also minimizing the dimensionality of the Hessian kernel. Robustness certificate and convergence guarantees are also provided.  Evaluation is performed on FashionMNIST and CIFAR-10 datasets to demonstrate the ability of the defense to mitigate attacks using three metrics (attack metric, robust metric, and utility metric). Comparison is performed with DP-based defenses, CMA, and CTMA.",0.3333333333333333,0.10982658959537572,0.16521739130434784
465,SP:2a6531194b14410a59ae43cda18bc29bd633a0ec,"This paper studies training neural networks with sparse weights and sparse activations (SWAT training). By using sparse weights in forward passes as well as sparse weights and activations in backward passes, SWAT can reduce the computation overhead and also reduce the training memory footprint. The primary contributions of the paper are in three folds: 1) The authors empirically compare the impact of (activation) gradient sparsity and weight + activation sparsity on the model performance---the comparison shows that the weight + activation sparsity has less influence on the model accuracy; 2) Across different models on CIFAR and ImageNet dataset, SWAP can reduce the training flops by 50% to 80% while using roughly 2 to 3x less training memory footprint saving (weight + activation); 3) The authors empirically study on why training using top-K based sparsification can attain strong model accuracy---the magnitude-based top-K approach can roughly preserve the directions of the vectors.","This paper proposes SWAT as a training algorithm for sparse networks on different architectures. The paper claims being able to reach a level of sparsity with no drop in accuracy.  The goal is to minimize the computations during training time. To this end, SWAT sets to zero the vectors where necessary. Different from other approaches, SWAT uses sparse computation in the forward and backward passes. The intuition behind is that eliminating small components does not have an impact on the training process but can be used to minimize the computation required. ",0.13157894736842105,0.21978021978021978,0.1646090534979424
466,SP:2a6bbbe26cf19664ffb879a8ea4fb9e3be195d1e,The paper builds on ODE-RNN model that allows to represent a time series as a continuous trajectory. The authors address the limitation of the ODE-RNN model that the trajectory is continuous everywhere except the observation points. They introduce a compensation term based on cubic splines that transforms the output trajectory into a continuous one. This approach is also applied to correct a hidden state trajectory. The authors demonstrate better interpolation properties on sparse time series data.,"This work addresses the discontinuity issues caused by jumps in hidden state/output at the arrival of new observations in a ODE-RNN. This problem is tackled by adding a cubic spline smoothing component on top of ODE-RNN to produce smooth and continuous hidden state/outputs. They derive a closed form solution for the cubic spline component based on the output of ODE-RNN and obtain an error bound for 4th order derivable inputs. Although the cubic spline component has no trainable component, this work shows that the gradient can flow through it to ODE-RNN and perform end-to-end training. ",0.20512820512820512,0.1553398058252427,0.1767955801104972
467,SP:2a700d8fec6b0eceebfa2410365e63c73b473788,"The mutually exclusive assumption of traditional softmax can be biased in case negative samples are not explicitly defined. This paper presents Cooperative Importance Sampling towards resolving this problem. The authors experimentally verify the effectiveness of the proposed approach using different tasks including applying matrix factorization in recommender system, language modeling tasks and a task on synthetic data.","This paper presents Partially Mutual Exclusive Softmax (PMES), a relaxation of the full softmax that is commonly used for multi-class data. PMES is designed for positive-unlabeled learning, e.g., language modeling, recommender systems (implicit feedback), where we only get to observe positive examples. The basic idea behind PMES is that rather than considering all the non-positive examples as negative in a regular full softmax, it instead only considers a ""relevant"" subset of negatives. Since we actually don't know which of the negatives are more relevant, the authors propose to incorporate a discriminator which attempts to rate each negative by how hard it is to distinguish it from positives, and weight them by the predicted score from the discriminator when computing the normalizing constant for the multinomial probability. The motivation is that the negatives with higher weights are the ones that are closer to the decision boundary, hence will provide more informative gradient comparing to the negatives that are further away from the decision boundary. On both real-world and synthetic data, the authors demonstrate the PMES improves over some other negative sampling strategies used in the literature. ",0.21052631578947367,0.06282722513089005,0.09677419354838708
468,SP:2a886848c0832643ba2bd13804fe3fe8104a33bb,"The paper is proposing to evolve datasets of (inputs, outputs) in the context of programming by example (PBE), where the goal is to infer a computer program that is consistent with the association of (inputs, outputs). The justification of the approach is to figure out instances that would allow to learn a model with PBE that would generalize better, compared to learning from synthetic datasets that are randomly generated. The approach followed consists to use an evolutionary algorithm to generate this new dataset, using the learn model as a guide, by picking the points where the model at hand performs poorly. Such adversarial approach proceed iteratively, adding extra pairs of (inputs, outputs) to the training set, to get it to perform better in situations where it has trouble.",Synthesis models trained on synthetic datasets of randomly generated programs and corresponding IO pairs often fail to generalize to real-world PBE problems. The models often learn specific aspects of the synthetic data distribution rather than the semantics of the programming language. This work proposes a more principled adversarial approach to generate synthetic data. The training set is built iteratively by finding data distributions on which a given model performs poorly and adding data drawn from these distributions to the training set. The model and the training dataset are built in tandem. The candidate distributions are generated by mutating the current population of distributions. Models trained using this method are shown to generalize to a variety of distributions.,0.1875,0.2033898305084746,0.1951219512195122
469,SP:2a936f08edc99fef3191aebe7fce8c3d69dadb63,"This paper investigates how language models allocate their probability mass, with an emphasis on rare sequences that are part of the 'heavy tail' of the distribution of natural language sequences. The authors use a language model to define a target distribution with access to samples and ground-truth probabilities. A language model is trained on an empirical estimate of the target distribution, and the authors study the gap between the learned model's and target distribution's probability assignments.   Using this methodology, the authors uncover various interesting phenomena: the model systematically assigns lower probabilities than the target distribution, but assigns unusually high probabilities to unnatural, perturbed sequences (suggesting an explanation for where the probability mass moved to). The authors include several fine-grained analyses with additional interesting findings.","The paper conducts experiments to evaluate whether neural sequence models such as LSTMs and Transformers are able to correctly assess the probability of rare sentences, which collectively constitute a large probability mass in natural language productions (heavy-tail phenomenon). In order to do so, it performs experiments in a controlled synthetic environment where a first language model $P_L$ is trained on a corpus of natural sentences, and a second model $P_M$ is trained to emulate the first model. The authors observe that the second model systematically tends to underestimate the probability of rare $P_L$ sentences, the more so the rarer such sentences are, and show that some artificially corrupted sentences tend to receive higher probability from $P_M$ than from $P_L$, partly explaining where the missing probability mass over rare well-formed sentences went.  ",0.234375,0.21739130434782608,0.2255639097744361
470,SP:2aa14bdb20536ea98977136c78dfe0eb4a43955d,"This paper presents a feature interpolation strategy for fast semantic segmentation in videos. They first compute features of keyframes, then interpolate intermediate frames based on block-motion vectors (BMV), and finally fuse the interpolated features as input to the prediction network. The experiments show that the model outperforms one recent, closely related work wrt inference time while preserving accuracy.","This paper advances a method for accelerating semantic segmentation on video content at higher resolutions. Semantic segmentation is typically performed over single images, while there is un-used redundancy between neighbouring frames. The authors propose exploiting this redundancy and leverage block motion vectors from MPEG H.264 video codec which encodes residual content between keyframes. The block motion vectors from H264 are here used to propagate feature maps from keyframes to neighbouring non-keyframe frames (in both temporal directions) avoiding thus an additional full forward pass through the network and integrate this in the training pipeline. Experimental results on CamVid and Cityscapes show that the proposed method gets competitive results while saving computational time.",0.3220338983050847,0.16666666666666666,0.21965317919075142
471,SP:2acc1eabd0b823f9490611d1aaf5503b1e0de00d,"This paper provides necessary and sufficient conditions for exact recovery problems in a two-community correlated stochastic block model (SBMs). In this model, correlated SBMs are generated on the same set of vertices in a natural way and then the vertices of  one of the SBMs is randomly permuted. The paper gives necessary and sufficient conditions for 1) recovering the (unknown) permutation to recover the correspondence between the two SBMs and 2) recovering the underlying community memberships.  The extension to multiple correlated SBMs in also considered. ","This paper revisits the community detection problem from a theoretical perspective. The community detection problem on the SBM is now well-understood, this paper looks at a case where 2 correlated SBMs are given instead of only one. The nodes of the 2 SBMs represent the same population but the mapping between the nodes of the 2 SBMs is not known. This is a natural extension of the mathematical problem of community detection on a single SBM motivated for example by de-anonymizing social networks. The authors obtain partial results for exact recovery. A natural algorithm is to first align the 2 SBMs and then used the union of the 2 SBMs which is still a SBM to find the communities. The authors fully characterize when exact alignment is possible and then provide sufficient conditions for exact recovery. They also prove a partial converse result and provide conditions under which community recovery is information theoretically impossible.",0.313953488372093,0.17307692307692307,0.2231404958677686
472,SP:2af62c222666760e3a313b875e9bcb8190fed30b,"This paper presents PrediNet: an architecture explicitly designed to extract representations in the form of three-place predicates (relations). They evaluate the architecture on a visual relational task called the ""Relations Game"" which involves comparing Tetris-like shapes according to their appearance, relative positions, etc.. They show that their architecture leads to useful generalizable representations in the sense that they can be used for new tasks without retraining.","The authors propose a new neural network architecture that learns to form propositional representations with an explicitly relational structure from raw pixel data. The authors testified the proposed algorithm using the Relations Game, whose aim is to label an image containing a number of objects as True or False according to whether a given relationship holds among the objects in the image. This paper is well organized. The applied methods are introduced in detail. The authors showed the improvement using the Relations Game.",0.17647058823529413,0.14457831325301204,0.15894039735099338
473,SP:2b285a2bd22a399911c14ffac8534bbf9d8123d9,"This paper aims to view the computations performed by residual networks through the lens of transient dynamical systems. A rough intuition is provided, followed by experiments in a toy concentric circle example and on MNIST. Finally, a method to determine the appropriate depth of ResNets is proposed, though experiments are only performed in the toy concentric circle experiment. ",In this paper the authors analyse the role of residuals in the performance of residual networks (res-nets) with shared layer weights and propose a method to adapt the depth of such networks during training. They exploit  the fact that res-nets identical blocks / shared layer weights are discrete time dynamical systems to conduct their analysis. Their main contribution seems to be an empirical evaluation of the role of transient dynamics in the performance of such res-nets. Experiments are done on a toy dataset on concentric circles and MNIST data.,0.3103448275862069,0.1978021978021978,0.24161073825503354
474,SP:2b7f7b8d90f9d6bf2d58fe973a988322c0a4a557,"This paper investigates the use of conventional regularizers for neural networks in the reinforcement learning setting. Contrary to the standard practice of foregoing regularizers in deep RL, the paper finds that their addition can improve the performance of policy gradient algorithms on a standard suite of continuous control tasks. Various regularizers are tried, including l2/l1 regularization, entropy regularization and dropout in a combination with a few standard deep RL algorithms such as TRPO, PPO and SAC. Other experiments also verify the impact of these regularizers on the sensitivity of other hyperparameters and whether regularization should be applied to the value or policy networks. ","The paper provides an empirical study of regularization in policy optimization methods in multiple continuous control tasks. The paper focuses on the effect of conventional regularization on performance in training environments, not generalization ability to different (but similar) testing environments. Their findings suggest that L2 and entropy regularization can improve the performance, be robust to hyperparameters on the tasks studied in the paper. ",0.15384615384615385,0.25396825396825395,0.19161676646706588
475,SP:2b838e0fc3a29d7d098f2163a92aa74b1aef2d2f,"This paper provides an unsupervised approach to solve the inverse problem for reconstructing medical CT and MRI scans using score-based generative models. The proposed method was evaluated on the LIDC and BraTS datasets. Compared to existing supervised and unsupervised approaches, the proposed method demonstrates comparable or better performances in terms of PSNR and SSIM. ","The manuscript applies denoising score matching to linear inverse problems to solve compressed sensing problems in medical imaging, such as angular-undersampled CT and accelerated MRI reconstruction. Throughout the paper, the observed measurements $y$ are considered noise-free, which is reflected by a Dirac measurement distribution. To train a score function, a variance exploding SDE is considered as in previous works, e.g. Song et al. (2021).  During inference, the authors incorporate a weighted projection onto measurement samples unlike previous approaches, which consider the gradient of the data distribution. This projection can be implemented in various sampling approaches such as annealed Langevin dynamics or predictor-corrector schemes.  The numerical results indicate that unsupervised score matching methods are well suited for inverse problems in imaging and yield superior generalization performance.",0.2545454545454545,0.10852713178294573,0.15217391304347827
476,SP:2b8df72b380b893a55a82934afd558d75a3f42f2,"Review: This paper considers the problem of dropping neurons from a neural network.  In the case where this is done randomly, this corresponds to the widely studied dropout algorithm.  If the goal is to become robust to randomly dropped neurons during evaluation, then it seems sufficient to just train with dropout (there is also a gaussian approximation to dropout using the central limit theorem called ""fast dropout"").  ","This contribution studies the impact of deletions of random neurons on prediction accuracy of trained architecture, with the application to failure analysis and the specific context of neuromorphic hardware. The manuscript shows that worst-case analysis of failure modes is NP hard and contributes a theoretical analysis of the average case impact of random perturbations with Bernouilli noise on prediction accuracy, as well as a training algorithm based on aggregation. The difficulty of tight bounds comes from the fact that with many layers a neural network can have a very large Lipschitz constant. The average case analysis is based on wide neural networks and an assumption of a form of smoothness in the values of hidden units as the width increases. The improve fitting procedure is done by adding a set of regularizing terms, including regularizing the spectral norm of the layers.",0.23880597014925373,0.11267605633802817,0.15311004784688997
477,SP:2b917d3dbb0c0e550491e98d3a1e433be923ae8a,"This paper collects and releases a substantial new resource for the challenging task of cross-document event coreference, of ""silver"" coreference clusters automatically constructed from hyperlinks in web news articles.  It is substantially larger than previous human-annoated cross-doc event coref datasets, which is a task that is extremely challenging to annotate.  The authors also demonstrate that training a model on this silver data yields a high-performing model as evaluated on a previous human-annotated dataset.","The paper collects a new ‘silver’ dataset HyperCoref for cross document coreference resolution task, constructing by using hyperlinks in online news articles. The paper shows that the dataset is considerably larger () than existing human-annotated datasets and has broader coverage in terms of event types. Experiments on three existing human-annotated datasets (ECB+, FCC-T, GVC) show that models trained on the silver-dataset perform comparable to those trained on gold train data. ",0.28205128205128205,0.3013698630136986,0.2913907284768212
478,SP:2baa8c55ccd7dcf20363295dbfedd8c03229fd05,"This paper investigates the use of pre-trained imagenet classifier networks as feature extractors for GAN discriminators. The author propose to use multiscale fixed random projections combined via an FPN-like approach, and explore which levels of the feature hierarchy are best fed into an ensemble of discriminators under different projection and mixing settings. Results are presented on a range of unimodal datasets (CLEVR, FFHQ, LSUN, etc) and compared against FastGAN and StyleGAN baselines, showing improvements particularly wrt sample efficiency.","The papers proposes a technique for faster training of GANs while achieving state-of-the-art FID scores on several datasets. The main idea is to use pre-trained features for the discriminator. Four improvements are recommended: 1) Multi-scale discriminators, 2) cross-channel mixing 3) cross-scale mixing 4) choice of pre-trained network.  FID scores are shown for several datasets, CLEVR, FFHQ, Cityscapes, Bedroom and Church.",0.175,0.20588235294117646,0.18918918918918917
479,SP:2babd7819655158cde03167c37188ddf6a9147b2,"The paper proposes an end-to-end differentiable strategy (called neural TLP) to learn unknown temporal relations between atomic events (like after(miss, swing), “miss occurs after swing” in the baseball example), subsequently used to predict composite events (like strike). The strategy consists of a cascade of a smoothing stage to filter  out noise from the input time series, an interval time extractor, a stage predicting temporal relations (such as before, after and during) and a linear output layer. Furthermore, the paper proposes a post-hoc procedure to extract propositional logical rules relating atomic events to composite ones from the last layer. The performance of the proposed strategy is evaluated on video recognition (CATER) and healthcare (MIMIC-III) datasets against two baselines, namely a LSTM neural net and a simplified version of the proposed strategy.","This paper presents an approach for learning temporal rules from data. The idea is to extract atomic events, and their temporal relationships between them. Subsequently, composite events are learned using composite event labels for supervision. The whole approach is formulated as an optimisation problem, after which standard techniques are applied to solve it. ",0.08888888888888889,0.22641509433962265,0.12765957446808512
480,SP:2bc9def678bda940b7e85e8341841674a1e48406,This work suggests a general framework for deriving complex information-theoretic queries using probabilistic circuits (PCs). This framework represents a complex query as a pipeline of operations. The manuscript also provides algorithms for applying these operations to PCs as well.,"This paper investigate the tractability of arithmetic operations on circuits for probabilistic inference.  There is considerable similar work when it comes to operators on logical circuits, and this paper generalises this to operators such as powers, logarithm and exponentials. The paper also considers these operations in a computational graph, which means that the results of this paper can be used to prove tractability conditions for many queries, in particular divergences and entropy calculations. The paper discusses various examples of such tractability results. ",0.275,0.13414634146341464,0.18032786885245902
481,SP:2bf8148e5dadace0b6dd4b9f715fa8261f2a52db,"This paper claims to propose a method to train q-based agents that use “alternating” Q-learning. However, the alternating approach given in the paper appears to be the normal Bellman update implemented in most versions of DQN. Furthermore, the citation given for AltQ (Mnih et al. 2016) makes no mention of the term “Alternating Q learning”.","This paper is well-written and it provides a convergence result for traditional Q-learning, with linear function approximation, when using an Adam-like update (AMSGrad). It does the same for a variation of this algorithm where the momentum-like term is reset every now and then. This second result is not that exciting as it ends up concluding that the “best way” to converge with such an approach is by resetting the momentum-like term rarely. That being said, it is still interesting to have such theoretical result. On the empirical side, this paper evaluates the traditional Q-learning algorithm with non-linear function approximation (through a neural network), using Adam (and AdamR) while not using a target network, in both an LQR problem and a subset of the Atari games. The empirical results are not necessarily that convincing and there are important details missing. I’m willing to increase my score if my concerns w.r.t. the empirical validation are addressed since this paper presents a potentially interesting theoretical result with Adam, which is so prominent in the literature nowadays.",0.24561403508771928,0.07650273224043716,0.11666666666666667
482,SP:2c14eabf1f6b4c828ab8c59c608421860fc9e7e0,"Goals: This paper introduces a new optimal transport loss based on a minibatch computation in order to alleviate some weaknesses from the original minibatch OT formulation. The formulation treats minibatches as data and seek to transport the minibatches from the source distribution to the minibatches from the target distribution. By doing so, their method prevents some undesirable connections between data.","This paper proposed Batch of Mini-batches Optimal Transport (BoMb-OT) method, which finds the optimal coupling between mini-batches in mini-batch optimal transport (m-OT), which is achieved by solving another OT problem over the mini-batches.  The authors claimed that doing this will capture the relation between different mini-batches better. They firstly proved that BoMb-OT approximates the population BoMb-OT metric in probability measure space with and without entropic regularization.  The authors then implemented the proposed BoMb-OT method and applied it on deep generative models and deep domain adaptation, showing that BoMb-OT has favourable performance over m-OT.   ",0.2,0.11428571428571428,0.14545454545454545
483,SP:2c24186f9710a15d58c6af94828b80ae796af3f9,"The paper proposes a new algorithm for multi-agent reinforcement learning (MARL) that adaptively picks learning rates for actor and critic. Specifically, the learning rates are updated to directions maximally affecting the Q-function, and the algorithm dynamically balances the learning rates between actor and critic. In numerical studies, the authors illustrate the efficiency of their method via four toy experimental scenarios and intuitively explain the underlying mechanism.","This paper proposed AdaMa, which can automatically use adaptive learning rates for each agent in cooperative Multi-Agent Reinforcement Learning (MARL). AdaMa calculated the learning rate of each actor and critic according to their contributions of locally increasing value functions.  Simple experiments using toy examples show that the proposed AdaMa method can improve fixed learning rate method and other heuristics.",0.23529411764705882,0.26666666666666666,0.25
484,SP:2c485765c1d5d0ada7730ca804d4a298682bf928,"In this paper, the authors investigate the effect of task diversity in the training process of meta-learning. The findings indicate that increasing task diversity during the meta-training process does not boost performance. They evaluate the performance on four few-shot image classification datasets. ","The paper studies how the diversity of tasks in the training phase affects the performance of meta-learning algorithms. The paper finds negative evidence, which is consistent with Setlur et al. (2021). Compared with the existing work, the paper performs more extensive experiments with different meta-learning algorithms, different task samplers, and different datasets.",0.28888888888888886,0.24074074074074073,0.2626262626262626
485,SP:2c51f08fadcb0a94a6ac27a34f75366a417c2d7b,"This work studies the problem of learning stochastic discounted infinite-horizon Markov Decision Processes (MDPs) with unknown transition. The authors propose an algorithm UCBVI-gamma based on recent advances in episodic MDPs (e.g. Azar et al., 2017; Jin et al., 2018; Zanette and Brunskill, 2019) and specifically the Bernstein-type exploration bonus. Besides, the authors provide a lower bound which indicates that UCBVI-gamma matches the minimax lower bound up to logarithmic factors. ",The authors study the problem of learning a discounted tabular-MDP. They adopt a notion of regret that is closely related to policy identification problem.  The authors make two main contributions: 1. They show how to adapt UCBVI to discounted MDP. This lead to an algorithm called UCBVI-\gamma algorithm. This model-based algorithm uses OFU principle by computing Bernstein-type bonus for empirical Q-function. The policy of the algorithm is updated every time step (online algorithm).  The author prove that its regret is upper bounded by \tilde{O}(\sqrt{SAT}/(1-\gamma)^1.5) where \gamma is the discount factor.  2. The authors also derive a minimax lower bound for the problem that essentially match the upper bound of the algorithm {\Omega}(\sqrt{SAT}/(1-\gamma)^1.5). This shows that their algorithm is minimax-optimal. ,0.3108108108108108,0.16666666666666666,0.21698113207547168
486,SP:2cabed9c97692e64a609bb5a66fe7505c53c59fb,"The authors proposes block-minifloat (BM), a floating-point format for DNN training. BM is a fairly simple extension to block floating-point (BFP), which was proposed in (Drumond 2018 and Yang 2019). In BFP, a block of integer mantissas share a single exponent. In BM, a block of narrow floats share a single exponent bias. The shared exponent bias helps to shorten the exponent field on each individual float element. This is a good contribution, though a bit trivial.","This paper introduced a new representation (Block Minifloat) for training DNNs with low precisions of 8-bit or less. This new representation combines FP8 formats and the shared exponent bias concept to cover the dynamic range of tensors needed for DNN training. Compared to other published FP8 format, this representation has smaller exponents, which allows to use a more efficient Kulisch accumulator. The representation has been verified on a spectrum of deep learning models and datasets.",0.175,0.18421052631578946,0.1794871794871795
487,SP:2cbcf75328f1976570d8694cabbc5642f966ebd6,"This paper proposes a method for learning how to explore environments. The paper mentions that the “exploration task” that is defined in this paper can be used for improving the well-known navigation tasks. For solving this task, a reward function a network architecture that uses RGBD images + reconstructed map + imitation learning + PPO is designed.","This is a well explained and well executed paper on using classical SLAM-like 2D maps for helping a standard Deep RL navigation agent (convnet + LSTM) explore efficiently an environment and without the need for extrinsinc rewards. The agent relies on 3 convnets, one processing RGB images, one the image of a coarse map in egocentric referential, and one of the image of a fine-grained map in egocentric referential (using pre-trained ResNet-18 convnets). Features produced by the convnets are fed into a recurrent policy trained using PPO. Two rewards are used: the increase in the map's coverage and an obstacle avoidance penalty. The agent is further bootstrapped through imitation learning in a goal-driven task executed by a human controlling the agent. The authors analyze the behavior of the navigation algorithm by various ablations, a baseline consisting of Pathak's (2017) Intrinsic Curiosity Module-based navigation and, commendably, a classical SLAM baseline with path planning to empty, unexplored spaces.",0.23636363636363636,0.07975460122699386,0.11926605504587155
488,SP:2cd4e9bce03b98ab2d321dca8628eeacfada140a,"This paper designs a multilayer connection structure for neural networks, such that the connection architecture supports implementation of a hierarchical classification scheme within these layers.  It applies this design to the task of hierarchical classification on ImageNet.  Experiments compare results with those of Deng et al. (2012), as well as baseline flat classification models.","The paper proposes a method to learn concept classes along with its concept superclasses. The proposed method relies on an ontology which they heuristically re-organize by essentially pruning nodes that have few descendants and large semantic overlap. The network proposed to model the ontology essentially just consists of a learned multiplicative gate at each level of the ontology with a standard xent loss over concepts and regularizing term that indicates if the category is an ancestor concept. The experimental results claim gains over some baselines, e.g., combined acc. of 69.05 vs chosen baseline 66.15 on ImageNet12 for ResNet-50 features at a cost of between 18.2% increase in parameters.",0.18518518518518517,0.08771929824561403,0.11904761904761904
489,SP:2d073cd15d16bdf07f9e934c28192a1b36a27b38,The paper proposed a deep Bayesian model for heterogeneous multi-omics data integration. The Gromov-Wasserstein (FGW) regularization between latent representations of heterogeneous views is used to align nodes/features in every pair of views. The experimental results have demonstrated improvement in inferring meaningful relations.,The authors propose a Bayesian framework to learn relations among multi-omic datasets. The main unique advantage over existing methods is the proposed method is able to learn without a priori dependency structure and it allows a certain degree of missingness and mismatching. Experiments on two biomedical multi-omics data sets partially demonstrate the effectiveness of the proposed method.,0.2,0.15254237288135594,0.1730769230769231
490,SP:2d12ba88cb0ad6b2d1f6174b3bb10d138d32c4e9,"Deep learning uses augmentations to improve generalization performance. Using all augmentations for a dataset may slow down training. A subset selection technique is proposed (e.g., ""coreset"") using insights from the Neural Tangent Kernel (NMT) framework such that an alignment between the NMT Jacobian and the residuals is preserved. This alignment score is used to select the coreset using submodular optimization, which allows the model to be trained on a subset of augmented data (e.g., 0.1% to 30%) while preserving most augmentation benefits. The speedup of the method is reported to be up to 6.3x.",The authors model data augmentation as an additive perturbation and analyze its effect on training dynamics and how it enlarges the smaller singular values of the network jacobian. Then they propose a new method to iteratively extract a subset of the training data that when augmented closely capture the full augmented data dynamics. Authors show that by augmenting this subset combined with full training data they can outperform the state-of-the-art method by 7.7% on CIFAR-10 and 4.7% on SVHN while achieving 6.3x and 2.2x speedup respectively.,0.17346938775510204,0.18085106382978725,0.17708333333333331
491,SP:2d237edc34601e158d7ed48ecc72bc873ae5f4dd,"The paper studies the VAE approximation error, when the encoder and decoder distributions are from conditional exponential families (EFs). Theorem 1 characterizes the form of the joint probability (an EF-Harmonium) which is consistent, i.e. where q_{phi}(z|x) \equiv p_{theta}(z|x). Sec 4.2 shows a v interesting example of Gaussian VAEs for CelebA images, where it is shown that a VAE ""unlearns"" the ground truth solution (being pulled away from the likelihood optimizer towards the consistent subset). Sec 4.3 shows another interesting example, where a careful formulation of the model identifies that it should use word counts rather than frequencies, and this is demonstrated empirically (Table 2).","Summary. This paper presents an analysis of the approximation error of VAE models when the encoder and decoder are from exponential families. They show that when the model is consistent (i.e., the encoder is able to match the posterior), the encoder and decoder distributions are exponential family distributions that are linearly parameterized. The paper also shows that barring pathological cases, when the model is tight the decoder distribution is close to a linearly parameterized exponential family distribution. In particular, this shows that in this case additional depth is not useful.  Despite the restriction to exponential family distributions, the paper shows a number of real instances of models that lie in this class including Gaussian VAEs and VAEs with RBM encoders. For Bernoulli VAEs for semantic hashing, the paper proposes and verifies improvements to a model presented in the literature. ",0.24561403508771928,0.2,0.2204724409448819
492,SP:2d246377df0afb9665f4ea9f2c510e9f48cc6d8c,The paper proposed to solve a vehicle routing problem with time windows using neural network and reinforcement learning framework. An attention based encoder-decoder model is used to predict the distribution over problem instances while satisfying the problem constraints. Then a RL framework is  trained to optimize the model parameter. Experimental results on a synthetic dataset demonstrate that the proposed framework performs at par with traditional combinatorial problem solvers like Google OR tools and LKH heuristic.,"This paper proposes a Neural Combinatorial Optimization approach to solving the Vehicle Routing Problem with Time Windows. It uses a policy gradient method to optimize an attention model, paired with a masking scheme that prevents unwanted actions during the policy rollout. Performance is compared with OR-Tools and LKH-3 solvers. ",0.2631578947368421,0.39215686274509803,0.31496062992125984
493,SP:2d4b408a083d8ccd887b847c98ff1faed9d90d30,"Recent studies demonstrate adversarial training suffers from severe overfitting besides getting very expensive. This paper proposes to handle the two problems organically altogether, with the tool of sparse training.   The authors show that injecting appropriate sparsity forms in training could substantially shrink the robust generalization gap and alleviate the robust overfitting, meanwhile significantly saving training and inference FLOPs. ","This paper deals with the problem of training a neural network so that it generalizes well over data unseen at training time. Namely, they address the particular case where a network is trained over an adversarial scheme. This paper proposes two methods for learning a sparse architecture called robust and flying bird. These methods aim at identifying sparse subnetworks arising during early training stages, so to get a pruning mask that eventually yields a sparse architecture (RobustBird). FlyingBird improves over Robust Bird in teh sense that the learning mask can be dynamically adjusted over time, i.e. pruned params may be recovered later on. The authors then experiment at training multiple architectures over different datasets in the experimental section, showing better generalization abilities and lower computational complexity (MACs) for their proposed methods Robust and Flying Birds. the authors conclude that sparsity help networks to generalize better, and as a byproduct it slashes computational complexity. ",0.25862068965517243,0.09740259740259741,0.14150943396226415
494,SP:2d58648b0c2f1866f7a5da9adf1e73b607a075d3,"The paper describes a GAN architecture and training methodology where a generator is trained to generate ""micro-"" patches, being passed as input a latent vector and patch co-ordinates. Micro-patches generated for different adjacent locations with the same latent vector are combined to generate a ""macro"" patch. This ""macro"" output is trained against a discriminator that tries to label this output as real and fake, as well as predict the location of the macro patch and the value of the latent vector. The generator is trained to fool the discriminator's label, and minimize the error in the prediction of location and latent vector information.","This paper proposes to constrain the Generator of a WGAN-GP on patches locations to generate small images (“micro-patches”), with an additional smoothness condition so these can be combined into full images. This is done by concatenating micro-patches into macro patches, that are fed to the Discriminator.  The discriminator aims at classifying the macro-patches as fake or real, while additionally recovering the latent noise used for generation as well as the spatial prior.",0.16981132075471697,0.23684210526315788,0.19780219780219777
495,SP:2db8b4f6637f4d7171a686f3daf386b0df1067a8,"This paper proposes a method to find a sequence of reasoning paragraphs in Wikipedia to answer queries requiring multi-hop reasoning. They make the key observation that answering multi-hop queries might require retrieving evidence that have very less lexical overlap with the question. Given a query, the proposed method starts from a set of initial paragraphs retrieved by a tf-idf retriever and uses the outgoing Wikipedia anchor link to hop to the next evidence. They propose a simple recurrent neural network that takes in the current paragraph (and the hidden state) and decide which paragraph to hop to in the next step. Because of the available supervision for the paragraphs (in HotpotQA), they can train a supervised path selector. They also add a special EoE token that denotes the end of the reasoning path, thereby having the ability to produce reasoning paths of different lengths. After training the retriever a beam of reasoning paths is sent to the reader module. The reader module re-ranks the reasoning paths again and then use a standard BERTQA model and the top re-ranked chain of paragraphs to find the evidence.","This paper introduces a graph-based recurrent retrieval model for retrieving evidence documents in a multi-hop reasoning question answering task. The main idea is that (1) the graph formed by Wikipedia links between passages can be used as constraint for constructing reasoning chains, and (2) the joint encoding of the question and current passage can be used to retrieve a subsequent passage in the reasoning chain. The paper describes a model for implementing the above retrieval system, and how they jointly train with a reading comprehension model. They demonstrate the effectiveness of the system on HotPotQA, showing improvements over previously published models, and SQuaD-Open, showing competitive results.",0.15263157894736842,0.26605504587155965,0.1939799331103679
496,SP:2dbd99bd7ef55248d5d6fcca7ae2866218173949,"This paper’s main contributions are (i) to propose two new benchmarks for online continual learning in the context of language modelling and (ii) evaluate the performance of a number of composition-of-experts-based models on the new datasets using a number of metrics. The multilingual benchmark, derived from an existing multilingual news corpus, consists of sequences of characters where the language is periodically switched, and the MultiDomain benchmark consists of sequences of English words where the corpus is periodically switched. The comparative performances of the various baselines on the two datasets, as well as an analysis of the mixture weights in one of the models during training, are used to provide insights into the qualitative differences between the datasets.","The paper proposes two benchmarks for continual language modeling: one evaluating character-level multilingual drift between languages which share similar characters and second evaluating word-level drift between English corpora of different domains. The setup is online in the sense of evaluation: they evaluate on the new sentences and then train over them (unlike image datasets), and catastrophic forgetting is hence characterised as having higher error than was in the past when there is a switch between the domains/languages. Hence, the loss functions measuring forgetting quantify the height and length of the rise in error. They compare a mixture of expert baselines with gating by different gating methods on this setup.",0.19008264462809918,0.20535714285714285,0.19742489270386265
497,SP:2dc6337218afc973db75d973d08c0cdd7e55698b,"The authors propose RMIX to deal with the randomness of rewards and the uncertainty in environments. RMIX learns the individual value distributions of each agent and uses a predictor to calculate the dynamic risk level. Given the individual value distribution and the risk level, a CVaR operator outputs the C value for execution. For training, the $C$ values are mixed as $C^{tot}$ and updated by TD error end-to-end. RMIX outperforms a series of value decomposition baselines on many challenging StarCraft II tasks. The paper is very clear and well-structured. Expanding value decomposition methods to the risk-sensitive field is a novel idea, and it shows competitive performance in empirical studies. ","This paper proposes a new value-based method using risk measures in cooperative multi-agent reinforcement learning. The authors propose a new network structure that calculates global CVaR through individual distribution and learns risk-sensitized multi-agent policies. The authors also propose a new dynamic risk level prediction method that can dynamically adjust the risk level according to the agent’s observation and action. Applying risk-sensitive reinforcement learning in multi-agent reinforcement learning is interesting, but several points can be improved.",0.16666666666666666,0.23170731707317074,0.19387755102040818
498,SP:2dd878321ec5ebf6cd2874fe1623b68f190467af,"This work investigates whether intra-class separation in the latent space of a neural network correlates with its generalization capabilities. To perform this, the authors design 4 measures that attempt to capture whether separate sub-clusters are formed for different sub-classes of a (super-)class. All measures take into account all activations in all layers of network. 2 measures operate at neuron level, 2 at layer level. 2 are designed for cases where we do have explicit sub-class labels, and 2 are for the case that no such labels are given. The work performs multiple experiments on Cifar10 & Cifar100 & Cifar100(superclasses) where multiple models are trained with varying hyper-parameter configurations, each leading to different performance. Then, it is shown that the 4 measures correlate positively with performance, which according to the authors suggests that intra-class separation within the network is happening and is important for generalization. ","The authors note that in classification tasks there typically exist within-class groups of similar images that are not explicitly encoded in the coarse class label -- they call this intraclass clustering. They hypothesize that the ability of DNNs to recognize these intraclass clusters without being explicitly told about that could correlate with generalization. They then proceed to verify this on a range of networks, architectures, and a large number of hyperparameter configurations. They take care to establish causality where possible. In addition, they show that the intraclass clustering can be detected with simple variance-based methods, and that it emerges early in training.",0.11333333333333333,0.1650485436893204,0.13438735177865616
499,SP:2de60266ac8f4832460bd1da6451a74f63fd8f28,"This paper proposes a combination of SGD with selective application of a non-backprop learning rule (Hebbian). The two learning rules are not applied together, but rather a boundary is determined where layers prior use SGD, and the ones after use the Hebbian approach. A selection algorithm dynamically adjusts the boundary over training. For accuracy reasons, they include weak supervision by using the overall classification loss to control the sign of the update. ","This paper try to leverage the benefit of Hebb learning to reduce CNN training time cost. In order to achieve this,  a learning mode selection algorithm is proposed to progressively increase  number of layers using Hebb learning. The writing of this paper is good and the idea is also interesting, however, the experimental part should be improved:",0.1506849315068493,0.19298245614035087,0.16923076923076924
500,SP:2dea3a92d8827e212ea00095f4f7e5f011538497,"This paper proposed an alternative point cloud feature extractor, named PointMLP. PointMLP is composed of residual MLPs and geometric affine modules. Classification results on ModelNet40 dataset show the proposed methods achieves slightly better accuracy while using much smaller number of parameters and faster runtime. The proposed method achieves better accuracy in classification results on ScanObjectNN dataset and is on par with state-of-the-art methods for 3D shape part segmentation task on the ShapeNetPart benchmark.","This paper introduces a lightweight and fast neural network architecture processing 3D point cloud. While the idea is quite simple, the proposed architecture outperforms or matches the performance of the previous architectures in terms of both accuracy and also inference time with various tasks including ModelNet40 classification, ScanObjectNN classification, and ShapeNetPart segmentation, as shown in the experimental results. The main idea is to make two modifications in the PointNet++ architecture, 1) adding MLP layers after each of the point feature aggregation (max-pooling) steps, and 2) applying a geometric affine transformation to the features processed with an MLP in each small PointNet module. It's interesting to see that these small modifications (especially the second) make dramatic changes in the results.",0.2236842105263158,0.14049586776859505,0.17258883248730966
501,SP:2e125a1c23bb6dca29df2b8cc9455ce23322c994,"This paper developed two sample and communication efficient decentralized actor-critic algorithms for multi-agent reinforcement learning. Specifically, the authors proposed decentralized AC and natural AC algorithms that can be private and efficient for different agents to learn. They added noise the local rewards of agents, which were shared among different agents. Moreover, the authors adopted mini-batch updates for the actors and critics in these two algorithms. Theoretically, the authors showed that both algorithms were able to achieve the state-of-the-art sample complexities. To validate the proposed algorithms, they used a simple environment to show the superiority over the existing decentralized AC algorithm. Overall, the investigated topic in this paper is absolutely interesting. The sample and communication complexities of decentralized MARL algorithms remain active research areas. While the mathematical analysis in this work looks good, the numerical results to me don't look very convincing. Additionally, there are quite a few points I have in mind regarding the proposed algorithm and the relevant analysis.","In this work, the authors propose two decentralized policy gradient-type algorithms for multi-agent reinforcement learning, namely, a decentralized actor-critic algorithm and a decentralized natural actor-critic algorithm. The stochastic updates of both algorithms preserve the agents' privacy information, including their local actions and local rewards. The authors analyze the finite-time convergence rate of both algorithms under Markovian sampling and linear function approximation, and prove that both algorithms achieve the state-of-the-art sample complexities and improved communication complexities.",0.20359281437125748,0.40963855421686746,0.27199999999999996
502,SP:2e305b4762d57663e3c96ae164a9cd385dfe9549,"The paper aims to benchmark a suite of Multi-Agent Deep Reinforcement Learning algorithms across different environments in the cooperative multi-agent setting. The paper compares standard algorithms alongside extensions of well-known policy gradient algorithms to the multi-agent setting, i.e. PPO (MAPPO), SAC (MASAC) and TD3 (MATD3). The paper investigates the ease of using an algorithm by doing a fair hyperparameter search for different algorithms. The paper concludes by saying that MAPPO is a promising choice for tackling a multi-agent problem. ","The major contribution of this paper is benchmarking 5 MARL algorithms on 4 cooperative multi-agent environments. Also, this paper found that under constrained hyperparameter search budgets, the multi-agent PPO algorithm has more consistent performance over the other algorithms across different tested multi-agent environments. The code base is open-sourced for public use, which benefits the MARL community.",0.18823529411764706,0.26666666666666666,0.2206896551724138
503,SP:2e51257f7719e5e6df7acd3a985489660869971e,"Low-rank matrix recovery in the presence of sparse corruptions and random noise, under incoherence assumptions on the low-rank and on the sparse components, have been considered. Following an existing line of work, a tuning-free optimization programs has been proposed for demixing and denoising. The analysis, utilizing existing techniques, establishes a bound on the reconstruction error. The bound has been observed to be loose by a dimension-dependent factor (according to the experiments and compared to other estimators for this problem). The estimator is a convex optimization problem which authors solve via ADMM.  Numerical experiments support the usefulness of the proposed approach in a set of synthetic and real data scenarios. ","This work combines stable Principal Component Pursuit and Square Root Lasso and proposes Square Root Principal Component Pursuit for low-rank + sparse recovery problem. Compared to stable PCP, Square Root PCP has the advantage that the choice of the regularization parameter is noise-independent, so it is easier to be deployed in applications where the noise level is unknown. Theoretical analysis and experiments confirm the effectiveness of the proposed method.",0.1504424778761062,0.24285714285714285,0.18579234972677594
504,SP:2e548e320d5da211ffed027de7f0c6b78935f205,"This paper proposed a novel approach to reduce size of the embedding table while not to drop in accuracy and computational optimization. Fixed-size embedding table has two problems, high memory usage cost and overfitting problem for those features that do not require too large representation. This paper recast the problem of embedding-size selection into learning column-wise sparsity, constraint K (eq(7)) and then convert S(V,s) problem (eq(8)). Paper used three benchmark datasets and some classical methods to verify effect.","The paper proposes PEP (Plug-in Embedding Pruning) to reduce the size of embedding table while incurring insignificant drop in accuracy. The related work is well summarized into Embedding Parameter Sharing and Embedding Size Selection methods and the motivation for the current approach is well explained. The paper draws inspiration from Lottery Ticket Hypothesis. The problem formulation of Embedding pruning is done in a crisp way avoiding additional hyper parameter tuning that can be found in other methods. Similar to LTH, the paper shows that the initiation strategy can make the training process faster and stable. The results show an impressive 97-99% parameter pruning via PEP. As for the computation cost, PEP results show an additional 20-30% time cost compare with base models.",0.25882352941176473,0.176,0.2095238095238095
505,SP:2e6e3e928f4a398cb89208e3af72d60022951b0f,"Summary:  1. This paper proposes two neural networks by construction, i.e., Triangularly-constructed Neural Network (TNN) and Semi-Quantized Activation Neural Network (SQANN).  2. These two neural networks are universal approximators, which is proven by construction.  3. These two neural networks are resistant to catastrophic forgetting.  4. For TNN, strongly activated neurons and half-activated neurons can be identified.  5. For SQANN, users can identify the samples that are likely out of distribution.   Contributions claimed by authors:  1. TNN and SQANN are proposed.  2. The universal approximation is proven, using the construction of TNN and SQANN.  3. Resistance to catastrophic forgetting is proven.  4. SQANN can identify out-of-distribution samples. ","This paper proposes two new neural networks (NN) construction schemes that aim at better interpretability, in the sense that (1) the NN should always memorize the training data; (2) the NN can roughly tell if a new test data has any similarity to any data in the training sample. The authors also provide approximation error bounds on both training and test data under certain assumptions. Some numerical examples are shown to support their theory.",0.13392857142857142,0.20270270270270271,0.16129032258064516
506,SP:2e7c43705291298211f8934cf38e84f8446d71ae,"This paper aims at exploring the properties of neural network training during the early phase. By some studies on the lottery ticket hypothesis, something important happens during the early phase of training so rewinding the network should go to these early phases instead of the initial phase. So, what is important during training? The paper explores this problem from four aspects through empirical studies: ","This paper is dedicated to examining the changes that networks undergo during the early phase of the network training. The author conducts extensive measurements of the network state and its updates during the early iterations of training. Based on the observations, they find that: i) deep network is not robust to reinitialization with random weights, but maintained signs; ii) the distribution is highly non-i.i.d after the early phase of network training. This is why permuting weight dramatically harms performance. iii) the changes in the supervised networks are label-agnostic. The author claims these results can play an important role in explaining the network changes in the initial critical period.",0.328125,0.1875,0.23863636363636365
507,SP:2eb629c9ac83f2068ae67b00c10c5c9ba11bbc13,"This paper is in defense of simple semi-supervised learning (SSL) with pseudo-labeling (PL): authors demonstrate with experiments on 4 vision datasets (CIFAR-10, CIFAR-100, Pascal VOC and UCF-101) that pseudo-labeling can perform on par with consistency regularization methods. Authors argue that PL doesn't work well because of poor network calibration: because of that the high confident predictions are wrong leading to noisy training and poor generalization. The main contribution of the paper is the usage of prediction uncertainty selection in addition to the confidence-based selection which provides high accuracy of PL used in the further training. Besides this PL is generalized to create negative labels: with this authors perform and show effectiveness of negative learning and multi-label classification. Proposed approach performs in the same ballpark as state-of-the-art methods on CIFAR-10 and CIFAR-100, while it achieves the new state-of-the-art results on video dataset and multi-label task. It is worth to notice that proposed approach is independent from the domain while consistency regularization methods extensively are based on the specific augmentation techniques for the vision/datasets.","As noted in (Guo et al., 2017), modern neural networks are often miscalibrated. Pseudo-labeling based Semi-Supervised learning schemes are predicated on high confidence predictions from these neural networks. This paper posits that this miscalibration may lead to inferior results in confidence-based pseudo-labeling approaches. By taking into account the uncertainty of models and only using pseudo labels from high-confidence instances with low uncertainty this work presents a model that significant improves on other PL strategies and is competitive with consistency-based regularization strategies that comprise the current state-of-the-art.",0.11518324607329843,0.23157894736842105,0.15384615384615385
508,SP:2eba253ff91a7543c5269403292f66cb93b68a8d,"The paper proposes to learn object detection model, while training on different datasets with different, potentially overlapping, label spaces. While previous methods do the label space mapping, from each dataset specific label space to the common universal label space, manually, this paper proposes to learn such mapping automatically. The proposed models work as well as dataset-specific models on resp. training datasets and generalize far better.",The main idea of the proposed work is to learn a universal label space for a given task (say object detection) and a set of different datasets with  semantically overlapping labels. The only supervision required by the approach is constituted by the single dataset label spaces and respective annotations. Each dataset label space may have partial o complete overlaps (e.g. rider mapping to cyclist and motorcyclist ). The approach exploits a pre-trained detector on the trivial label space given by the union of all label spaces as a starting point. An optimization problem jointly minimizing some loss taking into account the task error with a penalization on the cardinality of the label set.,0.3333333333333333,0.19298245614035087,0.24444444444444444
509,SP:2ec2433a907a60ebfbf9ffefc72b70eb76c1f591,This paper formalizes a new generalization error bound for the problem of spurious correlation (a.k.a. confounding factors or dataset bias) and shows that it is tighter than the well-established domain adaptation one under realistic assumptions. The analysis leads to a set of solutions linking to established solutions. It further proposes a practical solution that does not require explicit knowledge of spurious correlated features as the established ones need. ,"This paper studies the problem that spurious features in the training set can cause accuracy drop in the test phase. They formalize a generalization error bound for this setup and provide two solutions, one principled solution with the knowledge of spurious correlated features and one minimal supervision (MS) method without knowing this information, based on their bound. They also have some experimental results demonstrating the effectiveness of their proposed MS method.",0.22535211267605634,0.22535211267605634,0.22535211267605634
510,SP:2f2b672ccaca843584bb353595ffcd44d3a6f9f9,"This paper proposes an efficient method to compute self-attention in Transformers without sacrificing accuracy. The idea is to compute the covariance self-attention over the feature dimension followed by a 3x3 conv to model the patch interaction. With additional techniques such as feature grouping and L2 norm, the method shows competitive accuracy on ImageNet compared to the recent Vision Transformer models. This method has linear complexity to the input patches and thus can be used for high-resolution images on the detection and segmentation tasks.","This paper presents a modification of vision transformers by introducing Cross-Covariance Attention (XCA) and Local Patch Interaction (LPI) which substantially reduce the computational overhead and enhances the stability of training. The authors also adopt the DeiT training strategy with distillation using a convolutional teacher to improve the performance. Experiments on Imagenet classification, self-supervised training with DINO and many downstream tasks (COCO object detection and instance segmentation, ADE20K semantic segmentation) show the superior performance. ",0.18604651162790697,0.21333333333333335,0.19875776397515527
511,SP:2f460faff6d62d462bd80a4545f3ce435d2ab0f6,"In this paper, the authors propose the incremental RNN (iRNN), which is inspired by the continuous-time RNN (CTRNN). Theoretically, the equilibrium point of iRNN exists and is unique. Furthermore, the norm of the Jacobian between two hidden states is always one, provided that the Euler iterations converge. The authors proved this property as well as the exponential convergence rate of the Euler iteration. These properties avoid the vanishing/exploding gradient problem typical in RNN with long sequences in theory. Empirically, the proposed method is compared with multiple RNN architecture on various tasks. ","The authors present a novel work to address the problem of signal propagation in the recurrent neural networks. The idea is to build a attractor system for the signal transition from state h_{k-1} to h_k. If the attractor system converges to a equilibrium, then the hidden to hidden gradient is an identity matrix. This idea is elegant. The authors verify the performance of Increment RNN on long-term-dependency tasks and non-long-term-dependency tasks.",0.1827956989247312,0.21518987341772153,0.19767441860465118
512,SP:2f65e47bd1d28c29907b5061ab6d3e11f9ff1c4b,"The goal of the paper is to incorporate logical relations into pre-training of language models to solve the reliance of existing reasoning-enabled language models on external knowledge bases. This is done in a self-supervised way - facts (tuple of 2 arguments and a predicate) are parsed using dependency parsing, and then a logical graph is created to denote relationships between coreferents, and between predicates and arguments. Three pre-training objectives are presented over the facts and logical graph: logical connective masking, logical structure completion and logical path prediction.  The author's claimed contributions are the following: - 3 new pre-training objectives: logical connective masking, logical structure completion, logical path prediction - The model Prophet which ""achieves significant improvement over various logic reasoning involved NLP and NLU downstream tasks"" - An analysis that verifies how Prophet is using the context for logical reasoning","The paper proposes a new pre-training technique to induce a logical prior in the language model representation. Concretely, they propose pre-training on facts, represented as knowledge base triples (source, sink, relation) (knowledge-base completion) and link prediction, alongside traditional masked language modeling objective. Their proposed method achieves some improvement over downstream tasks, including a subset of GLUE benchmark and a couple of relation prediction datasets.  ",0.1267605633802817,0.26865671641791045,0.1722488038277512
513,SP:2fa2a5ffa0193c0e5840bd18dc500739d2c369e0,"This paper analyzed which learning rate schedule (LRS) should be used when the budget (number of iteration) is limited. First, the authors have introduced the concept of BAS (Budget-Aware Schedule). Various LRSs are classified, and it is experimentally shown that the LRSs based on BAS performed better. Among them, the performance of the linear decay method was shown to be simple and robust.","This work presents a simple technique for tuning the learning rate for Neural Network training when under a ""budget"" -- the budget here is specified as a fixed number of epochs that is expected to be a small fraction of the total number of epochs required to achieve maximum accuracy. The main contribution of this paper is in showing that a simpler linear decay schedule that goes to zero at the end of the proposed budget achieves good performance. The paper proposes a framework called budget-aware schedule which represents any learning rate schedule where the ratio of learning rate at time `'t' base learning rate is only a function of the ratio of 't' to total budget 'T'. In this family of schedules, the paper shows that a simple linear decay works best for all budgets. In the appendix, the authors compare their proposed schedule with adaptive techniques and show that under a given budget, it outperforms latets adaptive techniques like adabound, amsgrad, etc.",0.34375,0.13414634146341464,0.19298245614035087
514,SP:2fa9b2601acf885062d3c9d158f6518a9213f398,"This paper assesses the effects of training an image classifier with different label types: 1-hot coarse-grained labels (10 classes), 1-hot fine grained labels (30 labels which are all subcategories of the 10 coarse-grained categories), word vector representations of the 30 fine-grained labels. They also compare the representations learned from an unsupervised auto-encoder. They assess the different representations through cosine similarity within/between categories and through comparison with human judgments in an odd-one-out task. They find that (i) the auto-encoder representation does not capture the semantic information learned by the supervised representations and (ii) representations learned by the model depend on the label taxonomy,  how the targets are represented (1-hot vs. wordvec), and how the model is trained (e.g. fine-grained then coarse grained stages), (iiii) the different representations predict human judgements to differing degrees. the first finding is obvious and I'm not even sure why it needs to be stated -- of course semantics of images are not inherently encoded in the pixels of an image! The second point again, is not surprising . This paper starts to get at some interesting questions but does not follow through.  It is also quite confusing to read despite thee simple subject matter. This paper is also missing a related work section! There has been so much word on adding structure to the label space of image classifiers (e.g. models that learn image/text embedding space jointly, models that predict word vectors, graphical model approaches to building in semantic information, etc.) and none of this is discussed. There has also been work on comparing convnet representations to human percepts e.g. https://cocosci.princeton.edu/papers/Peterson_et_al-2018-Cognitive_Science.pdf)and none of this work is discussed! This work needs to be better situated within the context of previous work in this field. Please write a related work section.","This paper demonstrates the importance of labels at various levels (no label, basic level label, and superordinate level) as well as in combination to determine the importance of semantic information in classification problems. They train an identical CNN architecture either as an autoencoder (no labels), with the basic label, with the subordinate label, with the basic and subordinate labels, and with basic labels which are fine-tuned with one-hot encodings of superordinate labels, as well as with word vectors. Classification accuracy, t-SNE, cosine similarity matrices and predictions on a human behavior task are used to evaluate the differences across labels types. The authors find that superordinate labels are helpful and important for classification problems. ",0.078125,0.21551724137931033,0.1146788990825688
515,SP:2fdd3bcbf3e2c79fc91ccc96527d635ed96ecc9b,"- This paper presents a new approach to automatic differentiation (AD), namely the use of reversible programming to achieve memory-efficient function inverse and adjoint. The authors have done a good job reviewing the background and laying out the motivation for the new apporach. The implementation is based on adding an embedded DSL to Julia called NiLang. Through reversible programming, NiLang gets rid of the need for checkpointing and hence is amenable to CUDA execution. NiLang is benchmarked against native Julia, ForwardDiff and Tapenade. The performance of NiLang is slightly worse than other approachs in the GMM benchmark. But in the bundle adjustment benchmark, NiLang outperforms ForwardDiff and Tapenade, especially with CUDA acceleration.	","The paper adapts reversible computing techniques to compute gradients. The techniques presented are not new though the Julia based DSL is new. The results presented are for differentiating through a GMM. It is not clear if the technique scale to a modern day neural network models and how they will integrate into current frameworks like JAX, PyTorch or TensorFlow.",0.11607142857142858,0.22033898305084745,0.15204678362573099
516,SP:2ff18d17591580761f1c92cc74aa837b52915c71,"This paper proposed ProxQuant method to train neural networks with quantized weights. ProxQuant relax the quantization constraint to a continuous regularizer and then solve the optimization problem with proximal gradient method. The authors argues that previous solvers straight through estimator (STE) in BinaryConnect (Courbariaux et al. 2015) may not converge, and the proposed ProxQuant is better.","This paper proposes a new approach to learning quantized deep neural networks, which overcome some of the drawbacks of previous methods, namely the lack of understanding of why straight-through gradient works and its optimization instability. The core of the proposal is the use of quantization-encouraging regularization, and the derivation of the corresponding proximity operators. Building on that core, the rest of the approach is reasonably standard, based on stochastic proximal gradient descent, with a homotopy scheme.",0.23214285714285715,0.16666666666666666,0.19402985074626866
517,SP:301524218da40096adedfa6d058b1f6ef93ea882,"Authors used BERT alongside to a 2D-position embedding based on a sinusoidal function and a graph-based decoder to improve performance on document information extraction tasks. They do pre-train their model (BROS) on a large dataset with 11M documents, and then used such models to perform downstream tasks in four smaller datasets. Their models achieve better quantitative results when compared to the provided baselines.","The paper proposes the pre-trained language model BROS which aims to leverage both text and spatial information to improve information extraction on documents. Using the graph-based decoder from SPADE, BROS achieves the SOTA performance on some entity extraction and entity linking downstream tasks. However, the area-masking strategy does not show significant improvement over the LayoutLM and the graph decoder is proposed in SPADE which is not new. In addition, as most commercial OCR tools have already got very good reading order information, the benefit from the graph decoder might be marginal.",0.19696969696969696,0.13829787234042554,0.1625
518,SP:3021e8b74146a257b5befec014cd17d5d7bd3362,"Taylor polynomial based loss function metalearning acts as a regularizer that improves the networks adversarial attack robustness, performance, training time, and data utilization. The authors evolve weights, and so add arbitrary other factors to the loss, including adversarial robustness to learn a loss function parameterization which is more robust. They provide analysis of the attractor states under the optimization of a suite of loss functions.",This paper analyzes a learned loss function called TaylorGLO based on third-order Taylor expansion and its regularization properties. This approach is novel and interesting in that the loss function is also learned on data. The analysis of the TaylorGLO loss and another learned loss function Baikal loss near zero error reveals interesting properties of preventing overconfident predictions. ,0.18461538461538463,0.20689655172413793,0.19512195121951223
519,SP:3030aeb9862c75808ed5e9111432287520ff5062,"This work proposes a method to effectively find structurally sparse winning tickets. It consists of some post-processing techniques that can be added to each round of standard iterative magnitude pruning (IMP) methods. Starting from unstructured sparse sub-networks, the method uses a ""re-filling and re-grouping"" manner to enforce the formation of structural sparsity.","LTH (lottery ticket hypothesis) was mainly proposed for unstructured pruning. This paper shows it can also be validated on structured pruning, for the first time. The key for them to achieve so is the newly proposed post-processing techniques, refilling(+) and regrouping. They show by these techniques, structural winning tickets can be found, with up to 6.67x on hardware platforms.",0.16071428571428573,0.14754098360655737,0.15384615384615385
520,SP:3044e58365db4d2ac46059803c3696add32881ba,"This paper proposes an ML-based method to optimize TensorFlow Graph execution. Specifically, it combines graph neural networks (GNNs) and BRKGA (a genetic algorithm) to search over the joint space of TF node-device placement and scheduling. The core claims on the advantages of this method are that (1) it co-searches placement and scheduling space, (2) the trained model can generalize to different graphs and inference cost is very  small. The experimental results show that REGEL can outperform a few baseline methods on this problem.","In this paper, the authors proposed a framework to generating a task scheduling for a compiler to reduce the execution cost of neural networks. A computation graph is first fed into a GNN to produce a beta distribution, which is then fed into the BRKGA algorithm to yield the encoded solutions. The motivation is interesting, and the proposed method is technically reasonable. The details are also included in the appendix. To improve the quality, the following concerns may be considered:",0.19767441860465115,0.2125,0.20481927710843373
521,SP:30580fb0f3acf76221f8b031518a30228c4d6162,The authors propose a system called MetaPhys for personalized remote physiological sensing from videos.  Their system combines a pre-trained CNN with an existing meta learning method (MAML). The investigated both supervised and unsupervised training of their system.  Performance evaluation of their methods on benchmark datasets show their model significantly outperforms SOTA methods using multiple metrics as well as for different skin types. They further show that the unsupervised model achieves comparable results to the supervised model.,"In this paper, the authors present a few-shot learning model for non-contact physiological signal measurement to build a more accurate and convenient personalized health sensing system. The motivation is that traditional fine-tuning method for this task is difficult since it requires large sets of high-quality training data for specific individuals, due to differences between each individual, measurement environment, and camera sensor condition. Therefore, the authors applied MAML on top of the existing deep learning network (TS-CAN) and implemented a model that aims to learn fast from a small number of training samples. The main contributions of this paper are: a meta-learning model that supports both supervised and unsupervised few-shot adaptation; improved performance by about 40% compared to a baseline that does not use meta learning; empirical analysis of performance for subjects with different skin types. ",0.2597402597402597,0.14084507042253522,0.182648401826484
522,SP:3072194753b9f5af63f5d4c9a06b6d67f39e6b0b,"This paper studies the problem of learning classifiers from noisy data without specifying the noise rates. Inspired by the literature of peer prediction, the authors propose peer loss. First, a scoring function is introduced, minimizing which we can elicit the Bayes optimal classifier f*. Then the authors use the setting of CA to induces a scoring matrix, and then the peer loss. Moreover, this paper explores the theoretical properties of peer loss when p=0.5. In particular, the authors propose \alpha weighted peer loss to provide strong theoretical guarantees of the proposed ERM framework. The calibration and generalization abilities are also discussed in section 4.3. Finally, empirical studies show that the propose peer loss indeed remedies the difficulty of determining the noise rates in noisy label learning.","The paper studies the label noise problem with the motivation of without estimating the flip rate or transition matrix. This is an interesting direction for dealing with label noise. Most of the previous studies need either estimate the transition matrix or put restrictions on it, e.g., to be symmetric. A very related work to this paper: L_{DMI}: A Novel Information-theoretic Loss Function for Training Deep Nets Robust to Label Noise, where no restrictions have been made on the class-dependent transition matrix and the proposed method does not need to estimate the transition matrix. The authors may need to discuss the paper.",0.17054263565891473,0.20952380952380953,0.18803418803418803
523,SP:30e7bbca17b264e59fc856365ad7dcf6081c7861,"The paper found several methods to improve log likelihood of diffusion models while maintain their sample quality, including cosine instead of linear noise schedule, using a hybrid objective to learn parameters of the covariance function, and using importance sampling to improve the gradient noise. The authors also explore how sample quality and log likelihood scale with the number of diffusion steps and model capacity. Experiments on 64x64 ImageNet dataset show competitive llh while keeping the sample quality.","The paper talks builds upon the recent work from Ho (2020) about generative models that use noise diffusion. The authors suggest that the proposal in Ho can not only be used in good quality sample generation (as already shown by Ho), but also leads to reasonable improvements in likelihood. Overall, some of the ideas presented in the paper are interesting and useful; but the paper overall needs work. ",0.14285714285714285,0.16176470588235295,0.15172413793103448
524,SP:30f608af43649c9526b7e13e58afb90366e000d0,"This paper introduces DeepQ, a multi-codebook quantization framework with NN-based methods.   In DeepQ, code b is encoded by neural networks. To tackle the non-differentiable gradient estimation issue, a revised policy gradient method has been adapted here to accelerate convergence.   The effectiveness of the proposed methods is well demonstrated on multiple datasets.","This paper proposes a multi-codebook quantization method (aka additive quantization).   In this setting vectors are decoded as x = sum_i C(i, b_i) with C a codebook matrix.  There is no clear optimal algorithm to train the codebook and optimize the b_i (the strongest competitor that this paper compares with is LSQ [16]).   This paper proposes to train a neural net that computes the b_i's in a forward pass together with the codebook matrices.  At encoding time, the neural net outputs a probability distribution for the code components (a policy) from which several codes are sampled randomly, and the best one is kept (after computing the quantization error).  The training is based on a policy optimization, that is able to handle noisy gradients that result from the code sampling procedure.   The experiments show promising results, that sometimes outperform the SOTA LSQ at a much lower encoding cost.   ",0.3148148148148148,0.1118421052631579,0.1650485436893204
525,SP:30fffab6fd645af0a4f8b9c96d5535f11469667e,"Instead of back-propagation, the authors consider a randomized search heuristic to train the parameters of neural networks. The proposed work is based on the hypothesis that the initial set of neural network weights is close to the final solution. The authors identify the problem that existing randomized search methods update all the parameters of the network in each update. Thus the proposed method updates only a single weight per iteration. Experimental results on MNIST and CIFAR10 show that the proposed method delivers competitive results.","The paper proposes an RSO (random search optimization) method for training deep neural networks. This method is gradient-free and based on the Markov Chain Monte Carlo search. In particular, it adds a perturbation to weight in a deep neural network and tests if it reduces the loss on a mini-batch: the weight is updated if this reduces the loss, and retained otherwise. ",0.16470588235294117,0.21875,0.18791946308724833
526,SP:311d2ebcdc0f71789d6c46d23451657519495119,The paper theoretically investigates the role of “local optima” of the variational objective in ignoring latent variables (leading to posterior collapse) in variational autoencoders. The paper first discusses various potential causes for posterior collapse before diving deeper into a particular cause: local optima. The paper considers a class of near-affine decoders and characterise the relationship between the variance (gamma) in the likelihood and local optima. The paper then extends this discussion for deeper architecture and vanilla autoencoders and illustrate how this can arise when the reconstruction cost is high. The paper considers several experiments to illustrate this issue.,"This paper is clearly written and well structured. After categorizing difference causes of posterior collapse, the authors present a theoretical analysis of one such cause extending beyond the linear case covered in existing work. The authors then extended further to the deep VAE setting and showed that issues with the VAE may be accounted for by issues in the network architecture itself which would present when training an autoencoder.",0.15151515151515152,0.21739130434782608,0.17857142857142858
527,SP:313326bdfcb110ac0ff48cec45c3d69fc469e215,Authors proposed a model for input method for mobile or desktop devices. The goal is to convert the input sequence (from one language to another) or predict the next word. Their model is based on an LSTM with modified softmax activation function that is adjustable for large vocabulary sizes. They showed experimental results on Japanese BCCWJ data set.,"The paper demonstrates the main challenge of using LSTM-based language models for input method in real time is the huge amount of computation in the softmax. The authors present a system to speed up the inference by avoiding computing the full softmax in the Japanese conversion task, where the number of output words can be limited from the mapping of the input sequence through a lexicon. The experiment result is encouraging in that the proposed incremental selective softmax approach significantly reduces latency over the standard inference with the full softmax computation while not hurting accuracy much. The paper also evaluates the effect of quantization for LSTM LM model compression in terms of size and accuracy.",0.22413793103448276,0.11206896551724138,0.14942528735632185
528,SP:313f52f0734140154ab31a602457829ae6eda9c0,"This paper considers the problem of semi-supervised learning, where the unlabeled data may include out-of-class samples. To address this task, the paper proposes a method consisting of three steps: (1) detecting out-of-class samples in the unlabeled set, (2) assigning soft-labels to the detected out-of-class samples using class-conditional likelihoods from labeled data, and (3) using auxiliary batch normalization layers  to help mitigate the class distribution mismatch problem. Experiments are conducted on CIFAR-10, CIFAR-100, ImageNet datasets. Results show improvements over competing methods.","The paper proposes a new approach for open set semi-supervised learning, where there are unlabeled data from classes not in the labeled data. The paper uses a contrastive representation learning paradigm to learn a feature encoder and a similarity measurement. Then the paper filters outlier samples by the similarity measurement and further utilizes outlier samples with soft labels. The separate BN layers address the distribution shift between in-class and out-class data.",0.1978021978021978,0.24324324324324326,0.21818181818181817
529,SP:31412e46449bccbfe0b74080a1c15df64b2363d5,"Given several mutli-label machine learning APIs, this paper study how to select those APIs under a budget constrant while striving to improve the overall accuracy. The author first formulate the budget API select problem as an integer linear programming problem, then relax the integer contraint and solving the relax problem in dual. The advantage of such modeling is to have a fast decision function for online deployment of their API selection systems. The experiment results are promising and consists of several ablation studies. ","This paper addresses the practical task to use the combination of ML APIs for multi-label classification. Different from the related work FrugalML which ignores the correlation between ML APIs, the proposed FrugalMCT allows selecting and combining the different ML APIs based on a budget. Sufficient theoretical and empirical analyses are provided to demonstrate the effective of FrugalMCT.",0.14285714285714285,0.20689655172413793,0.16901408450704225
530,SP:3145e0027567692ea5c3ca4ef8d0d94b40f8f27f,"This paper makes a step towards understanding of the implicit bias of optimization algorithms in deep learning. The authors consider alternative loss functions for deep networks: (1) the temperature-scaled cross-entropy loss with different values of the temperature; (2) the hinge-loss with different values of the margin parameter; (3) the Gcdf loss with different values of the variance parameter. The paper introduces the Gcdf loss which is derived as a modification of the 0-1 loss under the noise in the parameters of the linear output layer. The authors propose to use the alternative losses as measures of margin and sharpness associated with a solution found by an optimization algorithm. The experiments show how SGD in different learning scenarios (low/high learning rate and small/large batch) performs implicit minimization of the alternative loss functions with different parameters. Specifically, using larger learning rates/smaller batch sizes is shown to implicitly minimize the losses corresponding to higher values of the temperature/margin/variance. The results provide insights about margins and sharpness of solutions found by different modes of SGD.","This paper want to show that minimizing cross-entropy loss will simultaneously minimize Hinge loss with different margins, cross-entropy loss with different temperatures and a newly introduced Gcdf loss with different standard deviations. The main contribution is a new gcdf loss based on Gaussian-perturbed parameters. However, this loss can only be used with linear models. For deep models, the authors suggest that only measure this loss on the top layer of model.",0.1388888888888889,0.33783783783783783,0.1968503937007874
531,SP:316b4921f9663cc676e8de7a482fea4c7a2c35f1,"In this work, the authors analyze Plug and Play (PnP) methods for solving inverse problems, and utilize the framework from compressive sensing with generative models to derive theoretical guarantees. In particular, the authors show that in a linear inverse problem, if 1) the residual operator of a denoiser is Lipschitz and 2) the measurement matrix satisfies a restricted eigenvalue condition over the range of the denoiser, then linear convergence of the PnP algorithm can be established for suitable parameter choices. Moreover, under a similar set of assumptions, an equivalence between PnP and Regularization by Denoising (RED) is derived, in that both algorithms have the same set of solutions. Empirical evaluations also show 1) supporting evidence for aspects of the theory holding for trained neural network-based denoisers and 2) that PnP algorithms compete with, and can outperform, state-of-the-art compressive sensing approaches using deep generative priors.","This paper contains three theoretical results as well as a numerical comparison for the regularization by denoising (RED) and plug-and-play prior (PnP) algorithms, in which energy minimization algorithms for inverse problems are used as a template to derive algorithmic schemes that utilize denoising (or artifact removal) networks instead of regularizers. The paper shows that under (compressed-sensing-like) assumptions the recovery of certain solutions can be guaranteed (Theorem 1), and subsequently extends it to an error bound in the presence of noise and no assumptions on the solution to be recovered (Theorem 2). Finally, it is shown that RED and PnP have the same fix point sets if the used denoising network is non-expansive (Theorem 3). In the numerical results, a comparison on the exemplary problem of compressed sensing image recovery is conducted to conclude that artifact removal networks (specialized on removing artifacts that arise in the considered reconstruction problem) perform significantly better than generic denoising networks.  ",0.19594594594594594,0.18125,0.18831168831168832
532,SP:31950e78fd806be2e0f7cc4728251fdc1a3c437d,"This paper proposes to model temporal sequences using autoregressive flows across time steps, that allow to model more explicitly temporal changes of the input, i.e. how the input x_t has changed w.r.t x_{<t}. As also stated by the authors, this is a generalization of other work that instead of modelling the input at each time step, models temporal differences between consecutive time steps.","The paper proposes to combine the video modeling approaches based on autoregressive flows (e.g. Kumar’19) with amortized variational inference (e.g. Denton’18), wherein an autoregressive latent variable model optimized with variational inference is extended with an autoregressive flow that further transforms the output of the latent variable model while allowing to compute exact conditional probability. This is motivated with a physical intuition, where a dynamics model can benefit from decorrelating the inputs, and it is demonstrated that layers of autoregressive flows can represent derivatives of the original signal. In a proof-of-concept experiment, it is shown that using a layer of autoregressive flow improves NLL of a latent variable model.",0.20588235294117646,0.12280701754385964,0.15384615384615385
533,SP:31a497e4a1c74532ad3357b19e9fa4000db61115,"This paper proposes to pre-train policies on some goal-reaching tasks, and then leverage the associated successor features to improve the learning of a new task. The method heavily draws from the Generalized Policy Evaluation/Improvement framework without adding much to it. The only relevant point would be showing (as the title indicates) how to obtain disentangled cumulants, and whether they help transfer to new tasks. Nevertheless, both the definition, the full method, and the claimed benefits are quite ambiguous.","The paper addresses the problem of policy transfer in reinforcement learning, which is an extremely relevant open problem in RL, and is being actively studied by the community.  The authors propose a framework for discovering a set of policies without external supervision which can then be used to produce reasonable performance on extrinsic tasks.  The work exhibits originality in that it shows that disentangled representations, learned by intrinsic rewards,  can lead to learn behaviours that are transferable to novel situations.  ",0.14814814814814814,0.15,0.14906832298136644
534,SP:31b3653cae47c7e33f5379141951ea37a8c98a79,"The authors have proposed using an active learning approach to estimate evaluation metrics for a given model. The approach learns a sampling function that decides which observations need to be labeled, which are then fed to a Bayesian neural network (BNN) that aims to estimate the distribution Y|X. The authors select which observations to sample by maximizing the mutual information between the model evaluation metric and the BNN parameters.","The paper proposes an active testing approach that actively selects test instances to estimate the performance of a (black box) machine learning model. The key idea is to train a Bayesian Neural Networks (BNN) with a small amount of labeled test data and evaluate how well the model-under-test agrees with the BNN on samples for which the BNN has a high confidence. More instances to be labeled by an oracle are selected with active learning, i.e. select the data point that minimizes the uncertainty of the metric prediction.",0.3142857142857143,0.24175824175824176,0.2732919254658385
535,SP:31b86280f4e7863cfa6c70d55695d26e7b65a8bf,"This paper presents a SANE model to improve the ensemble learning from the perspective of model specialization. In particular, it first gives the analysis on existing ensemble strategies, i.e., random and diversity-driven, via conducting experiments on synthetic data. By this way, it points out the weakness of these strategies lies in the lack of specialty. Motivated by this, this paper presents the specialization-aware method to improve the ensemble learning. Specifically, it introduces anchor points in the latent space for guiding the model learning towards specialty. To derive the correlation between samples and anchors, it utilizes the transformer-like attention mechanism for learning the weights of base models. This paper demonstrates its effectiveness on several image and tabular benchmarks. ","This paper presents a novel method for ensemble learning. By introducing a anchor scheme and specialization loss , the base learner are forced to be specialized. The method is validated on both tabular and image datasets.",0.10743801652892562,0.37142857142857144,0.16666666666666669
536,SP:31dd2c7f2862364818a9abd277425b627d0af4d6,"The authors propose an alternative approach to training seq2seq models, which addresses concerns about exposure bias and about the typical MLE objective being different from the final evaluation metric. In particular, the authors propose to use a dynamic program to compute the optimal continuations of predicted prefixes (during training) in terms of edit distance to the true output, and then use a per-token cross entropy loss, with a target distribution that is uniform over all optimal next-tokens. The authors conduct a number of experiments, and show that this scheme allows them to attain state-of-the-art performance on end-to-end speech recognition, and that they can moreover do this without needing to pretrain the model with the MLE objective.","The paper considers a shortcoming of sequence to sequence models trained using maximum likelihood estimation. In particular, a model trained in this way can be biased in the sense that training sequences typically have different sets of prefixes compared to test sequences. As a result, at the prediction time the model does not generalize well and for a given input sequence the decoder constructs a label sequence which reflects the training label sequences rather than the actual target label.",0.13821138211382114,0.21518987341772153,0.1683168316831683
537,SP:31e7f8d332aaeed8669c0a98d3e43edf1e6271bc,"This paper proposes an autoencoder for high-quality waveform synthesis. The approach is based on multi-band decomposition, VAE and adversarial fine-tuning. The synthesis speed is substantially faster than existing approaches on both CPU and GPU.","This paper aims to achieve fast and high-quality audio synthesis. The authors propose a variational autoencoder-based model called real-time audio variational autoencoder (RAVE) to achieve this aim. In particular, the authors introduce a two-stage training scheme to alleviate the difficulty in joint learning of the adequate representation and high-fidelity audio synthesis. More concretely, in the first stage, representation learning is conducted in a VAE framework. In the second stage, audio fidelity is improved using adversarial fine-tuning. The authors also introduce a post-analysis method to manipulate the balance between fidelity and compactness. The effectiveness of the proposed method was evaluated on the Strings and VCTK datasets. The applications to timbre transfer and signal compression were also demonstrated.",0.3783783783783784,0.11382113821138211,0.175
538,SP:31ea372b3f432d831b1a53b07ac223c958c78408,"This paper presents a general algorithm for CRF learning and inference.  The algorithm is a regularized version of the classical FW algorithm.  It generalizes several existing algorithms , such as mean field and the concave-convex procedure.  Empirical studies on semantic segmentation tasks demonstrate intriguing properties of the proposed regularized FW algorithm. ","Semantic segmentation is a widely-studied problem in computer vision, and over the years a range of techniques have been popular. This paper re-visits the use of dense CRF layers on top of a neural network, which can be used to model pairwise connectivity across output labels. They contribute a new optimization method for mean field inference in the CRF that converges quickly (provably), and is differentiable (such that the whole model can be trained end-to-end). The paper pushes the SOTA on two popular segmentation benchmarks.",0.23529411764705882,0.1348314606741573,0.17142857142857143
539,SP:32047b62ffb4a15e2ff7d757d8506abeb8770dde,The authors frame the decomposition of the Laplacian equation as an unsupervised regression problem that is using a 5-level (and fully connected?) neural network as regression function.  A cost function to be used in the optimization is proposed that is expanded to eigendecomposition problems of increasing complexity. A comparison with a classical method indicates that the proposed approach is comparable to or better than the former for the given task.,"The manuscript proposes a deep learning solver for the eigenvalue problem of differential self-adjoint operators. Specifically, the aim is to calculate M lowest eigenvalues and their corresponding eigenfunctions. This work is a natural follow up of the work by Bar and Sochen (2019) for solving PDE-based problems.  The unsupervised loss resembles the loss suggested in Bar and Sochen (2019), with addition of mainly two terms: (a) The Rayleigh Quotient term and (b) the orthogonality constraint.  In practice, the proposed framework is tested on the 1D and 2D Laplace operators on regular domains. ",0.2112676056338028,0.1595744680851064,0.18181818181818182
540,SP:3225cc5911de7539e93553a7794975ea4358671e,"This paper proposes a novel approach to estimate the confidence of predictions in a regression setting. The approach starts from the standard modelling assuming iid samples from a Gaussian distribution with unknown mean and variances and places evidential priors (relying on the Dempster-Shafer Theory of Evidence [1] /subjective logic [2]) on those quantities to model uncertainty in a deterministic fashion, i.e. without relying on sampling as most previous approaches. This opens the door to online applications with fully integrated uncertainty estimates. ","This paper proposed deep evidential regression, a method for training neural networks to not only estimate the output but also the associated evidence in support of that output. The main idea follows the evidential deep learning work proposed in (Sensoy et al., 2018) extending it from the classification regime to the regression regime, by placing evidential priors over the Gaussian likelihood function and performing the type-II maximum likelihood estimation similar to the empirical Bayes method [1,2]. The authors demonstrated that the both the epistemic and aleatoric uncertainties could be estimated in one forward pass under the proposed framework without resorting to multiple passes and showed favorable uncertainty comparing to existing methods. Robustness against out of distribution and adversarially perturbed data is illustrated as well.",0.2289156626506024,0.15079365079365079,0.1818181818181818
541,SP:326dad16a8e4a1aaf80950dbed74ac096c0d5fef,"In this work, the authors consider the problem of continual learning with distribution shifts.  The work extends the recent work invariant risk minimization (IRM) from Arjovsky et al. to a continual learning setup. IRM was designed as an offline learning framework. In this work, the authors consider the setting where the different domains arrive sequentially. The authors propose a Bayesian extension of the IRM framework that allows sequential updates as the environments arrive. They provide a justification for how the KL divergence term helps in shrinking the support continually to arrive at an approximately invariant support. Several experiments were carried out on colored MNIST and its variants to show how the proposed scheme is better than existing continual learning methods and existing IRM frameworks. ",This paper extends the idea of invariant risk minimization (IRM) initially introduced by Arjovsky et al. (2019) to the setting of continual learning in which environments are observed sequentially rather than concurrently. This extension is implemented under a variational Bayesian and bilevel framework and the optimization is solved using a variant of the alternating direction method of multiplier (ADMM). The authors demonstrate the superiority of the proposed methods on variants of Colored MNIST. ,0.20161290322580644,0.3424657534246575,0.25380710659898476
542,SP:3286b16b5791520a5d0e11bb42a8f3f5e5b8604d,"This paper presents a differentially private method for training a generative model. The proposed method takes advantage of the Sinkhorn divergence to achieve robustness against the hyperparameters' choices. The authors also introduce a cost function enabling the generative model to generate images associated with a specific class label. The experimental results show that the proposed method outperforms the existing methods for learning a generative model in a differentially private manner. Furthermore, such a high accuracy can be achieved without the use of publicity available data.","The paper proposes a method for training OT GANs using differentially private sinkhorn algorithm. The idea is very simple - train GANs with sinkhorn divergences and add Gaussian noise to the gradient of output wrt generated samples. So, the novelty by itself is minimal as sinkhorn GANs have previously been proposed. The method merely adds Gaussian noise to gradients. The DP analysis is also not very different.",0.15294117647058825,0.19696969696969696,0.17218543046357615
543,SP:32abdf60d25c01e6a2025568fda331da4881e463,"The paper investigates the multi-head self-attention mechanism (MHSA) of transformer networks through the lens of tensor decompositions via tensor diagram notation. The authors propose an extension to MHSA inspired by the Tucker decomposition (termed THSA), analyze its expressive power, and demonstrate that it belongs to a class of more expressive functions than MHSA. Further, the authors show the positive effect of this drop-in replacement on the downstream tasks.","Focusing on the multi-head self-attention (MHSA) structure, this paper proposes an extension of the tensor diagram to denote self-attention (SA) structures more intuitively. Then inspired by the Tucker format, this paper also proposes a new form of SA named Tucker-Head Self-Attention (THSA), which can also be illustrated with the tensor diagram extension. Although THSA derives some success, THSA may lack theoretical guarantee and experiments seems insufficient.",0.2535211267605634,0.2535211267605634,0.2535211267605634
544,SP:32adfd2c979b3d1b8092be2bd67e8970e8b27226,"+ This paper proposes a method for synthesizing 3D scenes in novel view by treating the network as a general radiance field. It seems that the method is more like traditional manner based on multiple view geometry. It enables the generalization ability of rendering unseen test data in contrast to the most related work, NeRF (Mildenhall et al., 2020).","This paper presents a new neural learner for learning generic scene radiance function. Compared with existing methods such as NeRf which are scene-specific requiring per scene based training, the proposed new method is potentially able to generalize to novel unseen scenes or objects.   Specifically, the method represents scene as a neural radiance filed in terms of spatial coordinates of camera centre and a query point. An attention model is used for aggregating back-projected image features at every query location, and the aggregated feature vectors are then used for predicting its RGB-alpha radiance.  ",0.1896551724137931,0.11578947368421053,0.1437908496732026
545,SP:32b0b62a233b816c8405deb383aed5e3a7d1cf0b,"This paper proposes a flow-based method for the unsupervised data set alignment problem. It firstly reveals that the minimization problem over density models can be addressed by optimizing the upper bound of generalized JSD. Based on this theoretical result, the authors propose a new regularizer for the multi-distribution alignment problem. Compared to prior work, e.g., AlignFlow and LRMF, the authors derive a more general framework for the unsupervised data set alignment problem. The authors also provide extensive experiments to verify its effectiveness and superiority.","The paper presents a unified framework for domain alignment through non-adversarial approaches. Instead of solving a min-max adversarial problem, this paper aims to solve a min-min optimization equivalent to minimizing the upper bound of JSD. It proves the equivalence and offers a computational and feasible solution that can be inserted into flow-based non-adversarial approaches in a plug-and-play fashion. Preliminary results on generating digits from different classes or domains have demonstrated the correctness of the model.",0.1839080459770115,0.1951219512195122,0.1893491124260355
546,SP:32be26cc5561e9335adc2179a3c832258c2a346e,The paper proposes an actor-critic neural network architecture for autoregressive generation of 3D molecular structures with reinforcement learning (RL). It builds upon the RL approach by Simm et al. (2020) which makes use of internal coordinates in order to deal with the symmetries that occur when placing atoms in the molecular design process.,This work presents an approach for 3D molecular design using reinforcement learning that exploits rotational symmetries in molecular conformations. The formulation involves an MDP that selects atoms from a “bag” and positions them in 3D space. The reward function is based on PM6 energies to encourage the generation of low-energy structures. The manuscript is well-written and provides ample context and appropriate references.,0.2222222222222222,0.1875,0.20338983050847456
547,SP:32d66326d021e4868f893849d6628d7c86da55a9,This paper presents a impossibility result for value-function approximation in batch-mode RL. The chart below puts this work in context. This work essentially shows -- through a constructive example of an MDP -- that the amount of data needed for approximating Q values must increases exponentially with the horizon in episodic RL tasks even if we assume that the Q-values are realizable and that the features gathered by the behavior policy -- that collected the data -- are uncorrelated. This problem arises because the data gathering policy can fail to get data from all states even though the features themselves are uncorrelated. ,The paper provides a theoretical analysis on the sample complexity of OPE with linear function approximation and assumptions on representation and distribution shift. The main results shows that realizability and feature coverage are not sufficient to guarantee a polynomial sample complexity. The paper also provides a performance guarantee for LSVI with a stronger assumption on the distribution shift. ,0.10891089108910891,0.1896551724137931,0.13836477987421386
548,SP:32d80c08e2e1a76e06e701d537264421493db122,"This work proposes a functional form for the relationship between <dataset size, model size> and generalization error, and performs an empirical study to validate it. First, it states 5 criteria that such a functional form must take, and proposes one such functional form containing 6 free coefficients that satisfy all these criteria. It then performs a rigorous empirical study consisting of 6 image datasets and 3 text datasets, each with 2 distinct architectures defined at several model scales, and trained with different dataset sizes. This process produces 42-49 data points for each <dataset, architecture> pair, and the 6 coefficients of the proposed functional form are fit to those data points, with < 2% mean deviation in accuracy. It then studies how this functional form performs at extrapolation, and finds that it still performs pretty well, with ~4.5% mean deviation in accuracy, but with additional caveats.","This paper proposes a functional form to model the dependence of generalization error on a held-out test set on model and dataset size. The functional form is derived based on empirical observations of the generalizing error for various model and dataset sizes (sections O1, O2, and O3) and on certain necessary criteria (C1, C4 and C5). The parameters of the function are then fit using linear regression on observed data. The authors show that the regressed function \(\epsilon(m,n)\) is able to predict the generalization error for various \(m\) and \(n\) reasonably accurately.",0.1780821917808219,0.2736842105263158,0.2157676348547718
549,SP:32e3f996f6a94ddf61f9fb63b52664982bf41726,"The authors propose to model general copula models by training a neural network that samples from a latent space and maps samples to the high dimensional unit cube. Fitting the model is done by transforming the generated samples to have uniform margins by empirically computing the ranks. Then, the model is optimized by minimizing the MMD distance w.r.t true uniform data samples. ","The paper proposes an implicit method (IGC) of estimating a copula. The suggested approach is elegant and from the presented results the method seems to work on par with existing non-parametric vine copula approaches. Previous works have made an attempt to use GANs for implicit copula estimation with difficulties, however, in IGC the authors suggest techniques to address the requirements for uniform margins with a simple two-step procedure leveraging the probability integral transform. The general idea and contributions are clearly presented and I find this work valuable due to its simplicity and I believe its efficiency can be further exploited in other copula-related/inspired applications.",0.171875,0.10185185185185185,0.12790697674418602
550,SP:32fd701727ba6bb22ac8305b1f08a54a5c805ba1,"The authors introduce two new algorithms: remember and forget experience replay (ReF-ER), and an actor-critic architecture for continuous-action problems which is significantly more computationally efficient than previous approaches (RACER). ReF-ER manages the experience in the replay memory more directly and removes trajectories (episodes) that follow policies less related to the current parameterized policy (based on the importance weights). RACER's main contribution is provides a closed form approximation of the action values, enabling significant gains computationally. They provide several empirical studies in benchmark domains showing the competitiveness of their approach, and the provided more stability to various continuous control algorithms (NAF, PG, u-DDPG).",This paper presents a method for forgetting and re-weighting experiences from a buffer during updates. It is well quantified experimentally and has some interesting tricks to improve performance in DDPG and other methods in continuous control which make use of a replay buffer. The authors also present another method “RACER” which makes use of this. ,0.07407407407407407,0.14285714285714285,0.0975609756097561
551,SP:32ff67eb5376e6c8c52c5adc601c520abc9a648c,"This work researches the deep complex-valued neural networks. Specifically, it proposes a new signal extraction mechanism that operates in frequency domain and applies to address the speech separation issue. Also, a function is proposed to explicitly consider both the magnitude and phase information of a signal. Related work on learning representation in frequency domain and speech separation is well introduced. Theoretical analysis is conducted to show the motivation and connection to signal processing. The architecture of the deep neural networks is presented in details, with the elaboration of the complex mask generation. Experimental study is conducted on a benchmark dataset to compare the proposed complex networks with those using real-part values only to demonstrate the improvement. ","This paper proposes a new method for source separation, by using deep learning UNets, complex-valued representations and the Fourier domain. Concretely, their contribution is : i) a complex-valued convolutional version of the Feature-Wise Linear Modulation, able to optimise the parameters needed to create multiple separated candidates for each of signal sources that are then combined using signal averaging; ii) the design of a loss that takes into account magnitude and phase while being scale and time invariant. It was then tested and compared with real-valued versions, and also some state-of-the-art methods.",0.15254237288135594,0.18556701030927836,0.16744186046511628
552,SP:3309939aebe492fd9db0d074f186051808f3bcbf,"This paper presents a new contribution for a largely understudied problem of label shift (also called target shift), a situation occurring when the class proportions vary between the training and test sets. The proposed contribution builds upon a recent work on the subject by Lipton et al., 2018 and addresses several of its weaknesses. The paper also gives several improved generalisation bounds w.r.t. that of Lipton et al. that are further used as guidelines to tune the regularisation parameter based on the size of source and target samples. Finally, the empirical results show that the proposed algorithm outperforms that of Lipton et al. especially in cases where the shift in proportions becomes quite important. ","- The authors consider the problem of learning under label shifts, where the label proportions p(y) and q(y) of the training and test distributions differ, while the conditionals p(x|y) and q(x|y) are equal. They build upon the work by Lipton et al. 18 on estimating label proportion weights q(y)/p(y) using the confusion matrix, by proposing an improved estimator with regularization. They show that their estimator provides better weight estimates compared to the unregularized version, and it also gives better prediction accuracies under large label shift scenarios. ",0.19827586206896552,0.24468085106382978,0.21904761904761905
553,SP:330aaa20ccf120126f6f9e8256f321972bdf92b6,"The paper proposes the idea of training machine models that are effectively recourse ready. The authors propose leveraging adversarial training and PAC confidence sets to train models that ""theoretically guarantee recourse"". The experiments with four datasets demonstrate increased recourse rates while sacrificing accuracy mildly.  ",The author(s) proposed an adversarial training-based classification algorithm that guarantees affected individuals receive recourse with a high probability. The paper considers an interesting topic. The numerical experiments demonstrate the effectiveness of the proposed algorithm. ,0.18181818181818182,0.2222222222222222,0.19999999999999998
554,SP:3312a33df68b98ddffec4706f031fc2173181d05,"The goal of this paper is to analyze knowledge consistency between pretrained deep neural nets. In order to do so the paper trains neural networks to predict a hidden layer of one DNN using a hidden layer of another DNN. The model is interesting in that it is multi layer but it also allows decomposing its prediction as the sum of outputs of neural nets with different numbers of hidden layers. The prediction is dubbed ""consistent features"", which are further decomposed in consistent features of different complexity levels, while the error is dubbed ""inconsistent features"".","This paper presents a method to disentangle intermediate features between two different deep neural networks. More specifically, given two networks, the proposed approach aims to find consistent and inconsistent feature components for a certain layer in each network. If one network is more powerful to the other (e.g., ResNet and AlexNet), the method can figure out which components are weak or strong (i.e., helpful to the performance) for the given task. The authors design a simple yet effective algorithm for extracting knowledge consistency. In addition, they provide a variety of practical experiments including network diagnosis, feature refinement, and network compression. Most of the experimental results support that the proposed method can practically extract consistent feature components with promising improvements.",0.2,0.15702479338842976,0.17592592592592596
555,SP:33386a5a96124115a197a16ea1ca2f2ba326c34d,"This paper examines reinforcement learning in the context of blood glucose control to help individuals with type 1 diabetes. The authors show that their methods lead to strong algorithms that can improve artificial pancreas systems. Their results are promising, and, very importantly, do not require meal announcements. The importance of their application is self evident.","The paper describes an RL based approach to administer insulin for blood glucose control among  type-1 diabetic patients.  The paper formulates this blood glucose control problem as a closed-loop reinforcement learning problem and demonstrates its effectiveness on data generated from an FDA-approved simulator of glucoregulatory system. Compared to existing approaches, the proposed method can operate without meal announcement by potentially making use of latent meal intake patterns. The authors also demonstrate how a learned policy for one particular subject can be used as initialization to train/fine-tuned the policy of another subject so as to combat the issue of high sample complexity.",0.21818181818181817,0.11320754716981132,0.14906832298136646
556,SP:333b75014a3cde3eb10486b9b7db6eea42db3196,"This paper proposed a model that is capable of tracking dialogue states in a non-recursive fashion. The main techniques behind the non-recursive model is similar to that of the ICLR 2018 paper ""NON-AUTOREGRESSIVE NEURAL MACHINE TRANSLATION"". Unfortunately, as state tacking can be formulated as one special case of sequence decoding, there is not much of innovation that can be claimed in this paper considering the ""fertility"" idea was already been proposed. The paper did illustrate a strong experimental results on a recent dataset comparing with many state-of-the-art models. However, it is not clear how much innovation this work generates and how the ICLR community would benefit from the problem that the paper is addressing.  ","The authors build on recent work for non-autoregressive encoder-decoder models in the context of machine translation (most significantly [Gu, et al., ICLR18]) and adapt this to dialogue state tracking. Specifically, as in [Gu, et al, ICLR18], they use a fertility decoder modified for DST to be on a per-slot basis which is input to a second decoder to generate the (open-vocabulary) tokens representing dialogue state. An interesting aspect of the resulting model as formulated is that the latent space also takes into account interdependencies between generated slot values, which leads to a direct structured prediction-like loss of joint accuracy. Additionally, as slot values have a smaller (and likely peakier) combinatorial space, NAT models actually are more applicable to DST than MT. The resulting model achieves state-of-the-art empirical results on the MultiWOZ dataset while incurring decoding times that are an order of magnitude faster. ",0.175,0.1390728476821192,0.15498154981549814
557,SP:3350fe8ea74f715832130fe2c8a5309b721aa24b,"This paper analyses a pitfall of current meta-learning algorithms, where the task can be inferred from the meta-training data alone, leaving the task-training data unused. Such a meta-learner would generalise well on the meta-training tasks, but will fail to generalise on new tasks at test time. This kind of overfitting is formalised as the memorization problem. This problem is implicitly resolved in current meta-learning algorithms by constructing mutually-exclusive meta-training tasks, which is not easy to construct in all scenarios. The paper introduces an information-theoretic meta-regularizer which forces information extraction from the task data (D) by restricting information flow from meta-parameters (\theta) and input (x^*). Experimental evaluation with one gradient based and one contextual meta-learning method, on non-mutually-exclusive tasks bring out the mettle of the proposed regulariser. ","This paper illustrates, identifies, and formally defines a memorization problem in meta-learning -- the model can simply memorize meta-training tasks and ignore meta-training train sets. The paper proposes to optimize the mutual information between testing predictions and the training data (given input and meta model), and upper bound it by imposing a information bottleneck between output and input+model. Unlike related work, this paper specifically is able to generalize to meta-test even when the meta-train dataset is not made confusing enough (i.e. even when model can learn well from test data in meta-train alone), making it applicable to use cases where it is hard to make the dataset confusing.",0.17142857142857143,0.20869565217391303,0.18823529411764706
558,SP:3366c152e982f278ec96e8304e0e95d92f4f4fb6,"In this work, the authors explore different ways to pre-train contextualized word and sentence representations for use in other tasks. They propose two main methods: a straight-forward extension of the ElMO model for hierarchical uni-directional language models, and a de-noising auto-encoder type method which allows to train bi-directional representations. The learned contextual representations are evaluated on three downstream tasks, demonstrating the superiority of the bi-directional training setting, and beating strong baselines on extractive summarization.","This paper proposes to extend the pretraining used for word representations in QA (e.g., ELMO) in the following sense: Instead of just predicting next/previous words in a sentence/paragraph, performing a hierarchical prediction over the whole document, by having a local LSTM and a global LSTM as presented in Fig. 1 + the idea of masked language model. Authors show meaningful improvements in 3 tasks that require document level understanding: extractive summarization, document segmentation, and answer passage retrieval for doc level QA. ",0.16049382716049382,0.1566265060240964,0.15853658536585366
559,SP:33a9dffdcc2a5fc2a30a5a2e9b8cb65cd1010bed,"Authors proposed an enhanced Pointer-Generator model called SPNet. The key difference between SPNet and PG are the separate handling or using of speaker role, semantic slot and domain labels. Authors also proposed a new metrics called Critical Information Completeness (CIC) to address ROUGE's weakness in assessing if key information is missing in the output.","The authors propose a new abstractive dialog summarization dataset and task based on the MultiWOZ dataset. Unlike previous work which targets very short descriptions of dialog transcripts (e.g. 'industrial designer presentation'), this paper looks to generate long descriptions of the entire dialog using the prompts in the MultiWOZ task. The authors also extend the pointer generator network of See et al.  (2018) to use speaker, semantic slot and domain information.  They show that this new model (SPNet) outperforms the baseline on existing automatic metrics, on a new metric tuned to measure recall on slots (dubbed CIC), and a thorough human evaluation.",0.23214285714285715,0.12745098039215685,0.16455696202531644
560,SP:33b20ec288ca2cf2c26ad5e9a2a8c463f1f89b36,"This paper tackles the problem of learning an optimizer, like ""learning to learn by gradient descent by gradient descent"" and its follow-up papers. Specifically, the authors focus on obtaining cleaner gradients from the unrolled training procedure. To do this, they use a variational optimization formulation and two different gradient estimates: one based on the reparameterization trick and one based on evolutionary strategies. The paper then uses a method from the recent RL literature to combine these two gradient estimates to obtain a variance that is upper-bounded by the minimum of the two gradients' variances. ","	This paper proposes a method to learn a neural network to perform optimization. The idea is that the neural network will receive as an input several parameters, including the weights of the network to be trained, the gradient, and so on, and will output new updated weights. The neural network that is used to compute new weights can be trained through a complicated process called un-rolled optimization. The authors of the paper show two problems with this approach. Namely, the gradients tend to explode as the number of iterations increases. Truncating the gradient computation introduces some bias. To solve these problems the authors propose a variational objective that smooths the objective surface. The proposed method is evaluated on the image net dataset showing better results than first order methods optimally optimized.",0.23958333333333334,0.17424242424242425,0.20175438596491233
561,SP:33df51441aeb40f2072d9f09b8384083713591ce,"This paper presents a method of extracting document class labels from the Wikipedia category hierarchy; the set of sub-areas on StackOverflow; and the list of sub-reddits on Reddit. These pairs are then used to train a BERT-based binary classifier that predicts whether a category matches a document. Since categories are named with natural language, the model can be applied to new classification tasks that have natural language labels.","This paper presents a dataset and evaluation benchmark for weakly supervised text classification. The main resource, NatCat, contains a large number of diverse real-world documents and categories, making it appealing for general-purpose off-the-shelf text classification. The way of generating weakly supervised data is efficient, intuitive and easy to reproduce. The baseline models trained on this resource easily outperform previous weakly supervised approaches.",0.15492957746478872,0.16666666666666666,0.16058394160583941
562,SP:33f86309e63b0605e3d2b83e839971523e236f5f,"Rewardless Open-Ended Learning (ROEL) is fundamentally a combination between two Paired Open-Ended Trailblazer (POET) and Dynamics-Aware Unsupervised Discovery of Skills (DADS). POET presents a framework for ""open-ended learning"" which automatically generating progressively more difficult environments to elicit agents with novel behaviors. DADS introduces a method of ""unsupervised RL"" which learns a variety of skills without rewards solely based on mutual information between state transitions and skill-determining latent variable. The result is an RL framework which generates environments to elicit controllable behaviors without a reward function from the environment.  The following empirical evaluations are performed: - Qualitative assessment of skills learned by ROEL - Qualitative comparison or ROEL and DADS - Measurement of rewards of different skills learned by ROEL and DADS - Measurement of state predictability of skills in different environments by ROEL and DADS  The primary contributions of the paper are: - Combining open-ended RL and unsupervised RL - ROEL yields a more robust set of policies in a bipedal-walker environment than the DADS baseline. ","In this work, the authors a method that lies in the intersection of two subfields of RL, namely open-endedness and unsupervised skill discovery. Specifically, they introduce a method called Rewardless Open-Ended Learning (ROEL) which extends a recent method called POET to perform skill discovery in a reward-free setting rather than traditional supervised RL. To this end, they use mutual-information-based skill discovery techniques which have recently become a popular approach for unsupervised RL. The authors empirically demonstrate that ROELD is able to learn identifiable skills in bipedal walker environment.",0.1497005988023952,0.26881720430107525,0.19230769230769232
563,SP:343ef3ab797100bbd2d8bc91a6fe9d05a67a897a,"In this paper, the authors study the error introduced by the estimation of critic function in the Actor-Critic algorithm. Then the author proposed an algorithm that utilizes the idea of double Q learning and using a KL-divergence like regularization method to control this error. Experimentally the proposed algorithm achieves good results comparing to the vanilla Actor-Critic algorithm. This paper shows a successful routine from the theoretical analysis to a practical algorithm.",Authors investigated the effect of approximation error for actor-critic. They derived an upper bound of approximation showing that minimizing the KL divergence between the two consecutive policies can drive this upper bound down. Based on their finding they  introduced the Error Controlled Actor-critic (ECAC) algorithm. They ran ablation study showing the positive impact of minimizing the KL divergence. Furthermore they compared ECAC against 4 state-of-the-art techniques showing their advantage across 4 out of 5 Mujoco domains.,0.21621621621621623,0.19753086419753085,0.2064516129032258
564,SP:3447c4f7cb227a9eba660c6c43fcbddb3d866567,"This paper combines a widely used variance reduction technique SVRG with the greedy-GQ. It provides a finite-time analysis of the proposed algorithm  in the off-policy and Markovian sampling setting (convergence to the stationary point) and improves the sample complexity from the order $\epsilon^{-3}$ to $\epsilon^{-2}$ comparing with the vanilla greedy GQ. Interestingly, the analysis shows that the biase error caused by the Markovian sampling and the variance error of the stochastic gradient are reduced by the $M$, where M is the batch size of the batch gradient in SVRG. At last, it verifies the theoretical claim by two toy examples.","Greedy-GQ is an RL algorithm for a control problem that extends on GTD, which is a prediction algorithm. While Greedy-GQ asymptotically converges to a stationary point, it does so with high sample complexity. The authors reduce the variance of Greedy-GQ by incorporating SVRG variance reduction scheme to both the time-scale update of the algorithm. The main contribution of the paper is in showing that the variance reduced Greedy-GQ algorithm achieves a sample complexity that is an order of magnitude less than the vanilla Greedy-GQ. ",0.20952380952380953,0.24444444444444444,0.22564102564102564
565,SP:345e244321aa18121d73d55e9e572eb904f48e9e,"This paper asks whether it works to remove task-specific heads and treat classification and regression problems as span extraction, by formatting problems in such a way that a single span extraction model can be used.  This is a reasonable question to ask, and the authors performed a very large number of experiments attempting to answer this question.  The authors claim that using span extractive models instead of task-specific heads yields improved performance over separate heads.","This paper introduces a method for converting sentence pair classification tasks and sentence regression tasks into span into span extraction tasks, by listing all the possible classes (entailment, contradiction, neural) or the discretized scores (0.0, 0.25 ...) and concatenating them with the source text. With this formulation, one can train a BERT-based span-extraction model (SpEx-BERT) on classification, regression, and QA tasks without introducing any task-specific parameters. The purposed SpEx-BERT model achieves moderate improvement (0.3 points) over the BERT-large baseline on the GLUE test set when fine-tuned on intermediate STILTs tasks (Phang et al., 2018).",0.2077922077922078,0.1553398058252427,0.17777777777777778
566,SP:3463f80651938950dc6a75263016119e4877c5ee,"The paper proposes a simple way of addressing the issue of mode-collapse by adding a regularisation to force the outputs to be diverse. Specifically, a loss is added that maximises the l2 loss between the images generated, normalised by the distance between the corresponding latent codes. This method is also used to control the balance between visual quality and diversity.","The paper proposes a method for generating diverse outputs for various conditional GAN frameworks including image-to-image translation, image-inpainting, and video prediction. The idea is quite simple, simply adding a regularization term so that the output images are sensitive to the input variable that controls the variation of the images. (Note that the variable is not the conditional input to the network.) The paper also shows how the regularization term is related to the gradient penalty term. The most exciting feature about the work is that it can be applied to various conditional synthesis frameworks for various tasks. The paper includes several experiments with comparison to the state-of-the-art. The achieved performance is satisfactory. ",0.29508196721311475,0.15254237288135594,0.2011173184357542
567,SP:34824d19f70879da119b1ecd77d64b06ebca462d,"This paper presents a method for reducing the representation error generative convolutional neural networks by combining them with untrained deep decoder. The method is evaluated on compressive sensing and super-resolution, where a better performance than the isolated use of Deep Decoders and GAN priors. The main contribution of the paper is not the performance, but the simplicity of this approach.","This paper proposes to use a combination of a pretrained GAN and an untrained deep decoder as the image prior for image restoration problem. The combined model jointly infers the latent code for the trained GAN and the parameters in the untrained deep decoder. It also jointly infers the mixing coefficient alpha and beta during test time for each image, thus learning how much we should rely on GAN. The proposed hybrid model is helpful on compressed sensing experiments on the CelebA dataset; however, it is only marginally better than deep decoder on image super resolution and out-of-distribution compressed sensing.",0.2786885245901639,0.16666666666666666,0.20858895705521474
568,SP:348371af70bb81a998b7dcfc8de2d60ea9b506e5,"This work studies the problem of distributed training with large batches in a communication-bottlenecked setup, where regular versions of algorithms such as LAMB become a constraint. Authors propose a new algorithm, which compresses the gradient momentum before aggregation and then reconstructs the gradients to recover the scaling coefficients for LAMB. This idea allows authors to achieve faster convergence compared to naive compression for LAMB while maintaining higher communication efficiency than a non-compressed version.","The paper proposes a communication-efficient distributed LAMB optimizer with 1-bit compression. It follows previous work to first warm-up the variance, but proposes to inference the scaling factor based on reconstructed variance. Experiments show training speedup due to communication compression. The proposed 1-bit LAMB achieves similar model performance to full-precision LAMB.",0.14666666666666667,0.2,0.16923076923076924
569,SP:3489d6d9dde3bec6f8d50f309d28572c393eac61,"C1. Transformers (without positional encodings and without layer normalization), with 2 attention heads of dimension 1 and feed-forward layers (FFN) with 4 hidden nodes, are universal approximators of continuous permutation-equivariant functions f of compact support, relative to any Lp metric (1 <= p < \infty). (Thm. 2, p. 3). (Without positional encodings, a function f computed by a Transformer is permutation equivariant: f(P(X)) = P(f(X)) for any permutation P of the columns of X, which are the vector encodings of the input tokens.)","This paper tries to analyse the Transformer, widely applied building block of a neural network component, to improve understanding of the internals of the model. The analysis starts showing that the transformer blocks generate permutation equivalent maps and then shows that the transformer can approximate any permutation equivalent map in a compact domain with arbitrary precision. Three key steps are developed and used to prove the universal approximation of arbitrary permutation equivalent map: 1) quantization of input via feed-forward layers, 2) contextual mapping via attention layers, and 3) value mapping via feed-forward layers. By introducing positional embeddings, the paper relaxes the restriction on permutation equivalence and proves that the Transformer is a universal approximator of any sequence to sequence function.",0.16279069767441862,0.11475409836065574,0.1346153846153846
570,SP:3498af23a51d9522d5727025750c462e114f5566,"This paper proposes a new approach to regularize the feature embedding of neural networks. The proposed regularizer, maximizes the mean singular value of the feature matrix per batch, leading to a uniform spread of features. This enables learning with larger learning rates without the risk of model collapse. Authors derive lower and upper bounds for the proposed singular values loss, as well as popular ranking losses used in recent studies, eg. triplet loss and pairwise loss. These bounds help to tune the mixing parameter of network’s loss and the singular value loss.","This paper proposes a regularization technique called SVMax (singular value maximization) that can mitigate model collapse and enable large learning rates to reduce training computation costs. The singular value decomposition of network activation is used to regularize the embedding space with unit circle embedding assumptions. In addition, a mathematical analysis of the mean singular value boundary is provided to reduce hyperparameter tuning. The authors evaluate the proposed method for the retrieval tasks and generative adversarial networks.",0.21505376344086022,0.2631578947368421,0.2366863905325444
571,SP:34ae68bada17973bcb8f7aab9a70349b31dde1ad,"This work proposed a new goodness of fit measure for generative network evaluations, which is based on how well the network can generate the training data. The measure is zero if the network could perfectly recover the training data, and would represent how far it is from generating the training set in the average manner of the total least square sense, where the one-to-one mapping between the generated data and the training sample is constructed through latent space optimization. Using the proposed measure, the authors showed an interesting trend present in the DCGAN training and the impact of the residual connection. The authors might want to add some discussion in Section 4.2 regarding why the residual connection is detrimental for covering the support.  Increasing the model complexity through larger latent space dimension and learning mixtures is proposed as solutions to improve the measure as well.","This paper defines a goodness of fit measure F for generative networks, that reflects how well a model can generate the training data. F allows to detect mode collapse: as long as it is strictly positive, mode collapse is observed as parts of the training data have not been memorized. It aims at providing an alternative to the Fréchet Inception Distance and the Inception Score that rely on pretrained neural networks (whereas this new measure does not). It also provides insight into the DCGAN and WGAN networks in that regard, observing for instance that data subsampling helps decrease F, which motivates the use of a mixture of GANs.",0.20945945945945946,0.28440366972477066,0.24124513618677043
572,SP:34c39b5ae4a943556b4acb7ee4a899c8703f2f21,"The author propose a novel approach for online coreset selection, i.e exemplars used in the rehearsal process of past tasks in a continual learning framework. The proposed method is based on the observation that not all the samples in a dataset are equally valuable, but their quality affects model's effectiveness and efficiency. The method selects the most representative and informative samples at each iteration and trains them in an online manner. The approach has been conviently compared with state-of-the art methods and demonstrated its superiority.","This paper proposes an Online Coreset Selection method to select the most representative and informative coreset at each iteration and trains them. The proposed method maximizes the model’s adaptation to a target dataset while selecting high-affinity samples to past tasks, which directly inhibits catastrophic forgetting. Experiments on the benchmark datasets show competitive results compared with baselines.",0.20224719101123595,0.3103448275862069,0.24489795918367344
573,SP:34c5488e2ff0ef69e35e7000998cd1f105774c33,"The authors propose a stronger lottery ticket hypothesis in this paper – the multi-prize lottery ticket hypothesis. In particular, the new hypothesis seeks answer to the required amount of over-parameterization for a randomly initialized network to become able to compress to a sparse untrained binary subnetwork with on-par accuracy. The authors prove the existence of such subnetwork and show the bounds on over-parameterization. The paper proposes new methods to get the binary-weight tickets and the binary-activation tickets, where binary-weight tickets are subnetworks with weights as binary, and binary-activation tickets have the activation function in the forward propagation as binary. As binary networks can largely reduce the computational complexity for inference, this work has practical importance especially for applications with constraints for memory and power. The paper has many simulation results to support the theoretical guarantees, and the proposed approach on binary-weight networks has advantages over existing methods.","The paper proposes an innovate method based on lottery ticket hypothesis to prune a BNN (parameters are only -1(0) and +1, it can be viewed as an extreme case of quantization) from a dense NN. It focuses on learning a mask to prune the NN instead of the traditional method (pruning on an already trained network). In addition, not only experiments but theortical proof are given and have a highly brief result.",0.1032258064516129,0.2191780821917808,0.14035087719298248
574,SP:34e3fdc7b317dbac05df5db0fc75ce396e324c10,"This paper aims to train a GHN model that can predict weights of each layer. The architecture is represented in adjacent matrix format, where a node represents one layer and an edge indicates whether two nodes are connected in given architecture. Each type of layer is represented with a one-hot vector as their node attribute. The outputs are predicted weights of the corresponding layer. Finally, a task-specific object function is minimized by updating the GHN.","This paper proposes a method to tackle the problem of architecture-agnostic federated learning. The primary motivation of this paper is that in some cases of federated learning, different participants may need to use different neural architectures and may not want the exact architecture to be known. To this end, the authors propose a method based on graph hypernetworks. The main insight of this method is that neural architectures can be represented as graphs and their weights can be outputs of a larger GNN. Empirically, the proposed method compares favorably against state-of-the-arts. ",0.23376623376623376,0.18947368421052632,0.20930232558139536
575,SP:34f3abe09b1ca5c5bbbf1a2e28b489fee010098e,"This paper combines replay and openMax approach to help continual learning.  The results shows robustness on different dataset include image and audio in the continual learning condition, where the new come data has a different distribution but the model still able to maintain reasonable quality for the previously and newly come examples. To my understanding, this approach was not ground-breaking but seems a reasonable combinations.","This paper tackles the problem of catastrophic forgetting when data is organized in a large number of batches of data (tasks) that are sequentially made available. To avoid catastrophic forgetting, the authors learn a VAE that generates the training data (both inputs and labels) and retrain it using samples from the new task combined with samples generated from the VAE trained in the previous tasks (generative replay). In this way, there's no need to store all past data and even the first learned batch keeps being refreshed and should not be forgotten.",0.18181818181818182,0.12903225806451613,0.1509433962264151
576,SP:3504773d062b05d1f7c358dfdc0da2ad78f5bc5e,"This paper studies the sample elicitation problem where agents are asked to report samples. The goal is then to evaluate the quality of these reported samples by means of a scoring function S. Following previous related works, the authors use the equivalence between maximizing the expected proper score and minimizing some f-divergence. Their approach relies on the dual expression of the f-divergence which writes as a maximum over a set of functions t. Theoretical guarantees are given for f-scorings obtained (with or without ground truth samples) by first computing the empirical optimal function t, then plugged to estimate the f-divergence. Finally, a deep learning approach is proposed by considering functions f parameterized as sparse deep neural networks.","This paper proposes a sample elicitation framework to tackle the problem of eliciting credible samples from agents for complex distributions. The authors suggest that deep neural frameworks can be applied in this framework for sample elicitation through the derivations. The authors also show the connection between the problem of sample elicitation and f-GAN. However, some problems in the proof on sample elicitation should be clarified or carefully explained.",0.14049586776859505,0.2463768115942029,0.17894736842105263
577,SP:351283f0a33b5d1eb8d54d4fb74e93f0505b051c,"The authors argue that the world consists of largely independent causal mechanisms that sparsely interact. The authors propose a new kind of recurrent network (RIM) that presumably distills this world view into inductive biases. RIMs consist of largely independent recurrent modules that are sparsely activated and interact through soft attention. They tested RIMs on a number of supervised and reinforcement learning tasks, and showed that RIMs perform better than LSTMs and several other more recently proposed networks (e.g., Differential Neural Computers, Relational Memory Core, etc.) in these tasks. In particular, RIMs can generalize more naturally than other networks to out-of-distribution test set in presumably modular tasks.","This paper proposes a neural network architecture consisting of multiple independent recurrent modules that interact sparingly. These independent modules are not all used simultaneously, a subset of them is active at each time step. This subset of active modules is chosen through an attention mechanism. The idea behind this architecture is that it would allow the different modules to specialize in different mechanisms and that would allow compositionality. The empirical results suggest that the proposed approach is able to generalize better than traditional architectures (which all have the implicit assumption that all processes interact).",0.14678899082568808,0.1702127659574468,0.15763546798029557
578,SP:351c576700ecf5c84f15b3a4baef958e72d099eb,"This work investigates representational power of LSTM to model natural language, in particular how well it models temporal dependencies within text. They define a notion of timescale of each LSTM unit and analitycally show that LSTM memory exhibits exponential decay, while natural language tends (based on prior work) to decay following the power law. Based on this, they figure that LSTM memory may decay following the power law *if the timescales approximate samples from the particular Inverse Gamma Distribution*. To achieve that they propose the multi-timescale LSTM unit, where the desired timescale is explicitly controlled via the forget gate bias.","This paper points out the relationship between words in natural language usually follow the power law. Gated recurrent neural networks such as LSTMs excel in modelling natural language, however, the forgetting mechanism of LSTMs  is ruled by the exponential decay. This work demonstrates a way to engineer the forgetting mechanism of LSTMs to mimic the power law relationship that is more presented in natural language. By applying their technique, the modified LSTM model can do better in modelling rare tokens, which usually span for longer timescales, hence the model can score lower perplexities on less frequent words. The key contribution of the paper is the derivation which shows that the forget gates of LSTMs are subject to exponential decay in zero-input regime after the first input token is given. And the expected value of exponential decay functions exp(-t/T) can approximate the power law when T is sampled from the Inverse Gamma distribution. ",0.22772277227722773,0.14838709677419354,0.17968749999999997
579,SP:351f676d2fa2b3b216ed7b5ebbb3b058eef5cb1c,"The paper proposes a method called NeuroChains for extracting a sub-network from a deep neural network (DNN) that can accurately match the outputs of the full network for inputs in a small region of the input space. The goal is to be able to explain the important steps that a DNN takes to get from inputs in a small region of the input space, to its predictions for those inputs. NeuroChains initialises the sub-network as the original DNN except each weight/filter is multiplied with a real-valued score. The L1 norm of these scores is minimised while penalising any deviation of the output of the sub-network from the output of the original network. After the minimisation, weights/filters with a score below some threshold value are removed, leaving a sub-network. In the paper there are experiments that aim to verify three claims: (1) NeuroChains can find sub-networks containing less than 5% of the filters in a deep convolutional neural network while preserving its outputs in some small region of the input space; (2) every filter selected by NeuroChains is important for preserving the outputs and removing one of them leads to considerable drop in performance; (3) the sub-networks extracted for small regions of the input space can be generalized to unseen samples in nearby regions.",The submission considers the task of extracting a small sub-network of a pre-trained neural network that can explain a local region of the data space (a small number of the same classes). The resulting sub-network can be interpreted as the inference path moving from the input to the prediction and the filters and associated weights along this path can be visualised. The key of the proposed approach is to apply a multiplicative weight to each filter and layer in the network and enforce these weights to be sparse. The subnetwork is then selected by thresholding the weights. Some quantitative and qualitative analyses were provided.,0.17567567567567569,0.3644859813084112,0.2370820668693009
580,SP:3533f4976f70e2fdac0934dbb782d7b8af64c9fd,The authors proposed to use the joint KL divergence between the generative joint distribution and the target distribution (containing latent variables which could correspond to latent parts we wanted to model (e.g. beliefs). It was illustrative to discuss decomposing the joint KL into different ways and thus forming information bounds in different scenarios. The decomposition of past and future in Eq.6 also provided a unified perspective for looking at the most currently used objectives.,"The authors formulate a general framework that unifies inference, action/perception, control, and several other tasks. The framework is based on minimizing the KL divergence between a parameterized ""actual"" distribution and a ""target"" distribution. The authors argue that this formulation unifies a wide range of previously proposed objectives. They also argue that it has some advantages when compared to Friston's ""free energy principle"" framework, with which it shares many similarities, in particular that probability matching is preferred to surprise minimization.",0.17105263157894737,0.16049382716049382,0.16560509554140126
581,SP:35355126f30b88391404bdea921a944e9e9da117," The paper follows and extends the work by Belkin, Hsu, and Xu (2020) and  Liang and Rakhlin (2018) which studies the bias-variance trade-off of the regression/interpolation problem in the under/over-parametrization regions.  In particular, this paper follows the random Fourier model setting in Xie et al. (2020) and analyzed a generalized weighted least-square optimization method that allows the weighting in both the parametrization and data space. The authors derived the generalization error of such weighted least-square framework for the over parametrized and under parameterized regimes and compare them in these two cases.  The general conclusion is that emphasizing low-frequency features provide better generalization ability.  The paper also studies both noise-free and noise cases.  ","This paper studies the weighted least squares, random features model under noise one-dimensional data setting in under-/over-parameterized regime. The derived error bounds demonstrate the impact of noise on the generalization error. Besides, the extension to kernel regression shows that, the selected weighted matrix is helpful to generalization when the RKHS is small (i.e., singular values of \Psi decay fast).",0.14049586776859505,0.2698412698412698,0.18478260869565216
582,SP:35407fdffbf982a97312ef16673be781d593ff22,The paper presents an improvement to the task of transfer learning by being deliberate about which channels from the base model are most relevant to the new task at hand. It does this by apply attentive feature selection (AFS) to select channels or features that align well with the down stream task and attentive feature distillation (AFD) to pass on these features to the student network. In the process they do channel pruning there by decreasing the size of the network and enabling faster inference speeds. Their major argument is that plain transfer learning is redundant and wasteful and careful attention applied to selection of the features and channels to be transfered can lead to smaller faster models which in several cases presented in the paper provide superior performance.," This paper proposes a method called attentive feature distillation and selection (AFDS) to improve the performance of transfer learning for CNNs. The authors argue that the regularization should constrain the proximity of feature maps, instead of pre-trained model weights. Specifically, the authors proposes two modifications of loss functions: 1) Attentive feature distillation (AFD), which modifies the regularization term to learn different weights for each channel and 2) Attentive feature selection (AFS), which modifies the ConvBN layers by predicts unimportant channels and suppress them. ",0.15503875968992248,0.23809523809523808,0.18779342723004694
583,SP:355bbf6e924ae8f382db1e51c1cecf638ff25a57,"The paper proposes an approach for predicting whether a given set of inputs will induce a given branch to be taken in an RTL program, along with an algorithm for synthesizing inputs to the program that induce a given branch to be taken. The objective is to aid verification of proposed hardware designs by reducing the number of actual simulations required to find test cases that fully cover the control flow graph of the RTL program. The approach is to use a graph neural network, enhanced with some task-specific features, along with a gradient-descent algorithm for finding inputs that induce a given branch to be taken. The paper evaluates the approach, showing that it leads to relatively high branch-taken predictive accuracy on three hardware architectures, and showing that the approach requires fewer evaluations than Bayesian Optimization driven search to find inputs that induce a given branch.","This paper introduces Design2Vec, which models the semantics of RTL programs using a graph neural network. The representation is used for 2 tasks: coverage prediction and test generation. The experiments on different designs show that Design2Vec can achieve high accuracy on the coverage prediction task and can also generate tests that cover hard-to-cover points. ",0.11409395973154363,0.30357142857142855,0.16585365853658535
584,SP:355d95d502cd5d5de8ce41d9792253ee06454986,The paper studies the problem of generating synthetic patient data for the evaluation of causal inference models. The generated patient data is expected to highly mimic the distribution of the original dataset while also taking patient privacy into consideration. Experiments are conducted on the synthetic dataset with three well-established causal inference models.,"The authors propose a method for using real-world patient data to generate (semi-)synthetic privacy-preserving data on which to evaluate methods for causal effect estimation. For this purpose, they adapt the ADS-GAN (Anonymization through Data Synthesis using Generative Adversarial Networks) model introduced by Yoon et al. (2020) to produce a synthetic dataset that is identical in distribution to the original dataset, yet cannot be used to identify any of the original patients. To ensure the former desideratum, the authors calculate the Wasserstein distance between $P_{\hat{X}}$ and $P_X$; to ensure the latter, they use $\epsilon$-identifiabilty (Yoon et al., 2020). The authors show empirically that the synthetic dataset satisfies these desiderata, and then evaluate a few causal effect estimators on the synthetic data using the generated ground truth.",0.32075471698113206,0.12781954887218044,0.18279569892473116
585,SP:35b6bf3da512cae6ad93e1422b1e272474f9a8cb,"This paper studies an optimistic variant of AMSGrad algorithm, where an estimate of the future gradient is incorporated into the optimization problem. The main claim is that when we have good enough (distance from the ground truth is small) estimate of the unknown gradient, the proposed algorithm will enjoy lower regret. Theoretical results are provided and experiments are conducted to compare the proposed algorithm with baselines. The idea seems to be not very novel since the optimistic optimization techniques are borrowed directly from the online optimization field, while it is still interesting to see this kind of work and to see its comparison with existing algorithms in experiments. However, the comparison seems to be not fair both in theory and experiments.","This paper proposes an online optimization method called Optimistic-AMSGrad, which combines two existing methods: (i) AMSGrad (Reddi et al 2018) and (ii) optimistic online learning where the prediction step is done with the extrapolation algorithm by Scieur et al 2016. The authors do a good job of presenting the method (by introducing the background in proper order), the paper seems self-contained and cites the relevant literature. The regret analysis of the proposed algorithm is provided, where the obtained regret can be smaller than AMSGrad depending on whether or not the guess of the gradient and the gradient are close.",0.2066115702479339,0.24752475247524752,0.22522522522522526
586,SP:35fdcb687dd1aff475c0c3cee2b899579de19b46,"One-shot sequence alignment with CNN. Comparisons of sequence data are important for many tasks including action recognition and retrieval. Previous approaches include generating fixed-size feature vectors (e.g., RNN) or temporally aligning two sequences (e.g., DTW). Instead, the proposed method directly predict the alignment matrix T between two sequences X and Y with CNN. This is differentiable, and hence can be applied to many tasks such as supervised sequence classification/retrieval, and few-shot classification. Experiments uses a variety of sequence classification tasks, such as skeleton-based action recognition and spoken digit audio classification, and show a good performance of the proposed method.","This paper focuses on temporal sequence alignment, i.e. the task of finding an optimal alignment between sequences of different lengths. This task has been addressed by various traditional methods (e.g. DTW) that involve dynamic programming or other optimisations techniques that cannot be easily embedded in end-to-end learning frameworks.   This work proposes a method where the optimal temporal alignment is learnt by a CNN. The input is formed concatenating two matrices measuring element-wise distances between two sequences A and B. The network is trained to output a matrix whose (i, j)-th element indicates the likelihood of Ai being aligned to Bj.   The framework is evaluated with two tasks: supervised representation learning and few-shot action recognition. Tested on several datasets, the method is able to attain competitive performance and fast inference speed.",0.2358490566037736,0.18248175182481752,0.205761316872428
587,SP:367b672094c7533843751a3f82a5cc073b1c3243,"The paper considers imitation learning problem in the presence of small perturbations and nuisances at test-time. In particular, it proposes Imitation with Planning at Test-time (IMPLANT), a new algorithm for imitation learning that incorporates decision-time planning within an inverse reinforcement learning algorithm. To counteract the imperfection due to policy optimization in RL step, IMPLANT uses the reward function estimated in the IRL step for decision-time planning. The effectiveness of the proposed method has been empirically evaluated on two kinds of setups, i.e., the default ‘no-transfer’ setting and the ‘transfer’ setting where the test dynamics is a perturbated version of the training dynamics. ","The authors propose a method to enhance imitation learning by using MPC on the reward function learned by an imitation learning approach. The chosen MPC approach uses the learned policy to generate candidates for a search process that maximizes the reward. To learn the reward function, the authors propose to use GAIL. Besides showing improved performance in a typical benchmark scenario, the authors compare their method with GAIL in various scenarios where some form of transfer is required. The writing is generally clear and easy to understand.",0.17592592592592593,0.21839080459770116,0.1948717948717949
588,SP:367eefa594e6815c8a09c675fcf89f2fe29afd5d,"Authors extended the XLSR model from the previous mono-lingual task, where self-supervised learning was used in representation learning, to multi-lingual task. The basic idea does make a lot of sense, where all the data, irrespective of the language, is pushed through the representation learning task.  We are anyways talking about human speech, so it is reasonable to assume that learning one language can help in learning the other language. ","This paper proposes an unsupervised cross-lingual speech representation learning algorithm for multi-lingual automatic speech recognition. The main building block is based on an existing study (wav2vec series). The idea of this study is to apply previously (successful) unsupervised speech representation learning scheme to cross-lingual scenario to overcome the data sparsity problem of ASR for low-resource language. In this way, the experiments done in this paper are very meaningful and could shed light on future work on low-resource speech processing. The evaluations are intensive, and the results support most of the main claims well.",0.2222222222222222,0.16326530612244897,0.18823529411764706
589,SP:368767f64b05defbb5e0c479759df4d251597745,"Authors propose an approach to perform classification of ballroom dance movements (called figures) captured by the sensing mechanism of a smartwatch and discriminated via different ANN architectures. The sequence of figures are modelled as a Marlov chain, which work in  a generative+discriminative fashion to output the final prediction of the model. Authors also present a dataset collected specifically for this work, to perform the inference of the algorithms included in the evaluation. Results show a remarkable accuracy, but are not compared to any existing state of art due to limited related work.","The paper presents some classification results for ballroom dancing movements, as measured by inertial sensors on a smartwatch.  The motivation is mixed - as a guide to dancers themselves and as an automatic grading mechanism for competition judges. However the sensors used can only measure a very limited aspect of the dance, and there is no 'gold standard' data describing the full motion of the dancers that can then be compared with the limited data actually measured, to be able to contrast variations in the full body motion with variations in the intertial sensors on the smartwatch.  Describing the project as a study of whole body movement seems a bit brave given that you measure only hand movements. The restriction to the yaw axis will make results very sensitive to how the hand is held.",0.22580645161290322,0.15671641791044777,0.18502202643171806
590,SP:36bf1ac338d0c4184cad1369aabbe0662734a9aa,"The paper argues that AUL is a better metric than AUC under the PU (positive and unlabeled data) learning setup in the sense that it leads to an unbiased estimator in this setting, which is not the case for the commonly used and known metric - AUC. It is also argued that it leads to better performance than those methods which directly optimize an AUC based metric and computationally efficient to evaluate than methods which attempt to estimate the unknown parameters (\alpha, \beta in the paper). The appropriateness of this setting in the PU learning setting is demonstrated on the UCI datasets.","In this paper, the author proposed to use Area Under Lift chart (AUL) as a new optimization metric for positive unlabeled (PU) learning. The proposed AUL can be estimated unbiasedly from PU data, without the need to estimate the mixture proportions. Experiments on several datasets show that the proposed method outperforms AUC optimization algorithms.",0.13861386138613863,0.25925925925925924,0.1806451612903226
591,SP:36c2148fd83ee8a637d4925b60374cd02af09468,"The authors have updated the paper and clarified some things, and now my impression of the paper has improved. It still feels a little incremental to me, but the potential application areas of these sorts of models are quite large and therefore incremental improvements are not insignificant. This paper suggests some natural follow-up work in exploring Hellinger distance and other variations for these models.","In this paper the authors distinguish between two families of training objectives for seq2seq models, namely, divergence minimization objectives and max-margin objectives. They primarily focus on the divergence minimization family, and show that the MRT and RAML objectives can be related to minimizing the KL divergence between the model's distribution over outputs and the ""exponentiated payoff distribution,"" with the two objectives differing in terms of the direction of the KL. In addition, the authors propose an objective using the Hellinger distance rather than the KL divergence, and they conduct experiments on machine translation and summarization comparing all the considered objectives.",0.2,0.12745098039215685,0.15568862275449102
592,SP:36ec768c7b2c29b3ee400d43e4a7fa0dc35ca6cf,"The paper derives the p-Laplacian message passing formula under the p-Laplacian based regularization framework and further proposes p-GNN architecture. Authors further justify the relations of p-Laplacian message passing with low and high-pass filters and the upper bound of one layer risk of p-GNNs. Experiments show the superiority of p-GNNs on both heterophilic and homophilic settings. However, we still have some concerns for the paper before further evaluation.","This paper proposes a p-Laplacian based GNN to handle heterophilic graphs and graphs with non-informative topologies. Both the above cases are assumed in most existing GNN architectures and hence this work breaks away from the norm. This work proposes a discrete p-Laplacian message passing scheme which is derived from a discrete regularization framework. The authors do a spectral analysis of their novel p-Laplacian message passing scheme and show that it works as both a low-pass and high-pass filter, which is then applicable to both homophilic and heterophilic graphs. More specifically, they show that p-GNN with p>2, works well for graphs which exhibit strong homophily, while for p \in [1,2) p-GNN works effectively on heterophilic graphs. The empirical results support the theoretical justifications and outperform the baselines quite significantly especially on heterophilic and non-informative topology bearing graphs.",0.33783783783783783,0.17006802721088435,0.22624434389140274
593,SP:36f276695fe54a7290e68a69eac687c0557bf454,"This paper organized a multi-task NAS benchmark including 4 widely used datasets and more than 20,000 models. It also proposed a searching architecture named Network Coding Propagation (NCP) to effectively find the optical model for specific tasks. Experimental results indicate that the proposed model can be applied to inter-task, cross-task, and intra-tasks problems and the authors also showed the generalization capability to other benchmarks. ","This paper tackles neural architecture search (NAS), addressing the problem of finding architectures suitable for a multitude of vision-related tasks, ranging from object detection to semantic segmentation. To the best of my knowledge, this is the first attempt in NAS for computer vision models that explicitly design the search space that allows for a search of architectures that are broadly applicable to a variety of tasks that usually rely on the different granularity of feature representation.  This paper makes two important steps towards the automated search of such general, multi-purpose architectures: (1) to study this problem, the paper formalizes a multi-task NAS benchmark, covering recognition, detection, semantic segmentation, and activity recognition (video) datasets. This allows for assessing the generality of the sought architecture across vision tasks. (2) to tackle the architecture search in such a setting, this paper propose makes the following contributions. First, it augments the search space with multiple stages that extract feature maps at several resolutions, followed by a feature fusion step (the number of blocks and feat. map resolutions are governed by the network hyperparameters.). This seems to be one of the key features that help to find architectures suitable for tasks that differ as much as image classification and semantic segmentation.  Next, for assessing the performance in this large search space, this paper builds on predictor-based methods, where the idea is to train a network that predicts the performance (i.e., the learned predictor) of the sought-network based on the (encoded) hyperparameters, governing the network architecture. Similarly, the proposed neural coding propagation (NCP) directly encodes the hyperparameters in the network coding space — those can thus be directly updated via back-propagation of the learned predictor. A predictor is learned for each task independently, and this way, gradients can be accumulated separately across different tasks before jointly updating the “architecture codes”. ",0.34782608695652173,0.07741935483870968,0.1266490765171504
594,SP:3759750e13689e4641744d077e21647795b03765,"This paper proposes a technique for performing data imputation using pre-trained normalizing flows. They do so by fitting a variational distribution over a subset of the 'base' variables of the normalizing flow. Along with the observations, a sample from this variational distribution is sufficient to fully specify a sample from the normalizing flow model. The authors present techniques for constructing samples in this way, and computing the derivatives required to optimise the variational distribution.","This paper presents a variant of flow, VISCOS flow, utilizing the Schur complement. This flow model is applied to the in-painting task, which estimates the unobserved feature variables given the observed features. Given this in-painting task, the inference requires the modeling on the latent variable, which results in the ELBO derivation on such latent variables as variational variables.",0.2,0.25,0.22222222222222224
595,SP:3761ec50c1dd06a108e7dc1a6b56b205b61d00c0,"The paper proposes a framework for semi-supervised settings to leverage both unlabeled data and (limited) labeled data where VAEs are trained subject to regularization terms from label information. More specifically, the proposed method trains a VAE and a NN classifier simultaneously by optimizing an objective that consists of the usual (unsupervised) variational lower bound, classification error for the labeled data based on the latent space, and consistency term for all data encouraging the same prediction for latent representations corresponding to the original and reconstructed version of a data point. The proposed method is compared with a few other deep generative semi-supervised learning methods on three image datasets.","This paper proposes a new VAE framework for semi-supervised problems, which uses the latent representation \\(z\\) to reconstruct input image \\(x\\) and to serve as the features for the classification of the label of \\(x\\). Based on this framework, the paper also proposes additional ""cycle"" losses, where the label prediction based on \\(\overline{z}\\) of \\(\overline{x}\\) is close to the true label (for data with supervisions) or the label of \\(x\\) (for data without supervisions). In addition, the paper also introduces another loss term of ""aggregate label consistency"" and applies other techniques including noise likelihood and STN. The proposed approach outperforms M1 and M2 of Kingma et al. 2014 on the synthetic dataset and shows more stability than M1 and M2. It seems that the performance advantage of the proposed method over others is not very significant on real datasets.",0.27522935779816515,0.2112676056338028,0.23904382470119523
596,SP:37732a5c56b1f8ce138ef14d366adc684ef7376c,"This paper proposed a method for self-supervised graph-level representation learning. The main idea is to enforce both the instance level smoothness embedding constraints, and a so-called global, semantic grouping structures across all instance graphs in the training data set.  To achieve this goal, the authors have adopted a global clustering framework to encourage the embedding of the graphs belonging to the same clusters to be close to each other, and by using a hierarchically organized set of prototypes. The proposed method is applied to pre-train GNN on massive unlabeled graphs, which is then fine-tuned to downstream learning tasks.","This paper proposes an unsupervised framework to perform graph representation learning. The local-instance structure is learned by first gets patch-level and graph-level representations for each graph, then maximize the mutual information between both correlated patches and correlated graphs, which are decided by attribute masking strategy. The global-semantic structure is maintained by leveraging RPCL to derive hierarchical prototypes of the representation and maximizing the mutual information between correlated graph representation and the searching path in the prototypes.",0.17475728155339806,0.225,0.19672131147540986
597,SP:37921395ed7b214f2921391b2fde1f2ba209719f,"The paper ""Do Transformers Understand Polynomial Simplification?"" introduces a new reasoning task (convert polynomials into a normal form) and studies the performance and errors of Transformers on this task. The task itself is quite simple: given a randomly generated term involving small constants, variables, additions, and multiplications, bring the term into a well-defined normal form. Each task has to be solved in a unique sequence of steps. The authors study the performance of Transformers to either simplify the expressions step by step or to predict the simplified version directly.","The authors analyze the performance of Transformer models on simplifying polynomials and - importantly - generating proofs at the same time. This is a very nice idea that allows to study the performance of Transformers in depth and at the same time in an important setting where verification is performed as part of running the model. And the authors show a strong baseline, with models performing very well in a number of settings. A few areas seem to have been neglected though. For one, the authors only train a 4-layer 4-head model, which is quite small as far as Transformers go. Maybe it's irrelevant for this problem - but having at least one bigger model as a point of comparison would be good. Next, the out-of-distribution question warrants more experiments. Can the Transformers simplify polynomials with way more factors than trained on? With a higher number of variables? Higher degrees? The authors also show that one main problem for Transformers is learning to multiply the coefficients. But - assuming this reviewer understood correctly - the authors do not apply the proof requirement to multiplication. E.g., for ""12*3"" the model has to immediately output ""36"" rather than ""10*3 + 2*3 = 30 + 6 = 36"". Maybe this could help the Transformer learn and be more resilient to coefficient size? So while the current version of the paper is ok, there are a few areas for improvement which prevent it from being a clear accept.",0.28888888888888886,0.10655737704918032,0.155688622754491
598,SP:3798e47ac56ab60bb2a913429c72ed2dff66531a,"Prior works generally thought non-robust features, which are vulnerable to small perturbations, are not semantically meaningful but are useful for generalization. This work challenges these traditional beliefs by pointing out that non-robust features can also be human-perception aligned and be less useful for generalization, if these non-robust features are discovered via universal adversarial perturbations (rather than via image-dependent perturbations). Extensive experiments are provided to justified these arguments.","This paper studies the link between non-robust features and universal adversarial perturbations. This paper shows that universal perturbation leverage non-robust features in data in a different way than standard adversarial attacks. Experiments are based on a universal version of projected gradient descent (PGD). The findings are that universal perturbations are more aligned with visual semantics and human perception that general adversarial attacks. Moreover, it is shown to be difficult to obtain generalisation or transferability between models based on universal signals, as opposed to standard adversarial samples. Generalization seems to decrease with the size of the set used for generating a given universal perturbation, while semantics of the features improve.",0.20833333333333334,0.13513513513513514,0.1639344262295082
599,SP:37aab9484f502a34029583b62eeb6657326bd0c3,"The authors introduce an approach for learning identity preserving transformations from data. First the low-dimensional manifold structure of the data is learned using an autoencoding neural network, then the transformations (the Lie group operators and their coefficients of combination) that map between perceptually similar image pairs are learned. The main contribution of the paper is that the learned operators can transform the data semantically. This is a challenging since 1) semantic transformation labels are not usually available; and 2) not all semantic transformations make sense for all elements of the dataset. The authors address these challenges using two auxiliary networks. The first identifies perceptually similar image pairs in the dataset and the second identifies where particular transformations are likely to be used.","This paper proposes to learn natural transformations in datasets, with manifold auto encoder (MAE), where the underlying identity-preserving transformations are not easily identifiable. By using Lie group operator, this problem reduces to learning paths/motion in the latent space of MAE. The main challenge in training MAE is how to choose a transformation pair, a point and its identity preserving transformed counterpart, in an unsupervised way. This paper introduces the idea of using penultimate layer  of a pretrained classifier on Imagenet to choose such point pairs and learn such MAE more effectively. The proposed method is validated on three datasets. ",0.15447154471544716,0.18811881188118812,0.16964285714285715
600,SP:37afbad2d7a35ae747b29b2bef8e0b87dc82bfa6,This paper adapts Segment Sorting to panoptic segmentation and proposes a Panoptic Segment Sorting (PSS). The proposed method learns to sort segments according to both of its semantic and instance labels. The semantic label is acquired by simply mapping and classifying prototype feature and instances are formed by a clustering algorithm. A seeding branch is further used to guide merging and avoid false positives.,"The paper presents a pixel-wise embedding strategy for panoptic segmentation, which aims to learn a pixel representation that encodes both semantic and instance information. To this end, the proposed method builds on top of the Segment Sorting approach and extends its contrastive loss to the instance level by utilizing panoptic supervision. To predict instance segmentation,  the paper also designs a merging process to cluster the pixels into instances, which further employs an object center prediction module for localization and a dynamic partition strategy to cope with scale variation.  This method is evaluated on two panotpic segmentation benchmarks, including Cityscapes and PASCAL VOC 2012. ",0.234375,0.14423076923076922,0.17857142857142858
601,SP:37bd7b6bf0f90eb24e82b831b5fd8c57c3b09142,"- This paper introduces a package for computing the second-order information of neural networks based on the Lanczos algorithm. The authors showcase the usages of the package with 1) visualizing the eigenspectrum of the curvature matrix; 2)visualizing the loss surface along with a specific direction, and 3) comparisons between different optimizers. Also, the authors claimed that they address several misconceptions about the Lanczos algorithm.","This paper proposes a software package to ease and provide a standard way for Hessian-related computation, both for loss analysis and second order optimization. It also provides analysis on why Lanczos algorithm is a better choice to estimate Hessian eigenvalue compared to Power Iterations. Finally, it empirically shows the advantage of using Hessian approximation that goes beyond diagonal approximation for spectrum computation.",0.2,0.20634920634920634,0.203125
602,SP:37c8908c43beda4efc9db25216225f0106fe009c,"The authors describe a method for adversarially modifying a given (test) example that 1) still retains the correct label on the example, but 2) causes a model to make an incorrect prediction on it. The novelty of their proposed method is that their adversarial modifications are along a provided semantic axis (e.g., changing the color of someone's skin in a face recognition task) instead of the standard $L_p$ perturbations that the existing literature has focused on (e.g., making a very small change to each individual pixel). The adversarial examples that the authors construct, experimentally, are impressive and striking. I'd especially like to acknowledge the work that the authors put in to construct an anonymous link where they showcase results from their experiments. Thank you!","This paper proposes to generate ""unrestricted adversarial examples"" via attribute-conditional image editing. Their method, SemanticAdv, leverages disentangled semantic factors and interpolates feature-map with higher freedom than attribute-space. Their adversarial optimization objectives combine both attack effectiveness and interpolation smoothness. They conduct extensive experiments for several tasks compared with CW-attack, showing broad applicability of the proposed method.",0.06201550387596899,0.13559322033898305,0.0851063829787234
603,SP:37d6119d0ce9490b2e1a203af15c5690b1b449e2,"Stored Embeddings for Efficient Reinforcement learning (SEER) is a method to reduce the computational cost of value-based off-policy reinforcement learning, e.g. Q-learning, in settings with pixel-based observations. It uses a convolutional encoder whose lower layers are frozen early in agent training, as there has been previous work showing that a convolutional network's lower layers converge earlier on in training. Following an early period of joint training with the convolutional encoder, the agent afterwards stores only the encoded image features into its replay buffer instead of the raw pixels of the image. This enables potentially significant memory and compute savings as the image no longer needs to be re-encoded during off-policy learning. The paper presents empirical results demonstrating that final agent performance is not hindered by this procedure and that, when counting in terms of total FLOPs calculated or replay buffer size, SEER has an advantage over the naive image-based replay buffers most commonly used. A variety of experimental settings are considered, differing across domains (DMControl, Atari) and training procedure (Rainbow, SAC, CURL). ","- This paper presents a method for compute- and memory-efficient reinforcement learning where the visual encoder is frozen partway into training.  After freezing, latent vectors are stored in the replay buffer instead of images (and any existing images are replaced by them).  This leads to both better compute and memory utilization. - The authors demonstrate their method by comparing to Rainbow on Atari and CURL on DM Control.  On DM control, their method reduces the compute by a considerable margin.  On Atari, the results are less clear cut, but the compute cost is reduced. - When they also impose a memory constraint, the effectiveness of their method is further increased. ",0.13259668508287292,0.2222222222222222,0.16608996539792387
604,SP:37e258666bfb1bbd89749be3543e3511bf3a81f7,"This paper studies data augmentation in the regime where labels for the augmented datapoints are known. Special emphasis is put on the study of overparametrised linear models with minimum Euclidean norm of the regression weights (a.k.a. ridgeless regression). The results of this study are then used to motivate their “X-regularization” method, a semi-supervised learning algorithm which they test on the task of improving accuracy of adversarially trained models. The authors report improvement in accuracy of adversarially trained classifiers on CIFAR-10 when X-regularization is applied.","This paper provides some theory into the question of whether data augmentation can hurt test-set performance. To paraphrase the theory, data augmentation can hurt when it causes the model to learn a spurious local details instead of global structure, even if the augmented data comes from the same (predictive) distribution, and even if the true model lies in the hypothesis class of the learned model. Ironically these effects may be diminished in the large-sample regime, where data augmentation is less important in practice. Motivated by these issues, the authors propose ""X-regularization"" which requires that models trained on standard and augmented data produce similar predictions on unlabeled data. The paper includes a few experiments on a toy staircase regression problem as well as some ResNet experiments on CIFAR-10.",0.2111111111111111,0.1450381679389313,0.17194570135746606
605,SP:38070da400d31759e1d0d9e30eefb5b7f9f4d640,"Review:  This paper refines the the truncation error analysis for discretizing the ODE to obtain accelerated optimization method.  The truncation results include higher order term. Built upon the analysis, the authors propose a new method which is claimed to be more stable for large step size and converges faster. Numerical evidence on matrix completion problem is provided.","This paper proposes an accelerated method that has a high-order truncation error $O(h^4)$ to the ordinary differential equation $\ddot{x} + \frac{3}{t}\dot{x} + f(x) = 0$ obtained from Nesterov's accelerated method by (Su et al., 2014), while Nesterov's method has $O(h^3)$ error. This implies that the iterates of the proposed method converge to the trajectory of the differential equation faster than those of Nesterov's method. The two toy numerical experiments illustrate such phenomenon for certain large step size. A matrix completion problem experiment is further included.",0.3333333333333333,0.19791666666666666,0.24836601307189538
606,SP:38428b1c328c445cf652bcd8f2f15c9d3aaf20e8,"This work proposes to apply behavioral testing in the evaluation of KGE models for link prediction. The authors first pointed out the drawbacks in the current evaluation method which typically averaging the accuracy metrics on all the triples in the test set. Then they suggested to apply the behavioral test evaluates the system's performance on different capabilities of the system. As two examples, the authors conducted such evaluation for symmetric relations and type hierarchies and further exposed discrepancy in the original evaluation.","This paper proposes a method for performing behavior testing for KG evaluation. Automated metrics are known to misrepresent the actual performance of the systems (see [1] for a critique of automated metrics for text generation). Additionally, automated metrics might only capture a subset of desired properties that a system is expected to have. Thus, any effort that aims to rethink evaluation strategies should be welcome by the community. ",0.1686746987951807,0.20588235294117646,0.18543046357615894
607,SP:385a392e6d055abd65a737f3c5be58105778ac11,"Stability is one of the important aspects of machine learning.  This paper views Jacobian regularization as a scheme to improve the stability, and studies the behavior of Jacobian regularization under random input perturbations, adversarial input perturbations, train/test distribution shift, and simply as a regularization tool for the classical setting without any distribution shifts nor perturbations.  There are already several related works that propose to use Jacobian regularization, but previous works didn’t have an efficient algorithm and also did not have theoretical convergence guarantee.  This paper offers a solution that efficiently approximate the Frobenius norm of the Jacobian and also show the optimal convergence rate for the proposed method.  Various experiments show that the behavior of Jacobian regularization and show that it is robust.","The main contribution of this paper is that it proposed an estimator of Jacobian regularization term for neural networks to reduce the computational cost reduced by orders of magnitude, and the estimator is mathematically proved unbiased. In details, the time consumed for the application of Jacobian regularizer and the unbiasedness of the proposed estimator are proved mathematically. Then the author experimentally demonstrated that the proposed regularization term retains all the practical benefits of the exact method but with a low computation cost. Quantitative experiments are provided to illustrate that the proposed Jacobian regularizer does not adversely affect the model, can be used simultaneously with other regularizers and effectively improve the model's robustness against random and adversarial input perturbations.",0.208,0.2184873949579832,0.21311475409836067
608,SP:385bf55e0a9bdb8a3f3db800f63acffcb4207927,"The paper studies adversarial robustness in the context of federated learning. The authors provide an algorithm for adversarial training that generates adversarial examples on a trusted public dataset and iteratively sends them to the clients, so that they can perform learning on the adversarial examples as well. Notably, the adversarial examples are created by inspecting both the bias and the variance of the current set of models. The method is tested empirically on a wide range of datasets and compared to adversarial training using the local clients' data.","The authors propose a robust federated learning algorithm, where they assume that all samples are iid, and $n_s$ clean samples are available at the server side. The authors then go on to optimize a loss function that optimizes the aggregate loss and propose some new algorithms with experimental results. While overall the paper is interesting, there are several shortcomings in the execution as discussed below that the authors can address to improve the paper.",0.17045454545454544,0.2,0.1840490797546012
609,SP:3879a6f9b904429fa766fe496ca16cefecdc5d02,"In this manuscript, a new pruning method is proposed by considering the inherent quadratic constraint between consecutive layers. Without this constraint, inactive weights cannot be safely removed. Even with the same objective function, the optimized result is different, as shown in the motivation section. Based on this observation, the pruning task is models as a QCQP optimization problem. And a faster algorithm to solve this problem is proposed. Moreover, the pruning on filter size can also be modeled as the QCQP problem, making the pruning on both channel and filter size feasible.","This paper introduces an optimization method for pruning channels in networks. The authors first motivated the proposed approach by showing that current pruning methods will result in ""inactive weights"" for the following layer.  Then the authors introduce a QCQP optimization method that can constrain the exact amout of resources during the optimization process. Extensive experiments are conducted on different benchmarks with different backbones. And the authors also performed spatial pruning to further reduce resource usage.",0.17391304347826086,0.21333333333333335,0.19161676646706585
610,SP:387bec1eff17597a83cf7174a59e8082cd1b32ba,"The authors review the information bottleneck (IB) in the context of deep learning. They discuss the obstacles to applying the IB (and a deterministic variant, the DIB) to modern datasets, review approaches to doing so, and introduce their own scalable approach. Their approach introduces practical surrogate objectives for the information regularizer term, and uses dropout as the source of stochasticity. They take advantage of the scalability of their method to train a ResNet with (D)IB on MNIST, CIFAR-10, and ImageNette and study adversarial robustness and evolution in the information plane.","This paper provides several surrogates for the Information Bottleneck (IB) and Deterministic Information Bottleneck (DIB) loss functions that are more friendly to optimization. For the decoder uncertainty part, the authors show that using Dropout and cross-entropy loss provides an unbiased estimator for the decoder cross-entropy which upperbounds the decoder uncertainty. For the regularization terms in IB/DIB, the authors inject noises to the latent features to lower-bound the conditional entropy of latent representations, and further proposes three types of surrogate objectives for the regularziation terms. Emprical results on CIFAR/ImageNette (a subset of ImageNet of 10 classes) show that the proposed surrogates yield similar behaviours in terms of adversarial robustness and information plane and the scalability of the proposed method.",0.2717391304347826,0.2032520325203252,0.23255813953488372
611,SP:3887435d443946bde2ef1f6939bffab745ab69b4,The paper proposes an OOD setting emphasizing on texture and semantics. The authors propose an OOD detection method which disentangles texture and semantics. The method achieves SoA performances.,"The submission proposes to evaluate OOD detection problems with regards to two aspects — detect distributional shift in texture, or that in object-identity. A Fourier transform is used to identify changes in texture, and a modification of SVDD is used to identify changes in object identity, by building density models on top of a PCA-reduction of the extracted features in both cases. Experiments are conducted which showcase that the two components can detect textural vs. object-identity shift while not mis-identifying one type of shift for the other.",0.2857142857142857,0.08888888888888889,0.13559322033898305
612,SP:3896a952ee9efdcd646cf5fb9ab1888f888b8086,"This paper address online false discovery rate (FDR $\simeq 1-\mathrm{Precision}$) control in anomaly detection, where we obtain observations sequentially and immediately decide whether we classify them into anomaly or not. The authors adopted smoothed FDR (sFDR) for criteria and then derived rejection thresholds that offer high detection power (Recall) for anomalies without shrinking its detection threshold to zero while maintaining target sFDR. It is made possible by the fact that FDR for no rejection is defined by the explicit parameter $\eta$ in the sFDR. They also proposed a way to handle local dependency in time-series with a similar procedure. Experimental results on synthetic datasets demonstrate that the proposed method performs better than existing methods, especially when an anomaly is very rare.","This paper discusses techniques by which some limitations of current online false discovery rate control algorithms can be overcome. Importantly, the sequential decision thresholds from current algorithms decay to zero in the absence of recent rejections of the null hypothesis -- a situation called alpha-death. A technique to overcome this is proposed.  ================ Update: The scope of contribution has been clarified in the rebuttal. The authors address the lack of real-world experiments somewhat, but more is desired to improve the strength of the paper.",0.14516129032258066,0.21428571428571427,0.17307692307692307
613,SP:38a415fd3aa50464470b6deeab96c007364afd17,"The paper introduces a new sparse training algorithm (SR-STE) based on the straight through estimator which is specially designed for the hardware constraints of Nvidia A100 GPU. Auxiliary, in order to study better this algorithm, the paper introduces also a metric (SAD) to measure the changes in the sparse network topology during training. The contributions have real added value as they show that sparse neural networks can actually benefit of hardware designed to consider sparsity. The experiments on CNNs and Transformers support the claims.","The authors proposed a new method for training N:M fine-grained structured sparse networks from scratch. The authors found that the SAD metric, which measures the number of weights whose pruning state is changed, became higher if the existing STE is used to train sparse networks and this metric had the positive relationship with accuracy drop. To reduce the SAD, SR-STE which gives higher weight decay coefficient to the pruned weights is applied to train sparse networks, improving the accuracy of sparse networks trained from scratch.",0.21176470588235294,0.20454545454545456,0.20809248554913296
614,SP:38d522d92ad048087149a9d612a694c8ab95f3af,"The authors present a working memory model composed of a recurrent neural network trained via gradient descent and an associative memory based on the approach taken by Ba et al. (2016) in ""Using Fast Weights to Attend to the Recent Past"".  The model consists of an LSTM to which takes the input and its own state from the previous step to produce an output (or new state) which is then passed to a fast weight memory (FWM) module.","The solution proposed is the combination of an RNN (LSTM) and Fast Weighted Memory (FWM). The LSTM produces a query to the memory used to retrieve information from the memory and be presented at the model output. It also controls the memory through fast weights that are updated through a Hebbian mechanism. The FWM is based on Tensor Product Representations (TPR). The FWM is differentiable and builds upon the work of TPR-RNN from Schlag and Schmidhuber and Metalearned Neural Memory (MNM) by Munkhdalai et al. In the experimental section, the authors propose a concatenated version of the bAbI dataset to test their model with language modeling and question answering. Further the model is trained on a meta-learning task over POMDPs on graphs, and on language modeling on the PennTree Bank dataset. They show that the LSTM-FWM model generalizes better than without memory and similar models and with smaller capacity.",0.2692307692307692,0.13815789473684212,0.18260869565217394
615,SP:38f7fc675b764f1d88f08c6eaaa0daa4b2351d37,"This paper is studying the vulnerabilities of modern BERT-based classifiers, which a service provider is hosting using a black-box inference API. Consistent with prior work [2], the authors succeed in extracting high performing copies of the APIs, by training models using the outputs of the API to queries (akin to distillation). The authors then study two attacks on the copy model --- private attribute identification of sentences in the API's training data & adversarial example transfer from the white-box copy model to the black-box API. The authors report high attack success rates, better than those from competitive baselines (which do not require constructing a copy model). A few defences are also explored but are ineffective to prevent these attacks.","The paper is motivated by a challenging problem in deploying a neural network-based model for sensitive domain and research in this direction is essential for making such model usable for sensitive domains. The paper presents a model extraction attack, where the adversary can steal a BERT- based API (i.e. the victim model), without knowing the victim model’s architecture, parameters or the training data distribution. The model extraction attack, where the adversary queries the target model with the goal to steal it and turn it into a white-box model. They demonstrated using simulated experiments that how the extracted model can be exploited to develop effective attribute inference attack to expose sensitive information of the training data. They claimed that the extracted model can lead to highly transferable adversarial attacks against the original model (victim model). ",0.20491803278688525,0.18115942028985507,0.1923076923076923
616,SP:3907616cf8748efca1c63a16cfb9335e1380aec8,"The paper proposes a new method active learning (AL) on graphs. Unlike other AL approaches, the proposed approach provides soft labels via *relaxed queries* to the *domain experts*.     Main Contributions:   1). The paper proposes a new innovative approach for graph active learning with soft labels. The key idea is to ask a human regarding whether the model prediction is correct or not (a binary classification task) as opposed to asking them the correct ""hard label"" of the node. The incorrect model predictions are also not ""thrown away"" and used as indirect supervision by performing a soft-max over the remaining classes. This leads to a new criteria for active learning, called ""maximizing information gain propagation"" as opposed to maximizing entropy as done by standard AL.   2). Results are shown on a variety of real-world datasets which show the superior performance of the proposed method in achieving higher test accuracy with a certain labeling budget.",The paper proposes an active learning method for GNNs that is based on an information gain maximization where ethe information gain is obtained by querying a data point and looking at the influence of the queried node on the neighborhood relative to their previous information.  They also claim the setting of relaxing the oracle answer to be a binary confirmation of the most probable label. Experiments are presented where some advantage is shown for the method.,0.14193548387096774,0.2894736842105263,0.19047619047619047
617,SP:392b9bd0c1db9af559169c2bccb01b94112e57a2,"This paper proposed a variational automatic curriculum learning framework for solving goal-conditioned cooperative multiagent reinforcement learning problems. In this framework, the learning objective is decomposed into two parts: policy learning on current task distribution, and curriculum update to a new task distribution. The curricula are trained based on two components, including task configuration and the number of agents. The experimental results demonstrate the proposed method can achieve better performance than a few baselines with light weight computation resources. ","The paper proposes a curriculum learning method for cooperative multi-agent reinforcement learning in sparse reward tasks. The authors derive a curriculum learning approach by forming a lower bound on the expected reward under a target distribution p(\phi). This lower bound is maximized by alternatingly optimizing the policy under a variational distribution q(\phi) and then adjusting the variational distribution based on the current performance of the agent. The authors investigate the theoretical behavior showing that the optimization of q(\phi) minimizes a form of ""weighted"" KL-Divergence to p(\phi). Further, they derive a gradient-based approach to optimize q(\phi) and propose an approximate implementation of their approach that performs empirically well in different multi-agent RL benchmarks.",0.2911392405063291,0.19008264462809918,0.22999999999999998
618,SP:396758010e3aaccd1f0befef2cbad6c2b2d03a06,"This paper presents a new multimodal benchmark for language conditioned RL settings, where an agent must complete tasks specified by text instructions in the Atari Frostbite environment. Their benchmark provides a dataset of 5M text-labeled transitions for training. Finally, the authors propose a model for language conditioned RL settings based on Transformer architecture as a baseline.","This work proposes a new instruction-following reinforcement learning environment based on the Atari Frostbite environment. They experiment with a modified decision transformer on the environment. The results largely show that performance improves with longer context, more pretraining, and more data.",0.15789473684210525,0.21951219512195122,0.18367346938775508
619,SP:3967648f814883f46f39e438e261741ef59c9953,"This paper introduces several ways to assess probabilistic object detectors that output predictive distributions. Moreover, it presents a proper and non-local scoring rule for training such probabilistic object detectors.  The model backbone consists of standard detectors (DETR, RetinaNet, FasterRCNN) with a variance regression head and a mean bounding box regression head.  The loss functions explored in the paper are the negative log likelihood (NLL, which is local and proper), energy score (ES, which is non-local and proper), and direct moment matching (DMM, which is non-local and non-proper), so this means that nine different combinations of detectors and losses can be formed.   The assessment uses NLL, MSE, ES and Brier Score on four partitions of the detection results (based on their IOU with ground truth): true positives, duplicates, localization errors, and false positives.  The training set is COCO, where there are three testing sets: the in-distribution test set is the COCO validation set, the artificially shifted data is the COCO validation dataset modified with 18 different image corruptions (Hendrycks & Dietterich, 2019), and the naturally shifted data is the OpenImages dataset (Kuznetsova et al., 2020).","This paper gives an empirical analysis of the predictive uncertainty for object detection and proposes a tool to establish and evaluate the uncertainty. The main claim of this paper is that, for the bounding box regression, non-local based algorithms have superiority in the consistency with the predictive distributions than local-based methods. The experiments are conducted on some state-of-the-art detectors and fairly demonstrate them.",0.10638297872340426,0.29411764705882354,0.15625
620,SP:398fa5d5b800e9aaa212f71363f2eccaa82e378e,"The paper proposes a method to construct recourses that are valid under worst case additive model shifts for linear models and applied to non-linear ones with LIME. The paper analyzes these robust recourses theoretically but not for the given algorithm. I think the paper overall is of great quality but it lacks in novelty in particular because of related work that shares the exact same problem formulation and experimental setup (see [25] as authors cite).  The algorithmic recourse problem is also of limited practical applicability, and thinking about robust (but much less realistic) recourses, does not help address the problems that help make algorithmic recourse more practically applicable. The proposed algorithm to solve the problem which is the main contribution of the paper is not analyzed theoretically, and empirical evidence do not discuss Theorem 2 which talks about the average cost of the recourses.  I think the paper is borderline primarily because of how similar it is to prior work. ","This paper deals with the robustness of algorithmic recourse options given to users by common methods in the field, as models get updated over time. In particular, unlike previous works, this one proposes a solution that aspires to withstand distributional shifts in training data over time, space, correction to measurements, etc. The proposed solution, ROAR, is inspired by adversarial training. The work also introduces a lower bound on probability of invalidation of recourse options of models trained normally, as well as upper bound the added cost the output of ROAR might incur. Finally, the authors compare the performance of ROAR, as well as to a causal version of ROAR (combined with Karimi et al.'s MINT) to those of existing popular methods, and offer a sensitivity analysis, demonstrating on a synthetic dataset the effect of distributional shifts on validity of recourse options.",0.13043478260869565,0.14788732394366197,0.13861386138613863
621,SP:39c4b49d0209716dd003914d2864662dc6082421,"The paper is about learning how to re-rank for retrieval with global image descriptors. There is a first step of retrieval to get the top-N neighbors to the query. Then, the NxN adjacency matrix is created which is the input for the re-ranking during training and during testing. The adjacency matrix is refined in an iterative way and by processing different sub-matrices each time.  During training the NxN adjacency matrix is forced to be close to the binary matrix that is contructed according to the class labels. At the same time, with the use of synthetic gradients, the backbone that is used to generate the feature vectors is updated so that the cosine similarity of the feature vectors facilitates the update of the adjacency matrix.  - this is a novel approach to re-ranking - the whole formulation is new for this task, so does the use of synthetic gradients - the method is applied on two different tasks: image retrieval and transductive few-shot learning.","The paper deals with image retrieval, i.e. the problem of finding images in a database which are the most similar to a given query image. More specifically, the paper describes a method for re-ranking retrieval (and few-shot classification) results in order to improve performance. The technique consists in learning how to refine the retrieval results by first representing them as a similarity matrix, then learning a deep network G that learns how to produce a step that refines this matrix.  The contributions of the paper could be summarized as follows:  1) A novel method for re-ranking that uses a neural network to enhance the similarity matrix directly (which the authors call a ubgraph Similarity Refiner); 2) An approach for combining the method above with k-reciprocal re-ranking; 3) Experiments showing the method above leads to consistent improvements (although with varying levels of significance)",0.20359281437125748,0.22972972972972974,0.21587301587301586
622,SP:39c5ad94a057196b513d4a96d3478ddf73add838,"This paper provides a metric to characterize local minima of deep network loss landscapes based on the Fisher information matrix of the model parameterized by the deep network. The authors connect the Fisher information to the curvature of the loss landscape (the loss considered is the negative loss likelihood) and obtain generalization bounds through PAC Bayes analysis. They further propose regularizing the training of deep networks using the local curvature of the loss as a regularizer. In the final experimental section of the paper, the relationship between the empirical measures and generalization is shown on a variety of networks.","This paper contributes to the deep learning generalization theory, mainly from the theoretical perspective with experimental verifications. The key proposition is given by the unnumbered simple equation in the middle of page 4 (please number it), where \mathcal{I} is the Fisher information matrix. According to the authors, this simple metric, which is the log-determinant of the Fisher information matrix, can characterize the generalization of a DNN.",0.21212121212121213,0.3088235294117647,0.25149700598802394
623,SP:39cb14ce95091715f262868c8eed6b52e653cb06,"This paper studies the convergence properties of three classical value estimation algorithms (TD, FVI and RM) under over-parameterized linear case. The difference among convergence results are interpreted unifiedly through different constraints in an optimization problem. It also proposes an generalization bound for FVI. Furthermore, based on the results mentioned before, it proposes two regularizers to help convergence in deep reinforcement learning and experimentally evaluates their performance.","In this paper, the authors consider the overparameterized linear representations of TD, FVI, and RM. A unified interpretation of these algorithms of minimizing the Euclidean norm of the weights subject to alternative constraints is proposed. The paper is also supported by the empirical results.",0.19402985074626866,0.29545454545454547,0.23423423423423423
624,SP:39d00d5d9529e4cc7096b8d2c17b0d5326a3d7f2,"The authors present an approach to inference of parameters of a limited scope of dynamical systems with codimension one bifurcations from user-defined number and location of bifurcation points. The approach solves the parameter inference problem by gradient-based optimization function consisting of two terms. A term matching the provided to the estimated bifurcation locations and a term forcing desired properties of the determinant of the Jacobian of the system. The approach is demonstrated on two simple examples, minimal models and a synthetic toggle switch.","In this work, authors suggest a gradient-based semi-supervised approach to infer the parameters of ODEs for producing a bifurcation diagram. A bifurcation measure is defined that uses the determinant of the state-space Jacobian as an indicator for bifurcating parameter regimes in the unsupervised term of the cost function. They demonstrate parameter inference with minimal models which explore the space of saddle-node and pitchfork diagrams and the genetic toggle switch from synthetic biology.",0.24705882352941178,0.27631578947368424,0.2608695652173913
625,SP:39e2b5a77cf6a3cf90efd0e78b2041855c4139fa,"The authors propose meta Q-learning, an algorithm for off-policy meta RL. The idea is to meta-train a context-dependent policy to maximize the expected return averaged over all training tasks, and then adapt this policy to any new task by leveraging both novel and past experience using importance sampling corrections. The proposed approach is evaluated on standard Mujoco benchmarks and compared to other relevant meta-rl algorithms.","This paper proposes Meta Q-Learning (MQL), an algorithm for efficient off-policy meta-learning. The method relies on a simple multi-task objective which provides initial parameter values for the adaptation phase. Adaptation is performed by gradient descent, minimizing TD-error on the new validation task (regularizing towards initial parameter values). To make adaptation data efficient, the method makes heavy use of off-policy data generated during meta-training, by minimizing its importance weighted TD-error. Importance weights are estimated via a likelihood ratio estimator, and are also used to derive the effective sample size of the meta-training batch, which is used to adaptively weight the regularization term. Intuitively, this has the effect of turning off regularization when meta-training trajectories are “close” to validation trajectories. One important but somewhat orthogonal contribution of the paper is to highlight the importance of context in meta-learning and fast adaptation. Concretely, the authors show that a simple actor-critic algorithm (TD3), whose policy and value are conditioned on a context variable derived from a recurrent network performs surprisingly well in comparison to SoTA meta-learning algorithms like PEARL. MQL is evaluated on benchmark meta-RL environments from continuous control tasks and is shown to perform competitively with PEARL.",0.37142857142857144,0.125,0.18705035971223022
626,SP:3a035de1d4b8f02e2896e2376965b6a259ac9867,"This paper is addressing the problem of hard exploration / escaping local minima in continuous control, by optimizing a population of agents for both environment reward and diversity, using both off-policy RL and Quality-Diversity (QD) optimization. Each agent is individually optimized using off-policy RL for either environment reward or diversity, and at a population level, individuals are selected using a QD method such as Map-Elites. On a hard exploration problem, Ant-Maze (Colas et al 2020), the proposed method is shown to be significantly more data-efficient compared to several other SOTA ES methods (ME-ES (Colas et al, 2020), NS-ES (Conti et al 2018), NSR-ES (Conti et al 2020)).   ","The authors describe a QD-RL algorithm to solve continuous control problems with neural controllers. The authors state that  they maximize diversity within the population and ” the return of each individual agent”. Furthermore, the authors state that QD-RL selects agents from a Pareto front or from a Map-Elites grid. This paper is weak in estimating its performance in a clear way. The overall structure in Section 4 is not well defined and difficult to follow. Descriptions of the methods and technical details of the proposed study are incomplete. Furthermore, literature review simply lists studies without presenting a coherent and systematic introduction or critical evaluation. Overall, the contribution of the paper is not significant. ",0.14782608695652175,0.14782608695652175,0.14782608695652175
627,SP:3a07b9f25dd5216e3183232f305f5eeb2333427e,"The paper starts by that observing the local minima obtained in a multi task scenario are connected with a linear path of low error regime to the local minima of each task in a continual learning scenario in contrast to the path between the different minima of tasks incrementally learned, provided the both training of multi task and continual learning have started from the same initialization. The paper studies and shows this mode connectivity empirically. It further discusses and analyses the factors behind this connectivity while noting that this is valid when tasks have shared structure in which local minima can be found nearby.","The paper studies the relation between the geometry of solutions of continual (CL) and multi-task learning (MTL). Towards this end, the authors empirically identify that all the solutions of CL (i.e. solutions obtained after each task) and MTL are connected by a linear region of low error. This is a very interesting finding and, to my knowledge, has not been studied previously in the CL literature. Based on this observation, the authors propose a memory and regularization-based CL method, MC-SGD, that ensures that the final CL solution is linearly connected to all the task’s solutions. The authors further demonstrate that the solution of the MTL lies in the region where the Hessian of the loss function is low and hence the regularization-based approaches that make use of curvature information (e.g.) EWC, are a promising direction for CL. Experiments are conducted on Permuted and Rotated MNIST, Split CIFAR benchmarks. MC-SGD performs strongly compared to other baselines. ",0.25,0.15950920245398773,0.1947565543071161
628,SP:3a268e208ecbf0a5dfa031a6bf54314f5df558c9,"The paper proposes a novel method, White Paper Assistant (WP), to prevent CNNs from utilizing spurious input-out correlations, the so-called shortcuts, in classification. The main idea is to intermittently update the CNN to predict uniform distribution over classes for white image inputs. Through careful and extensive empirical studies on various datasets, the paper shows that this simple regularization can prevent the CNN from excessively focusing on shortcuts, thus learning more generalizable features and improving the overall accuracy on the test set.","The present work introduces an approach to tackle Shortcut Learning by CNNs, called White Paper Assistance (WP). After motivating and introducing the method, the authors evaluate it on computer vision datasets with synthetic inserted shortcuts, ie. black pixels in the corners of the images. The authors show that the WP approach reduces the learning of so-called shortcuts.  ",0.1566265060240964,0.22413793103448276,0.1843971631205674
629,SP:3a342130759e47057da1d63ad04c5e28e3955dbd,"The paper proposes using a cosine activation function and Hadamard-Diagonal transformation as a means to improve the efficiency of MPC for machine learning. The paper considers a two-server model, where the training computation are carried out by two non-colluding parties. Experiments are provided to demonstrate the improvement on the test accuracy of the proposed approach over other baselines that use different activation functions.  ","MPC is a cryptographic technique to allow multiple party to jointly compute a protocol without leaking sensitive data, but building blocks in the neural network converted to MPC setup usually suffer from heavy communication overhead among parties, and jointly training ML models is also computationally expensive. So, in this work, authors propose an efficient MPC-based neural network. The network consists of cosine function as activation function under 2PC setup and linear transformations by Hadamard-Diagonal method.",0.12121212121212122,0.1038961038961039,0.11188811188811189
630,SP:3a3cf90eed62a89708aeb482709f8037abc4e274,"This paper proposes a method to learn a state representation for RL using the Laplacian. The proposed method aims to generalize previous work, which has only been shown in finite state spaces, to continuous and large state spaces. It goes to approximate the eigenvectors of the Laplacian which is constructed using a uniformly random policy to collect training data. One use-case of the learnt state representation is for reward-shaping that is said to accelerate the training of standard goal-driven RL algorithms. ","The authors propose a Laplacian in the context of reinforcement learning, together with learning the representations. Overall the authors make a nice contribution. The insight of defining rho to be the stationary distribution of the Markov chain P^pi and connecting this to eq (1) is interesting. Also the definition of the reward function on p.7 in terms of the distance between phi(s_{t+1}) and phi(z_g) looks original. The method is also well illustrated and compared with other methods, showing the efficiency of the proposed method.",0.17857142857142858,0.16483516483516483,0.17142857142857143
631,SP:3a3df1703d2f59babf2fc1abd8b17975479fc8a5,"This paper proposes a Bayesian neural network for predicting if an earthquake will break a fault or not, overcoming 'small data problem' and predicting model uncertainty. The data is composed of 8 features and a binary output, and the samples are all coming from simulations. An analysis on the means and standard deviations of the first and last layer of the neural network's weights has been carried out.","In the present paper, the author intends to get further insights into the physics behind earthquake ruptures using a BNN to model simulated data from the literature. By using a BNN, the parameters of the model are not deterministic scalar values, but complete probability distributions. Studying the change of the distributions in the parameters before and after training, the author tries to extract information about the relative importance of the input variables, and also comprehend the physical mechanisms behind earthquake ruptures. Results are shown in figure 3, on which the change of behavior of the distributions of the parameters can be observed, as well as in figure 4 where the mean and standard deviations for all the parameters are presented. The pattern in figure 6 seems to indicate that variables previously thought to be important in the task of predicting the presence of the rupture, such as normal stress and friction, are also pointed out as being important in this case.  Finally, the authors also claim an improvement in the F1 metric in comparison to previous NN methods. ",0.30434782608695654,0.11797752808988764,0.1700404858299595
632,SP:3a3e8b97dfde90fa74251f8ff90fc4010c09642b,"The paper discusses how, from an existing set of rules or a procedure generating rules ""on the fly"", one can use linear programming to select a subset of rules that would increase ""interpretability"", where an interpretable system of rules is here understood as a system with few, short rules.   The idea is to ensure a good accuracy level by minimizing a continuous hinge loss (ensuring the linearity of the problem), while penalizing retained rule (rules having a positive weight) through a cost proportional to the complexity of those rules. The experiments show that the paper does, indeed, improve upon the metric retained by the authors (rule length and rule quantity). Whether this produces something that is readable is not checked further on (assuming that this is sufficient for user-readability). ","The paper presents an approach to learning ensembles of classification rules using linear programming. Two variants of the algorithm are considered: one uses a collection of rules extracted from ensembles of decision trees as the starting point, and another one that learns rules from scratch by applying decision tree learning within the rule learning algorithm. UCI datasets (mostly two-class problems) are used to compare classifier complexity and accuracy with that of random forests, AdaBoost, and learning a single decision tree.",0.15384615384615385,0.24691358024691357,0.1895734597156398
633,SP:3a670c06bf87ba895ed91ed2280d88881defa412,"This paper proposes a new loss function for performing principal component analysis (PCA) using linear autoencoders (LAEs). With this new loss function, the decoder weights of LAEs can eventually converge to the exact ordered unnormalized eigenvectors of the sample covariance matrix. The main contribution is to add the identifiability of principal components in PCA using LAEs and. Two empirical experiments were done to show the effectiveness of proposed loss function on one synthetic dataset and the MNIST dataset. ","This paper proposes a new loss function to compute the exact ordered eigenvectors of a dataset. The loss is motivated from the idea of computing the eigenvectors sequentially. However doing so would be computationally expensive, and the authors show that the loss function they propose (sum of sequential losses) has the same order (constant less than 7) of computational complexity as using the squared loss. A proof of the correctness of the algorithm is given, along with experiments to verify its performance.",0.2948717948717949,0.2804878048780488,0.2875
634,SP:3a7dfa4251b64bfa4e0fef36a4dcecce97e3031c,"The paper presented an input convex neural networks (ICNN)-based methods to approximate the optimal transport maps. The learning objective is based on the Monge-Ampere equation, i.e. zero loss corresponds to the solution to the Monge-Ampere equation. Physics Informed Neural Networks (PINNs) are adopted to minimise the loss. The author(s) also extended the work to density estimation. The problem is interesting as estimation of optimal maps has a wide range of applications. Experiment results look promising when compared with other PINNs in one experiment setup, but only qualitative results are provided for the density estimation experiment with no comparison of other baselines.","This paper introduces a new method for density estimation that is based on the idea of optimal mass transport (OMP), i.e., finding some function that transports a probability density into another probability density while minimizing the transportation cost. To do so, the authors leverage Brenier's theorem which guarantees the existence and uniqueness of the optimal transport map. As a consequence of this theorem,  the optimal transport map of the OMT problem can be obtained as the solution of a special nonlinear partial differential equation (PDE). The authors then show that the approximate solution can be computed with help of physics informed neural networks (PINNs). The approach is demonstrated for several canonical examples.",0.19811320754716982,0.18421052631578946,0.19090909090909092
635,SP:3aa1383a0cd06b30b6fb09ce293ce0e435e001bc,"In this paper, the authors delve deeper into the theoretical foundations of Reverse-complement equivariant convolutions for application to DNA sequences. Prior work has been mainly empirical and this helps to establish a general theoretical framework, thereby encompassing existing RC-equivariant-based models. By identifying this general theory, they were able to propose additional classes of RC equivariant models. They then compare the performance of standard models, existing models, and those proposed as a result from the theory on two regulatory genomics prediction tasks -- binary classification and profile prediction of TF ChIP-seq data. They show that for binary classification, their RC-models perform better than standard networks, but were largely similar for profile prediction.  ","The authors note that neural network models operating on DNA sequences desire shift equivariance and reverse complement (RC) equivariance. Existing proposed techniques have been somewhat ad hoc. The authors derive RC equivariant models from first principles, and expose a class of techniques that haven’t yet been studied. They benchmark several equivariant alternatives on ChIP-seq peak classification and nucleotide-resolution coverage prediction and demonstrate interesting results.",0.1391304347826087,0.23880597014925373,0.1758241758241758
636,SP:3aa14d5bb77c3cdf165b832dcc81f8b7867cefe6,"In this paper, the author analyzed gradient regularization in deep multitask learning. They empirically discovered a sharper concentration (low variance) in angles between the task gradient distributions could potentially improve the performance in multi-task learning. Then they proposed a new gradient regularization to enforce the gradient for each task be orthogonal. Empirical results (on Multi-digits MNIST and NYUv2 data-sets) indicate a marginal improvement, comparing with baselines.","This paper embraces the idea that better multi-task/lifelong learning can be achieved if tasks produce gradients that are orthogonal to the gradients produced by other tasks. The authors propose an approach to regularizing learning in order to incentivize this to happen. However, as they mention themselves, the regularized loss is computationally intractable in general and they only apply it to a subset of their network as a result. Given the computational scalability concerns, it is natural to wonder why researchers in the community would adopt this approach rather than other approaches that also aim to make gradients orthogonal. ",0.17391304347826086,0.12,0.14201183431952663
637,SP:3ae544b075487fc2a3731e1c017546ef0ff525e9,"This paper proposes a new visualization tool in order to understand the behavior of agents trained using deep RL. Specifically, they train a generative model of game states, and then optimize an energy-based distribution over state embeddings according to some target function, and then by sampling from the resulting distribution they create a diverse set of realistic states that score highly according to the target function. They propose a few target cost functions, which allow them to optimize for states in which the agent takes a particular action, states which are high reward (worst Q-value is large), states which are low reward (best Q-value is small), and critical states. They demonstrate results on Atari games as well as a simulated driving environment.","This paper proposes a generative technique to sample ""interesting"" states useful for analyzing the behavior of deep reinforcement learning agents. In this context, the concept of ""interesting"" is defined via user-specific target functions, e.g. states that arise as a consequence of taking specific actions (such as actions associated with high or low Q-values for example). The approach is evaluated in the Atari domain and in an autonomous driving simulator. Results are mainly presented as visualizations of interesting states that are described verbally.",0.176,0.25882352941176473,0.2095238095238095
638,SP:3ae91f3ba2414da1c21b536b52a3e25745ff75cf,"This paper proposes a pairwise communication between agents using a shared neural network. The idea is to define the joint action-value function as the sum of individual agent's values + pair-wise payoff between agents, which is based on the prior work [Castellini et al.]. In particular, this paper proposes to share the parameters of the pairwise payoff function to improve efficiency. The result on a grid-world domain shows that the proposed method performs better than baselines that either do not have pairwise communication (VDN) or learn fully joint action value function (QTRAN). ","Teh authors propose to learn value functions that are a sum of utility (single-agent) and payoff (2-agent) components. The weights between all function are shared (common RNN). This stands in contrast to VDNs (only uses utility functions or centralized value functions. The authors evaluate on predator-prey, where they argue that e.g. VDN fails to learn.",0.14736842105263157,0.23728813559322035,0.1818181818181818
639,SP:3af1ec26b5c02fa5ad9f0f7827c0863ce45e2607,"This paper investigates the underlying causes of the disparate impact produced by differentially private machine learning methods. To that end, the paper considers the notion of excessive risk gap, which measures the difference between the population-level and subgroup risks. The paper explores how two different differential privacy mechanisms (output perturbation and DP-SGD) affect the excessive risk gap. For output perturbation, the paper relates the excessive risk gap to the absolute difference between the population-level and subgroup trace of the hessian. For DP-SGD, the paper decomposes the expected loss into a non-private term, a private term due to clipping, and a private term due to noise. Finally, the paper leverages these insights to propose a novel formulation of DP-SGD that empirically decreases the excessive risk gap on real-world datasets.","The paper tries to solve the problem that ML models with DP tend to excerbate bias and unfairness. Particularly, it focuses on two well-studied DP algorithms: output perturbation and DP-SGD. The paper shows that the unfairness is caused by gradient clipping and noise addition. Based on the observations,  it further proposes a solution and its effectiveness has been tested experimentally. ",0.14074074074074075,0.3064516129032258,0.19289340101522842
640,SP:3af65f4601748c89802e82f7e312d169ab8f54f2,"This paper aims at solving geometric bin packing (2D or 3D) problems using a deep reinforcement learning framework. Namely, the framework is based on the actor-critic paradigm, and uses a conditional query learning model for performing composite actions (selections, rotations) in geometric bin packing. Experiments are performed on several instances of 2D-BPP and 3D-BPP,",This paper proposes an end-to-end deep reinforcement learning-based algorithm for the 2D and 3D bin packing problems. Its main contribution is conditional query learning (CQL) which allows effective decision over mutually conditioned action spaces through policy expressed as a sequence of conditional distributions. Efficient neural architectures for modeling of such a policy is proposed. Experiments validate the effectiveness of the algorithm through comparisons with genetic algorithm and vanilla RL baselines. ,0.2631578947368421,0.2054794520547945,0.23076923076923078
641,SP:3b0d0ac062a7bc618741cff17c7d507b0b0a7489,This paper investigates the impact of stale weights on the statistical efficiency and performance in a pipelined backpropagation scheme that maximizes accelerator utilization while keeping the memory overhead modest. The paper proposes to combine pipelined and non-pipelined training in a hybrid scheme to address the issue of significant drop in accuracy when pipelining is deeper in the network. The performance of the proposed pipelined backpropagation is demonstrated on 2 GPUs using ResNet with speedups of up to 1.8X over a 1-GPU baseline and a small drop in inference accuracy.,"This paper proposes a new pipelined training approach to speedup the training for neural networks. The approach separates forward and backpropagation processes into multiple stages, cache the activation and gradients between stages, processes stages simultaneously, and then uses the stored activations to compute gradients for updating the weights. The approach leads to stale weights and gradients. The authors studied the relation between weight staleness and show that the quality degradation mainly correlates with the percentage of the weights being stale in the pipeline. The quality degradation can also be remedied by turning off the pipelining at the later training steps while overall training speed is still faster than without pipelined training.",0.18478260869565216,0.15315315315315314,0.16748768472906403
642,SP:3b8a2360d24c7a5c2236c57abbe1e92e9964b337,"The authors introduce a novel approach for generating data with intrinsic Euclidean symmetries. The proposed model uses recent advances in continuous normalizing flows, variational dequantization, and equivariant neural networks to construct a generative algorithm E(n)-equivariant along some modeled variables. The authors tackled many theoretical and technical problems to make the model stable and obtain desired equivariance in Euclidean space. The generative process looks as follows: first, the two groups of latent codes are sampled from the Gaussian distribution, which is rotation and reflection invariant; these samples are passed through the continuous normalizing flow guided by an Equivariant Graph Neural Networks. To force the translation equivariance, the authors propose to center the latent codes and work with (M-1) x n linear subspace. The target distribution is given by applying the variational dequantization for the sampled latent codes. The authors validate their approach on synthetic data and molecular conformations produced with DFT (density functional theory). ","The paper introduces a new type of equivariant normalizing flow by using the CNF framework with a modified equivariant graph NN as a dynamics function. The equivariance discussed is wrt Euclidean symmetries, which are important for physical systems. They show that their flow beats prior equivariant baselines on synthetic data. Moreover, the model is capable of transforming spacial, categorical and ordinal features simultaneously. This allows the sampling of molecular configurations with positions, atom types, and charges. ",0.12179487179487179,0.25,0.16379310344827586
643,SP:3b90d1be98c9d3d60ce7ef415b471a824076b967,"The paper proposed to learn skills correspondences between robots of different morphologies in an unsupervised way - without requiring paired data from the robots. They learn a skill translation model that maps skills from a source robot to a target robot. The translation model is learned by minimizing a loss composed of two components: (1) the likelihood of the translated skills under the target distribution estimated from target robot skills data, and (2) the likelihood of the target skills under the translated distribution estimated from the translated skills data.  The proposed approaches hinges on the assumption that robots with different morphologies follow similar high-level strategies when performing similar tasks. So, a sequence of tasks across the robots is used to learn the skills correspondences. ","This paper addresses the problem of transferring skills between morphologically different robots. This approach to learning skill correspondences is framed as a problem of matching distributions of sequences of skills across robots. The paper proposes an unsupervised objective, inspired by work in unsupervised machine translation, that makes the skill translation model learn to match the distribution of skill sequences. The proposed approach is experimentally evaluated on 3 transfer settings in a simulated robot environment.",0.1532258064516129,0.25675675675675674,0.1919191919191919
644,SP:3ba30fe17eeba72e27d752277c8740433e5ef369,"This work introduces a framework, called DAT, to scale out adversarial training to distributed settings. DAT combines three techniques: one-shot fast gradient sign method for more efficient inner maximization, gradient quantization for reduced communication volume, and layer-wise adaptive learning rate optimizer for large-batch training.  Equipped with the proposed techniques, the authors obtain promising speedups to perform adversarial training against ResNet18 and ResNet50 on CIFAR-10 and ImageNet with multi-node and multi-GPU, while achieving comparable (roughly under 2% difference) accuracy.","This paper proposed distributed adversarial training (DAT) for robust models. The method is a combination of PGD-like adversarial training, LARS-like large batch training, and quantizing gradients for communication efficiency in distributed training. The authors show convergence of adversarial training with LARS-like learning rate under layer-wise assumptions, and empirical results of DAT can scale to 6x6=36 GPUs and batch size 6*512 for ImageNet.",0.17857142857142858,0.22058823529411764,0.19736842105263155
645,SP:3bec1083d30b42438c1d66b4f382b80d34032b7e,"The authors consider the problem of ``""sketching"" – a popular compression technique in machine learning - used for reducing the size of the data enabling one to quickly compute an approximate solution using this compressed input. This paper introduces a general framework for learning and applying sparse sketching matrices. A two-stage procedure for learning sketches with the same sparsity pattern as CountSketch is proposed which involves first learning the sketch’s non-zero entries, and then optimizing their values. They then show how to apply the obtained sketch so that it has worst case approximation error guarantees. This procedure is applied to three applications, namely least squares regression, low rank approximation (LRA) and k-means clustering. Experimental results demonstrate a substantial reduction in the approximation error compared to other baseline approaches (including classically learned sketches). On the theoretical front, it is shown for regression and LRA that the proposed approach obtains improved error guarantees for fixed time complexity.  Additionally, it is shown for LRA (under certain input distributions) that including the first stage is strictly better than not including it. Finally, a more straightforward way of retaining worst case approximation guarantees for k-means is shown. ","The authors consider a specific sketching method, CountSketch, and three objective functions defined over the data design matrix: multiple-response regression (MMR), low-rank approximation (LRA), and k-means clustering. They compare the classical CountSketch with a random choices of the {-1,+1}-valued sketching matrix against: (1) Gradient descent optimization of the CountSketch weights. This was previously introduced for LRA and the authors extend it to MMR and k-means. (2) Greedy optimization of the positions of the CountSketch non-zero entries.",0.13333333333333333,0.3132530120481928,0.18705035971223025
646,SP:3bf64bcc780380921a57f996019861e87d24884e,"The authors propose a new approach called Federated Divergence-aware Exponential moving Average update (FedEMA) to avoid the IID assumption. FedEMA is built onto of FedSSL which is a framework for self-supervised learning in a Federated Learning context. The authors proposes a new approach to fuse the local and global knowledge effectively through a EMA update, where the decay rate of EMA is dynamically measured by a divergence. ","This paper investigates a generic federated SSL recipe that applies FedAvg to a range of existing SSL works including SimCLR, MoCo, BYOL and SimSiam. Each of these SSL blocks comprises two encoding networks, including an online net and a target net. The two nets were trained via optimizing a similarity loss such that the distance between encodings of different augmented versions (e.g. rotation) of the same input is small and vice versa. Depending on the specific SSL block, the parameterization of the two nets might be identical (SimCLR, SimSiam) or not (MoCo, BYOL). At each iteration, the online net of each client is uploaded to a server to be averaged. Then, the (global) averaged version is sent back to each client. Each client then reset its online net as a weighted average of the global and local version of the online net (to account for potential data heterogeneity), and continue updating the SSL block via gradient updates and so on.      Here, the main contribution of the paper is a series of ablation studies (Table 1, Figure 2, Table 2, Figure 3) that measure the isolated impact of several fundamental components of the aforementioned SSL blocks (e.g., SimCLR, SimSiam, MoCo and BYOL). This includes the predictor, stop-gradient, exponential moving average (EMA), non-identical online and target encoding net. The results indicate that BYOLD contains all the essential elements (predictor, EMA and non-identical online & target net & no stop-gradient) so the federated SSL recipe is rotated towards having BYOL as the model choice. Then, a customized, divergence-aware EMA is proposed for this recipe that is shown to improve substantially over existing FL-SSL baselines (Tables 3-4; Tables 6-7). There is also a bit of ablation study that measures the isolated impact of the new EMA which is also substantial as shown in Figure 5.",0.2898550724637681,0.06472491909385113,0.10582010582010581
647,SP:3c24c8f9c44d7d59f54fd4cf3853f91db9e29e79,"This paper analyzes the variance of gradient estimates in policy-gradient-based multi-agent RL, specifically for standard multi-agent policy gradient (including both centralized and decentralized training) and for the COMA gradient. The paper then derives an optimal baseline (OB) as well as a tractable surrogate for variance reduction. The non-optimality of the variance of standard MAPG and COMA is shown. Numerically, lower variance of the OB is shown in an analytical example, and performance (in terms of reward and win rate) improvement is shown when the OB is implemented on top of MAPPO and COMA in the discrete-action StarCraft micromanagement scenarios and continuous-action multi-agent MuJoCo.","This paper theoretically studies the variance of multi-agent policy gradients.   It shows that the extra variance that CTDE MAPG methods have compared to DT methods scales linearly on the number of agents, and quadratically on the local advantage of each agent.   The paper further proposes the optimal baseline technique to reduce the variance of the MAPG estimator. While the analytic form of the optimal baseline is computational challenging to compute, the assumption that the policies are parameterized by neural networks with softmax layer is used to find a surrogate minimisation objective that is more tractable to compute/approximate.   Experiments are conducted to confirm the effectiveness of the optimal baseline technique. ",0.22522522522522523,0.22522522522522523,0.22522522522522523
648,SP:3c415c075029fe70504aac9ad8fd3a7a8995458c,"The paper is devoted to self-supervised learning of local features (both detectors and descriptors simultaneously). The problem is old yet not fully solved yet, because handcrafted SIFT is still winning the benchmarks. This work mostly follows and improves upon SuperPoint (DeTone et.al 2017) and the follow-up work UnsuperPoint (Christiansen et.al 2019) architecture and training scheme.",The following work proposes several improvements over prior works in unsupervised/self-supervised keypoint-descriptor learning such as Christiansen et al. One improvement is the relaxation of the cell-boundaries for keypoint prediction -- specifically allowing keypoints anchored at the cell's center to be offset into neighboring cells. Another change was the introduction of an inlier-outlier classifier network to be used as a proxy loss for the keypoint position and descriptors. They found the inlier-outlier loss to improve homography accuracy at 1 and 3 pixel thresholds.,0.1694915254237288,0.11363636363636363,0.13605442176870747
649,SP:3c564f60a942d2b56589ce292cc233d137560152,"This paper proposes class-incremental learning with unlabeled data correlated to labeled data, and a method to tackle it. The task can be considered as a variant of [Lee et al.], which has no assumption on the unlabeled dataset, while this paper assumes the correlation between labeled and unlabeled dataset explicitly. The proposed method is inspired by state-of-the-art class-incremental learning, semi-supervised learning, and out-of-distribution (OoD) detection methods: local distillation [Li and Hoiem], OoD detection [Hsu et al.], consistency regularization and pseudo labeling (or hard distillation) [Sohn et al.], and loss balancing based on class statistics [Lee et al.]. Experimental results support that the proposed method outperforms prior works in the proposed task.","This paper investigates a semi-supervised continual learning (SSCL) setting and proposes a new method called DistillMatch for this setting. The major contributions are: (1) The authors carefully design a realistic SSCL setting where object-object correlations between labeled and unlabeled sets are maintained through a label super-class structure. And then, they develop the DistillMatch method combining knowledge distillation, pseudo-labels, out of distribution detection, and consistency regularization. (2) They show that  DistillMatch outperforms other existing methods on CIFAR-100 dataset, and ablation study results are shown also. ",0.19327731092436976,0.25842696629213485,0.22115384615384615
650,SP:3c637265c7844256d8e73afb0d1ac811db505c73,"This paper provides some analyses of the difference between adversarial training and standard training for linear classification problem. In particular, it proves that when the data is \eps linearly separable, adversarial training converges faster than standard trading. It also argues that when the data is not \eps linearly separable, adversarial training is more robust to outlier. Simulations are constructed to verify the arguments in the paper but there is no experiments on real dataset. ","The aim of this paper is to provide a theoretical analysis of adversarial training under the linear classification setting. The main result states that, under many technical assumptions,  adversarial training using gradient descent may converge to the hard margin SVM classifier with a fast rate. Here ""fast"" is not the standard 1/T fast rates but, rather, a rate of o(1/log T) (in comparison to recent results that looked into the convergence of gradient descent with logistic loss to the hard-margin SVM solution).",0.21621621621621623,0.18604651162790697,0.2
651,SP:3c7efb6ff61e1589c76a8bbcb156cd6d4fb6b4af,"The paper addresses multi-agent RL problems by presenting a decentralized approach where the agents learn to share their reward with their neighbors. In this method, a high-level policy determines a weight vector for weighting the reward of neighboring agents, and then each agent learns their own independent policy. The learning is thus conducted locally in a partially connected network toward a common goal and without the knowledge of global state and actions.","The paper present a new method, called LToS which enables agents to share rewards in MARL. Two levels of policies, high-level and low-level, determines rewards and optimize global objectives. Three diverse scenarios were used to test the performance of LToS compared to other baseline methods. LToS consistently outperforms other methods. In the second scenario, authors also show the need for high-level policy by introduction fixed LToS. ",0.1891891891891892,0.2028985507246377,0.1958041958041958
652,SP:3cda613e93b67aa8b562cd2564f4d3583fe9f2e8,"The paper makes an observation that signal dynamics common to a class of causal systems may contain strong information to enable the use of the encoder of the Neural Relational Inference (2018) for extracting (Granger) causal graphs. It minimally extends the NRI model with an empty edge type and demonstrates that the observation holds in a few cases of dynamical systems. Additionally, to handle the unobserved common causes the paper shows improvements in ROCAUC when the encoder is modified to model them directly.","The authors proposed a framework called Amortized Causal Discovery (ACD) for recovering causal relationships in time series where samples are generated from models with different underlying causal graphs but shared dynamics. This framework is applicable in settings such as modeling neural spiking trains where the dynamics of how neurons react to the activities of other neurons remain the same. In the proposed framework, they considered a causal discovery encoder $f_{\theta}$, which tries to extract causal relationships and map it to a latent space. Moreover, there is a dynamic decoder $f_{\phi}$, which provides one-step predictions. The proposed architecture is similar to a variational auto-encoder and the encoder part is based on graph neural networks.",0.1927710843373494,0.13675213675213677,0.16
653,SP:3cdd60ae34de5fcc54bc31a4d7803fc4ac86939d,"The authors propose an approximate MCMC method for sampling a posterior distribution of weights in a Bayesian neural network.  They claim that existing MCMC methods are limited by poor scaling with dimensionality of the weights, and they propose a method inspired by HMC on finite-dimensional approximations of measures on an infinite-dimensional Hilbert space (Beskos et al, 2011).  In short, the idea is to use a low dimensional approximation to the parameters (i.e. weights) of the neural network, representing them instead as a weighted combination of basis functions in neural network parameter space.  Then the authors propose to use HMC on this lower dimensional representation.  While the idea is intriguing, there are a number of flaws in the presentation, notational inconsistencies, and missing experiments that prohibit acceptance in the current form.","The idea of extending  Riemannian Langevin dynamics to functional spaces is elegant, however it is extremely hard to follow the proposed method as details are kept to a minimum. The finite approximation of the posterior distribution is a function of the parameters theta, however it displays parameters lambda. The couple of sentences: ""Then by sampling λ, we sample a functional f equivalently. The Riemannian Langevin dynamics on the functional space can thus be written as: (6)"" come without a single explanation.",0.13533834586466165,0.225,0.16901408450704225
654,SP:3cdfd6f5f8455a41ef1edf46fada784b77b40cd7,"This work proposes a method for generating synthetic datasets for testing path-based (knowledge) graph completion. Until recently, there were not many good benchmarks for evaluating reasoning with learned rules or learned knowledge, but there has been a fair amount of work on developing benchmarks for this lately. The synthetic datasets generated here are distinguished by the ability to produce datasets that share a controllable amount of rules. This permits the benchmarks to be used to evaluate multitask learning, robustness to distribution shift, etc. As an illustration of this, the paper includes experiments with a variety of baseline methods showing how (a) the generalization ability of various methods grows and then declines as the number of tasks is increased and (b) fine-tuning on diverse tasks improves accuracy. They also show that in a continual learning setting, the baseline methods all exhibit catastrophic forgetting.","The authors propose a synthetic graph generator to evaluate graph neural networks. The generation process starts with defining rules, subset of rules are used to define a world, each world is then used to sample a graph. Test queries are generated by picking a pair of vertices u, v and generating a path connecting them via the rules. There are some biases in the generation process. For instance, the rules are exclusively open path or chain rules. And as noted above, the test queries mostly stick to a path (the authors allow some variations by adding nodes to vertices already on the path but the path seems to form the backbone of the test query). The remainder of the paper takes a few well known graph neural networks and evaluates them on data generated using GraphLog. Based on these results, the authors claim that E-GAT outperforms RGCNs.",0.16666666666666666,0.16216216216216217,0.16438356164383564
655,SP:3d06de343694b2f9db428428f68dee272e459486,The authors pose a problem of learning a mapping when when a low-dimensional state simulation is given along with target image tragectories. The goal of the paper is to learn a mapping from image to state such that at test time the agent can directly use this mapping with a trained policy from the simulator to perform in the target domain. The contribution of this paper lies in its problem formulation and an algorithm named Cross-mOdal Domain Adaptation with Sequential structure (CODAS).,"The paper proposes a new approach for performing cross-modal domain adaptation, i.e. adapting a policy trained with inputs from modality A (eg low-dimensional environment state) to work with inputs from domain B (eg images). The main use case demonstrated in the paper is the adaptation of policies trained on states in a simulator to work on image inputs, which can be useful for eg real world deployment where states might not be available. While it is a very classic approach to separately train a perception module images --> state (eg in robotics), the main novelty of the presented method is, that this mapping can be learned without the need for paired [image, state] data.",0.25,0.1810344827586207,0.21000000000000002
656,SP:3d11e14e6bd250c3d83574309659fdd9f0aed45f,"The paper proposes a technique for joint detection and reconstruction of objects from images. The core idea is to express the signed distance function (used for reconstruction) within a set of pre-trained linear bases, and regress the bases coefficients by a deep network. The effectiveness of the solution is evaluated on a number of datasets against recently published work, and shows good performance.","This paper presents a joint framework for detecting multiple 3D objects from input images while also reconstructing the 3D shapes. The proposed method improves upon previous work [20,21] for joint 3D object detection and reconstruction mostly at the system/architectural level. The authors also propose a new way of compactly representing 3D shapes with signed distance functions (SDF) using PCA that can be naturally incorporated into the framework. Experiments are benchmarked with synthetic multi-object ShapeNet renderings, Pix3D, and a new dataset with annotations for multi-object detection & reconstruction.",0.234375,0.16666666666666666,0.19480519480519481
657,SP:3d274f069759276b0cf97066f302eec226514705,"The authors consider the problem of determining the minibatch size for SGD by first fixing a set of candidate sizes, and then learning a distribution over those sizes using a MAB algorithm. A minibatch size is first sampled from the distribution, then one training epoch is performed. A validation error is then computed, and if it is lower than that of the last epoch, the cost of the minibatch is taken to be zero (otherwise one), and the distribution is updated. This is Algorithm 1.","The paper applies multi-armed bandits for choosing the size of the minibatch to be used in each training epoch of a standard CNN. The loss of the bandit is binary: zero if the validation loss decreases and 1 otherwise. In the experiments, the Exp3 bandit algorithm is run with Adam and Adagrad on MNIST, CIFAR-10, and CIFAR-100. The results show that the bandit approach allows to obtain a test error better (although not significantly better) than the test error corresponding to the best minibatch size among those considered by the bandit.",0.21176470588235294,0.19148936170212766,0.2011173184357542
658,SP:3d3842a5e0816084c5a2406f1b0143d0215b9559,"Authors extend deepFool by adding extra steps and constraints to find closer points to the source image as the adversarial image. They both project onto the decision boundary. Deepfool does and adhoc clipping to keep the pixel values in (0,1) but the new proposed method respects the constraints during the steps. Also during the steps they combine projection of last step result and original image to keep it closer to the original image. Moreover, at the end of the optimization they perform extra search steps to get closer to the original image. Also they add random restarts. Rather than considering the original image, they randomly choose an image in the half ballpark of the total delta.","The authors propose a new gradient-based method (FAB) for constructing adversarial perturbations for deep neural networks. At a high level, the method repeatedly estimates the decision boundary based on the linearization of the classifier at a given point and projects to the closest ""misclassified"" example based on that estimation (similar to DeepFool). The authors build on this idea, proposing several improvements and evaluate their attack empirically against a variety of models.",0.1111111111111111,0.18055555555555555,0.1375661375661376
659,SP:3d4981a5b80d3f1f2b1249fa1a310988dfc81a91,"In this study, the authors develop a method to predict the function of proteins from their structure as well as the network of proteins with which they interact in a given tissue. The method consists in training a linear classifier on the output of two existing embedding methods, UniRep/SeqVec and OhmNet, respectively embedding the amino acid sequences and the tissue-specific protein-protein interaction networks. This method improves prediction of protein function by 19% compared to OhmNet alone.","This paper introduces a method to incorporate both sequence information and graph information to learn the protein representations. The idea is very straightforward. Basically, it used the embedding from OhmNet [Marinka et al, 2017] for the graph information and used the sequence information from UniRep [Ethan et al, 2019] or SeqVec [Michael et al, 2019]. It uses one experiment to show the performance of the combination of the two pieces of information.",0.16455696202531644,0.18055555555555555,0.17218543046357612
660,SP:3d76cac4f6c4d3bb1003b739801a4981c0db00b8,"This paper apply a model-based RL algorithm, DyNA-PPO for designing biological sequences. By being model-based, this algorithm is sample efficiency compared to model-free RL algorithms. This advantage is attractive and important in the context of biological sequence design since the designed is constrained to be done in the large batch / low round settings. To further improves model efficiency, the authors reduce learning bias by quantifying the reliability and automatically selecting models of appropriate complexity via cross validation. To encourage diversity in the target distribution they also penalize the reward using a visitation-based strategy.","In this work the authors propose a framework for combinatorial optimisation problems in the conditions that the measurements are expensive. The basic idea is to make an approximation of the reward function and then train the policy using the simulated environment based on the approximated reward function. The applications are shown in a set of biological tasks, which shows that the model performs well compared to the baselines. ",0.14285714285714285,0.20588235294117646,0.1686746987951807
661,SP:3d8e456a346e4f54909fb689197cbf80c51e601a,"The paper investigates the choice of learning paradigms to reach out-of-distribution generalization, namely IRM vs ERM under different scenarios of domain generalization. Technically, generalization bounds and rates are calculated to be able to compare theoretically how each paradigm fares in the different scenarios. Proposed analysis shows that IRM generalizes better than ERM in a number of important cases: presence of confounders and/or anti--causal variables. Numerical experiments on variants of the Colored MNIST benchmark (for each scenario) verify the theoretical findings.","This paper considers a learning scenario where training data $(X,Y)$ comes from a mixture, where membership in each mixture component (“environment”) is clearly labeled. Generalization is required not just under the same mixture, but potentially under changing mixing distributions. This is captured via several alternative formulations. The key underlying assumption that makes the extrapolation possible is the existence of a a representation $\Phi(X)$ that leads to an environment-invariant statistics (by focusing on quadratic loss and linear predictors, the paper asks for invariant $E[Y|\Phi(X)]$ and constant $var[Y|\Phi(X)]$). A range of other assumptions are made to enable analysis, such as sufficiency of the representation in at least one environment and boundedness of the loss and its gradient.",0.15476190476190477,0.10483870967741936,0.125
662,SP:3d9a527624bf5887ac6327c7bea19b6e368bceb0,"This paper proposes an RL-based GNN explainer to address the neglected interactions among nodes and edges in the generated subgraph for model interpretation in the existing works. Specifically, the subgraph generation process is modeled as a Markov decision process (MDP) where the state is the currently selected node, action space is composed by the candidate neighboring nodes, and reward signal is the combinatorial loss to encourage the RL learner to generate a compact and succinct subgraph. In this way, the subgraph generation process strictly follows the structure of the original graph and therefore considers the interactions among nodes and edges.","This paper studied the explanation for GNNs. The authors formulated the task of generating an exploratory sub-graph as a combinatorial optimization problem, and proposed a framework, RG-Explainer, to solve the problem via reinforcement learning.   The RG-Explainer framework consists of three parts: a seed locator for starting node selection, a graph generator for generating the explanatory sub-graph, and a learned stopping criteria to avoid generating very large explanatory graphs.   The authors conducted experiments on node classification and graph classification tasks.  The qualitative results showed that the proposed method could provide plausible explanations. The quantitative results showed that the proposed method has better accuracy, and outperforms the baseline in both inductive and transductive settings. ",0.21782178217821782,0.1896551724137931,0.20276497695852533
663,SP:3d9c05b1e68c0b1e976ccad7b87c2c710ebada2d,"-The idea of this paper is just to crop the detections and then forwarded to a second stage for more accurate predictions. This idea can be traced back to the original R-CNN paper, which is not even referred and discussed. There are also many papers having a second stage to refine the detection predictions, e.g. Cascade R-CNN, RefineDet, Revisiting RCNN, but none of them are discussed in this paper.",This paper presents a simple yet powerful and flexible framework to refine the predictions of a two-stage detector. The approach can produce more precise predictions by using mixture data of image information and the objects' class and center. They showed a simple scheme can increase the mAP of the SOTA models and it is able to produce predictions that are more precise than ground truth.,0.19444444444444445,0.21212121212121213,0.20289855072463767
664,SP:3dc1e6e375c55ce9b892ca09aecdf88b1243c777,"This paper proposed a way to detect a skew in the distribution of classes in a stream of images and reweight the class priors accordingly, to estimate the final posterior probabilities of present classes. This probability re-calibration is referred to as the probability layer. A simple algorithm is proposed to detect the class distribution skew. The proposed benefit of this method is that they do not require fine-tuning any network parameters using newly skewed data. ",The paper proposes a simple idea to calibrate probabilities outputted by a CNN model to adapt easily to environments where class distributions change with space and time (and are often skewed). The paper shows that such a simple approach is sufficient to get good accuracies without requiring any costly retraining or transfer learning. Thereby proving to give benefits in terms of resource consumption and at the same time giving better results than the state of the art.,0.18181818181818182,0.18181818181818182,0.18181818181818182
665,SP:3dc405392862e1e3f5a9cbd72ca9c9e630daaf81,"This paper describes a simple yet effective approach to deactivate the undesirable features using out-of-distribution data. By shrinking the undesirable features from feature extraction layers instead of task-specific layers using L2 penalty, this method is task agnostic. Authors demonstrated and compared performance with task-specific approaches on classification, regression and mixed tasks using several benchmark data sets. ","Problem: DNN predictions may get influenced by the undesirable features that are irrelevant to the task at hand, which causes poor  generalization.  Solution: Existing work showed calibration on out-of-distribution (OOD) samples can remove the contribution of undesirable features in classification. The caveat is its applicability to feature extraction. The paper proposes TAUFE, a novel regularizer that deactivates all the undesirable features in OOD examples from the feature-extraction layer, thereby removing the dependency on the task specific softmax layer. Results: TAUFE outperforms state-of-the-art methods on the standard benchmarks for classification, regression and the mix of the two. ",0.3,0.17647058823529413,0.22222222222222224
666,SP:3dd9ae7b88b3e6848ee1fbd11c274d7a395d3167,"Neural Networks are vulnerable to adversarial perturbations. This paper proposes a method that based on optimal control theory that uses semidefinite-programming. This is a quite popular topic in Adversarial training recently, there has been a few works in that line. There are almost no experiments in this paper. There are several typos in the paper and writing of this paper requires more work. There are several typos in this paper, for example STOA, should be SOTA (in the Section 6.) In its current state, this paper looks very rushed.","The goal of this paper is to train neural networks (NNs) in a way to be robust to adversarial attacks. The authors formulate training a NN as finding an optimal controller for a discrete dynamical system. This formulation allows them to use an optimal control algorithm, called method of successive approximations (MSA), to train a NN. The authors then show how constraints can be added to this optimization problem in order to make the trained NN more robust. They show that the resulted constraint optimization problem can be formulated as a semi-definite programming and provide some experimental results. ",0.14444444444444443,0.13131313131313133,0.1375661375661376
667,SP:3e145b336f187ed10a193fc6102d245fdd99e004,"In the paper, the authors study stable architectures for RNNs. On the theoretical side, the authors present a series of conditions such that a weight matrix of an RNN is contractive. On the modeling side, the authors propose RNN architectures that have contractive weight matrices. The proposed methods are evaluated on benchmark datasets including sequential MNIST, permuted MNIST, and sequential CIFAR-10. ","This paper is primarily a theoretical contribution to the construction of assemblies of recurrent neural networks. We know that combinations of learned modular components can be powerful and far more tractable than learning bespoke models from scratch, particularly in applied domains (e.g. AlphaGo). Yet so far, we have no theoretical guarantees that these combinations will actually remain stable. This paper develops the theory behind provably-stable combinations of RNNs using weight constraints and feedback mechanisms. Then, using fixed RNNs generated according to these constraints (leaving the connections between them as antisymmetric learnable parameters), the authors show that their sparse combination network is able to achieve SOTA performance on sequential image classification benchmarks with far fewer learned parameters and the previous stability guarantee.",0.20967741935483872,0.10569105691056911,0.14054054054054055
668,SP:3e3e429ab3ba27875731c7cecf2d00bd959973b6,This paper aims to apply the model of Wang 2019 to the new NDH task of Thomason '19.  Both of these datasets are built on the same room-to-room environment and both are for natural language instruction following.  Thomason's work extends the R2R paradigm to include a dialogue history which is collapsed into a single instruction.  The contribution of this paper is to build a single model which alternatingly samples trajectories from each of the two datasets to train a more general actor and the authors also believe that the presence of an environment classifier assists in generalization.,"This paper addresses some challenges of following natural language instructions for navigating in visual environments. The main challenge in such tasks is the scarcity of available training data, which results in generalization problems where the agent has difficulty navigating in unseen environments. Therefore, the authors propose two key ideas to tackle this issue and incorporate them in the reinforced cross-modal matching (RCM) model (Wang et al, 2019). First, they use a generalized multitask learning model to transfer knowledge across two different tasks: Vision-Language Navigation (VLN) and Navigation from Dialog History (NDH). This results in learning features that explain both tasks simultaneously and hence generalize better. Moreover, by training on both tasks the effective size of training data is increased significantly. Second, they propose an environment-agnostic learning technique in order to learn invariant representations that are still efficient for navigation. This prevents overfitting to specific visual features of the environment and therefore helps improving generalization. The contribution of this paper is combining and incorporating these two key ideas in the RCM framework and verifying it on VLN and NDH tasks. This approach is novel compared to prior results in tackling the VLN task. Their experimental results show that the two proposed techniques improve generalization in a complementary fashion, measured by decreased performance gap between seen and unseen environments.  They demonstrate that their technique outperforms state-of-the-art methods on unseen data on some evaluation metrics.",0.29,0.12184873949579832,0.17159763313609466
669,SP:3e46e1dd9730179c71a009b20355101423c348b1,The paper defines an entity-monitoring problem where the goal is to identify the distinct objects see in an episode where the agent/model moves through the scene/observes partial state. The paper proposes the OBM-Net model architecture to address this problem and identify all the distinct objects observed over each episode. The key idea of OBM-Net to have fixed set of slots which allow tracking multiple hypothesis over time and use an attention mechanism to update the slots with observations over time. ,The paper proposes an end-to-end system for the data association and filtering (DAF) problem. The architecture is built to mimic components typically found in DAF systems to provide a sort of algorithmic prior to the network. The resulting system is evaluated on several different tasks using synthetic data.,0.1411764705882353,0.24,0.17777777777777776
670,SP:3e5e45d6810536f4e73cc6a2ba1fbf26992b20d4,The authors extend the generalized random forest by Athey et al. (2019) from partially linear models to nonparametric ones and combine it with a doubly robust estimation step. The paper contains a small scale simulation study and a small real data analysis.,"The paper proposes a generalized version of the causal forest for heterogeneous treatment effect estimation for continuous treatment by non-parametric modeling of the dose-response function. To provide non-parametric modeling, the proposed method makes use of kernel-based double/debiased estimators. Experiments of the proposed methods are run on assorted synthetic datasets as well as real-world datasets to demonstrate the effectiveness of the proposed method compared to competing methods.",0.16666666666666666,0.09722222222222222,0.12280701754385964
671,SP:3e632e5be2e41e5bb76f85ab673c8530d3e9a169,"The submission aims to develop a disentangled recommender that explicitly grants the users the ability to control a chosen aspect of the recommendation list. This is achieved by (1) learning disentangled user/item representations via beta-VAE and (2) aligning text tags with certain dimensions via an auxiliary loss (the term after gamma in Eq 2). Empirical results demonstrate that this supervised approach outperforms the unsupervised baselines in terms of disentanglement and controllability, e.g., it can explicitly control the recommender to recommend a list of romantic movies.","The paper proposes a framework to learn disentangled representations for collaborative filtering systems. To model the user-item interactions, the authors adopt the likelihood model proposed by \beta-Multi-VAE. The auxiliary task of predicting item labels is considered to increase the disentanglement and the ability to control the recommendations. Practical performance and the properties of disentanglement are demonstrated in experiments on real data sets. ",0.18181818181818182,0.24615384615384617,0.20915032679738566
672,SP:3e64cbaffc0f2c9cf7bb2d7716b50795f03fe1fa,"The paper discusses a new  data augmentation method which improves the accuracy of the network for several specific shifted domain scenarios. The main goal of the paper is to increase the robustness of the deep model trained on the augmented data to generalize well beyond the data corruption like the  rotation, translation, noise,.... For each input, they apply  $k$ different operation of image shift and make the weighted combination of them. The weight vector is generated randomly from Dirichlet distribution with the parameter $\alpha$.  The weighted combined images would be added to the original image in convex combination. The convex weights are generated from distribution Beta with parameter $\beta$. Later they train the network with adding the Jensen-Shannon divergence for the posterior distributions of augmented images as the consistency regularizer.  They show this data augmentation will increase the accuracy of the model for shifted and non-shifted domains and also it leads to more calibrated model for domain shift problem.","This paper proposes a method called AugMix, which is intended to improve model robustness to data distribution shift. AugMix appears fairly simple to implement. Several new images are created by augmenting an original image through chains of sequentially applied transformations (the ""Aug"" part of AugMix), then the augmented images are combined together, along with the original image, via a weighted sum (the ""Mix"" part of AugMix). Additionally, a Jensen-Shannon Divergence consistency loss is applied during training to encourage the model to make similar predictions for all augmented variations of a single image. This technique is shown to achieve state-of-the-art performance on standard robustness benchmarks without loss of clean test accuracy, and is also shown to improve calibration of model confidence estimates.",0.18633540372670807,0.24,0.20979020979020976
673,SP:3e69b216b8568e1ae0f25c73d45219ac3bef8a43,"This paper establishes the guarantee for the generalization of fairness-aware learning in binary classification under PAC-learning and a more practical asymptotic framework. Through the derived theorem, authors conclude that low sample size and class balance lead to the poor generalization of fairness-aware learning, and the need for a sample-efficient method is also argued. The experimental results using real data are aligned with the theorem, emphasizing the validity of theorem.","The paper provides an analysis of fairness via regularizing a loss function with a suitably selected fairness measure / metric. In particular, the paper analysis this under a PAC learning setting and a sample limit (asymptotic) setting. A majority of the paper focuses on the PAC setting, where Rademacher complexity bounds are made and analysed. Some experiments are included.",0.1917808219178082,0.2413793103448276,0.21374045801526717
674,SP:3e6d8b50675d42c92cc1c707868b029984319a4a,"This paper focuses on learning document embeddings, presenting a topic-document embedding (TDE) method employing syntactic and semantic properties by jointly learning topic and word embedding in a single framework. The proposed TDE approach follows corruption mechanism to create the global context and randomly select topic-specific word embeddings in learning document vectors, thus employing word, topic and document information in learning document vectors.  The experimental results have shown improved performed in terms of document classification, topic coherence and word embedding similarity evaluations.","Jointly learning word embeddings and document embeddings while taking into account topical information is somewhat interesting. The paper presents an improved skip-gram model where each individual word is associated with two matrices (e.g., the input projection matrix and the output projection matrix) which is designed to capture the topical aspect of words. In other words, each word is associated with K topic embeddings. While computing the predictive probability, the proposed model further considers a global context, i.e, a document embedding computed with the idea of document corruption. Basically, this paper simply combines the work of Shi et al. 2017 and Chen 2017, Both the innovation and experimental improvement are mariginal.",0.18072289156626506,0.13274336283185842,0.15306122448979592
675,SP:3e812bc034c95a7141296dd879217ce10d01065a,"Inspired by gradient-based NAS of single-path formulation, the authors propose a super-bit model, a single-path method, to decide the optimal number of quantization bits and pruning of a group of filters. While it can be a time-consuming process to study the impact of quantization of certain filters (or layers) on model accuracy, the proposed scheme finds a particular compression configuration in a trainable manner. The experimental results show that the proposed method presents higher model accuracy or lower computational cost (measured as the bit-operation count).","The paper describes the method to determine optimal quantization bit-width and pruning configuration for the neural network compression. Different from other approaches, the proposed method integrates multiple bit configurations (including pruning) into a single architecture, which is named “Super-bit”. The architecture uses binary gates to automatically select bit resolution. In addition, the super-bit model is differentiable and jointly trainable with parameters.",0.15384615384615385,0.21875,0.1806451612903226
676,SP:3e91cc255d09c478f8da733ba2f45ea40aa2da89,This paper proposes an AestheticNet and a new approach to bias-free machine learning tools. The former shows a higher Pearson correlation coefficient and a lower mean absolute error than competitive approaches. The latter helps to train an unbiased network with biased data for facial beauty prediction.,"In this paper, the authors study the problem of bias in facial beauty prediction problem. To this end, they first show that there do exist bias in an existing dataset. Then, they show that deep networks trained with such a biased dataset do capture and reflect the bias. Finally, they propose two solutions for addressing such bias.",0.19148936170212766,0.15789473684210525,0.17307692307692307
677,SP:3ed52251f2462bc5bb61c384ecafc1cce376ef26,"In this paper, the authors propose to use the *same* convolutional layer in every layer of a DNN. The network effectively is converted into repeatedly applying the same convolutional filter at multiple scales. The idea is motivated by wavelet decompositions and related work. The authors show that by repeatedly applying the same filter, the number of parameters that need to be stored for a model reduces proportionally to the depth of the network. At the same time, experimental evidence is provided that the performance of these models is not affected, when compared to the baseline (full) model. ","This paper proposes to modify a standard CNN by requiring all of its layers to share the same filter set, essentially allowing it to be expressed as an iterative (or recurrent) network.  This also has the effect of forcing the same number of feature channels to be used throughout the network.  For ResNet-like architectures with bottleneck blocks, sharing occurs at the level of the block (3 conv layers in series that are repeated).  Another variant of the sharing pattern inserts unshared 1x1 convolutional layers after shared layers or blocks; this adds some flexibility while still reducing parameters compared to standard CNNs.",0.2268041237113402,0.21568627450980393,0.22110552763819097
678,SP:3f20bfebcca1b1ff3743a3427ad44221c71e598a,"This paper focuses on the problem of goal conditioned reinforcement learning. The authors propose an alternative way of performing Bellman updates for goal conditioned value function. Specifically, the proposed method first partitions the space of state goal pairs by performing a K-means clustering, and then estimates the visitation frequency of a state goal pair to be inversely proportional to the maximum difference of Q values within the cluster. For state goal pairs with low visitation frequency, the authors construct a lower bound of the Bellman target value by finding the Q value of a near state goal pair and subtracting the Lipchitz value multiplied by the distance. The authors then use this lower bound as target value to update the Q function. To generate goals for hindsight replay, the authors adopted a skew-fit type method to the empirical distribution of the K-means clusters to sample goals for replay.","This paper developed methods for resampling from the hindsight experience replay buffer. The resampling strategy was developed based on the current policy, and the overall distribution of the relative goals. As the distribution over goals evolves over time, the multi-goal agent's replay curriculum is adjusted throughout the learning process. The developed approach, called hindsight curriculum generation (HCG), was applied to DDPG, and evaluated using a set of four robot control problems. Results show that HCG performed better than a few baseline methods, and its performance was claimed to be insensitive to the choice of hyper-parameters. ",0.13245033112582782,0.20408163265306123,0.1606425702811245
679,SP:3f2384e43d16f4b06bf238e4ce097d4e34f25ee7,"The following work presents a CLEVR-based compositionality benchmark. The task of the model is to verify logical statements about an image, and in order to achieve such, must learn how to map individual statements to a composition of functions over the image checking for color, placement, shape, etc. Specific to this dataset is that it is explicitly few-shot, which forces the models to generalize very quickly and to infer under uncertainty.","This work proposes the CURI dataset to measure productive concept learning under uncertainty. The dataset is designed using a concept space defined by a language and formulated as a few-shot meta-learning problem to tell apart in-concept samples from out-of-concept samples. The authors also design several out-of-generalization data splits that test models' ood generalization performance. Together with an oracle model, the authors show using the prototypical network that the compositional concept learning and reasoning problem in CURI is challenging.",0.1506849315068493,0.12941176470588237,0.13924050632911392
680,SP:3f293ac26fc0a4ce0f2a9845905d7f7601b172dc,"The authors propose to learn a non-parametric MDP model from batch data, which can be solved efficiently using discrete value iteration (by solving for the “core” states which are all the end-states in observed transitions) and which provides a Q-value defined over the full continuous space through a kNN lookup. There is an interesting penalty term when the estimate relies on far-away support data. The value of the optimal policy in the approximated MDP can be bounded, under some smoothness assumptions, in the original MDP.",The authors present a nearest neighbour method for learning a model offline from the statistics of the given data set. Representations are provided from other off-policy deep RL methods. Value iteration is used on top of the model to learn the final policy. The algorithm is tested in several Atari games over two data set sizes. ,0.16853932584269662,0.2631578947368421,0.2054794520547945
681,SP:3f2e132cbd2eaf710316773a3f38c84c24f23b63,"The authors try to tackle the *distribution shift* problem with a meta learning approach. The algorithm, namely ARM, is proposed. Following regular meta learning regime, ARM uses an updated version of parameter $\theta'$ to calculate the loss for back propagation. Several specific implementations are put forward, i.e. the contextual / gradient-based methods. Experiments are performed in small and large scale datasets to demonstrate the effectiveness of the proposed algorithm. Detailed ablation study and qualitative analysis are also conducted.","This paper studies domain adaptation under the assumption that only unlabeled target data is available in training and the domain shift follows a special group shift. The main idea for the proposed method is having an adaptation model that takes only the unlabeled data in and output updated parameters. The proposed method also involves the test-time training, which means the adaptation model takes in unlabeled training data in training but takes in unlabeled target data in the adaptation phase. The method is called adaptive risk minimization and there are two meta-learning approaches provided, contextual and gradient-based, in the paper. In the experiment, the proposed method outperforms a limited set of baselines. The paper also discusses a few cases when the assumption is violated like the group indicators are unknown. ",0.22784810126582278,0.13636363636363635,0.17061611374407581
682,SP:3f482ef803d5de09018a4b1f8e120320ef1622d0,"The paper presents a package for black-box optimization and is specifically designed for the optimization of experimental designs. To this end, the authors build upon multi-objective Bayesian Optimization which allows to obtain good points within a few function evaluations and also enables to obtain a Pareto-Front of non-dominated points. To have an efficient, asynchronous parallelization, the authors propose Believer-Penalizer for choosing the next point while others are still being evaluated. The main idea is to choose either Kriging Believer (KB) and Local Penalization (LP) based on a threshold on the uncertainty in the posterior distribution of the probabilistic surrogate model. In the experiments, the authors show that their package achieves often a fairly good performance.","In this paper, the authors present AutoOED, an open-source platform for efficiently optimizing multiobjective problems (MO) with a restricted budget of experiments. The platform automatically guides the design of experiments to be evaluated. AutoOED is built upon multi-objective Bayesian optimization (MOBO).  To accelerate the optimization in a time-efficient manner, the authors propose a strategy called Believer-Penalizer (BP) that allows batch experiments to be accelerated asynchronously without affecting performance. The authors also provide a graphical user interface (GUI) for users to visualize and guide the experiment design intuitively. Finally, we demonstrate that AutoOED can control and guide real-world hardware experiments in a fully automated way without human intervention. Finally, the authors demonstrate that AutoOED can control and guide real-world hardware experiments in a fully automated way without human intervention. ",0.225,0.20149253731343283,0.2125984251968504
683,SP:3f9266d190e590b01625de888376769d59737d81,"This paper provides a generalization of AGD to constant sectional curvature spaces (or subsets of them), and proves the same global rates of convergence that hold in the Euclidean space. Additionally, they provide reductions for the bounded sectional curvature case. Their basic strategy involves the use of geodesic maps to accumulate local linear lower bounds, in a way that accounts for the geometric distortion incurred by the map.","This paper considered the problem of minimizing (strongly and non-strongly) geodesically convex functions on hyperbolic and spherical manifolds, manifolds of constant curvature 1 and -1, respectively, and proposed accelerated algorithms for such problems. In particular, the author(s) showed the proposed algorithms enjoy global accelerated rates that match their Euclidean counterparts. A key to the main result is Lemma 2.2 which asserts a certain quasar convexity-type condition of the pull-back of the objective function to some Euclidean domain through a geodesic map. Based on this lemma, the main result follows from combining techniques for developing accelerated algorithms in Euclidean space, such as the approximate duality gap technique and a certain discretization scheme for continuous dynamics. Some reduction results, which obtain accelerated algorithms for the strongly convex case from the non-strongly convex case, and vice versa, are also presented.",0.29411764705882354,0.13986013986013987,0.18957345971563985
684,SP:3fb778bf2a70b808044c4cd4be288a4d1a9a3465,"This work addresses the question about how pre-trained language models encode semantic information. It adapts the methodology proposed in Hewitt & Manning (2019) for syntax to semantics, using the WordNet structure instead of a syntactic structure of a sentence to encode distances among word representations. The paper analyzes how embedding models encode suitable information to recreate the structure of WordNet. The study also shows evidence about the limitations of current pre-trained language models, demonstrating that all of them have difficulties to encode specific concepts."," The authors conduct a study investigating how different language models incorporate semantic information in their respective learned representations. Investigating language models on their performance in concept-level tasks is motivated by the importance of the ability to organize and understand concepts in human intelligence. Another motivation is that other studies on the semantics in language models are not conclusive according to the authors, especially in determining where the semantic knowledge lies within the language models. ",0.21176470588235294,0.24,0.22499999999999998
685,SP:3fb88680c58847e0dff0263cbf7ab555e18647d7,"This paper proposes an asynchronous decentralized learning protocol. The motivation is to remove the need for computation nodes to synchronize broadcasting their local models (e.g., to a server), which improves efficiency and brings the setting closer to practical scenarios. The main contributions include (1) an event indexing system; (2) an projection scheme to ensure weight aggregation does not exit the feasibility region; (3) an instantaneous averaging scheme that aggregates neighboring models as soon as each node goes idle and (4) a regret bound analysis.","This work considers decentralized online learning in the asynchronous setup. Precisely, the learners do not make predictions at the same time and both the local updates and message transmissions incur delays. To account for this situation, the authors propose to index the time by two types of events: predictions and updates. Under this framework, an asynchronous push-sum algorithm is studied and its regret bound is established. The experiments do not only demonstrate the benefit of asynchronous method but also investigate several design choices of the algorithm.",0.17647058823529413,0.1724137931034483,0.1744186046511628
686,SP:3fc873bd47448de58d54f7def16a1ddb7df613b8,"This paper performs an empirical analysis of the heavy-tailedness of the PPO gradients across MuJoCo environments. They find that PPO gradients are heavy-tailed, which means that they are sensitive to outliers, which means computing the expected gradient is hard. The paper studies two causes of this issue -- advantage estimation errors and the harm caused by optimizing density ratios in a sampled setting, and shows that removing either of them with the other issue controlled for helps PPO. They then propose to use a standard robust mean estimation technique to obtain a robust gradient mean estimator that is plugged into PPO, and performs sort of somewhat worse than vanilla PPO. ","This paper presents an intriguing analysis of the gradient distributions over the course of training for popular RL algorithms in common mujoco benchmarks.  The observation that negative advantages are a bigger contributor to the kurtosis than positive advantages seems interesting and if true as a general phenomenon, deserving of more understanding. The authors also propose a new alternative (inspired by robust statistic) to the simple PPO clipping heuristic that does reasonably well even if it doesn't deliver any clear improvements over PPO.",0.1981981981981982,0.26506024096385544,0.2268041237113402
687,SP:3fc909ff04f888517dc1b7fdfad3ca019ead54b5,"This paper develops a modified version of FedAvg by local batch normalization that is tailored for federated learning with non-i.i.d. data. Different from most of existing work that consider the unbalanced labels, this paper uses unbalanced features to motivate the non-i.i.d. federated settings. Specifically, the unbalanced features are captured by the difference in local covariances. ","This work proposes an extremely simple approach to a well-know problem within Federated Learning: batch normalisation. Indeed, FL usually imply an averaging of different model parameters trained on different distributed devices. But what happen with the running statistics that some training methods have ? Such as batch norm and some optimisers ? Well, this work proposes to address the first issue by introducing a specific batch norm method named Local Batch Normalization (FedBN). Standard BN statistics cannot simply be aggregated due to strong variations potentially occurring when training data across the clients aren't IID distributed (i.e strong shift in the input representation). To alleviate this issue, the authors propose to exclude the BN parameters from the aggregation (i.e. each client has its own BN excluded from FL). ",0.21311475409836064,0.10077519379844961,0.1368421052631579
688,SP:3fde6f1c7155da227b3583e6670900e74ecd0afc,"This paper introduced a well-grounded framework for uncertainty estimation on interdependent nodes. This paper first proposed explicit and motivated axioms describing desired properties for aleatoric and epistemic uncertainty in the absence or in the presence of network effects. Then it proposed GPN, a GNN for uncertainty estimation which provably follows our axioms. Furthermore, extensive experiments was conducted to evaluate the uncertainty performances of a broad range of baselines for OOD detection and robustness against node features or edge shifts. GPN outperforms all baselines in these experiments.","In this paper, the authors proposed a graph posterior network based on the uncertainty theory to enhance the node classification in graph learning. The uncertainty estimation based on the interdependent node inputs instead of assuming i.i.d inputs is interesting. Through theoretical analysis and experiments on 8 data sets, they claim that the proposed framework has advantages in node classification and OOD detection.",0.16091954022988506,0.21875,0.18543046357615892
689,SP:3fed87e29b3609f6d356dafce16be061a85471ab,The paper provides a baseline method that generates a dataset of high+low res precipitation maps. The paper argues that precision of weather event predictions depend on the imagery resolution and hence having high res maps will lead to better weather prediction.  The eventual dataset that is formed contains a variety of diverse climate events like hurricanes etc and the pair of high/low res forms the necessary annotation. ,"This paper proposes a dataset called RainNet for studying precipitation downscaling. RainNet consists of ~62k pairs of low-res/high-res precipitation maps from various meteorological events over the east coast of the US over 17 years. This dataset was created from two existing products: NLDAS and the NCEP's Stage IV 4km gridded precipitation data. Further, the paper proposes two metrics, Precipitation Error Measure (PEM) and Precipitation Dynamics Error Measure (PDEM). Finally, the paper compares several superresolution methods from computer vision literature, traditional statistical approaches to downscaling, as well as the proposed architecture/method on the proposed dataset to form a set of benchmark results.",0.2463768115942029,0.16037735849056603,0.19428571428571428
690,SP:4015789338b07b5dab3e4eaf542d5b0b7aaba267,"In this paper, the authors propose a novel token-pooling method to reduce redundancies in tokens for recent vision transformers. They analyze the computation cost distribution of vision transformers and the limitations of grid-based & score-based token downsampling methods. They further formulate a reconstruction loss and optimize it with the token pooling layer. The experimental results based on DeiT show that token pooling improves accuracy while reducing computation cost by a large margin. This idea can be applied to other vision transformers as well.","This paper proposes a new token downsampling method for vision transformer, called Token Pooling, to prune redundant tokens efficiently, so as to achieve a better flop-accuracy trade-off. Specifically, token pooling is a nonuniform data-aware downsampling method, which uses cluster algorithms to aggregate information from tokens automatically. To keep important information, the authors also proposed minimizing the reconstruction loss caused by downsampling. The authors performed experiments on the ImageNet-1k dataset, showing that the proposed token pooling can significantly improve the flop-accuracy trade-off over the existing downsampling methods.",0.21176470588235294,0.1956521739130435,0.2033898305084746
691,SP:4045aeb245ca2e1341b85397e81090d9f99217cf,"This article introduces a learner-evaluator framework that incorporates the different variations of problems related to incremental learning. It also proposes a method called Continual Prototype Evolution for dealing with the most general version of the problem, incremental learning on data streams, in which the learning task is not specified. The paper presents an extensive amount of experiments indicating that in this scenario, the proposed method improves significantly on existing approaches in terms of accuracy and memory efficiency. The article is well organized, easy to read and understand.","This paper covers an interesting topic of continual learning of the stream of data. One limitation of the existing classification algorithms is their close-set assumption. In close-set methods, a predefined set of classes are considered and a model is trained on the available data from these classes, based on the assumption that test data will be driven from a similar distribution as the training data. However, most of the real-world problems are open-set problems. Open-set models should be able to learn continuously in an online manner with minimum or zero supervision. In other words, they should be able to learn new classes or update the existing classes based on the received new data on-the-fly, without forgetting the previously learned knowledge.  ",0.17045454545454544,0.11811023622047244,0.13953488372093023
692,SP:40701460d7ed2175ff193b228f93af7d50911267,"This paper presents semi-supervised keypoint localization networks and loss functions to overcome the need for the labeled keypoint data for that task. It simultaneously generates keypoint heatmaps and pose invariant keypoint representations, where these representations were separately used to enforce translation equivariance, and translation invariance, and semantic consistency, respectively. The proposed method attains the improvement on several benchmarks for human and animal body landmark localization.","The paper presents an approach to keypoint localization (to retrieve people/animals pose) combining labeled and unlabeled data. Features are extracted and concatenated into a single descriptor per keypoints, by multiplying feature maps and heatmaps and max-pooling over the spatial domain, and used for semantic classification. Images are transformed with simple perspective augmentations. The non-supervised part comes in enforcing that keypoint representations for unlabeled images remain close.",0.19696969696969696,0.18840579710144928,0.1925925925925926
693,SP:407fd895712f394b12b56e886901748270d11bd3,In this work the author focus on transfer in RL via proposing to transfer knowledge through behavior instead of representations. They propose using coverage as an objective for the pre-training procedure. They then employ the NGU (Badia 2020) They also propose a method based on coverage pre-training for transfer and provide empirical evidence in support of their method for transfer in RL on the Atari suite.  ,"This paper proposed a transfer approach for reinforcement learning. The proposed approach leverages a policy pre-trained via Never Give Up (NGU) approach, and can facilitate learning challenging RL tasks including the ones with sparse reward. This paper presents many strong pieces of evidence that this approach can be used to tackle challenging RL problems including hard exploration and multi-task learning. ",0.1323529411764706,0.14516129032258066,0.13846153846153847
694,SP:408820218c984f610c311c44957499cf7744beea,"In their abstract, the authors claim to provide state-of-the-art perplexity on Penn Treebank, which is not true. As the authors state, their notion of ""state-of-the-art"" excludes exactly that earlier work, which does provide state-of-the-art perplexity on Penn Treebank (Yang et al. 2017), as stated in Sec. 4.1. The question is, why one would exlude the mixture-of-softmax approach here? This is clearly misleading.","This paper proposes an additional loss term to use when training an LSTM LM.  The authors argue that, intuitively, we want the output distribution to retain some information about the context, or ""past"".  Given this, they use the output distribution as input to a one layer network that must predict the current token.  The loss for this network is incorporated as an additional term used when training the LM.  The authors show that by adding this loss term they can achieve SOTA (for single softmax model) perplexity on a number of LM benchmarks.",0.16216216216216217,0.12903225806451613,0.1437125748502994
695,SP:40a3502f03e9bef04f4f8c088e6b7dcb768846da,"This paper studies a novel problem setup where a learner has unbalanced data, and a service provider has complementary or sufficient data, and the learner needs to improve accuracy in as few rounds of communication as possible, where the communication in each round is unbounded. An algorithm AssistSGD is proposed and shown to converge to a stationary point. Experiments show that AssistSGD has better performance than baselines and is close to centralized SGD on CIFAR 10 and reinforcement learning tasks,","This paper investigates a novel learning scenario, where the learner has limited access to the global data distribution and can share learned model parameters with a so-called service provider through multiple (but limited) rounds of interactions. The motivation is interesting and seemingly useful for the scenarios described in the introduction. The authors propose an intuitive assisted learning framework applicable to both (deep) supervised learning and reinforcement learning, and experiments show that the proposed algorithms achieve comparable performance with learning from centralized data. However, there are a few concerns/ questions in the problem setup and the proposed assisted learning protocol, please see the detailed review below.",0.3125,0.2358490566037736,0.26881720430107525
696,SP:40aeb37eea243288569e41cdd3100403021fc866,"In this paper, they introduce relational multi-task learning in which they construct a graph with the data points and task and labels as edges. They represent the data points as the embedding of NN model and task as the last layer of NN model for that task. Then they solve the link label prediction problem between each node and task by using GNN and heterogeneous message passing method to predict the label of test data point on a new task at inference time.","The paper exploits the multi-task modeling using a heterogenous Graph Neural Network. The key contribution of the work is having both data (sample) and task nodes in the same graph, focusing on data-task relation, accommodating for sparse task labels by design.  Experimental results show relevant improvements with the proposed relational model on biomedical datasets and Imagenet splits for few-shot. ",0.20238095238095238,0.27419354838709675,0.2328767123287671
697,SP:40e4749c3e5c57e12a6c540510b74ae3551e479a,"This paper proposes a prior distribution over covariance matrices of kernels which is defined as a sequential graphical model where each variable is Wishart distributed and its scale matrix is a non-linear transformation of its predecesor variable on the graph. The paper begins by considering a DGP with isotropic kernels across the layers and realizes that the Gram matrices are Wishart distributed. Based on this, the paper proposes to bypass the inference of the features and sample the Gram matrices directly from Wishart distributions. This insight, in addition to the layered structure of DGPs, gives rise to the proposed prior distribution. Furthermore, given the restrictions of the Wishart distribution for modelling covariance matrices of arbitrary size [1], as well as the conjugacy properties of the inverse Wishart distribution, the paper uses the inverse Wishart distribution instead. Doubly stochastic variational inference is proposed for approximating the posterior distribution which includes the use of inducing points thanks to the marginalization properties of the inverse Wishart distribution. The experimental contribution consists of a comparison against DGP and Neural Network GP on the UCI, MNIST and CIFAR-10 dataset.","This paper proposes deep kernel processes (DKPs), which can be viewed as a specific kind of deep Gaussian processes where the kernel can be written as a function of the Gram matrix. The features in the intermediate layers are integrated out and the Gram matrix are Wishart distributed. A doubly stochastic variational inference method is proposed to learn DKPs. The idea looks novel to me. My major concern is about the writing.",0.15053763440860216,0.3888888888888889,0.21705426356589144
698,SP:40e6f3c9b45c37a5580314fde5407e7ceab19fa9,"The paper studies threat models for images which take into account the foreground and background within the image. Specifically, they use DeepGaze II to identify pixels as either foreground or background, and use an Lp threat model with a larger radius in the background and a smaller radius in the foreground. The results are largely what one would expect: defenses for different threat models perform poorly against this attack, in comparison to adversarial training on adversarial examples generated by the attack. These attacks have good foreground score, though this is according to the same DeepGaze II model used to generate the examples to begin with. ",I like the idea to check whether it might be possible that noise can be injected selectively in areas where it is likely to make the adversarial example less suspicious and thus it might be possible to inject more noise in those directions. But the challenge is that this might increase the saliency of those areas. The authors propose to use recent work from DeepGazeII to detect saliencies of various pixels.,0.11428571428571428,0.16901408450704225,0.13636363636363638
699,SP:40ed38eb25d29057685c22a2118da3f7d269535b,"This paper sheds light on the impact of nondeterminism to the run-to-run variability of neural network performance---a situation many people using neural networks have experienced. The authors establish an experimental strategy to analyze the different sources of nondeterminism. Some sources of nondeterminism are parameter initialization, data shuffling, data augmentation, regularization and cuDNN.","The paper investigates the effect of nondeterminism and stability in Neural Networks (NNs) for supervised learning tasks in a systematic manner. The paper is very well-written. All the steps towards the claims of the paper are clearly stated. The empirical analysis is systematic and the two main results are thought provoking and interesting: 1) Different sources of nondeterminism (such as random initialization, data augmentation, data shuffling, etc.) causes similar levels of variability (based on standard deviation and correlation metrics), and 2) Changes in the optimization even in the order of 10^-10 in a single weight can have same variability level as changing the random seed entirely. The paper also validates that a prior work called Snapshot Ensembles (to some degree) resolves the instability problem in NNs.",0.2909090909090909,0.125,0.17486338797814208
700,SP:4113fc49197e2f7904f2ede5bda27d5d9dd6bc0e,"The paper proposes a method for federated learning of a mixture of experts model (FedMix). The approach allows training an ensemble of models each of which specializes to a subset of clients with similar data characteristics. The authors argue that this way of training an ensemble reduces the gradient divergence/interference, improves the overall performance, and sometimes reduces the communication overhead. The new method is evaluated a few federated image classification datasets.","The paper proposes a novel algorithm, which is a federated form on mixture of experts, called Federated Mixture of Experts (FedMix). In FedMix, an ensemble of specialized models is trained instead of a single global model. This strikes a compromise between training a single global model and one model per client. A gating mechanism is employed, to choose an expert model that is responsible for a given data point, thus aligning the gradient updates across experts and alleviating the consequences of non-i.i.d. data.",0.3194444444444444,0.26744186046511625,0.29113924050632906
701,SP:41235400cab3254a3d5036ccc826427024412655,"As the title suggests, this paper gives algorithms for learning mixtures of $k$ Gaussians to within total variation distance $\alpha$. It uses a reduction to private list decodable learners from privately learning mixtures of distributions. The number of samples used is linear in $d$ and quadratic in $k$. The flow of the paper is as follows: first it gives algorithms for estimating mixtures of univariate Gaussians, then uses them to estimate mixtures of axis-aligned Gaussians. The main, non-trivial prior tool used in this paper is the private hypothesis selection algorithm. The algorithm for estimating mixtures of univariate Gaussians first involves creating a list-decodable learner for univariate Gaussians, followed by using the aforementioned reduction.","This paper considered the problem of learning a mixture of gaussians under DP constraint. The authors proposed an (exponential time) algorithm for learning univariate k-mixture of gaussian distributions with sample complexity k^2log^(3/2)(1/\delta)/alpha^2eps. They conjectured the extra k factor in the sample complexity is information theoretically unnecessary. The key of the algorithm is a reduction from the list-decodable learning to learning mixture distributions. Specifically, given a list decodable algorithm, one can enumerate all possible combinations of the k-mixtures and use a private hypothesis selection algorithm to find the most plausible k-mixture. They proposed a list decodable algorithm for learning gaussian distribution, which adopts a similar approach as [48].   For the multivariate gaussian setting, they considered the axis-aligned gaussian setting. They first obtain a list of distribution on each dimension, and take all possible combinations of the univariate distribution to form a large list of axis aligned gaussians. This leads to a multivariate gaussian k-mixture learning algorithm with sample complexity k^2dlog^(3/2)(1/delta)/alpha^2eps. ",0.25,0.16201117318435754,0.19661016949152543
702,SP:4140a212888e058dc1f0bfaa5233f54e9d87fcee,"This paper proposes training losses, unlikelihood objective, for mitigating the repetition problem of the text generated by recent neural language models. The problem is well-motivated by evidence from the existing literature. Specifically, the paper argues that the main cause of the degenerated output is the maximum likelihood objective commonly used to train language models. Their main contribution is to introduce additional objectives to penalize “unlikely” word probabilities. The proposed penalty is derived into 2 objectives: token level (previous words in context) and sentence level (future decoded words). The prior objective is used along with the MLE, while the later and more expensive is used for fine-tuning. They perform experiments on Wikitext-103 and evaluate models on the perplexity of the models, and n-gram statistics such as repetition, and uniqueness of the decoded texts. The proposed training scheme (UL-token+seq) is shown to have the closest statistics to the original corpus while the perplexity slightly suffers. The additional manual analysis shows that human annotators prefer the outputs (sentence completion) of the proposed method over the other baselines.","The main contribution of this paper lies in the proposed unlikelihood training objective for open-ended text generation. The key idea is to enforce the unlikely generations to be assigned lower probability by the model. Both token and sequence-level unlikelihood training objectives are provided. Impressively, the authors show that models trained with the proposed method can generate high-quality text via only beam search, without using top-k, nucleus sampling, or beam blocking methods. ",0.1111111111111111,0.26666666666666666,0.1568627450980392
703,SP:41438e8d8c46ffaeb4ff56cb6d3228c9e7c58372,"  The paper proposes a new state of the art in planning-based approach   to Atari game.  The paper carefully analyses existing work, including   $pi$-IW+ which uses both value and policy functions, and fixes several   incorrect decisions that qualitatively does not make sense, such as   mixing up the estimate for the base and the critical path policy.    Perhaps what I would ask the authors is the way the paper is written:   The current text is not written in the style of ""They do X which has   this issue; therefore we do Y"" --- issue-focused description, but in   the style of ""We do Y; X does this; X is problematic"".  For example,   Sec 4.2 could be titled as ""Addressing the complex novelty definition   in RIW"", or ""Simplifying the novelty; depth-based novelty is not   necessary"".    The algorithm also has a mechanism inspired by AlphaZero, which   resembles active-learning (section 4.5), which compares the old and   the updated parameters.  Following up work should more carefully   evaluate this mechanism as an active-learning scheme.    Its second contribution is the proposal of a standard evaluation   scheme, which is now an adequate proposal due to the recent   improvement in the field.    The proposed algorithm is carefully evaluated empirically,   characterizing the sparseness and the branching factor.    This is a solid paper that I recommend for acceptance. ","This paper introduces a novel width-based algorithm, RIW+CPV, for playing Atari 2600 games. RIW+CPV is based on RIW, an algorithm that performs a depth-first search while pruning nodes according to IW's novelty metric and it guides the search with a base policy (later works showed how to learn such a base policy). In addition to the base policy, RIW+CPV learns a value function that is used to evaluate the leaf nodes of the lookahead tree RIW expands before deciding on the action that will be applied in the environment. Empirical results show that RIW+CPV achieves higher scores on a larger number of games than other IW-based methods for Atari 2600 games. ",0.0990990990990991,0.18487394957983194,0.12903225806451613
704,SP:417f7538cb0067ef717416f886a041d66b88f015,"The paper presents a method for combining the Companion Cognitive Architecture with BERT for the purpose of discovering new Cyc-style common-sense facts. By using BERT at relevant points in the Companion pipeline, the paper achieves a significant performance improvement over an end-to-end T5 model. In particular the BERT network for filtering facts proposed by the cognitive systems results in a huge jump in precision from 46 to 71. ","This paper presents an approach for augmenting a knowledge base with general knowledge facts by extracting them from text. The system parses new sentences, converts them into semantic relations, ties them to the existing knowledge graph to compute a connectivity with the current knowledge base, and uses BERT to evaluate plausibility. An experiment shows that the precision of the proposed system in extracting facts is quite high, higher than the baselines.",0.18055555555555555,0.18309859154929578,0.1818181818181818
705,SP:41867edbd1bb96ff8340c8decefba2127a67dced,"The paper proposes a model building off of the generative query network model that takes in as input multiple images, builds a model of the 3D scene, and renders it. This can be trained end to end. The insight of the method is that one can factor the underlying representation into different objects. The system is trained on scenes rendered in mujoco.","The paper presents a framework for 3D representation learning from images of 2D scenes. The proposed architecture, which the authors call ROOTS (Representation of Object-Oriented Three-dimension Scenes), is based on the CGQN (Consistent Generative Query Networks) network. The paper provides 2 modifications. The representation is 1. factorized to differentiate objects and background and 2. hierarchical to first have a view point invariant 3D representation and then a view-point dependent 2D representation. Qualitative and qualitative experiments are performed using the MuJoCo physics simulator [1] (please add citation in the paper).  ",0.22580645161290322,0.15217391304347827,0.1818181818181818
706,SP:4187dfac4b5cc4b526eda88dc007ff1cd0ca77e6,"In this paper, authors proposes an algorithm to use Dirichlet prior on the variational auto-encoder (VAE). They used this prior as natural conjugate to likelihood distributtion of multinomial (categorical). The paper proposes a way to use scalability power of VAE for data distributed by categorical distribution. In order to apply reparametrization trick, authors have used iid Gamma random variable to construct draw from Dirichlet distribution and have used approximation with inverse gamma CDF,  it is discussed how this method has better performance than other approximations method for gamma distribution such as Weibull and logistic Gaussian.",This paper proposes to change the typical Gaussian posterior distribution (and prior) for the latent features z associated to an image x that is used in Variational Autoencoders by a Dirichlet distribution. The work improves over previous attempts based on a soft-max + Gaussian distribution and the soft-max + Weibull distribution. The trick proposed to make feasible training the model includes approximating the inverse CDF of the gamma distribution and using the fact that the Dirichlet distribution can also be obtained as a normalized sum of gamma random variables. The method is compared in several problems. Some analysis of the reasons why it performs better is also carried out.,0.17708333333333334,0.1559633027522936,0.16585365853658537
707,SP:4195e5d68282c690d91bded806f793ae85c9d355,"This paper presents a (meta-)solver for particular program synthesis problems, where the model has access to a (logic) specification of the program to be synthesized, and a grammar that can change from one task instance to another. The presented model is an RL-based model that jointly trains 1) the joint graph-based embedding of the specification and the grammar, and 2) a policy able to operate on different (from instance to instance) grammars. Interestingly, not only can the model operate as a stand-alone solver, but it can be run as a meta-solver - trained on a subset of tasks, and applied (with tuning) on a new task. Experiments show that the model outperforms two baselines (one being a (near-to-)SOTA model) in the stand-alone setting and that the model successfully transfers knowledge (considers fewer candidates) in the meta-solving mode.","This paper presents a reinforcement learning based approach to learn a search strategy to search for programs in the generic syntax-guided synthesis (SyGuS) formulation. Unlike previous neural program synthesis approaches, where the DSL grammar is fixed or the specification is in the form of input-output examples only, the SyGuS formulation considers different grammars for different synthesis problems and the specification format is also more general. The main idea of the approach is to first learn a joint representation of the specification and grammar using a graph neural network model, and then train a policy using reinforcement learning to guide the search with a grammar adaptive policy network that is conditioned on the joint representation. Since the specifications considered here are richer logical expressions, it uses a SAT solver for checking the validity of the proposed solution and to also obtain counterexamples for future rewards. The technique is evaluated on 210 SyGuS benchmarks coming from the cryptographic circuit synthesis domain, and shows significant improvements in terms of number of instances solved compared to CVC4 and ESymbolic baseline search techniques from the formal methods community. Moreover, the learnt policy is also showed to generalize beyond the benchmarks on which it is trained and the meta-solver performs reasonably well compared to the per-task out-of-box solver.",0.27586206896551724,0.1834862385321101,0.22038567493112948
708,SP:4196105314347c2b726f72052176f48af6168562,"This paper studies the problem of iterative machine teaching with a focus on synthesizing the labels.   Specifically, the authors deal with the white-box (w* is known, the target parameter) and black-box teaching settings (w* is unknown). For the white-box setting, the authors propose a simple greedy teaching algorithm LAST, which is myopic. To incorporate the long-horizon information, the authors further present two methods: 1) unrolling the gradient steps and 2) learn a teaching policy with RL. These two methods are also applied to deal with the black-box setting.   For the theoretical analysis, the authors cast the effect of label synthesis/teaching as smartly tuning the learning rates, which also enjoys the exponential teachability under the convex and Lipschitz assumptions on the loss functions.   Empirical results show that the proposed methods are effective and require fewer iterations to converge than standard training (SGD).","This paper proposes to address the sequential machine teaching problem by synthesizing labels. The proposed method is termed LAST. LAST avoids the expensive data selection and still provably improves the convergence of the learner. Specifically, LAST considers two types of teacher models: greedy teacher and parameterized teacher. For the parameterized teacher, the paper proposes unrolling and policy gradients to learn it. The theoretical justification is thorough and convincing. The experiments are comprehensive and well designed. They cover almost every setting one can think of. The empirical performance shows sufficient gains to support the major argument that LAST can effectively improve convergence.",0.1836734693877551,0.26732673267326734,0.217741935483871
709,SP:419fb7e10620ee111ec8b30ec69252d67244aac8,"The authors tackle out-of-distribution detection without requiring additional detailed labels by leveraging the recent advancements in self-supervised methods combined with Mahalanobis distance metrics in feature space. They find that their approach matches or slightly outperforms supervised baselines, and widely outperforms other unsupervised approaches. They also consider a few-shot version of the task and extend their method to take advantage of supervision when available.","The paper addresses the OOD problem without learning from class labels. It proposes to learn the feature representation with unsupervised learning, then applies Mahalanobis distance to measure how far a test data is away from the in-distribution data. The proposed framework also considers the cases of when class labels or OOD data are available. The experiments on image datasets (mainly cifar-10/100) demonstrate its advantage over other unsupervised OOD methods.",0.19402985074626866,0.18055555555555555,0.1870503597122302
710,SP:41c25734f6ea2aa0669893eb6ddfc355f4998b6b,"This paper studies the problem of PAC learning an axis-aligned rectangle in d-dimensions under the constraint of differential privacy (DP). The class of d-dimensional axis-aligned rectangles can be viewed as a generalization of threshold functions. Previous work have shown that the problem of privately learning thresholds is equivalent (up to constants) to the problem of privately selecting the interior point of a set of totally ordered points. A naive approach to extend this result to high-dimensional rectangles is to compute the threshold in each dimension separately and then use advanced composition. Unfortunately the dependence of the samples complexity of this approach on the dimension is $d^{1.5}$ (rather than $d$). Therefore, this problem captures one of the main technical challenges of designing DP methods, namely handling high-dimensional data.   The authors introduce a carefully constructed algorithm that applies the private interior point algorithm on each dimension, but at each step prunes some points in the dataset so that they are not used in future steps. Intuitively, this approach allows them to overcome the expensive advanced composition since not too many points will be reused. [and as a consequence, the resulting method has only linear dependence on $d$]","This paper studies the problem of privately learning an axis-aligned rectangle. In private learning, the goal is to approximate an unknown target function while leaking little information about individual training samples. More formally, the learning algorithm is required to be differentially private in the sense that for any two training sets differing in a single training sample, the distributions of the output target functions on the two data sets are (eps,delta)-close in the standard differentially private notion.  Previous work on this problem includes a learning algorithm with sample complexity O(d^1.5 (log* X)^1.5) and one with O(d log X) when the rectangles comes from a d-dimensional grid X^d. Here the dependency on eps, delta and the accuracy of the learned hypothesis has been hidden from the bound, but is polynomial in eps and the accuracy and polylogarithmic in delta.  It is known from a lower bound side that the sample complexity must depend on log*X and grow linearly with d. The goal of this submission is to derive a learning algorithm with samples depending linearly on d and as o(log X). This is achieved by presenting an algorithm needing O(d (log*X)^1.5) samples, thus shaving a sqrt(d) factor (or a logX/log*X factor) from previous work.  The main idea in the algorithm is to use a subroutine for the Interior Point Problem to find a point close to the edges of the rectangle learned. Formally, the IPP asks to output a point lying between the minimum and maximum point in a one-dimensional data base with domain X. This can be done privately with O((log*X)^1.5) samples, ignoring the dependency on eps and delta. The basic idea is to pick the outermost 100n+noise points that lie inside the rectangle along each axis. From these, the n points closest to the interior of the rectangle are selected and the IPP algorithm is run on them to output a point with i'th coordinate inside the rectangle and close to the border.",0.27586206896551724,0.15954415954415954,0.20216606498194944
711,SP:41db1e50777ea9db3c15ce7d62a2fc50925abe5b,"This paper presents a method to reduce the bandwidth required to update DNN models on edge devices.   The key insight is that model updates typically incorporate new data (training samples), and that after doing so, a minority of weights capture the majority of change due to retraining.  The authors propose a method by which to identify this weight subset, and compare the relative size (and test accuracy) of that update to that of other solutions (such as sending the entire network or sending a random subset of the weights on each retraining round).  Experiments with a number of existing data sets and models illustrate that the approach reduces update size more than 77% while maintaining reasonable test accuracy. ","In this paper, the authors have proposed a new approach to determine the optimized subset of weights instead of simply conduct full weights updating. In order to better update the weights, they measure each weight's contribution to the analytical upper bound on the loss reduction from two sides (global and locally). After evaluation, a weight will be updated only if it has a large contribution to the loss reduction given the newly collected data samples. The experimental results show that their method can achieve a high inference accuracy while updating a rather small number of weights. ",0.1694915254237288,0.20618556701030927,0.18604651162790697
712,SP:41de1f1971e860acdbb74dcd266fd308c035b47b,"This work proposes a new environment, Read to Fight Monsters (RTFM), and correspondingly a new algorithm, txt2\pi, for solving this problem. The RTFM requires the agent to read a description of the rules (x beats y, etc) and a description of the goal (to eliminate y), and perform the task correctly to win the game. The txt2\pi algorithm uses the newly proposed FiLM^2 module and consists of integrating the visual input (grid world configuration) and the text input (descriptions) to learn a policy and baseline (actor-critic). ","This paper constructs a new game that requires combining visual reasoning with text understanding to win.  The authors propose a new model txt2π, based on a new layer called FiLM², which combines text and visual features in a way that allows visual features to be encoded with knowledge of the text features (as in the FiLM layer from previous work), as well as text to be encoded with knowledge of the visual features. The model is trained to play the game using IMPALA.  Ablation studies show that the FiLM² layer leads to a substantial improvement, and also shows the necessity of curriculum learning.  Performance is still below human performance suggesting this is a promising area for future work.",0.24444444444444444,0.1864406779661017,0.21153846153846156
713,SP:41e70121223317279d2026514d8e786cf22a4aaf,"This paper proposes a novel approach for the loss function of matrix completion when geometric information is available. The proposed method consists of two ideas: (1) spectral regularization (i.e., Dirichlet energy) with a re-parameterizing basis and (2) multiresolution of spectral loss (i.e., zoomout loss). In addition, the zoomout loss is motivated by the approach for shape correspondence and can be a generalization of the recent matrix completion method (deep matrix factorization). Empirical results show the best performance compared to other recent methods under small-scale datasets. Moreover, the proposed method outperforms when the geometric model is accurate (verified on the synthetic setting) and this can reflect that the proposed method is a good choice when the graph structures are given.","This paper aims to solve the matrix completion problem by incorporating geometric information. The proposed approach involves using graphs encoding relations between rows (and columns), applying spectral decomposition to these graphs, and using a multi-resolution spectral geometric loss to reconstruct the functional map which could then be used to directly recover the underlying matrix. The paper evaluates the proposed network on both synthetic and real datasets and shows improvements over the existing geometric methods and convex relaxations.",0.1951219512195122,0.3076923076923077,0.23880597014925378
714,SP:41f2c5e8a9a38a38a14436b57ba124e1b69ff3d2,"The idea of using neural networks to approximate the solutions of the pdes is very interesting, specially in high-dimensional setting where classical approaches fail to scale. Although there has been many efforts in this direction, there are still open venues to explore. One of the most important aspect is the choice of loss function to guide the training of the neural network. And the paper's aim is to address this issue by proposing Sobolev norm as the loss function instead of the commonly used $L^2$-norm. The Sobolev norm includes additional term about derivatives of the error. The main claim is that with the inclusion of the additional term, the convergence of the neural network training becomes faster. This is the basic promise of the paper.  ","Sobolev training of neural networks, which augments the standard loss function with terms that penalize discrepancies between the derivatives of the network and target functions, has been shown empirically to improve data-efficiency. Intuitively, one would expect that it also aids generalization in settings where the target function is sufficiently smooth. This manuscript proposes augmenting the loss functions used to represent the solutions of partial differential equations with terms penalizing the Sobolev norm of the solution, its initial condition, and the boundary condition. The motivation for this approach is clear because data -efficiency is of the utmost importance in PDE learning problems where the data could be very difficult to access. ",0.2248062015503876,0.26126126126126126,0.24166666666666667
715,SP:41f31c90b20a96ab6e645a42f9767fdab23f07d8,"This paper focuses on the problem of causal structural learning from heterogeneous populations, where the label or index of the population is unknown. The main contribution of this paper is on developing a distance covariance-based kernel to measure the similarity between the underlying nonlinear causal structures of different samples, so that we can first perform clustering to identify the homogeneous subpopulations and then use existing methods to learn a causal structure for each of these subpopulations. The proposed method is tested on genetic data. ",Paper proposes a new distance covariance based kernel for causal clustering of heterogenous population data. It presents theoretical results  on how kernel it can be used as a two-sample statistical test for causal data and induces a metric space on ancestral graphs. Empirical results show leaned causal graphs for gene expression data.,0.16470588235294117,0.2641509433962264,0.20289855072463767
716,SP:41f62bc0a7b3a9d4debaa2b1345538727a3f680e,"This paper focuses on contrastive learning for performing self-supervised network pre-training.  Two components are proposed: First, to select semantically similar images that are pulled together in the contrastive learning, the paper proposes ""center-wise local image mixture"" (CLIM) - both k-means clustering and knn neighbors are computed, and then for a given anchor image x, and images x' that fall within the same cluster and are a knn neighbor (and additionally closer to the cluster center than x) are selected as a positive match to x.  This is motivated from the perspective of allowing for consideration of both local similarity and global aggregation.  This selection is further modified by the use of cutmix data augmentation, where (x, x') are combined via a binary mask.  This is motivated from the perspective of allowing for some smoothing regularization to handle potentially noisy matches from CLIM.","The paper addresses the problem of contrastive representation learning, and proposes a new data augmentation, dubbed CLIM, that leverages similarity between images. Instead of generating positives pairs using different transformation of the same image -as it is standard in contrastive learning-, positive pairs are generated using those similar images to the anchor image: after clustering the representation space using k-means, the nearest neighbours that are closer to the corresponding center of the cluster where the anchor belongs to are selected. Then, positive pairs are constructed following Cutmix, which can be seen as a regulariser, and which consists in cutting and pasting patches among these pairs to generate new samples. Finally, the paper also proposes a multi-resolution augmentation, which consists in random zooms in (ie. random crop + resize) at different scales to enable scale invariance.",0.1724137931034483,0.18382352941176472,0.1779359430604982
717,SP:41f93461a907d77fc2e0f4f4e3e89a0e7a133736,"The paper presents an empirical evaluation of many algorithmic choices made in the implementations of on-policy actor-critic algorithms in deep reinforcement learning (RL). The authors group those choices in clusters in which they expect some interactions. For each cluster, they test sets of randomly made choices while assuming that choices outside a cluster are set to competitive default values. Based on those experimental results, the authors formulate recommendations about how to make those choices for each cluster.","This paper carries out a large-scale study for understanding of on-policy deep actor-critic. The study looks into a large choices of many implementation settings and design decisions, and investigate their impact on the task performance. The evaluations are done with 250000 RL agents on 5 different continuous control tasks. For each evaluation category, there is a finding summary that provides practical recommendations.",0.16455696202531644,0.2,0.18055555555555555
718,SP:424eaac0eb5a5fcb526c39f5e21f9ec7506aa3bc,"The paper proposes a parametric form for a matrix representation of a graph to be used as a building block within graph neural networks (GNNs). In essence, people use different normalized versions of the adjacency and Laplacian matrices within GNNs. The authors, in turn, propose a generic parametrized version that encompasses those normalizations and that can be learned from data.","The authors consider the problem of learning a parametrized graph shift operator (or message passing operator) in the context of graph neural networks. They consider a family of GSO (that they name PGSO) based on seven scalar parameters, and show that it includes most commonly used operators such as the adjacency matrix or the laplacian. The spectral properties of the PGSO are analyzed. Finally, some empirical results are provided demonstrating the PGSO as a drop-in replacement for standard GSO in GNN architectures.",0.21666666666666667,0.1566265060240964,0.18181818181818182
719,SP:42784c9a7dce81ab38635d4619569766934abff7,"This paper considers training autoencoders with a hyperspherical latent space distribution. The encoder maps inputs to latent variables with a unit norm, and a contrastive loss with momentum is used to encourage the latent variables to be distributed uniformly over the surface of the unit-hypersphere. Generations of this autoencoder model are compared against wasserstein auto-encoders and several VAEs and evaluated with FID scores on CIFAR10 and CelebA. On CelebA the model is outperformed by both WAE-GAN (Wasserstein auto-encoders trained with a GAN objective to match the latent distributions) and a 2-stage VAE. On CIFAR10 the model outperforms related work, but only when using a different encoder/decoder architecture.","Description: The authors propose momentum contrastive Wasserstein autoencoders (MoCA), which is an extension of the Wasserstein autoencoder (WAE) that aims to match the prior p(z) and aggregate variational posterior q(z) through the use of contrastive learning, as opposed to earlier proposed techniques (MMD, GAN). The use of contrastive learning here is theoretically motivated by the fact that -- as shown in Wang & Isola (2020) -- in the limit of infinitely many negative samples, the distribution induced by the contrastive encoder is uniform on the hypersphere. Therefore, if p(z) is the unit + uniform hypersphere, then we can leverage contrastive learning to drive the aggregate variational posterior q(z) to be as close to it as possible. This provides a principled way to train WAEs since its corresponding optimisation assumes that P_Z == Q_Z.",0.1415929203539823,0.11940298507462686,0.12955465587044535
720,SP:42885bdb86f343bd752c9a406d7e985fec81a7f6,"In this paper, the authors propose Sandwich Affine strategy to separate the affine layer in BN into one shared sandwich affine layer, cascaded by several parallel independent affine layers. Such method should well address the inherent feature distribution heterogeneity in many tasks. Following this idea, the SaAuxBN and SaIN have also been introduced in this paper. The extensive experiments demonstrate the effectiveness of such methods in neural architecture search (NAS), image generation, adversarial training, and style transfer.","This paper considers improving the performance of various normalizers by factorizing the affinity operations in normalization layer into on shared affinity operation, as well as several several independent affinity operation, each of which is corresponding to a specific data distribution. The experiments on various tasks (e.g. NAS, GAN, adversarial defense) demonstrate the effectiveness of proposed methods.",0.22077922077922077,0.2982456140350877,0.25373134328358204
721,SP:42b2a4961b167d02370a0924d0666be1bf962110,The paper proposes a new regularization for the dictionary in the learned convolutional sparse coding model of Sreter & Giryes '18. The main contribution is that the dictionary is regularized to be composed of 1) a fixed low-pass filter and 2) a set of learned filters to occupy the complementary high-frequency space. A second contribution is that the thresholding in the network is adjustable according to the estimated noise level in the image. ,"The paper proposes a denoising method with a neural network inspired from convolutional dictionary learning. In the proposed method, one atom of the dictionary is constrained to be a low frequency filters and all other atoms are to be high frequency atoms. The authors also propose to make the threshold depends on the noise level to better adapt to different noise level and to use strided convolution to reduce the computational cost of the method. The method is then evaluated on images from BSD68.",0.33783783783783783,0.2976190476190476,0.31645569620253167
722,SP:42c3eb2cad23ed513b09f0810e3d7dd4e7bb2532,"This paper first investigates when and why fine-tuning and joint training are not the best methods for transfer learning. The authors generate a toy dataset, in which the source-specific and transferable features are thus clearly distinguishable, for the transfer learning tasks. As both fine-tuning and joint training are not optimal solutions for the experimental dataset, they further design MeRLin, which is based on the meta-learning mechanism, to learn a generalizable model weight.","The paper investigates failure cases for transfer learning (fine-tuning and joint training), specifically in the context where training on the source data may highlight features that are irrelevant for the target data. This is done through semi-synthetic data. Based on the insights, the authors present an approach called Meta Representation Learning (MeRLin) inspired by Meta Learning and Learning-to-learn approaches. This approach is evaluated on several real-world transfer-learning tasks from vision and NLP. The authors also derive theoretical results on constructed data distributions for which superiority of Merlin can be shown analytically.",0.2894736842105263,0.2268041237113402,0.254335260115607
723,SP:42d41dec3695a319b32a212d33682ae15535f27c,"The paper is a nice piece of works which clearly articulates the objective and the subsequent discussion. The focus of the paper--i.e. disclose the difficulties of piano fingering data annotation and the proposal of automating this process by automatically extracting fingerings from public videos and MIDI files, using  computer-vision DNN-based algorithms —although not really mainstream, it does provide some practical insights using a couple of experimental settings (piano fingering model and prediction) to help the readers. ","In this paper, the authors proposed an automatic piano fingering algorithm, that accepts YouTube videos and corresponding MIDI files and outputs fingering prediction for each note. The claimed contribution is two-fold: First, they proposed the algorithm, and second, they claim that the algorithm can be used to automatically generate large datasets for piano fingering problems. The motivation is clearly stated and convincing. The overall algorithm is mainly described. ",0.15,0.17391304347826086,0.1610738255033557
724,SP:42ff146511e450b30afabdbb8396c6db640d05fa,"The paper introduces the _learning to optimize_ (L2O) framework into the solution of minimax problems. The base model is composed of two decoupled LSTMs with a shared objective, with the two LSTMs being respectively responsible for the update of the min and max variables. On top of this, the authors further investigate two possible improvements.  One consists in applying curriculum learning to improve the generalization capability of the solver while the other uses safeguarding to guarantee convergence in convex-concave problems.","Classical iterative minimax optimization algorithms display the unstable dynamics. Their convergence is often sensitive to the parameters and needs to be re-tuned for different problems to ensure convergence. Therefore, there is a practical motivation to develop L2O for minimax problems, so that we could meta-learn and adapt optimization rules to a special class of functions. ",0.12345679012345678,0.17543859649122806,0.14492753623188406
725,SP:4304fa522634ec30bcf3862d4ae463baeed51711,"This paper addresses the problem of Inverse Contextual Bandit.  They raise an important question: given demonstrated behavior from an agent, how has the agent’s knowledge been evolving over time? Formally, Given a contextual bandit problem $(X, A, R, T )$,  where $R, T$ are unknown to the agent. Given an observational dataset $D$, and a family of reward parameterizations $P$ and belief parameterizations $B$, the inverse contextual bandits problem is to determine the true environment parameter $\rho^*$ and the belief parameters $\beta_{1:T}$.   They propose two algorithms to learn these parameters. The first uses the agent’s knowledge in terms of Bayesian update. The second uses the Gaussian process. They demonstrate their algorithm through simulated and real-world data for liver transplantations. ","This paper studies an inverse (linear) contextual bandits (ICB) problem, where, given a $T$-round realization of a bandit policy’s actions and observed rewards, the goal is to design an algorithm to estimate the underlying environment parameter, along with the “belief trajectory” of the bandit policy. A particular emphasis is placed on the belief trajectory being “interpretable” and capturing changes in the policy’s “knowledge of the world” over time.  The paper’s main contributions are (i) formalizing the inverse contextual bandits problem, (ii) designing two algorithms for this problem based on two different ways of modelling beliefs of the bandit policy, and (iii) providing empirical illustrations of how their algorithm can be used to investigate and explain changes in medical decision-making over time ",0.22764227642276422,0.2222222222222222,0.22489959839357426
726,SP:4313c3bed7eaa75d90537a6d993bb6207f4adae2,"The paper is concerned with selective classification in a stylised 'realisably noisy' data model, wherein the support of the input distribution is partitioned into two chunks, the ""informative"" $\Omega_I$ and the ""uninformative"" $\Omega_U,$ such that  - The labels are completely noisy ($\mathrm{Bern}(1/2)$) if the input lies in $\Omega_U$. - The labels are completely clean if the input lies in $\Omega_I$. - The learner has access to hypothesis classes $\mathcal{F}, \mathcal{H}$ such that      - There exists an $f^* \in \mathcal{F}$ with $f^*(x) = y$ on $\Omega_I$.     - There exists a $g^* \in \mathcal{H}$ with $g^*(x) = 2\mathbf{1}\{x \in \Omega_I\} - 1.$  The paper studies the problem of learning a pair $(f,g),$ with $g$ serving as a selector, and $f$ as a predictor, such that $g \approx g^*$ and $f \approx y$ on $\{g \ge 0\}$ (and $\approx f^*$ on $\Omega_I$ if $g$ is learnt well), with the concrete goal of attaining both small selective risk ($P(f^*(x) \neq y|g(x) \ge 0)$) and both low false alarm and low missed detection for $g$ with respect to $g^*$. As is standard in selective classification, supervision of the value of $g^*$ is not given, and instead only $(x,y)$ pairs are provided.  This is approached by designing a new loss for learning a selector given a predictor $f$, denoted $W(g;f, \theta)$, that basically uses $\mathbf{1}\{f(x) = y\}$ as proxy supervision for when $g < 0$ or $g > 0$ is preferred, but weighted by a factor to account for the prevalence of uninformative versus informative data. It is first shown, using uniform convergence techniques, that if the indicator ERM problem can be solved, then given  if $f^*_{S_n}$ is taken to be a minimiser of standard empirical risk, and $g^*_{S_n}$ to be the minimiser of an empirical version of $W(g;f^*_{S_n}, \theta)$ for appropriately chosen $\theta$ (in a way which depends on the prevalence of informative data $\alpha$), then these goals can be attained in a PAC sense, with sample complexity scaling as $\tilde\{O\}( \frac{d_\{\mathrm{vc}\}(\mathcal{F}) + d_\{\mathrm{vc}\}(\mathcal{H}) }{\epsilon^2 \alpha^2})$.  The paper then switches gears, and a alternating minimisation based heuristic method for practically learning $(f,g)$ is proposed. The idea is to first learn (soft functions) $f$ and then $g$ using relaxed versions of the above losses, and then multiplicatively increase the weight of points that are selected by the $g$ in their contribution to the loss for $f$, and repeat. The remainder of the paper is devoted to empirical evaluation of this method in two situations - firstly, uniformative (randomised labels) MNIST data is given along with varying amounts of clean Fashion MNIST data; and secondly, part of the classes from the SVHN dataset have their labels randomised to represent uninformative data, while the rest remain clean. While the scheme is observed to have similar performance in how well the selector identifies the underlying $g^*$, the proposed method has remarkably better selective risk compared to baselines from the recent selective classification literature.","This paper considers supervised learning with abstention -- where the learning method can decide to make prediction in some region of the feature space, and declare the rest of the feature space unpredictable. The setting is related to but different from the classical selective prediction, and to prediction uncertainty quantification (i.e. imbuing predictions with calibrated confidence intervals). Classical selective prediction balances coverage vs. accuracy -- whereas in the setting here the authors assume that there is a ""true"" split into an informative and uninformative partition of the feature-space,  and the goal is to both recover the partition and learn a good model on the informative partition.  The paper focuses on theoretical analysis, and also has experimental results suggesting that if the data is generated according to the author's model, than a heuristic algorithm inspired by the analysis indeed outperforms other selective prediction baselines. ",0.08237547892720307,0.2986111111111111,0.12912912912912913
727,SP:43329ddc4ce5ca94bde0ed3df97a040d090a4b41,"-- EDIT: I have updated my scores in response to clarifications --  The problem of optimizing a convex quadratic function via first order methods is considered. This is a well-understood problem from the worst case point of view, and its complexity will depend on the largest and smallest eigenvalues of the associated Hessian matrix. However, a nice recent average-case analysis by Pedrogosa and Scieur gives the following result: if the spectral density of the Hessian converges to a ""nice"" probability measure (such as the Manchenko-Pastur law), then first-order methods that are tailored to this density may converge faster. In fact, such methods can be obtained from the three-term recurrence for the orthogonal polynomials of the measure.  The present manuscript follows up on the Pedregosa/Scieur, but departs from in two specific ways. Firstly, it considers the case where the limiting spectral law is a beta distribution, and derives the corresponding iteration. Secondly, the authors analyze the performance of this iteration under ""mispecification"": that is, they allow for more general spectral measures than the beta, and only specify how these measures behave near the extremes. In spite of this, they are able to derive bounds of the same order as in the beta case.   A few other theoretical results are presented: worst-case rates for the method derived from the beta distribution; an analysis of Nesterov's method under conditions on the tail of the spectral measure, and a result on Laguerre spectral measures. These results generalize other theorems obtained in the Pedregosa/Scieur paper. The theory is complemented by a small numerical study.  ","The paper considers the problem of average convergence rate of first order methods on a given ensemble of quadratic problems. The authors propose the Generalized Chebyshev Method (GCM) and show that it is optimal when the e.s.d. is beta distribution. They also show that so long as we know the behavior of e.s.d. near the edges of its support, GCM still achieves the optimal rate. The authors finally consider the Nestrov method and derive its asymptotic average-case convergence rate.",0.10150375939849623,0.32142857142857145,0.15428571428571428
728,SP:433a47ed8978997d213bc7072f66a4d62e2e92e3,"This paper studies representation learning in an e-commerce setting. In particular, the paper explores the use of the recently proposed Bootstrap Your Own Latent (BYOL) framework to learn product representations. Rather than using different views of the same entity (as is done in the image domain), different products within a single shopping session are used. Experiments show that the unsupervised BYOL alone does not perform well in this setting. To remedy this issue, the objective is modified by adding a supervised product category prediction loss. Experimental comparisons are made to several baselines on four downstream supervised learning tasks.","The authors study the problem of representation learning of marketplace products to apply in downstream tasks. More specifically, the authors extend the work of BYOL with a new objective function by adding a cross-entropy objective. The main hypothesis of this paper is that different products of the same browsing session can be thought of as different augmentations of the same session. ",0.1414141414141414,0.22580645161290322,0.17391304347826084
729,SP:4341b2c3554d27983bb5077f0cb3448c0c764823,"This paper targets on addressing the node embedding problem in disassortative graphs. A non-local aggregation framework is proposed, since local aggregation may be harmful for some disassortative graphs. To address the high computational cost in the recent Geom-GCN model that has an attention-like step to compute the Euclidean distance between every pair of nodes, an idea of attention-guided sorting is introduced. It learns an ordering of nodes, such that distant but informative nodes are put near each other. The sorting order depends on the attention scores computed with the local embedding vector of a node. Then Covn(.) function is applied on the sorted sequence of local node embeddings to obtain the non-local embedding. The final node embedding is then the concatenation of the local and non-local embedding, which is used for node classification. ",The goal of the paper is to perform node classification for graphs. The authors propose a strategy to augment message passing graph neural networks with information from non-local nodes in the graph - with a focus on dis-assortative graphs. Dis-assortative graphs are graph datasets - where nodes with identical node labels are distant from each other in terms of edge connectivity. ,0.09352517985611511,0.20967741935483872,0.12935323383084577
730,SP:4363825dfbd8c5b5a616ea5b0f67a751dcbe7eaf,This paper deals with the global convergence of deep linear ResNets. The author show that under some initialization conditions for the first and the last layer (that are not optimized !) GD and SGD does converge to a global minimum of the min squared error. The closed related work seems to be Bartlett et al. 2019 that study the convergence of GD in the case of linear networks.  ,"In this paper, the authors study the convergence of (stochastic) gradient descent in training deep linear residual networks, where linear transformation at input and output layers are fixed and matrices in other layers are trained. They first establish a global convergence of GD/SGD under some conditions on the fixed linear transformations. They they showed that for Gaussian random input and output transformation, global convergence still holds under conditions on the width of networks strictly milder than the literature. Linear convergence rate of SG/SGD are also established.",0.2835820895522388,0.2159090909090909,0.24516129032258066
731,SP:436ded90847e688e4edd7555ddf94838b4337dd4,"The paper considers point forecasting of hierarchical time series, i.e. multivariate time series with hierarchical aggregation constraints. The authors propose a new approach based on decomposing the series along a global set of basis time series where (approximate) hierarchical constraints are applied on the coefficients of the basis decomposition. Forecasts are produced using a dynamic linear autoregressive model. Compared to existing state-of-the-art hierarchical models, the proposed approach improved overall performance on forecasts at different levels of the hierarchy on several public datasets. ","The paper introduces a method for hierarchical time series forecasting. The problem setting is: given historical hierarchical univariate time series  data and given historical and future features (like holidays, etc..), try to  predict future values for all time series, while keeping the coherence  constraints of the hierarchy. The forecasting is broken down into an autoregressive part with shared  parameters for all time series, and a basis decomposition with different  weights for each time series (regularized by the hierarchy structure). The method is then being compared to different baseline methods on three  datasets.",0.26744186046511625,0.25,0.2584269662921348
732,SP:43728b5763907cbe84f1c7ded63e5f63c45415c5,"This paper tackles the challenging question of how deep networks might learn to extrapolate knowledge outside the support of their training distribution. The paper contributes both with novel theoretical arguments as well as with empirical evidence collected on targeted cases. Differently from other recent approaches to the problem, the theoretical analyses presented here are non-asymptotic and provide precise information about the kind of functions that MLPs can learn in the proximity of the training region. Moreover, the authors provide compelling arguments about the need to explicitly encoding (task-specific) non-linearities in the input representation and/or in the model architecture in order to promote successful extrapolation.","This paper analyzes the extrapolate ability of MLPs and GNNs. In contrast to the existing theoretical works that focus on generalizability  and capacity of these models, this paper emphasizes the behavior of training algorithm using gradient descent. It takes analogy of kernel regression via the neural tangent kernel as an example to study the bias induced by the gradient descent algorithm. The presentation of this paper is clear and well-organized with the most significant result shown in the first section, raising interest of the readers, as opposed to leaving them behind a massive amount of proofs. The contribution of this paper is significant as well since it draws attention of the researcher to theoretical analysis on the bias induced from the implementations of the algorithms as compared to the theoretical analysis on the model structure itself. Model extrapolation is also closely connected to topics such as meta-learning, multi-task learning, domain adaptation and semi-supervised learning since the ability of model extrapolation will limit its performance when applied to other tasks. ",0.25925925925925924,0.16184971098265896,0.19928825622775803
733,SP:43745886db4fda4f60a1aa4f60b44d2cf5ae37a1,"The paper describes a method for learning a deep neural network for multi-view stereo. The overall network includes feature-extraction layers applied to all images, followed by a spatial-transformer network (which is differentiable, but with no learnable parameters) that is applied to warp these features from every matching image to the reference image's co-ordinate frame for a series of candidate depth planes, followed by concatenation of the reference and match image features and 3D convolution layers to form a cost volume. The cost volumes of different pairs are averaged, and additional layers are used to refine this cost volume while relying on the reference image's RGB features, followed by soft-max and an expectation over depth values to output the final depth at each pixel. The entire network is trained end-to-end and experiments show that it outperforms state-of-the-art methods for MVS by a significant margin on a number of datasets.","This paper proposes a method for stereo reconstruction using Deep Learning. Like some previous methods, a 'cost volume' is first computed by plane sweeping, in other words the cost volume is indexed by the 2D locations in the image plane, and the disparities for 3D planes parallel to the image plane. A network then predicts the disparities for each image location from this cost volume.",0.125,0.3076923076923077,0.17777777777777778
734,SP:4394b824230526bc513436acebdacb85254e7e81,"The paper studies the effects of preconditioning on generalization properties in deep learning. By using a bias-variance decomposition of the expected risk, the paper determines optimal precondition matrix $P$ for bias and variance. Then the paper analyzes the generalization performance via the aspects: clean labels, well-specified model and aligned signal. Finally, it extends the analysis to the reproducing kernel Hilbert.","The authors theoretically study the prediction performance of pre-conditioned gradient descent/flow with linear models and squared loss aligning in the setting of least squares regression and non-parametric regression. For parametric least squares, the predication performance of the limiting solution for preconditioned gradient flow i.e. time goes to infinity, is studied in an asymptotic regime where both the number of samples and dimension go to infinity in proportion to one another. Meanwhile for non-parametric regression, source and capacity assumptions are leveraged to achieve finite sample guarantees. Experiments are also conducted on neural networks in a student and teacher setup. ",0.1774193548387097,0.10679611650485436,0.13333333333333333
735,SP:43fde058475c6f68bfcad69c3bed3982344e5fa2,"This paper considers an architecture change to the transformer in which they swap the feedforward subcomponent of the standard transformer with an ""attention only"" variant that includes persistent ""memory"" vectors. The model is evaluated against a suite of baselines on the tasks of character- and word-level language modeling. Combining this ""all attention"" approach with adaptive span yields results about equivalent to the SOTA, in some cases with fewer parameters than existing models. The authors do a nice job of presenting ablation results. A key finding here, for example, is that the a model stripped of both persistent vectors and the feedforward sublayer performs poorly. ","This paper proposes a simple modification to the ubiquitous Transformer model. Noticing that the feed-forward layer of a Transformer layer looks a bit like an attention over ""persistent"" memory vectors, the authors propose to explicitly incorporate this notion directly into the self-attention layer. This involves concatenating the contextual representations with global, learned memory vectors, which are attended over. ",0.18095238095238095,0.31666666666666665,0.2303030303030303
736,SP:443b64bd0352a4283857b9c0e416436b6936732d,"This paper aims to conduct few-shot learning on unlabeled data (instead of on training tasks with few-shot labeled data per task). The proposed algorithm is a trivial combination of existing clustering method and a few-shot learning method, i.e., the clustering provides pseudo labels, from which a series of few-shot training tasks are generated, and then traditional few-shot learning method can be applied afterward. Many existing techniques are integrated, e.g., k-reciprocal Jaccard distance, DBSCAN clustering, prototypical network, triplet loss, etc. The paper reported the experimental results on Omniglot and Market1501.","This paper considers the problem of learning an image representation for few-shot learning without using image labels during training. This is a well-motivated problem since (as the paper points out) learning such a representation using ""episodes"" of low-shot learning problems as examples may require a large amount of annotated data. The paper proposes an iterative algorithm which alternates between clustering the images using the current model and updating the model using the clusters as ""pseudo-labels"". This approach is not particularly elegant as there is no clear objective being optimized, but it may nevertheless be effective. One main claim of the paper is that the iterative nature of this process is key to the success of the algorithm. The choice of model is a multi-layer conv-net which is trained using SGD (Adam). The paper investigates both triplet (with and without hard negatives) and ""prototype"" losses for learning the model parameters. To find clusters, the paper adopts the DBSCAN algorithm using the Jaccard similarity of the k-reciprocal neighbour sets.",0.21649484536082475,0.1206896551724138,0.15498154981549817
737,SP:445fc2caa1539447d3820e6ad6ae965d40d0cb76,"This paper proposes two fully-connected layers based neural graph pooling methods for graph neural networks, named Neural Pooling Method 1 and Neural Pooling Method 2. The first method uses a first FC to reduce the feature dimension and then FC2 to compute the weights to do weighted-average over features for different nodes. The second method uses two FC to reduce the dimension and then compute second-order statistics by Flatten(H^{\top}H). Experimental results on four datasets (PTC, PROTEINS, IMDB-BINARY, IMDB-MULTI) of two tasks (bioinformatics, social networks) show that the proposed graph pooling method can improve the performance by 0.5%-1.2% accuracy while decreasing the std.","In this paper, the authors proposed two graph pooling methods, i.e., Neural Pooling Method 1 and 2. Both of them are flat pooling strategies, which try to obtain a graph representation directly from its node representations without coarsening graphs step by step. Specifically, the major idea of Neural Pooling Method 1 is to use GCN layer to learn a score for each node. Then, the graph representation is obtained by weighted summing the node representations with the learned scores as weights.  Neural Pooling Method 2 follows a similar design. The difference is that, instead of a single score, it has multiple scores for each node, which leads to a matrix for graph representation. This matrix is then flattened into a vector to serve as the graph representation.",0.21238938053097345,0.1875,0.1991701244813278
738,SP:446463708b8bc1be364288fe869a04e054280507,"The goal of the paper is clear. However, the proposed method has only a very incremental novelty compared to SPORF and the previous approaches in computer vision (e.g., Shotton et al., 2011). Although the authors claim the method can take advantage of structure in all kinds of data, the only conducted experiment is on the image data which is fairly limited.","This paper proposed a new method called manifold forest to improve decision forest (DF) classification results. It is motivated by that, natural data is often in some manifold but not randomly distributed. It showed how to use the 2D spatial structures of natural images by constructing structured atoms. Results on 3 toy examples and MNIST showed the better performance than standard RF and SPORF.",0.14516129032258066,0.140625,0.14285714285714288
739,SP:447a69bbd183f33b2950448c3d2bd50b7400410e,"The paper proposes a solution to few-shot meta learning approaches overfitting to the number of shots they are finetuned on, and not generalizing as well as expected to novel shots. In order to mitigate this problem, the paper suggests a parameterization of the meta learner which also conditions on the number of shots the model trains on. In practice, this is done via manipulation of the batch normalization parameters based on the number of shots. With this conditioning, the paper shows that the models perform better across a range of shots that they are evaluated on, compared to various sensible baselines.","This paper proposed an implementation method of using different numbers of shots of data for few-shot learning such as to mitigate the negative effect of ""different shots"". It optimized the FiLM parameters using meta gradient descent during episodic meta-training with different-shot learning tasks. It conducted the experiments on quite a set of ""meta-dataset benchmarks"".",0.1568627450980392,0.27586206896551724,0.2
740,SP:4496f5847520ba21176ac3ea35183849b6b8239e,"This paper presents a novel class of associative memory models. The model is expressed as a network with two-body interactions (synapses) and a well-defined energy function, and it is shown to generalise and unify several existing approaches (Hopfield Networks, Dense Associative Memories and Modern Hopfield Networks). Besides its theoretical and computational properties, the model is presented as being more biologically valid/plausible than some of the existing approaches it generalizes.","The authors proposed a dynamical system that unifies several associative memory models, including the classical Hopfield network and two recently proposed modern Hopfield networks. The dynamical system is described as interactions between two groups of neurons (feature and memory neurons), providing a more biological interpretation of modern Hopfield networks. The proposed system reduces to different associative memory models by choosing different generalized activation functions, each of which maps inputs to a group of neurons into output activity. This manuscript provides sufficient details for understanding, its derivations are correct, and its results are useful in bringing modern Hopfield networks closer to biology.",0.2361111111111111,0.16831683168316833,0.1965317919075145
741,SP:44a4a56c6048b2e7deb16dc106f4552e8f2227b9,The paper proposes an approach to generate semantic explanations for high-dimensional data. The proposed approach consists of two modules -- the first module transforms the high-dimensional raw data into lower-dimensional semantic latent space and the second module applies Shapely explainability to this lower-dimensional latent space to generate explanations in terms of semantic concepts. The approach has been applied to six different datasets.,"This paper develops a Shapley value approach to explanation that uses low-dimensional latent features to explain the original input. In high-dimensional settings, Shapley values can be computationally intractable; as such, the authors adapt the characteristic (aka value) function $v(\cdot)$ to consider coalitions defined in latent space. This helps ensure that only feasible and plausible (i.e., semantically meaningful) perturbations are made. They consider three different latent encodings: Fourier Transforms, Disentanglement, and image-to-image translation (to isolate factors of variation).",0.2,0.1566265060240964,0.17567567567567569
742,SP:44ab69acefac1dba66c4849ea3eea5e7d3285710,"The paper presents a model for learning representations of time series. It addresses, in particular, the context of multivariate time series having exogenous and endogenous dimensions, and where the goal is to learn good representations independently from the context (exogenous dimensions). This work is an extension of existing work, the additions being the multivariate aspect and the context-invariant aspect. The context-invariant problem is treated thanks to an adversarial learning mechanism.  Experiments are conducted on synthetic and real datasets.","This article deals with representation of multivariate signals in the case where we can distinguish endogenous & exogenous channels. This article mainly relies on (Franceschi et al.,2019), whose proposal consists in representing signals using Dilated-TCNN and to apply triplet loss on the sequences as in word2vec. Then the authors introduce 3 cases: normal behavior, anomalies where both endogenous & exogenous are impacted and partial anomalies. The encoded representation of a contextualized signal should be close to its temporal neigbors. Then, the authors tackle prediction & classification tasks on M5 and electricity datasets. The experimental part is a little bit confusing, as the datasets used in the different experiments are not the same. Generally speaking, results are very difficult to interpret.",0.1875,0.12605042016806722,0.1507537688442211
743,SP:44aca1ce39be826e389afbff70936eb0ef774f8f,"This paper is about developing VAEs in non-Euclidean spaces. Fairly recently, ML researchers have developed non-Euclidean embeddings, initially in hyperbolic space (constant negative curvature), and then in product spaces that have varying curvatures. These ideas were developed for embeddings, and recent attempts have been made to build entire models that operate in non-Euclidean spaces. The authors develop VAEs for the product spaces case.","This paper introduces a general formulation of the notion of a VAE with a latent space composed by a curved manifold. It follows the current trend of learning representations on curved spaces by proposing a formulation of the latent distributions of the VAE in a variety of fixed-curvature spaces, and introduces an approach to learn the curvature of the space itself. Extensive mathematical derivations are provided, as well as experiments illustrating the impact of various choices of latent manifolds on the performance of the VAE.",0.15151515151515152,0.11627906976744186,0.13157894736842105
744,SP:44bc7dda97cc764219656e8a9a6cc8f60d195c29,"The paper presents a new model for code completion which allows the model to completions with “holes” that are inserted in places where the model is uncertain. The idea of generating “holes” to enable skipping over “hard parts” of the prediction is novel and interesting. To realize this idea, the authors present a model that generates partial syntax trees where some of the non-terminals may be left without further expansion.  The model is evaluated on C# and Python programs and is shown to outperform existing techniques. The also paper presents a thorough ablation study. ","This work proposes, GRAMMAFORMER, a transformer model for generating code with ""holes"" inserted in places where a model is uncertain. GRAMMAFORMER is trained on code completion task for C# and Python. The model generates 10-50% more accurate completions and 37-50% longer sketches.",0.2,0.4318181818181818,0.2733812949640288
745,SP:4514e92c7a02cd2765a9cc4b35392594b022fa3e,"This paper proposes an interesting view to analyze the long-tailed problem. It states that the gradients are dominated by the head classes so that the tail classes perform poorly. From this observation, the authors propose a dual-phase approach that first train $W_r, W_c^1$ with only head-class data, and extend to train $W_r, W_c$ with tail-class data and the constructed exemplar memory bank for head classes with a newly proposed memory retentive loss.",This paper works on long-tailed classification. The authors conducted an analysis and claimed that the difference of gradients computed on the head and tail classes plays an important role in the performance drop. The authors then proposed a two-stage approach to first train on the head classes and then train on the tail classes in an incremental learning fashion. The proposed algorithm achieved better performance than existing methods on benchmark datasets.,0.2839506172839506,0.3150684931506849,0.2987012987012987
746,SP:4522ae8f5aaec18049aafa53746c3bc337d620db,"This paper focuses on the domain generalization problem where the source domain contains synthetic data. An interesting phenomenon is observed in this paper: the diversity of the learned feature embeddings plays an important role in the generalization performance. Then, this paper presents a method to address the syn-to-real generalization problem by combining augmentation, contrastive loss and attention pooling techniques. In general, the observed phenomenon is interesting but the proposed method is not a well-motivated solution. Besides, the researched problem is not a general one, which limits the impact of this paper.","Synthetic-to-real generalization is an important topic of extensive practical interest. This paper motivates its work from an observation of feature diversity difference between synthetic and real training: synthetic training tends to generate less diverse or even collapsed features, whereas models trained on natural images give much diverse ones. Based on that, the author developed a contrastive “push and pull” framework to: (1) keep proximity between learned and ImageNet-pretrained features; and (2) push the feature embeddings away from each other across different images, using the feature diversity observation as the inductive bias.  ",0.13829787234042554,0.13829787234042554,0.13829787234042554
747,SP:452600e23747ac98ed7513304b5a008d8ee278bf,"The paper at hand describes an approach to enable neural networks to take arbitrary structured data (basically any data that is not easily represented as a fixed-dimensional vector) as input. The paper describes how such data can be represented as a set (e.g. a sequence is represented as a set of index + data) and then an auxiliary network called the set aggregating network (SAN)  is used to represent the data in a high dimensional latent space. In addition to the idea, the paper provides a theoretical analysis of the approach which shows that with a sufficiently high dimensional representation the network is able to learn a unique representation for each input example. ","The paper argues that plain (fully connected) neural networks cannot represent structured data, e.g. sequences, graphs, etc. Specialized architectures have instead been invented for each such case, e.g. recurrent neural networks, graph networks etc. The paper then proposes to treat these structured data types as sets and propose a neural network method for converting a set into a fixed size vector, which can then be classified using plain neural networks. The method works by projecting each member of the set into M dimensions where they are passed through a ReLU and summed. The paper proves that given high enough dimensionality M, no information will be lost during this process. The paper performs experiments on graph data, text data and image data. The paper concludes ""We proposed a general framework for processing structured data by neural network.""",0.21052631578947367,0.17391304347826086,0.1904761904761905
748,SP:452647b7c89a17b86b0d420c3cfe0bf0326301fa,"This paper studies the SCO with loss function that satisfies growth conditions in the differential privacy model. Firstly, it considers the empirical risk function and provide an algorithm based on the inverse sensitivity mechanism. Then they show an efficient algorithm and the lower bounds of the problem in the both $\epsilon$ and $(\epsilon, \delta)$-DP models.","This paper presents a differentially private mechanism for releasing data and an optimisation algorithm that can use the released data and minimise a convex function. While there are many such algorithms in prior work, the current manuscript provides an algorithm that is adaptive and has convergence rate that improves with the ""growth"" of the function around the optimum point. Furthermore, the authors present matching lower bounds, which show that their algorithm is close to optimal.  ",0.23214285714285715,0.17333333333333334,0.1984732824427481
749,SP:453129ae5abd43775d038344ecfc58711d55264c,The paper introduces an automated graph neural network model with explicit link information. The model is tested on link prediction task (both homogeneous and heterogenous graphs) and node classification task. It shows improvement compared with the baseline models selected.,"This paper proposes a neural architecture search method for using GNNs for link prediction. The proposed method explicitly models edge information in the search process, and proposes several novel design and search space choices for AutoGNN. Through a DARTS-like differentiable search method, the proposed method achieves state-of-the-art performance on various link prediction and node/graph classification tasks.",0.28205128205128205,0.18032786885245902,0.22000000000000003
750,SP:4535803bbaeba4ee21bd85c05ff7ecea4fdbfe10,"The paper proposed a generative model for image style transfer in real time. In particular, comparing to the existing work, the proposed method is able to generate a series of transferred images instead of one, and more importantly, users can adjust different parameters without re-training the network to control over the synthesized output. The proposed method was evaluated on publicly-available datasets, and achieved convincing experimental results.","The paper presents an approach for style transfer with controlable parameters. The controllable parameters correspond to the weights associated to ""style losses"" or ordinary style transfer models (distance between gram matrices of generated vs style image at specific layers of a network). The authors propose to learn a single architecture that takes these parameters as input to generate an image that resembles what would be generated by optimizing directly on these parameters. Examples of transfer and of the effect of these parameters are given. A quantitative evaluation shows that the effect of changing the parameters of the new network has the effect of reducing the loss at the desired layers.",0.25,0.15454545454545454,0.19101123595505617
751,SP:4544639f7c0d43d2b79ce9bd8ba5e723cefe9ffd,"This paper proposes an embedding mechanism for partial programs for search space exploration in example-driven synthesis. It executes a sub-expression concretely whenever possible and applies neural module networks on vector representations otherwise. The embeddings of partial programs and goal states are used for determining the next step towards expanding an unfilled hole. This method is evaluated on three benchmark sets: tower construction, functional list processing and string editing.","This paper proposes a novel top-down program synthesis for programming-by-example which combines concrete evaluation with neural embeddings. The authors take inspiration from abstract execution, which can execute partial programs by abstractly representing sets of possible execution states. Instead of hand-designing an abstract execution method, however, they propose a neural equivalent, which instead embeds possible states into a feature vector. While this approach has weaker guarantees than traditional abstract execution, it is much more flexible, and can be used as a powerful guiding function for execution-based top-down program search.",0.2,0.14893617021276595,0.17073170731707318
752,SP:454c98d15b785ccd0128dbf7d8209adbda1fd2e8,"This paper mainly concerns the quality of in-domain uncertainty for image classification. After exploring common standards for uncertainty quantification, the authors point out pitfalls of existing metrics by investigating different ensembling techniques and introduce a novel metric called deep ensemble equivalent (DEE) that essentially measures the number of independent models in an ensemble of DNNs. Based on the DEE score, a detailed evaluation of modern DNN ensembles is performed on CIFAR-10/100 and ImageNet datasets.",The paper provide an extensive review of current advances in uncertainty estimation in neural networks with the analysis of drawbacks of currently used uncertainty metrics and comparison on scale the recent method to estimate uncertainty. The paper covers a lot of uncertainty metrics and a wide range of methods. The paper focuses on in-domain uncertainty estimation complementing the recent similar review on out-of-domain uncertainty estimation.,0.18181818181818182,0.20588235294117646,0.19310344827586207
753,SP:4559980d3efc338e248142f556ceede2d45d7c92,"The authors suggest a method to create combined low-dimensional representations for combinations of pairs of words which have a specific syntactic relationship (e.g. adjective - noun). Building on the generative word embedding model provided by Arora et al. (2015), their solution uses the core tensor from the Tucker decomposition of a 3-way PMI tensor to generate an additive term, used in the composition of two word embedding vectors.","The authors consider the use of tensor approximations to more accurately capture syntactical aspects of compositionality for word embeddings. Given two words a and b, when your goal is to find a word whose meaning is roughly that of the phrase (a,b), a standard approach to to find the word whose embedding is close to the sum of the embeddings, a + b. The authors point out that others have observed that this form of compositionality does not leverage any information on the syntax of the pair (a,b), and the propose using a tensor contraction to model an additional multiplicative interaction between a and b, so they propose finding the word whose embedding is closest to a + b + T*a*b, where T is a tensor, and T*a*b denotes the vector obtained by contracting a and b with T. They test this idea specifically on the use-case where (a,b) is an adjective,noun pair, and show that their form of compositionality outperforms weighted versions of additive compositionality in terms of spearman and pearson correlation with human judgements. In their model, the word embeddings are learned separately, then the tensor T is learned by minimizing an objective whose goal is to minimize the error in predicting observed trigram statistics. The specific objective comes from a nontrivial tensorial extension of the original matricial RAND-WALK model for learning word embeddings.",0.3,0.09012875536480687,0.13861386138613863
754,SP:45721cf7c3816adacb89ce44a1ff4453ca342aee,"The paper studies the problem of learning the class of symmetric boolean function, that is, functions that depend only on |x| = \sum_i x_i. The paper shows that with proper initialization, one-hidden layer over-parametrized networks can learn this class of functions. The main observation that the authors make is that the last layer weights are updated as in the Perceptron algorithm and as long as the first layer has learned a large-margin representation, the first-layer weights do not change much. The authors experimentally validate their theory and additionally show that random initialization fails to converge to a low test-error solution while their special initialization works.","PAPER SUMMARY: This paper studies the problem of training a single hidden layer neural network to represent an arbitrary symmetric function. These are functions $f : \{0,1\}^n \to \{-1, 1\}$ which are invariant to permutations in the input coordinates. The authors' main result (Theorem 1) shows that if you take a single hidden layer network with $O(n)$ hidden units and initialize the weights in a particular way, then for any symmetric $f$, SGD training will converge to an empirical risk minimizer with guaranteed small generalization error. On the other hand, the authors' experiments suggest that arbitrary symmetric functions are not learnable from random initialization. Taken together, these results point to the importance of designing network architectures/ initializations that respect the structure in the function class you're trying to represent.",0.22522522522522523,0.1893939393939394,0.205761316872428
755,SP:4575567f743dfddde8d82d911115cf806f78042f,"This paper proposes and empirically evaluates SAM, an optimization method that is designed to seek out regions of uniformly low training loss. The method is derived from a bound on the generalization performance of parameters $w$ in terms of the maximal training loss in a region around $w$. After various approximations, minimizing this upper bound gives rise to a simple method, which first performs a (normalized) gradient ascent step; computes the gradient at that perturbed location; and uses that gradient to update the weights. The empirical evaluation shows that SAM improves generalization performance across a wide range of settings.","Motivated by the connection between the flatness of minima and its generalization ability, the authors propose Sharpness-aware Minimization (SAM), which explicitly minimizes both loss value and loss sharpness during training deep neural networks. They find SAM improves generalization for a range of image classification tasks and provide robustness to label noise as well. They also introduce a new notion of sharpness named m-sharpness.",0.12121212121212122,0.18461538461538463,0.14634146341463417
756,SP:457a2131015db955a2dc97e1bf428af1eb145e4b,"The paper proposes a Graph Convolutional Network-based encoder-decoder model with sequential attention for goal-oriented dialogue systems, with the purpose of exploiting the graph structures in KB and sentences in conversation. The model consists of three encoders for a query, dialogue history, and KB, respectively, and a decoder with a sequential attention mechanism. The proposed model attains state-of-the-art performance on the modified DSTC2 dataset of (Bordes et al., 2017). For the experiments with graphs constructed from word co-occurrence matrix, code-mixed versions of modified DSTC2 released by (Banerjee et al., 2018) are used.","The current paper proposes using Graph Convolutional Networks (GCN) to explicitly represent and use relational data in dialog modeling, as well an attention mechanism for combining information from multiple sources (dialog history, knowledge base, current utterance). The work assumes that the knowledge base associated with the dialog task has en entity-to-entity-relationship format and can be naturally expressed as a graph. The dependency tree of dialog utterances can also be expressed as a graph, and the dialog history as a set of graphs. To utilize this structure, the proposed method uses GCNs whose lowest layer embeddings are initialized with the entity embeddings or via outputs of standard RNN-like models. The main claim is that the proposed model outperforms the current state-of-the-art on a goal-oriented dialog task.",0.24242424242424243,0.18045112781954886,0.20689655172413793
757,SP:457e8a56292b7c3001e0bae17c86b978ab95bcce,"This paper considers the general problem of testing hypotheses about the world by a kind of reinforcement learning, much as a person might learn by taking actions and observing their outcomes -- equivalently learning policies that can generate observations to validate a hypothesis.   A hypothesis is a symbolic representation of precondition, action and effects. The paper takes advantage of the ability of reinforcement learning to manipulate the environment that makes it possible to make causal inferences about the world. ","This paper introduces a problem setting where an RL agent must interact with its environment to predict whether a given hypothesis is true or false. On modified versions of environments like gridworld and cartpole, they show that PPO with a sparse reward is unable to correctly test the hypothesis. The key technical contribution is making the reward more dense by assuming a predefined structure in a subset of hypotheses. This denser reward is used to pretrain the RL policy, which is then finetuned over the rest of the hypotheses using sparse reward.",0.20512820512820512,0.17391304347826086,0.18823529411764706
758,SP:4586d1c6908f3dd8e5cb3b67d445f1011bf503c2,"This paper proposed a soft, spatial, sequential, top-down attention model which enable the agent and classifier actively select important, task relative information to generate the appropriate output. Given the observations, the proposed method uses a convLSTM to produce the key and value tensor. Different from multi-head attention, the query vector is generated in a top-down fashion. The authors proposed to augment the spatial feature with Fourier bases which is similar to previous work. The authors verify the proposed method on both reinforcement learning and supervised learning. On reinforcement learning, the proposed method outperformed the feedforward baseline and LSTM baseline. On reinforcement learning task, the proposed method achieves compelling result with more interpretable attention map that shows the model's decision. ","The paper proposes a variant model of existing recurrent attention models. The paper explores the use of query-based attention, spatial basis, and multiple attention modules running in parallel. The effectiveness of the proposed method is demonstrated with various tasks including RL (on Atari games), ImageNet image classification, and action recognition, and shows reasonable performance. ",0.13008130081300814,0.2909090909090909,0.1797752808988764
759,SP:45887dbc0540ff444f7ae8dcf564b917ea73d967,"This paper introduces a memory-augmented RNN (MARNN) which aims at being lightweight and   differentiable. In a nutshell, authors propose to augment a LSTM-type architecture with several memory cells. At each time-step, MARNN retrieves one memory cell, updates his state, and updates the memory cell content. To learn the retrieval operation that requires discrete addressing,  authors rely on the Gumbel-Softmax. Authors evaluate their approach on PennTreeBank character level modelling where they demonstrate competitive performances. They also report state-of-art performance on the Thumos dataset. The paper is overall clear and pleasant to read. ","This paper introduces a new RNN architecture with external memory for sequence modeling. The proposed architecture (MARNN) is a simplification of TARDIS (Gulcehre et al., 2017). It uses the similar reader-writer tying mechanism, gates to control information flow from previous hidden state and memory. However, it has a simpler addressing mechanism. Authors show results in Character level PTB and a temporal action detection/proposal task.",0.17525773195876287,0.25757575757575757,0.2085889570552147
760,SP:45ba88126844e65868d6284c7175a9893ccaf67e,"This paper aims to improve pretraining Pre-LayerNorm transformers by alleviating two issues: early layers have much larger gradients than later ones, and naive residual learning can't provide optimal weighting. To this end, it proposes to add two LayerNorms after the multi-head attention and the GELU non-linear activation in FFN, respectively. It also adds learnable scaling coefficients for the FFN residual and the attention head outputs. The four modifications are applied to both casual and masked language modeling with improvements observed in downstream tasks.","NormFormer improves on Pre-LN transformers by making the following modifications: learnable scaling parameters for each dimension of the output of each attention head prior to concatenation across heads (*Scaled Attention*); layer norm on the attention output (*Post Attn LN*); layer norm on the FFN nonlinearity output (*FFN LN*); and learnable scaling parameters for each dimension of the skip connection around the FFN (*Scaled Residuals*). They apply NormFormer to GPT3- and RoBERTa-style model configurations, and find that NormFormer models reach baseline iso-accuracy in 22%-43% less time, and achieve notably lower (higher) iso-time perplexity (accuracy). They then conduct a number of analyses to attempt to understand why NormFormer works.",0.1839080459770115,0.14285714285714285,0.16080402010050251
761,SP:45bf7ca342ad1752c7f7c056653137b9283c487f,"The authors consider active deep learning. They propose decomposing predictive entropy into a) vacuity (lack of evidence) and b) dissonance (contradictory evidence). They frame this in terms of ""subjective logic"". In practice this is achieved by having the NN output the parameters of a Dirichlet, which allows an additional degree of freedom describing variance/vacuity. Dissonance is defined in terms of the support of contradictory classes. To get improved estimates of vacuity they augment the loss with a term regularizing the Dirichlet parameters to be small (low precision) at unlabelled points with higher KDE(unlablled points) than KDE(labelled points). They propose initially weighting vacuity and later dissonance as AL proceeds. Encouraging results are presented on simulated 2D data, MNIST and CIFAR10. ","This paper propose an active deep learning model. By leveraging subjective Logic, they propose to decompose the entropy of a predicted class distribution into vacuity (lack of evidence) and dissonance (conflict of strong evidence). Instead of using the predicted class distribution, they estimate the supporting evidence for each class. In the actual data sampling stage, they first sample from those high-vacuity dense region, to shape the true decision boundary, and then gradually sample from those high-dissonance region to fine-tune the decision boundary. They show better performance than the baselines on both synthetic and real datasets. ",0.20491803278688525,0.25510204081632654,0.22727272727272727
762,SP:45cbc9c97027fe59ce2ce7f8a02d9257d3460a4c,"The paper claims that a (computationally intractable) randomized smoothing of any classifier can be distilled into the (deterministic) classifier itself via fine-tuning it with gradient penalty. This is motivated by a theoretical result that Gaussian smoothing of a classifier is equivalent to solving a certain heat equation, which can be approximated by a regularized loss training. Experimental results use the resulting deterministic classifier to compute the certified radius compared to (stochastic) smoothed classifiers, arguing its efficiency and higher certified radius of the proposed method. ","Randomized smoothing is the major way to certify the robustness of large scale networks, however, it requires sampling from Gaussian distribution many times, which is not fast enough for real-time inference. This paper uses a regularized loss to get deterministic Gaussian averaged results. This paper points out an interesting direction for certifying robustness, the method is simple and effective.",0.1411764705882353,0.2,0.16551724137931034
763,SP:45e3c0fe995ae679dd4e6bf28dcc63b341e1a1d2,"The paper considers a new line search variant for minimizing functions with access to function value (zero order) and gradient (first order) estimates only through probabilistic oracles. For both oracles the output is a function of the input point and a random variable, and with probability 1-delta the output is close to the actual value. For the remaining delta probability, the first order oracle assumes nothing while the zero order oracle assumes that large errors are increasingly unlikely, making the requirements for the two oracles different.  The random variable in the oracle, could for instance represent the mini-batch used to estimate the required quantity. The authors propose a variant of Armijo Line search that  - Adds some slack on the Armijo condition depending on the quality of the zeroth order oracle  - Recompute gradient and function values in each step in the line search instead of using the same one.  For this line search method the authors show high probability iteration bounds for minimizing a Lipshitz bounded smooth function, that converge to an epsilon stationary point (norm gradient less than epsilon) where epsilon is lower bounded by the quality of the oracles.  The bounds are more general in the sense that less is assumed about the oracles, and that the paper shows high probability iteration bounds, where the usual is a bound on the expected number of iterations.  ",Consider unconstrained smooth optimization with probabilistic zeroth- and first-order oracles. This paper proposes a new gradient descent with line search method and provides a high-probability upper bound of the iteration complexity. The authors highlight that their assumptions on the noisy zeroth- and first-order oracles are weaker than those in literature. ,0.08771929824561403,0.37735849056603776,0.1423487544483986
764,SP:4603dc6870b79530bca7e79309af459529b522c6,"This paper provides the mathematical frame for influence functions (IFs) for several unsupervised machine learning approaches such as kNN, KDE, and GMM, and proposes a way to empirically compute VAE's IF, and performs several experiments to describe the rationale for using IF for unsupervised tasks. Their approach, VAE-TracIn, can answer which training samples are most responsible for increasing the likelihood of itself (i.e. self-influences) and/or a test sample. The authors claim that the self-influences can be used to discard undesired training samples before training and provide several experimental results showing that IFs for a test sample can identify most and least responsible training samples. ",The paper investigates influence functions for several classical unsupervised learning methods and VAE. Influence functions in unsupervised learning can reveal the most responsible training samples that increase the likelihood (or reduce the loss) of a particular test sample. A particular usage of the proposed approach is for data cleaning. The authors demonstrated their approach on the MNIST and CIFAR-10 datasets. ,0.20909090909090908,0.3770491803278688,0.26900584795321636
765,SP:4605e601a717bc05833778d0916a393ffdf8c331,"This paper proposes a new reweighted-RNN by unfolding a reweighted L1-L1 minimization problem. It develops an iterative algorithm to solve the reweighted L1-L1 minimization problem, where the soft-thresholding functions can be adaptively learned. This paper provides the generalization error bound for deep RNNs and shows that the proposed reweighted-RNN has a lower generalization error bound. In addition, the paper shows that the proposed algorithm can be applied to video-frame reconstruction and achieves favorable results against state-of-the-art methods. The paper is well organized, and the motivation is clear. ","This paper proposes a novel method to solve the sequential signal reconstruction problem. The method is based on the deep unfolding methods and incorporates the reweighting mechanism. Additionally, they derive the generalization error bound and show how their over-parameterized reweighting RNNs ensure good generalization. Lastly, the experiments on the task of video sequence reconstruction suggest the superior performance of the proposed method.",0.22916666666666666,0.3492063492063492,0.27672955974842767
766,SP:46077327cae32f22bb4042a8118056e2889eba52,"This paper presents an approach to learn, what the authors call, graph cellular automata (GCAs). Graph neural networks are trained to learn transition rules for  GCAs and tested on three different domains: Voronoi tessellation, learning dynamics of flocking agents, and learning to approximate 2D/3D target structures. The main contribution is the application of graph neural networks to these three interesting problems.  ","The paper presents the Graph Neural Cellular Automata (GNCA) architecture, a general-purpose architecture that uses a Graph Neural Network (GNN) to learn a desired Graph Cellular Automata (GCA). The proposed architecture is used to learn different transition rules in different kinds of space (discrete and continuous). In the paper, there is a brief (but complete) introduction to Graph Cellular Automata and Graph Neural Network. The GNCA architecture borns by the natural and clearly explained connection between GNN and GCA. The effectiveness of this architecture is demonstrated by three experiments that explore different scenarios: learning a transition rule via supervised learning in a discrete state space, learning a transition rule in a continuous state space, and learning an unknown transition rule to reproduce a target. Each result is discussed using different metrics in order to evaluate how well the model performs in that particular setting.",0.3548387096774194,0.15172413793103448,0.21256038647342995
767,SP:461e76527806e28b022e6c4ed7872e6d8d7a3697,"The paper proposes an algorithm to extend the recently proposed method of “covering options” from a tabular setting to continuous state spaces (or large discrete state spaces). The proposed algorithm approximately computes the second eigenfunction of the normalized laplacian of the state space, uses it to identify an under-explored region and trains an option to terminate in such a region. Each new learnt option is added to the initial set of primitive actions and a policy over this growing set of actions is learnt separately. An online algorithm is also proposed that does the above option learning process intermittently in addition to training for an external task. The paper shows empirical evidence of better or equal performance to base algorithms which do not discover options, prior work such as DIAYN (Eysenbach et. al, 2019) (that discover options via mutual information maximization between visited states and options), as well as ablations of their proposed method with different number of options.","The authors introduce deep covering options, an online mechanism to extend the covering options to large state spaces. They claim their method discovers options that are task agnostic. The method is evaluated in sparse reward domains and claims to gain improvement in exploration and performance as well.  The authors extend the recent developments in eigenfunction estimation of the Laplacian to a principled approach for option discovery to non-linear function approximation. ",0.13125,0.29577464788732394,0.18181818181818182
768,SP:4647fc008073e5ee4e432f84e645aedb7faf736d,"The paper proposed a learned variant of the well-known iterative Hessian sketch (IHS) method of Pilanci and Wainwright, for efficiently solving least-squares regression. The proposed method is essentially a learned variant of the count-sketch, where the positions of the non-zero entries are random while the value is learned. While getting a learned variant for IHS is an interesting direction, the current theoretical contribution of this paper is only incremental, and most importantly, the reviewer is unconvinced for the practicality of the current approach.","Sketching is a popular technique in numerical linear algebra for achieving various desirable properties (e.g., lower complexity, one pass methods). The present paper considers a particular kind of sketch for which the sketch matrix is learned from data. It shows how such learned sketches can be used in two types of problems: Hessian sketching (Sec. 3) and Hessian regression (Sec. 4). The authors give both algorithms and provide theoretical guarantees. They also apply these techniques to a number of both synthetic and real datasets in the experiments. For the most part, the experiments indicate that the proposed methods give a consistent, but not necessarily very large, improvement.",0.21839080459770116,0.17592592592592593,0.1948717948717949
769,SP:466111f5a62b7eb0394c79f7f81185a9f567078b,"This paper is based on the positive semi-definite model from reference [15], and propose a positive semi-definite (PSD) models for probability distribution. The paper then focuses on the family of Gaussian PSD, which can be written as a sum of weighted pairwise multiplicative kernels over sample points. Most importantly, the weights do not need to be positive, and it only requires that the matrix of weights is a symmetric positive semidefinite matrix to ensure that the function is positive everywhere. The authors then show that the PSD model facilitates the sum and product rules; and as the number of sample grows large, one can use projection to compress the model. Further, the authors show the approximation capacity of the PSD model and demonstrate the usefulness of the PSD model on some simple tasks.","The authors discuss an application of recent work in nonnegative function estimation to the problem of density estimation.  In particular, they argue that under mild assumptions, PSD models can concisely model a large range of interesting densities and that these densities can be (more or less) efficiently learned.  The work concludes with a qualitative comparison against existing density estimation strategies.",0.08888888888888889,0.2,0.12307692307692307
770,SP:4673d78e21f98a766c4340809623e54d165f69d9,"The paper considers the problem of training networks for point cloud processing through a point cloud completion task. Given a point cloud, it is rendered from a set of viewpoints and for each viewpoint the set of visible points is determine. A network is then trained to generate the full point cloud from the partially observed point cloud for a given view. Here, an encoder-decoder architecture is used, where the encoder corresponds to the network that should be pre-trained. Experimental results show that the proposed method outperforms two baselines for three tasks (object classification, object part segmentation, and semantic segmentation), when using less training data, and that the pre-training on the occlusion task leads to faster convergence.","This paper proposes a better pre-trained prior for a variety of downstream applications in point cloud analysis. The workflow of the pre-training mechanism is to first 1) generate occluded points that result from view occlusion and then 2) optimize the encoder to learn how to complete the occluded points from the partial point cloud. In downstream applications, the obtained encoder will be used as the initial weights in the network training. Empirical experiments have shown that such a pre-train mechanism can improve initialization over prior baselines and benefit a variety of tasks even with a large domain gap.",0.2,0.2376237623762376,0.2171945701357466
771,SP:467735fd49561cd06342bb38a921e541553c6633,"the paper attempts to infer Granger causality between nonlinearly interacting stochastic processes from their time series measurements. instead of using MLP/LSTM etc to to model time series measurement, the paper proposed to use component-wise time series prediction model with Statistical Recurrent Units to model the measurements. they consider a low-dimensional version of SRU, which they call economy-SRU. in particular, they use group-wise regularizing to accompany the particular structure of the model to aid interpretability. they compared the performance with existing models with MLP/LSTM and show some gains in a few examples (but not all.) the proposal is interesting, but the experiment section might need further strengthening. currently, the experimental results do not immediately pop out as showing eSRU particularly useful.","In this paper the authors propose using Statistical Recurrent Units to predict the network for Granger causality. They motivate this choice by the high representation power of SRUs for multivariate time series, the good performance they usually enjoy and as a way to alleviate the vanishing gradient problem. More importantly the particular form of the SRUs gives a very simple predictor and therefore explanability for Granger causality: the authors propose to simply mark serie $i$ as Granger caused by $j$ if the $j$th column of the input mixing matrix of the $g_i$ is non-zero.",0.15079365079365079,0.1958762886597938,0.17040358744394618
772,SP:4677ba60a6346626bfba72170b2d0c68cf9ed6be,"This paper proposes methods for incentivizing exploration in multi-agent RL.  There are two approaches that are proposed, both framed as influence maximization (of either the state transitions or the decisions of the other agents).  The scaling to multiple agents is done via decomposing to pairwise interactions. This influence objective is the appended to the standard intrinsic motivation objective for single agent RL.","This paper studies the problem of designing effective exploration strategies in multi-agent domains. The key idea is to define one agent's exploration in terms of its interactions with other agents. This leads to two auxiliary exploration objectives, which measure how one agent's actions affect the dynamics and value of another agent's actions. The paper does an admirable job comparing the proposed method against a number of baselines, where the proposed method performs significantly better. Visualizations and ablation experiments nicely illustrate the contributions of various components of the method.",0.2222222222222222,0.15217391304347827,0.18064516129032257
773,SP:469a42606ce6db61e5944f22bf3c0993cfb8d108,"This work proposes an adaptation to MAML-type models that accounts for posterior uncertainty in task specific latent variables. This is achieved via a hierarchical Bayesian view of MAML, employing variational inference for the task-specific parameters. The key intuition of this paper is that one can perform fast and efficient test-time variational inference for the task-specific latent variables by learning a good initialization during meta-training. This is achieved in a very similar fashion to MAML, and allows for an interesting form of amortization of test-time inference.","The authors consider meta-learning to learn a prior over neural network weights. This is done via amortized variational inference. This means that a good initialisation of the variational parameters are learned across tasks, such that a good set of hyperparameters per task can be found in a few gradient steps. The proposed approach is evaluated on a toy and several popular benchmarks (like miniImagenet).",0.15384615384615385,0.2153846153846154,0.1794871794871795
774,SP:46d1e7fa1759841b98b213076456ebb78273d62b,"The authors propose to tackle the problem of multi-objective reinforcement learning (MORL) by considering a logical function as reward signal. In their proposed solution, the logical function is also encoded and concatenated with the state. They argue, via simulation and toy examples, that the proposed model is able to generalize to logical formulas of the multidimensional rewards that has not observed during training.",This paper proposes using logical specifications to facilitate Q-learning in multi-objective reinforcement learning (MORL). Empirically the proposed method can generalize to unseen reward specifications with performance competitive to agents being fully trained in the new environment. The proposed setting employs a more expressive objectives space induced by propositional logic. The proposed method uses a recurrent encoder to embed specifications into vectors and uses them to parametrize the Q-function. ,0.234375,0.2112676056338028,0.2222222222222222
775,SP:46d31f575928c68f60302520901feabe823e0dd4,"This paper proposes a new kind of episodic finite MDPs called ""deep hierarchical MDP"" (hMDP). An L-layer hMDP can be *roughly* thought of as L episodic finite MDPs stacked together. A variant of UCRL2 [JOA10] is proposed to solve these hMDPs and some results from its regret analysis are provided. ","This paper studies the theoretical aspects of HRL. It provides theoretical analysis for the complexity of Deep HRL. The idea is to exploit a given action hierarchy, and known state decomposition, the fact that the high-level state space shares similar low-level structures. The final result is an exponential improvement of HRL to flat RL. ",0.13725490196078433,0.125,0.13084112149532712
776,SP:46f8bfb644d14e8ff9a9053057e27f96c4c32a97,"The paper presents a model for the supporting sentence prediction task in machine reading comprehension. To enhance interpretability of the model, the paper proposes to use the semantic relations among a question, target sentence, and sentences in an article as features of the model. The semantic relations are obtained from semantic role labeling and named entities. The paper shows the prediction accuracy of the proposed model compared against some prior models, and conducts ablation experiments and case studies. ","The authors propose a method for adding interpretable semantic features for a Machine Reading Comprehension model  based on semantic relations across words and sentences.  The goal is to use semantic role labeling annotation to produce features used on a neural model for a language downstream task.  The main contributions are:  semantic features based on linguistic annotation, and interpretable semantic features for training a neural model. The study shows that the semantic features used to train Question Answering model performs comparable to related work. ",0.2692307692307692,0.25301204819277107,0.2608695652173913
777,SP:4706017e6f8b958c7d0825fed98b285ea2994b59,"This paper presents a new pointwise convolution (PC) method which applies conventional transforms such as DWHT and DCT. The proposed method aims to reduce the computational complexity of CNNs without degrading the performance. Compared with the original PC layer, the DWHT/DCT-based methods do not require any learnable parameters and reduce the floating-point operations. The paper also empirically optimizes the networks by removing ReLU after the proposed PC layers and using conventional transforms for high-level features extraction. Experiments on CIFAR100 show that the DWHT-based model improves the accuracy and reduces parameters and FLOPs compared with MobileNet-V1.","This paper proposes a new pointwise convolution layer, which is non-parametric and can be efficient thanks to the fast conventional transforms. Specifically, it could use either DCT or DHWT to do the transforming job and explores the optimal block structure to use this new kind of PC layer. Extensive experimental studies are provided to verify the new PC layer and experimental results show that the new layer could reduce the parameters and FLOPs while not loosing accuracy.",0.24752475247524752,0.32051282051282054,0.2793296089385475
778,SP:470d98d23a746a65b18404aaabf1a15d34fc24fa,The paper presents a learning method for the scenario of feature dependent label noise. A framework where label noise diminishes away from the decision boundary is established and a relabeling strategy based on this by relabeling highly confident points is proposed.  The method is a straight-forward adaptive method which the authors both theoretically and empirically explore in detail.,"Label noise is very frequently in many real world applications. However, the noise can be with different distributions. If we build the learning model under a certain distribution, it is difficult to capture the discriminative information. In this paper, without assuming that the noise is a certain distribution, the proposed method can handle the general noise, and it mainly target a new family of feature-dependent label noise, which is much more general than commonly used i.i.d. label noise and encompasses a broad spectrum of noise patterns. The experimental results show that the proposed method is promising. Meanwhile, the theoretical analysis of the proposed method is well inferred.",0.3050847457627119,0.16363636363636364,0.21301775147928992
779,SP:472a49b377cca8a9ffa8353f2f81c137c92e8578,"For linear regression, the paper shows that several popular heuristics used in deep learning correspond to regularized empirical risk minimization with sub-quadratic penalties, thereby, arguing that these methods indeed induce sparsity. The analysis leverages the so-called \eta-trick, where the penalty is replaced with its variational (minimization) form. Empirical results are also provided to support the theory. ","This paper examines stochastic perturbation methods, such as dropout, through the lens of the ""eta-trick"".  This trick allows the optimization objective to be re-written as a joint objective in terms of the original parameters and auxiliary parameters eta.  This new objective consists of the original loss in addition to a quadratic penalty in the parameters and a formulation-specific function of eta.  The paper shows that any adaptive dropout method that updates the dropout parameters monotonically as a function of the weight magnitudes is equivalent to regularized risk minimization with a subquadratic penalty, which is known to induce sparsity.  The paper analyses standout, variational dropout, L0 regularization, and magnitude pruning from this perspective, deriving the corresponding penalty term (Table 2) and allowing for comparison.  The paper then experimentally compares variants of variational dropout, finding that performance is well-described by the eta-trick reformulation since stochastic variants suffer from the introduced noise.  ",0.2711864406779661,0.1038961038961039,0.1502347417840376
780,SP:475019f17c9bf4c7e167222d56f920d12f8c8439,"This paper proposes to use Wasserstein distance in the primal form for imitation learning. Compared with its dual form and f-divergence minimization variants, it avoids the unstable minimax optimization. In order to compute the Wasserstein distance in primal form, they also propose a greedy approximation. Their experiments demonstrate that this method has a better performance compared with baseline methods.","The authors proposed an imitation learning algorithm that utilizes the primal form of Wasserstein distance to match agent’s and expert’s state-action visitation distributions. They considered the upper bound of the primal form and devise the optimization method based on greedy coupling which makes learning suitable for sequential problems. With standardized Euclidean distance and exponential smoothing, the proposed method PWIL is shown to perform well for both MuJoCo and Door Opening Tasks and highly outperforms the baseline (DAC) for Humanoid. ",0.2,0.14634146341463414,0.16901408450704225
781,SP:4752f8e41d60c11a80f110200f77cb8a3a64b68e,"The authors investigate the problem of learning a camouflage pattern which, when applied to a simulated vehicle, will prevent an object detector from detecting it. The problem is frames as finding the camouflage pattern which minimises the expected decision scores from the detector over a distribution of possible views of this pattern applied to a vehicle (e.g. vantage point, background, etc). This expectation is approximated by sampling detector scores when applying the detector considered to images synthesised using a number of vantage points and scene contexts. In order to generate a gradient signal with respect to the camouflage applied (the simulated image rendering is non-differentiable) the approach considers learning a clone network which takes as input the camouflage pattern, the vehicle model and a given environment and outputs the vehicle detector’s devision values. The clone network and the optimal camouflage are learned alternately in order to obtain a relatively faithful approximation. The approach is evaluated in simulation using two standard object detectors (Mask R-CNN and YOLOv3) on two vehicle models over a range of transformations.","Adversarial attacks and defences are of growing popularity now a days. As AI starts to be present everywhere, more and more people can start to try to attack those systems. Critical systems such as security systems are the ones that can suffer more from those attacks. In this paper the case of vehicles that attack an object detection system by trying to not be detected are tackled.",0.0670391061452514,0.1791044776119403,0.09756097560975609
782,SP:4758a1780d55349f71362bc930fba49a08895733,"This paper proposes locally constant network (LCN), which is implemented via the gradient of piece-wise linear networks such as ReLU networks. The authors built the equivalence between LCN and decision trees, and also demonstrated that LCN with M neurons has the same representation capability as decision trees with 2^M leaf nodes. The experiments conducted in the paper disclose that training LCN outperforms other methods using decision trees. ","This paper leverages the piecewise linearity of predictions in ReLU neural networks to encode and learn piecewise constant predictors akin to oblique decision trees (trees with splits made on linear combinations of features instead of axis-aligned splits). The core observation is that the Jacobian of a ReLU network is piecewise constant w.r.t to the input. This Jacobian is chosen to encode the hard splits of a decision tree. The paper establishes an exact equivalence between decision trees and a slightly modified form of the locally constant networks (LCN). The LCN used for experiments is slightly relaxed to allow for training, including ""annealing"" from a the softplus nonlinearity to ReLU during training, adding one or more output layers to perform the final prediction, and training with connection dropout. Experiments show LCN models outperform existing methods for oblique decision trees, but ensembles are often matched or outperformed by random forests.",0.3333333333333333,0.152317880794702,0.20909090909090908
783,SP:476e903197a3f3861692dfaa7136c5a274414e73,"The main contribution of this paper is a new heuristic for identifying ""less useful"" activation channels. The authors then propose using simple approximations for activation functions for these channels without compromising network accuracy. The main novelty in the approximation used by the authors is flexibility in the degree of the polynomial approximation. Additionally, the authors propose a new hyper-parameter search strategy (BTPBT) to efficiently search the hyper-parameter space for the optimal approximation parameters.","The paper present a system for two-party deep learning inference. The main contribution is activation layers that are more expensive in two-party computation are replaced by approximations dynamically based on the training data. To this end, the authors use a divide-and-conquer approach to gauge the impact of replacing activation functions of some layers by a version more amenable to secure computation. Furthermore, the algorithm also considers various degrees for approximation (0, 2, and 3). Experiments show that this reduces the latency by up to two thirds while maintaining a similar accuracy.",0.22666666666666666,0.17894736842105263,0.19999999999999998
784,SP:478a18897696ba946947faeee860203186d7e756,"This paper considers a unified framework named TERM for addressing a bunch of problems arising in the simple averaged empirical minimization. By leveraging the key hyper-parameter t in the TERM loss, it can recover the original average loss and approximate robust loss, min/max loss, and the superquantile loss, etc. The authors also propose gradient-based optimization algorithms for solving the TERM problem.  ","This work analyzes the LogSumExp aggregated loss (named tiled empirical risk minimization, or TERM, in the paper). It provides several general properties of the loss, such as its relation to min/avg/max-loss, and interpretations of different trade-offs. Empirically, it is shown that TERM can be applied to a diverse set of problems, including robust optimization, fairness and generalization.",0.21875,0.22950819672131148,0.22399999999999998
785,SP:47a15159ddb23477577e4378f534181cb8537ee5,"This paper analyzes Polyak momentum in the deterministic case for two simple but important non-convex problems: phase retrieval and finding the cubic-regularized newton step. It is shown that in both cases the problems posses a “benign region” in which the objective “looks” a bit convex. In the phase retrieval case, assuming that the data is generated from a normal distribution, it is shown that having a non-zero momentum parameter in fact allows the momentum method to find the benign region faster, after which standard convex analysis can take over to find the optimal point.","The authors analysed the dynamics heavy ball momentum in non-convex optimization settings (namely the phase retrieval and the cubic-regularized problems). The results show that the algorithm leads to a faster convergence rate in comparison with gradient descent without inertial contributions. Although there are results in the context of convex optimization, the result in non-convex setting is novel and very interesting. ",0.1958762886597938,0.30158730158730157,0.2375
786,SP:47a40977751b78338c8d1f18117521b58c6be39d,"The abstract and title of the paper convey the summary accurately. This paper proposes to improve the recently proposed work on N:M sparsity by Zhou et al., ICLR 2021. The former work results in models that have N:M unstructured sparsity that can be used in newer accelerators like Ampere but are handicapped by the fact that all the layers have the same sparsity ratios. This results in the inability to optimize for FLOPs for a given # parameter count thus having a knob for tuning the tradeoffs.   This paper proposes to fix that by proposing an iterative scheme called DominoSearch to find layer-wise fine-grained schemes/rations for N:M sparsity providing much-needed flexibility. DominoSearch operates on pre-trained models with a budget constraint and overtime figures out the good-enough mixed N:M scheme along with layer-wise sparsity for all the weight tensors on the network (layers). This is achieved with weight penalty as well as explicit layer-wise penalties combined with standard group-wise sparsity used for N:M scheme. The layer-wise penalty factor helps in trading off accuracy, FLOPs and model size is based on the sparsity achieved iteratively + a prefixed scheme like ERK for measuring redundancy.   With one caveat that all the baselines (except Zhou et al ICLR 2021) are trained from scratch and sparsity is induced during that time, while this paper works on pre-trained models. The experimental section is super strong and has strong practical implications along with a clear Pareto dominance on the baselines. ","The authors propose combining two existing techniques, N:M sparsity and per-layer (rather than uniform/global) pruning rates.  By allowing each layer to choose a particular N:M pair, the network can find a configuration that is not constrained to sharing a single N:M.  The solution is DominoSearch, an algorithm which starts with pretrained (dense) weights and determines a pruning threshold for each group of M weights based on the initial values.  Some number of iterations of fine-tuning adjust the weights gradually lower, in turn reducing each layer's chosen N.  Once some complexity target (either parameter or FLOP count) is hit, the network's layer-wise N:M are frozen, and the weights are finally fine-tuned.  A layer-wise penalty factor adjusts the overall complexity metric to account for layers which have relatively more or fewer FLOPs.  Empirical results show compelling reductions in FLOPs and parameters when compared to training with unstructured sparsity or uniform N:M sparsity.",0.13229571984435798,0.2085889570552147,0.1619047619047619
787,SP:47bcfdf057ce7e9fc379ea2e58b3c5e00b2b61a1,"This paper introduce a simple algorithm called deformable kernels. It learns to generate a collection of coordinate offset Δk for each of the convolutional kernel element. Then during convolution, the kernel is treated as a 2D regular grid and sampled (interpolated) according to the generated coordinate offset before applying to the inputs. An auxiliary shallow network is learned to generate those coordinate offsets based in inputs. This method is very similar to the existing ""deformable convolution"" algorithm, though this operate on the kernels instead. Numerical experiments on image classification and object detection tasks show that the method performs better or comparably to strong baselines. It boost the performance even more when combined with existing methods.","This work presents the idea of deformable kernels (DKs). As opposed to rigid kernels in standard convolutional networks, DKs allow each of their grid locations to be moved around in a larger kernel field. The offset by which a DK grid cell is moved is computed conditioned on the input to the network. To motivate the idea of DKs, the authors give some background on convolution, receptive and effective receptive fields (ERFs). The authors argue that since ERFs are spatially porous and irregularly distributed, one way to model them is to convolve square grids of input with DKs, which are composed of samples drawn from larger kernels. The authors define the concept of global and local DKs. They further contrast DKs with spatial sampling (deformable convolutions) and argue that although conceptually similar, both approaches are complementary to each other and can be used in combination in practice. Numerical experiments show competitive performance of DKs on image classification and object detection tasks. In the end empirical analysis is performed to analyze the characteristics of DKs.",0.26956521739130435,0.1781609195402299,0.21453287197231835
788,SP:47c40cbd381242ca804b1d6c6e95d04e28520733,"This paper proposes an unsupervised graph-level representation learning method considering global-local disentanglement. Specifically, the authors propose a GL-Disen model based on graph VAE architecture to jointly learn global and local representations for a graph. The global information is shared across the whole graph while the local information varies from patch to patch, corresponding to common and local factors, respectively. Empirical experimental results show that the learned representation achieves superior performance in the downstream graph classification task, and analyses demonstrate the learned representations exhibit some disentangle property.   ","In this paper, the authors proposed a disentanglement learning based approach for unsupervised graph level representation learning. They assume that disentangled representations which capture these global and local generative factors into independent latent units can be highly beneficial for graph level tasks. The extensive experiments and analysis  show that our method achieves the state-of-the-art performance on the task of unsupervised graph representation learning.",0.2247191011235955,0.30303030303030304,0.25806451612903225
789,SP:47cd92b480c1b66cd5c559da3909188d43e0db87,"The nature of FL workloads poses three evident system and machine learning challenges: communication overheads to broadcast models to clients and send locally-updated models back to the server; compute overheads, since clients might be in the form of constrained devices or battery powered; and overfitting, due to the asymmetric data distribution in the clients in terms of labels and number of training examples. The work here proposed (FedMorph) addresses these three challenges by morphing/extracting sub-models from the global model and dispatch these to the clients to perform local training. Then, the morphed sub-networks get aggregated into the global model via distillation. A FL setup using FedMorph demonstrates a much reduced overffiting. ","The paper proposes FedMorph to address the communication and computation heterogeneity problem in federated learning. At every round, small morphed sub networks are send to clients for local training. The server updates the global model by distilling from the aggregated morphed subnets.",0.12173913043478261,0.3333333333333333,0.17834394904458598
790,SP:480a43692dce83fedcd2464b293c1481d84e8952,"This paper focuses on transferability measures both in a supervised and unsupervised context. In particular, the authors propose a shrinkage-based estimation of H-score in order to correct its instability and discuss the limitations of the other approaches on two different scenarios: source model selection or target task selection. Experiments are done on these tasks on CIFAR.     ","This paper is interested in task transferability measures (both in the supervised and the unsupervised case). Task transferability measures are useful in quantifying how much knowledge of the source domain or model is transferable to the target model (or target domain in the unsupervised setup). Ultimately, one aims at having effective transferability measures to select the best setup for the task of transfer learning. The 4 main contributions of this paper are: - Highlighting instabilities in the computation of the H-score which leads to poor estimate, and proposing to correct these instabilities with regularized covariance estimations, demonstrating an 80% improvement over the original H-score - Fast implementation that is 3-55 times faster than another state of the art baseline - Identify problems with other existing transferability measures (NCE, LEEP and N LEEP) and propose to measure correlation against relative target accuracy (instead of vanilla accuracy). - In the unsupervised setup, propose to use dimension reduction to improve the effectiveness of existing and proposed transferability measures. ",0.3620689655172414,0.12804878048780488,0.1891891891891892
791,SP:4815005f4ab4a69abde3b5456b811e4e98ba86c7,"This work proposes a new form of adversarial training, supported by two proposed adversarial attacks based off a perceptual distance. The choice of perceptual distance (LPIPS), is computed by comparing the activations of (possibly different) two neural networks with respect to a pair of inputs. The authors propose two new attacks based off this perceptual distance: PPGD and LPA, as it is distinct from the common choice of L_2 or L_inf. This work claims that performing adversarial training against adversarial examples crafted by the proposed attacks, induces robustness to a wide range of ""narrow"" threat models e.g. L_2, JPEG, L_inf.","This paper studies the adversarial robustness of deep neural networks against multiple and unforeseen threat models. Since there lacks a precise formalization of human perception, this paper adopts LPIPS, a metric that correlates well with human perception based on neural network activations. Then, two adversarial attack methods are proposed to generate adversarial examples under the metric. And an adversarial training method is also proposed. The experiments on various threat models validate the effectiveness of the proposed method.",0.1523809523809524,0.2077922077922078,0.17582417582417587
792,SP:4821cbd324cb4e3eb2a62c6d39d6c30d184d88b6,This manuscript introduces the attention module into the framework of physics-informed neural networks. The contributions are: (1) proposing a network architecture that marries the popular attention mechanism to physics-informed neural networks. (2) separating the large attention module by operating on the channel and spatial dimensions individually. The authors empirically studied the efficacy of this architecture on PDEs including Navier-Stokes fluid simulation and Burgers equation.,"The authors propose a new architecture and loss function for training physics-informed neural networks (PINNs) on fluid flow problems. The idea is centered around augmenting a basic residual network with two additional attention blocks that are placed before and after residual blocks. These two new blocks aim to introduce channel and spatial attention into the model. In addition, they propose a new loss function that is tailored to solving PDEs such as Navier Stokes and Burgers Equation.",0.29850746268656714,0.2564102564102564,0.27586206896551724
793,SP:4834eb08d9761f5c3307e8c5c1fd3cac62032e26,"This work aims at providing a way of deriving explanations/reasons (in terms of features) from Boolean random forest (i.e., performing binary classification). They present three kinds of explanations (and the “minimal” variant for two of them): a direct reason is the most obvious one and directly comes from the interpretation of a single decision tree, a sufficient reason is one that is common to all trees, and a majority reason that is one related to the majority vote prediction and is appropriated for random forest models. Computational complexity is discussed for all approaches. ","This paper is devoted to computing abductive explanations for random forest (RF) machine learning (ML) models. Concretely, the paper proposes a variant of such explanations called majoritary reasons and argues that this new kind of explanation is not only easier to compute than computing sufficient reasons (both from the theoretical and practical points of view) but also that in practice they may be advantageous to a user due to their often smaller size than that of sufficient reasons. For that, an encoding and a MaxSAT-based solution for computing majoritary reasons for RF models is proposed. ",0.21052631578947367,0.20833333333333334,0.20942408376963348
794,SP:487be1dac03389a08da54338075aa5970f8c3588,"The paper argues that deductive reasoning is an open problem in current machine learning scenarios where features are learned rather than hand-crafted. To highlight the limitations of current approaches, the paper proposes a benchmark suite of 10 simple tasks (finding the minimum, divisibility test, etc.) that are trivial with some feature engineering, but are shown to be very hard without it. Experiments are performed with random forests, neural networks (MLP?), and recurrent neural networks.","This paper's contribution is introducing a set of tasks and datasets that require deductive approaches as opposed to common induction-based models. The paper tackles an important and interesting problem that helps to shape the future of the neuro-symbolic research area. My main concern however is, the paper ignores and does not cover the current state-of-the-art techniques and their corresponding datasets and by just introducing some datasets fail to give a correct image of the current efforts in this area. For example, the variation of Neural Turing Machine and Memory Networks has been successfully applied to the sorting problem (which has been proposed as one of the tasks of interest in deductive reasoning in this paper as well) [1], however, the authors have not discussed these class of networks at all. In fact, the authors mention the gap in the current models by talking about the need for models that can store the facts and the intermediate results for being able to conduct deductive reasoning but do not talk about the role and shortcomings of Memory Networks and Neural Turing based models or  Neural",0.25333333333333335,0.10052910052910052,0.14393939393939395
795,SP:4880635544d5dd03261487167b770ca4de40909f,"This paper presents a controllable rendering engine for MIDI files, based on the DDSP framework. Given F0 and loudness contour, DDSP can estimate the parameters of a harmonic + noise synthesis model, to render a corresponding audio file. Similar to MIDI2Params, which predicts framewise FO and loudness contours from a MIDI file, MIDI DDSP introduces an intermediate hierarchical level, allowing to control some newly introduced ""expression controls"". A mapping from MIDI files to ""expression controls"" is learnt, so that MIDI files can be automatically rendered. However, because these note wise controls are explicit, they also allow human manipulation of the performance rendering. Influence of the expression controls is assessed with a correlation study, showing that the human manipulation has the expected effect on the generated performance. This quantitative evaluation is further confirmed by convincing audio examples.","This paper proposes a music performance modeling network using three sub-modules which are expression generator, synthesis generator, and DDSP inference. The idea of using these three sub-modules to create three-level performance modeling (the three-level control values are notes, performance features, and synthesis parameters) is interesting and the result shows that the proposed model can give more ability of control while not harming the overall audio generation performance. It seems the proposed method that having three trainable networks with two hand-crafted methods (actually note detection is not the part of the contribution of this paper, so I didn't count it) gives full pipeline of hierarchical modeling and this is a good research contribution.",0.16296296296296298,0.1864406779661017,0.17391304347826086
796,SP:4896bf9436d8c03f6751b45118bf29ff0d116c6e,This paper tackles the task of going to a point-goal using an abstract 2D map of a given environment. The central idea is to use the given abstract 2D map to predict parameters for the transition function in the environment depicted by the map. This predicted transition function is used to search for actions to execute via planning.,"This submission tackles the Point Goal navigation task given access to the agent’s starting location, current state (position and velocity), the goal location and a top-down map. The submission presents two approaches for tackling this task. First is MMN (Map-conditioned Multi-task Navigator) which is model-based approach which learns to hyper-network to convert map input to a transition function. Second approach is MAH (Map-conditioned Ape-X HER DQN) which is model-free approach using Ape-X DQN with Hindsight experience replay.",0.2711864406779661,0.1839080459770115,0.2191780821917808
797,SP:48c5c18dac59913411633150b5f40fbcd1647d1e,"The authors propose a new method of coordinated, per client and weight dropout for federated learning. The intuition behind the method is to increase the dropout probability (probability of having a weight set to zero) for weights where different clients often have opposite parity gradients (as when those gradients are summed together are likely to cancel each other out). The authors show that doing this can reduce the computational cost on clients of FL by up to 3x.  ","The paper proposes a new method where local workers will drop part of their model using a shared dropout probability received from the server at each communication round. The dropout probabilities are computed by solving an optimization to promote similarity across agent's update. Compared with popular baselines in federated learning, the proposed method demonstrates better performance in terms of number of FLOPs.",0.16666666666666666,0.20634920634920634,0.18439716312056736
798,SP:48df1a6af80b29c4c38439bda1d69472ade37f2c,"This paper extends on the framework of matrix computation in Hinz & Van d Geer (2019) to give a tight upper bound for linear regions. In particular, the paper shows improvement over the bounds derived in Serra et al. 2018 and extends the bounds for more complex networks with skip and residual connections. The paper also shows why skip and residual connections can be beneficial by showing that they lead to networks with larger number of linear regions. ",This paper studies the counting of linear regions of a multi-layer ReLU network and gives an upper bound on the number of linear regions that is tighter than existing results. Networks with skip connections and pooling layers are also considered. The authors then compare their bounds for standard multi-layer networks and networks with skip connections/pooling layers and conclude that the latter has certain advantages in expressive power. ,0.24675324675324675,0.2714285714285714,0.25850340136054417
799,SP:48e591a5fa2802fc4bb0c7100d120ff860b074f3,"The paper aims at providing a mathematical structure for explaining the mechanism behind the attention block characteristic to transformers. The focus of the paper is on the scaled dot-product attention, reviewed in Eq. (1). In my understanding, the whole mechanism can be seen as an instance of the set kernel. The inputs are bags of items, where an item is denoted with $s_j$. The items are embedded into some feature space via matrix multiplication $W^V s_j$. The set kernel representation of a bag is obtained by weighted averaging of item embeddings, where the item-specific weight is the output of an exponential family model. The latter model is obtained by combining embeddings of items and corresponding context vectors, denoted with $t_i$ (see Eq. 1 for more details).","In this paper, the authors treat a particular Transformer, ""dot-product attention"", as  an RKBS kernel called ""exponentiated query-key kernel"". The explicit form of feature maps and Bach space are given. Moreover, authors term a binary kernel learning problems within the framework of regularized empirical risk minimization. The problem and the correponding representer theorem is new due to its extension to Banach space. A new approximation theorem is also proved and  some experiements are done. ",0.13636363636363635,0.23684210526315788,0.17307692307692307
800,SP:490d7696f5360437b3c735c3d21d417c369b2412,"This paper uses an autoregressive filtering variational approximation for parameter estimation in discrete dynamical systems. One issue that crops up with this *particular choice* of variational distribution is that (a) inference proceeds sequentially (by definition) and (b) this does not make use of parallelism in modern hardware. To mitigate this, the paper proposes using fixed point iterations. After the first iteration, the approximate posterior for each latent variable corresponds to a random draw from a logistic distribution. Each subsequent application of the fixed point iteration modifies the posterior distribution by incorporating information from the previous latent state. After T applications of the fixed point equation, the procedure approximates an auto-regressive variational posterior distribution. Its possible I've misunderstood the point being made in Sections 2.2 - 2.4, but the paper points out that the choice of iterations ""looks like"" a normalizing flow (with Jacobian 1).","Normalizing flows provide a way for variational posteriors to go beyond the mean-field assumption and introduce correlations in the posterior for latent variables. Typically, normalizing flows are only defined for continuous distributions, and the authors tackle the issue of creating flexible variational posteriors for discrete latent models. They posit a general autoregressive posterior family for discrete variables or their continuous relaxations. In order to perform variational inference with reparameterization gradients, one needs to have a sample from their variational family and be able to evaluate the density at the sample. The obvious way to sample from this autoregressive variational family is O(T) for T the number of autoregressive time-steps. Instead, they propose a method based off fixed point iterations to compute logits in parallel based off the results of previous iterations to generate an approximate sample. Moreover, they can interpret each iteration as a volume-preserving flow, so they don't have to add any terms to the density. They also use a continuous relaxation of Bernoulli random variables so they can back-propagate through a recognition network. They use their method on synthetic calcium spike data, and show that the correlated posterior is better-suited to handle uncertainty. ",0.17006802721088435,0.12376237623762376,0.14326647564469916
801,SP:4913d3bf3911917a1fd6752a3321beffc2804c7c,"The paper shows a method of Foveated Transformer motivated by a human foveal vision where the spatial resolution varies depending on the focused point. Namely, the method mainly consists of the spatial attention model that controls the gaze point and spatial-varying convolutional filter (dense pooling in center and sparse pooling in peripheral). The former simulates human gaze control and the latter mimics the human retina. The experimental validation is performed by the object recognition task (ImageNet) and adversarial attack tasks and performed better than the Deit-Tiny model that uses a similar number of parameters.","This paper proposes a called Foveater which uses a foveated module to extract the information from the feature map with different levels of details and different locations. This proposed method has the architecture that makes sense for the image classification task. However, I found it is difficult to find significant technical novelty in this paper.",0.10416666666666667,0.18181818181818182,0.1324503311258278
802,SP:49192c4c658b9b74837f6fe36d67289ec82d3e6c,"This paper proposes a method C5T5, a self-supervised pre-training method based on the T5 pre-trained model, which is able to make zero-shot select-and-replace edits to satisfy specific property values. The specific difference of this paper is the IUPAC names (a standardized molecular representation), and the method is totally self-supervised. The experiments are evaluated on octanol-water partition, distribution coefficients, polar surface area, and refractivity, above four properties. Experiments show that the designed methods are able to achieve the optimization objective. ","**Summary**  This paper proposed a way to modify the molecule based on language pretraining techniques. The sequence representation of molecules is based on IUPAC names, which can be more semantically meaningful and much easier to model than the SMILES or graph based molecule representation. The pretraining is done via a conditional text generation model where the model predicts the fragment names based on the remainder of the molecule and corresponding property values. The application on downstream molecule property optimization tasks show that the proposed approach is effective at obtaining high quality molecules. ",0.21839080459770116,0.20652173913043478,0.21229050279329612
803,SP:49577cf8ac5482e49fde9d222b889e5799c53c11,"In this paper, the authors build on the 'learning to learn' work, that aims to leverage deep learning models with optimization algorithms, most commonly with recurrent networks.  The goal is to utilize meta-learners that can adapt the optimization update strategy based on data/experience.  The authors aim to tackle problems that often arise in such meta-optimization schemes, such as covergence and generalization problems.  The paper is overall well-written, and several experiments are presented","This paper presents several improvements over the existing learning to learn models including Andrychowicz et al. (2016) and Lv et al. (2017). Specifically, this paper analyzes the issues in the original learning to learn paradigm (L2L), including instability during training and bias term issues in the RNN. It proposes a new loss based on weighted difference for improving the meta-optimizer in the later stage of optimization. It also proposes information sharing between RNNs for each coordinate. Finally it presents how to fine-tune the meta-optimizer on new task. ",0.21052631578947367,0.17777777777777778,0.19277108433734938
804,SP:4998f68082df1553ec138f34f999d7a7f9bfaa72,"The paper proposes a new metric to evaluate GANs. The metric, Cross Local Intrinsic Dimensionality (CrossLID) is estimated by comparing distributions of nearest neighbor distances between samples from the real data distribution and the generator. Concretely, it proposes using the inverse of the average of the negative log of the ratios of the distances of the K nearest neighbors to the maximum distance within the neighborhood. ","Statistics based on KNN distances are ubiquitous in machine learning. In this paper the authors propose to apply the existing LID metric to GANs. The metric can be decomposed as follows: (1) Given a point x in X, compute the k-nearest neighbors KNN(x, X) and let those distances be R1, R2, …, Rk. Now, rewrite LID(x, X) = [max_over_i (log Ri) - mean_over_i (log Ri)] to uncover that the distribution of (log-)distances is summarized as a function of the max distance and the mean distance. (2) To extend the metric to two sets, A and B, define CrossLID(A; B) = E_(x in A) [LID(x, B)]. To see why CrossLID is useful, let X be the observed data and G the generated data. First consider CrossLID(A, B) where A=B=X which determines a lower-bound which is essentially the average (over elements of A) LID statistic determined by the underlying KNN graph of X. Now, keep A=X, and progressively change B to G (say by replacing some points from X with some points from G). This will induce a change of the distance statistics of some points from A, which will be detected on the individual LID scores of those points, and will hence be propagated to CrossLID. As a result, LID close to the baseline LID detects both sample quality issues as well as mode dropping/collapse issues. In practice, instead of computing this measure in the pixel space, one can compute it in the feature space of some feature extractor, or in some cases directly in the learned feature space of the generator. Finally, given some labeling of the points, one can keep track of the CrossLID statistic for each mode and use this during training to oversample modes for which the gap between the expected CrossLID and computed one is large.",0.4090909090909091,0.08626198083067092,0.14248021108179418
805,SP:49ac2a2ac51be0f41d095bcdf204b6da967b98b2,"This paper considers safe RL through solving a constrained MDP in (1). The authors proposed a primal method which alternates between maximizing the reward and minimizing the constraint violation. The convergence rate of the algorithm is also provided under standard settings, e.g., bounded reward, iid samples, etc.. Interestingly, the authors also analyzed the case for using a 2-layer neural network (NN) function approximator for the policy and the actor. ","This paper proposes a new method for constrained MDP. The proposed method does not require primal-dual formulation and is easy to implement given the availability of state-of-the-art policy optimization solvers.  When the natural policy gradient is used as the  policy optimizer,  a sublinear global convergence rate is proved for both the tabular setting and the function approximation case.",0.2676056338028169,0.3064516129032258,0.28571428571428564
806,SP:49bb8457a99e6a178e7893c9629e6543b15a564a,"This paper analyses the consistency-based SSL methods in settings  where  data lie a manifold of much lower dimension than the input space and obtains tractable results. The paper relates the analysis with Manifold Tangent Classifiers and shows that the quality of the perturbations plays a key role  to achieve a promising results in this set of SSL methods. Finally, the paper extends the Hidden Manifold Model by incorporating data-augmentation techniques and proposes a framework  to provide a direction for analyzing consistency-based SSL methods.","The authors analyze consistency-based models in specific settings where analytically tractable results can be obtained. They establish that leveraging more sophisticated data augmentation schemes is crucial to obtain huge gains when using consistency based models. Finally, they propose an extension of Hidden Manifold Model that incorporates data augmentation for understanding and experimenting with SSL methods.",0.22093023255813954,0.3392857142857143,0.2676056338028169
807,SP:49dbe409062fa25cd57b8cf7e30a8321e8e94c0b,"Proposes an importance sampling approach to sampling failure cases for RL algorithms. The proposal distribution is based on a function learned via a neural network on failures that occur during agent training. The method is compared to random sampling on two problems where the ""true"" failure probability can be approximated through random sampling. The IS method requires substantially fewer samples to produce failure cases and to estimate the failure probability.",This paper proposed an adversarial approach to identifying catastrophic failure cases in reinforcement learning. It is a timely topic and may have practical significance. The proposed approach is built on importance sampling for the failure search and function fitting for estimating the failure probabilities. Experiments on two simulated environments show significant gain of the proposed approaches over naive search. ,0.22857142857142856,0.2711864406779661,0.24806201550387597
808,SP:49eadb6ece84834c7132156b2769cd0a720ac8fb,"The authors propose a generative model that is a combination (product) of a VAE and an EBM, where the goal of the EBM is to reduce the probability of out-of-manifold samples, which are typically generated by VAEs. The authors propose efficient training and sampling procedures, in which the VAE is trained first and during the EBM negative-phase, samples are drawn from the joint (x, z) VAE space using reparameterization. The method is shown to achieve high quality samples on several modern image datasets, good FID scores and mode coverage. Ablation studies show the contribution of the different elements.","This paper proposes a model that corrects VAE by an energy-based model defined on image space. The model is learned in two phase. The first phase learns the VAE model, while the second phase learns the EBM correction term by MLE. Experimental results show that the proposed method outperforms pure EBM defined on image space and also pure VAE models by large margins. ",0.1782178217821782,0.28125,0.21818181818181817
809,SP:49ef0331201083490748c1dbcd12d130cb0a68d4,"This work studies the head size <--> head number tradeoff in multihead attention. It argues and formally establishes that (1) the expressivity of an attention head is determined by its dimension and (b) fixing the head dimension, one gains additional expressive power by using more heads. In response to such observations, the paper proposes Fixed Multihead Attention, where the constraint that `head_size * number_of_heads = embedding_size` in standard multihead attention is lifted; and it allows for using more attention heads without making each head smaller. One can control the total amount of parameters by using smaller embedding sizes, making it comparable (in terms of #parameters) to standard multihead attention. Empirical results on language modeling and NLI tasks confirms the arguments. ","This work discusses how to set the projection size for each head (head size) in multi-head attention module, especially Transformer. Theorem 1 is interesting, which points out a lower bound for the head size. The proposed method is to decouple the dependency between the head size and the embedding size. The experiments show that the proposed method is able to achieve comparable performance to BERT with fewer training cost.",0.17355371900826447,0.3,0.2198952879581152
810,SP:49ef158a8170a8002d1111080db8009d5a6419d1,"This paper provides a unique perspective on the implicit regularization effect of gradient descent that has been observed and studied previously. The authors point out that the discrete steps taken by the gradient descent updates means that the path followed through the optimization landscape is not that of steepest descent, but some alternate path. Thinking of GD as trying to solve the continuous time evolution equation implied by GD, they analyze the errors that the actual updates make in solving this equation. Given these errors, they construct an alternate ODE whose solution has a discretization that is precisely the GD updates (up to higher order corrections in the learning rate). Determining the loss implied by this alternative ODE gives an additional term, proportional to the norm squared of the gradient, the learning rate, and the number of parameters. This ""Implicit Regularization'' leads to flatter optimization solutions, implying a positive effect on the generalization properties of models optimized under GD.","The authors show the discrete steps of gradient descent implicitly regularize models by penalizing trajectories that have large loss-gradients, which is called Implicit Gradient Regularization in the paper. The authors adopt a standard argument from the backward error analysis of Runge-Kutta methods to show this phenomenon. In the paper, the authors also provide some empirical results which indicate gradient descent leads to flat minima where test errors are small and solutions are robust to noisy parameter perturbations.",0.1320754716981132,0.26582278481012656,0.17647058823529413
811,SP:4a1a4003949cbe2f0d0fee232d166874ab52716f,"In contrast to standard reinforcement learning (RL), the paper investigates the variant where the observation made by the agent about its state has a cost. The authors propose to model the problem as a POMDP with an augmented action space (normal action + observation accuracy) and a new reward function that is defined as the original one penalized by the observation cost. They solve the problem with TRPO in three control domains: mountain car, pendulum, and cart pole.","The paper proposes a reinforcement learning algorithm that enables an agent to ""fine tune"" the quality/accuracy of its sensors to its current task. The paper considers a partially observable MDP setting where the agent, besides the control actions, is endowed with a set of ""tuning actions"" that control the noise in the perception of the different components of the state. Additional reward terms are introduced that discourage the use of ""tuning"". By enabling the agent to fine tune its perception to the current task, the paper seeks to also investigate the relative importance of different state features in terms of the task.",0.22077922077922077,0.1650485436893204,0.18888888888888888
812,SP:4a2116053dafd3977fbf2e9d2879fce7c3965448,"In this paper, the authors propose a new variant of Transformer called Tied-multi Transformer. Given such a model with an N-layer encoder and an M-layer decoder, it is trained with M*N loss functions, where each combination of the nth-layer of the encoder and the mth-layer of the decoder is used to train an NMT model. The authors propose a way to dynamically select which layers to be used when a specific sentence comes.  At last, the authors also try recurrent stack and knowledge to further compress the models.","This work proposes a way to reduce the latencies incurred in inference for neural machine translation. Basic idea is to train a model with softmax attached to each output of decoder layers, and computes a loss by aggregating the cross entropy losses over the softmaxes. During inference, it could either use one of the softmax or train an additional model which dynamically selects softmaxes given an input string. Experimental results show that it is possible to reduce latencies by trading off the translation qualities measured by BLEU. Dynamically selection did not show any gains in latencies, though, this work empirically shows potential gains in oracle studies. This work further shows that the model could be compressed further by knowledge distillation.",0.20212765957446807,0.15833333333333333,0.17757009345794392
813,SP:4a83a8ba8190703c509ecc17fbdc70e82e67d6c8,"This paper studies the traffic forecasting problem and proposes to conduct prediction by pattern matching. Authors first extract key patterns from the historical data in an offline manner and then fetch the patterns for each time series with a distance function (e.g., cosine similarity). Then, the patterns of different nodes are interacted with GCN to get node representation.",This paper explores a new direction of model design in traffic forecasting tasks. It proposes a neural memory module to model the spatio-temporal traffic data and designs a new traffic forecasting model based on the memory module. Experiments on a few public datasets demonstrate the effectiveness of the proposed scheme. ,0.22033898305084745,0.2549019607843137,0.23636363636363636
814,SP:4a83aeec9e7a387683678c056e71a70d238511ed,"To deal with data scarcity in context of learning large Transformer language models for theorem proving, this work proposes a methodology (called PACT) for extracting auxiliary task data for joint training alongside the tactic prediction objective. The methodology has been applied to Lean proof assistant. PACT significantly improves the theorem proving success rate on held-out suite of test theorems. ","This paper addresses the general setup of using transformer models for interactive theorem proving (ITP) tasks. The ITP engine considered here is Lean. The contribution of the paper is a data augmentation method. This is achieved by mining low level artifacts from a given dataset of Lean proofs. This includes data extracted from additional type information inferred by Lean while processing the given proofs. Several prediction tasks are formed for this additional data, to allow pre-training and co-training in combination with the existing WebMath dataset. Results show that the additional datasets extracted in this way aid substantively when used for pretraining and cotraining. ",0.21666666666666667,0.12380952380952381,0.1575757575757576
815,SP:4adb251b077fb8d1046be25622ca6f7f7be78989,"In this work, the authors propose a new strategy to compress a teacher neural network. Briefly, the authors propose using Bayesian optimization (BO) where the accuracy of the networks is modelled using a Gaussian Process function with a squared exponential kernel on continuous neural network (NN) embeddings. Such embeddings are the output of a bidirectional LSTM taking as input the “raw” (discrete) NN representations (when regarded as a covariance function of the “raw” (discrete) NN representations, the kernel is a deep kernel).",This paper proposes a method for finding optimal architectures for deep neural networks based on a teacher network. The optimal network is found by removing or shrinking layers or adding skip connections. A Bayesian Optimization approach is used by employing a Gaussian Process to guide the search and the acquisition function expected improvement. A special kernel is used in the GP to model the space of network architectures. The method proposed is compared to a random search strategy and a method based on reinforcement learning.,0.25609756097560976,0.24705882352941178,0.251497005988024
816,SP:4addc1c9c0f91be7fc176425cb41c22cb4e562ba,"The paper proposes a method for avoiding the oversmoothing happening in standard GNN methods. It defines a receptive field of a node, as the set of nodes that send messages to that node and proposes a method to create adaptive receptive fields specific to each node. Instead of using all the nodes in a multi-hop neighbourhood, an reinforcement learning method is proposed to select only a subset of these nodes. The RL problem is formalised such that each state represents a set of already selected nodes, while actions represent the next selected node. The goal of the RL agent (constructor) is to form an adaptive neighbourhood for each node, and the reward is given by the loss of a GNN method (evaluator) that uses this neighbourhood. ","The authors theoretically and empirically show that soft-attention mechanism uses in GCNs suffers from over-smoothness in large neighborhoods. For addressing this shortcoming, they propose a neighborhood sampling approach called adaptive receptive fields (ARFs) which discretely select nodes among the multi-hop neighborhood and allow to efficiently explore long-distance dependencies in graphs. The authors also propose GRARF (GCN with Reinforced ARF) which learns optimal policy of constructing ARFs with reinforcement learning. For a given node, an RL agent successively expands ARF via a two-stage process. Firstly, a contact node in an intermediately-constructed ARF is selected and then a context among the direct neighbors of the contact node is added to ARF. The reward is the performance of the trained GCN on constructed ARF. Overall, the results demonstrate the effectiveness of the approach on benchmark datasets. The authors also demonstrate that the method is quite effective at handling noise in the graph compared to GCN and GAT by evaluating them on the Cora dataset with synthetically added noise.  ",0.2047244094488189,0.15204678362573099,0.174496644295302
817,SP:4ae68ed1b9175b904a6f026277e9ff8bb288797b,"This paper focuses on analyzing the regularization of adversarial robustness (AR) on neural networks (NNs). They establish a generalization error (GE) bound characterizing the regularization of AR, and identify two quantities: margin distributions and singular values of NNs' weight matrices. With empirical studies, they show that AR is achieved by regularizing NNs towards less confident solutions and making feature space changes smoother uniformly in all directions, which prevents sudden change wrt perturbations but leads to performance degradation.","The paper presents new theory to develop understanding about why adversarially robust neural networks show lower test performance compared to their standard counterparts despite being more robust to perturbations in the data. The main hypothesis is that the degradation in performance in adversarially robust networks is due to many samples being concentrated around the decision boundary, which makes the network less confident about its decisions. The paper studies this hypothesis by deriving a bound on the generalization error based on the margin between the samples in the training set and the decision boundary. The paper then presents empirical demonstrations that aim to illustrate the theoretical findings. ",0.15584415584415584,0.11320754716981132,0.13114754098360654
818,SP:4ae6b28a86ddef3fcb212ba132c2058109fbc938,This paper studied how to leverage the power of graph neural networks for counting subgraph isomorphism. The motivation is that the current subgraph isomorphism detection is NP-complete problem and a proposed approach based on GNN could approximately solve the counting problem in polynomial time. Then they relaxed original subgraph isomorphism (which is equivalent to the exact subgraph matching problem)  and proposed the problem of doing subgraph isomorphism counting task. The GNN and sequence modeling methods are discussed for solving this problem. The experimental results confirmed the effectiveness of these methods. ,"This paper proposes a method called Dynamic Intermedium Attention Memory Network (DIAMNet) to learn the subgraph isomorphism counting for a given pattern graph P and target graph G. This requires global information unlike usual GNN cases such as node classification, link prediction, community detection. First, input graphs P and G are converted embedding vectors through sequence models (CNN, RNN, Transformer-XL) or graph models (RGCN), and fed into their DIAMNet that uses an external memory as an intermedium to attend both the pattern and the graph. The external memory is updated based on multi-head attention as in Transformer. The output of DIAMNet is passed to FC that outputs 'count' directly. The training is based on minimizing MSE loss as a regression problem. Extensive experimental evaluations report that DIAMNet showed superior performance over competing methods and baselines.",0.1978021978021978,0.13138686131386862,0.15789473684210525
819,SP:4aebddd56e10489765e302e291cf41589d02b530,"The paper presents a new NN architecture designed for life-long learning of natural language processing. As well depicted in Figure 2, the proposed network is trained to generate the correct answers and training samples at the same time. This prevents the ""catastrophic forgetting"" of an old task. Compared to the old methods that train a separate generator, the performance of the proposed method is noticeably good as shown in Fig 3. This demonstrates that the new life-long learning approach is effective in avoiding catastrophic forgetting.",This paper studies the problem of lifelong language learning. The core idea underlying the algorithm includes two parts: 1. Consider the NLP tasks as QA and then train a LM model that generates an answer based on the context and the question; 2. to generate samples representing previous tasks before training on a new task. ,0.12643678160919541,0.2,0.15492957746478875
820,SP:4b23ef2262646d8e924f67770af22618f5e83b39,"In this paper, the authors propose neural channel expansion (NCE) to adjust the network structure to compensate for the performance degradation from uniform-precision quantization. Given a hardware constraint, the proposed NCE selectively expands the width for the quantization sensitive layers. Experiments on CIFAR-10 and ImageNet shows the effectiveness of the proposed NCE. However, the novelty of this paper is limited since the proposed method is just an extension of TAS. Besides, the comparisons between NCE and the existing methods are missing. My detailed comments are as follows. ","The authors propose neural channel expansion (NCE), a neural architecture search (NAS) and quantization method. Existing NAS+Q methods typically search for the architecture of the DNN along with the precision at each layer, maximizing accuracy while respecting some kind of hardware constraint. The result is a DNN with mixed-precision, which is challenging for most existing hardware (which only support one or a few precisions). NCE keeps precision the same in each layer, and instead uses the precision sensitivity signal in the NAS to adjust the width of the layer (expand or shrink). The result is uniform-precision, hardware-friendly DNN.",0.24719101123595505,0.21568627450980393,0.23036649214659685
821,SP:4b307b0c041fd25ca19dedd123ecacb3888182bb,"This paper proposes a nearest-neighbor-based algorithm for implicit maximum likelihood.  Samples are produced by the generator network and then a nearest neighbors algorithm is run to match the samples with their nearest data point.  The generator is then updated using the Euclidean distance between samples and neighbors as the optimization objective.  Six conditions are then provided, and if they are met, then the authors show that this method is performing maximum likelihood on the implied density.  Experiments report Parzen window density estimates, samples from the model, and latent-space interpolations for MNIST, Toronto Faces, and CIFAR-10.","The paper proposes a new algorithm for implicit maximum likelihood estimation based on a fast Nearest Neighbor search. The algorithm can be used to implicitly maximize the likelihood of models for which the former quantity is not intractable but for which sampling is easy which is typically the case for implicit models.  The paper shows that under some conditions the optimal solution of the algorithm corresponds to the MLE solution and provides some experimental evidence that the method leads to a higher likelihood. However, The paper lacks clarity and the experiments are not really convincing. Here are some remarks:",0.24242424242424243,0.24242424242424243,0.24242424242424243
822,SP:4b745d0f1a688e009c1eff19df47effd48a053ee,This paper proposes vision transformer based VQGAN whose encoder and decoder are implemented as transformers rather than standard CNNs. It provides few improvements that demonstrates quantitatively better results in multiple datasets in unconditional / conditional image generation. It also shows how the proposed model can perform well as an unsupervised representation learning framework. ,"This paper mainly investigates how to further improve the image generation quality of previous work VQGAN, where several modifications are proposed to train a better quantized auto-encoder model. After modeling the discrete tokens with an auto-regressive transformer, we could observe that the generation results of the proposed ViT-VQGAN are really amazing and beat most of previous works in various benchmarks. Meanwhile, ViT-VQGAN also demonstrates its exceptional representation capabilities through unsupervised linear-probing.  To summarize, it seems there are several key factors to obtain a better reconstruction model:  - Project the latent codes into lower dimension, which leads to a larger codebook size and less ‘dead’ codes. - StyleGAN Discriminator. - $\ell_{2}$ normalization on latent variables. - Stronger backbone (ViT-like architecture or decoder with more parameters).  ",0.17307692307692307,0.07086614173228346,0.1005586592178771
823,SP:4b9fa87d7dcf9f5efec1e834cbb1a27f468cba02,"This paper describes a two-stage encoder-decoder model for semantic parsing. The model first decodes a cross-domain schema (CDS) representation from the input utterance, then decodes the final logial form from both the utterance and CDS. The model outperforms other multitask Seq2Seq models on the Snips (Goo et al., 2018) dataset, but is still behind the traditional slot-filling models (Goo et al., 2018).","This paper introduces “Cross domain schemas” (CDS) for semantic parsing of utterances made to a virtual assistant. CDS captures similarities in requests according to the underlying actions or attributes being discussed, regardless of the user’s high-level intent. Also introduced is a model which leverages CDS to improve semantic parsing of utterances to a meaning representation language (MRL). This model first parses an utterance to CDS, then uses an encoding of the CDS jointly with the utterance encoding to decode a meaning representation. By treating different intents as separate domains, the authors construct a multi-task learning setup for CDS and MRL parsing. Results are provided for the Snips dataset of virtual assistant queries. ",0.2727272727272727,0.1565217391304348,0.1988950276243094
824,SP:4bafcd10c07834bb7e4008f5d089edda2c7a01e5,"The paper studies meta-reinforcement learning in the fully offline setting, and proposes a novel algorithm 'FOCAL'. Given offline datasets for tasks sampled from some prior, the algorithm learns a context encoder using distance-based metrics. The encoder is used for inferring the task-latent $z$, which is used to condition the policy rollout $\pi(a | s, z)$. They demonstrate experiments where FOCAL outperforms baselines like PEARL.","This paper tackles the problem of offline meta reinforcement learning, where an agent aims to learn a policy which can adapt to an unseen task (dynamics/reward), but from entirely offline data. As a result of being fully offline, the agent can no longer explore in the new task at test time, but instead receives randomly sampled transitions from the new task, from which it must infer the task. They then propose a method for learning task inference from fully offline data, as well as a policy conditioned on this task encoding from offline data built off behavior regularized actor critic (BRAC). Results indicate that in this outperforms PEARL as well as multi-task offline RL with BCQ.  ",0.23880597014925373,0.13559322033898305,0.17297297297297295
825,SP:4bdba79c4d8aae31317a3aae2915e2fd459cd2f6,"This paper modifies the basic network architecture of two mainstream self-supervised optical flow estimation methods from events in order to create a Spiking NN version of them. The paper compares several neuron models, loss functions, and gradient computation methods for training. Performance is comparable to classic CNN methods.  ","The paper investigates optical-flow estimation from event-cameras, and in particular provides the first deep SNN solution for real-world applications of this concept. The approach filters event streams from the input into an event-representation where every partition has the same number of events, which is then fed to the SNN. A backward pass is also possible using a contrast maximization loss. A new self-supervised learning framework is introduced.  The results show the new method to be on par with the state-of-the-art.",0.22448979591836735,0.125,0.16058394160583941
826,SP:4c1ba325175a1a289d7467dc269d20eabc67383c,"The paper proposes a novel method for embedding numerals which can be learned by using neural word embedding learning techniques. The paper motivates the work by reviewing the difficulty of embedding components to represent numerals: OOV in most cases. Their main contribution is the introduction of a method composes numeral embedding by a weighted average of prototype embeddings based on the similarities between the numeral and prototypes. There are two proposed prototypes: SOM and GMM and the similarity functions are an absolute difference and the density function respectively. During the training, the numerals have the proposed embeddings while the others have normal word embeddings. The paper slightly modifies the negative sampling to ensure numerals being sampled. A series of 4 empirical studies have been presented. First, the paper confirms that the proposed method does not negatively affect non-numeral embeddings. And then, the quality of the numeral embeddings are evaluated and compared. The experiments show that the proposed method has better performance on numerical property tests, numeral prediction, and a sequence labeling task.","The paper talks about a recently highlighted problem in word embeddings which is their incapability to represent numerals, especially the out-of-vocabulary numerals. For addressing the problem, they propose a method that induces a finite set of prototype numerals using either self-organizing map or Gaussian Mixture model. Then, each numeral is represented as a weighted average of prototype numeral embeddings. The method also involves squashing large quantities using log function. Finally, the training is performed similar to Skip-gram in word2vec but with the embedding of numerals computed using prototype numerals. ",0.14450867052023122,0.26881720430107525,0.1879699248120301
827,SP:4c48dff5afc7fefe00e4c7e92e319ae4a68165cd,"The paper proposes a metric for unsupervised model (and hyperparameter) selection for VAE-based models. The essential basis for the metric is to rank the models based on how much disentanglement they provide. This method relies on a key observation from this paper [A] viz., disentangled representations by any VAE-based model are likely to be similar (upto permutation and sign).","This paper addresses the problem of unsupervised model selection for disentangled representation learning. Based on the understanding of “why VAEs disentangle” [Burgess et al. 2017, Locatello et al. 2018, Mathieu et al. 2019, Rolinek et al. 2019], the authors adopt the assumption that disentangled representations are all alike (up to permutation and sign inverse) while entangled representations are different, and propose UDR method and its variants. Experimental results clearly show that UDR is a good approach for hyperparameter/model selection.",0.26229508196721313,0.2,0.2269503546099291
828,SP:4c50cbd2b765c3b7abca57e5ef2a1c0a2990668d,The paper proposes simple modifications to GAN architecture for unsupervised conditional image generation. The authors achieve this by making the distribution of noise z dependent on variable y that can depend on the label distribution when available. This involves learning to predict the input noise z as well as y from the generated image. The qualitative results shown for unsupervised conditional image generations using the approach are convincing. ,"This paper is concerned with the so-called conditional generation, which was descried as the task of sampling from an unknown distribution conditioned on semantics of the data. This proposed method aims at achieving this by using a latent distribution engineered according to a certain data prior. Experimental results showed that the proposed method seems to produce good results.",0.16176470588235295,0.1864406779661017,0.1732283464566929
829,SP:4c52d1c81fa793c07fb6ea1dc85b107acb709254,"This paper proposes a neural architecture search (NAS) algorithm which automatically finds a efficient network architecture, FasterSeg, for real time semantic segmentation. In designing a NAS algorithm the author takes cue from recent architectural advances introduced for faster segmentation as well as improved accuracy. For instances a) it explores and integrates multi-resolution branches from BiSeNet during NAS b) simultaneously optimizes the loss for accuracy and latency (as done in CAS algorithm) and c) knowledge distillation for semantic segmentation. However, the usage of these blocks in FasterSeg has been well refined to integrate with NAS search. To be precise, their improved version of latency loss avoids architectural collapse during latency-constrained search and it claims to be the first work to co-search for teacher and student network using NAS. Empirical experiments on benchmark dataset suggests that FasterSeg  is more than 30 percent faster with similar accuracy as state-of-the-art real-time segmentation algorithms.","This paper presents an automatically designed semantic segmentation network utilising neural architecture search. The proposed method is discovered from a search space integrating multi-resolution branches, that has been recently found to be vital in manually designed segmentation models. To calibrate the balance between the goals of high accuracy and low latency, the authors propose a decoupled and fine-grained latency regularization, that effectively overcomes the observed phenomenons that the searched networks are prone to “collapsing” to low-latency yet poor-accuracy models. Moreover, the authors extend the proposed method to a new collaborative search (co-searching) framework, simultaneously searching for a teacher and a student network in the same single run. The teacher-student distillation further boosts the student model’s accuracy. Experimental results on Cityscapes, CamVid, and BDD verified the efficacy of the proposed method.",0.1987179487179487,0.22627737226277372,0.21160409556313992
830,SP:4c6ace9170685dc461c8d15b84a507ce37246d81,"This paper defines and presents a method for the novel task of panoptic 3D scene reconstruction, i.e. jointly predicting complete 3D scene geometry, 3D semantic and 3D instance labels. The method consists of using backbone 2D models for depth and instance segmentation and lifting them into 3D before processing with a SG-NN [5] like model to complete and refine the initial volume into instance, semantic and occupancy/TSDF volumes. The authors propose an ""instance propagation"" method to associate 2D instance masks with 3D instances which is shown to improve over a post hoc ""instance clustering"" in a 3D semantic only volume. Experiments on a synthetic dataset (3D Front) and Matterport3D show improvement over prior works , some of which tackle a subset of the problem (e.g. only scene structure and semantics).   The primary contribution of this paper is the definition of this new holistic panoptic 3D scene reconstruction task and a new method and evaluation metric for the same with improved performance over prior works which tackle these individual tasks in isolation.","The authors define a new problem called ""panoptic 3D scene reconstruction"" - a joint task of 3D geometry prediction, semantic segmentation, and instance segmentation, from a single RGB image. To address this new task, a two-stage method is proposed. In the first stage, 2D CNN is used to predict 2D features, a depth image, and 2D instance segmentations. In the second stage, these 2D features and instance segmentation results are back-projected into 3D, and then passed into a 3D CNN for the final 3D predictions. This proposed pipeline is demonstrated on the synthetic 3D-front dataset, as well as the Matterport3D real-world dataset, and significantly outperforms prior related work.",0.1724137931034483,0.2702702702702703,0.2105263157894737
831,SP:4c8f0cf7f6196f586ec83d16a768742d13a16cea,"This work proposes a new metric for calibration in classification where calibration is measured over localities in the input space, and the localities are determined with a kernel over the feature space. A recalibration algorithm (LoRe) is additionally proposed, which aims to recalibrate the class predictions w.r.t. local calibration error (LCE). The experiments show that 1) LoRe achieves better local calibration (measured by MLCE, i.e. maximum LCE) than baseline recalibration methods on ImageNet, 2) LoRe achieves better group-wise calibration (measured by worst group-wise maximum calibration error) across 3 datasets with identifiable groups, and 3) achieves competitive performance in a simple decision making task where confident incorrect predictions incur high costs. ","This paper proposes a new measure of calibration called Local Calibration. While conventional calibration measures are only defined with probabilistic outputs, the proposed local calibration measure further incorporates the feature space by considering the neighbouring region with a kernel. The authors also propose a calibration method according to the definition and experimentally demonstrate the advantages.",0.14782608695652175,0.3090909090909091,0.19999999999999998
832,SP:4ceb178b6b3d531512c7740d0fb52a00b7a95f04,"This paper proposes a ""decentralized"" method for representation learning in knowledge graphs that doesn't explicitly depend on a learned embedding for the entity node of interest, e_i. Rather, the embedding for e_i is constructed in a distributed fashion (similar in motivation to the distributional hypothesis/skip-gram word embeddings) from its neighbors via a second-order attention mechanism. The main idea is that this is better for ""cold start"" problems in which unknown entities might have no features, which makes building any representation that explicitly depends on entity-centric features hard.","This paper presents a method for knowledge graph embedding based on graph attention networks (GAT). The key idea is to avoid using the information for a node (i.e., its representation vectors) when computing the attention weights for the neighbors of the node. The paper argues that this approach can better generalize to unseen nodes where no pre-defined features/information is available. As such, the paper does not include the representations for a node $e$ from prior layers in the aggregations to compute $e$'s representations in the next layers, leveraging the representation vectors of the nodes from prior layers to obtain attention weights for the current layer. The paper also proposes to a self-learning method to learn the parameters by optimizing the mutual information of the final and initial embedding vectors for the nodes. A distillation approach is also employed to use the initial embedding vectors as the teachers and the final embedding vectors as the students. The proposed method is applied to two downstream tasks, i.e., entity alignment and entity prediction, leading to competitive performance with many prior works (the learned node embeddings still need to be aligned using task-specific losses). Some experiments on unseen entities and ablation studies are also conducted to demonstrate the benefits of the proposed method. ",0.24468085106382978,0.10648148148148148,0.14838709677419354
833,SP:4d58f330415e44e06446eaccd907b9fa0861f40e,"The paper introduces a novel way to solve Full-Waveform Inversion problem which is a common problem in geological surveys. Their method is based on CNN, giving a reconstruction of velocity field for measured seismic data, and the loss function which connects CNN to a discretized version of the governing partial differential equations (the wave equation). The power of the method lies in unsupervised learning which allows one to use more data without expensive data labelling. This is demonstrated using numerical results using their simulated seismic dataset. ","The paper presents a method for full-waveform inversion (an inverse problem in seismic imaging) that combines a convolutional neural network (CNN) with a physics-based forward modeling operator. As opposed to other work which directly learns the inverse mapping from measurements to the sought-after velocity parameter, the authors propose an ""unsupervised"" approach. Here, the CNN takes the seismic measurements as input and predicts a velocity field. Then, the physics-based forward operator produces measurements which can be compared to the original measurements to train the network. The authors evaluate their method on a new simulated dataset and show that it can outperform other supervised approaches. ",0.25287356321839083,0.205607476635514,0.2268041237113402
834,SP:4d67a9c7e532e4c0f0e3150d9330cc233802c12f,"The authors apply (tree-based) genetic programming (GP) to RNN search, or more specifically RNNs with memory cells, with the foremost example of this being the LSTM. GP provide a structured search that seems appropriate for designing NN modules, and has previously been applied successfully to evolving CNNs. However, the authors fail to mention that (tree-based) GP has been applied to evolving RNN topologies as far back as 2 decades ago, with even multiple cells in a single RNN unit [1]. The selection of more advanced techniques is good though - use of Modi for allowing multiple outputs, and neat-GP for more effective search (though a reference to the ""hall of fame"" [2] is lacking).","This paper explores evolutionary optimization for LSTM architecture search. To better explore the search space, authors used tree-based encoding and Genetic Programing (GP) with homologous crossover, tree distance metric, etc.  The search process is pretty simple and fast. However, there is a lack of experiments and analysis to show the effectiveness of the search algorithm and of the architecture founded by the approach. ",0.14655172413793102,0.265625,0.18888888888888886
835,SP:4da7ae6cfcf4cab7581bab283e12354b60d3b2dd,"In this paper, the authors propose a method to train models in FP16 precision. The authors show that the key reason of training performance drop is the overflow or underflow of back propagation information. Instead of using a fixed value or dynamic value proposed by a previous work, this paper adopts a more elaborate way to minimize underflow","The authors propose an adaptive loss scaling method during the backpropagation stage for the mix precision training to reduce the underflow. Compared with the previous work, which scales the loss by human design, and needs to be consistent in all layers. The authors state that they can decide the scale rate layer by layer automatically to reduce the underflow in a low precision situation. ",0.22413793103448276,0.203125,0.21311475409836064
836,SP:4df661cd71eb3a7947d890ff84e25f48b6b38012,"This paper presents an empirical study on the effect of face obfuscation in the ImageNet dataset. The main conclusion is that face obfuscation does not decrease the utility of the dataset. Specifically, the authors showed that various networks trained on the obfuscated dataset only experienced small accuracy drop on the image classification task. The authors also discussed the impact on different categories, showing that face obfuscation hurt more to the object categories that are more closely related to faces (i.e., the bounding boxes of which overlap more with faces). Last but now least, experiments has been conducted to show that face obfuscation also does not have a significant impact on the transferability of the features learned from the new dataset. All these conclusions are inline with intuitions since ImageNet is not primarily focused on human activities / faces.","The main concern addressed in this paper is the privacy problem that may result from images in ImageNet databases containing unexpected faces. The authors propose a two-step face filtering method. First, the authors use a detector called Amazon Rekognition to detect the ImageNet database. Then, the authors further optimize the detector output through the crowdsourcing platform Amazon Mechanical Turk (AMT) to reduce false positives and false negatives in automated detection. For the detected faces, the authors took two approaches, distinguishing between blurring and overlaying, and tested their effectiveness on different models separately. The accuracy of the two approaches was reduced by 0.9% on average compared to the original database on the ILSVRC classification challenge. And using the database that has blurred or covered the faces still maintains the transferability of the original database in the tests of downstream tasks. Contribution： 1. The authors perform a very time-consuming and labor-intensive task for accurate labeling and filtering of faces in the ImageNet database and statistical analysis of the classes of faces contained in ImageNet. 2. The authors demonstrate experiments related to classification tasks and pre-trained model training using a database containing blurred or covered faces, proving that the theory is feasible and that the dropped accuracy is acceptable. 3. In terms of ethics, using blurred or covered face data for training can reduce privacy concerns. The study of the ImageNet database in terms of privacy can provide an important reference for subsequent databases",0.2318840579710145,0.13008130081300814,0.16666666666666669
837,SP:4df83f99f68580ffe805e3826ea01f4a0c5dc523,This work targets learning multi-class classifiers in the continual learning setting. The key idea is to learn new tasks by taking gradient steps in directions orthogonal to the gradient subspaces marked as crucial for previous past tasks. The method employs SVD after learning each task to find the crucial subspaces (which it calls as Core Gradient Subspaces) and stores them in a memory. Reasonable quantitative and qualitative evaluation has been performed to compare the method against existing SOTA baselines.,"The paper proposes one of the most scalable approaches to sequential continual learning with known task boundaries and related tasks, while taking steps towards enforcing data privacy and removing some of the task label constraints. At all levels in expressive deep models, SVD is used on learned representations to identify important bases of task gradient spaces and a memory is populated with such directions. Learning progresses only in directions orthogonal to gradient memory. Several recent evaluation methodologies are used to empirically validate the approach with significant success. ",0.2,0.1839080459770115,0.19161676646706585
838,SP:4e110cb77b848272f468030bfe05014d08d7b838,"This work proposes the h-potential, which is a solution to an objective that measures state-transition asymmetry in an MDP. Roughly speaking, in many situations some state transitions (s-->s’) are more probable than their converse (s’-->s), and if we have a function that assigns a higher value to a more probable transition (compared to its converse), then we can use it as a measure of the “reversibility” of that transition. This function can then be used, for example, as an intrinsic reward signal; indeed, there may be cases where state transitions should be avoided if they are not reversible. ","This paper proposes that we learn the “arrow of time” for an MDP: that is, a function (called the h-potential) that tends to increase as the MDP steps forward. Such an arrow should automatically capture notions such as irreversibility, and so can be used to define a measure of reachability, which previous work has shown can be used to penalize the agent for causing negative side effects. In addition, it can be used as intrinsic motivation for the agent: in particular, the agent can be rewarded for trajectories that decrease the h-potential (i.e. are “like” going backwards in time, or reducing entropy), which is hard to do and should lead to interesting skills. They propose that we learn the arrow of time by optimizing a function to grow over time along trajectories take from a random policy. Experiments demonstrate that in simple environments the learned function has the properties we would expect it to given results from physics.",0.21568627450980393,0.13664596273291926,0.16730038022813687
839,SP:4e236051d8d837d5c6795e61e9ccf075cc3108bf,"The paper presents a scalable approach to recommend datasets from data providers to consumers looking to assemble datasets to pre-train models for downstream tasks. The approach does not leak source data from data providers and target data from consumers, and instead uses an intermediary public dataset and expert models trained on subsets of this public dataset to evaluate the data in sources that are likely to benefit the target tasks. The approach is scalable (independent of the number of source datasets), does not transfer source or target datasets to a server, transfers only expert models, and evaluates these expert models only on the source datasets and target datasets in the provider and consumer servers alone to keep computation costs low. The experiment results demonstrate the efficacy of this method, and show (somewhat surprisingly) that it is able to identify relevant source datasets even when the intermediate public dataset does not contain data relevant to the target downstream tasks.","This paper presents an idea of a data recommender system called Scalable Neural Data Server (SNDS) to support transfer learning for target customers. The interesting point is that SNDS does not store any source or target dataset on the server, but only maintains the benchmark intermediary datasets, and the pools of experts that are trained on the intermediary datasets. SNDS shares the pool of experts to both data providers and consumers to compute similarities between the consumer's data and the data provider's datasets. Image rotation prediction is used to measure the expert model's performance on the source and target datasets. In this way, SNDS indirectly measures the data similarity between the sources and targets. Compared to its predecessor NDS, SNDS trains experts for an intermediary public dataset, instead of training an expert for each source. Using this method, SNDS achieves scalability as well as securing datasets from both sides. Extensive experiments are done to gauge the usefulness of data recommended by SNDS. With SNDS-recommended source, classification performance on target datasets improved significantly. To support this, the authors show that domain confusion exists between target datasets and recommended sources. The performance gain using SNDS is comparable to that of NDS, even though SNDS trains experts on the public datasets and promises cheaper computation costs. Besides, SNDS generalize to types of images that are not represented in the public dataset. ",0.29559748427672955,0.2025862068965517,0.24040920716112532
840,SP:4e23c046f8234b35d88e3957b0725fb7a3d06374,"This paper presented a memory-based continual learning model where relationships between training samples are represented with a random graph that is defined from the non-linear embedding of the input data. Catastrophic forgetting between tasks is partially (1) alleviated with a graph regularization that penalizes changes of random graph statistics, and (1) memory replay and reservoir sampling to update memory. The performance of this model is evaluated against several state-of-the-art models to handle the catastrophic loss. ","The paper proposes a novel way of using random graphs to improve task-free continual learning method. It builds to random graphs, G and A, based on the similarity of images stored in the memory and those of the current tasks, and utilize the relative information to build representation of the images and predict. The idea is well-formulated, and carried out in a sound way. The graph regularization term resembles the knowledge-distillation, as the authors also mentioned, but it serves different purpose of preserving the covariance structure of the outputs of the image encoders. ",0.225,0.1875,0.20454545454545456
841,SP:4e2ac2684ed817d9221154e922dabd54ff51fc90,"This paper points out that momentum in GD optimizers results in a far more rapid reduction in effective step sizes for scale-invariant weights.  To solve the problem, two algorithms called SGDP and AdamP are proposed, which project the updates to tangent space of the parameter. Experiments on several tasks including image classification, language modeling, etc show the effectiveness of the proposed algorithms. The idea to study the integration of BN and momentum is interesting. The analyses and proposed algorithms provide guidance to practitioners. ","This paper shows that momentum-based gradient descent optimizers reduce the effective step size in training scale-invariant models including deep neural networks normalized by batch normalization, layer normaliztion, instance normalization and group normalization. The authors then propose a solution that projects the update at each step in gradient descent onto the tangent space of the model parameters. Theoretical results are provided to show that this projection operator only adjusts the effective learning rate but does not change the effective update directions. Empirical results on various tasks are provided to justify the advantage of the proposed method over the baseline momentum-based (stochastic) gradient descent and Adam.",0.2857142857142857,0.22429906542056074,0.2513089005235602
842,SP:4e39dea3cdfdad801112d4894b73503345de78dc,This paper proposed inter-domain gradient matching for domain generalization. They also approximated the proposed model with a simple first-order algorithm to avoid costly second-order computations.  The performance on the WILDs and DomainBed seems better than the ERM algorithm. ,The work tries to tackle the problem of domain generalisation in multi-source setting. The main claim of the paper is that by maximising inner product  between gradients from different domains leads to better learning of domain invariant features. The provide a meta-learning inspired algorithm Fish to approximate the second-order derivates. The results on several domain generalisation dataset is shown. ,0.24390243902439024,0.16129032258064516,0.1941747572815534
843,SP:4e5cbc8389be556e7f0bc008d19d635e6736622f,"The paper presents an analysis of differential privacy in machine learning, with a focus on neural networks trained via differentially private stochastic gradient descent (DPSGD). The main focus and the message in the paper is that the handcrafted features work better compared to learned features during training of NNs and having more training data results in better outcomes (i.e. a better privacy-utility trade-off).","The paper considers ways of improving private versions of SGD in the context of image classification. The main finding is that providing ""hand crafted"" features can significantly improve the privacy/accuracy trade-off. In some cases, even a linear model built on top of such features (like those produced by ScatterNet), can improve over differentially private SGD. A plausible explanation for this phenomenon is that extra features can reduce the number of iterations required in SGD, resulting in better privacy and/or less noise. (It is also argued that having much more data similarly improves the trade-off, but this is unsurprising and, it seems, has been observed before by McMahan et al.)",0.2878787878787879,0.168141592920354,0.21229050279329612
844,SP:4e5cd6138722d9bfe662959519d7edadbbd2ea52,"This paper introduces an anchor-free object detection framework that aims at simultaneously predicting the object position and the corresponding boundary. To achieve this, the proposed FoveaBox detector predicts category-sensitive semantic maps for the object existing possibility, and  produces category-agnostic bounding box for each position that is likely to contain an object. The scales of target boxes are associated with feature pyramid representations. Experiments are performed on MS COCO detection benchmark.","The paper introduces foveabox, a method that performs ""keypoint"" like object detection -- instead of ""anchor"" based detection (to be discussed later). The idea is simple: predict class labels for pixels that fall within (a reduced version) the GT boxes of the instance; and predict bounding box offsets for those positive pixels. The idea is built on top of the FPN backbone, where a set of feature maps (each representing a specific scale) are used to detect object boxes in multiple scales.  The method is mainly compared against RetinaNet (which is ""anchor"" driven), and also compared against other more recent methods (ExtremeNet, CenterNet, FCOS) etc. ",0.2328767123287671,0.16346153846153846,0.19209039548022597
845,SP:4e6499c7c269d851002e32c68d302d727424f4d3,"The paper studies the standard denoising problem under the assumption that the unknown n-dimensional signal can be written as the output of a known d-layer neural network G mapping k dimensions to n dimensions. The paper specifies an algorithm to perform this denoising and the algorithm is based on a variant of the usual gradient method. Then, under additional assumptions on the neural network G, the paper proves that their algorithm produces a denoised signal that achieves a mean squared accuracy of k/n. Because the input signal has ""effective"" dimensionality k (as it can be written as G(x) for some k-dimensional x), it is nice that it can be recovered at the accuracy k/n by Gradient Descent despite the complicated nature of G. In this respect, the result is quite interesting. However, the underlying assumptions are too strong in my opinion as described below: ","The paper analyzes the recovery accuracy of a ""tweaked"" gradient descent algorithm for imaging denoising and compressive sensing under deep generative priors. In particular, when assuming Gaussian randomness of the network weights and extremely stringent conditions of network sizes, they demonstrate a specific denoising rate of O(k/n), with k and n being the input and output dimension of the generative network. This is seemingly optimal in terms of the dependence on the latent code dimensionality and the signal dimensionality and is the first result of this kind. ",0.16666666666666666,0.2808988764044944,0.2092050209205021
846,SP:4e822c1ba32ac54bfc6edf160d684c8fb84bdc36,"This paper proposes a new regularizer to improve GAN training. By noticing that the discriminator does not always reach optimum at each iteration, this paper proposes Adversary's Assistant (AdvAs) for helping the discriminator to satisfy this condition. Interestingly, compared to the previous methods for improving GAN training, this work applies the regularizer at the generator (rather than the discriminator) and is theoretical motivated. Experiments on several GAN objectives, datasets and network architectures are provided to support the effectiveness of AdvAs.","This paper concerns how to efficiently regularize the generatior for training generative adversarial networks (GANs). A new regularizer for the generator loss is proposed to penalize the norm of the gradient with respect to discriminator’s parameters ($\phi$). In other words, the generator learns to encourage small norm of the discriminator’s gradient w.r.t $\phi$. The author(s) also propose a heuristic to remove the introduction of a further hyperparameter. The author(s) applied the proposed regularizer to WGAN-GP, AutoGAN, and StyleGAN2 to validate its effectiveness. Their experiments reveal that the new regularizer is promising.",0.2222222222222222,0.1836734693877551,0.2011173184357542
847,SP:4ee46486b69550aea4f1a3a6beb0caf6ea8c635e,"The paper studies the problem of global optimization of high-dimensional sparse estimators regularized by PCP (folded concave penalty). The main result is showing that under certain conditions, with high probability, the desired global solution is an oracle stationary point satisfying the so-called S^3ONC conditions. In light of this result and an existing polynomial-time algorithm for finding an S^3ONC solution, the global solution can be recovered with polynomial computational complexity. Numerical evidence is provided to show the theoretical predictions. ","The authors study the high-dimensional sparse estimation problems, which is one of the fundamental topics in both machine learning and optimization communities. In the literature, the folded concave penalty (FCP) methods have been shown to enjoy the strong oracle property for high-dimensional sparse estimation.  While LASSO solutions can be easily computed, such solutions do not admit unbiasedness and oracle property or require strong conditions. Therefore,  the problems with FCP have received much attentions and been studied in terms of hardness and approximability of the problems recently .",0.1927710843373494,0.18181818181818182,0.18713450292397663
848,SP:4f201b7e397d5a6e30ca7cea4b379baa1a046899,"The paper proposes the IMA model, a scalable model that learns modality importances and robust multimodal representations through a novel cross-covariance based loss function. The proposed model performs unimodal inference in absence of modalities and also addresses the problem of detecting important subspaces in each modality through weighted cross-covariance loss terms, which are minimized by unimodal importance networks. Results are shown that the IMA model is able to distinguish digits from uncorrelated noise, and word-level importances are learned that correspond to the separation between function and emotional words. The multimodal representations learned by IMA are also competitive with state-of-the-art baseline approaches on downstream tasks.","This paper presents a multimodal Autoencoder framework that learns the multimodal latent representations alongwith the importance of regions in each modality’s representation space in an unsupervised fashion. Multimodal fusion algorithms either use complex architecture representations or use disentangling joint representations for improving generative auto-encoding architectures using VAEs, GANs, WAE and some variants of these. This paper presents an elegant importance based model and architecture that takes into account various local and joint loss functions along with alignment factors to represent the Autoencoder model.",0.16363636363636364,0.21176470588235294,0.18461538461538463
849,SP:4f867d248d56c66b38031050c4b180ac1f21cd5d,"The paper proposes a non-approximate method for solving MAP inference problem in collective graphical model (CGM). The paper uses difference of convex algorithm (DCA) strategy as a solver for the optimization problem since the objective function can be expressed as a sum of convex and concave function. The solution is obtained via minimization of a surrogate function that upper bounds the objective function. The technical details appear to be correct and the simulation results show the superiority of the proposed algorithm over its competitors. Further, a real world application involving car trajectories is performed to validate the performance of the proposed methodology.","The authors consider the problem of MAP estimate of count data given noisy count data. For example $X_1(t), X_2(t), \ldots, X_M(t)$ describe the location of an agent at time $t$, $N_i(t)$ is the number of agents at location $i$ at time $t$, and $Y_i(t)$ is a noisy estimate of $N_i(t)$. The goal is to estimate $N$ given $Y$. The noise distribution is assumed to be log-convex.  The authors develop an approach based on the difference of convex algorithm, which is an extension of the convex-concave procedure. They show that this procedure can monotonically improve a solution by repeatedly solving the minimum convex flow problem, which is known to be efficiently solvable.  The authors demonstrate that their approach improves over non-linear belief propagation with a continuous approximation of the discrete time problem.",0.23300970873786409,0.1643835616438356,0.19277108433734938
850,SP:4f8854605423fab230a26fa2d12d3bfef54b0ca5,"The paper aims at increasing the sample diversity of neural processes when the condition set is small, while maintaining visual fidelity. The low-data regime is arguably where neural processes are most interesting, and in that regard the paper is right to turn to this setting. The discussion on how different aggregation functions affect the predictive uncertainty of the neural process is also appreciated, as is the experiment on regressing the size of the condition set based on the latent embedding.","This paper proposes an improvement of the standard NP by using a mixture distribution \q_{\phi}, semi-implicit variational inference, and max pooling to capture the multimodel structure of the posterior distribution. Replacing one normal Gaussian distribution with a mixture (of Gaussians, normally) is a widely-adopted idea in latent variable models including NP; the adopted semi-implicit variational inference was originally developed in Yin and Zhou ICML 2018, and no further improvement on this inference method is proposed in this manuscript; max pooling is one of three commonly used pooling methods, i.e., max, min, and mean pooling. using one of them to replace another is simple but the explanation of the reason why max pooling is better is interesting and profound. So, the improvement is weak although it is shown to be effective by the empirical study. More importantly, the authors have investigated the posterior contraction of NP. It is interesting. The relationship between the two parts of the objective function of NP has been discussed related to the posterior contraction, both parts have contributed to the contraction apart from their classical explanation on reconstruction and regularization. To my best knowledge, it is the first work to discuss the posterior contraction of NP. It is a classical property in Bayesian and this link will enable further theoretical analysis for NP. ",0.2716049382716049,0.0990990990990991,0.14521452145214522
851,SP:4f8f34e95732b3f87b23878289062d359cda110f,"The authors propose PARCUS (""Pattern Representations on Continuous Spaces""), a model which computes a soft-matching probability for all words in an input sequence with so-called prototypes in order to predict a label for the input. Furthermore, for training, PARCUS makes use of rationales. Those are indicators of input importance, and help to boost the loss for relevant tokens.","This paper considers the problem of text classification, especially the settings in which the number of labeled sentences is very small. However, authors assume, annotations of rationales behind the label, i.e. highlighting tokens in a sentence which are important in deciding its label. As per my understanding, this is a big limitation. Second, the proposed model makes inference of class labels just based upon occurrence of words in a sentence, rather than making more sophisticated inferences relying upon sub-sequence patterns at least. ",0.16666666666666666,0.11904761904761904,0.1388888888888889
852,SP:4f9202a08ea9a0a243b07b0536906deca67f2391,"The paper presents a method for seizure detection and classification. In particular, the method is self supervised, based on graph neural network and use EEG signals. The authors report significant performance in detection and classification, as well as provide methods for qualitative evaluation of model interpretability. ","The authors propose a graph-based representation from thresholded  Gaussian and linear (correlation) kernels (undirected connectivity) coupled with a diffusion convolutional recurrent network. Besides, a Fourier-based preprocessing is carried out with self-supervised (autoencoders) to initialize the network weights.  Experiments are performed on an EEG-based seizure detection and localization task. The seizure localization is conducted using occlusion and dropping approaches on EEG channels. Obtained results elucidate an interesting strategy for seizure analysis on a well-known public database.",0.2391304347826087,0.1375,0.17460317460317462
853,SP:4f9c3ed91f44326e3bddf14223779d7f5fa07954,This paper proposes a Quantization neural network to spiking neural network (QNN2SNN) conversion method. The authors first analyze the conversion error between ANN and SNN. Then they construct the ann with quantized activation so that the error can be eliminated. Both theoretical and empirical results are presented in this paper. ,"This paper proposes a quantization clip-bottom-shift activation function to replace the ReLU activation function in ANNs, so as to better approximate the activation function of SNNs. The authors also prove that the expected error of ANN-SNN conversion can be reduced to 0 by using this method. The reported results on CIFAR-10/100 and ImageNet dataset show that this work archives state-of-the-art accuracy with fewer time-steps.",0.32,0.2191780821917808,0.26016260162601623
854,SP:4fba557254310577845d291e0f216dc76403c9ac,"The paper tries to handle the class imbalance problem by decoupling the learning process into representation learning and classification, in contrast to the current methods that jointly learn both of them. They comprehensively study several sampling methods for representation learning and different strategies for classification. They find that instance-balanced sampling gives the best representation, and simply adjusting the classifier will equip the model with long-tailed recognition ability. They achieve start of art on long-tailed data (ImageNet-LT, Places-LT and iNaturalist).","The paper considers the problem of long-tailed image classification, where the class frequencies during (supervised) training of an image classifier are heavily skewed, so that the classifier underfits on under-represented classes. Different known and novel sampling schemes during training as well as post-training procedures to restore the class balance after training are studied. The overall best strategy turns out to be naive training on the skewed training set, and post-hoc rebalancing only of the classification stage. The paper presents various ablation studies and comparisons with related methods on the ImageNet-LT, Places-LT, and iNaturalist data sets, achieving state-of-the-art performance.",0.2619047619047619,0.205607476635514,0.23036649214659685
855,SP:4fc7700df32695121eeb7c7a858077c45c50b44d,"Results: To defend against adversarial attacks, this work experimentally analyzes the feature distribution of traditionally- trained CNNs for gaining more knowledge about adversarial examples. Two properties, i.e., the non-clustering property and confusing-distance property, of the feature distribution are identified by means of t-SNE visualization and clustering analysis (showing the limitations regarding representativeness) in Figure 1. The authors introduce a loss function which separates out cluster centers of CNN output features, setting them as far as possible - so that model accuracy is preserved while strengthening robustness. They test on two datasets: CIFAR10, MNIST, and show improvements in ""robustness"" of the model. ","This paper tackles the problem of training models that are robust to adversarial inputs. The authors starts by observing that previous models generate embeddings that can both (i) place same-class embeddings in different clusters and (ii) different-class embeddings in close proximity. They then introduce new loss functions that penalize these behaviors and design a training procedure (MAT) around these new losses. Finally, they show favorable performance of MAT compared to state-of-the-art techniques for addressing adversarial robustness.",0.14423076923076922,0.18518518518518517,0.16216216216216214
856,SP:4fdd94362be6718ab249cdb8da4e75b9eade64bd,"This work explains how to use a seq2seq encoder-decoder neural network on the case of multivariate time series. The authors name this particular application of seq2seq the wave2wave network. Given a multivariate time series covering a time interval, it is split into subintervals of equal length, such that each block is a matrix. This matrix becomes an input into a recurrent encoder. On the decoder side, the similar matrix is produced at the output. The proposed neural network is tested on two data sets: an earthquake and activity translation.","In this paper, the authors propose modifications to baseline seq-to-seq systems for wave-to-wave translation. To handle possibly long inputs and outputs, as well as significant length differences, they propose to use sliding windows. For high-dimensional outputs, they use an iterative approach predicting each dimension independently. They evaluate their models on earthquake data on on activity translation (video to motion capture).",0.1,0.13846153846153847,0.11612903225806452
857,SP:4fe317ebc002abdec341b978f730b3dcaa58b9cf,This works aims at task-oriented fine-tuning from pre-trained ImageNet models. It proposes a Neural Architecture Search and Online Adaption framework (NASOA) to perform fast task-oriented model fine-tuning. The NASOA first employ an offline NAS to select a group of models and then pick up the most suitable model from this group via an online schedule generator. ,"In this paper, a joint Neural Architecture Search and Online Adaption (NASOA) framework is proposed to achieve a faster task-oriented fine-tuning upon the request of users. In particular, two main contributions are made in this paper: (1) A fine-tuning pipeline that seamlessly combines the training-efficient NAS and online adaption algorithm is introduced, which can effectively generate a personalized fine-tuning schedule of each desired task via an adaptive model for accumulating experience from the past tasks. (2) A block-level and macro-level search space is introduced in the resulting framework, which enables a simple to complex block design and fine adjustment of the computation allocation on each stage.",0.32786885245901637,0.17699115044247787,0.22988505747126434
858,SP:4fe65143f73a8de8303ad2fbd71e998ae9317152,"This is the first work that studies probability calibration for knowledge graph embedding models. In the case where ground-truth negatives are available the authors directly use off-the-shelf established calibration techniques (Platt scaling, isotonic regression). When ground-truth negatives are not available they propose to synthetically generate corrupted triples as negatives and use sample weights to guarantee that the frequencies adhere to the base rate.","The paper studies probability calibration for three different knowledge graph embedding methods, with a focus on TransE evaluated on the task of knowledge graph triple classification. It studies Brier and log loss performance of Platt scaling and isotonic regression probability calibration on WN11 for TransE and claims that better calibration yields better performance as measured by mean reciprocal rank. Calibration plots for other datasets are also included as evidence. Furthermore, evidence is presented that probability calibration can lead to better performance for the task of triple classification. The main contributions of the paper also include the adaption of sampling techniques introduced by Bordes et al. (2013) adapted for estimating negatives for probability calibrations.",0.26865671641791045,0.1592920353982301,0.19999999999999998
859,SP:50073cbe6ab4b44b3c68f141542c1e81df0c5f61,This paper proposed the temporal graph attention layer which aggregates in-hop features with self-attention and incorporates temporal information with Fourier based relative positional encoding. This idea is novel in GCN field. Experimental results demonstrate that the TGAT which adds temporal encoding outperforms the other methods. Overall this paper addressed its core ideas clearly and made proper experiments and analysis to demonstrate the superiority against existing counterparts.,"This paper addresses the problem of representation learning for temporal graphs. That is, graphs where the topology can evolve over time. The contribution is a temporal graph attention (TGAT) layer aims to exploit learned temporal dynamics of graph evolution in tasks such as node classification and link prediction. This TGAT layer can work in an inductive manner unlike much prior work which is restricted to the transduction setting. Specifically, a temporal-kernel is introduced to generate time-related features, and incorporated into the self-attention mechanism. The results on some standard and new graph-structured benchmarks show improved performance vs a variety of baselines in both transduction and inductive settings. ",0.23529411764705882,0.14545454545454545,0.17977528089887643
860,SP:500d68ce2d8f1e6fea4fa54703101c6823ba2b6c,Authors propose an augmentation technique for image classification. The augmented image is obtained by segmenting the salient object and masking the background. Therefore the technique gives one additional augmented image per each training image. The authors show an improved performance when using this augmentation on binary classification task (cats vs. dogs) using a dataset of 2000 images.,"This work proposes to augment object focused image to improve image classification. Essentially, this work tries to remove background from original image using an existing algorithm and human editor, and train an image classification model using different combinations of original images and background-removed image. Five simple models are trained and their performance is compared to show that using background-removed images together with original images can help improve accuracy on validation set on a simple dataset. ",0.19298245614035087,0.14285714285714285,0.16417910447761194
861,SP:503051a1584c3f2fe519fb8154c63b9066bb4a26,"This paper advocates for studying the effect of design choices in deep learning via their effect on entire *learning curves* (test error vs num samples N), as opposed to their effect only for a fixed N. This is a valid and important message, and it is indeed an aspect that is often overlooked in certain domains. However, although this paper addresses an important issue, there are methodological concerns (described below) which prevent me from recommending acceptance. In summary, the paper oversimplifies certain important aspects in both the setup and the experiments.","In this paper, the authors first propose a simple weighted least squares method to compute the ""learning curve"" (error plotted against dataset size) , where error is modelled with the form error = alpha - eta*n^gamma, for parameters alpha, eta, gamma. Gamma is taken to be - 0.5, while alpha, eta are estimated from the data. This also allows an estimate of ""data reliance"", in essence the slope of error wrt dataset size, computing how much error decrease is dependent on dataset size.",0.14285714285714285,0.15853658536585366,0.15028901734104047
862,SP:5042502317c1ae133d310b3ede02e7abde1a7507,"In this paper, the authors introduce a novel procedure to predict or acquire insights from the structure of a macromolecule (such as a protein, RNA, or DNA), represented as a set of positions associated with atoms or groups of atoms in 3D Euclidean space. Their approach, called GVP-GNN, can be applied to any problem where the input domain is a structure of a single macromolecule or molecules bound to one another. Their approach is divided into two steps: model quality assessment and computational protein design. ","The challenge of predicting the structure of biological macro-molecules is widely relevant in many applications and difficult to address. This paper divides the types of approaches taken to address this challenge into those that use ""geometric"" information (i.e. positions of molecules in space), and those that utilize ""relational methods"" mainly through graphs (how different parts of molecule relate). This study is an attempt to integrate the two source of information by a novel network architecture. They introduce geometric vector perceptrons as a way of summarizing geometric information for graph layers without loss of information as it happens in dense layers. They evaluate the performance of these architectures on MQA and CPD tasks, both relevant and standard benchmarks in the field. ",0.18604651162790697,0.13114754098360656,0.15384615384615383
863,SP:50759dd814d98ba988b7cc423e3115d62e05db47,"This method proposes to decompose convolutional filters using a low rank filter basis where the convolutional operation in a layer consists of shareable filter basis and non-shareable layer coefficients. This is developped to save computational costs whilst maintaining performance. To regularise against vanishing/exploding gradients and promoting more useful representations, the authors seek orthogonal filter basis'. This filter basis is shared across layers in contrast to other works who look at recursive sharing.","This paper addresses the problem of obtaining more compact CNNs by a parameter sharing method. The authors propose to represent a weight filter in a low-rank subspace (represented as a linear combination of low-rank filter basis) plus a set of non-shared low-rank filter basis (per-layer). In this way, the shared low-rank filter basis is reused across several layers, and the non-shared ones per layer are used to enhance model generalization ability. Experiments are performed on CIFAR and ImageNet datasets, using some popular CNN structures for evaluation.",0.28378378378378377,0.22580645161290322,0.25149700598802394
864,SP:50780fb6b72c0da68cb960a12530c54a831222de,"This paper investigates the degree to which we might view attention weights as explanatory across NLP tasks and architectures. Notably, the authors distinguish between single and ""pair"" sequence tasks, the latter including NLI, and generation tasks (e.g., translation). The argument here is that attention weights do not provide explanatory power for single sequence tasks like classification, but do for NLI and generation. Another notable distinction from most (although not all; see the references below) prior work on the explainability of attention mechanisms in NLP is the inclusion of transformer/self-attentive architectures. ","I use (unqualified) “self-attention” to refer to attention of tokens in a sequence to other tokens in the same sequence, as described by [some corrected version of] Eq (1) and the paragraph following it (citing Bahdanau et al. 2015). This contrasts with “Transformer self-attention” and “cross-sequence attention”.",0.0967741935483871,0.18,0.1258741258741259
865,SP:508bf356b2458c11c010ffbf70fa2f1009886752,"The paper presents a detailed study on the commonsense reasoning ability of pre-trained Transformer-based LMs such as BERT and RoBERTa. The authors build an experimental framework for evaluating different models with different knowledge sources under different infusion strategies, e.g., continually pre-training (revision) or retrieval-based learning (openbook), or both. The authors present a few methods that can improve the results and reduce the gap between smaller LMs and larger ones. ","This paper asks how to improve commonsense question answering by infusing or providing potentially useful knowledge to BERT-style models. Authors explore using finetuning on and/or retrieving of useful or related knowledge for questions, and experiment with multiple ways to combine the useful knowledge with the questions. Results show that simultaneously finetuning on related knowledge source and retrieving a few examples for each question improves performance the best. ",0.14864864864864866,0.15942028985507245,0.15384615384615385
866,SP:508e62e7f8cd002f2ee01c2ba032ce79a1f3a469,"This paper proposes a data relabeling technique using influence function. The authors first derived the influence function for data relabeling as follows.  $$ \eta_{\theta \delta}\left(z\_i, z\_j^{c}\right) \left. \triangleq \frac{d l\_j^c \left(\hat{\theta}\_{\epsilon\_i \delta\_j}\right)}{d \epsilon\_i}\right|_{c\_i=0} =-\nabla\_{\theta} l\_j^c(\hat{\theta}) H\_{\hat{\theta}}^{-1}\left(\nabla\_\theta l\_i\left(z\_{i \delta}, \hat{\theta}\right)-\nabla\_\theta l\_i(\hat{\theta})\right) $$  The authors then derived the specific expression for the cross-entropy loss: $$ \eta_{\theta R}\left(z_{i}, z_{j}^{c}\right)=-\nabla_{\theta} l_{j}(\hat{\theta}) H_{\hat{\theta}}^{-1} w\left(z_{i}, \hat{\theta}\right)=-\nabla_{\theta} l_{j}(\hat{\theta}) H_{\hat{\theta}}^{-1}\left(-\frac{\nabla_{\theta} l_{i}(\hat{\theta})}{1-\varphi\left(x_{i}, \hat{\theta}\right)}\right)=\frac{-\Phi_{\theta}\left(z_{i}, z_{j}^{c}\right)}{1-\varphi\left(x_{i}, \hat{\theta}\right)} $$ The authors experimentally demonstrated that data relabeling is more effective than the standard sampling/data reweighting-based approach for model improvement.","The authors present an approach and framework to mitigate training biases by combining influence functions and data relabeling.  The idea behind training biases is that part of the data that is used to train the model does not accurately represent the real data distribution seen in the test set. Thus, having a mismatch between training and test data. This creates a generalization problem for the machine learning model.   Other authors have used different resampling approaches to try and address this problem, relying on the training loss and then relabeling the data; or by using influence functions and changing the weight of the harmful examples so that the effect on the test loss is lower.  The current authors combine both approaches, and present a framework that relabels harmful training data based on influence functions (on the test set).   The results of their experiments show that they are able to reduce the test loss compared to other data resampling approaches.",0.08994708994708994,0.10759493670886076,0.09798270893371756
867,SP:50912255573295ef5e76ec95e6e83b9ee0b3534e,"This paper proposes an application of reinforcement learning for adaptive mesh refinement in large-scale finite element simulations of complex physical systems. The authors suggest to formulate the mesh refinement problem as a MDP and propose different policy architectures for scalable application of reinforcement learning. Experiment results demonstrate that the proposed RL approaches outperform existing baselines, and can generalize well to situations of different finement budgets and larger meshes.","For various complicated problems governed by PDEs (e.g. solid/fluid interactions, aerodynamics, elasticity, backscattering, etc.) the computational cost can become prohibitive even for one inquiry, let alone parametric study. In the same time, mesh refinement is crucial to achieve acceptable accuracy. To mitigate such challenges, one solution is to use adaptive mesh refinement (AMR), for which the mesh refined only in the regions that numerically are sensitive to error propagation. For example for boundary layer models or shock-boundary layer interactions, one much capture the dynamics in high-gradients region of the solution, which are typically in vicinity of the walls or are part of the solution, while in very far regions of the domain, a coarse mesh is sufficient.  Authors recognize that the process of AMR, refinement at each step, can be formulated a Markov decision process (MDP) and hence utilize reinforcement learning (RL) to train refinement policies directly from simulation. But this in turn poses a new challenge, at each step, the dimension of state (number of elements) and action space may (and should) alter. They propose suitable policy updates to overcome this challenge and come up with three different architectures for the implementation. Three test cases are used for experiments (static, advection and Burger) and authors compare all three architectures with each other as well as some traditional AMR methods to demonstrate the performance of the proposed method. They also carry out extra tests on the same set of PDEs to show generalization and out of distribution capabilities of the method for both static and transient PDEs. The paper is well-written and two tricks for RL are impressive (using Nmax to take care of varying dimension of state/action space and use of surrogate reward for training). However, I have some major reservations that I'll explain below in the Main Review.  ",0.36231884057971014,0.08143322475570032,0.13297872340425532
868,SP:50b24dbbb5c3f29aa48d666473d3d0f459d0da3a,"The main idea of the paper is using neural networks to provide ""starting hints"" to a program synthesizer that is based on genetic programming. Specifically, the network predicts one or two lines that must be present in the desired program given the I/O examples for the task. These lines are used to initialize the GP process instead of an empty program.","This work considers training neural networks to provide ""hints"" (suggested lines of code) as a way of augmenting genetic programming systems. At test time, a neural network conditions on input-output examples and learns to predict 1-2 lines of code which are present in a program satisfying those input-outputs. At train time, the system learns in a self supervised manner by bootstrapping off previously discovered programs, augmenting them to produce a large corpus of similar problems, and then training the network to predict lines of code present in this augmented data set, similar to DeepCoder.",0.27419354838709675,0.17525773195876287,0.21383647798742136
869,SP:50d19cab5e7a10f1d01b63b284b1714d744b807b,"This paper proposes an approximate second-order method with low computational cost. A common pitfall of second-order methods is the computation (and perhaps inversion) of the Hessian matrix. While this can be avoided by instead relying on Hessian-vector products as done in CG, it typically still requires several iterations. Instead, the authors suggest a simpler approach that relies on one single gradient step and a warm start strategy. The authors points out that the resulting algorithm resembles a momentum method. They also provide some simple convergence proofs on quadratics and benchmark their method to train deep neural networks.","Authors propose choosing direction by using a single step of gradient descent ""towards Newton step"" from an original estimate, and then taking this direction instead of original gradient. This direction is reused as a starting estimate for the next iteration of the algorithm. This can be efficiently implemented since it only relies on Hessian-vector products which are accessible in all major frameworks.",0.14,0.2222222222222222,0.17177914110429449
870,SP:50de6aaf2c0749724bf725075d84a00021646310,"This paper proposes PUUPL, an uncertainty-aware pseudo-label selection method for positive-unlabeled (PU) learning. To improve the performance of pseudo-labeling, the authors suggest using the epistemic uncertainty (the difference between the entropy of the mean prediction and the mean of entropies of each prediction). In the experiments, PUUPL outperformed the existing state-of-the-art PU learning methods.","This paper studies the PU learning problem. It proposes a two-step approach that can estimate the pseudo-label uncertainty so that more reliable pseudo-labels can be assigned, which improves the predictive performance. The proposed estimation method is different from previous methods. ",0.16393442622950818,0.23255813953488372,0.1923076923076923
871,SP:50e66229a129e7cfe6a966218c2b635db03770e5," The work presented in this paper tackles the expressivity issue with graph neural networks (GNN). Drawing from the probabilistic graphical models' literature, the authors define the notion of G-compatible functions (i.e. can be factorized over the list of maximal cliques in graph G) and show how they are linked to G-invariant functions (i.e. invariant to node permutation). Then, the authors propose their new GNN architecture called Neural Tree. In their approach, an intermediate tree-structured representation, called H-tree, of the input graph G is constructed first. Traditional message passing is then performed on that H-tree instead of the input graph. The authors go on to show how neural trees can approximate G-compatible functions, thus capable of learning graph invariant functions.  Node classification experiments were conducted on two types of graphs: 3D scene graphs, and citation networks. The neural tree architecture was tested with four different aggregation functions (used during message passing) and compared against their typical architecture implementation (GCN, GraphSAGE, GAT, and GIN). Empirically, using the proposed neural tree architecture always yields higher accuracy. Additional experiments were done to measure the impact on the accuracy when changing the size of the training data (% of labeled nodes), and the number of iterations of message passing. Neural trees appear to be better when having access to a limited amount of labeled nodes, and the optimal number of iterations of message passing seems to follow a similar trend as with the standard GCN architecture.","This paper presents a new GNN architecture, which performs message passing on a hierarchical H-tree structure constructed from the original graph. Nodes in the H-tree represent subgraphs of the original graph, and thus message passing on H-tree can achieve higher expressive power by going beyond the node-to-node communication. Theoretical results show that the proposed neural tree architecture can approximate any smooth probability distribution function over an undirected graph. Such expressive power is achieved with number of parameters exponential with the width of the H-tree and linear with the original graph size. Experiments on a scene graph and a citation network show neural tree with existing GNN aggregation functions outperform the corresponding GNN alone. ",0.14516129032258066,0.3025210084033613,0.19618528610354222
872,SP:50fc4ed275dfba23494957478389b0a9ba30838e,"The paper describes a noisy channel approach for document-level translation, which does not rely on parallel documents to train. The approach relies on a sentence-level translation model (from target-to-source languages) and a document level language model (on target language), each is trained separately. For decoding, the paper relies on another proposal model (i.e., a sentence level translation model from source to target) and performs beam-search weighted by a linear combination of the scores of all three models. Experiments show strong results on two standard translation benchmarks.",This paper presents a simple approach for document-level machine translation. The idea is to use a language model on the target side and a reverse translation model to choose the best document-level translation. This is theoretically justified by Bayes’ rule and the assumption that the sentences are conditionally independent. The authors implement this idea using a reranking model that rescores 50 candidate translations generated by a standard Transformer model for forward translation. ,0.25,0.3108108108108108,0.27710843373493976
873,SP:50fe6a0cf9b00e462adff4c4273b2604546b4023,"This paper proposes new neural models for hyperbolic space, which unlike previous hyperbolic NN works, relies on the notion of horocycle in the Poincare disk. This novel framework has connections to spectral learnig in hyperbolic space. Representation theorems alla Cybenko for layers constructed from these neurons are presented. Finally, various experiments on clustering and classifying datasets using these neurons to generate hyperbolic embeddings are presented. ",This paper develops a MLR based on hyperbolic geometry. The idea is based on well-known concept of horocycle and horospheres which are known to be hyperbolic counterpart of line and plane in Euclidean geometry (see Coxter). Then the authors show the universal approximation which kind of follows similarly from the Euclidean counterpart. In fact we can probably conject that this universal approximation holds for any manifolds with constant sectional curvature.,0.15384615384615385,0.14084507042253522,0.14705882352941177
874,SP:515995dd42b4aecbd625206b16aeaca43c5a1495,"The paper provides an interesting way to add structure to MARL problems that have delay in the communication of state information. By explicitly building a predictive module for the future latent state of the agent and including that predicted state in the passed messages, it is possible that the agent will appropriately pass information that removes the effect of the delay in message passing across the network. They then apply this model to some interesting traffic light and cooperative vehicle control tasks.","The paper proposes to communicate predicted local states between neighboring agents to address the problem of delayed information in networked multi-agent reinforcement learning. To enable agents to predict future states, a world model is learned at each agent. It is empirically demonstrated that the proposed method has good performance in traffic signal control and cooperative adaptive cruise control. ",0.21951219512195122,0.3050847457627119,0.2553191489361702
875,SP:5165c93ec3eefa99a32d00be8d59dd6894bb1d87,"This paper first defines a new definition of calibration which, in contrast to the one used in prior work, is confined to the maximum observed time in the data. They then propose a KM regularizer for making sure their survival curves are calibrated: they are closer to KM curves. They also claim that their regularization, unlike prior work, does not require any hyperparameters and avoids the binning approach.","In this work, the authors propose a novel approach for learning calibrated predictions for survival analysis and similar tasks. The intuition of the approach is that the average probability that a prediction has a value less than or equal to $t$ should approximately equal the number of observations with value less than or equal to $t$. The authors then derive a differentiable regularization term using this idea and Kaplan-Meier curves. A small set of empirical evaluations suggest the proposed approach modestly outperforms another recent survival analysis calibration method according to some metrics.",0.20588235294117646,0.15053763440860216,0.17391304347826086
876,SP:516b27b0867e288ba30da79602356fe581d59d8a,"This paper presents MetaMorph, a Transformer based universal controller to learn behaviors across different robot morphologies. Their Transformer module takes a sequence of tokens as input, corresponding to the number of modules in the robot. Each input token comprises the proprioceptive and morphology information for each constituent robot’s module. MetaMorph is trained using a standard model-free Proximal Policy Optimization (PPO) method. However, to ensure all robots get to explore given environments and gather a similar amount of experience, the paper introduces a dynamic replay buffer which prioritizes robots’ selection for experience collection based on their previous iteration's episode lengths. The results are compared against MLP based experts trained for all individual robots, Graph Neural Network-based universal controller, and ablated modules of MetaMorph to highlight design choices. Moreover, results also demonstrate the generalization capacity of MetaMorph to different robots through zero-shot transfer and fine-tuning.  ","This paper proposes a Transformer-based universal policy to control modular robots. Being the space of modular robots combinatorial, it is (almost) impossible to train specific policy for each sample of the ""robot distribution"". Therefore, the paper proposes a transformer-based architecture design with explicit information about the robot morphology that, trained on a large number of possible morphologies. This universal controller generalizes zero-shot to unseen robot designs belonging to the training distribution and can be efficiently fine-tuned on new robots and tasks. The approach is thoroughly evaluated on different tasks.",0.16778523489932887,0.26881720430107525,0.2066115702479339
877,SP:51a5349be44696d07c4bb9c6f94f2447022ceca3,"This paper proposed a method to train quantized supernets which can be directly deployed without retraining. The motivation is to have a supernet with a given quantization bit-width which only train once and can be deployed with different architectures (under different FLOPs budget). This paper made a bunch of experiments showing that the proposed once quantized for all method can find DNN architectures which have SOTA performance with low bit-width. The paper also shows that when training lower-bits supernet, it is helpful to use the weights from the trained higher-bits supernet.","This paper presents a new method to search for quantized neural networks. This method is different from others that it results in quantized weights which can be deployed without post-process such as fine-tuning. Proposed method first trains a 4-bit quantized supernet, and search for the best performance sub-net using the validation dataset. Then, the method initialize the 3-bit supernet using the 4-bit supernet, and trains 3-bit supernet using the knowledge distilation method. Proposed method iterates the initialization, training, and search process until the goal bit resolution is achieved.",0.22105263157894736,0.22105263157894736,0.22105263157894736
878,SP:51a88b77450225e0f80f9fa25510fb4ea64463b2,"The paper focuses on the problem of modeling, predicting and estimating entropy information over continuous-time discrete event processes. Specifically, the paper leverages unifilar HSMM's for model inference and then uses the inferred states to make future predictions. The authors also use inferred model with previously developed techniques for estimating entropy rate. The authors describe the methods and provide the evidence of the effectiveness of their method with experiments on a synthetic dataset.","The authors present a model for time series which are represented as discrete events in continuous time and describe methods for doing parameter inference, future event prediction and entropy rate estimation for such processes. Their model is based on models for Bayesian Structure prediction where they add the temporal dimension in a rigorous way while solving several technical challenges in the interim. The writing style is lucid and the illustrations are helpful and high quality. ",0.16216216216216217,0.16,0.1610738255033557
879,SP:52151a689fcb14825e98a508930b9ddbdb8faf0b,"The author(s) face the design of Bayesian autoencoders (BAE) and, in particular, the model selection problem. A likelihood model is proposed, then to optimize it the prior of the weights is also needed, a normal distribution is proposed where mean and variances are to be learned. Marginal likelihood estimation is brought here to learn these hyperparameters, but being intractable is transformed into an approximated expression using distributional sliced-Wassersteing distance (DSWD). This expression is estimated with Monte Carlo integration and optimized via gradient descent. In the end, the prior is found by matching the true data distribution and the parametrized marginal distribution of the joint probability of the data and the weights.  The contribution of the manuscript is to develop the mathematical framework to optimize the hyperparameters of a prior for the weights in an autoencoder using DSWD. The solution is designed for a normal prior with to-be-learned mean and variance and continuous Bernoulli likelihood for the probability of the data conditioned to the weights.","The goal of this paper is to train a Bayesian autoencoder (BAE), where the AE parameters are specified as random variables with trainable hyperparameters. Three contributions are claimed: (1) the distributional sliced-Wasserstein (DSW) distance [25] is leveraged to enable sample-based training of BAE hyperparameters (which model the distribution of AE parameters); (2) to instantiate the AE parameters, the SGHMC [9] is used; (3) to sample from a BAE, the authors propose to learn an ex-post density to model the distribution of the projected latent codes, mimicking [12,8,16]. Experiments on MNIST, FREY-YALE, and CELEBA are conducted.",0.15476190476190477,0.25742574257425743,0.1933085501858736
880,SP:522aebc6b5d57da5550911d44f91572975118008,"This paper proposes the Adam+ algorithm that maintains an exponential moving average of the first moment and normalizes it by its $p$-th moment for some $p \in (1/2, 1)$. When $p = 2/3$, with appropriate hyperparameters, Adam+ achieves the state-of-the-art complexity $O(1/\epsilon^{3.5})$ to obtain an approximate first-order stationary point for smooth objectives with smooth Hessians. The proof technique is similar to that for SCGD by Wang et al. (2017), which construct a Lyapunov function for algorithms of this kind. ","This paper proposes a new optimizer called Adam+, with two main distinctions from standard Adam template: 1) the first order moment estimate is computed using the gradient evaluated at an extrapolated iterate. 2) the step size is scaled with the square root of the norm of the first order moment, rather than the exponential moving average (EMA) in the previous work. Under Lipschitz continuous gradient, Hessian and bounded gradient assumptions, the complexity for finding a point with small gradient norm is $\epsilon^{-3.5}$, which is a SOTA complexity. The practical performance of the algorithm is evaluated in a range of different tasks and the performance is shown to be consistently promising and comparable to SGD/Momentum SGD.",0.2247191011235955,0.1694915254237288,0.1932367149758454
881,SP:5247942ad6db19ef5124aa562fd1d4186358c779,The paper presents an approach to select the best reward shaping potential signal out of multiple available shaping potentials. The main idea seems to be to select the shaping signal that minimizes the inverse of the difference of potentials between the next state and the current state. The experiments show the proposed approach works better than other baselines. ,"The idea of potential-based reward shaping (PBRS) is to improve the performance of learning agents by incorporating additional domain knowledge into their reward function (making it dense), while maintaining the same asymptotic convergence guarantees. However, one aspect of PBRS, that is introduced in this work, is how to select among multiple shaping signals in an adaptive manner that is also dependent on the current context, in a way that can overall improve the performance of the agent. A method is proposed  here that learns to select among two or more shaping functions based on experience, represented as the difference between the TD error (or surprise) and the shaped reward signal, the conjecture being that signals that are closer to the TD error can lead to the best improvement in the agent's performance. The signal with the smallest difference is used as a self-supervised label to train a classifier that selects the signal. Experiments show that the method is at par with other similar approaches while being simpler to implement. ",0.3793103448275862,0.12790697674418605,0.19130434782608696
882,SP:5260bc0d3c1b956f31d8921a51bbc776843cd6ef,One of promising approach to tackle the few-shot problems is to use meta-learning so that the learner can quickly generalize to an unseen task. One-class classification requires only a set of positive examples to discriminate negative examples from positive examples. The current paper addresses a method of meta-training one-class classifiers in the MAML framework when only a handful of positive examples are available. ," This paper tackles an interesting problem, one-class classification or anomaly detection, using a meta-learning approach. The main contribution is to introduce a parameter such that the inner-loop of the meta-learning algorithm better reflects the imbalance which occurs during meta-testing. Results are shown comparing a few simple baselines to both MAML and the modified variant, on a few datasets such as image-based ones (MNIST, miniImageNet), a synthetic dataset, and a real-world time-series example from CNC milling machines.",0.19117647058823528,0.15476190476190477,0.17105263157894737
883,SP:52701ccbe77facd26fa921a2610dad1da60e1a5f,"This paper proposes a novel framework for training flow models named Autoregressive Quantile Flows (AQF). The proposed method utilizes a new objective by evaluating forecasts with proper scoring rules, including the continuous ranked probability score and the check score. The advantages of the proposed objective are 1) it could avoid the explicit calculation of the determinant of the Jacobian matrix and 2) it could also provide uncertainty estimation for predictions. Experiments on multiple tasks including regression, object detection, time series forecasting, and generation validate the effectiveness of this framework.","This paper proposed a quantile regression method for uncertainty estimation based on autoregressive quantile flow. The flow model can be trained in both forward and reverse setting using different loss functions, and the quantile flow framework can be combined with other linear or non-linear transformations. The authors have conducted diverse empirical evaluations on objective detection (bounding box regression), time series forecasting, and generative models to demonstrate the advantage of the proposed method.",0.20224719101123595,0.2465753424657534,0.2222222222222222
884,SP:528ad3f6625f1cf86ac5219fba6ee1a457b65240,"This paper investigates the search-control problem in Dyna-style reinforcement learning algorithms. They first provide a theoretical justification behind the error-based prioritization and propose a new sampling method based on gradient ascent of which optimization results are equivalent to samples drawn from the priority distribution. The suggested prioritization method is examined in various domains, namely, GridWorld, AcroBot, CartPole, MazeGridWorld, and roundabout-v0, and it shows a better sample efficiency in most domains.","The paper proposes a new way of prioritization in experience replay and Dyna-style planning methods. In particular, it proposes to exploit a learned model to actively search for states with high expected errors. The states are then prioritized proportional to the expected errors. The authors motivate the approach by a theoretical/empirical observation that the prioritized optimization of L2 loss is equivalent to the direct optimization of cubic loss. More specifically they tackle (1) outdated priorities of training samples, (2) insufficient coverage of the sample space; which are identified as the main shortcomings of previously explored prioritization methods. ",0.1891891891891892,0.1414141414141414,0.16184971098265896
885,SP:529fd3a7215e22cd444370bd86d7b0522cdbd526,"The authors consider self-play in zero-sum discounted two-player Markov games with compact state space and finite actions. They present a smooth fictitious self-play algorithm where each player adopts an entropy-regularized policy optimization method with the average of the past generated Q-values. Under appropriate assumptions, among which a Lipschitz regularity of the Markov game, the authors prove that this algorithm approximates the Nash equilibrium at a rate O(1/T) where T is the number of iteration.","This paper studies the problem of learning to play a Nash equilibrium in two-player, zero-sum Markov games.  This is a longstanding problem, with many algorithms proposed but relatively few theoretical convergence guarantees, and most of those either for quite restricted settings or with strong assumptions.  This is in stark contrast to the stateless setting of Normal Form Games, where we have many strong theoretical convergence guarantees.  The main algorithm is a version of the classic fictitious play algorithm.  Like prior adaptations of fictitious play to Markov Games, it operates on the Q-values, but a key novelty (at least in the stateful setting; similar ideas were recently applied in a special case of normal form games by Swenson and Poor 2019) is the use of a particular form of regularization in the best response process.  The main result is that as long as the game satisfies Lipschitz and Concentratability properties for each player when the other plays optimally and the policy updates are sufficiently accurate then play converges to a Nash equilibrium.",0.3048780487804878,0.14367816091954022,0.19531249999999997
886,SP:52cbd90cb8f3de333a12f8c42cad968d36b509c3,"The author(s) propose to accelerate the training of deep neural networks while also maintain the performance of the trained model by switching between fully half-precision computation and mixed-precision computation. Compared to the commonly-used mixed-precision training strategy, the proposed method can accelerate the training speed. Besides, on an image classification task, models trained by the proposed method achieve comparable performance with those trained by mix-precision training or full-precision training.","This proposes two techniques to replace mixed-precision arithmetic with half-precision training for a large part of the training process. In the first approach, the authors simply switch all mixed-precision operations with half-precision operations, and can achieve performances slightly lower than SOTA. In the second approach, the authors propose to dynamically switch between mixed-operations and half-precision operations during training. The authors claim that this second approach can match SOTA results while using half-precision arithmetic for more than 94% of training.",0.21333333333333335,0.18604651162790697,0.19875776397515527
887,SP:533b0f1a7c913c41fac5602f19cf341ccf0f961a,"The paper presents an extensive study on hyperparameters and design choices for adversarial imitation learning, including the choice of divergence (reward function), RL algorithm and whether marginals $p(s,a)$, $p(s)$, $p(s,s')$ or $p(s,a,s')$ are to be matched. Evaluations are conducted on MuJoCo and Adroit environments --- the latter experiments also made use of human demonstrations. The main findings are that demonstrations collected by an RL agent are not good proxies for human demonstrations and that more standard discriminator regularizers like dropout perform similarly well as gradient penalty. ","The work conducts a detailed empirical analysis of a range of design decisions in the domain of adversarial imitation learning. The imitation learning framework is sufficiently general to encompass prior work like GAIL, AIRL, various extensions to these algorithms (e.g. regularizers), different RL algorithms used for the generator training. These decisions are tested in a comprehensive hyperparameter sweep involving over 500k trained agents across eight continuous control tasks. The results include many observations that will be useful to practitioners, such as the importance of observation normalization. It also in some cases casts doubt on received wisdom, such as the various AIL-specific methods for discriminator regularization, which seem to be little better than standard SL approaches like dropout.",0.17204301075268819,0.13445378151260504,0.1509433962264151
888,SP:5343a29c611b40fc6df160bff09a9aaf8140d0ab,"This paper considers the problem of skill discovery in settings where the data appears to be a Markov Decision Process and part of the state is unobservable. The hidden state variables are interpreted as causal factors that control important aspects of the environment  dynamics. Under this interpretation, the paper advocates for the use of a reward that encourages learned skills that exercise individual components of the hidden state. These skills are learned with a model-based RL algorithm -- one skill per causal factor -- then transferred for use in a downstream control problem that uses a different learning algorithm. The paper claims the learned skills are qualitatively meaningful, and that they enable agents to solve downstream problems without any additional training. Data used for empirical evidence comes from a simulated manipulation robot. ",This paper develops an intrinsic reward to help identify factors of variation within a family of MDPs. This intrinsic reward takes a form of curiosity and is used to develop initial behaviors to identify the causes of the latent variation in the environment dynamics. The experiments are used to validate the proposed intrinsic reward across several analyses used to identify its utility and effectiveness.,0.11450381679389313,0.234375,0.15384615384615385
889,SP:535c313f14cbdf5a973f7e61e059f9d27d07a3c2,"This paper introduces a method to detect cars from a single image. The method imposes several handcrafted constraints specific to the dataset in order to achieve higher improvement and efficiency. These constraints are quite strong and they not generalize to new situations (eg. a car in the sky, a car upside down a car with multiple wheels). The results do not seem particularly strong because the dataset seems easy and the improvements over previous works is small. ","I find it very hard to review this paper. The idea of using keypoints to carry pose estimation is is more than 15 years old, and for the car examples reported in this paper, I'm wondering why not just you SURF or SIFT - these would certainly have been reasonable baselines. The convnets cited in this paper are mostly targeted at the harder problem of estimating human body poses.",0.12987012987012986,0.14492753623188406,0.13698630136986298
890,SP:53652cae401fc0eefd3e6aa57552dac089eb91fc,The paper investigates if generative models can be used to improve the robust accuracy of image models. The authors show that the current SOTA across multiple attack models and commonly used datasets can be significantly improved by using generative models. They show that the conditional Wasserstein difference between the test distribution and the one learned by the generative model is an upper bound for the difference in robustness achieved by models trained on either distribution.  They investigate what generative models provide good proxy distributions by robustly training discriminators and using their accuracy at different attack strengths as a metric. The discriminators are also shown to be helpful to order generated samples by their effectiveness for adversarial training. ,"This paper focuses on utilizing synthetic images generated by a generative model for the task of achieving robustness to adversarial attacks. Towards this, the paper aims to assess the suitability of the proxy distribution defined by the generative model for the underlying task. The paper shows that conditional Wasserstein distance serves as a selection criterion for the proxy distribution. Acknowledging the intractability of estimating the conditional Wasserstein distance, the paper then proposed a novel metric based on robust discrimination between the proxy distribution and the real distribution. Finally, the paper empirically demonstrates that using synthetic images from a suitable generative model can indeed improve the robust and clean accuracy of the model over existing baselines.",0.20512820512820512,0.20869565217391303,0.20689655172413796
891,SP:53ba8f4c7b66717d550559729320c2ef3364a759,"The paper discovers parallel and co-linear structures in known accelerated first order methods and claims that these are important ingredients to achieve acceleration. The introduction of parallel structure in an optimization algorithm yields a standard way of designing a discrete Lyapunov function to analyze its convergence. A new Lyapunov analysis for OGM-G is obtained, but also a new method FISTA-G, which, combined with FISTA, yields to an improvement in the state of the art regarding convergence of gradient in the proximal gradient setting. An experiment in compressed sensing is presented as well.","This paper studies the geometric structure in composite minimization by making gradients small. More specifically, the author identifies parallel and collinear geometric structures. The novelty of this paper is the analysis of parallel structure and its extension to new variants of accelerated methods. It is indeed important to study the geometric structures for convergence rates of gradients for convex problems and the Lyapunov analysis is a standard way to analyze the convergence rates.  ",0.18947368421052632,0.2465753424657534,0.21428571428571427
892,SP:53e0d7909b00c88201dc1d7a8da7bd1efa4eb48e,"The paper introduces an algorithm for mitigating disparate impact of private learning (DP-SGD) on different groups of a given population. In each iteration of DP-SGD, instead of using a uniform gradient clipping threshold for all groups, the proposed Fair DP-SGD algorithm uses an optimal clipping threshold (one that minimizes the bias-variance tradeoff) for each group separately. The authors include experimental results to show how well their algorithm performs compared to state-of-the-art algorithms.","This paper addresses the problem of an unbalanced data set. In particular, the accuracy on the well-represented classes is higher than the accuracy in underrepresented classes in an unbalanced dataset. This paper shows that DPSGD makes the problem of an unbalanced dataset even worse and decreases accuracy on the underrepresented class significantly. Further, this paper introduces a modification of DPSGD, which can increase the underrepresented class's accuracy.",0.12658227848101267,0.14492753623188406,0.13513513513513514
893,SP:53e5103b5c33881acc10549723af160c902a21cd,This paper studies the statistical properties of bidirectional GANs. It studies the sample complexity of the bidirectional GAN estimate under the Dudley metric. They relax a couple of assumptions usually made in GAN theory literature; they do not assume that the dimension of the latent distribution and the data distribution are the same or that the true data distribution has bounded support. ,The paper presents non-asymptotic error analysis for bidirectional GANs. The distinctive feature of the error analysis is relaxing the assumption that the data and latent variable should have the same dimension.  The constants in the error bound is also explicit in dimension.  ,0.20967741935483872,0.3023255813953488,0.24761904761904757
894,SP:53ed366f6004f4c6edc7fcc5516d7e016c21ba91,"The authors identify an interesting empirical phenomenon: across a range of network architectures and training approaches (supervised, unsupervised, auto-encoders), the feature spaces identified by these networks are similar. The authors introduce a specific way to summarize the feature space of a network as a vector (the top-left singular vector of the num_examples x num_features matrix) and show that these vectors are highly correlated across networks. In addition, the authors show that the features spaces become more similar throughout training and are predictive of the generalization performance of a neural network.","This paper has a closer look at the distributions of samples in the feature space by utilizing P-vector to analyze principal subspace. According to their empirical studies, the authors concluded that the feature spaces learned by different deep models with the same dataset would share common principal subspaces for the same dataset. It will not be affected by DNN architectures or the usage of labels in feature learning. Only the training procedure gradually shapes the feature subspace to the shared common subspace. ",0.1595744680851064,0.18072289156626506,0.16949152542372883
895,SP:540624cca4f85a6aefa04b33f3029e67cefeb340,"This paper presents a new loss objective for NMT. The main idea is to optimize an interpolation of KL(P|Q) and KL(Q|P), which is Kulback-Liebler Divergence computed at the word-level for model distribution Q and true distribution P. The motivation is that KL(P|Q) finds a Q that covers all modes of the data whereas KL(Q|P) finds a Q that concentrates on a single mode. So optimizing on the interpolation gets the best of both worlds. In my opinion, this is a relatively simple and known idea in ML (but perhaps not in MT? I'm not sure.) On the other hand, the NMT experiments are well-implemented and convincingly shows that it improves BLEU on a WMT dataset. ","This paper describes an alternative training objective to cross-entropy loss for sequence-to-sequence models. The key observation is that cross-entropy is minimizing KL(P|Q) for a data distribution P and a model distribution Q; they add another loss that minimizes the inverse KL(Q|P) to create their dual-skew divergence. The idea is tested in the context of neural MT, using a model similar to that proposed by Bahdanau et al. (2015) with results on English-to-French and English-to-German WNT 2014. In the context of beam search, improvements are small (<=0.5 BLEU) but statistically significant.",0.2204724409448819,0.2692307692307692,0.2424242424242424
896,SP:5406872be7f8a36576284f9a18ecb76d658bf25c,"The authors derive the influence function of models that are first pre-trained and then fine-tuned. This extends influence functions beyond the standard supervised setting that they have been primarily considered in. To do so, the authors make two methodological contributions: 1) working through the calculus for the pre-training setting and deriving a corresponding efficient algorithm, and 2) adding $L_2$ regularization to approximate the effect of fine-tuning for a limited number of gradient steps.","This is an analysis paper of pretraining with the tool “influence function”. First, the authors calculate the influence score for the models with/without pretraining, and then propose some implementation details (i.e., use CG to estimate the inversed Hessian). To calculate the influence function of a model with pretraining, the authors use an approximation f(w)+||w-w*||, where w* is pretrained. ",0.1794871794871795,0.2222222222222222,0.19858156028368792
897,SP:543adf5a6e83b2d343b5f4482f1fb41388f1314c,This paper studies the online inference and learning problems for nonsymmetric determinantal point processes (NDPPs). The authors use the online greedy algorithm for MAP inference and modify the learning objective for being suitable in the online setting. Experiments with real-world datasets show that the proposed online algorithms are comparable or even better than state-of-the-art offline algorithms.,"This paper proposes online and streaming algorithms for MAP inference and learning for nonsymmetric determinantal point processes (NDPPs).  For the streaming setting, data points arrive in an arbitrary order, and the algorithms are constrained to using a single pass over the data, along with requiring sublinear memory consumption.  In the online setting, there is the additional requirement of maintaining a valid solution at any time step.  The authors provide some theoretical guarantees for the proposed algorithms, and perform experiments that demonstrate that their performance is comparable to (or better than) offline algorithms for these tasks. ",0.4666666666666667,0.29473684210526313,0.3612903225806452
898,SP:5456e53f2d1a0f4eda6dddc67ea65cb23cee6216,"In this paper, the authors proposed a method to train Spiking Neural Networks (SNN) with spike-based implicit differentiation on the equilibrium state. Main idea is to use a spike-triggered event instead of average firing rate to approximate implicit differentiation of Feedback Spiking Neural Networks (FSNN). To enable such idea and to further reduce the approximation errors, the authors proposed several techniques such as adopting ternary spiking neuron couples and shifting resting potential. The experimental results showed that the proposed method can achieve high accuracy in several tasks such as MNIST, CIFAR-10, and CIFAR-100 with fewer time steps for training compared to existing methods.","The paper aims at porting the IDE method  into a spike-fbased and more bio-plausible version. The previous IDE used firing rates rather than spikes for computation, although reference Xiao et al in NeurIPS 2021 had already addressed implementations in spiking neural networks. The authors analyze the approximation error that results from solving implicit differentiation by spikes and report a solution based on ternary spiking neurons, that can be implemented with pairs of standard spiking neurons. They achieve in this way quite good performance for MNIST and CIFAR10.",0.17757009345794392,0.21348314606741572,0.19387755102040816
899,SP:545da4fe9052319abda88a3ca5ddccaabd2ff2b4,"In this paper, the authors propose to hide information in phase of the input features. They proposed that if each layer of processing layer, sitting outside of the local unit, is phase preserving, then they can recover the phase back. They propose a modification to the most popular layers in DNN to satisfy that property.","This paper proposes a novel way to outsource a part of the information processing in a deep learning model to an untrusted remote location while revealing only little information about the input or final output of the computation. To this end the result of an on-chip encoder (e.g. the first N layers of a ConvNet) is encoded in a complex number with a random phase, which is then shipped to a remote location and gets processed (the next M layers of a ConvNet) in a way that is phase-equivariant. This result is shipped back to the device which extracts the desired information by inverting the phase randomisation. Additional distractor signals are encoded through a GAN-type approach.",0.32727272727272727,0.15,0.20571428571428568
900,SP:547e6e3b94ec05ba8024184556024fadd305985e,"This work introduces a proximal algorithm for training neural networks. Specifically, the method allows the use of non-convex regularization functions and general PSD pre-conditioners  in the objective, while guaranteeing convergence to a stationary point. Empirical results are provided for training sparse neural networks on CIFAR and ImageNet.","The paper presents a framework for adaptive proximal stochastic methods. The general algorithm provided, ProxGen, is a variation on traditional proximal gradient descent in which the gradient is multiplied by the inverse of some $C_t+ \delta I$, and the norm in the prox operator is given by $\|x\| = x^{\top} (C_t+ \delta I) x$. They give a convergence result which matches the optimal rate for SGD, and they show experiments with sparse, group-sparse, and binary neural networks in which they show improvements over existing algorithms.",0.2857142857142857,0.1590909090909091,0.20437956204379562
901,SP:548aec7a3eab3e843017e91576c97c1c85c359f4,"The authors propose a new Transformer variant for neural machine translation. Compared with the standard Transformer framework, this work explains the representation generation process of the encoder via a multi-ordered-graph MoG and develops a novel Graph-Transformer method based on MoG, which is capable of capturing diverse relationships within the sequence. Empirical results over benchmark datasets validate the effectiveness of the proposed method. ","The paper proposes a new multigraph architecture called Multi-Order-Graph to explain the representation generation process in neural sequence encoders (Self-Attention or SAN based models). The main contribution of this MoG is the introduction of n-order dependency which can model not only relationships between words but also high order relationships such as syntax and semantics between subgraphs. Taking inspiration from MoG explanation, a self-attention powered Graph Transformer is proposed which beats the Transformer baselines on NMT tasks (English-German and German-English).",0.23076923076923078,0.1744186046511628,0.1986754966887417
902,SP:548d657fad01a5bd74806fdbff9ee2d8cffe0197,"The paper considers the problem of optimally partitioning a panel into treatment and control groups, leveraging past observations to ensure a more balanced allocation between treatment & control.  Generally randomized-controlled trials are the standard in this instance, because particularly with large enough populations and samples the results will be robust to any issues in picking control groups. This paper strives to provide an approach when the sample size is not large enough to provide a suitably power RCT. The alternative approach is inspired by work in synthetic controls, where ex-post one may determine a set of weighted controls to use for a single potentially-unplanned treatment.   The setting in this problem lies somewhere between the two - applicable for a small handful where perhaps tuning treatment/control can give additional experimental power, at some robustness cost.   The approach shown draws heavily from the approaches in the synthetic control literature, formulating three approaches: 1) per-unit, wherein effectively synthetic controls are formulated for each treatment - or at least weightings are done accordingly, 2) two-way global, wherein weightings are only for each variable rather than the pairing - so one weighted treatment set, one weighted control set, and then 3) one-way global, with unweighed treatment and a weighted control. Across all, the experimenter is minimizing RMSE.  The paper formulates each as a mixed-integer optimization problem and does a simulated experiment on unemployment statistics across the 50 states (in 40 time periods), with either a fixed or linear additive treatment effect.  The paper does not include justifications for expected conditions on the randomness that would lead to this approach behaving better than an RCT (though it is cited as a future concern).  ","The authors propose and analyze a new problem at the intersection of experiment design and synthetic control: in a panel data setting (many units i=1:N observed over time t=1:T), how should treatments be assigned and how should weights be computed at time T such that counterfactuals are imputed well at time T+1?  The authors interpret the question three ways, providing three mixed integer programming problems. The authors compare the quality of counterfactual implementation of these new experiment designs with difference in means (where neither treatment assignment nor weights are optimized) and synthetic control (where treatment assignment is not optimized).",0.0711743772241993,0.19230769230769232,0.1038961038961039
903,SP:54970f80b2bc7243081bf2b6df4d6ca5dd43f759,"In this paper, the authors propose to apply dithered quantization (DQ) to the stochastic gradients computed through the training process. Though an extra noise is added to the gradient, it improves the quantization error. Hence after the noise is removed at the update server, it achieves superior results when compared against unquantized baseline.","Authors establish a connection between communication reduction in distributed optimization and dithered quantization. This allows us to understand prior approaches in a new perspective, and also motivates authors to develop two new distributed training algorithms which communication overhead is significantly reduced. The first algorithm, DQSG, uses dithered quantization to reduce the communication bits. The second algorithm, NDQSG, uses nested dithered quantization to further reduce the amount of needed communication. The usefulness of these algorithms are empirically validated by computing the raw communication bits and average entropy of them. Therefore, dithered communication seems to provide both theory and algorithm which are useful.",0.24528301886792453,0.12871287128712872,0.16883116883116883
904,SP:549b4b2a88e8b13656ee6bd9425fe1d2be77b334,"This work proposes to use a normalization method to address temporal distribution shift in time-series forecasting. The proposed approach, *RevIN*, consists of two steps: instance normalization on input sequences and ""de-normalization"" of output sequences by re-using statistics (mean and variance) computed during the normalization step. Experiments are conducted on two time-series datasets (ETT and ECL) with varying splits and prediction windows lengths. Results show that RevIN used on top of deep-learning based methods for time-series forecasting (Informer, N-BEATS and SCINet) improves prediction performances, in particular for long sequence prediction. Finally, they conduct an empirical comparison with other normalization methods, such as batch normalization and min-max normalization, to evaluate the adequateness of instance normalization and of the denormalization step. ","The authors propose a ""reversible instance normalization"" as an input pre and post processing procedure to improve the forecasting of any given base model - targeted at addressing the distribution shift that is common in time series data - e.g., time series are typically non-stationary.  This works by normalizing each time window input to a (deep learning) forecast model, applying the model on the normalized data, then unnormalizing the predictions to get the final predictions.   The normalization is done by subtracting the mean and dividing by the std. dev. in a current (input instance) window, followed by scaling and shifting by learnable, shared cross-instance (global), scaling and shifting parameters per input feature / variable.    The authors perform extensive experiments to show the proposed approach significantly improves the base metric score results for 3 recent, state-of-the-art forecasting algorithms across several datasets, and further that it significantly improves over other normalization approaches, and helps align distributions between train and test windows.",0.20634920634920634,0.16049382716049382,0.18055555555555555
905,SP:54c599a6476212857ac5d5871c361e31a78b7100,"This paper proposed a self-supervised learning framework for graph representation learning based on a cross-correlation-based loss function. In the proposed framework, two views of the input graph obtained by augmentation methods are passed through the same encoder to compute two embedding matrices, then Barlow Twins loss is used to compute the loss according to the embedding matrices. The main contribution of this paper lies in that it adapted Barlow Twins from vision to graph representation learning field and evaluated the performance of this self-supervised framework in multiple node classification tasks. The proposed method achieved analogous results compared to SOTA methods with lower time and space complexity. ","The paper applies the recently proposed self-supervised learning method Barlow-Twins to graph structured data. For constructing the augmented version of a graph, previous methods such as edge-dropping or feature masking are used. The paper conducts experimental evaluation on datasets of various scales on both transductive and inductive setting.  ",0.14545454545454545,0.3137254901960784,0.19875776397515527
906,SP:54c817d799e7d164e998f3234062111af667cf80,"The authors propose an approach to augment experience replay buffers with properties that can alleviate issues with catastrophic forgetting. The buffers are augmented by storing both new and historical experiences, along with the desired historical policy & value distribution. The AC learning now couples two additional losses that ensures the new policy does not drift away from old actor distribution (via KL) and new value does not drift away from old critic distribution (via L2 loss).","The paper proposes a novel trial to alleviate the catastrophic forgetting for continual learning which is kind a mixture model of on and off-policy. The core concept of the method is utilizing experience replay buffer for all past events with new experience. They mainly worked on their method in the setting of reinforcement learning. In the experiments, they show that the model successfully mitigate the catastrophic forgetting with this behavioral cloning, and has the performance comparable to recent continual learning approaches.",0.16,0.14634146341463414,0.15286624203821655
907,SP:54c86a69dc233f3a53e816f66089ab72a7997bac,"The transition matrix plays a vital role in modeling label noise. Current methods focus on modeling the transition from clean labels to noisy labels. While this paper alternatively models the transition from Bayes optimal labels to noisy labels. Since we usually use the Bayes optimal labels for prediction. This transformation will not affect the practical use but makes the estimation of the matrix much easier.  Specifically, this paper designs a DNN to estimate the transition matrix. During training, the DNN can be optimized with the classifier simultaneously in an end-to-end manner.  Extensive experiments are conducted to support the proposed method.","The paper proposes to estimate an Instance-Dependent Noise (IDN) label transition matrix. Instead of modelling the clean label transition as typically done in previous literature, the authors propose to estimate the Bayes label transition using a DNN, motivate by several advantages including theoretically guaranteed Bayes label collection and smaller feasible solution space, hence empirically easier to model. Controlled experiments show consistent improvement over other SOTA methods in noisy label transition.",0.13725490196078433,0.19718309859154928,0.16184971098265896
908,SP:54e2b82691851b880425f85be0279b423132edfb,"Data augmentation is a common technique to improve generalization, especially when data is scarce. This paper introduces a theoretical framework for analyzing the effectiveness of consistency regularization when data augmentation is employed. In the limit, consistency regularization is akin to solving a constrained optimization problem with consistency constraints. The paper theoretically studies this limit for linear regression, logistic regression, and a two-layer perceptron with ReLU activation, and tries to characterize the benefits of consistency regularization beyond that of vanilla data augmentation. The paper then continues to experiments where it is shown that consistency regularization outperforms data augmentation on three benchmarks, and the benefits are significant especially when labeled data is scarce. ","This paper aims to offer a theoretical analysis of the training with data augmentation and associated consistency loss. While it is intuitive that training with data augmentation and consistency loss will help, this paper offers a theoretical justification of the intuitions. The simple framework (to view DAC as a hypothesis space complexity reduction technique) is neat and intuitive. ",0.16071428571428573,0.3103448275862069,0.21176470588235297
909,SP:54eb8cf5375f436952059b8e6890a0550b98fb52,"This papers studies how to explore, in order to generate experience for faster learning of policies in context of RL. RL methods typically employ simple hand-tuned exploration schedules (such as epsilon greedy exploration, and changing the epsilon as training proceeds). This paper proposes a scheme for learning this schedule. The paper does this by modeling this as a non-stationary multi-arm bandit problem. Different exploration settings (tuple of choice of exploration, and the exact hyper-parameter), are considered as different non-stationary multi-arm bandits (while also employing some factorization) and expected returns are maintained over training. Arm (exploration strategy and hyper-parameter) is picked according to the return. The paper demonstrates results on the Atari suite of RL benchmarks, and shows results that demonstrate that their proposed search leads to faster learning.","This paper develops a multi-arm bandit-based algorithm to dynamically adapt the exploration policy for reinforcement learning. The arms of the bandit are parameters of the policy such as exploration noise, per-action biases etc. A proxy fitness metric is defined that measures the return of the trajectories upon perturbations of the policy z; the bandit then samples perturbations z that are better than the average fitness of the past few perturbations.",0.13333333333333333,0.2465753424657534,0.17307692307692307
910,SP:54f48b0f37ee22d8027ab01da5ea6801520d9dc3,"This paper proposes a method to learn embeddings in complex hyperbolic spaces. In contrast with real hyperbolic spaces, complex hyperbolic spaces have a variable negative curvature, which can handle more flexible graph structures. Experiments show that complex hyperbolic embeddings outperform real hyperbolic embeddings on synthetic and real-world graphs. ","The paper introduces an extension of real hyperbolic embeddings to the complex hyperbolic space [A]. The exploited geometry is an extension of the Poincaré ball that contains complex vectors (instead of real vectors) whose norm is smaller than 1. The resulting manifold is of nonconstant negative curvature, which the authors expect to be favorable for embedding various hierarchical structures.  Following the optimization framework of [B] and since the complex hyperbolic space is a Riemannian manifold, Section 4.3 presents a standard Riemannian optimization framework to learn nonparametric embeddings. The proposed manifold shows (slightly) superior results compared to real hyperbolic embeddings proposed in [B,C] in the graph reconstruction and link prediction tasks.",0.3469387755102041,0.15178571428571427,0.21118012422360247
911,SP:551579ae4e3fe3b943e738e04b923d519bea84e8,"The authors tackle the problem of skill discovery by skill chaining. In particular, the authors claim two key contributions over the state of the art in option discovery 1) learn initiation sets 2) do not need to specify the number of options and this is also learned. Skill discovery is formalized by skill chaining; wherein the skills are chained backward from a goal state, and in a way, such that termination of an option is the initiation of the option that precedes in its chain. ","This paper studies the problem of learning suitable action abstractions (i.e., options or skills) that can be composed hierarchically to solve control tasks. The starting point for the paper is the (classic) observation that one skill should end where another can start. The paper then proposes a recursive algorithm for learning skills that obey this property. After finding some number of trajectories that reach the goal, the last few states of these trajectories are taken to define the initiation set for the ultimate skill and the termination set for the penultimate skill. The procedure is repeated, yielding a sequence (a ""chain"") of skills that extends from the initial state distribution to the terminal state. The fact that the number of skills is not defined apriori seems to be a strength, and the extension to trees of skills is neat.",0.24705882352941178,0.15,0.18666666666666665
912,SP:55199c8f21981b3956a07d485d040defc5ba3fa9,"The paper addresses a novel research problem of using ""indirect"" label sources in the weak supervision framework to create labelled datasets. The indirect label sources are similar to the labeling functions in prior works in weak supervision ( data programming) with one caveat that these sources produce labels from different space than that of the original ( target) label spaces. It can be useful, when there are good indirect LFs and there is some relationships between the labels in the LF's label space and target label space. This paper, gives a probabilistic label model (PRML) which utilizes these indirect LFs and label relationships to produce desired labels for the given unlabeled data. The methodology is backed by theoretical analysis and real-world experiments. In analysis, a generalization error bound (for the end model learned using estimated labels) is provided which turns out to be similar to the work in Data programming (Ratner et al. 2016). One needs to be careful with the issue of indistinguishability between labels, in such setup. This issue has been studied in detail and they provide definition, conditions for distinguishability. Experiments on real-world data shows that the proposed method works well in comparison to several competing baselines.    ","This paper studied a weakly supervised classification problem, called **weak indirect supervision**, where the supervision signals are from labels that are different from but still informative of the classes. The author proposed a new two-step method that first creates probabilistic labels using an **exponential family graphical model** based on (1) a set of **indirect labeling functions** (pretrained classifier, heuristic rules, etc.) that output deterministic labels and (2) a given **label relation graph** (ontology graph, knowledge base, etc.) that captures the relations between the observed labels and the target classes, then uses the generated labels to train a classifier for the target classes. The author provided a theoretical analysis on the requirements of the labeling functions and derived a generalization error bound. The proposed method was evaluated on semi-synthetic datasets based on the ImageNet dataset for image classification and the LSHTC dataset for text classification.",0.1691542288557214,0.2328767123287671,0.19596541786743515
913,SP:551d4ab2faa435d4f352efc6109525f0a1a5510c,"This paper presents a deeply supervised few-shot learning model via ensemble achieving state-of-the-art performance on mini-ImageNet and tiredImageNet. The authors first studied the classification accuracy on mini-Image across convolutional layers and found the network could perform well even in the middle layer. Therefore, they added classification headers on the selected layers, so that these layers can directly output predictions. The final result is the ensemble of all the select layer predictions, called the Multiple Representation Emsemble. To improve the result, they further average the results of two models with different network backbones, called Multi-Model Emsemble. The results show this method can achieve state-of-the-art performance on the two datasets.","Thanks to the authors for providing such an ensemble approach. This paper aims to find a way to directly utilize representations with the classification layer(s) to obtain better performance.  The ensemble method is able to create an ensemble of classifiers. And the ensemble achieves the new state-of-the-art results in a few-shot setting, comparing to previous regular and ensemble approaches.",0.13559322033898305,0.25,0.17582417582417584
914,SP:552102a1c068df0cc113a00582f5bd5069e05e69,"This paper introduced a proximal approach to optimize neural networks by linearizing the network output instead of the loss function. They demonstrate their algorithm on multi-class hinge loss, where they can show that optimal step size can be computed in close form without significant additional cost. Their experimental results showed competitive performance to SGD/Adam on the same network architectures. ","This paper proposes a Frank-Wolfe based method, called DFW, for training Deep Network. The DFW method linearizes the loss function into a smooth one, and also adopts Nesterov Momentum to accelerate the training. Both techniques have been widely used in the literature for similar settings. This paper mainly focuses on the algorithm part, but only empirically demonstrate the convergence results. ",0.16393442622950818,0.16393442622950818,0.16393442622950818
915,SP:55367291f235b256ca2f583722106e6507accd05,"The paper proposes a new model combining an auto-encoder (AE) and a normalising flow (NF). The model, Generative Latent Flow (GLF), uses the AE to map the inputs to a latent space, which is then transformed using the NF. The approach is intuitively beneficial in that the AE can reduce the dimensionality of the inputs such that the NF mapping becomes much faster, computationally. The proposed method is compared to related methods that use a variational AE (VAE) in combination with an NF, and the similarities are pointed out and studied empirically.","The authors propose a model that combines a simple Auto-Encoder (AE) together with a Normalizing Flow (NF) model, such that to derive a generative model. In particular, the AE is used to learn a low-dimensional representation of the given data in a latent space. Then, a NF model learns under a maximum likelihood principle, the distribution of these latent codes by applying an invertible transformation on a easy to sample distribution.",0.24731182795698925,0.3150684931506849,0.27710843373493976
916,SP:5542cb8de7d232cde44071f0612827309298e98b,The paper studies visual question answering focusing on answering questions in a reference image of a different viewpoint. They propose a new dataset CLEVR-MRT drawing motivation from the well-known visual reasoning dataset CLEVR to illustrate the idea in which they have full control of the changes of viewpoints in an image. They then propose to use a volumetric encoder to represent 3D image features of an image via either 2D-to-3D projection or a contrastive-based encoder and further adapt an existing method (FiLM) to handle 3D tensors. Experiments on the CLEVR-MRT show that the use of the 2D features and 3D features of an image is complementary to each other.,"The paper explores the problem of visual question answering from another perspective. Similar to VQA, a system is provided with a scene and a question. However, the difference is that the question needs to be answered from a viewpoint different from the one provided. Hence, the system needs to perform “mental rotation”. The paper creates a new dataset called CLEVR Mental Rotation Tests which is based on the prior CLEVR dataset. The paper also studies the efficacy of various supervised and self-supervised models on the proposed dataset.",0.1826086956521739,0.23863636363636365,0.20689655172413796
917,SP:558e16a6d21c668b92792c51293357eaecb4dc9d,"This paper proposed a regularized policy learning algorithm for offline reinforcement learning. The implicit policy is trained by a GAN-like framework, and the regularization loss constrains the distance between learned policy and behavior policy. Experiments and ablation study on the D4RL dataset validate the proposed framework and algorithmic designs.","One of the existing Offline RL algorithms is to constrain the learned policy, such as constraining the learned policy to be consistent with the behavior policy itself or the action distribution based on state conditions, or adopting a Gaussian policy. However, in any given state s, the potential action value function in the action space may have multiple local maxima. Therefore, only one point can be used to evaluate whether the current policy is close to the behavior policy in any specific state, which may not well reflect the true difference between the two conditional distributions, and the stochastic policy that leads to determinism or unimodality may only capture one of the local optima leads to ignoring many other high-value actions. Especially when such policies such as CVAE and other models exhibit strong model-recovering behavior, large probability density may be assigned to low data density areas, resulting in exaggerating the density of high-value actions.  In response to the above problems, the method proposed in this article: - Uses an implicit policy to capture the multi-modality of the action value function - Controls the <s,a> access frequency in the data set to be as consistent as possible with the <s,a> access frequency of the learned policy as an additional training target, without the need to explicitly construct a behavior policy - provides the theory that proves, the method of matching behavior policy and current policy is equivalent to matching their corresponding <s,a> access frequency ",0.3,0.06072874493927125,0.101010101010101
918,SP:5590cddf899915fbaa37c3864b6687f1a4ce7cd4,"This paper considers using a GAN to generate synthetic data in a differentially private manner [see also https://www.biorxiv.org/content/early/2018/06/05/159756 ]. The key novelty is the integration of the PATE differential privacy framework from recent work. Specifically, rather than a single distinguisher as is usual in a GAN, there is a ""student distinguisher"" and several ""teacher distinguishers"". The student distinguisher is used as usual except that it does not have access to the real data, only the teacher distinguishers have access to the real data (as well as the synthetic data). The data is partitioned amongst the teacher distinguishers and their output is aggregated in a differentially private manner (and gradients are not revealed). The role of the teacher distinguishers is solely to correct the student distinguisher when it errs.","The paper studies the problem of generating synthetic datasets (while ensuring differential privacy) via training a GAN. One natural approach is the teacher-student framework considered in the PATE framework.  In the original PATE framework, while the teachers are ensured to preserve differential privacy, the student model (typically a GAN) requires the presence of publicly data samples. The main contribution of this paper is to get around the requirement of public data via using uniformly random samples in [0,1]^d.",0.15441176470588236,0.25925925925925924,0.1935483870967742
919,SP:55d2dc208f48d80e8b3cbd20cff9067ebab663a6,"Paper is about finding variational attributes for catalogue named entities.  Examples of such attributes is ""capacity"" for a memory card (e.g. Sandisk flash drive ""64GB"") and identification of such attributes helps in duplicate detection in E-commerce cataloging and search.  The proposed approach is unsupervised where they first detect some candidate entity variations (pairs of entities with high similarity scores) and then in each pair detect the ""significant"" phrase that ""contrasts"" one entity from the other one in the pair as the contrastive feature.  The significance phrases (ngrams) is estimated exhaustively from a corpora with a PMI-like metric.  Authors experiment with three entity linking systems with diverse architecture ranging from rule-based to logistic regression and neural-based models on three domains (music, grocessary and software catalogs).  Results are promising and show that most systems benefit from these features.","The authors propose a new algorithm, contrastive entity linkage (CEL), to identify duplicates and variations of entities in catalogues. The authors introduce the concept of base entities and entity variations. A base entity is defined using a set of attributes, and all variations must have the same values for base attributes, but differ in the non-base attributes. The key idea is to mine significant phrases from the unstructured attributes of a record such as the title or a product. The significant phrases are added as a new attribute, and a classifier is trained using the new ""variational"" attribute. Experiments show that inclusion of the variational attribute improves entity resolution results.",0.15602836879432624,0.1981981981981982,0.17460317460317462
920,SP:55e4c0663d63e508027c4ac1a75025ffeabac81b,This paper studies the implicit regularization effect that arises from using stochastic gradient descent with label noise and squared loss. They derive the expression for the implicit regularization term and show that it favors solutions which are stable against perturbations of the parameters. This paper validates their empirical findings using SGD on linear regression task with label noise. This paper also uses their results to study the self distillation technique.,"The paper studies the implicit regularization effect of unbiased random label noise on the dynamics of stochastic gradient descent(SGD). More precisely, an unbiased random noise is added to the true labels and the paper aims to analyze the regularization effect of it. The paper shows that the unbiased label noise would favor convergence to points which ",0.2857142857142857,0.3508771929824561,0.31496062992125984
921,SP:55f2c1321201a48682c90a08b79080416436e929,The paper proposes an optimistic policy optimization algorithm. It is theoretically shown that the algorithm has sublinear regret for multiple model classes such as kernel function and NTK. The policy update rule also allows the algorithm to have sublinear regret for  adversarial reward function. The technique for analyzing nonparametric model classes can potentially be extended to other reinforcement learning algorithms based on optimism.,This paper proves a regret bound for an optimistic variant of a policy optimization algorithm in an advsersarial reward setting. The paper extends prior work in this setting by considering function classes with bounded Eluder dimension instead of linear functions. This yields guarantees for a kernel-based variant of the algorithm (which also apply to neural kernels like the NTK).,0.20634920634920634,0.21666666666666667,0.2113821138211382
922,SP:55f583b190d59af8aaa7bda3c9e44bf5ed7ea96c,"This paper uses visual representation learned over monolingual corpora with image annotations, which overcomes the lack of large-scale bilingual sentence-image pairs for multimodal NMT. Their approach enables visual information to be integrated into large-scale text-only NMT. Experiments on four widely used translation datasets show that the proposed approach achieves significant improvements over strong baselines.","The authors propose to augment NMT with a grounded inventory of images.  The intuition is clear and the premise is very tempting.  The key architectural choice is to allow the transformer to use language embeddings to attend into a topic-image lookup table.  The proportion is learned to balance how much signal comes from each source.    Figure 4, attempts to investigate the importance of this sharing and its effects on performance.",0.08620689655172414,0.07042253521126761,0.07751937984496124
923,SP:55fe07527cc3340f2217fa8bab1d9746106fa04c,"The paper presents a variational inference approach for locally linear dynamical models. In particular,  the latent dynamics are drawn from a Gaussian approximation of the parent variational distribution,  enabled by Laplace approximations with fixed point updates, while the parameters are optimized the resulting stochastic ELBO. Experiments demonstrate the ability of the proposed approach to learning nonlinear dynamics, explaining data variability, forecasting and inferring latent dimensions.  ","This paper discusses a algorithm for variational inference of a non-linear dynamical models. In this paper model assumption is to use single stage Markov model in latent space with every latent variable Z_t to be defined Gaussian distributed with mean depends on Z_(t-1) and time invariant variance matrix lambda. The non linearity in transition is encoded in mean of Guassian distribution. For modeling the likelihood and observation model, the Poisson or Normal distribution are used with X_t being sampled from another Gaussian or Poisson distribution with the non-linearty being encoded in the parameters of distribution with variable Z_t.  This way of modeling resembles so of many linear dynamical model with the difference of transition and observation distribution have nonlinearity term encoded in them. ",0.2923076923076923,0.14615384615384616,0.19487179487179487
924,SP:561cb64e5320799677a5a7108830aaec9d33a963,"The paper is dedicated to studying adversarial attack and defense problems from the perspective of Fourier analysis. They demonstrate that the adversarial vulnerability of neural networks can be attributed to non-zero high-frequency components. Then, the author proposes a simple post average approach to smooth out the insignificant high-frequency components, which can improve the adversarial robustness of neural networks. They conduct extensive experiments on ImageNet and CIFAR-10 to defend existing attacks, including FGSM, PGD, DeepFool, and C&W attacks.","The paper proposes an approach for improving robustness of already trained artificial neural networks with relu activation functions. The main motivation comes from signal processing where robustness is typically obtained via averaging moduli of Fourier coefficients over some frequency band (e.g., mel-frequency coefficients and deep scattering spectrum are based on this principle). The strategy amounts to sampling several random direction vectors in a ball of constant radius centered at a training example and averaging their predictions. The empirical estimate of the expected predictor value over the ball centered at a training example is used as its hypothesis value.",0.13414634146341464,0.11,0.1208791208791209
925,SP:5626c1fc910929420a1453636be1da17572c3872,"This paper considers the important problem of mutual information estimation in neural networks, a problem at the root of a debate on the usefulness of the information-bottleneck approach for the analysis of information flow in neural networks. There exist many approximation schemes to get estimates of the inter-layers mutual information, but the issue is that they may lead to different conclusions due to their sensitivity to discretization schemes. The authors propose instead to study discretized neural nets, trained with a simple learning procedure taking into account the discretization and that thus does not need post-training discretization. In this case mutual informations can be computed exactly and the data quantifies the true information flow along training.","**Update after authors' response:** The authors have managed to clarify some issues and make a couple of small improvements to the manuscript. I am tempted to raise my score to a 7, but to me personally the paper does not quite pass the threshold for an 8 (which is the next possible rating on the conference scale). I am in favor of accepting the paper and will argue so during the reviewers' discussion.  **Summary**  The paper investigates the information-plane analysis of deep neural network training dynamics. The original claim was that neural networks go through distinct fitting and compression phases in SGD training that are well characterized by the information plane. These findings have later been disputed (particularly due to the way mutual information is estimated) which has lead to tens of papers investigating the phenomenon with mixed conclusions. The main idea of this paper is to eliminate the estimation problem by training neural networks with quantized activations, where the discrete mutual information can be computed exactly (in the limit of infinite samples). The original claims, controversy, and follow-up works are introduced and discussed in great detail. Original experiments are repeated with a very similar protocol to facilitate comparability of results. Additional experiments on MNIST are conducted, and ablations are performed. Results show the two distinct phases for some activation functions and some layers, but not for other activation functions.  **Main contributions**  1) Thorough discussion of the history of the Information-plane analysis, the main claims and previous findings and the follow-up papers it has spawned. Significance: The background and related work is well researched and well presented, which is very helpful for readers who have not followed this line of research closely. The only downside is that there is a fairly recent review (which is cited in the paper) which somewhat limits significance.  2) Quantized-activation training to avoid estimation errors when computing mutual information terms. Significance: the idea is very sensible in principle. Unfortunately, as some of the ablations show, the qualitative results can depend strongly on the quantization bit-width chosen. This is unfortunate since the main goal was to eliminate the influence of binning in naive estimation of the mutual information. Nonetheless, the results are exact and reliable for training quantized-activation neural networks - what is not clear is how to choose the quantization. 3) Reproduction of original experiments of Schwartz-Ziv & Tishby and Saxe et al. By sticking as closely as possible to the original training protocols, the new results are as comparable as possible (which does not mean that it is guaranteed that quantized-activation training dynamics are similar to “non-quantized” dynamics analyzed via binning - but empirically this seems to hold to a large degree). The paper also shows interesting ablations and additional experiments on MNIST. Significance: The most important experiments to run are included in the paper and important ablations are shown. The significance of the results could be improved by showing larger scale experiments on different kinds of networks (CNNs, ResNets, Transformers, …). ",0.3220338983050847,0.07539682539682539,0.12218649517684886
926,SP:5630dcc454f4e040626c29557dc5c67cbb289dda,"The paper introduces Dose Response Generative Adversarial Network (DRGAN) that is aimed at generating entire dose-response curve from observational data with single dose treatments. This work is an extension of GANITE (Yoon et al., 2018) for the case of real-valued treatments (i.e., dosage). The proposed model consists of 3 blocks: (1) a generator, (2) a discriminator, and (3) an inference block. In this paper, GANITE’s generator and discriminator architectures are modified to be able to handle real-valued treatments.",The paper proposes a generative adversarial net model for heterogeneous dose-response causal effect estimation. The idea is to generate counterfactual dose-response curves using the generator that can fool the discriminator that tries to distinguish between factual data and counterfactual data. Factual data along with counterfactual data generated by the GAN can then be used for heterogeneous causal effect estimation. ,0.14457831325301204,0.19672131147540983,0.16666666666666666
927,SP:5633fe1fee1abdd2a61bdd7679a771ce611f0f4e,"The paper proposed a new generative model for 3D periodic material molecular structure. They designed a special variational autoencoder, where the decoder is parameterized by the denoising score-matching framework. Experiments demonstrate the model can successfully generate valid and realistic material, and optimize desired properties.","This paper aims to address challenging stable crystal materials generation problems via diffusion variational autoencoder with graph representation learning. Several recent advances in generative models and GNN are combined together to develop the entire workflow from data distribution learning, prediction to sample generation and property optimization. The authors demonstrate their method by using three datasets and compare with three baseline methods. ",0.15555555555555556,0.11475409836065574,0.1320754716981132
928,SP:5674e8decbf353c9e5590e5c85ee5b8397a5db08,"Review: The paper proposes a technique for anomaly detection. It presents a novel method that unifies the current classification-based approaches to overcome generalization issues and outperforms the state of the art. This work also generalizes to non-image data by extending the transformation functions to include random affine transformations. A lot of important applications of anomaly detection are based on tabular data so this is significant. The “normal” data is divided into M subspaces where there are M different transformations, the idea is to then learn a feature space using triplet loss that learns supervised clusters with low intra-class variation and high inter-class variation. A score is computed (using the probabilities based on the learnt feature space) on the test samples to obtain their degree of anomalousness. The intuition behind this self-supervised approach is that learning to discriminate between many types of geometric transformations applied to normal images can help to learn cues useful for detecting novelties. ","This paper proposes a novel approach to classification-based anomaly detection for general data. Classification-based anomaly detection uses auxiliary tasks (transformations) to train a model to extract useful features from the data. This approach is well-known in image data, where auxiliary tasks such as classification of rotated or flipped images have been demonstrated to work effectively. The paper generalizes to the task by using the affine transformation y = Wx+b. A novel distance-based classification is also devised to learn the model in such as way that it generalizes to unseen data. This is achieved by modeling the each auxiliary task subspace by a sphere and by using the distance to the center for the calculation of the loss function. The anomaly score then becomes the product of the probabilities that the transformed samples are in their respective subspaces. The paper provides comparison to SOT methods for both Cifar10 and 4 non-image datasets. The proposed method substantially outperforms SOT on all datasets. A section is devoted to explore the benefits of this approach on adversarial attacks using PGD. It is shown that random transformations (implemented with the affine transformation and a random matrix) do increase the robustness of the models by 50%. Another section is devoted to studying the effect of contamination (anomaly data in the training set). The approach is shown to degrade more gracefully than DAGMM on KDDCUP99. Finally, a section studies the effect of the number of tasks on the performance, showing that after a certain number of task (which is probably problem-dependent), the accuracy stabilizes.",0.2546583850931677,0.155893536121673,0.19339622641509432
929,SP:56a799994baed2b0f32c40c7586cb50c8a43f855,"This paper proposed a way to decompose the difference between values of two policies in two MDPs respectively. Such a decomposition results in two parts, the first one is the difference between values of one policy under two MDPs; the second part is the difference between values of two policies under the same MDP. Using this decomposition, the paper then proposed three algorithms.   The first algorithm, called RPO, is used when there are two MDPs that the agent can interact with. The agent uses data from both two MDPs to get a good policy for one of the two MDPs. Such an algorithm is expected to be useful when gathering data from one MDP is costly while it from the other MDP is much cheaper.   The second algorithm is a model learning algorithm. In this setting, the agent only interacts with one MDP and learns a model to approximate the MDP. The RTO algorithm is different from the classic model learning algorithm (regression) in that the model is learned to achieve some consistency between the predicted values from the model and from the MDP.  The third algorithm combines the first two algorithms and is a full model-based algorithm. Specifically, now the agent only interacts with one MDP and learns a model of that MDP using RTO. Meanwhile, it also maintains and updates a policy that is expected to perform well in the MDP, using data from both the MDP and the model.  ","The paper studies transfer in reinforcement learning (RL), beginning with a theorem that relates the performance of one policy under a particular dynamics to another policy under different dynamics. This is broken down into a “dynamics-induced gap” and a “policy-induced gap”, for which explicit expressions are given. Optimizing a bound on the policy-induced gap w.r.t. the policy leads to an algorithm they call Relative Policy Optimization (RPO), and similarly optimizing a bound on the dynamics-induced gap w.r.t. the dynamics leads to an algorithm they call Relative Transition Optimization (RTO). The two algorithms can be combined into a single algorithm, Relative Policy-Transition Optimization (RPTO), which optimizes both the policy and the dynamics. Experiments indicate that RPTO achieves better transfer performance, both in terms of sample efficiency and asymptotic performance, than RPO and PPO warm-started from an expert policy from the source task.",0.1440329218106996,0.23178807947019867,0.17766497461928937
930,SP:56e4d560f80360bd6f50d162caade651b5ff91a6,"This paper proposes a new federated learning framework called HeteroFL, which supports the training of different sizes of local models in heterogeneous clients. Clients with higher computation capability can train larger models while clients with less computation capability train smaller models, and all these model architectures belong to the same model class. This approach dramatically benefits clients with limited computation capability and fully exploits their computation power. ","This work presents a novel FL algorithm named HeteroFL (the name might sounds weird to some peoples) and 3 different simple methods to improve FL in heterogeneous conditions (i.e. both in term of clients and data partitioning). These tricks are: 1. A revised batchnormalisation; 2. a pre-activity scaling; 3. a masked loss (i.e only consider local classes)  to help with non-IID datasets. All these modifications have been tested on 3 different datasets and 2 different tasks. From the results, we can see that the proposed approach works better. Although, it is not clear from where the benefit comes. ",0.19402985074626866,0.12745098039215685,0.15384615384615383
931,SP:56eb9cca9680e7ac118f3baf29789f172715c7d0,"The paper introduces a framework for lifelong learning of compositional structures. The algorithm is loosely inspired by biological learning and consists of two main steps. The step of component selection relies on existing methods that can learn task-specific structure. In the next step (adaptation), the algorithm adapts the knowledge from the previous tasks to the current task and if that is insufficient to solve the task, new components are added. Adaptation step relies on existing methods for adapting the knowledge state given a new task in continual learning (component parameters are updated). Knowledge expansion (adding new components) uses component dropout, a method proposed by the authors which combines pruning and alternating backpropagation steps with and without the potential new component. The proposed method is beneficial in terms of computational complexity in comparison with the standard lifelong learning methods. The authors evaluate the method on three compositional structures and show that it outperforms the baselines. The paper includes visualisation of the learned components, extensive appendix with additional experiments and ablation studies, and a systematic overview of the prior work in learning compositional structures and lifelong learning.","The authors propose a new framework for compositional lifelong learning. In the proposed approach, the composition and adaptation parts are separated when a lifelong learner faces a new task: first, learn the best way to compose all existing components for the new task (and train an optional new component if exiting components aren't sufficient to reach a good performance), and only then adapt the components parameters to better fit the new problem. This new framework is validated on extensive experiments, using three composition and 3 adaptation strategies from the literature on 9 datasets. The paper is pleasing to read, each choice is discussed and justified",0.16129032258064516,0.2830188679245283,0.20547945205479448
932,SP:56ffc50ee9fad6bf28dc34d87e8fc42cf56fdc0f,"In this paper the authors propose a method for training a classifier to be more effective at OOD (out of distribution) detection. Many OOD detection methods work by utilizing an auxiliary dataset as examples of OOD-ness. This is the approach taken in this paper and OOD is trained as being a k+1 classification class.  When training the OOD class the proposed method allows for adversarial perturbation of the OOD examples to help improve training. This is a pretty common technique in deep learning, see for example ""Deep Robust One Class Classification.""  Finally the main novelty of the method proposed by the authors is to sort a collection of OOD examples and sort according to the OOD score of the current model and use the ""qNth"" to be presented as OOD examples during the next epoch during training. The authors term this ""Informative Outlier Mining."" The authors demonstrate that this method works well experimentally.","1. The paper presents a lot of theory but insufficient evidence. It only employs limited image data (SVHN, CIFAR variants). The paper should be clear that the scope is limited to well-known image datasets only. This is because the approach is dependent on auxiliary data which is available for the image datasets. It is not clear if the approach might be more generally applicable to (say) network traffic, credit card transactions, natural language, etc. It would be better to include other types of data and along with auxiliary data generated through more generic means.",0.1032258064516129,0.16842105263157894,0.128
933,SP:57ac36954da5fb78b9f816c3aac6fd19d9c70e4f,"This paper introduces Deep Goal Oriented Clustering, an approach for joint clustering and classification. The approach shares a latent embedding for the data between the two tasks. The latent embedding is parameterized by a mixture of Gaussians. The approach gives a probabilistic, VAE-based formulation and derives the variational lower bound for the model. The authors run experiments investigating the effectiveness of their approach and the impact of the clustering-component of their approach. ","In traditional clustering algorithms, incorporation of “side-information”, or additional features only available during training time, typically assume some prior knowledge of the ground-truth clusters, or constraints on those clusters. However, this need not be the case, as training samples may contain arbitrary information which only indirectly corresponds to true cluster labels. This work proposes a novel method, called Deep Goal-Oriented Clustering (DGC), to incorporate such arbitrary “side-information” into a probabilistic auto-encoder based clustering algorithm.",0.12162162162162163,0.11392405063291139,0.11764705882352941
934,SP:57cc0c93dd03b67e5edf378ed41bd492bd6da2b2,The authors formulate the problem of black-box defense and propose a novel black-box defense approach called the Zero Order AutoEncoder-based Denoised Smoothing (ZO-AE-DS). Black-box defense corresponds to situations in which the defense model information cannot be obtained due to privacy protection in real scenarios. ZO-AE-DS introduces zero-order optimization on the structure of denoised smoothing (DS) to estimate the gradient and uses an Autoencoder (AE) to connect the denoiser with the model so that zero-order optimization can be conducted in a (low-dimension) feature embedding space.,"This work provides an algorithm to ensure robust training of an ML model with just black-box knowledge of it i.e., input and output access. The algorithm relies on using Denoised Smoothing with zeroth-order optimization where the gradients are estimated using random perturbations (finite-differencing). They avoid the computational burden and high variance of these estimates by first training an auto-encoder to reduce the inputs to a low-dimensional subspace. They show over different architectures and multiple datasets (Cifar10, STL10, image reconstruction over MNIST) that the proposed algorithm performs better than the baseline which is the Denoised Smoothing algorithm by Salman et al.",0.17894736842105263,0.16037735849056603,0.1691542288557214
935,SP:57f17f321704112897b6ff1af14c741dc01c6d2d,"This work introduces a conditional posterior sampling algorithm that is a model-free posterior sampling reinforcement learning algorithm and can be applied to general Markov decision processes and value function classes. Authors provide theoretical guarantees for the proposed algorithm.  Actually, it has been proved that the worst-case regret of the proposed algorithm is near-optimal and that improves the best known regret bounds for posterior sampling approaches (OPT-RLSVI, UCB-LSVI). The key component of the proposed algorithm is the definition of the likelihood over the collected samples (observations - state, action, reward) given a value function. To conclude, it is a theoretical work that shows that there is no statistical efficiency gap between OFU and posterior sampling algorithms. ","In this paper, the authors study the model-free posterior sampling algorithm for the episodic RL problem. A novel algorithm and analysis are proposed. The regret guarantee is proved, and specifically it depends on a term related to the function class, a term related to the structural complexity measure (decoupling coefficient), and other parameters. The authors also show the decoupling coefficient is small for linear MDPs, generalized linear MDPs, and Bellman-Eluder Dimension. When specialized to linear MDP, the regret bound matches Zanette et al. [2020b], thus statistically efficient. However, the algorithm suffers from computationally inefficiency.   ----- I have read the response and other reviews. I'll keep my original rating.",0.17647058823529413,0.19090909090909092,0.1834061135371179
936,SP:5817f96548dd3269127fe57d136b38735e6acea8,"The paper presents VR-reSGLD, a method to accelerate replica exchange stochastic gradient Langevin diffusion (reSGLD), which has been proposed recently to tackle non-convex learning problems. reSGLD suffers from two major sources of error resulting in low swapping rates: minibatch noise and the discretization error of Langevin diffusion. The idea of the paper is to use control variates to reduce the variance of energy estimators and thereby improve the swapping rate (which should lead to an accelerated convergence). Unlike previous modifications of SGLD, the variance reduction proposed in the paper aims at improving the energy estimators rather than the gradient estimators. The paper presents non-asymptotic results backing the intended acceleration of the Markov jump process. Numerical experiments illustrate the performance gain achieved by VR-reSGLD. These tests include a one-dimensional example (learning the component mean of a bimodal mixture of Gaussians) and Bayesian training of DNNs based on CIFAR imaging data. ","The authors propose a variant of the Replica Exchange Stochastic Gradient Langevin Dynamics (reSGLD) for non log-concave sampling by using a variant reduction technique on the estimation of the swapping rate. Assuming that the log-density is a finite sum. the authors apply classical variance reduction techniques to the energy estimator necessay to compute the swapping rate. They show that applying such technique yields a higher swapping frequency and faster convergent rate of both the continuous time SDE and its dicretization scheme. Finally, the authors perform numerical experiments on both synthetic and real world data, and show that VR indeed reduces the variance of energy estimator by several orders of magnitude, hence inducing faster convergence.",0.18831168831168832,0.25,0.21481481481481482
937,SP:5820c97c44d7ad06c16cf5e7ce4f8b197ea08c94,"This paper proposes a stochastic second order method to train neural network under some specific regularisation criterion. The method is based on the Sifrian, an extension of the Lagrangian that splits the definition of the gradient of each layer's parameter as different constraints with their own multiplier. Solving the best direction from the Sifrian is complicated in the general case but can be done when considering only one sample. This allows for a stochastic algorithm to train the neural network. Finally, some limited  numerical experiments are conducted.","This paper claims that it is possible to compute the Newton method's update exactly for deep neural networks (multi-layer perceptrons). The motivation is that Newton's method, as a second-order optimizer that includes loss curvature information, should improve upon first-order optimizers, such as gradient descent, that use only first derivatives (gradient) of the loss. Second order methods tipically converge in a smaller number of iterations, but each update is expensive to compute and that's why they are not widely used in practice. It must be noted that Newton's method is almost never mentioned in the context of Neural Networks (NN), because it is only guaranteed to converge for convex loss functions (which is clearly not the case for NN). However, the authors claim they have some tricks to fix that. ",0.2159090909090909,0.13970588235294118,0.16964285714285718
938,SP:58544efe4373310d82b14a2822a0c4e34e810c25,"This paper presents a graph neural network-based approach to solve two binary analysis tasks (program classification and binary similarity detection). The key idea of the paper is to merge different forms of representation of binary code (compiler IR, assembly code, etc.). ","This paper proposes a program analysis model based on graph neural networks that performs analysis on the assembly code of a program and uses Control Flow Graph (CFG), Call Graph (CG), and Data Flow Graph (DFG) of the program as inputs. The goal is to design a generalized model that can solve both source-code level tasks (e.g., program classification) and compilation-related task (e.g., vulnerability analysis). Program embedding based on the assembly code allows the model to learn compilation-specific features and the use of multiple graphs reflect semantic and structural information.",0.35714285714285715,0.15789473684210525,0.218978102189781
939,SP:585ea7586283caf39965101656d1dc17abe1b331,"This work proposes a new model class designed to make SHAP value calculations more efficient. The proposed method exploits sparsity and additivity among intermediate values to provide fast exact SHAP values for shallow ShapNets, and fast approximate SHAP values for Deep ShapNets. This approach enables SHAP-based regularization during training, layer-wise explanations, and faster SHAP-based explanations with minimal loss in quality.","The paper proposes to incorporate Shapley values as latent representations in deep models. Specifically, the paper constructs Shallow SHAPNETs that computes the exact Shapley values. The paper also constructs Deep SHAPNETs that maintain the missingness and accuracy properties of Shapley values. The effectiveness of the proposed SHAPNETs is demonstrated through experiments on synthetic and real-world data. ",0.15873015873015872,0.17543859649122806,0.16666666666666666
940,SP:586149146ed5e74dd231b134fa6ba582f6e1f72b,"of the paper:  The paper studies adversarial attacks in RL, focusing both on the design of optimal attack strategies on RL agents, as well as robust training RL procedures for mitigating attacks. Building on the results of (Zhang et al., 2020), the paper proposes a new learning framework (ATLA), that simultaneously trains a (strong) adversary and a (robust) deep RL agent. The paper showcases the importance of the new framework through extensive experimental evaluation. ",This paper proposes to improve the robustness of a reinforcement learning agent by alternatively training an agent and an adversary who perturbs the state observations. The learning of an “optimal” adversary for a fixed policy is based on the theory of SA-MDP in prior work. The learning of an optimal policy under a fixed adversary is done by solving a POMDP problem. Experimental results show that the proposed alternating training with learned adversaries (ATLA) framework can improve the performance and robustness of PPO.,0.22972972972972974,0.20238095238095238,0.2151898734177215
941,SP:5867aa8bb3eaaf5f916865d662be8667318a514f,This paper propose a new way to learn self-supervised model ensembling. Their novel approach learns representations via gradient descent directly at inference time after having pretrained feature extractors. And the authors conduct a series of experiments to show the efficacy of their method. ,"The paper proposes a new self-supervised ensembling method to get a better feature representation. Instead of using the conventional averaging or concatenating to ensemble multiple features, this paper proposes a different inference scheme where the backbone is also updated during the test time in a self supervised fashion. Experiments are conducted to empirically show the superiority of their methods compared to some existing methods.",0.3409090909090909,0.23076923076923078,0.27522935779816515
942,SP:586a3c4bec83130fd4f2a46220c12ab37250877b,"This paper presents a new algorithm for goal-conditioned HRL, named HIGL, that trains a high-level policy to generate subgoals towards landmarks, i.e., promising states to explore. Two criteria are considered for being a landmark, coverage of the visited state space and novelty of states. Unlike prior work that only considered generating subgoals close to the current state, this work takes both (1) reachability and (2) potential information of subgoals into account. The proposed HIGL outperforms the previous state-of-the-art method in both dense and sparse reward settings thanks to the directed landmark-driven exploration by the high-level policy.  ","Paper introduces HIGL, a hierarchical RL framework based on landmarks. The main idea is to limit the higher level action space (which is often taken to be the full state space), by restricting it to specific landmarks. These landmarks are defined bases on two criteria: coverage of the visited state space, and novelty of the visited states. These landmarks are then integrated in an HRL framework. Experiments on three U-maze like environments show that their method performs well. ",0.19230769230769232,0.25316455696202533,0.21857923497267764
943,SP:586c729c2c163cba6c8a0519dd853463bbc405b7,"The authors have put decent effort to bring concept-based representation learning and disentanglement learning together under one umbrella in terms of the quality of generated concepts in presence as well as absence of ground truth concept labels. Some related metrics were proposed for evaluation of the quality of concepts for both these methods. Based on these studies, presented in the paper, some important conclusions were made based on requirements of concept supervision and their effects on final concept quality as well as the predictive performance of the model.","The authors consider the question of whether recent concept-based learning algorithms, as well disentangled representation learning algorithms, result in high-quality representations. In particular, they consider what high-quality should mean in terms of the relationship with ground truth concepts and the ability to make accurate predictions for a downstream task. To this end, they propose two main metrics for representations that are explicitly or implicitly encouraged to encode concepts: 1) a score that captures how well the learned representation preserves the relationships between concepts (which may be correlated), and 2) a score that captures how well concepts can be split into groups that are useful/useless for predicting particular label dimensions.",0.20224719101123595,0.1592920353982301,0.1782178217821782
944,SP:5893f3dba5c2341a1e9dad1002d7ac226417c026,"This paper proposes a new benchmark for NAS methods, which is called NAS-Bench-360. Unlike the existing benchmark datasets for NAS, the proposed benchmark contains ten diverse tasks derived from various fields of research. This paper has tested several standard NAS methods on the proposed benchmark and confirmed that there are many gaps among the ten tasks and NAS methods.","This paper proposes a benchmark to test the performance of NAS algorithms and search spaces on a diverse set of tasks. The benchmark consists of 10 different datasets across different modalities. On these tasks, a variety of NAS algorithm as well as search spaces are allowed a fixed amount of compute resources (in terms of GPU hours) to explore and train, and reach the final performance. The search space are not limited to architecture topologies, but also hyper-parameters. On this new benchmark, authors find that existing SoTA NAS methods may not generalize to different tasks, especially with low compute budgets. ",0.2786885245901639,0.16831683168316833,0.20987654320987653
945,SP:58b222745ef2775a8925397ba2a98ba086e945e4,"The authors introduce a discriminative model for semi-supervised learning for which several existing methods are special cases. In their model, for each data value, there is a distribution from which the label is sampled. Although this distribution is unknown, in their framework the sampling distribution's parameters are approximately produced by a discriminative model such as a neural network trained on the labeled data.","This paper proposes a probabilistic model to describe semi-supervised/unsupervised learning, which is further applied to model neuro-symbolic learning. Comparing to traditional unsupervised/semi-supervised learning formulations, the proposed model imposes a prior on the label distribution instead of input features. When applying this formulation to neuro-symbolic learning, the symbolic part can be regarded as a prior on label space to constrain the learning process. Finally, the authors propose three methods to calculate the loss of violating the symbolic prior constraints on label space.",0.24615384615384617,0.1839080459770115,0.21052631578947367
946,SP:58b49ce9f05350745bc62b1ed2cb116fa07bb7d9,"The paper considers the problem of automated adaptation of learning rate during (deep) neural network training. The use cases described are standard and adversarial training for image classification. Given the wide use of DNNs in computer vision (and other areas), learning rate tuning is clearly an important problem and is being actively researched.","This paper proposes an algorithm for automatically tuning the learning rate of SGD while training deep neural networks. The proposed learning rate tuning algorithm is a finite state machine and consists of two phases: the first phase finds the largest learning rate that the network can begin training with for p = 10 epochs; the second phase is an optimistic binary exploration phase which increases or decreases the learning rate depending upon whether the loss is NaN, increasing or decreasing. Empirical results are shown on a few standard neural networks for image classification on CIFAR-10/100 datasets and for adversarial training on the CIFAR-10 dataset.",0.2830188679245283,0.14150943396226415,0.18867924528301885
947,SP:58b67f1e081e61982d524768c88f3754c3470e0a,"The proposed method addresses continual learning, by learning a mapping from the input space to an embedding space, and employing a loss that encourages clustering the embeddings by class (and task?) around some centroids called prototypes. Catastrophic forgetting is mitigated by adding a penalty term that is proportional to the distance of the embeddings under the current network of some samples from the past tasks, and the centroids previously associated to each of them.","Paper proposes a method for continual learning. The method is based on the learning of a metric space where classes are represented by prototypes in this space. To prevent forgetting the method proposes to perform prototype recall, aiming to keep prototypes in the same location in embedding space (Fig 1b). The method is compared with several recent methods and is shown to outperform them on two small datasets (MNIST permuted and CIFAR10). The idea of using prototypes for continual learning is interesting, as the authors point out, this does not require adding new neurons to the network for new tasks.",0.25675675675675674,0.19,0.21839080459770116
948,SP:58d0e331b89085a01a2c56ec63efb1126f616846,"The motivation of this work is on the computational cost of using BNNs in practice, where applications might require a large number of BNNs in an ensemble formation for achieving good performance. The work in this manuscript aims to reduce the computational cost ensemble.  The manuscript's insight for solving the computational cost is to exploit similarities in spatial neighbouring from images. This is a similar approach used in convolutional neural networks. Experimental results show improved efficiency in image tasks, while also considerably reducing the computational cost when compared to competitor methods.","This paper proposed a spatial `smooth` layer including a feature range bounding layer `prob` and `blur` the intermediate feature map in a CNN. 'Smooth' improves the accuracy and uncertainty of both deterministic CNN and a Bayesian NN approximated by MC-dropout. Authors tried to justify how `smooth` improves the optimization of neural networks by 1. interpolating the `blur` operations as an ensemble of the neighboring features 2. showing `smooth` filter out the high-frequency noises introduced by MC-dropout and smoothen the loss landscapes perturbed by MC-dropout. Authors empirically evaluated `smooth` on image classification and semantic segmentation tasks and showed that it improves both accuracy and uncertainty. Authors also tried to connect common pieces in CNNs like global average pooling, ReLU + BN as special cases of `smooth`.",0.15217391304347827,0.109375,0.1272727272727273
949,SP:590a081dcfa6a61b6228700092654cf8647ffecd,"This paper is a continuation of an original associated learning paper by Kao&Chen 2021. It attempts to propoose new learning approach associated learning as an alternative way to back-propagation. On top of the original paper, it discovers more interesting properties and extend AL to CNN, LSTM and transformers (though lacking sufficient details).","This paper proposes associated learning (AL) for CNN, RNN, and transformer. Different from back-propagation (BP), AL decomposes BP’s global end-to-end training strategy into several small local optimization targets such that each sub-networks has an isolated gradient flow. To achieve this, the paper proposes to map input $x$ and output $y$ into intermediate AL layers and performs metric learning (e.g., $t_1=b_1(s_1)$) and auto-encoder learning ($t_1=t_1^{‘}$), as shown in Figure 2. Moreover, Each AL layer can be optimized locally. The idea is interesting. The experiments demonstrate the effectiveness on (IMDB Review, AG’s News corpus, DBpedia Ontology, the Stanford Sentiment Treebank, CIFAR10, and Fashion-MNIST.",0.2222222222222222,0.1016949152542373,0.13953488372093023
950,SP:59210764f21eadc8e69e720f9d12f3b85cf74ceb,"The authors propose a new benchmark for evaluating surrogate functions for architecture search. According to the authors, existing tabular architecture search benchmarks are insufficient for this purpose due to using overly small search spaces. The main difference of this benchmark and other existing architecture search benchmarks such as NAS Bench 101 and NAS Bench 201 is that they do not attempt to evaluate all the architectures in the search space and do so for a much larger search space (DARTS). The authors then use this new dataset to show that surrogate functions are better than tabular estimators (error wise; although some lower performance architectures were discarded to make this case). Additionally, the authors compare the proposed benchmark (based on surrogate functions) with a real benchmark and observe that the results are qualitatively similar. Finally, the authors show that reevaluate the claim that local search is state-of-the-art for architecture search and find that, using their benchmark, that local search is still state-of-the-art provided that enough computational budget is available for the experiment.","This work filled an important gap in the NAS benchmarks. The previous benchmarks only contain small search space due to the expensive cost of evaluation of neural architecture. In this search space, random search often becomes competitive in the narrow search space. Thus, to provide meaningful comparison, this work provided a benchmark in a large NAS search space (same as in DARTS), and using  surrogate models to predict validation performance of untrained neural architecture. The empirical results suggested using the surrogate benchmarks resulted in similar optimization trajectory as real evaluations and the author also shows one can derive/validate research ideas quickly with the benchmarks.",0.14689265536723164,0.24761904761904763,0.1843971631205674
951,SP:5948c59cae322efd1b6fef76d3cbddfe9771c102,"In this work, the authors propose a model for clustering survival data which accounts for both survival time as well as covariates, such as patient demographics. The model is similar to previous approaches, though it incorporates a neural network encoder to handle unstructured data types as input. A modest set of experiments suggest that the proposed approach identifies more meaningful clusters than similar approaches. Also, while not the focus of the proposed approach, empirical evaluation shows that the proposed method performs similarly to existing approaches on time-to-event predictions.","This work tackles the problem of clustering in the context of survival data using a generative model. A variational autoencoder is used for modelling the data, while the latent representation is leveraged to model the survival outcome conditionned on the assigned cluster following a Weibull distribution. This approach allows to leverage both the survival outcome and the covariates for clustering. Moreover, the latent state associated to each cluster is then used for interpretability of the observed cluster. Synthetic and real world datasets demonstrate the competitiveness of the method on both discriminative and clustering performances.",0.2111111111111111,0.20212765957446807,0.20652173913043478
952,SP:594bd533a35136573306102a080e81fefeb0c37b,"The paper presents an invertible generative network, for conditional image generation.  The model is an extension of Real NVP with a conditioning component. Experiments are performed for image generation on two tasks: class conditional generation on MNIST and image colorization conditioned on a grey scale image (luminance). Comparisons are performed with a conditional VAE and a conditional GAN (Pix2Pix). An ablation study motivates the importance and role of the different components.","This paper proposes conditional Invertible Neural Networks (cINN), which introduces conditioning to conventional flow-based generative models. Conditioning is injected into the model via a conditional affine coupling block, which concatenates conditioning with the input to the scaling and shifting sub-networks in the coupling block. Other small modification are proposed to improve training stability at higher learning rates, including soft clamping of scaling coefficients, and Haar wavelet downsampling, which is proposed to replace the squeeze operation (pixel shuffle) that is often used in flow-based models. The invertibility of the cINN allows for style transfer by projecting images into the latent space, and then reconstructing the image with a different conditioning. The performance of the cINN is evaluated empirically on the task of colorization, where it is shown to outperform other techniques in terms of nearness to the true colours, as well as sample diversity.",0.22535211267605634,0.1095890410958904,0.1474654377880184
953,SP:59629689ec4e6ffa51a30e0a931f103caadd81b8,"This paper is a direct follow-up of Zhang et al 2020b. With assumptions including overparametrized two-layer ReLU network, normalized dataset, gamma-separability, and Lipschitz convex loss, it proves the convergence of FedAvg under adversarial perturbation. These assumptions are easy adaptations from Zhang et al 2020b.    --post rebuttal--  I would like to thank the authors for the response. However, after reading the author response my opinion remains the same, as the authors acknowledge that this work is an extension of Zhang et al 2020b and there is no experiment after the revision. My main concern is still the novelty. I would encourage the authors to work on the future direction for empirically verifying their general framework.  ","This paper proposes a federated adversarial learning (FAL) framework with strong theoretical guarantees. Compared to the centralized model, the federated model allows each local client to generate the adversarial samples and updates the gradient themselves for several iterations and then communicate to the centralized model for global updating.  This is the first work that gives convergence guarantees for FAL.  Their technical analysis mainly involves two parts In the first part, they utilize the overparameterization and separability assumption to ensure the initialized model is close to some model U^* which can achieve the small robust loss. Then in the second part, by using such property on the initialized model and by bounding the difference between real gradient and the FL gradient, they are able to show the convergence. As the authors stated, this FL gradient is a new gradient they use to tackle the difference between global and local updates. ",0.1794871794871795,0.14093959731543623,0.15789473684210525
954,SP:598a0c59ed1b2fb08626115179948768d09f0e45,"* This paper proposes an optimization problem to adopt insert/replace operations (program obfuscations) to generate adversarial programs. They apply it to the task of program summarization, and show that they outperform the existing baseline published in 2020. In particular, one of the main contributions is the identification of the site-perturbation and site-selection process, and formalizing them as practical optimization based on PGD. ","This work tackles the problem of adversarial attacks against ML models for code-understanding tasks, such as function summarization. It formulates the problem as the adversarial application of existing semantics-preserving program transformations (e.g., renaming variables), by jointly optimizing on the location of such a transformation, and the argument to the transformation (e.g., what to replace an existing identifier with). It shows that such adversarial examples increase the attack success rate over baseline approaches, and training with such examples increases the robustness of the resulting model to the same or baseline attacks.",0.21875,0.14893617021276595,0.1772151898734177
955,SP:599f2f7249aba31390c85edfeda4e7dd63ec4915,The paper proposes a neural approach that increases network resilience by edge wiring. The approach uses a combination of graph neural network (GNN) and policy gradient method to do so. The experiments use a few small networks and several non-neural baselines. ,"This paper studies how to improve network resilience by proposing a reinforcement learning-based framework named **ResiNet** and a new GNN architecture called **FireGNN**. The proposed framework is able to directly generalize to unseen graphs. The new GNN architecture applies the graph filtration process, which enhances the expressivity of GNN. The authors conduct experiments on synthetic and real datasets to compare the proposed framework with previous baseline methods.",0.23809523809523808,0.14705882352941177,0.18181818181818185
956,SP:59b5a45bcd83258725665038057e8106e050721b,"This paper deals with the class-imbalanced semi-supervised learning problem. The paper utilizes existing semi-supervised learning algorithms to acquire good representation, and additionally introduces an auxiliary balanced classifier called ABC, which is trained on a class-balanced subset of a minibatch to mitigate the biased results caused by class-imbalance. The ABC is trained using not only the balanced subset but also unlabeled data with consistency loss. The experimental results show that the proposed method outperforms existing methods by large margin.","The authors introduce a semi-supervised learning algorithm (SSL) for class-imbalanced scenarios.  In particular, an Auxiliar Balanced Classifier coupled with a 0/1 mask is used to favor the cost regularization. The methodology is interesting, and the experiments demonstrate that the proposed method outperforms state-of-the-art techniques on image classification tasks, even for large datasets under challenging imbalance ratios.",0.2289156626506024,0.3064516129032258,0.26206896551724135
957,SP:59bd93781598c2b893c92d41b3cad91b5f719e57,"The paper proposes a regularization term to augment loss functions, where the regularization term effectively minimizes the calibration error of the model. The term itself is a kernel density estimator over the K-simplex space (hence Dirichlet kernel is the natural choice).  The authors claim the estimator is consistent (but not unbiased, though they partially debias it) and empirically verify that their method yields tradeoff between accuracy and calibration that is near Pareto optimal.",The paper proposes a new approach for calibrating neural network outputs. The idea is to train the neural network with a regularized loss function that is a linear combination of prediction and calibration errors. The calibration error is measured as the Lp norm of the difference between predicted class probabilities and the expected true class probabilities given the predicted class probabilities where the latter term is computed using a kernel density estimate with a Dirichlet Kernel. The approach is evaluated in terms of accuracy and expected calibration error on CIFAR-10 and CIFAR-100.,0.32432432432432434,0.2553191489361702,0.28571428571428575
958,SP:59f3aa13da7e04d36e60a67555cd8254047e949a,"This paper proposes BlendSearch, which combines global and local optimisation for the problem of hyperparameter optimisation when search cost is heterogenous. To achieve so, they use the combination of one global search instance (e.g. Bayesian optimisation; used to identify promising regions as starting points for local search) with multiple local search instances (which actually do the search). The local search instances will be created, merged and deleted on the fly using the criteria proposed by the authors. The paper finally experimentally validates their approach in various hyperparameter tuning experiments to show promising results.",The proposed BlendedSearch (BS) presents an intuitive next step in the combination of global and local search schemes for hyper-parameter optimization (HPO). Global search schemes are widely used for HPO but can suffer from large HPO times since their vanilla forms do not account for function evaluation costs. Local search schemes are usually not widely used for HPO but seem useful if the goal is to restrict the search to a region of the search space where the function evaluation costs do not grow drastically. The proposed BS interleaves global and local search steps to ensure that the global search does not go into regions of high evaluation costs while also avoiding being stuck in local minima.,0.20212765957446807,0.16101694915254236,0.1792452830188679
959,SP:5a02acc83ad8731d9fa51bce94132813b5d78fc9,"This paper shows generalizations of the method of bounded differences to a broad class of functions with sub-Gaussian and sub-exponential behavior. Important applications include Rademacher averages, and bounding the generalization error of PCA. The paper is quite technical, but the machinery developed therein is highly general, and seems to this reviewer to be of great interest in a broad variety of machine learning settings. ","McDiarmid's inequality is one of the workhorses of modern machine learning. In its simplest form, however, it requires the function under consideration to verify a bounded differences property. This work (as others before it) investigates extensions of this idea beyond this stringent requirement.  Using the entropy method [Boucheron et al., 2013, Section 6],  the authors prove concentration inequalities for functions of independent random variables for which the *conditional versions* (random function that keeps all arguments but one fixed) enjoy sub-Gaussianity/sub-exponentiality (instead of being bounded as for *vanilla McDiarmid*).  They further put the new tools in application for vector valued concentration, principal subspace analysis and generalization through Rademacher complexity and algorithmic stability.",0.18181818181818182,0.10434782608695652,0.1325966850828729
960,SP:5a0e35b51548e82135b965e7b692e8a0af1289f8,"This paper considers reinforcement learning for discrete choice models with unobserved heterogeneity, which is useful for analyzing dynamic Economic behavior.  Random choice-specific shocks in reward is accommodated, which are only observed by the agent but not recorded in the data. Existing optimization approaches rely on finding a functional fixed point, which is computationally expensive.  The main contribution of the paper lies in formulating discrete choice models into an MDP, and showing that the value function is concave with respect to the policy (represented by conditional choice probability).  So policy gradient algorithm can provably converge to the global optimal.  Conditions on the parameters for global concavity are identified and rates of convergences are established.  Finally, significant advantages in computation were demonstrated on the data from Rust (1987), compared with “nested fixed point” algorithms that is commonly used in Econometrics.","This paper deals with a certain class of models, known as discrete choice models. These models are popular in econometrics, and aim at modelling the complex behavioural patterns of individuals or firms. Entities in these models are typically modelled as rational agents, that behave optimally for reaching their goal of maximizing a certain objective function such as maximizing expected cumulative discounted payoff over a fixed period.",0.1079136690647482,0.22727272727272727,0.1463414634146341
961,SP:5a0fa18c836d63dae05055f3197e479099d7abb5,"This paper proposes an approach to adversarial detection.  The approach first computes a representation of the activation layers using the Benford-Fourier coefficients.  One then generates a range of noisy instances, and trains an SVM using those noisy instances as supervised labels (e.g., noisy instances are adversarial).  The SVM uses the Benford-Fourier coefficients of the activation layer as the input features.  The results show good performance against some baselines such as LID.",This paper presents a new discriminator metric for adversarial attack's detection by deriving the different properties of l-th neuron network layer on different adv/benign samples. This method can achieve good AUC score comparing to other start-of-art detection methods and also achieve good robustness under corresponding adaptive attack. The framework is clear and the experiment is solid.,0.13513513513513514,0.16393442622950818,0.14814814814814814
962,SP:5a114af6b868ac0f8923205ea5257590967110c0,The authors introduce the use of value function variance (conditioned on state transition) as auxiliary reward promoting exploration during training. The variance is estimated using the bootstrap DQN approach. The main difference with similar methods is that the value uncertainty is not used in a Thompson sampling scheme but it is instead use to provide exploration reward. ,"This paper proposes to use an intrinsic reward based on uncertainties calculated from temporal difference errors. The approach, called Temporal Difference Uncertainties (TDU), estimates the variance of td errors across multiple (bootstrapped) parameters, for a given state, action, next state and reward, where variability is due only to variance in parameters. The other addition is to learn a separate set of action-values that use this intrinsic reward, from the bootstrap set. Actions are then taken by randomly sampling an action-value function from the combined set. ",0.19298245614035087,0.12643678160919541,0.15277777777777776
963,SP:5a1ad3ed5e9e4e7c7b0f10530688f2f52ee76948,"This paper presents a new learnable representation fo audio signal classification and compares it to the classical mel-filterbanks representation and two other learnable representations on a broad range of audio classification tasks, from birdsongs to pitch, instrument, language or emotion recognition. The proposed representation combines several parameterized representation techniques from the recent litterature. It is reported to yield on par or better classification results than the other methods on several of these tasks using single- or multi-task learning.","The paper shows a detailed interpretation on the relationship between each component of hand-crafted audio front-ends (such as mel-spectrograms) and learnable counterparts. To do that, they followed the narratives presented from the previous works such as SincNet and improved the model by changing the several components of it. The authors grouped the audio front-ends into mainly three parts which are filtering, pooling, and compression. And, the contributions were made at each stage. For filtering stage, instead of learning all the parameters of the convolution layer, they let the model to learn only center frequency and bandwidth of the filterbanks that are initially assigned with Gabor filters. For pooling stage, instead of using simple average or max poolings, they let the model to learn low pass filtering with small parameters. For compression, instead of using log based dynamic compression, they extended Per-Channel Energy Normalization by replacing a fixed smoothing factor to learnable parameters and named it to sPCEN.",0.2,0.09876543209876543,0.1322314049586777
964,SP:5a1d5dd1a128cc32d3e9c71f309cb7031fcffcdb,"The authors introduce the idea of distributed backdoor attacks in the FL framework, in which the dishonest participants in FL add local triggers to their training data to influence the global model to classify triggered images in a desired way. They show empirically that the learned models then are more likely to be successfully forced to misclassified images in which all the local triggers are present at test time, than are models learned using centralized backdoor attacks, where all attackers use the same trigger pattern (one of the same size as the concatenation of the local triggers, to be fair in the comparison). They then demonstrate that because the local triggers cause smaller corruptions in the model coefficients, these distributed attacks survive robust FL training algorithms (namely FoolsGold, and a recent robust regression based method) more often than centralized attacks. Similar experiments are conducted on the Loan text dataset, using appropriate analogs of local triggers, with similar results.","This paper studies backdoor attacks under federated learning setting. To inject a certain backdoor pattern, existing work generate poisoning samples by blending the same pattern with different input samples. Even for federated learning where the adversary can control multiple parties, such as [1], all parties still use the same global backdoor pattern to generate poisoning samples locally. On the contrary, in this work, they decompose the global pattern into several small local patterns, and each adversarial party only uses a local pattern to generate poisoning samples. In their evaluation, they show that the backdoor attacks generated in this way are more effective, resilient to benign model parameter updates, and also survive better against existing defense algorithms against attacks in federated learning settings.",0.1518987341772152,0.19672131147540983,0.17142857142857143
965,SP:5a25c3acfaa7210b5109f2873eebd806824385c0,"This work introduces a meta-learning framework, based on MAML, for single-target DA (STDA) and open compound DA (OCDA) in semantic segmentation. Similar to Li et al. [22], the idea is to learn the initial condition (model's parameters) that is more favorable for target adaptation. The proposed framework makes use of an existing image-2-image model to translate source images into, what are called here, latent images; this is to have target-like annotated data to guide meta-optimization.  Each iteration of the proposed algorithm is composed of two consecutive steps: (1) meta-training operating on source and latent data to find the favorable initial condition for the next step and (2) meta-testing to perform target adaptation starting from the learned initial condition.   The meta-training optimization, similar to MAML, involves inner and outer loops. In case of STDA, the inner loop performs UDA optimization steps on labeled source and unlabeled latent samples; the outer loop, based on the optimized weights of the inner loops, meta-optimizes the network to minimize segmentation loss computed using labeled latent data. In case of OCDA with k target sub-domains, k-mean clustering is first done to assign sub-domain pseudo-labels to target images. This information is used in the image-2-image operation to translate source data into sub-domain-like data. Different to STDA, there is an additional adversarial objective in the outer loop.  To evaluate performance, this work consider two DA benchmarks: GTA5->Cityscapes (STDA) and Cityscapes->C-Driving (OCDA). Reported results show improvement of the proposed framework as compared to previous approaches.",The paper proposes a meta-learning framework for open compound domain adaptation. The method uses k-mean clustering to estimate the domain of target samples and employs the image translation method to augment datasets. Then the augmented images are used for the meta-learning framework. The method outperforms baselines on Cityscapes and C-Driving. ,0.09328358208955224,0.46296296296296297,0.15527950310559008
966,SP:5a5c019b22174c87b664a406aae491b42539d31d,"They propose ""Sample Efficient Deep Neuroevolution"" (SEDN) model and experiment on Atari games. In this model, they use a Variational Encoder (VAE) to encode state frames into a latent vector, and use an LSTM to encode the current latent vector and action to predict the next latent space. A policy network (trained using CMA-ES) takes the latent space, and hidden state of the RNN as an input, and outputs an action to execute.","The main difficulty of neuroevolution---requiring a huge number of simulations for high dimensional problem---is addressed in this paper by introducing VAE to reduce the state space dimensionality and using a rather shallow controller network. This idea itself is very promising, however, it has been introduced in (Ha and Schmidhuber, 2018).  Still, there seems to be differences in how to gather histories and how to use them. Nevertheless, the differences are not well described in the text. The effect of the modification is not evaluated on experiments.",0.20270270270270271,0.17045454545454544,0.18518518518518517
967,SP:5a8d1e9cc2fac478649c832a15dd2df254861d03,"The paper provides the convergence analysis at linear rate of gradient descent to global minima for deep linear neural networks – the fully-connected neural networks with linear activation with l2 loss. The convergence only works under two necessary assumptions on initialization: “weight matrices at initialization are approximately balanced” and “the initial loss is smaller than the loss of any rank-deficient solution”. The result of this work is similar to that of Barlett et al. 2018, but the difference is that, in Barlett et al. 2018, they consider a subclass of linear neural networks (linear residual networks – a subclass of linear neural networks which the input, output and all hidden layers are the same dimensions). ","This paper continues the recent line of study on the convergence behaviour of gradient descent for deep linear neural networks. For more than 2 layers, the optimization problem is nonconvex and it is known strict saddle points exist. The main contribution is a relaxation of the balancedness condition in previous work by Arora et al and a new deficiency margin condition, which together allowed the authors to prove that gradient descent will converge to an epsilon solution in at most O(log 1/epsilon) iterations (under reasonable assumptions on step size and other parameters). Examples on how to satisfy the two conditions are discussed. Overall, the obtained results appear to be a solid contribution beyond our current understanding of deep linear neural networks, and potentially may be helpful towards our understanding of deep nonlinear neural networks.",0.26956521739130435,0.22794117647058823,0.24701195219123506
968,SP:5abcf6f6bd3c0079e6f942f614949a3f566afed8,"In this paper, the authors propose a method to perform architecture search on the number of channels in convolutional layers. The proposed method, called AutoSlim, is a one-shot approach based on previous work of Slimmable Networks [2,3]. The authors have tested the proposed methods on a variety of architectures on ImageNet dataset. ","This paper proposes a simple and one-shot approach on neural architecture search for the number of channels to achieve better accuracy. Rather than training a lot of network samples, the proposed method trains a single slimmable network to approximate the network accuracy of different channel configurations. The experimental results show that the proposed method achieves better performance than the existing baseline methods.",0.3333333333333333,0.2857142857142857,0.30769230769230765
969,SP:5ad585e3d6d5f9f620d0d73d958de52ed90255e0,"In supervised learning tasks, it is common in practice to apply a *whitening* transformation to remove correlations between input features. This can improve the conditioning of the underlying data manifold, enabling faster convergence. This paper shows  that for a large class of models --- models $f$ consisting of a fully-connected layer followed by an arbitrary parameterized function, $f(X) = g_\theta(WX)$ --- data whitening removes all information that is relevant for generalization. Furthermore, this has implications for the generalization ability of second-order methods such as Newton's method due to a well-known equivalence between Newton's method and steepest-descent applied to whitened data. The effects suggested by the presented theory are verified empirically, and the are additionally observed in convolutional neural networks, suggesting that the phenomenon could apply more broadly to more complicated connectionist models as well.","The authors analyse the training dynamics of a machine learning model consisting in a linear unit, followed by any parametrized function. The authors in particular focus on the impact of whitening  the data beforehand or using second order methods. They show that the learned parameters of the model only depend on the training data through its Gram matrix. Since whitening trivializes the Gram matrix, the authors argue that whitening destroys important information.",0.12142857142857143,0.2361111111111111,0.16037735849056603
970,SP:5af5a69509d6176336791a840c17703dee176a1d,"The paper proposes a novel method to set the optimal ensemble size in gradient boosting. In particular, the authors propose an adaptive strategy that sets distinct ensemble sizes for different regions of the input space. For that, they propose dividing the input space in coherent regions (whose instances are similar both in terms of features and labels) and estimating the optimal ensemble size within those regions. For clustering data, they propose using a decision tree induced from the entire training set, and the leaves of the trees are the clusters that comprise the data partition. They show the results of both a biased and a less-biased estimator for finding out the optimal ensemble size per region, and they compare their findings with the traditional strategy of simply pruning the ensembles based on a single optimal number of learners estimated from a cross-validation procedure. Results in 6 public datasets show that in at least 4 of those datasets the method seems to provide better results.","This paper proposes to tune the number of models in a boosting ensemble in an instance-wise fashion. The idea is to first cluster the samples using a decision tree and then to tune the size of the ensemble independently for each cluster, instead of doing it globally for all instances. An efficient two-level cross-validation procedure is designed to tune both the number of terms in each cluster and the number of clusters. Experiments are conducted on 6 large-scale problems that show that local pruning brings some improvement with respect to the more standard global pruning technique. ",0.1746987951807229,0.29,0.2180451127819549
971,SP:5b09ea8501379dc26d78719656eb7b1519ebf57c,"This paper introduces the concept of Sampling Importance Resampling (SIR) and give a simple method to adjust the off-policyness in the TD update rule of (general) value function learning, as an alternative of importance sampling. The authors argue that this resampling technique has several advantages over IS, especially on the stability with respect to step-size if we are doing optimization based the reweighted/resampled samples. In experiment section they show the sensitivity to learning rate of IR TD learning is closer to the on-policy TD learning, comparing with using IS or WIS.","In this work, the authors studied the technique of importance re-sampling (IR) for off-policy evaluation in RL, which tends to have low-biased (and it's unbiased in the bias-correction version) and low-variance. Different than existing methods such as importance sampling (IS) and weighted importance sampling (WIS) which correct the distribution over policy/transitions by an importance sampling ratio, in IR one stores the offline data in a buffer and re-samples the experience data (in form of state, action, & next-state) for on-policy RL updates. This approach avoids using importance sampling ratios directly, which potentially alleviate the variance issue in TD estimates. The authors further analyze the bias and consistency of IR, discuss about the variance of IR, and demonstrate the effectiveness of IR by comparing it with IS/WIS on several benchmark domains.",0.24210526315789474,0.16428571428571428,0.19574468085106383
972,SP:5b11047d4041923ad950fa4c060c1bdecde6543a,This paper presents a self-supervised learning method GASSL for graph representation learning. The authors have designed 2 key points:  a) Utilizing BYOL framework to learn graph representation; b) Using adversarial training to automatically generate challenging views for self-supervised learning. The idea seems to be simple but effective. Sufficient experimental analyses are conducted.,"The paper investigates the unsupervised representation of graph data and proposes an adversarial self-supervised learning (GASSL) framework. The paper adopts the self-supervised framework in reference [12] for graph embedding representation, and apply adversarial learning to improve the robustness of the model, following the framework in [26]. A number of experimental results are given to validate the performance of the proposed model. The contribution of the paper is incremental.",0.25925925925925924,0.2,0.22580645161290322
973,SP:5b434057f9759ec9458e792789d0c9f1f8e4cba9,"The authors propose a new autoencoding algorithm for the unsupervised generative modeling which they call Sliced Wasserstein Autoencoders (SWAE). SWAE minimizes a reconstruction cost (measured with respect to the non-negative cost function c(x,x') defined for pairs of input images x, x'), regularized by a penalty measuring a discrepancy between the prior distribution over the latent space qz and the push-forward pz of the unknown data distribution through the deterministic encoder. The authors present an extensive theoretical argument supporting the choice of this objective and a number of empirical results performed on MNIST, LSUN bedrooms, and Celeba. ","This paper presents an extension of Wasserstein autoencoder (WAE) by modifying the regularization term in learning objective of variational autoencoder. This term measures the divergence between the distribution of the encoded training samples and the samplable prior distribution. The modification is based on the sliced-Wasserstein distance where the distance between two distributions is measured through slicing or projecting the high-dimensional distributions into one-dimensional marginal distributions. As a result, a closed-form solution to the integral in Eq. (9) is obtained via a numerical method. The adversarial learning in WAE, designed to fulfill the calculation of high-dimensional distance, can be avoided. In general, this is an interesting work by introducing new idea of sliced-Wasserstein distance.",0.17,0.14285714285714285,0.15525114155251143
974,SP:5b4768c8d71e9b044c50d77fb68d545370ca8329,"The paper introduces a new function $L(x)$ so that, when optimised under certain objectives defined over continuous observation $x$ and discrete latent $z$, learns the correct clustering probability $p(z|x)$. The loss functions considered are the Jensen-Fisher divergence and muture information. The authors introduces modifications to the principled objectives in practice and demonstrate performance on toy and real image datasets.","This work introduces a parameterization called Neural Bayes that facilitates learning representations from unlabeled data by categorizing them, where each data point x is mapped to a latent discrete variable z such that the distribution p(x) is segmented into a finite number of conditional distributions. Imposing different constraints on the latent discrete space will result in learning representations manifesting various properties. Two use cases of the proposed parameterization are studied: disjoint manifold separation and mutual information maximization.",0.20634920634920634,0.16666666666666666,0.18439716312056736
975,SP:5b547cc5f22e5d9316d8ab945a48e5b1074f72a1,"This paper studies a fundamental question regarding the adversarial Bayes classifier, i.e., does the optimal Bayes classifier exists and does it have any robustness guarantee. The contribution of this paper is theoretical: it proposes the concept of ‘pseudo-certifiable robustness’ and proves that the optimal Bayes classifier exists and satisfies the proposed ‘pseudo-certified robustness’. The proofs are mostly about real analysis and measure theory. ","This paper establishes the existence of a binary classifier which minimizes the expected adversarial loss under a data and label distribution, which they call the adversarial Bayes classifier. The authors do so by constructing a sequence of classifiers which converges to the infimum risk, and then demonstrate that the risk is sequentially lower semi-continuous, which establishes the existence of a minimum. They also extend this result to some non-additive perturbations.",0.22727272727272727,0.20833333333333334,0.21739130434782608
976,SP:5b6213ef045829fea8f1ba44e1a6718aaba2dbe3,"The authors proposed an approach to visualize the regional visual patterns learned by the DNN models during the training. The method shows that (1) adversarial attacks mainly affect the regional features in depth layers. The authors also categorize the adversarial attack impact in four types; and (2) in the distillation scenario, the student learns to extract less reliable knowledge points than the teacher. It is an interesting approach with promising results, quantitative and analysis. ","Paper proposes a visualization method for probing into the intermediate visual patterns learned by the DNN layers. The idea is to learn a linear transformation to project the original DNN features into a lower dimensional space for mimicing the classification based on the original features. In other words, the projected low-dim features infer the similarity among samples. Experiments are conducted multiple datasets and DNN architectures.",0.21621621621621623,0.24242424242424243,0.22857142857142856
977,SP:5b88514d3eba834efba72c605496c4c057c30387,"In this paper, the authors propose a new “grandmother cell”-like memory mechanism for improving image generation performance in GANs. In short, this method clusters and stores activation vectors observed during training. Then at image generation time, activation vectors are augmented with the sum of the stored memories at the closest cluster. This seems to improve GAN performance for few-shot image generation tasks. The authors also visualize the learned memory clusters, which seems to reveal some semantic clustering. ","Paper proposes a novel prototype-based memory modulation layer (MoCA) to improve the generator network of a GAN. The target problem is few-shot image generation. Memory is arranged hierarchically into prototype semantic cells and prototype component cells. This design is loosely inspired by the recent discovery of ""grandmother cells"" in V1.  Experimental results show that in terms of FID score, using FastGAN base architecture, MoCA can bring 5.8% improvement on Animal Face Dog, 13.8% improvement on Obama, 21.7% improvement on ImageNet-100 and 12.4% improvement on COCO-300 dataset when using FastGAN as the baseline models. With StyleGAN2 base architecture, there was an 5.1% improvement on Animal Face Dog dataset, 8.1% improvement on Obama dataset, 14.1% improvement on ImageNet-100 dataset and 17.3% improvement on COCO-300 dataset.",0.1518987341772152,0.08759124087591241,0.1111111111111111
978,SP:5bd15d735380afa17fd1dde6df22de951699a755,"This paper studied the expressive power of models composed of invertible flows and injective embeddings. First, this paper defined the concept of the Embedding Gap as the measure by which a model can approximate an embedding with low-dimensional support. Then, this paper defined the concept of MEP as the ability to approximate the target embedding arbitrarily small in terms of the Embedding Gap. This paper showed that when invertible layers have the MEP properties and the first layer is a distributively universal approximator (and some additional assumptions), the model is a universal approximator in terms of 2-Wasserstein distance (Theorem 1). Finally, this paper gave a method to compute the inverse transformation of an injective layer with a special form of linear transformation and ReLU nonlinearity. (Theorem 2).","In this paper, the authors studies flow models by a newly developed approximation measure when the data is on a low-dimensional manifold. Specifically, they consider an architecture that alternates a bijective function with the same input and output dimensions, and a function with a larger dimension at the output. There are several successful methods for this, but the globally invertible flow is not well understood. To address this problem, this work shows the approximate properties of the flow architecture. Specifically, they show the approximation accuracy of the models with distributions that have a certain manifold as their support. In doing so, they proposed a new notion of embedding gap to evaluate the manifold embedding. This may allow them to represent cases that cannot be represented by existing topologies. In addition, they defined a value of MEP, which allows us to evaluate the approximation capability under different topologies. This establishes the validity of evaluating the performance for each layer.",0.20155038759689922,0.16352201257861634,0.18055555555555552
979,SP:5bdbbd811a7a85540ccf3d99348aa96702191849,This paper proposes a scaling law for transfer learning that takes into account  the size of both the pretraining and finetuning datasets. They showed the parameters of the scaling law can be  estimated and this can be used to approximate the performance of the model given the amount of pretraining data. The authors experiments are focused on the scenario where the pretranining dataset is synthetically generated.,"This paper postulates a scaling law for pre-training and transfer learning via fine-tuning. They empirically postulate a law and also theoretically show that in a simpler setting with assumptions, a similar law should hold. The paper is written and experiments are done in a synthetic to real transfer setting. Experiments are done by pre-training on a synthetic dataset made using BlenderProc and transferring to real data ranging classification, object detection and semantic segmentation. They find that parameters of their scaling law can be estimated to find very good fits to empirical error across all the different transfer tasks.",0.3181818181818182,0.2079207920792079,0.25149700598802394
980,SP:5be59a79316e4eeac5d6da1804b61a484a9ac2aa,"In this paper, the author proposes Meta_abd which is a hybrid model that learns a deep recognition model and FOL rules the same time. The goal of this work is to learn FOL rules from raw data such as digits presented in image patches in an end-to-end fashion. The model is evaluated with 3 induction benchmarks associated to the MINST digit dataset.","In this paper, the authors have presented a framework that combines meta-interpretive learning and the abductive learning of neural networks. The high-level idea is to formulate a unified probabilistic interpretation of the entire algorithm so that both the inductive logic programming module and the neural network modules can be trained jointly from data. The authors have demonstrated the application of the proposed algorithm to learning arithmetic operations and sorting operations by looking at input-output mnist digits.",0.23076923076923078,0.189873417721519,0.20833333333333334
981,SP:5bf8fd6f74c8aa558dd854cdd70d1afa31a2989b,"This paper works on methods for compressed embedding layers for low memory inference, where the compressed embedding are learned together with the task-specific models in a differentiable end-to-end fashion. The methods in the paper build on a slight variant of the K-way D-dimensional discrete code representation proposed by Chen et al.. Specifically, the two methods in the paper are motivated by the idea that the K-way D-dimensional code can be viewed as a form of product quantization. The first proposed method (DPQ-SX) uses softmax-based approximation to allow for differentiable learning, while the second proposed methods uses clustering centroid-based approximation. Empirically, the authors demonstrate that the proposed methods for generating compressed embedding can achieve matching inference accuracy with the corresponding uncompressed full embedding across 3 NLP tasks; these proposed approach can outperform the pre-trained word embedding and the K-way D-dimensional code baselines in language modeling tasks.","This paper considers the problem of having compact yet expressive KD code for NLP tasks. The authors claim that the proposed differentiable product quantization framework has better compression but similar performance compared to existing KD codes.The authors present two instances of the DPQ framework: DPQ-SX using softmax to make it differentiable, and DPQ-VQ using centroid based approximation. While DPQ-SX performs better in terms of performance and compression, DPQ-VQ has the advantage in scalability.",0.13924050632911392,0.28205128205128205,0.1864406779661017
982,SP:5c1ba72542bd2c3ebac7e96f88fb48599d725b6b,This paper proposes an AlphaGo Zero style algorithm for training policies for solving combinatorial optimization problems. The main idea is to generate training data with MCTS for both a policy network and a value network via self-play. Different graph neural networks (GNNs) are considered as learning models to compare their performances. Empirical evaluations on 5 NP-hard class of problems are provided to demonstrate better performance than an existing RL method S2V-DQN. Comparisons are also provided with CPlex and other approximation algorithms for specific classes of problems. ,"There has been a sequence of recent works on learning heuristics for combinatorial optimization problems on graphs by treating them as Markov decision processes, and learning by reinforcement a good policy. Since the dynamics of these problems can be readily simulated, in this paper, the authors propose to use AlphaZero, a MCTS variant, with a GNN architecture to learn and predict good solutions. They compare against the approach of Khalil et al. (2017), as well as hand-made heuristics, on three benchmark problems (Min Vertex Cover, Max Cut, Max Clique). There are results on Max Independent Set and Min Feedback Vertex Set in the appendix as well.",0.15730337078651685,0.1308411214953271,0.14285714285714285
983,SP:5c62d26db077ad23a6556481905a52e86f8ef93c,"This paper focuses on the problem of training a neural model to understand source code. The authors argue that both graph information (such as the parsed abstract syntax tree) and sequence information (such as the raw program tokens) are useful for understanding code, and describe a particular method of adding raw program tokens to a graph called SCS. They also describe a modification of a transformer (called a GN-Transformer) that uses this SCS graph representation, and present results on code summarization tasks."," In this work, authors propose a new direction in summarizing code snippets by combining their AST and lexical code features in the form of a graph called SCG (which is shown not to be optimal). Their model, GN-Transformer, further extracts information from SCG to summarize the code snippet. This model is a combination of transformers and graph network and is benchmarked on two datasets of Java and Python source code. The results show that the model marginally outperforms the selected benchmarks. ",0.1927710843373494,0.1951219512195122,0.19393939393939394
984,SP:5c679af56d9947de1b793665b4c4eb952a672f0a,"This paper proposed a modification to the classical transformer architecture and demonstrated significant performance gain on multiple benchmark tasks in both natural language processing and computer vision. Specifically, the authors propose to introduce a convolution-based attention map prediction module, so the dependencies of attention maps across different layers can be captured. With the extensive experiments, the proposed modification is quite effective on improving the model's performance.","This paper proposes a novel approach to improve self-attention through by bridging the attention maps from different layers via a chain of convolution-based prediction modules.  In particular, it proposes to augment the existing works on Transformer through supplementary prediction modules by CNN-based attention prediction layers.  The main contribution of this paper is the introduction of CNN-based attention prediction to enhance model predictions. Empirical studies are performed to show the superiority of the proposed model PA-Transformer over several SOTA approaches on NLP and image classification tasks. ",0.25,0.18888888888888888,0.21518987341772153
985,SP:5c6f72812c5b61731e649e7b37d31629dfd9a7ba,"The paper propose a few improvements to the sampling-based NAS using RL: 1) an uncertainty-aware critic to decide whether the sample needs to be trained; 2) a life-long knowledge pool to initialize the sample that needs training; and 3) an architecture experience buffer to reuse old samples for RL training. The experiments are done on ImageNet, facial recognition and transferability on object detection. The proposed methods are compared with related works. Finally the paper finishes with ablation studies on both the effectiveness and transferability of the proposed modules. ","This paper proposes a fast general framework (FNAS) for neural architecture search (NAS) problem to enhance the processing efficiency up to 10x times. Three interesting strategies (UAC, LKP, AEB) for reinforcement learning (RL) processing are introduced in the proposed FNAS and evaluated by extensive experiments to show their efficacy. In particular, the assumption that architecture knowledge is transferable has been verified by real observation.",0.14285714285714285,0.203125,0.16774193548387095
986,SP:5c782fa6fa0245b510c2aa33ea661b2f8cf09062,"This paper propose to study the Lipschitz constant of convolutional layers and to give an easy to compute and differentiable upper bound. The upper bound is composed of 4 different bounds, based on tensor unfolding of the Jacobian, and taking the min of these 4 values. This upper bound is then used to train networks with spectral norm regularization and compared with network trained with singular value clipping from `Sedghi et al. (2019)`. The proposed bound gives similar performances with much cheaper computational time.","This paper provides an method for computing an upper bound for the spectral norm of the linear transformation induced by a convolutional layer. An upper bound was first introduced as a heuristic by Miyato et al, but they did not prove any bounds. The authors use the exact computation of singular values of a convolutional layer in Sedghi, Gupta and Long to prove that the Miyato heuristic is indeed an upper bound. They further generalize Miyato's method to find 3 additional heuristics, all of which are proved to be upper bounds, and then show empirically that the minimum of these bounds gives a much tighter bound, often very close to the exact value. The bounds are significantly faster to compute than exact spectral norms, both in complexity and in practice.",0.25,0.16030534351145037,0.19534883720930232
987,SP:5c78aac08d907ff07205fe28bf9fa4385c58f40d,"This paper proposes a new method for training certifiably robust models that achieves better results than the previous SOTA results by IBP, with a moderate increase in training time. It uses a CROWN-based bound in the warm up phase of IBP, which serves as a better initialization for the later phase of IBP and lead to improvements in both robust and standard accuracy. The CROWN-based bound uses IBP to compute bounds for intermediate pre-activations and applies CROWN only to computing the bounds of the margins, which has a complexity between IBP and CROWN. The experimental results are verify detailed to demonstrate the improvement.","This work proposes CROWN-IBP - novel and efficient certified defense method against adversarial attacks, by combining linear relaxation methods which tend to have tighter bounds with the more efficient interval-based methods. With an attempt to augment the IBP method with its lower computation complexity with the tight CROWN bounds, to get the best of both worlds. One of the primary contributions here is that reduction of computation complexity by an order of \Ln while maintaining similar or better bounds on error. The authors show compelling results with varied sized networks on both MNIST and CIFAR dataset, providing significant improvements over past baselines.",0.16981132075471697,0.17475728155339806,0.1722488038277512
988,SP:5c8aaf82d1ec469859fd51d2aa77cb93f50aacde,"Authors propose to overcome the sparse reward problem using an exploration strategy that incentivizes the agent to visit different parts of the game screen. This is done by building Q-maps, a 3D tensor that measures the value of the agent's current state (defined as the position of the agent) and action in reaching other (x, y) locations in the map. Each 2D slice of the Q-map measures the value at different (x, y) locations for one action. Such 2D slices (i.e. channels) are stacked together to form the Q-map. Taking the max across the channels, thus, provides the Q-value for the optimal action. ",The main idea in the paper is to use on-screen locations as goals for an RL agent. Using a de-convolutional network to parameterize the Q-function allows all goals to be updated at once and correlations between nearby or similar goal locations could be modelled. The paper explores how this type of goal space can be used for better exploration showing modest improvement in scores on Super Mario.,0.11009174311926606,0.17142857142857143,0.1340782122905028
989,SP:5ca4c62eae1c6a5a870524715c3be44c40383f98,"The paper presents an algorithm to match two distributions with latent variables, named expected information maximization (EIM). Specifically, EIM is based on the I-Projection, which basically is equivalent to minimizing the reverse KL divergence (i.e. min KL[p_model || p_data]); to handle latent variables, an upper-bound is derived, which is the corresponding reverse KL divergence in the joint space. To minimize that joint reverse KL, a specific procedure is developed, leading to the presented EIM. EIM variants for different applications are discussed. Fancy robot-related experiments are used to evaluate the presented algorithm.","This paper propose EIM an analog to EM but to perform the I-projection (i.e. reverse-KL) instead of the usual M-projection for EM. The motivation is that the reverse-KL is mode-seeking in contrast to the forward-KL which is mode-covering. The authors argue that in the case that the model is mis-specified, I-projection is sometimes desired as to avoid putting mass on very unlikely regions of the space under the target p.",0.21649484536082475,0.2625,0.23728813559322035
990,SP:5cc9822eed3b9ba0f55f3c7f7d0e546f2ce22434,"This paper extends the definition of adversarial examples to the ones that are “far” from the training data, and provides two conditions that are sufficient to guarantee the non-existence of adversarial examples. The core idea of the paper is using the epistemic uncertainty, that is the mutual information measuring the reduction of the uncertainty given an observation of the data, to detect such faraway data. The authors provided simulation studies to support their arguments.","The paper studies the adversarial robustness of Bayesian classifiers. The authors state two conditions that they show are provably sufficient for ""idealised models"" on ""idealised datasets"" to not have adversarial examples. (In the context of this paper, adversarial examples can either be nearby points that are classified differently with high confidence or points that are ""far"" from training data and classified with high confidence.) They complement their results with experiments.",0.24,0.2571428571428571,0.2482758620689655
991,SP:5cf0b8f16bda52b90c78f312effd934f828e3bab,This paper proposed a simple linear programming model for learning logical rules for KG completion. The model selects candidate rules from KG with explicit constraints and then solves a linear programming problem. The authors conduct experiments on several public datasets and the model has better efficiency than baseline models. ,"The paper presents a method to obtain weights for a knowledge graph scoring model for link prediction. There are numerous good algorithms for mining rules from knowledge graphs (e.g. AnyBURL and AMIE). Less research has focused on the problem of creating scoring functions based on an (implicit) list of rules. This is what the present paper proposes.   The core idea is to formulate a linear program whose solution corresponds to a scoring method. Instead of incorporating all rules (there are typically many!) into the LP formulation, the authors propose a column generation approach.   ",0.24489795918367346,0.1276595744680851,0.1678321678321678
992,SP:5d0044bca3d6e3e90f407c23b2ef347b2f11d3c2,"This paper provides a meta learning framework that shows how to learn new tasks in an interactive setup.  Each task is learned through a reinforcement learning setup, and then the task is being updated by observing new instructions. They evaluate the proposed method in a simulated setup, in which an agent is moving in a partially-observable environment. They show that the proposed interactive setup achieves better results than when the agent all the instructions are fully observable at the beginning. ","This paper studies how to teach agents to complete tasks via natural language instructions in an iterative way, e.g., correct the behavior of agents. This is a very natural way to learn as humans. The basic idea is to learn a model that takes correction and history as inputs and output what action to take. This paper formulates this in meta-learning setting in which each task is drawn from a pre-designed task distribution and then the models are able to adapt to new tasks very fast. The proposed method is evaluated in a virtual environment where the task is to pick up a particular object in a room and bring it to a particular goal location in a different room. There are two baselines: 1) instruction only (missing information), 2) full information (not iterative), the proposed method outperforms 1) with higher task completion rate and 2) with fewer number of corrections.",0.30864197530864196,0.16233766233766234,0.2127659574468085
993,SP:5d2c22e82721397371999020d145c432fd6e7a42,"This paper attempts to address the semi-supervised learning topic by proposing a method based on an aggregated loss considering both cross-entry and Davies-Bouldin Index. Cross-entropy is used to ensure the maximum margin between classes and Davies-Bouldin Index is applied to the labeled data and to the whole dataset, respectively, to ensure a high quality of clustering. Evaluations in four small and simple datasets are reported to demonstrate the effectiveness of the proposed method.","The authors propose a novel loss function for semi-supervised learning. Arguing that SOTA semi-supervised learning methods neglect spatial information (latent clustering structure) in the data, the authors propose a loss function which combines clustering objectives with classification objectives. The proposed loss function combines the cross-entropy loss, the within-cluster scatter as known from k-means, the distance between centroids and the margin between classes. The proposed loss is notably non-continuous since it makes use of the maximum function. The authors employ  ADAM with a learning rate of 0.001 with exponential decay to optimize the novel loss function. Experiments on MNIST and three comparably small datasets show that the proposed method is able to achieve high accuracy with only few labeled data points.",0.28205128205128205,0.1732283464566929,0.21463414634146338
994,SP:5d41c9d8df0e7ce2dc9328a938e0f4c9cf2b3bd6,"This paper proposes a new method of noise removal using convolutional VAE.  An observed image with noise is input to VAE, and after the expression $z$ in the latent space, the noise removed image is finally output.  After that, it is possible to generate a pseudo noisy observation image according to the noise model.  The noise model part is flexibly designed using the Gaussian mixture model.  In the training, VAE and noise model can be learned at the same time. Since VAE is a generative model, and a clean denoising image can be obtained by averaging a large number of candidates of clean images, $s$, sampled from the periphery of the latent space representation $z$.","This paper devises a novel unsupervised denoising paradigm, DIVNOISING, that allows us, for the first time, to generate diverse and plausible denoising solutions, sampled from a learned posterior. This approach only requires noisy images and a suitable description of the imaging noise distribution, providing a new perspective for the image denoising field. It has demonstrated that the quality of denoised images is highly competitive, typically outperforming the unsupervised state-of-the-art, and at times even improving on supervised results. This paper is well-written and good-organized. However, the reviewer has the following concerns.",0.17391304347826086,0.21052631578947367,0.1904761904761905
995,SP:5d875376d1c68281008c7a22abcf09b968afb841,"This paper proposes *Unsupervised Robust Representation Learning* (URRL), a framework that combines several data augmentation schemes and a similarity-based loss. The goal is to improve the robustness of visual representations to image perturbations. A further goal is to maintain the robustness properties of pre-trained representations after fine-tuning the network to downstream tasks.","This paper uses a different data augmentation (AugMix) scheme to improve self-supervised representation learning. It improves accuracy and (corruption and adversarial) robustness by a sufficiently interesting amount. The paper's presentation is clear, but the paper could be more thorough. Since the technique is simple and general, it could easily be broadly applicable to the burgeoning area of self-supervised learning.",0.2545454545454545,0.22580645161290322,0.2393162393162393
996,SP:5d9783cb0a70b17938f30263aac12ab010d63844,"The paper deals with action recognition in videos, i.e. detecting to which class a given sequence of frames belongs to. However, the paper proposes to explore whether an image classifier (instead of a video or spatiotemporal-based classifier) would already be enough to accomplish this task. In order to do so, the authors organize the frames from a video into a single image by organizing them into a grid, then proceed to learn them using Swin Transformers (Swin-B) image classification models.  The authors report surprising results which are indeed on-par or higher than the SotA in Kinetics400, MiT, Jester and Diving48 datasets.","The paper proposes to perform action recognition by first rearranging the frames from a video into a 3x3 or 4x4 grid to form a ""super image"", and then giving the super image to a standard image classifier to perform action recognition. Given that this super image will be a larger image, the paper leverages the more memory efficient Swin Transformer [1] as an image classifier to perform action recognition. Experiments on Kinetics400, Moments In Time, Something-Something V2 (SSV2), Jester and Diving48 show that the proposed method is on par or exceeds SOTA in terms of accuracy. On Kinetics400, the method not only is SOTA in terms of accuracy, but also is the most FLOPs-efficient method given a specific accuracy. The strong performance suggests that a deep network's ability to model spatial relationships could also be applied to model temporal relationships across frames in a video, which is an orthogonal direction to having explicit components in the network modeling temporal relationships. Furthermore, being able to connect action recognition with image classification enables existing image classification techniques to be applied to action recognition, which could potentially accelerate the field.  [1]: Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin Transformer: Hierarchical Vision Transformer using Shifted Windows. arXiv.org, March 2021.",0.23809523809523808,0.11363636363636363,0.15384615384615383
997,SP:5dadee976ef100a6bd77cd4e3a0f02b8376556af,"This paper analyzes adaptive algorithms such as adagrad and AMSGrad in a finite-sum optimization problem. The proofs appear to treat this setting through online convex optimization and online-to-batch conversion. It is shown that both AdaGrad and AMSGrad improve when the individual losses are all minimized at the same point. Further, line search techniques are analyzed in conjunction with these algorithms, and empirical results show that in practice the line searches speed up convergence.","This paper studies adaptive gradient methods under the over-parametrized settings, where the authors study the converge in the interpolation setting. In this setting, the optimal objective is 0. The authors show that the convergence rate is O(1/T). In addition, when the interpolation is approximately satisfied, the authors show the convergence to a neighborhood of the solution. The authors also provide theoretical justifications for popular line search methods.",0.19736842105263158,0.21428571428571427,0.20547945205479454
998,SP:5db89a98e14e6cb553431c750c85944f0b766b6b,"This paper tackles the problem of enabling robots to learn long-horizon, sparse-reward tasks. The proposed approach, the Curious Sample Planner (CSP), builds on insights in task and motion planning (TAMP), which is a standard approach for tackling these kinds of tasks. TAMP constructs a plan in the space of macro-actions (e.g., move object 1 to location (x,y)), and uses a motion planner to execute each macro-action. However, TAMP typically requires being able to describe macro-action effects and preconditions with logical predicates, which can be impossible in real-world environments, due to complex dynamics and interactions. CSP overcomes this limitation by planning in the space of macro-actions in a way that is biased toward novelty.","The paper introduces Curious Sample Planner (CSP) a long-horizon motion planning method that combines task and motion planning with deep reinforcement learning in order to solve simulated robotic tasks with sparse rewards. The CSP algorithm considers two different hierarchies of actions: primitive actions, which control the rotation of several joints in a robotic arm, and macro-actions corresponding to complex behaviours  such as moving from one position to another or linking two objects together. Macro-actions are selected using the actor-critic architecture PPO and then turned into primitive actions using geometric motion planning and inverse kinematics. Specifically, RRT-Connect is used for motion planning with the recursive Newton-Euler algorithm for inverse kinematics on a perfect model of the environment to determine the specific sequence of primitive actions necessary to execute the macro-action. As CSP is interacting with the environment, it also builds a tree of states in the environment connected by the macro-actions leading to each of them. Each vertex of the tree is assigned a curiosity score, which is used as an exploration bonus for PPO and to determine the probability with which each vertex is sampled from the tree for future exploration. The whole process is repeated until a feasible path from the initial state to the goal state is found. The paper provides empirical evaluations in four different tasks where it compares the performance of CSP with three different curiosity measures to the performance of PPO and A2C. The results show that CSP accomplishes each task while using significantly less samples. Moreover, a second set of experiments is presented that show the potential for transfer learning across tasks using CSP. ",0.2540983606557377,0.11151079136690648,0.155
999,SP:5e0e7c093642425da2d581fd0fd6f45fd2fa5131,"This paper proposes a measure (“effective path”) of which units and weights were most important for classification of a particular input or input class. Using the effective path, the authors analyze the overlap between paths across classes for CNNs and between adversarially modified and unmodified images. Finally, the paper proposes an adversarial defense method based on effective path which detects adversarially manipulated images with high accuracy and generality to a variety of settings. ","This paper proposes a method for the detection of adversarial examples based on identification of critical paths (called ""effective paths"") in DNN classifiers. Borrowing from the analysis of execution paths of control-flow programs, the authors use back-propagation from the neuron associated from the final class decision to identify a minimal subset of input synapses accounting for more than a threshold proportion (""theta"") of the total input weight. The identification process is then recursively applied at the preceding layer for those neurons associated with the selected minimal subset of synapses, forming a tree of synapses (the ""effective path""). The authors then propose to compare the effective paths (actually, unions of paths) of different examples using simple structural dissimilarity measures, which they extend to allow comparison to a typical (aggregated) path for multiple examples drawn from a common class.",0.273972602739726,0.14388489208633093,0.18867924528301888
1000,SP:5e1fddf52c13f31d98224d4731059d088170fbc1,"The paper revisits the federated learning framework from McMahan in the context of differential privacy.  The general concern with the vanilla federated learning framework is that it is susceptible to differencing attacks. To that end, the paper proposes to make the each of the interaction in the server-side component of the gradient descent to be differentially private w.r.t. the client contributions. This is simply done by adding noise (appropriately scaled) to the gradient updates.","The main claim the authors make is that providing privacy in learning should go beyond just privacy for individual records to providing privacy for data contributors which could be an entire hospital. Adding privacy by design to the machine learning pipe-line is an important topic. Unfortunately, the presentation of this paper makes it hard to follow. ",0.14285714285714285,0.19298245614035087,0.16417910447761194
1001,SP:5e3798130b00275f58f296666d614d56147ec57a,This paper offers an interesting viewpoint of adversarial robustness by comparing neural networks with skip connections such as ResNet with their Neural ODE counterparts. The authors analyze the different behaviors of the networks through their Lipschitz constants. They also try to support their claims that Neural ODEs are more robust due to their continuity (small step sizes) through experiments.  ,"This paper uses theoretical grounding, starting with Lipshitz continuity-based assumptions on residual connections, to show why such architectures are more susceptible to adversarial inputs. In the process, the authors draw a parallel between these residual connections and neural ODEs, showing how the latter can circumvent the main reason that leads to adversarial susceptibility for the former. Finally, via empirical evaluations, they show how neural ODEs have ""natural"" robustness to adversarial examples: they have a non-trivial performance on adversarial inputs, despite not being explicitly trained for robustness.",0.22033898305084745,0.14772727272727273,0.17687074829931973
1002,SP:5e57ecc0e0bf2e70846f7d2c0e9b1b625f5e1f0e,"The paper proposed a self-supervised learning framework for learning node feature by exploring the correlation between the node feature and the graph structure, which leverages the graph information based on neighborhood prediction. To be specific, the proposed GIANT approach is combined with the pre-trained language model BERT, and incorporated the XMC formalism based on XR-Transformer. Partial theoretical analysis is also presented. Experiments conducted on three large benchmark datasets show promissing improvements.",This paper develops a self-supervised learning framework to extract node features with the aid of graph. Connections between neighborhood prediction and the XMC problem are also established. Experiments on large-scale data show the superiority of the proposed method.,0.25675675675675674,0.475,0.33333333333333337
1003,SP:5eb3d197fb5005f876dac170b9a40717d965f66c,"This paper proposes smoothing the classifier in the distributional robust learning framework by adding random noise to the input. The smoothed distributional robust framework is used to gain robustness against adversarial perturbations in settings where the classifier is originally non-smooth and then smoothed via the additive noise. While the proposed idea can be potentially useful for training adversarially-robust classifiers over non-smooth function spaces, the paper's theoretical formulation seems to reduce to original non-smoothed distributional robust optimization. Theorem 2 also seems incorrect and its proof suffers from several mistakes.  ","This paper studies the problem of certified robustness in adversarial learning. In a nutshell, they apply the randomized smoothing technique to the distributional robustness certificate proposed by Sinha et al. (2018), thereby relaxing the smoothness assumption required therein so that the ReLU network can be applied. Based on this new formulation, they derive the upper bound on the worst-case population loss and develop an algorithm with convergence guarantees. The results on tested on MNIST, CIFAR-10 and Tiny ImageNet.",0.16129032258064516,0.1875,0.17341040462427748
1004,SP:5ee804c8b2609b7a2adea1b39361b0b55b49b7bd,"This work proposes the notion of ""interventional consistency"" as a beneficial property learned representations should have and introduces a regularization term to enforce it in autoencoders. Moreover, the authors introduce an ""explicit latent causal block"" that allows learning a structural causal model (SCM) over the latent factors. The experimental section argues that both the regularization and the ""causal layer"" improve interventional consistency. ",The paper proposes to use interventional consistency to regularise representation learning in VAEs. The idea is well-motivated by the ICM principle and theoretically justified. The paper suggests to use interventional consistency for both training and evaluation of the representation learnt by VAEs. Results show that the proposed idea can give more modular and interpretable representation.,0.1774193548387097,0.19642857142857142,0.1864406779661017
1005,SP:5eed765bdae8974a4dc216b49631d9709767e29e,"In this paper, the author maps the problem of time series PDE into a naive reinforcement learning problem. Under the MDP assumption, the author sets the initial state of the particles as the current state, the flux at all spaces as the possible actions, and map the state-action pair deterministically to the next state of the particle diffusion. The reward is defined as the two norms between the prediction and the Burger’s equation. The naiveness comes from the fact that the typical reinforcement learning problem, the agent needs to decide how to choose an action. In this paper, it is formulated as an intrinsic proper that follows Burger’s equation instead. ","This paper proposes to use reinforcement learning for constructing discretziation stencils of numerical schemes. More specifically, the method focuses on the widely used WENO schemes, which are an established class of finite difference schemes. Within this context, the method aims for training models to infer the weighting for a specific stencil with eight flux terms.",0.08849557522123894,0.18181818181818182,0.11904761904761907
1006,SP:5f026e00085a3f771abf068bd884e27a6f9d9e44,"The paper proposes an imitation learning algorithm that combines behavioral cloning with a regularizer that encourages the agent to visit states similar to the demonstrated states. The key idea is to use ensemble disagreement to approximate uncertainty, and use RL to train the imitation agent to visit states in which an ensemble of cloned imitation policies is least uncertain about which action the expert would take. Experiments on image-based Atari games show that the proposed method significantly outperforms BC and GAIL baselines in three games, and performs comparably or slightly better than the baselines in the remaining three games.","The paper aims to address the covariate shift issue of behavior cloning (BC). The main idea of the paper is to learn a policy by minimizing a BC loss and an uncertainty loss. This uncertainty loss is defined as a variance of a policy posterior given by demonstration. To approximate this posterior, the paper uses an ensemble approach, where an ensemble of policies is learned from demonstrations. This approach leads to a method called disagreement-regularized imitation learning (DRIL). The paper proofs for a tabular setting that DRIL has a linear regret bound in terms of the horizon, which is better than that of BC which has a quadratic regret bound. Empirical evaluation shows that DRIL outperforms BC in both discrete and continuous control tasks, and it outperforms GAIL in discrete control tasks. ",0.24,0.18045112781954886,0.20600858369098712
1007,SP:5f27d75465dd7f7f154bf2ffbd4d06474b1a834b," The authors propose an active clustering algorithm where the oracle annotate examples in must-link, cannot-link fashion. Assuming that the cost of labeling pairwise relationships of unlabeled data is less costly than annotating examples.  They propose to represent the pairwise labeling process as an n-set partition overall the unlabeled set of size n. They study the distribution of the number of queries of the proposed with the objective to bound the average number of queries needed by an AC algorithm to recover the n-set partition, they suggest a first setting where the partition is assumed to be drawn from a uniform random distribution of all possible partitions over the n-set, they show that if the process of labeling forms a chordal graph for all queries in the AC algorithm, then the average complexity in terms of number of queries is minimal and comparable for all  AC algorithms with chordal graph constraint, the argument made to suggest that pairwise labeling is always better than sample labeling in this setting is unclear. For the second setting, they assume that the distribution of random partitions generates graphs with a fixed number of blocks which relates to the number of classes and class distribution of the unlabeled set, they show that the clique AC algorithm exhibits minimal linear complexity convergence in terms of number of query in this case. Lastly,  they propose a method for correcting errors in the process of labeling pairwise examples, they show that we can detect k labeling errors under strong connectivity conditions depending on k on the partition graph. ","The authors address the problem of pairwise clustering, where users are given pairs of instances and need to decide whether they belong to the same class or not. Given the human feedback, a clustering is computed. The authors show the importance of chordal algorithms for complexity and analyze random and clique algorithms. ",0.09090909090909091,0.46153846153846156,0.1518987341772152
1008,SP:5f2bba1f11065ba65a0b3cfa79db380aa5bba2d8,"This paper was very clearly written and easy to follow. Kudos to the authors. In particular, the experimental evaluation section was exceptionally clear. Thanks to the authors for making the paper so easy to review. The “Main Contributions” section was excellent as well as it allows the reader to quickly understand what the paper is claiming.","the paper introduces a novel protocol for training neural networks that aims at leveraging the empirical benefits of adversarial training while allowing to certify the robustness of the network using the convex relation approach introduced by Wong & Kolter. The key ingredient is a novel algorithm for layer-wise adversarial (re-)training via convex relaxations. On CIFAR-10, the proposed protocol yields new state-of-the-art performance for certifying robustness against L_inf perturbations less than 2/255, and comparable performance over existing methods for perturbations less than 8/255 (where the comparison excludes randomized-smoothing based approaches as proposed by Cohen et al.).",0.16071428571428573,0.08653846153846154,0.1125
1009,SP:5f32c357c2f143c81d31176fe38fae9826e138b3,"This paper studies the two learning rates \alpha and \beta used in Model-Agnostic Meta-Learning (MAML) algorithm by [Finn et al., 2017]. MAML is known to be difficult to train, and part of the reason why is the need to tune the two learning rates. Under simplifications, the paper derives some necessary conditions on \alpha and \beta for the MAML iterates to converge to local minima, and then verifies the theory by experiments on synthetic and real-world data.","The authors study a method to help tuning the two learning rates used in the MAML training algorithm. First, they derive a necessary condition for the convergence of the gradient descent in the single task setting. The condition relies on the eigenvalues of the Hessian of the task loss. This condition is reminiscent of convergence criteria for gradient descent on quadratic objectives, and the authors make the interesting observation that the criteria for the exterior learning rate beta depends on the interior learning rate alpha. ",0.225,0.21176470588235294,0.21818181818181817
1010,SP:5f5615d414a232aeaec93033053471ce6bb09fc4,"This paper aims to explain dropout from the lens of game theoretic interactions. Let x denote the input of a deep neural net (DNN), intuitively, the interaction between two variables x_i and x_j quantifies how much the presence/absence of the j-th variable affects the contribution of the i-th variable to the output of the DNN. With the above definition in place, the authors show theoretically and empirically that dropout reduces the interactions between input variables of DNNs. As this type of interactions turn out to be strongly correlated with overfitting, the authors suggest that dropout alleviates overfitting by reducing interactions between input variables (or activation units) of DNNs. Based on this understanding of dropout, an alternative regularization technique is proposed, which explicitly penalizes pairwise interactions between variables. ","This paper analyzes the effect of dropout on interaction between units in a neural network. The strength of the interaction is measured using a metric that is used in game theory to quantify interaction between players in a co-operative game. The paper shows that dropout reduces high-order interaction (as measured by this metric), and that reduction in interaction is correlated with better generalization. The paper introduces a new regularizer that explicitly minimizes the metric and claims that using this regularizer instead of dropout has some advantages.",0.18181818181818182,0.2727272727272727,0.21818181818181817
1011,SP:5f7434c2a4e815f70674cd3684bb31de7401a648,"Authors propose a new Dataset CLEVRER, a simulated video dataset involving interaction between objects. It is discussed, the existing state-of-the-art models for visual question answering, doesn’t capture the causal structure between the objects and their claim is supported by their experiments.  Authors also proposed a model which captures the dynamics of the objects involved in the video, through experiments they have shown their model performs better than the existing models. ","This paper studies the temporal and causal structures in videos. Specifically, the authors first introduce a new dataset called CLEVRER drawing motivation from CLEVR, a well-known visual reasoning dataset. They further evaluate a set of state-of-the-art methods on the newly introduced dataset to confirm their initial beliefs of the challenges posed by causal reasoning. Based on empirical clues, they also suggest neural-symbolic based framework for causal reasoning.",0.21621621621621623,0.2222222222222222,0.2191780821917808
1012,SP:5f747124fe1423eca55c0ca2af58083f91c82cfc,"The paper presents a methodology to obtain bounds on counterfactual probabilities from unknown SCMs using observational data. The authors consider a setting where the causal structure (DAG) of the data-generating model is known and all the endogenous variables are discrete and finite.    In this setting, the authors show that the set of all SCMs compatible with the known DAG, G, and observational data can be mapped to a special class of SCMs, which they call discrete SCMs. These discrete SCMs have the nice property that they are compatible with DAG G and the observational distribution and all exogenous variables are discrete and finite (with known maximum value). The authors show that there must exist a discrete SCM within this family which agrees with the original (unknown) SCM on all counterfactual probabilities. Using this as the main idea, the authors attempt to bound the counterfactual probabilities by maximising/minimising the counterfactual probabilities over all discrete SCMs in this family.    The paper makes no assumptions about the missing exogenous variables in the SCM model under question. This makes for a very powerful idea which can be used to bound counterfactual queries.","EDIT:  I thank the authors for their clarifications and corrections to my previous line of thought, and I am prepared to revise my score up to 5 as a result.  I take the point about polynomial vs linear programming, and I can see that Lemma 4 is a non-trivial result.  The authors, however, make no effort to point to Lemma 4 as being the primary source of the novelty in Theorem 1!  Overall, the content of the paper seems too rich for a conference with a page limit like this one, it might be better off submitted to a journal with much more explanation and more examples.  ----  This paper gives a Monte Carlo method for obtaining bounds from any DAG model with hidden variables.   The authors illustrate the algorithm on the front door model, as well as the instrumental variables model; they give several more examples in the supplementary material.    I think the paper could be improved by explaining more explicitly how the Bayesian algorithm for obtaining samples helps, when presumably one could solve the linear program (6).",0.14736842105263157,0.1564245810055866,0.15176151761517617
1013,SP:5f86ae910ede1e5182c54b64e626a522faf330e6,"The paper proposes a simple method (SALR) to encourage the SGD to converge to flatter minima for better generalization. The basic idea is that it increases the learning rate when the sharpness is high, vice versa, such that SGD can escape sharp regions quickly. The sharpness is measured by the difference between the maximum and minimum found by a local SGD with a few fixed steps.","This work proposes an algorithm that aims at finding a flat minimizer. The high-level strategy in the design of the proposed algorithm is increasing the learning rate when the iterate is in the region of a sharp minimizer. The authors claim that by increasing the learning rate, the iterate can get out of the undesired region. To estimate the local landscape (local sharpness), the authors provide a heuristic, which requires running gradient descent and gradient ascent for some number of iterations. The proposed algorithm has a promising result empirically, compared to entropy SGD (Chaudhari et al.) which also aims at finding a solution that generalizes well.",0.30303030303030304,0.18691588785046728,0.23121387283236994
1014,SP:5f8c45f7d133f3ec6e0280fb596a3242e2f48733,"This paper presents an unsupervised deep learning approach for learning representations of 3D protein structures. They use an objective function motivated by the recent contrastive learning approaches (from computer vision). They show the utility of their model in two downstream applications: protein fold classification, enzyme classification and protein similarity prediction. The main contributions are: 1. they show how the contrastive learning framework can be used in the context of protein structures 2. they analyze the learned representations 3. they show the utility of the model to downstream applications 4. they show how fine-tuning their model leads to an improved performance","This paper studies unsupervised contrastive learning on protein structures, using sub-structure sampling as the data transformation strategy in contrastive learning. The protein structure representation from contrastive learning is then evaluated for three tasks: fold classification, enzyme classification, and protein similarity.  The main contributions are: 1) Demonstrating that contrastive learning with sub-structure sampling is a viable strategy for learning protein structure representations. 2) Improving empirical results for fold classification and enzyme classification when compared to existing methods.",0.27722772277227725,0.358974358974359,0.3128491620111732
1015,SP:5f9e6a9b02d4ed607e2943e4b78fca65a56edf15,"A major concern about the paper is related to the unsupported claims and contribution throughout the paper. For example, the way the training copes with distribution shift or alleviate forgetting is not clear or elaborated on. Beyond the abstract and before the empirical validation no theory or justification is provided to substantiate this claim. The idea of the paper and the motivation are very interesting. The experiments look convincing. Writing and presentation are a good start point for improving the paper. ","This paper presented a stochastic gradient descent approach to learn a non-stationary high-dimensional Gaussian mixture model from online data. The authors identified 3 challenges - local optima, numerical instability, and catastrophic forgetting, and proposed to address these challenges respective with adaptive annealing, exponential-free approximation, and adaptive SGD learning rate. The proposed approach is demonstrated with several vision/non-vision tasks.",0.1111111111111111,0.14516129032258066,0.12587412587412586
1016,SP:5fbdd9020e410152a667b9c6551cab9cc3f14af3,"This paper proposes an anchor-free object detector that does bounding box regression in the polar coordinate instead of in the Cartesian coordinate. The motivation of doing this is because there are larger variance in offset vectors in the Cartesian coordinate (the extreme case when a point is on one of the four corners of the bounding box, the offset vector becomes [0, w, 0, h]). The authors propose a solution to regress to the pair of corners (either TL+BR or TR+BL) in the polar coordinate, and select the corner pair that gives the smallest variance during training.","This paper proposes a new key-point based object detector, PolarNet, which predicts the distances between key-points and corner pairs (such as top-left and bottom-right pair or top-right and bottom-left pair) on polar coordinates. This is different from other key-point based object detectors such as FCOS which predicts distances between key-points and bounding box boundaries on cartesian coordinates.  The authors claim that the advantage of representing the offsets in the form of polar coordinates is this representation reduces the variance in the offsets, which makes learning easier.",0.21,0.22340425531914893,0.21649484536082472
1017,SP:5fff81a3906d13d4a4105e509b399c203d8e1d58,"The authors introduce a deep ensemble kernel learning approach as a linear-based learning combination, from a deep learning scheme, to approximate kernel functions under a Bayesian (GP) framework. Namely, a universal kernel approximation strategy is proposed from eigen-based decomposition and deep learning-based function composition. Then, a variational inference strategy is used to solve the optimization from kernel-based mappings. Two regularization strategies are studied: optimal prior covariance and isotropic covariance. Results demonstrate the benefits of the proposal.","This paper proposes a variant of the Deep Kernel Learning model (DKL) [1] where multiple independent networks are trained for the features instead of a single network. In addition, the paper proposes to use a linear kernel as a base kernel which allows for universal approximation of any arbitrary kernel, as well as allowing for exact inference of the kernel hyperparameters. The use of stochastic variational inference is proposed for inferring the neural networks weights. The model is compared against Deep Ensemble (DE) and DKL on a synthetic dataset and the UCI dataset.",0.2,0.17204301075268819,0.18497109826589597
1018,SP:60133dcf473580ef37878b0d79fc044c30adefda,"This is an experimental paper that seeks out to investigate information processing in multi-path networks i.e. networks such as ResNet, EfficientNet, Inception-style. The goal was to investigate how different pathways process information in such networks in order to better understand learned representations to inform new network architectures in the future. The authors used logistic regression probes (LRP) and representation saturation as metrics to power their analysis. Through the analysis of a network composed of many multi-path networks with differing number of layers or different receptive fields, the authors demonstrate that shorter pathways often dominate longer pathways. Further, if pathways are slightly difference, distinct features will be promoted in later layers.","This paper analyzes the distribution of information processing in multi-path networks (including skip-connection models such as ResNet and DenseNet). They apply logistic regression on the hidden layers, namely logistic regression probes, to track the progress of the intermediate solution quality, and they analyze in which condition (depth of the path and receptive field size) the neural network prefers to skip the paths. They also measure the CKA similarity of the hidden representations learned by the multi-path model when the paths are homogeneous. They claim that with their analysis, later layers in ResNet and DenseNet can be skipped as pruning due to the unproductive layers. In addition, they find that for multi-path model, the shorter path is dominant when the depth of the paths are very different, and when the pathways are homogeneous, the behavior of the pathways changes to a coexisting behavior.",0.2543859649122807,0.19863013698630136,0.22307692307692306
1019,SP:6022b52e1e160bd034df1a7c71c6ca163bcf4dc0,"This paper proposes Surprise Minimizing RL (SMiRL), a conceptual framework for training a reinforcement learning agent to seek out states with high likelihood under a density model trained on visited states. They qualitatively and quantitatively explore various aspects of the behaviour of these agents and argue that they exhibit a variety of favourable properties. They also compare their surprise minimizing algorithm with a variety of novelty-seeking algorithms (which can be considered somewhat the opposite) and show that in certain cases surprise minimization can result in more desirable behaviour. Finally, they show that using surprise minimization as an auxiliary reward can speed learning in certain settings.","This paper proposes a novel form of surprise-minimizing intrinsic reward signal that leads to interesting behavior in the absence of an external reward signal. The proposed approach encourages an agent to visit states with high probability / density under a parametric marginal state distribution that is learned as the agent interacts with its environment. The method (dubbed SMiRL) is evaluated in visual and proprioceptive high-dimensional ""entropic"" benchmarks (that progress without the agent doing anything in order to prevent trivial solutions such as standing and never moving), and compared against two surprise-maximizing intrinsic motivation methods (ICM and RND) as well as to a reward-maximizing oracle. The experiments demonstrate that SMiRL can lead to more sensible behavior compared to ICM and RND in the chosen environments, and eventually recover the performance of a purely reward-maximizing agent. Also, SMiRL can be used for imitation learning by pre-training the parametric state distribution with data from a teacher. Finally, SMiRL shows the potential of speeding up reinforcement learning by using intrinsic motivation as an additional reward signal added to the external task-defining reward.",0.24528301886792453,0.14130434782608695,0.17931034482758618
1020,SP:60232b35685b12a1aa583e9b2ef650eafb7bfcc0,"The paper proposes a simple method, ""instruction-tuning"", to improve the zero-shot learning capability of large language model, which 1) annotates prompts for a wide range of tasks and then 2) fine-tunes the model to ""answer/respond to"" those prompt. The empirical results are impressive: after instruction-tuning, the 0-shot performance is better than GPT-3 (0-shot, sometimes few-shot) on a wide range of datasets; nevertheless, on datasets with formats already similar to language modeling, the performance gain is negligible or even negative.  The paper also made a few other observations 1) performance benefits from the number of task clusters 2) instruction-tuning is only beneficial when the model size is larger enough, and 3) few-shot learning still helps. ","The paper explores a simple and effective method to improve zero-shot performance of pretrained language models. Authors take a 137B parameter pretrained model and finetune it on multiple tasks verbalized via natural language instruction templates. As the result, the instruction-tuned model performs well on un-seen tasks with the zero-shot setting.",0.16,0.37037037037037035,0.22346368715083798
1021,SP:6053644135b4a44cbd98ba1b40c3f143e28b6bff,"This paper analyzes the emergence of commonsense knowledge in few-shot knowledge models. In particular, it attempts to answer whether and when is this knowledge learned: during pretraining or from fine-tuning on KG examples. To investigate this, various commonsense knowledge models are trained in few-shot settings. The results and analysis in the paper shows that commonsense knowledge models can adapt from limited examples. Moreover, similar to a recent line of work, this work confirms that KG fine-tuning learns an interface to the commonsense knowledge learned during pretraining. Finally, the paper also presents an analysis of absolute, angular, and distributional parameter changes during few-shot fine-tuning. However, the insights here are less convincing to me.","This paper analyzes fine-tuning of pre-trained generative language models on a commonsense knowledge task, investigating how much the strong performance of the models is due to pre-training or to task-specific learning (via fine-tuning or prompting/in-context learning). The task is to predict natural text for the tail of (head, relation, tail) relationships from the Atomic_20^20 knowledge graph (KG), e.g. (""PersonX goes to the mall"", xIntent) -> ""to buy clothes"". The paper shows that a T5-based model obtains a substantial fraction of the performance of fine-tuning on the full Atomic dataset, using few-shot learning with only a small number of examples (3) per relation. Few-shot learning also obtains a substantial improvement over zero-shot performance for this model. The paper also presents several measures of parameter differences between pre-trained and fine-tuned models and performs an analysis with them, showing that more parameters are updated in the models' decoders than in their encoders. Taken together with past work, the evaluation results and analysis support the paper's claim that most of the knowledge useful for the KG task was already present in the pre-trained models.",0.2627118644067797,0.15656565656565657,0.1962025316455696
1022,SP:605b718f10904f4545755d5e71f555518dbf722e,"This paper presents a new approach to learning disentangled representations of sequential data. The model, FAVAE, is based on the information bottleneck framework (Alemi et al, 2016; Achille et al, 2016) and extends the recent beta-VAE (Higgins et al, 2017) and CCI-VAE (Burgess et al, 2017) work by changing the encoder/decoder to a Quasi-Recurrent Neural Network (QRNN) and adding multiple latents through a ladder VAE approach (Zhao et al, 2017). The authors demonstrate that their approach is able to learn a more disentangled representation than the limited set of baselines on three toy datasets.","The paper proposes the factorized action variational autoencoder (FAVAE) as a new model for learning disentangled representations in high-dimensional sequences, such as videos. In contrast to earlier work that encouraged disentanglement through a carefully-designed dynamical prior, the authors propose a different encoder-decoder architecture combined with a modified loss function (Beta-VAE with a “shift C scheme”). As a result, the authors claim that their approach leads to useful disentangled representation learning in toy video data, and in data taken from a robotic task.",0.21428571428571427,0.2441860465116279,0.22826086956521738
1023,SP:6082f06dbd0195e1bbef91251569013e4ba484d8,"Annotation in the clinical dataset is hard to prepare, so it is important if self-learning algorithms can be applied to medical data which can do few-shot learning. In this paper, authors put forward a method to do segmentation which makes use of pretraining with contrastive learning with metadata, and then better fine tuning with self-paced learning. The second step is necessary to mitigate meta data noise. This paper shows experiments on three public datasets. With a few annotated data, the algorithms still show comparable performance with the fully supervised segmentation algorithm.","The authors propose using “metal labels” in pertaining image encoders on unlabeled datasets. They use the metal-labels in pertaining the encoder, and also as an auxiliary task in training. They show their method works on multiple medical datasets.",0.06382978723404255,0.15384615384615385,0.09022556390977444
1024,SP:6085b40ac206d3d52fd664b15099128b7cbbb4f0,"This paper introduces equi-normalization (ENorm): a normalization technique that relies on the scaling invariance properties of the ReLU, similarly to Path-SGD. Their method explicitly use this property to balance the weights of the network, without changing the function computed by the network. The main difference with Path-SGD is that the network is explicitly balanced, while Path-SGD uses a regularizer to implicitly balance the network. Since it doesn’t rely on mini-batch to normalize the network, Equi-normalization could be a good alternative to BN in small mini-batch regime. The method is validated on 3 tasks (MLP on CIFAR10, CNN on CIFAR10, Reidual Network on ImageNet).","The authors propose a new weight re-parameterization technique called Equi-normalization (ENorm) inspired by the Sinkhorn-Knopp algorithm. The authors show that the proposed method preserve functionally equivalent property in respect of the output of the functions (Linear, Conv, and Max-Pool) and show also that ENorm converges to the global optimum through the optimization. The experimental results show that ENorm performs better than baseline methods on CIFAR-10 and ImageNet datasets.",0.15315315315315314,0.2328767123287671,0.18478260869565216
1025,SP:608ec90d9c9d08fc825ae49a17cff75d816c95a7,"This article proposes a method for object counting which can be trained with weak supervision. Object counting methods are often trained with point annotations, i.e., one click-point per object. In this article, a weaker way of annotation is used: count-based annotation, i.e., the number of objects of each class present in the image are given as annotation but no precise location of the objects. This article is an extension of density-based object counting methods for weakly supervision.","The main contribution of the paper is the extension of techniques for weakly supervised localization, i.e. given ground truth counts of objects in a given image, one can do training to generate hidden layer density maps that allow for feature detection and localization of objects.   The main contribution of the paper seems to be the regularization of the density map by incorporation of a Gini impurity penalty and the contrasting of the regularizer against beta-variational autoencoder formulation. The experiments show the utility of the method in a toy example and an example involving pedestrians in video surveillance.  ",0.15853658536585366,0.13131313131313133,0.14364640883977903
1026,SP:609072c4e2753277ab90174dc3a7b66d03653498,"The paper proposes an approach to Few-shot Learning based on the the CosFace (Normalized Softmax) Loss. After pretraining, class weights are added to the cross entropy loss for each new class in the test set, which are computed by averaging over inferred weights from a support set while fixing the remaining network weights (feature extractor). Experiments conducted on CIFAR10 and Fashion-MNIST indicated gains over baseline approaches.","This paper is about classification of images in an open set setting. Data coming from new classes are introduced to the network after training on data from a fixed set of known classes. The goal is to be able to correctly classify the old and new classes either jointly or not. This paper proposes a method for handling new classes by increasing the size of the classifier weights for each new classes. The network is trained using the Normalized softmax loss and new classifier elements are added by finding the center of mass of the data coming from the new set of class. The method performs on FASHION MNIST, CIFAR and Plantnet datasets.",0.27941176470588236,0.168141592920354,0.20994475138121546
1027,SP:6102c0d1cbc3ee0f3e9260c40e53c09a34d3d94d,"The paper proposes to make a clear connection between the InfoNCE learning objective (which is a lower bound of the mutual information) and multiple language models like BERT and XLN. Then based on the observation that classical LM can be seen as instances of InfoNCE, they propose a new (InfoWord) model relying on the same principles, but taking inspiration from other models also based on InfoNCE. Mainly, the proposed model  differs both in the nature of the a and b variables used in InfoNCE, and also on the fact that it uses negative sampling instead of softmax. Experiments are made on two tasks and compared to a classical BERT model, and on the BERT-NCE model that is a BERT variant proposed by the authors which is somehow in-between BERT and InfoWord. They show that their approach works quite well. ","This paper first gives a concise yet precise summary of maximizing one of variational lower bounds of mutual information, InfoNCE, then it provides an alternative view to explain case by case why word embedding Skip-gram, BERT, XLNet work in practice can be viewed by InfoNCE framework, thus we have a good understand for these methods. Moreover it introduces a self-learning method  that maximizes the mutual information between a global sentence representation and n-grams in the sentence based on deep InfoMax framework instead. Experiments show that it is better then BERT and BERT-NCE. It's known that InfoNCE increases bias but reduce variance, the same is true for deep InfoMax. Do you observe this in your experiments? If so, please provide.",0.18439716312056736,0.20967741935483872,0.19622641509433963
1028,SP:612ac9845a8de12d468f804d585fc0e2bb79b0d0,"The paper introduces the use of dropout for World Models. The argument put forward is that different dropout masks essentially lead to different “dream” environments. The authors compare their approach to the original World Models paper and the recent Game GAN work in the two original World Model environments (Doom and Car Racing). The authors appear to show results that outperform these baselines, and they then perform ablation studies to fully dig into the implications of this application of dropout. ","The paper proposes a method for improving the generalisation of model-based  RL algorithms. The paper proposes that one should learn a distribution of transition models, which they do by training with Dropout to improve generalization in model-based RL. While the paper is addressing an important problem, sadly it lacks in novelty, it is unclear if the results are significant and there is a lack of discussion and comparison to related work in this direction.",0.2,0.21052631578947367,0.20512820512820512
1029,SP:6143691512df0e976ae6ede68118a19b138c959f,"This paper mixes automated theorem proving with machine learning models. The final goal, of course, is to be able to train a model that works in conjunction with an automated theorem proving system to efficiently prove theorems, and, ideally, in a way that resembles the way humans prove theorems. This is a distant goal, and the authors instead focus on several tractable tasks that are required for future progress in this direction. They start by integrating the Coq theorem proving environment with ML frameworks, allowing for the creation of models that perform various tasks related to theorem proving. In particular, they focus on two tasks. One is to estimate how many steps are left to complete the proof given a current proof state. The other is to determine what is a good choice of next step. Finally, they also consider issues surrounding representations of the various data structures involved in proofs (i.e., the proof tree, variables, etc.). They test various models on a synthetic nearly trivial logical expression proof, along with a more complicated (and meaningful real world) group theory result.","The submission describes a system for applying machine learning to interactive theorem proving. The paper focuses on two tasks: tactic prediction (e.g. attempting a proof by induction) and position evaluation (the number of  remaining steps required for a proof). Experiments show that a neural model outperforms an SVM on both tasks, using proof states sampled from a proof of the Feit-Thompson theorem as a dataset. It's great to see work on applying neural networks to symbolic reasoning. The paper is clearly written, and provides helpful background on interactive theorem proving.",0.11538461538461539,0.22580645161290322,0.1527272727272727
1030,SP:615886c264f4481f18aa1a34098c946664a55324,"The paper has two main contributions:  1. It takes a known monotonicity regularizer and trains with it using a new distribution that is roughly a mixing of uniform and the training distribution. It shows empirically that using this method increases the ""size"" of the input region in which the model is monotonic.   2. It defines several regularizers that are meant to encourage ""monotonic behavior"" of the model's output w.r.t the outputs of an intermediate layer or latent variable. It provides experiments that show how using these regularizers does not hurt the model's performance and two applications of the added structure: 1) detecting noisey/adverserial examples and 2) more controllable generation in generative models. ","This paper proposes an incremental improvement to existing methods that encourage monotonicity through a regularization term. The contribution of the paper is about how to sample the data to compute this regularization term, which is an expectation w.r.t. a data distribution. So instead of purely sampling from existing training data or performing uniform sampling in potentially high-dimensional feature space, this paper proposes to use mixup, which essentially involves creating synthetic examples by interpolating between existing training examples. The authors also extend this regularization term to the case where the prediction function outputs a vector, e.g., multi-class classification), and the case of VAE. The authors provide some experiment evidence that the proposed change can reach better performance for some data sets.",0.15384615384615385,0.144,0.14876033057851237
1031,SP:6189787a0a56a17434f7457ecf41aa327915936a,"The paper presents a novel end-to-end mechanistic generative model of electron flow in a particular type of chemical reaction (“Linear Electron Flow” reactions) . Interestingly, modeling the flow of electrons aids in the prediction of the final product of a chemical reaction over and above problems which attack this “product prediction problem” directly. The method is also shown to generalize well to held-out reactions (e.g. from a chemistry textbook).","The paper presents a novel method for predicting organic chemical reactions, in particular, for learning (Robinson-Ingold's) ''arrow pushing"" mechanisms in an end-to-end manner. Organic molecules consist of covalent bonds (that's why we can model them as molecular graphs), and organic reactions are recombinations of these bonds. As seen in organic chemistry textbooks, traditional chemists would qualitatively understand organic reactions as an alternating series of electron movements by bond breaking (bond cleavage) and bond forming (bond formation). Though now quantum chemistry calculations can give accurate quantitative predictions, these qualitative understanding of organic reactions still also gives strong foundations to consider and develop organic reactions. The proposed method tries to learn these series of bond changes directly through differentiable architectures consisting of three graph neural networks: 1) the one for determining the initial atom where electron movements start, 2) the one for representing state transitions from  the previous bond change to the next, and 3) the one for determining when the electron movements end. Experimental evaluations illustrate the quantitative improvement in final product prediction against existing methods, as well as give chemical intuitions that the proposed method can detect a class of LEFs (linear electron flows).",0.3333333333333333,0.12060301507537688,0.17712177121771214
1032,SP:61bb7f39ffbf7caed41c8c0ef0650010d8a253aa,"The authors of this paper construct a new few-shot learning dataset. The whole dataset consists of several data from different sources. The authors test several representative meta-learning models (e.g., matching network, Prototype network, MAML) on this dataset and give the analysis. Furthermore, the authors combine MAML and Prototype network, which achieves the best performance on this new dataset.","The paper presents Meta-Dataset, a benchmark for few-shot classification that combines various image classification data sets, allows the number of classes and examples per class to vary, and considers the relationships between classes. It performs an empirical evaluation of six algorithms from the literature, k-NN, FineTune, Prototypical Networks, Matching Networks, Relation Networks, and MAML. A new approach combining Prototypical Networks and first-order MAML is shown to outperform those algorithms, but there is substantial room for improvement overall.",0.21311475409836064,0.16049382716049382,0.18309859154929578
1033,SP:61c1ba5a02194732b56c6491b40e80d2d0846851,"This paper introduces a framework for composing tasks by treating tasks as a Boolean algebra. The paper assumes an undiscounted MDP with a 0-1 reward and a fixed absorbing set G, and considers a family of tasks defined by different reward functions. Each task defers only by the value of the reward function at the absorbing set G. These restrictions are quite severe but basically describes goal-state reaching sparse reward tasks, which are quite general and valuable to study. The paper then defines a mapping onto a Boolean algebra for these tasks and shows how the mapping also allows re-using optimal Q functions for each task to solve a Boolean composition of these tasks. This is demonstrated on the tabular four-rooms environment and using deep Q learning for a 2D navigation task.","The paper proposes a method of combining value functions for a certain class of tasks, including shortest path problems, to solve composed tasks. By expressing tasks as a Boolean algebra, they can be combined using the negation, conjunction and disjunction operations. Analogous operations are available for the optimal value functions of the tasks, which allows the agent to have immediate access to the optimal policy of these composed tasks after solving the base tasks. The theoretical composition properties are confirmed empirically on the four rooms environment and with function approximation on a more complex domain. ",0.22794117647058823,0.3263157894736842,0.2683982683982684
1034,SP:61dde0e4c82d4357aeaaba158f8944d9517a55c3,"The paper proposes to adapt the mass matrix used in HMC by maximising the speed measure introduced in [1]. Estimating the speed measure is non-trivial and it is achieved by firstly finding a lower bound of the density induced by a HMC kernel and then estimating the bound using Russian-roulette sampling. Experiments performed on multiple targets show that the method is working in practice.  [1] Michalis Titsias and Petros Dellaportas. Gradient-based adaptive Markov chain Monte Carlo. NeurIPS, 2019.","In this paper, the authors propose an adaptive Hamiltonian Monte Carlo method. In their method, they adapt the hyperparameters of HMC by maximizing an approximation of the proposal entropy. And they show the efficiency of their method by experiments.",0.13580246913580246,0.28205128205128205,0.18333333333333332
1035,SP:61e38c36fc69f1cc6f7867971e75e06f7248283b,"This paper attempts to solve match prediction problem, i.e., whether a group is preferred over the other. The key challenge is ""consistency"" since it's hard to find the universal pattern over tasks. Instead, this paper propose to learn reward and penalty modules and both vary when the underlying model changes. Experiment results show that the proposed method consistently works the best. ","This paper proposed a novel architecture to tackle the match prediction problem.  There are two/three modules in the architecture, the R/P modules and the G module. R/P modules take the current utility estimates of the individuals in a given group comparison as input and produce the current R/P estimates for the individuals as output. The G module takes the final utility estimates of the individuals in a given group comparison as input and produces the winning probability estimate of one group preferred over the other in the given group comparison as output.",0.23809523809523808,0.15625,0.18867924528301888
1036,SP:61e4186bf0f3ce2e595196285f5f19e45d67a0d8,"This paper works on the problem if training a set of networks to solve a set of tasks. The authors try to discover an optimal task split into the networks so that the test performances are maximized given a fixed testing resource budget. By default, this requires searching over the entire task combination space and is too slow. The authors propose two strategies for fast approximating the enumerative search. Experiments show their searched combinations give better performance in the fixed-budget testing setting than several alternatives.","This paper focuses on how to partition a bunch of tasks in several groups and then it use multi-task learning to improve the performance.  The paper makes an observation that multi-task relationships are not entirely correlated to transfer relationships and proposes a computational framework to optimize the assignment of tasks to network under a given computational budget constraint. It experiments on different combinations of the tasks and uses two heuristics to reduce the training overheads, early stopping approximation and higher order approximation. ",0.19767441860465115,0.20238095238095238,0.2
1037,SP:620dded5d2b04f0d178ebd00c303f9fb43afdb30,"This paper proposes two modifications for the MixMatch method [1] and achieves improved accuracy on a range of semi-supervised benchmarks. The first modification enforces the distribution of predicted labels to match the distribution of labeled data. The second modification is adding a learned data augmentation strategy, and adapting the method to work with strong data augmentation. The final method is titled ReMixMatch, and improves significantly over MixMatch, especially in low-data regime. ","This paper presents ReMixMatch an improved version of MixMatch. The main contributions are the distribution alignment and the augmentation anchoring. Distribution alignment rescales the predictions based on the difference between the model marginals and the ground truth running average estimation. Augmentation anchoring instead of computing the guessed probabilities on unlabelled data as the average probabilities on transformed samples (as in MixMatch), it considers as guessed labels the average probabilities obtained from weak transformations (flip+crop) even when using stronger transformations (Autoaugment like). ",0.2054794520547945,0.18292682926829268,0.19354838709677416
1038,SP:6230a5ef4101ff305dd674d4cc562bb23d39d8fa,"The manuscript entitled “Photonic Differential Privacy with Direct Feedback Alignment” extends their previous work - Differential Privacy with Direct Feedback Alignment. In this work, they leverage the intrinsic noise (which might be controlled by temperature) of optical random projections to build a differentially private DFA mechanism, making Optical Processing Units (OPUs) a solution of choice to provide a private-by-design training. This work is motivated by a photonic implementation that naturally induces noise that we exploit for differential privacy. The proposed method is demonstrated by simulations showing that adding noise does not decrease the performance significantly. In other words, this approach is robust to increasing DP noise. This paper also provides its theoretical analysis.","The paper proposes a hardware-based approach to Differential Privacy (DP) using OPU to perform optical random projections for a differentially private DFA training algorithm, leveraging noise intrinsic to the hardware to achieve privacy-by-design. The proposed approach was analyzed mathematically in detail. The proposed methods were analyzed on the vanilla Fashion MNIST dataset.    The paper is very well written in general. The proposed methods/approach are very interesting, and mathematical results are solid. ",0.15789473684210525,0.24,0.19047619047619047
1039,SP:62366ea14ace4437298fb9ddf7f095563709e3bf,"This paper proposes a framework to unfold the safeguarded Krasnosel’ski˘ı-Mann (SKM) method for the learn to optimization (L2O) schemes. First, SKM is proposed in Algorithm 1 with convergence guarantee established in Theorem 3.1 and Corollary 3.1. Then, SKM is unfolded and executed with a neural network summarized in Algorithm 2. Experiments on the Lasso and nonnegative least squares show the efficiency of the proposed method as well as the effectiveness of safeguarding compared to traditional L2O methods.   ","This paper presents a unified framework for parametrizing provably convergent algorithms and learning the parameters for a training dataset of problem instances of interest. The learned algorithm can then be used on unseen problems. One key idea to this algorithm is that it is safeguarded, meaning it will perform some standard, non-learned iterations, if the predicted iterate is not good enough under some condition.",0.13580246913580246,0.16923076923076924,0.15068493150684933
1040,SP:6240f298135e32b342253ad334e193473f1f9fe5,"Methods like backpropagation require the updates to be propagated along the same pathways and weights as the forward computation step (i.e. the ""weight transport problem""). To solve this problem, the authors propose activation sharing, which uses random fixed weights both to forwardpropagate activations and to backpropagate error, without bidirectional connections. It is argued that this is more biologically plausible, and can be used to train deep networks (which previous methods could not do). ","This work presents a new neural network learning algorithm that removes some of the constraints required by the traditional backpropagation algorithm. Constraints such as explicit bidirectional connections and symmetric weights between the forward and feedback paths are not used with the proposed algorithm. Through experiments on multiple popular datasets, the authors demonstrate their algorithm is competitive or better than several other learning algorithms including Feedback Alignment and Direct Feedback Alignment despite having fewer constraints.  This work also provides a thorough overview of the signals propagated through the neural network for algorithms like backpropagation, feedback alignment, direct feedback alignment, and weight mirroring. From this review, it is easy to distinguish the differences between how these signals are combined to generate updates for forward and backward paths.",0.17567567567567569,0.104,0.13065326633165827
1041,SP:624274b6944826b6f9597298b290ae50566d6e5c,"The paper introduces an approach for semi-supervised learning based on local label propagation. The idea is to leverage the geometric structure in the embedding space, such that data near to each other in the embedding space should have the same labels. The labels of the K-nearest labeled examples are weighted to form the propagated pseudo label of the data point. And the objective aims to match the propagated pseudo label and the predicted label from the classification model. An extra term is added to the objective to force data points with similar pseudo labels to get close to each other in the embedding space. The local propagation strategy makes the method scalable compared to similar methods in the literature. The method is tested on different experimental setups and show superior performance than the state of the art baselines. ","The authors propose a local label propagation approach for large-scale semi-supervised learning. The approach learns a representation that tries to minimize a combination of the cross-entropy loss on the labeled data and a negative inner-product-based likelihood between the propagated pseudo-label and other examples with the same true label. The pseudo-labels on the unlabeled data are then calculated with a weighted k-NN scheme, where the weights take a heuristic correction of a soft similarity. Some further computational speedup is done with a memory cache described in an earlier work (Wu 2018b). Experimental results seem significantly superior to the competitors. The design choices are mostly justified with ablation studies.",0.22142857142857142,0.26956521739130435,0.24313725490196078
1042,SP:62517d35207a58ae175ea3c3787512424e8ece51,"The authors study the robustness of adversially-trained models across different classes. They find that classes tend to have largely non-uniform robust accuracy--i.e., some are less robust then others. Moreover, certain datapoints can only be misclassified as specific classes and removing these classes during training can make these datapoints robust. Next, the authors investigate how this robustness discrepancy across classes relates to the norm of the last fully-connected layer of the model, as well as to the strength of the attack used. Finally, the authors propose a new adversarial attack that they evaluate against existing models.","This paper examines the robustness of adversarially robust models at the class-level.  Specifically, they note a disparity in the class-wise robustness of models for standard datasets. Furthermore, they suggest that many of these class-level vulnerabilities are eliminated if the model is trained without the corresponding confounding class. Finally, they propose a temperature based attack to further degrade accuracy of vulnerable classes.",0.16,0.25,0.19512195121951217
1043,SP:6260d6cfb07fe0981539d9a1e4a47d21479316ad,"Overview: This paper discusses the risk of membership inference attacks that deep neural networks might face when used in a practical manner on real world datasets. Membership inference attacks can result in privacy breaches, a significant concern for many fields who might stand to benefit from using deep learning in applications. The authors demonstrate how attack accuracy goes up when one dataset is used for training while another altogether is used for testing. They propose the use of causal learning approaches in order to negate risk of membership inference attacks. Causal models can handle distribution shifts across datasets because they learn using a causal structure. ","   The authors consider a transfer learning problem where the source distribution is P(X,Y) while the target distribution is P*(X,Y) and classifier is trained on data from the source distribution. They also assume that the causal graph generating the data (X and Y) is identical while the conditional probabilities (mechanisms) could change between the source and the target. Further, they assume that if X_C is the Markov Blanket for variable Y in P and P*,  then P(Y|X_C) = P*(Y|X_C). Therefore the best predictor in terms of cross entropy loss for both distributions is identical if it focuses on the variables in the Markov Blanket. Authors define ""causal hypothesis"" as the one that uses only variables in the Markov Blanket (X_C) to predict Y.",0.13333333333333333,0.10526315789473684,0.11764705882352941
1044,SP:626b5d8d5a5aadf5f99ec791df9f4e507870e69b,"This paper analyzes the optimality and convergence of the two-scale update for an actor-critic algorithm where the actor and critic are parameterized by two layer NNs (which is a generalization of traditional linear function approximation guarantees in RL). The authors analyze for the PPO as actor and minimizer of the the MSBE as the critic. Considering the actor-critic updates as gradient flow differential equations in the L_2 Wasserstein space, in following steps, the authors show: (1) optimality and convergence rate of policy error proportional to inverse of time and the critic error (2) bounding the critic error based on the Wasserstein error of the distribution of NN weights (3) applying (1) and (2) with Restarting mechanism (resampling the critic weights from an initial distribution when they are sufficiently close to the initial distribution), they prove the global optimality and convergence rate of AC method .","This paper studies actor-critic (AC) algorithms with neural networks from a theoretical perspective.   The authors consider an AC algorithm variant that updates its actor with PPO with a small stepsize, and its critic updated via TD and a larger stepsize. Under certain conditions, the authors prove that this AC reaches the optimal policy with sublinear rate. The authors additionally show that the feature representations learned by the critic can move further away from the initialization. ",0.13513513513513514,0.2631578947368421,0.17857142857142858
1045,SP:626c65a0fe391afe1b3a8769de16e9f1ccded977,"This paper proposes a method to disentangle content and motion from videos for high-resolution video synthesis. The proposed method consists of a motion generator, pre-trained generator, image discriminator, and video discriminator. The motion generator predicts the latent motion trajectory z, which is residually updated over time. Then the image generator produces each individual frame from the motion trajectory. For training, five types of loss functions are combined. In experiments, video generation by the proposed method is performed on UCF-101, FaceForensics, and Sky time-Lapse datasets. Also, cross-domain video generation and more ablation studies were conducted to show the effectiveness of the proposed method.","This paper addresses the problem of video synthesis --- generating diverse, realistic videos. This paper's core idea is to leverage a fixed, pre-trained GAN model for image synthesis and train a motion generator to produce a sequence of latent vectors to generate image sequences (using the pretrained GAN and the generated latent vectors) are temporally coherent. The specific technical novelties lie in (1) predicting the motion residual and (2) adding contrastive image discriminator to ensure that generated contents in a video are similar. The paper provides an extensive set of experiments demonstrating the proposed method's effectiveness over the state-of-the-art video synthesis models.",0.22429906542056074,0.22429906542056074,0.22429906542056074
1046,SP:627a0f2c3be51ea6d1e8f56c7b2dd35142758509,"This paper presents a new dual-task of joint few-shot recognition and novel synthesis. The main idea of this paper is to learn a shared generative model across the dual-task to boost the performances of both tasks. To achieve this, bowtie networks are employed to jointly learn geometric and semantic representations with a feedback loop. The proposed method is evaluated on fine-grained recognition datasets.","This paper proposes a ""feedback-based bowtie network"" FBNet for joint generative synthesis via a GAN-based framework (specifically HoloGAN) and few-shot fine-grained recognition. The key idea of this work is to supervise both networks jointly via feedback mechanisms between the two, which helps to improve both tasks: image synthesis and few-shot recognition. The authors propose to use the synthesis network for synthesizing augmented images and additional losses computed by the image classification network along with conditional generation to improve the quality of the synthesized images.",0.31343283582089554,0.23595505617977527,0.2692307692307692
1047,SP:628d4a238d969db682254bce90685cd0ce023763,"Summary:  This paper proposes a spectral initialization algorithm for compressive phase retrieval and show that it is provably close to the ground truth. They also generalize previous results in compressive phase retrieval using generative models. Finally, the authors show that sparse PCA can be used to find a good initialization for sparse phase retrieval.","This paper considers the problem of noisy compressive phase retrieval (CPR) of $n$ dimensional signal under two different priors: (i) $L$-Lipschitz continuous generative model with latent dimension $k$ and (ii) underlying sparsity $s$. The main claims of this paper are theoretical in nature, where the authors derive the sample requirements for existence of a solution for CPR under both types of priors (assuming there exists an algorithm that can  solve the CPR minimization). The sample requirements obtained are of the order required for a linear compressive sensing problem, and therefore roughly sample optimal.  Additionally the authors use a _truncated_ spectral initialization algorithm for CPR, which they show has solution that lies close enough to the ground truth signal using only O($k\log L$) (and O($s\log n$)) samples.  The authors design a related spectral initialization technique which can be combined with any other off-the-shelf CPR algorithms, while requiring fewer sample requirements then prior state of art.   Spectral initialization has been previously used for the general phase retrieval problem as well as under sparsity and structured sparsity priors, however incurring increased sample requirements. In this paper the authors prove closeness of a truncated spectral initialization to ground truth in sparse phase retrieval which brings down the sample requirement from O($s^2 \log n$) to O($s\log n$).  They also show similar guarantees for the case of deep generative priors.",0.46296296296296297,0.10638297872340426,0.17301038062283738
1048,SP:62a75399aa97a61432385cf1dffabb674741a18a,"This paper looks at how deep convolutional neural networks for image denoising can generalize across various noise levels. First, they argue that state-of-the-art denoising networks perform poorly outside of the training noise range. The authors empirically show that as denoising performance degrades on unseen noise levels, the network residual for a specific input is being increasingly dominated by the network bias (as opposed to the purely linear Jacobian term). Therefore, they propose using bias-free convolutional neural networks for better generalization performance in image denoising. Their experimental results show that bias-free denoisers significantly outperform their original counter-parts on unseen noise levels across various popular architectures. Then, they perform a local analysis of the bias-free network around an input image that is now a strictly linear function of the input. They empirically demonstrate that the Jacobian is approximately low-rank and symmetric, therefore the effect of the denoiser can be interpreted as a nonlinear adaptive filter that projects the noisy image onto a low-dimensional signal subspace. The authors show that most of the energy of the clean image falls into the signal subspace and the effective dimensionality of this subspace is inversely proportional to the noise level.","This paper proposed to remove all bias terms in denoising networks to avoid overfitting when different noise levels exist. With analysis, the paper concludes that the dimensions of subspaces of image features are adaptively changing according to the noise level. An interesting result is that the MSE is proportional to sigma instead of sigma^2 when using bias-free networks, which provides some theoretical evidence of advantage of using BF-CNN.",0.09852216748768473,0.28169014084507044,0.14598540145985403
1049,SP:62b109418f4a6e8c755a0864e766448e37d2f9c3,"This paper introduces a wavelet-based superpixel algorithm and a spatially heterogeneous pooling. More specifically, they introduce an algorithm to compress images in the pixel domain and it leads non-uniformly distributed and multiscale superpixels. Furthermore, they introduced a spatially heterogeneous pooling method tailored to the superpixel algorithm. Finally, they demonstrate the effectiveness of their method on MNIST, Fashion-MNIST, and CIFAR-10 datasets. ","The paper introduces a new approach to leveraging graph neural networks for image tasks. While prior work has been based on constructing graphs using a super-pixel map using methods like SLIC, that generate super-pixels of all roughly the same size, the proposed method generates a scale-adaptive partition. It also introduces a new pooling operator on this graph structure, and demonstrates that, together, these lead to improved performance when used with GNNs.",0.171875,0.14864864864864866,0.15942028985507245
1050,SP:62c41894b5a79ff20a4a1e3d56c646e08981814d,This paper presents an experimental study of gradient based meta learning models and most notably MAML. The results suggest that modeling and adaptation are happening on different parts of the network leading to an inefficient use of the model capacity which explains the poor performance of MAML on linear (or small networks) models. To tackle this issue they proposed a kronecker factorization of the meta optimizer.,"This paper analyzes the popular MAML (Model-Agnostic Meta-Learner) method, and thereafter proposes a new approach to meta-learning based on observations from empirical studies. The key idea of the work is to separate the base model and task-specific adaptation components of MAML. This decoupling of adaptation and modeling reduces the burden on the model, thus enabling smaller memory efficient deep learning models to adapt and give high performance on meta learning tasks. The paper proposes a learnable meta-optimizer consisting of a parametrized function U such that the knowledge of adaptation is embedded into its parameters (A,b), instead of forward model parameters. The computational challenges posed by the proposed method are addressed by expressing the parameter matrix A as a Knonecker product of small matrices which is more efficient from memory and time complexity view point. The results on Omniglot and CIFAR-FS are promising, and the paper shows that the proposed meta-optimize is ""more expressive"", as well as can adapt a shallower model to the same level of performance as MAML.",0.30303030303030304,0.11299435028248588,0.1646090534979424
1051,SP:62d218e9619a8a076aa2ef20f64bb26eb8516591,"This paper presents a derivation of a generalization bound for neural networks designed specifically to deal with permutation invariant data (such as point clouds). The heart of the contribution is that the bound includes a  1/n! (i.e. 1 / (n-factorial)) factor to the major term, where n is the number of permutable elements there are in a data example (think: number of points in a point cloud). This term goes some way towards making the bound tight.","This paper derives a generalization bound for permutation invariant networks. The main idea is to prove that the bound is inversely proportional to the square-root of the number of possible permutations to the input. The key result is Theorem 3 that bounds the covering number of a neural network (defined under an approximation control bound, Thm 4) using the number of permutations. The paper proves the theorem by showing that the space of input permutations can reduced to group actions over a fundamental domain, and deriving a bound for the covering number of the fundamental domain (Lemma 1), which is then extended to derive the same for the neural network setting. For the permutation invariance setting, the fundamental domain is obtained via the sorting operator. ",0.3037974683544304,0.19047619047619047,0.23414634146341462
1052,SP:62d9ff0ab002c3a5d47b3cfcf2a645336d3aad2d,"This paper studies the convergence rates of the two first-order methods, named $q$-RGF and $q$-SGF. These are constructed by forward Euler discretizing the $q$-rescaled gradient flow ($q$-RGF) [Wibisono et al., 2016] and $q$-signed GF ($q$-SGF) [Romero-Benosman, 2020], respectively. These gradient flows are shown to converge in finite time in [Romero-Benosman, 2020], under the gradient dominant condition of order $q$. The authors show that their forward Euler discretized versions have linear rates, under an additional Lipschitz smoothness of order $q$. The paper also considers their stochastic variants. Numerical experiments on toy examples and practical example illustrate that the proposed method might have practical advantage over existing methods such as GD and ADAM.",This paper considers the analysis of two discrete time schemes derived from gradient flows named q-RGF and q-SGF. The topic fits more generally into continuous time perspectives for optimization and the relations between ODE theory and optimization. This is an interesting direction with many interesting promises.,0.13333333333333333,0.3333333333333333,0.19047619047619044
1053,SP:62e72e469e4e6d1f0c6eac1074fd35439086e08a,"This paper tries to solve the protein-legend binding prediction problem in the computational biology field. It uses the learned embedding for protein and legend, separately, from two published papers. Then those two embeddings were inputted to another deep learning model, performing the final prediction. Tested on one dataset, it shows the proposed method can outperform the other baseline methods.","The authors present a model with state-of-the-art performance for predicting protein-ligand affinity and provide a thorough set of benchmarks to illustrate the superiority of combining learned low-dimensional embedding representations  of both ligands and proteins. The authors then show that these learned representations are more powerful than handcrafted features such as circular fingerprints, etc. when combined into a model that jointly takes as input both the ligand and protein.",0.15,0.1232876712328767,0.13533834586466165
1054,SP:631bfb07c83d98b09d95e8ad06969f8ecbe936e9,"This paper examines the setting of partially observable stochastic games where agents have the possibility of communication.  The approach taken is what would be termed “direct revelation” in mechanism design: agents are supposed to reveal their full internal state / history to each other at each step.  This gives the most complete information possible to enable good decisions.  However, agents may not have an incentive to report truthfully, so an approach based on peer prediction is used to incentivize this.  The results show improvements over prior approaches to communication in three tasks: predator prey, traffic junction, and StarCraft.","This work presents an auxiliary loss that promotes truthfulness in non-cooperative multi-agent games with communication channels. The truthfulness is promoted through prediction rewards, which capture how well each agent can model other agents' policies via observing their messages. For this mechanism to work, it assumes that each agent has access to other policies, and such an assumption can be satisfied under the self-play / centralized-learning decentralized-execution / shared-weights setup. Having such access to the policy weights, an agent can observe how consistent was their action with their broadcasted message which is a function over their hidden state. Thus by promoting consistency between their actions and messages, truthfulness is achieved. This paper provides theoretical justification of the proposed mechanism and introduces ideas from mechanism design literature in multi-agent reinforcement learning under a non-cooperative setup (not sharing rewards).",0.17525773195876287,0.11971830985915492,0.1422594142259414
1055,SP:633cf2b404a8d76c5f4fc2e2c88546b9a35a7688,"This paper addresses the problem of the low efficiency of program search guided by a pre-trained oracle or on discrete and non-differentiable architecture space. To this end, the paper proposes a framework that performs program architecture search on top of a differentiable relaxation of the architecture space. This allows the program architectures and parameters to be learned via policy-gradient methods without RL oracle. The proposed method also exploits compositionality by allowing an ensemble of primitive functions that perform task-agnostic skills. The experimental results on navigation and manipulation domains show that the proposed method can reliably obtain task-solving programs and outperforms or performs competitively compared to RL baselines including SAC, PPO, TRPO. I believe this work studies an interesting and promising research direction and proposes a convincing framework to tackle this problem with solid technical contributions. Yet, I am mainly concerned with some missing baselines, relevant works, and ablations.","This paper presents a novel method for synthesizing programmatic policies. The code idea of the method is to define a relaxed and differentiable version of the domain-specific language (DSL) used to encode the programmatic policies.   The program space the DSL induces can be described as a program of the DSL itself. Since the program defines a differentiable space, one can use policy gradient methods to search in the space of programs by assigning higher probabilities to production rules that maximize the expected rewards.   The search for programmatic policies happens in two steps. The first step applies a policy gradient method to optimize the probabilities defining the program space. Then, one can extract the most likely program structure from the search space by greedily choosing the production rules with higher probabilities. The resulting program is further optimized with reinforcement learning.   Empirical results on continuous control problems show the advantages of the method. ",0.1830065359477124,0.18421052631578946,0.18360655737704917
1056,SP:63621148403a12bfbf0dd14179ad3933d6ebe50d,"This paper proposes to improve dialogue summarization by encoding the text with a sequential encoder (for token-level contextualization) and a graph encoder (for long-distance and semantic contextualization). A KG is built and considered to be a surrogate for ""factual knowledge"". A dual-copy mechanism is used while decoding in the hope that direct access to this factual knowledge will enhance the faithfulness of the generated summaries.","This paper proposes a knowledge graph enhanced network to improve abstractive dialog summarization with graphs constructed from the dialog structure and factual knowledge. The dialog graph is composed of utterances as nodes and 3 heuristic types of edges (such as utterances of the same speaker, adjacent utterances). The factual graph is constructed via openIE and dependency parsing, which the authors claim are complementary as the triplets (results of openIE) are not always available. ",0.23529411764705882,0.2191780821917808,0.22695035460992907
1057,SP:637febea2b6c5d1ca1045af68beb32e1249e47dd,"The paper focuses on the stability prediction task on the ShapeStacks dataset. Specifically, the paper creates a new extension to the dataset, and it proposes the use of ""Neural Stethoscopes"" framework to analyze deep neural nets' physical reasoning of local stability v.s. global stability. It is shown in the paper neural nets tend to be misled by local stability when the task is to predict global stability. Then the paper utilizes the proposed framework to de-bias the misleading correlation to achieve a state-of-the-art on the dataset.","This paper is about using ""neural stethoscopes"", small complementary neural networks that are added to a main network which with their auxilary loss functions can measure suitability of features or guide the learning process. The idea is incremental to multi-task learning and enable, in a single framework, to validate intermediate features for additional related tasks. Moreover it can promote or suppress the correlation of such features to the tasks related to the main one. The framework is applied to the task of visual stability prediction of block towers. The paper builds upon Groth et al. 2018, adding the concept of local stability as correlated secondary task, used with the proposed neural stethoscopes. Experiments with an extension of ShapeStacks (Groth et al. 2018) dataset where the local stability is added to the global stability class, show that it is possibile increase the performance using the additional task. Moreover, it is shown that neural stethoscopes can suppress nuisance information when using a biased training dataset where the local and global stability are purposely inversely correlated.",0.27472527472527475,0.14367816091954022,0.18867924528301888
1058,SP:6389ff57423090975659dbcd572192bd48f9c3b5,"This paper introduces a new perspective on federated learning through the lens of posterior inference. The paper designs a computation- and communication-efficient posterior inference algorithm—federated posterior averaging (FEDPA), which generalizes FedAvg. FEDPA is compared with the strong baselines in Reddi et al. (2020) on realistic FL benchmarks, which achieves state-of-the-art results with respect to multiple metrics of interest. ","The authors propose a new method of generating local (client) updates in Federated Learning (FL), where the clients return an adjusted version of their usual local updates to the server. The authors derive this new local update rigorously from the viewpoint of estimating the posterior distribution of the data (under Gaussianity assumptions). They also provide an efficient method for calculating this new update, and show that it outperforms Federated Averaging on several datasets.",0.19047619047619047,0.1643835616438356,0.17647058823529413
1059,SP:639b2442d88a9f786ff589798f656206bd071c53,The authors propose a new framework to evaluate the generalizability of trained networks. The framework is based on evaluating the perturbation response curve on intra and inter-class sample mixup. It uses two novel statistical measures: the Gi-score and the Pal-score to predict the generalization gap. The framework is able to achieve a state-of-the-art predictive measure for several tasks in the PGDL competition and can be used to capture invariants to parametric input transformations.,"This paper firstly uses Gini coefficient and Palma ratio together with PR curve for measuring generalization. The paper claims that their framework outperforms the state-of-the-art measures on most of the tasks in the PGDL competition and can capture invariance to input transformation for a trained network. Finally, the paper shows some experimental results on image classification.",0.24050632911392406,0.3220338983050847,0.2753623188405797
1060,SP:63a12d3b46928bf6fece89f1a1a51579ab162d84,"The distance metric learned by low-dimensional embeddings typically captures the knowledge that we already know. This paper proposes a principled way of factoring out prior knowledge (in the form of distance matrices) from tSNE and UMAP embeddings. Two algorithms are proposed for factoring out prior knowledge. JEDI (for tSNE embeds) uses a parameterized JS divergence-- the objective is to learn a low-dimensional distance metric that preserves high-dimensional distances but is orthogonal to the prior distance matrix. CONFETTI is the second algorithm which also optimizes a similar objective to JEDI but doesn't employ JS divergence and is algorithm independent, so one can use it for tSNE or UMAP. Results are shown on synthetic and real-world flower and cell-sequencing data and they highlight the superior ability of JEDI and CONFETTI algorithms in factoring-out prior knowledge compared to the baselines. ","The author(s) provide two methods for factoring out specific covariates from tSNE, UMAP or other distance matrices. The first one is JEDI, an extension of tSNE that minimizes a parameterized divergence (that takes into account the information to be factored out) instead of the simple KL divergence between high dimensional data and low-dimensional embedding. Because tSNE has inherent limitations, the author(s) also propose CONFETTI, a simple approach to create a distance matrix based on the distance matrices of the covariates and the input data. This produces a proper distance metric and can be used upstream of any embedding procedure. On synthetic data, the proposed methods perform to the level of ctSNE as well as a second baseline sLLE-1. However, both methods are not directly meant to solve the original problem. Only JEDI and CONFETTI may factor out continuous variations (ctSNE is designed for discrete clusters). On real world data, the method seems to effectively reorganize embeddings (either of images, or of single cells) by factoring out variations of interest. ",0.22916666666666666,0.1907514450867052,0.20820189274447948
1061,SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb,The authors proposed a Bayesian graph neural network framework for node classification. The proposed models outperformed the baselines in six node classification tasks. The main contribution is to evaluate various uncertainty measures for the uncertainty analysis of Bayesian graph neural networks. The authors show that vacuity and aleatoric measure are important to detect out-of-distribution and the dissonance uncertainty plays a key role for improving performance.,"This paper proposes to model various uncertainty measures in Graph Convolutional Networks (GCN) by Bayesian MC Dropout. Compared to existing Bayesian GCN methods, this work stands out in two aspects: 1) in terms of prediction, it considers multiple uncertainty measures including aleatoric, epistemic, vacuity and dissonance (see paper for definitions); 2) in terms of generative modeling, the GCN first predicts the parameters of a Dirichlet distribution, and then the class probabilities are sampled from the Dirichlet. Training/inference roughly follows MC Dropout, with two additional priors/teachers: 1) the prediction task is guided by a deterministic teacher network (via KL(model || teacher)), and 2) the Dirichlet parameters are guided by a kernel-based prior (via KL(model || prior)). Experiments on six datasets showed superior performance in terms of the end prediction task, as well as better uncertainty modeling in terms of out-of-distribution detection.",0.208955223880597,0.09655172413793103,0.13207547169811318
1062,SP:63bd51b9796b118e53bf1bff71c405f61f210e9f,"The paper introduces a decentralized framework for adaptive momentum-based gradient descent optimizers, such as ADAM. The proposed method is novel and is among the first works to consider a decentralized communication graph without a master node. The author discovers the divergent properties of the recent work of DADAM (Nazari, 2019) and proposes a way to fix it by adding a similar consensus step for the adaptive learning rates of agents. The mathematical derivation seems to be correct to the best of my knowledge. Finally, the author tests their method on a simple CNN and show their superiority compared to DADAM to achieve a close to the centralized performance.","In this paper, the authors attempt to use adaptive gradient methods in decentralized training paradigm. They develop a general framework to convert an adaptive gradient method from a centralized one to its decentralized variant. Specifically, they propose a decentralized AMSGrad algorithm. They also point out a potential divergent problem of an existing method and investigate the conditions to ensure convergence. Finally, they conduct some experiments to verify the performance of their algorithm.",0.1743119266055046,0.2638888888888889,0.20994475138121546
1063,SP:63d27e55aee31e5c154cb6b4c7f577154d9be2ec,"Differentially private stochastic gradient descent requires clipping the gradient computed on each example before aggregation. That is, we compute the 2-norm of the gradient vector and, if it is too large, we scale it down. Surprisingly, this step entails a significant computational overhead relative to non-private stochastic gradient descent. The reasons for this slowdown are not entirely clear to me. It seems to be a software issue deep in the bowels of TensorFlow and PyTorch -- somewhere between the Python and the Hardware this operation is poorly optimized.  This paper proposes to alleviate the problem by performing approximate, rather than exact clipping. Specifically, a Johnson-Lindenstrauss sketch is used to approximate the 2-norm of the vector instead of exactly computing it. This JL approximation can be computed more efficiently than the exact norm. However, there is a tradeoff between speed and approximation quality as we can alter the dimension of the JL sketch.  Technically, the most involved aspect of this work is the privacy analysis. Since the gradients are only approximately bounded, we cannot apply the usual analysis. This algorithm does not satisfy Renyi differential privacy as there is heavy-tailed privacy loss due to the possibility of drastically underestimating the norm. Instead an entirely new analysis is required based on the recent Fourier accounting approach.  Experimental results demonstrate that there is a significant improvement in runtime. However, the privacy parameters also degrade significantly. ","This paper considers the computation and memory cost problem introduced by per-sample clipping in private gradient descent algorithms. To accelerate per-sample clipping, this paper proposed a new framework using JL projections to estimate the per-sample gradient norms. The authors provide rigorous differential privacy analysis of the proposed framework. They also give empirical evaluations of the proposed algorithms in terms of privacy, utility, and computation time.",0.08050847457627118,0.27941176470588236,0.12499999999999999
1064,SP:63f8a0b2517c67e8d33f6522e9ee0402a2ed574b,"This paper presents weakly supervised framework for image segmentation tasks with limited annotated data. It first builds several labeling functions with limited annotation and then uses probability graph to fuse the labels.  Last, the final output will be generated via CNN network.  There are two key challenges in such setting. First, how to build the labeling functions. Second, how to measure the accuracies from the labeling functions. ","This paper studies few-shot segmentation for medical images where labeled data is hard to obtain.  It proposed a stage-wise pipeline where pseudo labels are first proposed by noisy learning functions (LFs), then aggregated through a PGM, and finally used to train a segmentation model. The authors argue the two biggest challenges are ""injecting knowledge for segmentation model"" and ""measuring accuracies of pseudo labels"", and propose two modules to address them. The experiments have shown that the proposed method outperforming several few-shot learning baselines.",0.23880597014925373,0.18604651162790697,0.2091503267973856
1065,SP:640d652c3d0bdfd7a5b3e557d2cb390882183268,"- This paper claims to provide a “alternate” view of pretrained embedding as commonsense repository. But this is not a new view at all. It is well known embedding can encode commonsense knowledge, which is a reason it helps a wide variety of recent commonsense related tasks (and there has been considerable analysis on what kind of coomonsense is learned and helpful).","This paper provides an overview of methods to use embeddings for texts as common-sense knowledge. It mentions many aspects where embeddings can be used as common-sense knowledge. However, the paper lacks both novelty and in-depth analysis.  Most methods proposed are basically computing the cosine distances between language embeddings pairs and find the closest one. It's hard to imagine how to scale up this process in real applications. And most of the analyses are based on cherry-picked examples rather than evaluation with quantitative metrics. ",0.16393442622950818,0.11363636363636363,0.1342281879194631
1066,SP:64282a23a9df8092c2fc9737045a96d1ac64f4ac,"The authors introduce DiCGAN, an algorithm to learn a generative model that comes up with samples whose likelihood is based on a real dataset but adjusted given user preferences. They train the critic to assign high values to samples with higher preference values and thus the generator tends to move its samples towards these points. The idea is nice and reasonably novel in my opinion, but the paper has quite a few problems.","The motivation of this study is to estimate the distribution of desired data from the entire data distribution. And the proposed solution extends existing GAN solutions by introducing an additional pairwise loss on the discriminator, e.g., its scores on the desired instances should be higher than the undesired ones. The idea is natural and neat, and it is also proved to be effective in the reported experiments. ",0.1643835616438356,0.17647058823529413,0.1702127659574468
1067,SP:643501d344b4a7404916431d0a56aba58c354e79,"This paper proposes the alignment of cross-lingual contextual embeddings not just at the word level, but at the sense level. It does this by relying purely on unaligned, unlabeled monolingual corpora used for pre-training, along with bilingual lexica. It does this by adapting the LM objective to be a sense-aware cross entropy loss, in which the sense is obtained by the use of a streaming k-means clustering algorithm combined with dimensionality reduction. If a bilingual lexicon is available, a sense-level translation objective can be added to encourage the model to predict the same sense in the other language (thereby encouraging identical senses of a word in the two languages to be closer together). ",This paper proposes to introduce multiple senses into pre-trained models. The proposed method selects senses dynamically while pretraining the model and applies a sense-aware cross-entropy loss for pretraining. This paper further proposes to jointly pre-train a sense-aware cross-lingual model with sense-level translation. The proposed model yields better performance than the baseline models under both monolingual and cross-lingual setting. ,0.1694915254237288,0.30303030303030304,0.21739130434782608
1068,SP:643597431db07482ab2de551f78064a102b16c6c,"The paper presents a generative model for scenes that uses tree-structured latent variables to recursively decompose images into objects and parts, without any object or part supervision during training. The model is trained using variational inference. Experiments are performed on two new datasets (2D Shapes and Compositional CLEVR), demonstrating that the model is able to successfully uncover recursive scene/object/part decompositions in an unsupervised setting. The model is compared against prior work (SPACE) that performs non-hierarchical scene modeling.","Generative Scene Graph Networks (GSGN) is a variational auto-encoder with the intermediate representation being tree-like scene graphs. The leaf nodes stand for primitive parts and edges stand for poses to compose parts into objects recursively. The experiments are done in two image datasets of single color, simple shape 2D/3D objects: Multi-dSprites and CLEVR, and the model is able to discover objects without supervision.",0.2222222222222222,0.26865671641791045,0.24324324324324326
1069,SP:64794a022e18c8cee6599446d5846dd00bc0b8ab,"This paper presents a self-training algorithm based on GCN to improve the semi-supervised node classification on graphs. The key idea is to add new nodes with high confidence as supervision to enlarge the labeled nodes. Although the experimental results show the proposed method outperforms or performs similarly to baseline methods, the paper has several weaknesses. First the presented approach is not clearly introduced, with inconsistent statements on building the checking part, and lack of details on how to calculate the confidence to add the new nodes. Second, the novelty of the presented approach is limited, as adding unlabeled samples with high confidence is not a novel idea. Third, the paper writing should be improved, as there are errors.  ","This paper proposes a self-training based semi-supervised framework for node classification using Graph Neural Networks when the amount of labelled data is very limited. Self-training is performed by incorporating highly confident samples with their corresponding predicted class as the pseudo label. Authors show that incorporation of correct pseudo labels is a crucial step as the performance degrades rapidly with the incorporation of wrong labels. This work ensures high quality of pseudo labels by a ""checking part"" with feature aggregation. Aggregated features with linear SVM performs comparably with GNN methods.",0.18333333333333332,0.2391304347826087,0.20754716981132076
1070,SP:6489b2a3fe7c2893a1ab5e9cd6030c22cd99e697,"This paper considers the issue of distribution mismatch between the input data used for training generative models and the new data for new instance generation. Given a sample operation, the authors propose to use the so-called optimal transport to map the distribution of the new data to that of the input data that were used training. The optimal transport is essentially a monotonic transformation as the composite of the inverse of the target distribution and the source distribution.","Noticing that widely used latent code interpolations for exploring the generative capabilities of VAEs and GANs have distribution mismatch problems, this paper proposes to utilize monotone transport map to exactly eliminate the distribution mismatch between modified interpolated codes and a prior distribution, assuming I.I.D. code components and a L1 code distance. More precisely, a transformation of the latent space operation is learnt with the objective that the distribution of the transformed variable match the prior distribution used in training the generative models. Optimal transport is used as a measure to minimize the two distributions. By restricting the class of cost functions used in the optimal transport formulation, the solution to the optimal transport problem (and hence the transformation function) has been shown to take a simple form (closed form in cases where cdf has a analytical form). Experiments on CIFAR-10, LLD-icon, LSUN, CelebA datasets show that, the minimally modified interpolated codes for several different interpolations produce samples with higher Inception Scores and better visual effects under an improved Wasserstein GAN than the original interpolated codes.",0.35443037974683544,0.1564245810055866,0.2170542635658915
1071,SP:648c9f61876219050edc481d57891ec3465617d3,"This paper introduces a network architecture search (NAS) suitable for a feature pyramid network (FPN) that provides notable detection accuracy for objects at every scale. Based on the decomposition of FPN structure as (multi-scale) feature generation and feature utilization, the proposed NAS offers a new design strategies for both components. For feature generation, NAS super-net is trained to find the optimal selection of whether to reduce, maintain, or extend feature resolution after each module. For feature utilitization, it defines conditions for efficiently selecting the optimal FPN architecture. The proposed MSNAS yields the better accuracy than its backbone FPN and other NAS methods on the COCO object detection benchmark dataset.","This submission works on the task of architecture search for object detection. The authors focus on two components: how to produce multi-scale features and how to use multi-scale features. The authors formalized a simple search space, and applied an evolution-based search algorithm. Experiments show the proposed searching algorithm is able to outperform the FPN baselines with various (small) backbones.",0.13513513513513514,0.24193548387096775,0.17341040462427748
1072,SP:6493d8b1a276e9fe0fde56dba69d5308ae117f2d,"Authors present a novel regularizer to impose graph structure upon hidden layers of a neural Network. The intuition is that Neural Networks has typically  symmetric computation among different channels in one layer. Due to the lack of order, visually inspecting the hidden representation is not feasible. By adding edges one can impose a structure upon nodes in one layer and add for example a Laplacian regularizer rather than simple L2 norm regularizer to force the activations to follow the imposed structure. ","Authors highlight the contribution of graph spectral regularizer to the interpretability of neural networks. Specifically, authors consider the Laplacian smoothing regularizer to enhance the local consistency/smoothness between a neuron and its neighbors. Furthermore, by extending the graph Fourier transformation to overcomplete dictionary representation, authors further propose a spectral bottleneck regularizer. Experimental results show that when suitable structural information and corresponding regularizers are imposed, the interpretability of the intermediate layers is improved.",0.1728395061728395,0.19444444444444445,0.18300653594771243
1073,SP:64afac7388471f9ecc2ea9a47befeda6e7fd0703,The authors study the problem of finding the top $k$ right singular vectors of a data matrix $X$. They propose a modification of an established game theoretic gradient based algorithm $\alpha$-EigenGame. They observe that the gradients of $\alpha$-EigenGame are biased when implemented stochastically by subsampling the data matrix $X$. Their proposed modification guarantees unbiased updates while converging to the true singular vectors. Their modified updates in combination with their data parallel distrusted algorithm leads to significantly improved convergence rates.  ,The paper considers PCA problem from a game-theoretic view and propose a novel algorithm ($\mu$-EigenGame) with stochastic convergence guarantees. The proposed method introduces an unbiased update which allows greater parallelism over data. The empirical results show that $\mu$-EigenGame outperforms its predecessor $\alpha$-EigenGame.,0.13580246913580246,0.2391304347826087,0.1732283464566929
1074,SP:64da35ba47ea28883a1828aa80926f57b037332f,"I believe that the main contribution is that the paper shows that albert-xxlarge-v2 is the best zero-shot model on the commonsense datasets (out of multiple models available in huggingface that are being evaluated). However, the authors also seem to argue against finetuning as a general approach for commonsense reasoning, though I don't see how this is backed up by the paper (except for maybe the small experiment with 20 sentence pairs?). ","The paper makes multiple independent contributions, including:  1. The addition of a new adversarial common-sense reasoning dataset dubbed “Winogradversarial” 2. The explicit gathering together of multiple research threads all exploring the use of pretrained language models for zero-shot prediction on language-understanding tasks 3. The singling-out of the albert-xxlarge-v2 architecture as performing especially well on zero-shot common-sense reasoning tasks, achieving SOTA on the TimeDial dataset  The overall message of the paper is that the existing framework of fine-tuning models for common-sense reasoning tasks is flawed and prone to overfitting, and that more robust results can be achieved using pretrained models in a zero-shot manner. In particular, doing so with the albert-xxlarge-v2 model achieves state-of-the-art performance on some benchmarks. ",0.22666666666666666,0.12781954887218044,0.16346153846153846
1075,SP:650494d831e1b4a0bb8f51b21574f233b1e18986,"The paper considers the problem of how to provide a collection of counterfactual explanations for a binary linear classifier such that an informed choice can be made on how best to actualise a new input based on individual preferences such that a different classification is likely to be made, even under potentially changing model parameters. It introduces the Counterfactual Plan under Ambiguity (COPA) framework, consisting of a probabilistic validity assessment of a predetermined plan under a given parameter distribution of the classifier, followed by a correction of the predetermined plan to improve validity under that distribution. These are combined in the COPA framework to produce a plan that optimises a weighted combination of the desiderata ‘proximity’, ‘diversity’ and ‘validity’. Experiments show the resulting output satisfies the derived upper and lower bounds on the validity, with good performance on the desiderata. ","This paper studies the effect of uncertainly in the parameters of an ML model used for consequential decision making on the validity, proximity, and diversity of sets of counterfactual explanations (CFE), namely counterfactual plans. In particular, the paper assumes the model parameters are sampled from a distribution would known mean and covariance, and studies the aforementioned metrics of counterfactual plans when the parameter distribution changes in a bounded manner (according to the Gelbrich distance). Beyond a diagnostic tool (providing bounds on how much the parametere distribution can change), the paper presents a method for counterfactual plan correction after having generated a plan (ex-post), and an approach to generate robust counterfactual plans before the fact (ex-ante). Experiments are presented for the proposed methods.",0.16428571428571428,0.18548387096774194,0.17424242424242423
1076,SP:650d7f17c93a91cce9f886766671ed19044deecd,"This paper proposes to use an uncertainty-weighted objective for offline RL with BEAR (Kumar et al.) that penalizes the MMD distance between the learned policy and the previous policy. The uncertainty weighted objective weights the policy improvement objective with the variance in the Q-function, where this variance primarily represents aleatoric or intrinsic uncertainty, not the epistemic or belief uncertainty. They show that their method performs reasonably better than prior methods on the D4RL datasets and show that the learned Q-values are better than BEAR.","This paper considers the problem of dealing with uncertainty for static datasets in offlineRL. The authors propose a novel algorithm ‘UWAC’, uncertainty weighted actor-critic. UWAC takes a Bayesian perspective of RL, and uses Monte Carlo dropout for detecting, down-weighting OOD samples. Building on BEAR, they estimate the epistemic uncertainty as the Var(Q(s, a)), and modify the update to downweight samples with higher variance. On D4RL datasets, UWAC seems to perform competitively against model-based baselines like MOPO, model-free baselines like BEAR/CQL.",0.1839080459770115,0.1839080459770115,0.1839080459770115
1077,SP:652c65bc4ad22362de934a265d23ae6185ac1a39,"The paper has two distinct parts. In the first part (section 2) it studies the volume of preimage of a ReLU network’s activation at a certain layer as being singular, finite, or infinite. This part is an extension of the work in the study of (Carlsson et al. 2017). The second part (section 3) builds on the piecewise linearity of a ReLU network’s forward function. As a result, each point in the input space is in a polytope where the model acts linearly. In that respect, it studies the stability of the linearized model at a point in the input space. The study involves looking at the singular values of the linear mapping. ",This paper presents an analysis of the inverse invariance of ReLU networks. It makes the observation that one can describe the pre-image of an image point z = F(x) using linear algebra arguments. They provide necessary conditions for the pre-image to be a singleton or a finite volume polytope. They also provide upper-bounds on the singular values of a train network and measure those in standard CNNs.,0.1391304347826087,0.22857142857142856,0.17297297297297298
1078,SP:655be2d7f8ffe68416e0c3a5b4218ffe45a37bfc,"This paper experimentally investigates how fast the generalization error decreases when some specific kernel functions are used in real datasets. This paper conducted numerical experiments on several datasets to investigate the decreasing rate of the generalization error, and the rate is determined for such datasets. This decreasing rate is theoretically analyzed by using the approximation theory of RKHS in the teacher-student setting. It is shown that the rate is determined with the smoothness and effective dimensionality of input. Then, the smoothness of the teacher function is also derived through this analysis.","This paper studies, empirically and theoretically, the learning rates of (shift-invariant) kernel learners in a misspecified setting. In the well-specified setting, the rate of kernel learners is at least $n^{-1/2}$, and in a misspecified setting assuming only Lipschitz targets, the rate is $n^{-1/d}$. Neither seems to match the experimental rate on MNIST and CIFAR-10; this paper proposes a theoretical model that can more-or-less match the experimental rate with essentially-reasonable assumptions.",0.18478260869565216,0.2125,0.19767441860465115
1079,SP:658a4b376dcab0ebcde076f72991b170d4ff14e7,"This paper empirically studies various CNN robustifying mechanisms aiming to achieve rotational invariance. The main finding is that such robustifying mechanisms may lead to lack of robustness against pixel-level attacks such as FGSM and its variants. The paper does a comprehensive job in studying relevant robustifying schemes and attacks strategies. However, the paper does not present sufficiently new information worthy of a regular conference paper, it can be a good workshop paper though for the Robust Learning community. Some analytical insights would really strengthen the work. Also, from an empirical standpoint, the authors need to consider other data sets beyond just the MNIST data set.   ","Using the dataset MNIST, the authors empirically studied the robustness of several rotation-equivariant neural network models(GCNN, H-Nets, PTN, et al.) to geometric transformation and small pixel-wise perturbations. Their experiments showed that the equivariant network models(StdCNNs, GCNNs, H-Nets, et al.) are robust to geometric transformation but vulnerable to pixel-wise adversarial perturbations. These findings help us understand the  neural network models better.",0.07547169811320754,0.11940298507462686,0.09248554913294797
1080,SP:65c40a7c183c8bdf5dfdd69bd6beb48ce29b1e19,"This paper attempts to solve the problem of non-differentiable connection between the generation and discriminator of a GAN. The authors come up with an estimator of the gradient for the generator from the gradient of the discriminator, which was disconnected previously. With this change, the model should be able to  select better tokens than random selection, which could leads to more robust training. The experiment results on both COCO Image Captions and EMNLP 2017 News datasets justify the authors' argument. ","The submission proposes to train a GAN on discrete sequences using the straight-through Gumbel estimator introduced in Jang et al. (2016) in combination with gradient centering. The proposed approach is evaluated on COCO and EMNLP News in terms of BLEU and Self-BLEU scores, Fréchet Embedding Distance, Language Model Score, and Reverse Language Model Score.",0.14814814814814814,0.21052631578947367,0.17391304347826086
1081,SP:65cf439b128b8b7e2596b065df7c9294b408ed19,"The paper considers the problem of finding the optimal policy in the Markovian decision Processes, where a KL policy regularizer is added to the objective function. Instead of the closed form solution which leads  to the KL-regularized Bellman equation the paper proposes to use an incremental gradient ascent algorithm. The paper recommends an iterative policy gradient scheme to  optimize this  objective function. There exists a substantial literature on the subject of KL-regularized RL as well as using the  policy gradient algorithms  to optimize this objective function using policy gradient schemes (See all variants of KL(entropy)-constraint actor-critic or reinforce algorithms, e.g. A2C, IMPALA,...). Unfortunately the paper doesn’t provide any comparison with those methods. In the absence of those comparisons the significance of this work to the literature of RL is not clear, as it is not solving an open problem which hasn't addressed before, neither it  provides theoretical/empirical evidence that it has advanced the start-of-the-art in terms of providing a more efficient solution.","This work proposes a policy iteration algorithm that implements full-depth, full-width backups in contrast to one-step, full-width methods. The authors go over existing algorithms and talks a bit how their proposal conceptually differs in how it performs said backups. They provide a bit of intuition to help explain their algorithm's derivation. Finally, they provide a few experiments showing that their algorithm works.",0.05747126436781609,0.14925373134328357,0.08298755186721991
1082,SP:65e92cbe15e2f0237433a41149d1d68ded0cc51c,"In this paper, the authors provide a new interpretation of existing video compression models. Their perspective is that a video decoder is a stochastic temporal autoregressive model with latent variables. The introduced latent variables could be either used for providing more expressive power for 1) motion estimation&compensation modeling and 2) residual noise modeling, which are two key components of traditional video codecs. The proposed method shows favorable results when the bitrate is higher than 0.12 bits per pixel on the public benchmarks.","In this paper, the authors focus on the problem of lossy video compression. To this end they propose the application of latent variable sequential generative models, specifically autoregressive flows to compress video streams. They evaluate variations of these models quantitatively including their own proposed version of scale space flow. They also introduce a new dataset named Youtube-NT and show promising quantitative performance.",0.14285714285714285,0.19047619047619047,0.16326530612244897
1083,SP:6613614b72eb91be6cbc618e3f07330dbcbe68e8,"This paper introduces a new supervised dimensionality reduction model. Supervision is provided in the form of class probabilities and the learning algorithm learns low-dimensional representations such that posterior cluster assignment probabilities given the representations match the observed class probabilities. The representations can be learned directly or the parameters of a neural network can be learned which maps inputs to the lower-dimensional space. The authors provide an extensive theoretical analysis of the proposed method and evaluate it on dimensionality reduction, visualization, and zero-shot learning tasks.","Authors propose a method of embedding training data examples into low-dimensional spaces such that mixture probabilities from a mixture model on these points are close to probability predictions from the original model in terms of KL divergence. Authors suggest two use-cases of such an approach: 1) data visualization, and 2) zero-shot learning. For the visualization use-case, authors compare against other dimensionality reduction methods with qualitative analysis on a synthetic problem, as well as evaluation metrics such as Neighborhood-Preservation Ratio and Clustering Distance Preservation Ratio. For zero-shot use-case, they take pre-trained models on two zero-shot tasks, and improve the accuracy by using probability outputs from pre-trained models as target.",0.21839080459770116,0.16101694915254236,0.18536585365853658
1084,SP:66169cd52e7746d7ca61a767f7ae2c1693727025,"This paper proposes a method to quantify the complexity of a learning task. The paper is motivated from the “20 questions“ game where an agent computes the answer (label) via a sequence of questions asked on the input data with answers given by an Oracle (simple functions of the data, in this case). The authors formalize this process and define the complexity of a learning task as the smallest number of questions from a given set Q necessary to predict the labels accurately averaged across the dataset. Information Pursuit (IP) of Geman & Jedynak 1996 is used to instantiate this definition using variational and normalizing-flow based models to learn the conditional distributions. Experimental results are shown for MNIST, Fashion-MNIST, KMNIST and Caltech Silhouettes datasets.","The paper claims that existing measures of complexity such as entropy are not suitable for measuring task complexity since they focus on the complexity of X rather than the predictive relationship from X to Y. The paper argues that mutual information is not useful for comparing different learning tasks, as two tasks (MNIST vs Fashion-MNIST) can have similar MI but intuitively different complexity (second-to-last paragraph in related work). The paper proposes a measure for task complexity based on the number of queries required to predict a label of an input. The form of the queries is not specified, and the provided examples include half-space queries, single feature (decision-tree-like) queries, or high level semantic queries.  The proposed method instead considers a query generator E, then encoding X as the answers to the sequence of queries generated by E, and predicting Y from the answers. The complexity of a task is related to the number of equivalence classes induced by the input X and the query generator E.",0.224,0.16279069767441862,0.18855218855218855
1085,SP:661b75d2b9213295a69ab5f524c6983c67e783ec,This paper is about risk-sensitive RL based on the CVaR risk measure. This paper is mainly based on the work presented in Dabney et al. in 2018 which is about distributional RL for a family of risk measures which includes CVaR as well. The main motivation for this work was the point that the method presented in Dabney et al. 2018 overestimates the dynamics and could be excessively conservative in certain scenarios. Authors have proposed to use static CVaR instead and have developed algorithms to do that.,"This paper consider the problem of learning a risk-averse policy base on CVaR measure using distributional reinforcement learning. The main contributions of this paper are twofold. First, they show that the standard distributional RL algorithm overestimate the dynamic, Markovian CVaR, which might be too conservative. Secondly, they propose a modified algorithm that can learn a proper CVaR-optimized policy based on static, non-Markovian CVaR. ",0.19318181818181818,0.25757575757575757,0.22077922077922077
1086,SP:662edd2fd9437de887821ebf7de06415eba13fae,"Motivated by the observation that powerful deep autoregressive models such as PixelCNNs lack the ability to produce semantically meaningful latent embeddings and generate visually appealing interpolated images by latent representation manipulations, this paper proposes using Fisher scores projected to a reasonably low-dimensional space as latent embeddings for image manipulations. A decoder based on a CNN, a Conditional RealNVP, or a Conditional Pyramid PixelCNN is used to decode high-dimensional images from these projected Fisher score.  Experiments with different autoregressive and decoder architectures are conducted on MNIST and CelebA datasets are conducted. ","This paper focuses on the problem of interpolating between data points using neural autoregressive models. The core idea is that it is possible to use (a smaller-dimensional projection of) the Fisher score of the density function defined by the autoregressive model to represent data points in embedding space, and a neural decoder for mapping them back to input space. Experiments on both MNIST and Celeb suggest that this is a sensible method, and leads to smoother interpolations rather than just relying on the embeddings resulting from the network activations.",0.16304347826086957,0.16666666666666666,0.16483516483516483
1087,SP:664054eccfdebcb9ea3ac78f3d89501dc3f8a352,"The paper proposed a gradient-based algorithm GBMS to solve PDEs based on the solutions of other similar problems. In GBMS, a network is trained to produce good initial guess for the iterative solver of the PDE. Numerical experiments are performed to show the effectiveness of the method.","This paper proposes leveraging data from previous problem instances to improve efficiency of solving similar ones in the future. A general gradient-based method is proposed, which is applied to generating initial guesses to differential equation solutions. This problem is formulated as a meta-learning problem. ",0.20833333333333334,0.21739130434782608,0.2127659574468085
1088,SP:664b4cc73449713aac9e5e0d40027993d7a17c3a,"This paper proposes as solution to manage the case where gradients are conflicting in gradient-based Multi-Task Learning (MTL), pointing to different directions. They propose a simple “gradient surgery” technique that alters the gradients by projecting a conflicting gradient on the normal vector of the other one, in order to mitigate the effect. The method is generic in the sense that it can be directly applied to various gradient-based architectures easily.","The paper presents a method to boost multi-task learning performance by editing gradient to remove conflicts between tasks. The main idea is to use cosine similarity to 1) determine if two task gradients conflict and 2) to project one conflicting gradient to the normal plane of the other, thereby removing the conflict at the expense of disturbing the other gradient to some extent. Experiments are presented for classification and other computer vision tasks along with reinforcement learning problems.",0.2602739726027397,0.24050632911392406,0.25
1089,SP:668a13137e2d0f2dd7e7f9de5e72118d9a7eb5df,"This paper investigates how to improve the test time performance of learned image compression models through finetuning of the full model. The authors finetune the model (both the model parameters and the prior on the latent space) for every test-time instance, appending the model updates to the bitstream. The model updates are coded according to a discretised, mean-zero Gaussian distribution with a single learned variance. They demonstrate that this approach yields a superior rate-distortion curve than the non-finetuned model on a set of I-frame video data.","The paper describes an instance specific finetuning method for image and video compression including finetuning the decoder. Based on the shown experiments, the required additional bits for sending the updated finetuned model parameters are worth the achieved increase in RD performance. However, the method has only been evaluated on one video dataset and with respect to its own baseline and not with respect to any other existing method.",0.15384615384615385,0.20588235294117646,0.1761006289308176
1090,SP:66a3dbe015b07649121b664fbb28c7e198b0282d,"The current paper deals with meta-learning and essentially proposes a generalization of MAML (a popular gradient-based meta-learning algorithm) that mostly builds upon two main recent advances in meta-learning: 1) an architectural one (see e.g. T-Nets), which consists in optimizing the parameters of additional layers during the meta-learning outer loop (as opposed to only optimizing the initial conditions of the original parameters like in MAML), and 2) a theoretical one (see e.g. Meta-SGD, Meta-curvature), which is based on the geometrical observation that one set of parameters can precondition a second set of parameters that are consequently being optimized in a ""warped"" geometry, possibly speeding up learning.","The authors propose warped gradient descent (WarpGrad) an optimisation framework for facilitating gradient-based meta-learning. WarpGrad interleaves within the learner meta-learned warp-layers that implicitly precondition the gradients of the task-specific parameters during backpropagation. In contrast to the linear projection layers employed in T-Nets, warp-layers are unrestricted in form and induce a full Jacobian preconditioning matrix. The warp layers are meta-learned in a trajectory-agnostic fashion, thus obviating the need to backpropagate through the gradient steps to compute the updates of their parameters. The framework is readily applicable to standard gradient-based meta-learners, and is shown to yield a significant boost in performance on both few-shot and multi-shot learning tasks, as well as to have promising applications to continual learning.",0.19130434782608696,0.17054263565891473,0.18032786885245902
1091,SP:66d433dfb2512bdb004f50f94d38514636a89fc6,"In this article, the authors revisited the idea of *effective dimensionality* as a complexity measure for large-scale machine learning systems, and in particular, modern deep neural networks. Theoretical arguments were provided for linear and generalized linear models (Theorem 4.1 and 4.2). Connections were made between the proposed effective dimensionality and the double descent phenomenon, width-depth trade-off, function-space homogeneity, and other generalization measures in the literature. Experiments on linear models as well as deep networks (ResNet18) were provided to support the effectiveness of the proposed metric.","The paper applies the effective dimensionality (introduced by MacKay, Gull and others) to study the generalization properties of large probabilistic models. Effective dimensionality is the number of parameters determined by the data (derived from the curvature of the posterior at the MAP estimate), and shown to be more informative than simple parameter counting. After demonstrating the usefulness of the effective dimensionality, the authors study double descent observed when training deep nets of increasing width/depth. The authors argue that double descent is an artifact that can be understood by studying the effective dimensionality of the model. They take a detailed look at width-depth trade-offs using numerical experiments. Moreover, they compare the effective dimensionality with other generalization measures and find a superior performance. ",0.2087912087912088,0.1532258064516129,0.17674418604651165
1092,SP:66df426d54b2965855f955ec2946f5304b974ef5,"This manuscript proposes to reduce the intensive computation and memory requirement in reinforcement learning trainings by freezing the parameters of lower layers early. Besides, the authors also propose to store the low-dimensional latent vectors rather than the high-dimensional images in the replay buffer for experience replay. The effectiveness of the proposed techniques is evaluated on DeepMind Control environments and Atari. The motivation for this work is strong, and the results are impressive. However, the proposed technique is described in a very general way without clearly defined applicable conditions and specific design methods. Below are detailed comments and questions.","This work proposes LeVER, a method that modifies general off-policy RL algorithms with a fixed layer freezing policy for early embedding layers (in this particular case, a few early layers of a CNN). As a direct consequence, the method enables to store embeddings in the experience replay buffer rather than observations, with a potential decrease in memory required, as well as providing a boost in clock time due to fewer gradient computations needed for every update. The method is benchmarked with a couple of off-policy RL algorithms against a few different environments.",0.16,0.1702127659574468,0.16494845360824742
1093,SP:6707e0b6e307f247bb8fcbaa126ce6693c447387,"The paper presented a differentiable approximation to splines for use as a differentiable layer in differential programming. The main idea is to exploit the sparsity of the resulting Jacobian matrix for the spline approximation operation, and to use a Guassian approximation for the non-differentiable Direc delta spike functions from the Cox-de Boor base function. The authors used this differentiable spline approximation in three application settings: 2d image segmentation; 3d surface fitting for point clouds using NURBS, and solving a PDE (Poisson Equation).","The paper presents sparse Jacobians/backward algorithms for several spline formulations and motivates their use in differentiable algorithms. The formulations include general splines, NURBS, and basis functions for FEM solvers.  The resulting differentiable modules are applied to the three proof of concept tasks of image segmentation, point cloud reconstruction, and solving Poisson equations, where they show promising results.",0.21428571428571427,0.3103448275862069,0.2535211267605634
1094,SP:672b4b380be73c57e2e7fd3d9f7ea8af0d98f6d1,"In this paper, the authors proposed to identify noisy training examples using ensemble consensus. The authors argued and demonstrated through numeric studies that, to the contrary of some earlier work, training examples with low training loss are not necessarily mislabeled. Rather, the authors hypothesized that examples with high noise require memorization, which is sensitive to perturbations. Thus, the authors proposed to identify and subsequently remove those examples from training by looking at the loss after small perturbations to the model parameters. Examples with consistently low training loss are retained for training. The authors also provided several alternatives of perturbations, including examining the consensus between an ensemble of networks, between multiple stochastic predictions, or between predictions from prior training epochs. Finally, the authors demonstrated the performance of their procedures using numerical studies.","This paper proposes a general method for eliminating noisy labels in supervised learning based on the combination of two ideas: outputs of noisy examples are less robust under noise, and noisy labels are less likely to have a low loss. The authors then propose 3 concrete instantiations of the idea, and do a thorough empirical study (including ablations) across multiple architectures, datasets, noise types, and comparing to multiple related methods. The results show pretty convincingly that one of the new methods (LTEC) that uses past networks outputs to build an ensemble performs really well.",0.1450381679389313,0.20212765957446807,0.1688888888888889
1095,SP:674372d2a8bfd6460e61cf6d39f85a9128cdf131,"The paper proposes a novel way of reconstructing Granger causal structures using a differentiable neural network architecture that contains attention modules that are proportional to the Granger causality of the input layers. Furthermore, the architecture blends individual-specific induced causal structures and cross-population prototypical causal structures. The paper has an extensive experimental section on which the proposed method shows impressive improvements in causal discovery performance and predictive performance on par with state-of-the-art.",This paper proposes a new way of finding the Granger temporal-causal network based on attention mechanism on the predictions obtained by individual time series. It describes a surprisingly complex procedure for computing the attention vector based on combining Granger-inspired attentions with attentions obtained during a diverse prototype generation process. There are also extensive experiments demonstrating the success of the proposed method in uncovering the underlying temporal-causal graph.,0.23684210526315788,0.2571428571428571,0.2465753424657534
1096,SP:6756185c40a7b21ad0227438da812184ab470195,"This paper proposes a joint Wasserstein Auto-Encoder (JWAE) method to solve the problem of joint distribution matching. Instead of ﬁnding a coupling, the paper seeks a decoupling to make the primal problem of Wasserstein distance tractable. The decoupled version of joint Wasserstein distance is used for empirical reconstruction losses of within-domain Auto-Encodings and cyclic mappings. In addition, two GAN divergences are used to learn the cross-domain mappings such that the generated distributions are close to the real distribution, and another GAN divergence is imposed to align the latent distributions generated by two Auto-Encoders. Later, the paper applies the proposed model on the interpolation based video-to-video synthesis problem. ","This paper studies the joint distribution matching problem where given data samples in two different domains, one is interested in learning a bi-directional mapping between unpaired data elements in these domains. The paper proposes a joint Wasserstein auto-encoder (JWAE) to solve this problem. The paper shows that under the decomposable cost metric and deterministic decoding maps, the optimization problem associated with the JWAE formulation can be reduced to a tractable optimization problem. The paper also establishes a generalization bound for the JWAE formulation. Finally, the paper conducts an experimental evaluation of the proposed solution with the help of a video-to-video synthesis problem and show improved performance as compared to the existing results in the literature.",0.2719298245614035,0.2605042016806723,0.26609442060085836
1097,SP:677142c2fc75609c7728334a2adeebf0b4620453,"The paper proposes to use the distributionally robust learning (DRL) for unsupervised domain adaptation. First, the authors demonstrate how differentiable density ratio estimation can be done for source and target domains in an end-to-end manner. Following this, the authors demonstrate how confidence estimation (reliant on DRL) can be utilized for self-training based approaches for unsupervised domain adaptation. In terms of results, the authors show that the proposed approach — Distributionally Robust Self-Training (DRSL) — can provide competitive performance on t he VisDA 2017 benchmark. Furthermore, DRSL is able to achieve more calibrated probabilities (useful for more calibrated uncertainty measures) with competitive predictive performance. Finally, the authors provide some intuition as to why DRSL results in increasingly aligned conditional source and target distributions due to increased focus on learning shape features.","I find the paper to be well motivated. Self-labeling has proven to be a useful approach for unsupervised domain adaptation. And since wrong pseudo-labels in the target domain result catastrophic failure in early iterations, it makes sense to calibrate the production of pseudo-labels through the use of uncertainty estimation. This is done through the framework of distributionally robust learning. ",0.13636363636363635,0.2903225806451613,0.18556701030927836
1098,SP:677691c9f540dbcb7169e0009bd5ee1d3d6b14d8,This paper is addressing the gradual domain adaptation (GDA) problem without the access of intermediate domain indices. This paper proposes a coarse-to-fine method to predict the indices of the intermediate domain sequence. The results are shown to be comparative to pre-defined methods. ,"This paper is concerned with gradual domain adaptation, when we have access to data from intermediate distributions between source and target and use them to gradually adapt the model through self-training. To address the challenge of lack of intermediate data annotated and grouped based on their distance to the source domain, the paper proposes IDOL (Intermediate Domain Labeler) to index unlabeled available data that presumably covers the gap between source and target  domains based on their distance to source.  IDOL consists of two steps: 1. A progressively trained domain discriminator is used to assign a score to each example. (a higher/lower score indicates that the example is closer to the source/target domain). 2. A model based on a cycle-consistency loss is applied to refine the coarse scores progressively. The main idea is to group examples into intermediate domains such that enough discriminative information is preserved that we could approximately regain the accuracy on the source domain by consuming the intermediate domains in the reverse direction..   **Empirical results**: Experiments on  Rotated MNIST and Portraits indicate that with IDOL we can achieve comparable performance on gradual domain adaptation as when we have the ground truth (pre-defined) domain sequences. Furthermore the experiments indicate that applying IDOL on pre-defined domain sequences, treating them as the outputs from step 1, and refining them through step 2 can lead to domain sequences that are better suited for gradual domain adaptation. In general, it seems that applying IDOL in many cases with partial or noisy annotation of the intermediated domain sequences can be beneficial.  Finally, IDOL is also compared with UDA on CIFAR10 to STL tasks, indicating superiority of both (GDA + confidence) and (GDA + IDOL) to UDA in this setting. ",0.5333333333333333,0.08304498269896193,0.1437125748502994
1099,SP:67a5ff36ee4df5da8185f078c826943f5c101898,"This work proposes to extend latent state-space models (SSMs) with a latent variable that changes the dynamics. Update equations akin to Kalman filtering are provided, along with a training loss and method. Experiments on several robotics tasks appear to indicate that the method performs well relative to alternative methods that do not consider latent dynamics differences (up to the points below).","The paper proposes a method to learn a probabilistic recurrent state-space model for time-varying dynamics. The proposed method combines the Kalman filtering-based update rule with deep network-based encoder and decoder model. Effectively, the method can be used to replace RNN cells in a recurrent model, and is shown to outperform baseline models in modeling various robotic tasks.",0.20967741935483872,0.21311475409836064,0.21138211382113822
1100,SP:67ab253f6a6956136bbb413118bb1b160fddd85b,"This paper investigates the time-evolution of weights in normalized neural networks (e.g. one in which every layer has batch-norm applied). It proposes theorems regarding convergence to equilibrium, in which the norm of the weights approaches a fixed value. Compared to prior work, which established the fixed value, this work additionally gives the approach rate, and the scale of the variance due to stochastic gradients. The paper introduces the angular update parameter, and shows this approaches a fixed value. The paper emphasizes that equilibrium is not reached immediately, but is approached dynamically. It also asserts that equilibrium is not about convergence of stochastic oscillations to zero, but instead convergence to a fixed value, up to oscillations. The theoretical results are then investigated empirically, showing agreement with theoretical results for the weight norm and angular update, and the dynamical approach to equilibrium. ","In this paper, the dynamics of scale-invariant (SI) weights of normalized neural networks trained with SGD(M) + WD are studied. It is known that the scale-invariant parameters' intrinsic domain is a unit hypersphere, which the authors have effectively taken into account by introducing the ""angular update"" (AU) term, and the gradients w.r.t. SI parameters 1) scale inversely proportional to parameters norm and 2) are orthogonal to the radial direction in parameter space: the first property compels to introduce a unit gradient term and condition the dynamics of SI parameters on the intrinsic domain, the second one, together with weight decay, gives birth to the main concept of the paper &mdash; Spherical Motion Dynamics (SMD). Important attainment of this work is that, in contrast to the prior art, the notion of SMD equilibrium is not static (i.e., when $\Vert w_{t} \Vert_2 = \Vert w_{t+1} \Vert_2$) but represents a dynamic state when parameters norm oscillates around its theoretical value determined by hyperparameters and (generally varying) unit gradient norm. Interestingly, despite the dynamic nature of the equilibrium in terms of weight norm, the authors have shown that AU, in contrast, becomes approximately constant with its value only dependent on hyperparameters: learning rate, weight decay, and momentum factor. The authors corroborate their theoretical findings with experiments involving different computer vision tasks and networks architectures. They also provide an intriguing view on overfitting from the SMD perspective: when the learning rate drops, test error sometimes increases which could be interpreted as escaping from the local minimum due to an increase in the angular update.",0.2727272727272727,0.1455223880597015,0.1897810218978102
1101,SP:67c44f33dff59e4d218f753fdbc6296da62cdf62,"This paper compares SGD and SVRG (as a representative variance reduced method) to explore tradeoffs. Although the computational complexity vs overall convergence performance tradeoff is well-known at this point, an interesting new perspective is the comparison in regions of interpolation (where SGD gradient variance will diminish on its own) and label noise (which propogates more seriously in SGD vs SVRG). The analysis is done on a simple linear  model with regression, with some experiments on simulations, MNIST, and CIFAR.","This paper examines the tradeoffs between applying SVRG and SGD for training neural networks by providing an analysis of noisy least squares regression problems as well as experiments on simple MLPs and CNNs on MNIST and CIFAR-10. The theory analyzes a linear model where both the input $x$ and label noise $\epsilon$ follow Gaussian distributions. Under these assumptions, the paper shows that SVRG is able to converge to a smaller neighborhood at a slower rate than SGD, which converges faster to a larger neighborhood. This analysis coincides with the experimental behavior applied to neural networks, where one observes when training underparameterized models that SGD significantly outperforms SVRG initially, but SVRG is able to attain a lower loss value asymptotically. In the overparameterized regime, SGD is demonstrated to always outperform SVRG experimentally, which is argued to coincide with the case where there is no label noise in the theory.",0.2125,0.11409395973154363,0.14847161572052403
1102,SP:67dc5fd18a98a3b90a64a97536056688fb60d53f,The contribution of the paper is in proposing a quantitative measure of memorization based on the assumption that the activations at the deeper layers of a *generalizing* deep network should be invariant to intra-class variations. The measure corresponds to how well can the activation matrix of a batch be approximated by a low-rank decomposition. The paper proposes to use approximate non-negative matrix factorization and compares it to PCA. As for “wellness” it uses the final accuracy of the network after the activation is approximated in some layer(s).,"This paper aims to distinguish between networks which memorize and those with generalize by introducing a new detection method based on NMF. They evaluate this method across a number of datasets and provide comparisons to both PCA and random ablations (as in Morcos et al., 2018), finding that NMF outperforms both. Finally, they show that NMF is well-correlated with generalization error and can be used for early stopping. ",0.12087912087912088,0.15942028985507245,0.1375
1103,SP:67eedd76711109b15ff897d047a20276d00479f1,"The authors consider the problem of re-ranking an initial ranker that doesn’t consider interactions between items (e.g., a point-wise ranker) with a pointer-network approach that considers these interactions when re-ordering the input ranking. Notably, this is performed during decoding as opposed to {pairwise, list-wise} learning to rank approaches that consider interactions during training, but emit an item-wise score during inference. Operationally in practice, this has to be trained from click-through data for which the authors consider both a RL approach (Reinforce) and supervised training (a sequence-level hinge loss function) and decoded either with a single-step greedy policy or a sampling procedure. Experiments are conducted on learning-to-rank benchmarks where interactions are introduced to test the validity of the method and on a real-world, large-scale recommendation engine — showing solid improvements in both cases.",This paper formulates the re-ranking problem as a sequence generation task and tackles it with the pointer-network architecture. The paper formulates the problem clearly. The proposed model is trained on click-through log and outputs a ranking list of candidate items. The authors discuss two different potential approaches to train the model and conduct synthetic experiments as well as a real-world live experiment. The model also ran in a live experiment (A/B testing).  ,0.14383561643835616,0.2727272727272727,0.18834080717488788
1104,SP:67efe87f8db28e0aa68246cc5b34ddc028188df7,"This paper proposes a novel differentiable k-means clustering layer (DKM) for deep neural network model compression. The DKM utilizes attention mechanism to align the weight-to-cluster assignment with the training loss function. Overall, the idea is novel but the paper is not prepared enough. ","The paper is concerned with reducing the size of deep neural networks using weight sharing. The paper proposes a new building block that performs a soft k-means algorithm where each weight is assigned a convex combination of the cluster centers. At test-time, the weights are assigned to their closest cluster center such that a real (hard) weight sharing is obtained. The method achieves state-of-the-art accuracy using various architectures on several tasks.",0.2391304347826087,0.14473684210526316,0.180327868852459
1105,SP:681fe0a9929f5e6473029e70d5073913183e38a3,"This paper describes a simple yet effective technique for learning temporal point processes using a mixture of log-normal densities whose parameters are estimated with neural networks that also adds conditional information. The method is shown to perform better than more recent techniques for density estimation such as different versions of normalising flows. Experiments were reported on 6 datasets, comparing the approach against flow models and assessing the benefits of adding extra conditional information, performance with missing data, and benefits of sequence embeddings.","The authors propose a new paradigm for learning models for point processes which circumvents the need to explicitly model the conditional intensity. This utilizes recent work on Normalizing flows and upends a long-standing paradigm. The paper is a true tour-de-force and the authors make a very convincing case for why instead of modelling conditional intensity, one could (and should) model the distribution of times directly.",0.1927710843373494,0.23529411764705882,0.2119205298013245
1106,SP:684f590cdc9c5592b1f8d815d4b380186697d37d,"This paper introduces an interesting idea of enhancing the contextualised word embedding learned by Transformers with long-range semantic dependencies via topic learned by Poisson Gamma Belief Network (PGBN), a deep topic model. To leverage the topic information to guide the learning process of transformers, the authors proposed two types of topic-ware embeddings and one topic attention mechanism. The experimental results show incorporating topic information can further improve the performance of Transformers.","This paper introduces a global topic model into the Transformer to enrich longer-term dependencies beyond the fixed training segment, including contextual token/segment embedding (TE/SE) and Topic Attention (TA). However, some components seem to be unnecessary: The function of “+TA+SE” is very trivial by comparing “+Topic attention (TA)” with “+TE + SE + TA” in Table 1. In addition, the experiments of GLUE in Table 2 are only conducted on “Bert-base” with marginal improvements.",0.2191780821917808,0.21052631578947367,0.21476510067114093
1107,SP:6853e6809f742e73274ae90083a62d861c63a3b4,"This paper proposes a data augmentation scheme that synthesizes image background so that models can achieve better generalization by learning from one synthetic image and generalizing to real natural images. The process involves using previous images as background and adding adversarial noises. Experimental results show that it can generalize from synthetic traffic signs and digit images to real traffic sign images and handwritten digit images, outperforming a baseline that directly trains from the synthetic images without augmentations or with random background augmentations.","The authors mathematically show that the risk of a classifier is bounded by K / (2 - \alpha) if the object error of the classifier is bounded by \alpha. This means that decreasing K (context bias) can improve the performance. Inspired by this and by assuming that we have access to a function that generates an image based on object O and context C, the authors propose an algorithm that is context-agnostic. Their algorithm updates the model based on generated image and then uses this new image to generate the context for the next image. This way, the classifier is enforced to ignore the context. They evaluate their method on three different datasets.",0.13414634146341464,0.09821428571428571,0.11340206185567012
1108,SP:686bfd24ecc46724adfe6b4fba91dc2012b188c0,"The paper describes a methodology for reducing model dependance on bias by specifying a model family of biases (i.e. conv nets with only 1x1 convs to model color biases), and then forcing independence between feature representations of the bias model and the a full model (i.e. conv nets with 3x3 convs to also model edges). ",This manuscript discusses the problem of bias shortcut employed by many machine learning algorithms (due to dataset problems or underlying effects of any algorithmic bias within an application). The authors argue that models tend to underutilize their capacities to extract non-bias signals when bias shortcuts provide enough cues for recognition. This is an interesting and important aspect of machine learning models neglected by many recent developments. ,0.14035087719298245,0.11940298507462686,0.1290322580645161
1109,SP:686d12e3c1b9b03b8a0ad2106de8108b793daab3,"The paper studies offline policy evaluation (OPE) and optimization in the model-based setting. The main methodological contribution of the paper is using autoregressive models for the next state and reward prediction. The authors demonstrate that autoregressive models achieve higher likelihood compared to feedforward models on 9 environments from RL Unplugged [1] offline dataset. Given that model likelihood is only a proxy quality metric in OPE and control, they further demonstrate a positive correlation between likelihood and OPE estimates. The paper shows quantitatively that using autoregressive models results in more accurate OPE estimates than for feedforward models and model-free benchmarks. Finally, the authors apply autoregressive models for offline control and achieve higher returns than for feedforward models.","The authors consider the usage of autoregressive dynamics models for batch model-based RL, where state-variable/reward predictions are performed sequentially conditioned on previously-predicted variables. Extensive numerical results are provided in several continuous domains for both policy evaluation and optimization problems. The results showcase the effectiveness of autoregressive models and, in particular, their superiority over standard feed-forward models.",0.15254237288135594,0.29508196721311475,0.2011173184357542
1110,SP:6876ea7bf4463d2a56349841ef12b0d362d1d66b,"The paper presents a gradient optimization-based teacher-aware learner who can incorporate a teacher's cooperative intention into its likelihood function, and learn faster in comparison to the existing naive learning algorithms for machine teaching. The authors evaluate the proposed algorithm empirically on several machine learning tasks such as classification/regression/IRL and also on a simple setting where instruction/advice is taken from human teachers. Their results show that learning is indeed faster with a teacher-aware learner.","**High-Level Summary**  This paper studies cooperative teacher and learner settings. In this setting, the teacher and learner are trying to solve a classification task with input $x \in \mathcal{X}$ and label $y \in \mathcal{Y}$. The setup works in an online fashion where at each time step, the teacher selects an example $(x, y)$ to present to the student from a large dataset and the student learns from this example. The teacher knows the optimal parameters. Previous work has focused on the setting where the teacher is aware of the learner and tries to select the example to ensure the student learns the fastest. This paper studies an extension where the learner is also aware of the teacher's feedback (teacher-aware learner). The key novelty is in the learner trying to maximize its parameters to fit the feedback provided by the teacher while also trying to predict the distribution the teacher is using to sample the data from. This has an additional benefit in that it can help the learner perform ""pragmatic reasoning"". This is related to previous work on Rational-Speech Act models (e.g., Golland et al., 2010). The key difference is that previous work on RSA provided limited theoretical analysis and was concerned with specific tasks e.g., predicting actions while this work focuses on a more abstract task of learning parameters for classification. ",0.2375,0.08260869565217391,0.1225806451612903
1111,SP:687a3382a219565eb3eb85b707017eb582439565,"Paper summary:  This paper argues that reducing the reliance of neural networks on high-frequency components of images could help robustness against adversarial examples. To attain this goal, the authors propose a new regularization scheme that encourages convolutional kernels to be smoother. The authors augment standard loss functions with the proposed regularization scheme and study the effect on adversarial robustness, as well as perceptual-alignment of model gradients.","The authors propose a method for learning smoother convolutional kernels with the goal of improving robustness and human alignment. Specifically, they propose a regularizer penalizing large changes between consecutive pixels of the kernel with the intuition of penalizing the use of high-frequency input components. They evaluate the impact of their method on the adversarial robustness of various models and class visualization methods.",0.20588235294117646,0.2222222222222222,0.21374045801526717
1112,SP:68a116045efaad7a809e686eab1b5a8b1f665d99,"This paper introduces an interesting property of adversarial examples, which is called conferrability and can reflect the abilities whether an instance can exclusively transfer with a target label from a source model to its surrogates. A new method is proposed to generate conferrable adversarial examples. Experimental results show the effectiveness of the proposed method. The most impressive thing is the AUC of this method in verifying surrogates.","This paper studies fingerprinting a neural network model by using adversarial example techniques. The idea itself is interesting enough, the this work presents a neat development toward solving this problem. An important issue with this problem is to distinguish a reference model from a stolen model. Thus a desire property of the fingerprint adversarial example is to mislead all surrogate models but non reference models. Since adversarial examples are typically transferable to reference models, thus it is important to distinguish a fingerprint from a transferable adversarial example. For a long time, researchers do not have an answer to whether this is possible, and this work provides an evidence that it may generate a conferrable but not transferable adversarial example to achieve the goal. ",0.26865671641791045,0.14634146341463414,0.1894736842105263
1113,SP:68a322bf79a790fb6fac85ebb81f37ba3014d24b,"This work studies a rate-constrained contextual multi arm bandit (RC-CMAB) problem: the decision maker has to make action decisions for multiple parallel (independent and identical) CMAB problems (i.e. agents), but can only communicate the actions for each CMAB problem to a controller through a rate-constrained communication channel, from which the controller receives and decodes the actions of the decision maker, and applies such decoded decisions to each CMAB.  The paper first formulates the problem as a policy compression problem under an information theoretic framework, and then characterizes the optimal compression scheme for infinite agents. Next, the paper presents a practical coding scheme to communicate actions to finite agents under rate constraints, and finally benchmarks its performance against the compression scheme in the asymptotic regime.  ","This paper studies a CMAB problem where the actions for multiple agents are sent from the decision-maker over a rate-limited communication channel. The authors developed information-theoretic performance bound for Thompson sampling based policies, which reduce the problem to transmitting conditional probability distributions over a communication channel. A practical coding method was also developed. Numerical experiments were carried out to validate the proposed design.",0.1875,0.36363636363636365,0.24742268041237112
1114,SP:68a642280d63e15a28af346d362c02e858867653,"The paper presents a new probabilistic model for studying information flows in DNNs. To that end two Markov chains connecting the network's input, hidden layers, and output are introduced: (i) the forward chain models the conditional distribution of each layer given its input as a Gibbs distribution over the layer's weight vectors (the Hamiltonian is given by a non-linearity applied of dot products between weights and inputs); (ii) the backward chain, which is discussed much less, tries to capture the correlations introduces by BP. The authors show how to compute mutual information terms under their probabilistic model and provide some synthetic experiments under the proposed framework.","The paper points out that the IB principle based on the Markov chain assumption ($Y \rightarrow X \rightarrow T_1 \rightarrow \cdots \rightarrow \hat{Y}$) cannot fully characterize the information flow in DNNs, and hence several claims previously made on the assumption may not be accurate. For better quantification of the mutual information, this paper proposes a probabilistic framework of IB in deep neural networks (DNNs) by taking into account the back-propagation training. Under the probabilistic framework, the paper derives two Markov chains that characterize the information flow in DNNs and provides experimental evidence for supporting the validity of the Markov chain assumptions. The paper claims that the probabilistic approaches allow us to more accurately estimate the mutual information than existing non-parametric approaches and experimentally demonstrates how different activation functions and hidden layers achieve IB trade-offs.  ",0.1926605504587156,0.1510791366906475,0.1693548387096774
1115,SP:68afc80f1983d8ae90181ca41c8132c09d78983d,"1. The paper aims to train a model to move objects in an image using language. For instance, an image with a red cube and blue ball needs to be turned into an image  with a red cube and red ball if asked to ""replace the red cube with a blue ball"". The task itself is interesting as it aims to modify system behavior through language. ","This paper proposes a model that takes an image and a sentence as input, where the sentence is an instruction to manipulate objects in the scene, and outputs another image which shows the scene after manipulation. The model is an integration of CNN, RNN, Relation Nets, and GAN. The results are mostly on synthetic data, though the authors also included some results on real images toward the end.",0.16666666666666666,0.16176470588235295,0.16417910447761194
1116,SP:69009ae996d6676a628298180b3fff4b22b8828e,"This paper addresses a novel variant of AutoML, to automatically learn and generate optimization schedules for iterative alternate optimization problems. The problem is formulated as a RL problem, and comprehensive experiments on four various applications have demonstrated that the optimization schedule produced can guide the task model to achieve better quality of convergence, more sample-efficient, and the trained controller is transferable between datasets and models. Overall, the writing is quite clear, the problem is interesting and important, and the results are promising. ","This paper proposes a meta-learning solution for problems involving optimizing multiple loss values. They use a simple (small mlp), discrete, stochastic controller to control applications of updates among a finite number of different update procedures. This controller is a function of heuristic features derived from the optimization problem, and is optimized using policy gradient either exactly in toy settings or in a online / truncated manor on larger problems. They present results on 4 settings: quadratic regression, MLP classification, GAN, and multi-task MNT. They show promising performance on a number of tasks as well as show the controllers ability to generalize to novel tasks.",0.18072289156626506,0.14285714285714285,0.1595744680851064
1117,SP:69082f072d756cef8dcfa36186256965f39eac28,"The authors propose a modified ReLU, the GaLU, where the nonlinearity gating role is decoupled from the linear weights. Similar ideas have been previously proposed. For example Tsai et al: http://papers.nips.cc/paper/6516-tensor-switching-networks: ""The TS network decouples a hidden unit’s decision to activate (as encoded by the activation weights) from the analysis performed on the input when the unit is active (as encoded by the analysis weights)"" and Veness et al: Online learning with gated linear networks, https://arxiv.org/abs/1712.01897. ","The paper introduces a GaLU activation function, which is the product of a random gate function and a learnable linear function. The authors argue that empirically, neural networks with the GaLU activation is as effective as that with the ReLU activation, but theoretically, the GaLU activation is easier to understand because of the separation of the non-linearity and the learnable parameters. The the paper analyzes neural networks with one GaLU layer. Essentially, the network is a random transformation followed by a linear projection. This property enables analysis that are well known for the linear models.",0.2,0.1875,0.19354838709677422
1118,SP:69704bad659d8cc6e35dc5b7f372bf2e39805f4f,"The paper presents exact conditions for the convergence of several gradient based methods for solving bilinear games. In particular, the methods under study are Gradient Descent(GD), Extragradient (EG), Optimizatic Gradient descent (OGD) and Momentum methods. For these methods, the authors provide convergence rates (with optimal parameter setup) for both alternating (Gauss-Seidel) and simultaneous (Jacobi) updates.   ","This paper studies the convergence of multiple methods (Gradient, extragradient, optimistic and momentum) on a bilinear minmax game. More precisely, this paper uses spectral condition to study the difference between simultaneous (Jacobi) and alternating (Gau\ss-Seidel) updates. The analysis is based on Schur theorem and give necessary and sufficient condition for convergence. ",0.22807017543859648,0.24528301886792453,0.23636363636363636
1119,SP:69a60eb62ae3b7e2bb036b1434554397024a8d47,"- This paper conducted a detailed study on how does the loss modeling affects the final performance of the pruned model. The authors first provided a unified view of various pruning algorithms (e.g., Magnitude Pruning, SNIP, OBD, and OBS), which can be categorized into three classes: weight magnitude, linear and quadratic models of the loss function. In the experiments, the authors seek to answer the questions: 1) how well do each criterion preserve the loss; 2) how does the locality assumption affect the final performance; and 3) how does the loss relate to the final performance? Empirical, the authors found that the quadratic model preserves the loss the best, as expected. Also, the loss after pruning seems not strongly correlated with the performance after fine-tuning.","The authors study the use of loss-modeling to maintain model quality when inducing unstructured sparsity in deep neural networks. They study a range of different approximations and modifications that can help improve the quality of the approximation (taking local steps, avoid large changes in weight magnitude, avoiding assumptions about convergence). The authors conduct a thorough empirical investigation that yields practical observations for the design of future pruning techniques.",0.14285714285714285,0.2608695652173913,0.1846153846153846
1120,SP:69b7083929e4f0f4edce3e20b8b3fba5b36ed977,"Many streaming algorithms developed during the last decades are randomized and have an expected solution guarantee (approximation guarantee).  However, the promised guarantee is not with respect to an adaptive adversary that can choose the remaining part of the instance as a function of the decisions taken so far of the algorithm (and thus as a function of the random bits). This has prompted recent work on ""adversarial robustness of streaming"" to obtain guarantees regarding these stronger adaptive adversaries. First it has been shown that sketching based algorithms (i.e., sample a dimension-reduction matrix before the stream) is not robust against adaptive adversaries. This is because, the adversary can figure out the used matrix and then feed a worst-case instance.  The present paper has a more positive message. They show that a large family of streaming algorithms are in fact also robust against adaptive adversaries. On a high level they show that sampling based algorithms that roughly work as follows: before the arrival of an element e, we calculate a threshold for taking that element e based on the current state of the algorithm (and thus already used randomness). However, we use *new* randomness for deciding wether to take the element or not.  Such sampling based algorithms have been heavily used for e.g. clustering, graph sparsification and regression.   The main result of the paper is this observation together with tons of applications of prior algorithms that the authors list. ","This paper studies adversarial robust streaming algorithms. In the streaming model, there are many randomized algorithms. An adversary gives a sequence of update to the algorithm adaptively to learn the random bits used by the outputs of the algorithm. A adversarial robust streaming algorithm is robust to any adversarial updates. This paper gives an observation that if the streaming algorithm is sampling based and the random bit for each item is fresh, then the algorithm is robust even though the sampling probability depends on the previous random bits.",0.12863070539419086,0.3522727272727273,0.18844984802431608
1121,SP:69da1cecdf9fc25a9e6263943a5396b606cdcfef,"In this work, the authors show that the sequence of self-attention and feed-forward layers within a Transformer can be interpreted as an approximate numerical solution to a set of coupled ODEs. Based on this insight, the authors propose to replace the first-order Lie-Trotter splitting scheme by the more accurate, second-order Strang splitting scheme. They then present experimental results that indicate an improved performance of their Macaron Net compared to the Transformer and argue that this is due to the former being a more accurate numerical solution to the underlying set of ODEs.","The paper points out a formal analogy between transformers and an ODE modelling multi-particle convection (the feed-forward network) and diffusion (the self-attention head). The paper then adapts the Strang-Marchuk splitting scheme for solving ODEs to construct a slightly different transformer architecture: “FFN of Attention of FFN”, instead of “FFN of Attention”. The new architecture, refered to as a Macaron-Net, yields better performance in a variety of experiments.",0.15463917525773196,0.20833333333333334,0.17751479289940827
1122,SP:69ed927d692d152fdd4f35d082e4c3e0d5e123d2,"The paper tries to provide an explanation for a memorization phenomenon observed in convolutional autoencoders. In the case of memorization, the autoencoder always outputs the same fixed image for any input image, even when the input image is random noise. The authors provide an empirical analysis that connects such a phenomenon to strides in convolutional layers of the autoencoder. Then, a possible theoretical explanation is given in the form of conjecture with some empirical evidence.","The authors investigates downsampling as one method by which autoencoding CNNs may memorize data. The theoretical motivation provided concentrates on linear CNNs. They show that downsampling linear CNNs tent to learn a point-map of the training data, even though (under certain initializations) they are capable of learning identity maps. However, non-downsampling linear CNNs learn identity maps. Given enough data however, the authors claim that the downsampling CNN will learn the identity map.",0.14666666666666667,0.14864864864864866,0.14765100671140943
1123,SP:6a01f5c878927883644a5f75d2b15475cd97d596,This is in my view a strong contribution to the field of policy gradient methods for RL in the context of continuous control. The method the authors proposed is dedicated to solving the premature convergence issue in PPO through the learning of variance control policy. The authors employ CMA-ES which is usually employed for adaptive Gaussian exploration. The method is simple and yet provides good results on a several benchmarks when compared to PPO.,This paper proposes an improvement of the PPO algorithm inspired by some components of the CMA-ES black-box optimization method. The authors evaluate the proposed method on a few Mujoco domains and compare it with PPO method using simpler exploration strategies. The results show that PPO-CMA less likely to getting stuck in local optima especially in Humanoid and Swimmer environments. ,0.18666666666666668,0.22580645161290322,0.20437956204379562
1124,SP:6a1884e0f3d0e103ad14ab06b3f28308d4ccec2c,"This paper proposed a new transformer model framework for multitask learning on NLP tasks. To deal with challenges in multitask learning/co-training, the authors proposed five improvements, including modifications on the transformer layers with task conditioning and uncertainty sampling. In the experiments, the authors showed that the proposed model can outperform full fine-tuned BERT large model with less parameters (adding some parameters on a single co-trained model), and with less training data. ","The paper explores a collection of strategies to improve multitask learning and bring performance on par with single task training. The strategies build on and show good awareness of existing work and achieve positive overall results on GLUE, SuperGLUE, and MRQA tasks. Abolation experiments demonstrate the value of the individual components being proposed. The results are particularly impressive given the small number of additional parameters introduced into the model and in the context of prior work that has shown mixed results from multitask training.",0.24,0.21428571428571427,0.2264150943396226
1125,SP:6a3c4ae05d582f8896840483b08c735ced2976bc,"Certified robustness approaches have been studied for single models based on interval propagation as well as randomized smoothing. The use of ensembles for empirical robustness has also been studied in the literature. This paper attempts to theoretically study the certifiable defense achieved by ensembles. The paper analyzes the standard Weighted Ensemble (WE) and MaxMargin Ensemble (MME) protocols, and proves the necessary and sufficient conditions for robustness under smoothness assumptions. The key idea is to show and utilize the diversification of gradients and large confidence margins. ","This paper studies the following problem: How to train a certifiably robust classifier with ensemble methods? The authors considered two types of ensembles: the weighted-average ensemble and large-margin ensemble. They first derived theoretically sufficient and necessary conditions for robustness under two types of ensembles, with the conclusion that large confidence margin and diversified gradients are two factors which contributes to the robustness of ensemble models. Diversity-regularized training, a method of designing loss functions for training ensemble models, is proposed motivated by their theoretical findings. They applied this methodology to randomized smoothing, performed extensive experiments and showed non-trivial improvement over single model methods.",0.24705882352941178,0.19811320754716982,0.2198952879581152
1126,SP:6a87b089a5efc03251112b2b8551df432c7efb42,"In this paper, the authors propose an approach using curricula to identify how a system has learned. Using two commonly used tasks in neuroscience: evidence accumulation and delayed decision recurrent neural networks (RNNs) are trained using two different loss functions (target based and representation based). They show that by simply comparing the learning time during different curricula , we can identify which loss function was used. On the other hand, the learned state-space trajectories of RNNs are indistinguishable thus unable to disambiguate which loss function was used for training.  The findings here put emphasis on the collection of behavioral and neural data while animals in neuroscience labs undergo curriculum-based learning on top of the data that is collected after the animal has learned.","This paper simulates simple RNNs performing two classic decision-neuroscience experiments (a free choice evidence accumulation task and a delayed decision evidence accumulation task). The paper examines learning behaviour of these networks under three hand-crafted curricula, for each of two different RNN loss functions. The paper claims that one can diagnose the underlying learning rule (really the loss function) an RNN is using based upon the learning behaviour observed across the set of training curricula. They suggest a similar approach can be used to identify learning rules in animal neuroscience experiments. ",0.20161290322580644,0.2717391304347826,0.23148148148148145
1127,SP:6a8b6361018fa5986907f2b48128a4bdfcd79f43,"This paper presents a neural network training framework based on a genetic algorithm called Surgeon. The idea consists of two modules. First, a series of network structure changes that aims to minimize the network input and output. Second, a heuristic (with regard to the objective function) for ranking and selecting the potentially good network modifications. The algorithm works iteratively between the former propose candidate network changes, and the later decides which candidate to accept and evolve into.","this paper presents the Surgeon, a ANN/evolutionary algorithm hybrid optimization de- signed for neural architecture search. On SVHN and CIFAR-10, the network generated by the Surgeon is able to outperform the baseline in case of suboptimal topologies, or reach comparable accuracies while pruning the underlying network structure to less resource-intensive topologies. My major concern is the novelty, as the SVD technique and net2net techniques have all be proposed before. The experiment is not solid. The accuracy on Cifar is far from the state of the art. There is no large scale datasets. There's no performance comparison with related work, making the paper less convincing. ",0.24675324675324675,0.17592592592592593,0.20540540540540542
1128,SP:6a909e6ca1ea605f986c0bd229c852d535270af6,"The paper studies the impact of adversarial attacks on a ML based system for forecasting stock prices. The authors leverage Twitter data in order to enhance stock price prediction. Then, by determining the sensitivity of the model when perturbing the inputs. Then, small changes are applied to the inputs and output is observed. The authors experimented with the Tesla stock price.","In this paper, the authors studied the problem of adversarial ML in stock price forecasting. They first replicated an industry standard pipeline, which performs a sentiment analysis of Twitter data to forecast trends in stock prices. Then, they show that an adversary can exploit the lack of provenance to indirectly use tweets to manipulate the model’s perceived sentiment about a target company and in turn force the model to forecast price erroneously.",0.29508196721311475,0.2465753424657534,0.26865671641791045
1129,SP:6a92c5ac2c70f85a65c73a703d863dc1564ab549,"The paper presents a scheme for federated learning (FL) called FedVote. In FedVote, clients use binary neural networks where a latent restricted range weight vector $\boldsymbol{h}$ is learned, and stochastic rounding is applied to obtain quantized weights $\in$ {$-1,+1$}. The communication cost to the server (up-link) is reduced by using quantized weights. The server aggregates weights by summing over all the weights of the clients at each round of training and applying a sign function. This mechanism is referred to as plurality voting (ties are broken randomly). However, the paper also proposes to use soft voting, which normalizes the number of ones (cf. hard sign function) to get probability values. These probabilities are then quantized with a clipping mechanism to restricted maximum and minimum values, using predefined thresholds, and broadcasted to the clients (down-link). The latent weights of the client models are updated using the soft voting results. The paper also adapts work on reputation-based voting (Bendahmane et al. 2014) to deal with adversarial FL in the form of Byzantine attacks. The paper presents convergence analysis for FedVote under the independent and identically distributed data setting. Empirical evaluations is conducted on two datasets ,Fashion-MNIST and CIFAR-10, and applied to two models, LeNet-5 and VGG-7, respectively. ","This paper aims to reduce the communication cost for federated learning while ensuring that the aggregation method at the server is tolerant to the presence of Byzantine clients. Towards this instead of communicating the local update/gradients or their quantized version, this paper proposes to communicate the quantized model weights to the server. The server performs the aggregation in the quantized space and communicates the aggregate value back to the clients. To enable faithful quantization of the weights during the communication with the server, each client learns normalized weights (by applying a coordinate-wise normalization function to the latent weights).   The paper also proposes a weighted aggregation mechanism at the server that takes the reputations of different clients into account.    The paper analyzes the impact of the weight quantization on the convergence of the underlying federated learning algorithm in an i.i.d. setting. Empirical evaluations on Fashion-MNIST and CIFAR-10 show that the proposed method outperforms existing local update/gradient compression-based schemes.  ",0.21495327102803738,0.2787878787878788,0.24274406332453824
1130,SP:6aab83c6e2805838fee314ae400ce5a8bb08f8f3,"This paper investigates the problem of modeling insideness using neural networks. To this end, the authors carefully designed both feedforward and recurrent neural networks, which are, in principle, able to learn the insideness in its global optima. For evaluation, these methods are trained to predict the insideness in synthetically generated Jordan curves and tested under various settings such as generalization to the different configuration of curves or even different types of curves. The experiment results showed that the tested models are able to learn insideness, but it is not generalizable due to the severe overfitting. Authors also demonstrated that injecting step-wise supervision in coloring routine in recurrent networks can help the model to learn generalizable insideness. ","This submission introduces a new concept, termed insideness, to study semantic segmentation in deep learning era. The authors raise many interesting questions, such as (1) Does deep neural networks (DNN) understand insideness? (2) What representations do DNNs use to address the long-range relationships of insideness? (3) How do architectural choices affect the learning of these representations? This work adopts two popular networks, dilated DNN and ConvLSTM, to implement solutions for insideness problem in isolation. The results can help future research in semantic segmentation for the models to generalize better. ",0.17094017094017094,0.2222222222222222,0.1932367149758454
1131,SP:6afe8cd7741417913dd2ccef7cb4feccd5a592ef,"This work focuses on highlighting the strengths of Iterative Magnitude Pruning (IMP). Specifically, that it is capable of achieving strong performance when compared to more complex pruning approaches. The work explores the common arguments against IMP like, a) it reaches sub-optimal states since training doesn't compensate for sparse structures, b) it fails to identify optimal layer-wise pruning ratios and c) it is expensive, slow and non-competitive. The critical outcome shown is that IMP, with a global selection criterion and extremely small overhead, remains highly competitive with common state-of-the-art pruning approaches, both in sparsity, performance and theoretical speedup. ","The paper studies a fundamental and important research approach in network pruning: iterative magnitude pruning (IMP). Previously IMP is criticized to be time-consuming, layer-independent and sub-optimal in performance. In this paper, extensive empirical studies are conducted to show that under proper learning rates, IMP can have close performance with more advanced pruning approaches, with little training time increased. ",0.14423076923076922,0.2459016393442623,0.1818181818181818
1132,SP:6b1f56de94f5edc349fed07546f5964151b51d8e,"The paper presents a new algorithm for maximizing the diversity of different policies learned for a given task. The diversity is quantified using a metric, where in this case the total variation is used. A policy is different from a set of other policy if its minimum distance to all the other policies is high. The authors formulate a new constraint optimization problem where the diversity to previous policies is lower bounded in order to avoid a tedious search for combining task reward and diversity reward. The algorithm is evaluated on different Mojoco locomotion tasks. ","This paper proposes a new method for learning diverse policies in RL environments, with the ultimate goal of increasing reward. The paper develops a novel method, called interior policy differentiation (IPD), that constrains trained policy to be sufficiently different from one another. They test on 3 Mujoco domains, showing improved diversity in all of them and improved performance in 2 of them.",0.14736842105263157,0.22580645161290322,0.17834394904458598
1133,SP:6b29ca414857bbf1cb0dbf01e67520b37155f3a4,"The paper attempts to apply neural architecture search (NAS) to re-arrange, or re-allocate the network backbone blocks and the convolution filters for object detection. The search space is two-fold: 1) the network is allowed to search over allocation of different number of blocks in the backbone (e.g. ResNet, MobileNet); 2) the network is allowed to choose the dilation of each of the block. A one-shot NAS method is adopted for efficient search. After search, the model is shown to have 1) better AP results; and 2) more balanced effective receptive field (ERF). ","This paper works on neural architecture search for object detection. Two search directions are proposed: 1) searching the number of conv blocks at each resolution (or ""stage""). 2) searching the dilations for each conv block. A greedy neighbor-based search algorithm is adopted. The results show healthy improvements among different network architectures. And the searched architecture also performs well on other tasks or datasets. ",0.23711340206185566,0.359375,0.2857142857142857
1134,SP:6b2f3d86da1d86c6a13b70c06e913e6f8259dac7,"This paper presents a spatio-temporal attention LSTM for action recognition, where attention decides which pixels and frames are more important for classification. ConvNet features are extracted, a first layer of attention looks at the pixel level, then a second layer is applied at the temporal level. An LSTM is used to connect frame representation through time.","The paper proposes a spatio-temporal attention weighting mechanism in LSTM, applied to the task of human action recognition. VGG19 based frame features are fed to LSTM, soft attention is calculated based on previous works and temporal attention is predicted using another small neural network. The features are weighted by these attentions and eventually the network is trained with a regularized cross entropy loss. Empirical results are given on three datasets for action recognition, UCF11, UCF101 and HMDB51.",0.24561403508771928,0.1794871794871795,0.2074074074074074
1135,SP:6b329d6858b6dd7bda5fa7a547c086a7fb98116e,"The paper presents two analysis: (1) Characterization of when the training of VAEs using the ELBO leads to suboptimal generative models (biased towards ones with simple posteriors); and (2) How this suboptimality may affect downstream tasks that use the learned models. Specifically, the work focuses on VAEs using mean-field Gaussians as variational distributions, and explores how their limited modeling capacity affects the final generative model learned. They present some theoretical results and simple and illustrative scenarios. In addition, they present an analysis regarding how the suboptimal models learned affect other tasks, such as learning disentangled or compressed representations.","The paper presents a characterization of failure modes of Gaussian VAEs. It is known that Gaussian VAEs can fail to produce good models either by failing to match the data distribution or by learning latent variables that are uninformative. The paper builds upon prior work that suggests that the VAE objective can cause the inference model to over-regularize the generative model. The paper characterizes the conditions under which this over-regularization occurs with corresponding. Furthermore, the paper examines the affect of VAE pathologies on downstream tasks a number of unsupervised and supervised downstream tasks.",0.18181818181818182,0.18947368421052632,0.18556701030927839
1136,SP:6b55a41e6cde3b4e740941d48c237127c982da27,"The paper presents a new meta-learning method for solving the Schrodingers equation using neural networks. This method combines an existing neural wave function model called FermiNet together with a GNN (MetaGNN) to solve the Schrodingers equation for multiple geometries simultaneously. The MetaGNN takes the atomic graph as input and outputs a set of parameters that capture the 3D geometry of the system, which are then input to the FermiNet. The resulting method can is applicable to multiple geometries while being significantly faster to train. ","The paper develops a neural network based variational ansatz for modeling wave functions. Authors build their model on top of FermiNet architecture with a few modifications: they use a different feature embedding approach that is invariant with respect to basic spatial symmetries. In addition, authors use a GNN “hypernetwork” that predicts the parameters of the variational wave function for a given configuration of the system. With these modifications authors show that the model can be optimized on a range of system configurations simultaneously. The optimization is performed in a standard VMC setting.  The results are compared on commonly studied problems such as variations of energy of the H4 molecule, hydrogen chain system, nitrogen molecule and cyclobutadiene. Authors find that their approach generally achieves similar results to those of a FermiNet model, while training on multiple system configurations simultaneously, reducing the time needed to obtain variational energies for multiple configurations.",0.29411764705882354,0.16778523489932887,0.21367521367521367
1137,SP:6b629449901b057a5adea945556494ed61b47e8f,"The paper identifies two atomic problems, respectively in fields of ML (MNIST classification) and quantum mechanics (measuring a single photon), and brings them together in a simplified setup that uses a single photon emitted according to the spatial distribution of images to classify MNIST/Fashion-MNIST. The introduction of quantum mechanics into the problem is through a trainable computational model of a beam splitter/phase shifter mechanism, aka a rotation in a high dimensional complex space, that's allowed to alter the photon's state before hitting the measurement device. The paper shows that using this overly simplified (and claimed to be physically feasible) quantum computer, which acts as the representation learning layer, improves classification accuracy over any other representation learning method that doesn't use quantum computing. The major take-away is an accessible demonstration of how an elementary quantum computer might work for ML, and what may be possible with actual qubits.","This paper focuses on the quantum computing based machine learning and proposes a toy model to illustrate the quantum information processing. On the common used handwritten digit dataset MNIST, more than 40% images can be classified accurately. The proposed method looks interesting and the focused problem (combining quantum computing and machine learning) is of certain significance.",0.09740259740259741,0.26785714285714285,0.14285714285714285
1138,SP:6bb786b66e6692c476fc201d325e82f4fc2e15b8,"This paper formulates a theoretical model for testing extrapolation abilities of graph learning tasks, and suggests some practical feature maps to achieve good extrapolation properties empirically. In more detail, this paper introduces a model, a so-called structural causal model, for graphs where the graph creation process is modeled as a random variable that depends on different independent factors:  environment $E$, which is used to model the graph size $n$; graph property $W$, which is used for example to model the probability of edge existence; and random seed $Z_X$. The created graph is also scrambled by a random permutation to yield the observed graph $G^{\text{obs}}$. The ground truth labels of the graph $Y$ are functions of two factors $W$, the graph property, and $Z_Y$ random seed. ","The paper explores the problem of extrapolation in graph classification tasks and by leveraging Lovasz’s graph limit theory, provides graph representations and related theoretical guarantees on graph size extrapolation in the context of unattributed graphs. Specifically, it is shown that the graph representations characterized by induced homomorphism densities are size-invariant under certain conditions. The theoretical claims are validated by empirical evaluation of classifiers trained on the proposed graph representations. ",0.14615384615384616,0.2676056338028169,0.18905472636815918
1139,SP:6bf1569771191ea913217f527173f454d50e266c,This paper proposes a generalised self-training framework to build a Graph Neural Network to label graphs.  Of importance is the dynamic nature of the self-training. The authors do not change the GCN but extend the self-training portion as per the prior GCN paper by introducing Dynamic Self-Training that keeps a confidence score of labels predicted for unlabelled nodes.,This paper propose to modify the existing work [1] of self-training framework for graph convolutional networks. It tracks three limitations of [1] and propose three  use a threshold-based rule to insert new pseudo-labels and dynamic change the pseudo-label set. Moreover personalized weight are assigned to each activate pseudo-label proportional to its current classification margin. Evaluation of the proposed framework is performed on four networks for semi-supervised node classification task with varying label rates.,0.1935483870967742,0.1518987341772152,0.17021276595744683
1140,SP:6bf54a72a9f670d7c47a134440b73b2c3e07ee91,"The paper proposes a new option-based policy transfer framework for multi-agent reinforcement learning (MARL) called MAOPT. By framing multi-agent transfer as an option learning problem, MAOPT methods are able to learn when to give advice to agents and when to stop it. Authors provide a version of MOAPT for fully cooperative setting based on global state and reward, as well as two versions for mixed settings based on local states and per-agent rewards. The paper presents experimental results on two environments that show performance gains over existing RL methods.","This paper proposed an option-based framework for multiple agents to share knowledge with each other in the same MARL task. For scalability and robustness, two variants of the framework are designed, including 1) a global option advisor, which has the access to the global information of the environment; 2) local option advisor combined with successor representation option to enable more accurate option-value estimation. Experimental results demonstrate the proposed method is able to improve the performance of existing deep RL approaches for multiagent domains.",0.17204301075268819,0.18823529411764706,0.1797752808988764
1141,SP:6bfdc3596045227aaed04a50cd934e5d4bc1e9ad,"This paper outlines improved backdoor attacks for deep neural networks. Backdoor attacks are training-time attacks whereby an adveresary trains a network in such a way that it functions as a classifier on honestly generated images, but it has the added caveat of also being able to misclassify on images corrupted via a ""trigger"" set by an adversary. This is a grave security concern, and as such there is substantial literature that relates to both systematically training backdoored DNNs, and also detecting when a trained DNN has a backdoor. ",This paper proposed a class of methods for dynamic backdoor attack. The main idea is to generate different backdoor patterns and locations in backdoor attack. The threat model is the attacker has full access to the training data and the model training procedure. Both single-target and multi-target class-conditional triggers were explored. Experimental results on three datasets in the 100% poisoning setting verified the effectiveness of the proposed attack.,0.12359550561797752,0.15492957746478872,0.1375
1142,SP:6c17fdbd664d350f68d10c19eafae2b0b8f59969,"This paper considers the problem of estimating bounds on the mutual information. It begins by showing that popular recent estimators (e.g. MINE) are flawed, since they rely on the Donsker-Varadhan bound that cannot be estimated efficiently. They then point to entropy upper bounds as a much more feasible approach to MI approximation, and propose a framework for using them in practice. These upper bounds converge as 1/sqrt(N) to the true entropy value, making them potentially viable in practice to obtain reasonable approximations of MI. ","This paper studied the Donsker-Varadhan lower bound of KL-divergence. The authors show that with high probability, the DV lower bound is upper bounded by log of the sample size, so if the true KL-divergence is very large, then exponential sample size is needed to make the DV lower bound tight. The same argument holds true for any distribution-free high-confidence lower bound (such as DV lower bound) for KL divergence. Then the authors proposed to use an upper bound for entropy instead of lower bound for mutual information. ",0.17045454545454544,0.16304347826086957,0.16666666666666666
1143,SP:6c3b9e6e95025f24bb371dfeb598f5ebc049bbc7,"The paper introduces a setup with the goal to adapt from a coarse pretrained model to unseen fine-grained labels. This problem is formulated as a superclass-subclass latent model and learned with maximum likelihood via expectation-maximization. The proposed approach, super-class conditional Gaussian mixture (SCGM) model, defines a hierarchical Gaussian distribution on the class hierarchy that models both the superclasses and subclasses. SCGM is evaluated on 6 image-net related datasets and a a real Dialysis-Event dataset collected by hospitals, and demonstrates competitive results under two evaluation setups: generalizing to seen and unseen superclass.","The paper presents SCGM, a new technique for solving the Cross-Granularity Few-Shot learning (CGFS) problem.  CGFS is defined as the problem of adapting a classification model trained on coarse (“superclass”) labels to perform well on fine-grained labels, which consist of multiple “subclass” labels within each superclass.  The paper presents a new generative modeling approach that enables end-to-end classifier training in a manner that (a) incorporates information about superclass-subclass hierarchies (b) does not rely on explicit subclass enumeration (c) provides improved empirical performance on CGFS and (d) provides systems benefits with respect to existing baselines.  The authors provide detailed description of their approach and characterize its relationship with existing methods, and present empirical results that support their methodological choices.",0.20618556701030927,0.16129032258064516,0.18099547511312214
1144,SP:6c4659d71144bea924d9e77ee2be1bd6d11cf7f0,The paper extends over hypergraph convolutional networks (HCN) by adding a temporal evolution module in order to solve prediction tasks in a dynamic environment. The main part of the paper is the description of the proposed system. It is composed of a HCN for computing node embeddings at each time step and a LSTM as the temporal module. Experimental results are provided for dynamic prediction tasks over stock datasets.,"This paper proposes a method called DyHCN for learning dynamic hypergraph convolutional networks where the hypergraph structure is allowed to evolve over time. The interactions within each hyper edge, that between nodes, as well as related are used to learn the hypergaph embedding. The evolution of the centroid nodes is then modelled using LSTM. DyHCN gives better modelling accuracy as compared to some existing ones.",0.18840579710144928,0.2,0.19402985074626866
1145,SP:6c5368ae026fc1aaf92bdc208d90e4eec999575a,"The paper suggests a differentiable objective that can be used to train a network to output cluster probabilities for a given datapoint, given a fixed number of clusters and embeddings of the data points to be clustered. In particular, this objective can be seen as a relaxation of the normalized cut objective, where indicator variables in the original formulation are replaced with their expectations under the trained model. The authors experiment with a number of clustering datasets where the number of cluster is known beforehand (and where, for evaluation purposes, the ground truth is known), and find that their method generally improves over the clustering performance of SpectralNet (Shaham et al., 2018) in terms of accuracy and normalized mutual information, and that it finds solutions with lower normalized cut values.","This paper presents an end-to-end approach for clustering. The proposed model is called CNC. It simultaneously learns a data embedding that preserve data affinity using Siamese networks, and clusters data in the embedding space. The model is trained by minimizing a differentiable loss function that is derived from normalized cuts. As such, the embedding phase renders the data point friendly to spectral clustering. ",0.11538461538461539,0.23076923076923078,0.15384615384615388
1146,SP:6c6a2c5f444d100ce6003029a7b4e3436865cb88,"The paper presents several ideas to help understand and interpret the effects of different hyperparameters on the model chosen by automated machine learning.   The contributions include proposing an uncertainty measure for PDPs of probabilistic surrogate models including Bayesian optimization and others. To further increase interpretability, the paper suggests a procedure of dividing the hyperparameter space into subspaces/sub-regions, so that the hyperparameter effect of sub-regions can be analyzed individually.   The experiment results of the d-dimensional Styblinski-Tang function show the PDPs for surrogate models trained on less biased data produces lower values of the NLL and MC. , as well as lower values for the MC. Splitting into sub-regions helps to reduce MC generally. For high sampling bias, MC seems decrease when splitting 1 or 3 times, however, NLL can become worse in some cases.   In the other experiment, the paper studies HPO for 35 different OpenML classification tasks. The study found that the MC of the PDPs reduces significantly after 6 splits when comparing the PDP in sub-regions with the global PDP.  ","The paper suggests a modification of partial dependence plot for assessing the influence of hyperparameter on the fitting of the model in the context of Bayesian optimization. Bayesian optimization provides a surrogate function that describes the influence of hyperpatameter on the cost function with associated uncertainty. The surrogate function can be used as a proxy of the actual cost function to generate the partial dependence plot. However, this approach usually does not capture the associated uncertainty. Moreover, given Bayesian optimization explores the high-performing hyperparameter space more to find a suitable solution, it samples the hyperparameter space in a biased manner by design, and thus, it is more uncertain in region where less hyperparameters are sampled. Estimating the uncertainty of the partial dependence plot from these regions can bias the partial dependence plot. The authors resolve this issue by partitioning the hyperparameter space in regions based on the certainty of the surrogate function, and show that estimating partial dependence plot from region that has low uncertainty provides a better estimate, and the partial dependence plot becomes more interpretable.",0.192090395480226,0.19101123595505617,0.19154929577464785
1147,SP:6c7232bcb813f3083e14e4e26d517200dfcde4a9,"This paper presents a symbolic regression algorithm which uses policy gradient to learn a distribution over the space of mathematical expression structures. The distribution is represented by an RNN, and the on-policy sampling is also realised by this RNN. To prune the massive sample space, the authors include several constraints according to some prior domain knowledge. Furthermore, instead of optimising the RNN directly with policy gradient, the proposed algorithm also makes use of the risk-constrained method that emphasises the risks above a given percentile criteria. The proposed approach has achieved the best performance on several benchmark symbolic regression datasets.","The authors introduce a novel method for inferring a simple algebraic expression for an output in terms of an input. The method outputs a sequence tokens of the algebraic expression as represented by the pre-order traversal of an expression tree. For each token of the sequence, a recurrent neural network outputs a probability distribution on possible tokens, from which the token is sampled. Some notable contributions:",0.12871287128712872,0.19402985074626866,0.15476190476190477
1148,SP:6c766bf18a0b552410d411248af30915e331c5f7,"This paper adopts a loss metric called Grey Level Co-occurence Matrix (GLCM) as a new measurement of perceptual quality for single image super-resolution. The GLCM is particularly well suited for automatic perceptual/textural in-domain comparisons, which does not require time-consuming expert MOS evaluations. Experimental validation is carried on X-ray images of rock samples and promising results are achieved.","The paper considers the problem of generating a high-resolution image from a low-resolution one. The paper introduces the Grey Level Co-occurrence Matrix Method (GLCM) for evaluating the performance of super-resolution techniques and as an auxiliary loss function for training neural networks to perform well for super-resolution. The GLCM was originally introduced in a 1973 paper and has been used in a few papers in the computer vision community. The paper trains and validates a super-resolution GAN (SRGAN)  and a super-resolution CNN (SRCNN) on the DeepRock-SR dataset. Specifically, for the SRGAN, the paper uses the EDSRGAN network trained on loss function particular to the paper: The loss function consists of the addition of the L1 pixel-wise loss plus the VGG19 perceptual objective plus the proposed GLCM loss.",0.25396825396825395,0.11851851851851852,0.16161616161616163
1149,SP:6c84d7bf7bdfc6aa2eca4988fbb52b3cbb0b6cd7,"This paper studies iterative voting in which agents' utility vector could be different from the scoring vector. The authors show that PoA bounds is linear in the number of agents. Surprisingly, in an i.i.d. environment, the equilibrium winners have a constant order welfare advantage over the truthful winner.","The authors study the welfare of Nash equilibria reached via best-response dynamics from the truthful profile. For worst-case profiles, these equilibria can have linearly less welfare than the truthful outcome. Assuming impartial culture, however, the expected welfare of these equilibria is higher than the welfare for the truthful outcome, assuming rank-based utilities.",0.18,0.16363636363636364,0.17142857142857143
1150,SP:6c897187759edf48c1bd4f3536c098ac0d5f1179,"In this paper, the authors propose a new loss function to learn feature representations for image datasets that are class-imbalanced. The loss function is a simple yet effective tweak on an existing supervised contrastive loss work. A number of empirical tests are performed on long-tailed datasets showing the benefits of the proposed loss in beating state of the art methods.  Some specific questions are listed below:","**Overview:** The paper presents experiments showing that the contrastive learning losses produce better embeddings or feature spaces than those produced by using binary cross-entropy losses. The experiments show that embeddings learned using contrastive learning losses seem to favor long-tailed learning tasks, out-of-distribution tasks, and object detection. The paper also presents an extension of the contrastive loss to improve the embeddings. The experiments in the paper  use common and recent long-tail datasets as well as datasets for object detection and out-of-distribution tasks. ",0.19117647058823528,0.14772727272727273,0.16666666666666669
1151,SP:6c9cfcb932a9cbbb590d37ab376f4e04de8cc6af,"The paper proposes a novel convolutional kernel for CNN on the unstructured grids (mesh). Contrary to previous works, the proposed method formulates the convolution by a linear combination of differential operators, which is parameterized by kernel weights. Such kernel is then applied on the spherical mesh representation of features, which is appropriate to handle spherical data and makes the computation of differential operators efficient. The proposed method is evaluated on multiple recognition tasks on spherical data (e.g. 3d object classification and omnidirectional semantic segmentation) and demonstrates its advantages over existing methods.","The paper presents a new convolution-like operation for parameterized manifolds, and demonstrates its effectiveness on learning problems involving spherical signals. The basic idea is to define the MeshConvolution as a linear combination (with learnable coefficients) of differential operators (identity, gradient, and Laplacian). These operators can be efficiently approximated using the 1-hop neighbourhood of a vertex in the mesh.",0.1956521739130435,0.3,0.23684210526315788
1152,SP:6cad092c66273cdb0065834ee4459f1b76f8929d,"The authors propose LiSP, a model-based planning method that performs model-predictive control using learned skills rather than actions. The skills are learned using DADS, with a modified reward function that additionally encourages all skills to stay within the support of training data to avoid sink states. The experiment results show stable learning progress on reset-free and ever-changing targets, compared to other baselines.","This paper presents a lifelong reinforcement learning framework in a non-stationary environment with non-episodic interactions. The proposed approach is to 1) learn ""skills"" - a world model - to maximize the intrinsic rewards using both online and offline data, and to 2) make best plans based on the learned world model. This approach is evaluated with Hopper and Ant tasks.",0.15151515151515152,0.16666666666666666,0.15873015873015872
1153,SP:6cadee7608c7194037b971dcec3115929aa5e4fe,"In this paper, the authors evaluate the performance of classifiers trained and then later tested on both adversarially generated perturbations as well as more natural perturbations.  By considering six different natural perturbations, they show empirically that natural perturbations can improve performance against clean and adversarially-perturbed images.  They also show that adversarial training does not improve performance on unseen natural transformations.","This paper studies the effect of “robustification” (i.e., adversarial training or data augmentation) of models on the accuracy to seen and unseen perturbations. The authors propose a technique to “standardize” the robustification process across different perturbations. They evaluate their approach on several datasets, highlighting how standardization yields different insights compared to prior work.",0.16393442622950818,0.18518518518518517,0.17391304347826084
1154,SP:6cb547cec2e67bdd5ae1b278d99fabdeac826ed3,"The authors consider analyzing the EXP3.P algorithm for the case of unbounded reward functions, in the sense that the rewards are governed by a Gaussian distribution. The authors first demonstrate a regret lower bound result on the Gaussian MABs when the time horizon is bounded from above. Then, the authors proceed to the analysis of the EXP3.P algorithm on the Gaussian MABs, and establish a regret bound similar to that of Auer et al. 2002. Finally, the authors apply the EXP3.P, where an expert corresponds to a Q-learning network, in the EXP4-RL algorithm, and evaluate it on multiple RL instances.","This paper contributes to the study of EXP-based algorithms in two aspects. One is on the theoretical aspect: It analyzes the lower and upper bounds of EXP-3 for Gaussian multi-bandit setting for which the reward can be unbounded. The other is on the empirical aspect: It applied EXP4, originally developed for MAB, to Rl applications and demonstrated its advanced empirical performance. ",0.13333333333333333,0.21875,0.16568047337278108
1155,SP:6cb958ab5e4337bc6d1d72324503a8362acead04,"The paper addresses aspect-based sentiment analysis by running reinforcement learning on the dependency parse of input sentences. The agent learns a policy network to select the most effective walk along edges in the dependency graphs, starting from the target aspect in the input sentences. The state representation is learned with an LSTM. At the end of the path, a sentiment classifier predicts the distribution of the polarity. The reward is the mean squared error between the class label (i.e. sentiment polarity) and the probability predicted by the model. The paper claims that by limiting the agent's budget, the approach forces the agent to discard irrelevant information and focus on the effective paths, enabling the approach to perform well with a small number of training examples.","The paper proposes an approach to aspect-based sentiment classification, which is the task of identifying the sentiment of a specific phrase or entity in a sentence. The paper proposes to do this by first generating a dependency parse of the entire sentence and then using an RL agent to walk the dependency tree starting from the word or phrase to be classified. The state for the RL agent is the LSTM representation of its history. The final state is then used to classify the sentiment of the aspect.",0.21875,0.3146067415730337,0.25806451612903225
1156,SP:6cba5b688f59aee968462267a577a3496935dc7a,"The paper defines the optimality of a (valid) adjustment set in terms of a notion called 'adjustment information.'  Then, it focuses on estimators for which maximizing adjustment information equates to minimizing asymptotic estimation variance. The authors provide a sufficient and necessary graphical criterion for the existence of an optimal adjustment set under this notion. They also give an explicit and efficient construction of an adjustment set called the O set, which is proven to be optimal whenever graph optimality holds (the constraints in the graph are sufficient to determine an optimal adjustment set).","In this paper, the authors propose a criterion to select the optimal adjustment set. The authors propose a criterion (Eq. 4 and Def. 2) based on information theory to select which adjustment set is best. And they build the connections between this criterion to the common used minimized asymptotic variance (Eq. 7) for linear Gaussian causal model. Based on these, they propose a necessary and sufficient criterion for the existence of an optimal set. However, it is inefficient due to the large number of comparisons. Hence, the authors present an algorithm to find the o-set, which could be as the optimal set under some conditions as Thm. 3.",0.34408602150537637,0.29357798165137616,0.31683168316831684
1157,SP:6cbb71e94b31ced9cbe8bd2cfd3d0b8df02afde6,"The paper proposes a bilevel optimization approach for hyperparameter tuning. This idea is not new having been proposed in works prior to the current resurgence of deep learning (e.g., Do et al., 2007, Domke 2012, and Kunisch & Pock, 2013). However, the combination of bilevel optimization for hyperparameter tuning with approximation is interesting. Moreover, the proposed approach readily handles discrete parameters.","The paper deals with hyper-parameter optimization of neural networks. The authors formulate the problem as a bilevel optimization problem: minimizing the validation loss over the hyperparameters, subject to the parameters being at the minimum of the training loss. The authors propose an approximation of the so-called best-response function, that maps the hyperparameters to the corresponding optimal parameters (w.r.t the minimization of the training loss), allowing a formulate as a single-level optimization problem and the use gradient descent algorithm. The proposed",0.21311475409836064,0.1511627906976744,0.1768707482993197
1158,SP:6cc0e3b4b6385061150d8e36bcbc022069b475ba,"This paper studies the problem of visual imitation learning: given a video of an expert demonstration, take actions to reproduce that same behavior. The proposed method learns a distance metric on videos and uses that distance metric as a reward function for RL. Experiments show that this method does recover reasonable behaviors across a range of simulated robotic tasks.  Compared with prior methods, the main contribution of this work is that the distance metric is parametrized and trained as a siamese network.","This paper presents visual imitation with reinforcement learning (VIRL), an algorithm for learning to imitate expert trajectories based solely on visual observations, and without access to the expert’s actions.  The algorithm is similar in form to GAIL and its extensions, learning a reward function which captures the similarity between an observed behavior and the expert's demonstrations, while simultaneously using reinforcement learning to find a policy maximizing this reward, such that the learned policy will replicate the demonstrated behavior as well as possible.  A key feature of this method is that the learned reward function is defined by a learned distance metric, which evaluates the similarity between the agent's current trajectory, and the nearest demonstrated expert trajectory.",0.2804878048780488,0.19327731092436976,0.22885572139303487
1159,SP:6d65bbcb37acc413c086e5d32b250deeb9060037,"The authors propose a new method to sparsify DNNs based on a dropout induced by a Beta-Bernoulli prior. They further propose a data-dependent dropout by linking the Beta-Bernoulli prevalence to the inputs, achieving a higher sparsification rate. In the experimental section they show that the proposed method achieves better compression rates than other methods in the literature. However, experiments against some recent methods are missing. Also, some additional experiments using data-dependent dropouts not based on the Beta-Bernoulli prior would help to better disentangle the effects of the two contributions of the paper. Overall, the paper is well-written but the mentioning of the IBP is confusing. The authors devote quite a bit of space to the IBP when it is actually not used at all.","This work proposes Variational Beta-Bernoulli Dropout, a Bayesian way to sparsify neural networks by adopting Spike and Slab priors over the parameters of the network. Motivated by the Indian Buffet Process the authors further adopt Beta hyperpriors for the parameters of the Bernoulli distribution and also propose a way to set up the model such that it allows for input specific priors over the Bernoulli distributions. They then provide the necessary details for their variational approximations to the posterior distributions of both such models and experimentally validate their performance on the tasks of MNIST and CIFAR 10/100 classification.",0.14615384615384616,0.19,0.16521739130434784
1160,SP:6d70759d66c94400778b2bad913422e2ea28dac5,This paper proposes a more efficient version of ratio matching (RM) for training discrete energy-based models. The proposed method subsamples the dimensions to use in the original RM objective and then uses importance sampling to reduce variance. The importance sampling distribution is based on a Taylor-series approximation to the target energy function which approximates the minimal-variance importance sampling distribution. The authors show that this estimator is considerably more efficient than standard RM and enables RM to be applied to training EBMs in higher dimensions. The authors demonstrate their estimator on some toy datasets and to fit EBMs on graph data. The method is evaluated using MMD.,"The paper propose a Monte Carlo approximation for the expensive ratio matching method for learning discrete energy-based models. The key idea is to first write the ratio matching objective as an expectation wrt a uniform distribution, then use importance sampling for a more efficient estimation, where the optimal proposal distribution can be approximated by the gradient of the energy wrt the data space. Empirically, such an approximation shows even better results than the original expensive objective, possibly due to regularization from stochasticity and more focus on neighbors with low energies.",0.22935779816513763,0.27472527472527475,0.25
1161,SP:6d80f796adf8ca9c35f6fb2eee898eab1d71ad8e,"The paper proposes a novel dataset condensation technique that generates synthetic samples by matching model gradients with those obtained on the original input dataset. This technique is investigated empirically on several smaller datasets like MNIST, SVHN and CIFAR10. Two applications to continual learning and neural architecture search (NAS) are also explored and show some promising results.","This paper tackles the challenging dataset condensation problem. The goal is to learn to synthesize a small dataset, so that a neural network trained on the small synthetic dataset can have similar performance as a network trained on the full dataset. The proposed method tackles the problem by gradient matching. The proposed method achieves state-of-the-art performance, and shows promising results on two other downstream tasks, continual learning and neural architecture search.",0.2857142857142857,0.21621621621621623,0.24615384615384617
1162,SP:6dbb656031537976500fc17775a52c782ef46729,The paper proposes a method called neighbor2seq that converts the hierarchical structure of the center node to a sequence during message passing in graph neural networks. The proposed method aims to mitigate the issue of excessive computation and memory requirement of training graph neural networks. The proposed models Neighbor2Seq+Conv and Neighbor2Seq+Attn are tested on several datasets including a large scale benchmark dataset (ogbn-papers100M). The result shows some improvement especially on ogbn-papers100M while the improvement is not very obvious on other datasets.,"This paper proposed a simple graph neural network architecture that is easy to scale up and perform stochastic training. Instead of performing message passing as commonly used GNN, this paper first performs weighted combinations of node features per each hop of the neighbors of a center node, and then performs either CNN or attention mechanism to aggregate the features and obtain center node embedding. Since the feature aggregation can be performed offline, and the computation can easily be decomposed and stochastic training is straightforward, the method can easily scale up to graphs with 10M nodes. Experiments on median size or large size graphs show the comparable or better performance than alternatives. ",0.2,0.15315315315315314,0.17346938775510204
1163,SP:6dc30e63334ceb8d3ef8b987b0a1d92167c780c5,"This paper introduces the geometry-aware framework that can be adapted to any existing weight-sharing NAS methods optimized over gradient descent. The authors focus on the aspect of optimizing the architecture parameters to overcome the criticism of weight-sharing methods. The author's method relies on the mirror descent supporting their methods with a theoretical guarantee for the fast convergence. The author also supports their methods on various datasets such as CIFAR-10, ImageNet, NAS-Bench-201 (Dong & Yang), and NAS-Bench-1Shot (Zela et al.).","The submission presents a modification to the DARTS family of efficient Neural Architecture Search algorithms. The authors claim their modification (i) leads to better empirical performance, and (ii) is theoretically well-motivated. DARTS is a Neural Architecture Search algorithm which aims to find the most accurate network architecture within a human-defined search space.",0.10344827586206896,0.16666666666666666,0.1276595744680851
1164,SP:6deef1227ab2e0bf5dd2880ea7f3947490fb521d,"This paper proposes Divide-and-Conquer Monte Carlo Tree Search (DC-MCTS) for for goal-directed planning problems (i.e. problems where reaching a specific goal state is the objective, like traversing a maze with specified start and goal positions). The assumed setting is one where transition and reward models of the environment are not (necessarily) available, but a low-level goal-directed policy that can attempt to navigate from a given start to a given goal position, as well as value oracle that can return the success probability of the low-level policy on any given task, are available. Planning problems are modelled as AND/OR search trees, where OR nodes are labelled by a start state s and a goal state s'', and AND nodes are labelled by triples (s, s', s''). An OR node has children for every possible state, such that traversing to a child indicates the insertion of the corresponding state as an additional subgoal in between s and s', plus one extra child to indicate the choice of returning the current plan without inserting any additional subgoals. AND nodes have two children; one OR node for the first half (s, s') of the plan, and a second OR node for the second half (s', s'') of the plan. The MCTS can construct a plan by inserting subgoals such that they become easier to solve for the low-level policy by searching this tree.","This paper proposes Divide-and-Conquer Monte Carlo Tree Search (DC-MCTS), a planning algorithm for goal-directed decision-making problems, which makes a plan of the trajectory via recursive hierarchical partitioning. DC-MCTS assumes a (suboptimal) goal-directed low-level policy and its oracle value function. Then, it formulates the given planning problem as finding a sequence of sub-goal states and applies the divide-and-conquer strategy, i.e. split the original task into two sub-tasks (defined as initial state and goal state) and recursively solve them. Unlike the standard MCTS, the decision making of DC-MCTS operates not on the action space but on the state space of the problem, and the decision is made non-sequential way. Experimental results show that DC-MCTS outperforms the MCTS baseline that expands only the right sub-problem.",0.200836820083682,0.34532374100719426,0.25396825396825395
1165,SP:6dffc48a1e859d4fea90c951e8995ee38207819c,"The manuscript proposes  a distance aware pooling method to use in  graph convolutional neural for predicting whether a subject is infected with Covid-19 (diagnosis) and progression of the disease (prognosis). Experiments were conducted on CT images from three groups: Covid-19 group, common pneumonia group, and heathy group with about 900 samples in each group. The proposed model achieved 94.7% accuracy.    ","The paper is an application of GCN with good features on chest CT scan images for Covid-19 diagnosis and prognosis. First of all this is a relevant and appreciated effort when the world is fighting the pandemic. Hence some bonus points is directed towards that. As a whole, to the representation learning community, it adds limited research values apart from being an application of GCN which is aligned to the application track of ICLR. The paper claims that with less than 1% number of total parameters in the baseline 3D ResNet model, their method achieves 94.7% accuracy for diagnosis, which is marginally better than state of art - however whether the model was over-fitted is not clear. Prognosis information is an added claim, though automation part is not integrated.",0.2698412698412698,0.1297709923664122,0.17525773195876287
1166,SP:6e57d34252a302c1f3ce4aaacf6fb59fdbbf12b8,"Paper summary: The paper introduces an unsupervised method that utilizes an off-the-shelf BERT (without any fine-tuning) to create an information extraction system without any training data. It first creates ungrounded triples (a.k.a. OpenIE) from raw text by looking into the attention weights between words and finding a sequence of words through a beam search that has high attention weights between every consecutive words. When such sequence is created, the first and the last word become the head and the tail entities and the words between them becomes the relation. The next step is grounding each triplet to a known Knowledge Graph by utilizing off-the-shelf entity and relation grounding mechanisms. The proposed method shows 1-2% F1 score advantage over Stanford OpenIE on TAC KBP and Wikidata.","This paper presents an unsupervised approach for extracting OpenIE style triples from a corpus. The approach leverages the internal attention maps of pretrained transformers to identify paths which correspond to relations between a head entity and a tail entity. The extracted open triples are then mapped, wherever possible, to an existing KG to create what is referred to as an Open KG.",0.11278195488721804,0.24193548387096775,0.15384615384615385
1167,SP:6e9cc976b5835221dd518f26e3a9beaaaf6b890a,"The paper proposes compressing the layers of the neural networks using a product of sparse matrices. This approach is in line with the initial methods on neural network compression: direct (task-independent) compression of weights, which is followed by NN task-dependent fine-tuning. In this case, the direct compression is obtained using the Palm4MSA method of Magoarou and Gribonval (2016), and then models are fine-tuned in an end-to-end fashion using TensorFlow.","The authors introduced a neural network compressing method, based on factorization of weight matrix to the products of multiple sparse matrices. The goal is to achieve high compression rate. The author used a previous algorithm (Palm4MSA) to implement the method. The experiment result is better than other low-rank-based method, but is similar or worse to Iterative pruning and TT method.",0.18666666666666668,0.22580645161290322,0.20437956204379562
1168,SP:6eb1eee13155a89e5122099295567d3bbe403b30,"This paper studies the multi-source domain adaptation (MSDA) problem. The authors argue that the existing MSDA solutions (1) do not explicitly consider distribution conditioned on labels of each domain, (2) rely on limited feature extraction based on one extractor, (3) do not well explore target data due to the absence of label. Correspondingly, Multi-EPL is proposed based on moment matching.  ","The authors propose a novel method for multi-source domain adaptation (MSDA). For effective adaptation, the proposed method adopts three techniques: (1) label-wise moment matching, (2) pseudo-labeling target data, and (3) ensembling multiple feature extractors. Experimental results show that the proposed method outperforms several state-of-the-art methods in both image and text domains.",0.20967741935483872,0.22807017543859648,0.21848739495798322
1169,SP:6ebcd4fc6279bf7662a6691dae25f1bf4616432d,"The authors propose a predictive model based on the energy based model that uses a Transformer architecture for the energy function. It accepts as input an atom and its neighboring atoms and computes an energy for their configuration. The input features include representations of physical properties (atom identity, atom location within a side chain and amino-acid type) and spatial coordinates (x, y, z). A set of 64 atoms closest to the beta carbon of the target residue are selected and each is projected to a 256-dimensional vector. The predictive model computes an energy for the configuration of these 64 atoms surrounding a residue under investigation. The model is reported to achieve a slightly worse but comparable performance to the Rosetta energy function, the state-of-the-art method widely used in protein structure prediction and design. The authors investigate model’s outputs and hidden representations and conclude that it captures physicochemical properties relevant to the protein energy in general.","The paper proposes an Energy-Based-Model (EBM) for scoring the possible configurations of amino acid side chain conformations in protein structures with known amino acid backbone structure. The energy of the side-chain conformation (the chi-angle) for a given amino acid in the structure is calculated as a function of a local neighbourhood of atoms (A), where each atom is embedded into a 256d vector using its cartesian coordinates, atom identity, atom side-chain position and amino acid identity. The model is trained using approximate likelihood where the model samples are generated using precalculated table (from literature) of possible Chi angles conformations conditioned on the back-bone amino acid identity and back-bone angles. The results seem comprehensive comparing the transformer based energy function parameterization with two sensible baselines as well as the Rosetta energy function  which is the de facto standard tool for these types of calculations. Using rotamer recovery accuracy as the benchmark measure the empirical results are close to performance as the Rosetta energy model however always slightly worse. Further visualizations of the energy levels for different Chi angles seems to support that the learned energy function captures well known characteristics of the rotamer configuration energy landscape.",0.2360248447204969,0.18811881188118812,0.20936639118457298
1170,SP:6ebd0f56ad29eeb2a152333873da0c5614607174,"This paper proposes to learn the sub-graph patterns from a collection of training graphs. The key idea is to partition each graph into segments and enforce a global clustering of the subgraphs. The partitioning is also guided through contrastive learning, i.e., subgraphs should have a larger similarity with the graph it is drawn from, compared with other graphs. The learned GNN (that generates node embedding) will then be used to some downstream learning tasks with or without further fine-tuning. ","The paper describes a self-supervised framework to extract graph motifs and use them as input for downstream contrastive learning. The framework contains three components: (a) motif guided segmenter to derive node subgraphs, (b) a motif learning - a clustering task among the subgraphs to identify concrete graph motifs and (c) contrastive learner for downstream graph tasks. The global objective is defined as the sum of the likelihoods of the three components.  The framework is evaluated using from a large scale chemical compound graph dataset. The evaluation is performed for both transfer learning and utility of extracted features and outperforms the tested competing methods. ",0.2073170731707317,0.1650485436893204,0.1837837837837838
1171,SP:6ecf7180d11e9eaf100d489c1c20123cde7a258d,"This paper introduces a procedure for reconstructing the architecture and weights of deep ReLU network, given only the ability to query the network (observe network outputs for a sequence of inputs).  The algorithm takes advantage of the piecewise linearity of ReLU networks and an analysis by [Hanin and Rolnick, 2019b] of the boundaries between linear regions as bent hyperplanes.  The observation that a boundary bends only for other boundaries corresponding to neurons in earlier network layers leads to a recursive layer-by-layer procedure for recovering network parameters.  Experiments show ability to recover both random networks and networks trained for a memorization task.  The method is currently limited to ReLU networks and does not account for any parameter-sharing structure, such as that found in convolutional networks.","This paper introduces an approach to recover weights of ReLU neural networks by querying the network with specifically constructed inputs. The authors notice that the decision regions of such networks are piece-wise linear corresponding to activations of individual neurons. This allows to identify hyperplanes that constitute the decision boundary and find intersection points of the decision boundaries corresponding to neurons at different layers of the network. However, weights can be recovered only up to permutations of neurons in each layer and up to a constant scaling factor for each layer.",0.2125984251968504,0.2967032967032967,0.24770642201834864
1172,SP:6ee4bfb5b8a62e75eabf616a73f7f44c2adc4ead,"This paper proposes generative adversarial networks regularized by Determinantal Point Process (DPP) to learn diverse data space. DPP is a probabilistic model that encourages the diversity between the dataset. Authors observe that previous generative models have a mode-collapse problem, and they add generative DPP (GDPP) loss (eq (5)) as a diversity regularizer. Experiments show the GDPP loss is practically helpful to learn under synthetic multi-modal data and real-world image generation.","The paper proposes to introduce DPP into the vanilla GAN loss and uses it as a way to regularize the generator to produce more diverse outputs, in order to combat the mode-collapse problem. Since the proposed method is added as a simple loss regularizer, the approach does not introduce additional parameters, therefore, less training difficulties. The results on synthetic data seems promising, but there is insufficient evaluation being performed on real and larger dataset where the mode collapse problems are more likely to happen.",0.2328767123287671,0.2,0.21518987341772153
1173,SP:6ef6e5580db4cfa041bd6a0063953dc52c29a2a5,"The paper is focused on perturbation-based local explanation methods; methods that only need black-box(ish) access to the model and generally seek to find a region, pixel, etc's importance score through by removing that region, pixel, etc.. The intuition is that an important region if removed, will result in a large drop in the predicted class confidence. One main issue with such methods is that the removal itself can throw the image out of the data distribution and therefore result in a drop in confidence, not because of the region's importance, but because of the network's unpredictable behavior in such unseen parts of the input space. The work is focused on giving a solution to this problem: instead of removal through blurring, graying, etc, use inpainting; i.e. replace the removed region with using given the rest of the image. The idea has already been discussed out in the literature and the novelty of the work seems to be twofold: They introduce the same method in a way that is not curated for a specific perturbation-based method and could be concatenated with ""ANY"" given (or future) perturbation-based local explanation method (which authors notate by calling it ${existing_method}-G, they study robustness to hyper-parameter choice. ","The paper proposes a deep visualization technique for black-box image classifiers that feeds modified versions of the original input by means of an off-the-shelf (black box too) image inpainting approach (DeepFill-v1), in order to capture changes in the classification performance. In particular, the substitution of the input image follows three published paradigms: Sliding Patch (SP), Local Interpretable Model-Agnostic Explanations (LIME), Meaningful Perturbation (MP). Whereas the states of the art use gray images (SP, LIME)/blurred versions (MP) as substitution on different spatial supports (regular patch SP, random-shaped superpixel regions LIME, learned continuous region MP), the proposed approach inserts there the output of the inpainting.   ",0.11267605633802817,0.21818181818181817,0.14860681114551083
1174,SP:6f36e4a7b604bf894e65be9f88cc0f353a8bd1bf,"In this paper, the authors propose to learn surrogate loss functions for non-differentiable and non-decomposable loss. An alternative minimization method is used for training the surrogate network and prediction model. Learning surrogate loss functions for different tasks is somewhat novel, although there are some prior works on learning the loss, e.g., [1]. ","This paper proposes a method of learning loss functions in addition to the learning of predictors. Since it's not easy to optimize loss functions that evaluate the accuracy, surrogate loss functions have been widely employed. The design of the surrogate loss is problem-dependent, and handcraft is required. This paper tries to tackle this problem from the viewpoint of meta-learning, i.e., the surrogate loss learning. Typically, deep neural networks (DNN) are used to design a surrogate loss that approximates the original loss while maintaining the tractability of the optimization. Some convergence properties of the proposed method are analyzed. Some empirical studies showed the efficiency of the proposed method to the state-of-the-art baselines. ",0.3090909090909091,0.1440677966101695,0.19653179190751444
1175,SP:6f5d5acd8b55cc8dd01355d65adf10ea96ae7944,"The paper proposes a new transport-based divergence between distributions (CT) and a variant for empirical distributions (ACT). The new divergence is claimed to be more suitable for learning deep generative models than existing divergences like KL, JS (as in the vanilla GAN) and Wasserstein (as used in WGAN and its variants).  The proposed divergence mostly resembles, in my opinion, the Wasserstein divergence variant that uses the  Kantorovich–Rubinstein dual definition (which requires the learned function to be 1-Lipschitz). It seems that the main advantages of ACT over Wasserstein is that there is no constraint on the Lipschitz smoothness (which has to be enforced in WGAN by means of e.g. gradient clipping or gradient penalty), and the fact that ACT provides unbiased gradients that do not require the critic to reach an optimal point (as required in theory in GAN or WGAN).",The paper proposes conditional transport as a new divergence to measure the difference between two distributions. The idea is to learn the conditional transport plan of transporting one point in one distribution to the other marginal distribution. This conditional transport plan is modeled using a neural network. The resulting model is then applied to optimal transport formulation. Experiments are shown on image-based generative modeling dataset.,0.13194444444444445,0.2878787878787879,0.18095238095238095
1176,SP:6f78f139e4868101aba22e15be3678379fdccb6c,"This paper proposes a new type of models that are equivariant to entity permutations, which is an important criterion to build language models that can easily generalize to new entities. The authors modified a Memory-Network and a Third-order tensor product RNN to make them symbolic-shit invariant. The new models were evaluated and compared on the 20 bAbi tasks. Results show that the symbolic versions of the models yield better performance than the original ones.","The authors propose a network that is equivariant to entity permutations without requiring the pre-specification of the set of entities. To this end, the authors propose a hybrid semantic-symbolic embedding which they integrate into two QA models. Finally, the authors show significant gains on the bAbi tasks, with especially impressive gains in the 1K setting. ",0.22077922077922077,0.2982456140350877,0.25373134328358204
1177,SP:6f83e65ba5408b86d451f5545bf49100e9771f30,"This paper introduces TOGL, a new layer for Graph Neural Networks (GNN), making the GNN ""aware"" of topological information during this training phase. It differs from the closely related work *Graph Filtration Learning (GFL)* (although taking inspiration from it) as GFL is mostly a readout function (roughly, final layer in a GNN) while TOGL is a more general type of GNN-layer. Numerical experiments show how, when topological information is relevant, TOGL helps to leverage it.","The authors present a topology analysis improvement to GCN, using persistent homology, to capture global information regarding the topology of the graph.  The authors conduct several experiments, from graph to node classification, and also introduce two novel data sets to exemplify the importance of topology.  In most cases, the proposed method outperforms other baseline methods, as well as other topology aware methods.  ",0.09210526315789473,0.11290322580645161,0.10144927536231883
1178,SP:6f863f6927b23d0cd80b237580556db0a6880722,This paper presents and analyzes an accelerated algorithm for convex and strongly convex minimization when the objective function is an expectation of a convex function. It claims that the algorithm is optimal w.r.t. Mini-batch size and the convergence rate. The presented algorithm reaches the best-known rate for the accelerated stochastic algorithm and also shows the dependence on the mini-batch size is also optimal.  ,This paper improves the complexity bound w.r.t. minibatch speedup given by Cotter et al and Liu et al. for minibatch accelerated gradient descent for certain objectives (under sharpness condition). Generally the paper is well-organized with solid theoretical analysis and is easy to follow.  ,0.16176470588235295,0.2391304347826087,0.1929824561403509
1179,SP:6fa0afdd0b767254f88f9b06494f4193b4fd2c4f,"This paper focuses on the problem of Q value over-estimation in offline reinforcement learning and proposes three approaches (tricks) to help solve this problem. (1) estimate Q value of behavior policy avoiding max-operator in Q learning and take greedy action according to the behavior value estimation. (2) introduce ranking loss to push down the value estimation of all unobserved state-action pairs to avoid over-estimation. (3) use tanh operator to bound the range of Q value estimation, and learn a scale parameter with regularization term. The experimental results on several domains (Atari, Bsuite, Deepmind Lab) with discrete action space show performance better than existing algorithms.","The paper deals with offline aka batch RL for discrete actions. Three techniques ((i) behavior value estimation, (ii) ranking regularization, and (iii) reparametrization of the value function), which can be combined with each other, are presented. These techniques are compared with other methods in different experiments. Furthermore a new benchmark is being introduced.  It is claimed that in this new benchmark, the new techniques outperform state-of-the-art methods. Furthermore it is claimed that the presented method „behavior value estimation“, although it is only a one-step greedy optimization is typically already sufficient for dramatic gains.",0.12962962962962962,0.14432989690721648,0.13658536585365855
1180,SP:6fbc712869c021f261ee4e71e49a9043f8191925,The paper proposes SANE -- an architecture and a training algorithm for continual learning. The SANE model consists of a tree where each node can act as an RL agent and where nodes act according to the dispatching mechanism based on their reward prediction. This allows to activate and update only those agents that are specialized in the current task and thus may prevent catastrophic forgetting caused by updating the whole model.,"This work addresses multi-task learning where task boundaries are unknown. The approach is to construct a dynamic decision tree with nodes made up of small networks. Nodes are merged and promoted in the tree based on learned error bounds on value function estimates. Inference through the tree works by selecting nodes with the highest value prediction. It is an interesting approach for modular learning, even within the same environment.",0.15492957746478872,0.15714285714285714,0.15602836879432622
1181,SP:6fe5ce1a3c0f3a9a80bad30444dc2d51482b3b11,"The paper describes a family of sliced Wasserstein divergences that maximize the distribution over slices subject to constraints on the concentration of slices. Extremes of the family are the sliced Wasserstein and max-sliced Wasserstein distance. In between these the divergence is sensitive to informative discrepancies in multiple subspaces, while still leveraging the relatively fast computation the Wasserstein distance in one dimension for empirical distributions. A dual formulation provides a variational approximation using a (possibly deep) neural network to instantiate the slicing distribution through a pushforward approach. Basic theory prove the divergence is a distance metric between measures. Extensive experiments show improvement over sliced and max-sliced Wasserstein distances and related projection based approaches. ","The paper presents a novel variant of the Sliced Wasserstein (SW) distance. Wasserstein distances have been used recently in lot of machine learning problems. One of the major problem is that, in its primal form, it is computationally expensive. In order to alleviate this problem, a class of methods, called sliced, leverage on the fact that Wasserstein has a closed form expression in 1D (which amount to sort the samples). It replaces the original Wasserstein distance by an expectation of 1D sub-problems over directions drawn uniformly on the unit hypersphere (akin to a Radon transform). Observing that not all the directions are meaningful, the authors propose a variant of SW where the expectation over all the directions is replaced by an expectation over a distribution of directions. The ‘extent’ of this distribution is controlled by an extra parameter. Interestingly, the authors show that this formulation is computationally tractable if one parametrizes this distribution by a measurable function, expressed as a neural network. This result is obtained by deriving the Lagrangian dual of the original problem. Comparisons with previous works are then given in two GAN scenarii: one on MNIST to explore the importance of the different parameters, and another on larger and more complicated datasets, where the FID score is exposed. ",0.2543859649122807,0.13679245283018868,0.17791411042944785
1182,SP:6feb07f0db5f1efc2395d906e1c645fc8b512cae,"This paper considers the problem of learning the parameters of a two-layer ReLU network with a residual unit: given samples of the form $(x_i, y_i)$, with $y_i = B^*[(A^* x_i)^+ + x_i]$, the authors provide an algorithm that provably learns $A^*$ and $B^*$, as the sample size grows. It is crucially assumed that the entries of $A^*$ are non-negative and, by exploiting this fact, the learning problem is formulated via quadratic programming (QP): the authors show that there exist quadratic functionals whose minimisers can be used to deduce the ground-truth parameters. Furthermore, the QPs are re-written as linear programs (LPs), which are simpler to optimise and have the same solution space. Numerical results demonstrate the superiority of the proposed approach with respect to gradient descent methods.  ","This paper gives an algorithm for learning two-layer neural networks with ReLU activation (realizable case). The network also consists of skip connections to avoid the problems of identifiability. As a warm up, the authors first give a simple algorithms based on linear regression, whenever enough samples could be observed with all-positive and all-negative entries.   They start with an algorithm for recovering the layer two parameters. For this step, they use the $\ell_2$ loss and show that its minimizer is unique and matches with the ground truth parameters under certain condition. Subsequently, the authors replace the expectation in the objective with an average over the samples (based on the empirical risk minimization principle), which they could write as a convex quadratic program without making any parametric assumption. Finally, they show that the quadratic program can be equivalently written as a linear program, which lets them recover the parameters of the second layer (in fact the inverse matrix of this weight matrix).  Once layer 2 is learnt, the original problem reduces to that of learning the single layer non-linearity. They write the objective as a sum of weight estimator and a function estimator. They show that the minimizer of this loss is achieved when the estimated weight matrix is a diagonal matrix times the ground truth and the function measures the difference between the true nonlinear function and the scaled wright matrix. Again, they learn the function non-parametrically using a quadratic program, which they equivalently write as a linear program to get the scaled weight matrix. The scaling factors in the diagonal matrix can then be learnt using a linear regression.  Finally, the authors conduct extensive experimentation to validate that their algorithms performs superior to the vanilla SGD-based algorithm. They also show that their algorithm, especially the QP algorithm is robust to noise.",0.27611940298507465,0.12012987012987013,0.167420814479638
1183,SP:6feb5e58a91fa2eaab6a915a3897235ab02ebd82,"This paper builds upon the work of AdvGAN and proposes to add spatial transformations on top of it. The resulting attacking framework is demonstrated to outperform AdvGAN on attacking several defense approaches, such as Defense-GAN, AdvCritic and adversarial training. Compared to previous approaches on generating spatially transformed adversarial examples, this approaches amortizes the attacking procedure and can produce spatially transformed adversarial examples much faster. This approach also simultaneously combine spatial transformations and perturbations to make the attack stronger.",This paper proposes a new adversarial attack method by combining spatial transformations with perturbation-based noises. The proposed method uses two networks to generate the parameters of spatial transformation and the perturbation noise. The whole architecture is trained by a variant of GAN-loss to make the adversarial examples realistic to humans. Experiments on MNIST prove that the proposed attack method can improve the success rate of white-box attacks against several models.,0.20253164556962025,0.2191780821917808,0.2105263157894737
1184,SP:7003fdde96baedb55a47e5b42ad8d1866a86f5c7,"This paper incorporates information of obstacles to avoid (e.g robot navigation trajectory in the room where the robot has to avoid items such as furniture) into Gaussian process regression fit. They call the obstacles, negative datapairs and the rest of data, positive datapairs. The aim is to have a GP where the probability of passing through the negative datapairs is low. The proposed method is called the Gaussian process with negative constraints (GP-NC). ","This paper in concerned with Gaussian process regression under constraints that aim to discourage the model from learning certain values (negative constraints). These are called negative data pairs, and the authors propose an extension to the standard GP methodology to incorporate these constraints in the model. This is done by iteratively training a standard GP and maximising the KL between the GP and blobs of the negative data pairs.",0.24,0.2608695652173913,0.24999999999999994
1185,SP:701fd2e93907ea7c0c9c6e70d8eac8d91250e023,"This paper considers generative learning by discretizing a Wasserstein gradient with Euler methods. More precisely, some samples of a target distribution are given and the goal is to pushforward some samples of an initial distribution to the target distribution. The proposed method is obtained by  minimizing the f-divergence between the initial distribution and the target distribution, but considering the Wasserstein gradient flow of the f-divergence w.r.t. the target distribution (= the objective function). This Wasserstein gradient flow is discretized via Euler method to obtain the proposed algorithm. This Euler method involves the Wasserstein gradient of the objective, which is intractable. The authors describe a statistical methodology to compute this Wasserstein gradient based on the samples of the target distribution and samples from the current distribution. They also prove a bound for the estimated Wasserstein gradient wrt the true Wasserstein gradient. Finally, the paper presents relevant numerical experiments.","This paper tackles generative modeling (sampling, in particular) via finding the push forward functions T (equivalently, the velocity fields v) that iteratively moves particles from a reference distribution toward the target data distribution. The velocity fields are solved by minimizing the f-divergence between the particle density at iteration k and the target data density, which is shown to be in the form of gradient of density ratio. Based on this intuition, the training stage becomes estimating the density ratio via neural networks, for each iteration k=1,...,K. However, estimating the density ratio can be quite difficult when two densities have little overlapping support. Thus, the author proposes to add gradient regularizer to the density ratio estimating function. The experiment on real-world computer vision benchmarks demonstrate reasonable sampling quality, and the FID score on CIFAR-10 is comparable to some GAN baselines in the generative modeling literature.",0.22666666666666666,0.22818791946308725,0.22742474916387959
1186,SP:7028036b485c4e14aa50cc8a9f788f11b8807dd2,"In the paper, the authors carry out theoretically analysis on the expressive power for GNN. The analysis focused on the limiting case when the depth of layers goes to infinite. The authors prove that if the weights of the GNN satisfy certain condition based on the graph Laplacian, then the transformed features contain only degree and connected component information. Then the authors study the G_{np} random graph as a special case. Finally, empirical experiments are carried out to corroborates the theoretical results.","The paper studies why graph NNs lose the expressive power as additional layers are added. A dynamical system perspective is adopted and used to show that under certain conditions on the weights, the expressiveness of the network deteriorates. This is since the network's output eventually only carries information about superficial graph properties for distinguishing nodes, and nothing else. A case study of Erdos-Renyi graph is provided, showing that for dense graphs information loss indeed occurs. Guidelines to try and deal with this in practice were devised and empirically examined.",0.2289156626506024,0.2087912087912088,0.21839080459770116
1187,SP:707b1ba524c785d8942517ba7dff17115012181f,"This paper provides a empirical study on the robustness of image classification models to distributions shifts. The authors construct three benchmark datasets that control for effects like artistic renditions of common classes, view-point changes, and geographic shifts (among others). The datasets are then used to test various hypotheses regarding robustness enhancing measures empirically. The authors additionally propose a novel augmentation scheme, that uses deep image processing networks together with random perturbations of their weights to synthesize distorted image samples.","This paper investigates the robustness problem of computer vision model. To study the model robustness in a controlled setting, the author introduces three new robustness benchmarks: ImageNet-R, StreetView StoreFronts and DeepFashion Remixed. Each of them address different aspects of distribution drift in the real world. The author evaluates seven popular hypotheses on model robustness in the community on the three new datasets and has found counter-example for most of them. Based on those new results, the author concluded that model robustness problem is multi-variate in nature: no single solution could handle all aspects yet. And future work should be tested on multiple datasets to prove robustness. Moreover, the author also proposes a new data augmentation method using perturbed image-to-image deep learning model to generate visually diverse augmentations.",0.2625,0.1590909090909091,0.1981132075471698
1188,SP:707e8ce06a2315ede25190c7e4f5fc5e663d200f,"This paper introduces Adaptive Filters that enable some of the benefits of Message Passing architectures, but while maintaining a memory consumption that scales with the number of nodes.  The authors claim that this architecture is not only better performing, and use less memory, but more efficient for GPUs through the use of sparse matrix multiplication.  The idea of the model is that you have a number of filters (MLPs or linear layers) applied to each sending node latent, a ""filter"". These are then weighted and summed by a weighting vector calculated as a function of the receiving node. Since there are no functions that take as input both sending, receiving or edge inputs, the memory will scale with the number of nodes. You, in essence, get an efficient pseudo-attention mechanism.  ","This paper claimed they designed a new GNN architecture that achieves state-of-the-art performance with lower memory consumption and latency. More specifically, the proposed model uses memory proportional to the number of vertices in the graph $O(V)$, in contrast to competing methods which require memory proportional to the number of edges $O(E)$. The paper claimed that the new architecture enabled each vertex to have its own weight matrix, thus following a novel adaptive filtering approach. The experiments found that the proposed efficient model could achieve higher accuracy than competing approaches across six large and varied datasets against strong baselines. Moreover, the experiments demonstrated that the proposed method achieves lower latency and memory consumption for the same accuracy compared to competing approaches.",0.183206106870229,0.192,0.1875
1189,SP:708564ba7c606c5f162032bff2ed6a5f41e6c7ef,"It has previously been observed that training deep networks using large batch-sizes leads to a larger generalization gap compared to the gap when training with a relatively small batch-size. This paper proposes to add noise sampled from diagonal ""empirical"" Fisher matrix to the large batch gradient as a method for closing the generalization gap. The authors motivate the use of empirical Fisher for sampling noise by arguing that the covariance of gradients from small batch-sizes can be seen as approximately equal to a scaled version of the Fisher matrix. It is then pointed out that using the Fisher matrix directly to sample noise could in principle close the generalization gap but would lead to slow converegence similar to SGD with a small batch-size. The authors then claim that the convergence speed is better when noise is sampled from the diagonal Fisher matrix instead of the full Fisher matrix. This claim is proven in theory for a convex quadratic loss surface and experiments are conducted to empirically verify this claim both in the quadratic setting are for realistic deep networks. Finally an efficient method for sampling noise from the diagonal empirical Fisher matrix is proposed.","In this paper, the authors propose a method to close the generalization gap that arises in training DNNs with large batch. The author reasons about the effectiveness in SGD small batch training by looking at the curvature structure of the noise. Instead of using the naïve empirical fisher matrix, the authors propose to use diagonal fisher noise for large batch SGD training for DNNs. The proposed method is shown empirically to achieve both comparable generalization and the training speedup compared to small batch training. A convergence analysis is provided for the proposed method under convex quadratic setting. ",0.15656565656565657,0.3163265306122449,0.20945945945945946
1190,SP:70bb2ad8b8a46670e6ee60a6800656c4f2220ad0,"This paper considers the deep one-class classification problem. Some recent state of the art in this area is built upon self-supervised learning methods that are trained to predict the rotation applied to a training image, and then use the success of rotation prediction on test images as an outlier score. The paper observes that, while successful on standard benchmarks, this strategy is not robust to unexpected image rotations at test-time. Since, humans are (presumably) able to exhibit rotation invariance during test-time in 1-class classification, this is considered a flaw in existing methods. To rectify this flaw, the paper proposes to use an anomaly score which is the maximum over all possible rotation predictions. The results show that the proposed method outperforms prior approaches when exposed to novel rotations at test time. ",This paper presents a one-class classifier robust to geometrically-transformed inputs (GROC). A conformity score is proposed that measures how strongly an input image agrees with one of the predefined in-class transformations. Experiments show that the proposed method works well on 3 datasets for out-of-class detection and produces similar scores for in-class images under different transformations.,0.11764705882352941,0.26229508196721313,0.16243654822335027
1191,SP:70dd6ee712270dc93c4d1e1c20c31748e072adf2,"This paper proposes a new meta-reinforcement learning algorithm, MSGI, which focuses on the problem of adapting to unseen hierarchical tasks through interaction with the environment where the external reward is sparse. The authors make use of subtask graph inference to infer the latent subtask representation of a task through interacting with the environment using an adaptation policy and then optimize the adaptation policy based on the inferred latent subtask structure. Each task in the paper is represented as a tuple of subtask precondition and subtask reward, which are inferred via logic induction and MLE of Gaussians respectively. At meta-test time, MSGI rollouts a subtask graph execution (SGE) policy based on the graph inferred from the interactions between the environment and the adaptation policy. The authors also propose a UCB-inspired intrinsic reward to encourage exploration when optimizing the adaptation policy. Experiments are conducted on two grid-world domains as well as StarCraft II.","The authors propose a novel meta-rl problem where hierarchical tasks are characterized by a graph describing all sub-tasks and their dependencies. They propose a meta-rl approach to meta-train a policy that quickly infers the subtask graph from new task data. The approach is compared to relevant baselines from both the meta-rl and hierarchical rl literature on complex domains. In particular, the authors consider a large-scale Startcraft II experiment which proves the efficiency and scalability of the proposed methodology.",0.13548387096774195,0.25,0.17573221757322177
1192,SP:70e602af7d74d3cc54c6e39d9ac4733460adf758,"The paper proposes an empirical solution to coming up with a hierarchy of deep learning tasks or in general machine learning tasks. They propose a two-way analysis where power-law relations are assumed between (a) validation loss and training set size, and (b) the number of parameters of the best model and training set size. The first power-law exponent, \beta_g, indicates how much can more training data be helpful for a given task and is used for ordering the hardness of problems. The second power-law exponent, \beta_p, indicates how effectively does the model use extra parameters with increasing training set (can also be thought of as how good the model is at compression). From experiments across a range of domains, the authors find that indeed on tasks where much of the progress has been made tend to be ones with smaller \beta_g (and \beta_p). It's arguable as to how comparable these power-law exponents are across domains because of differences in losses and other factors, but it's definitely a good heuristic to start working in this direction.   ","The authors propose to measure the power-law exponent to sort natural language processing, speech and vision problems by the degree of their difficulty. The main idea is that, while in general model performance goes up for most tasks if more training data becomes available or for bigger model sizes, some tasks are more effective at leveraging more data. Those tasks are supposed to be easier on the proposed scale.",0.0967741935483871,0.2571428571428571,0.14062499999999997
1193,SP:70fa69d4e05f33ab8386117417c229a60e55b658,"The paper proposes a molecule representation learning method which is guided by chemical reactions.  In particular, it leverages chemical reaction equations by forcing the sum of reactant embeddings and the sum of product embed- dings to be equal for each chemical equation.  This idea is simple and useful, sharing the spirit of Word2Vec and TransE.     ","The paper is about learning a vector representation of molecules in a way that the learned representation preserves the equivalence of molecules with respect to chemical reactions. They do so by forcing the sum of reactant embeddings and the sum of product embeddings to be equal for each chemical equation.  They have also shown experimentally that such embeddings can improve the performance of downstream tasks such as chemical reaction prediction, molecule property prediction, and graph edit distance prediction problems. ",0.509090909090909,0.35443037974683544,0.417910447761194
1194,SP:70ffdb2504b0c72a7be46dec6a519b9717fb7d41,The paper considers the problem of using CNNs on an irregularly sampled grid. It proposes to incorporate the numerical uncertainty related to the disretisation of the domain using an approach inspired by probabilistic numerics. This involves defining continuous convolutional layers as affine transformations of the input GP and use rectified GPs to include the nonlinearity in the mapping. The resulting non-Gaussian distribution is then approximated with another GP in each layer. These are then approximated with a GP with an RBF kernel using Monte Carlo to produce observations with input dependent noise. The model is trained using MAP estimation.,"This work presents an uncertainty aware continuous convolutional layers for learning from continuous signals like time series/images. This work is most useful in the setting of irregularly sampled data. Gaussian processes (GP) are used to represent the irregularly sampled input. The proposed continuous convolutional layers can be directly applied to input Gaussian Process in a closed form, which subsequently outputs another GP with transformed mean and variance. Finally, the continuous convolutional layers are parameterized in terms of the flow of a PDE. The use of GP for feature representation and the ability of continuous convolutional layers to take GP as input provides the model with the ability to propagate uncertainty.",0.22,0.1981981981981982,0.20853080568720378
1195,SP:7102235a9333e4d73a5f90d5241ec37ca3fe9345,"The paper proposes hinge policy optimization, a new theoretical framework for interpreting policy gradient algorithms as classification problems to be solved with a hinge loss. In this perspective, the sign of the advantage function becomes the label, and the difference in action probabilities between policy after and before an update becomes the classifier's output. The paper shows the equivalence between such a formulation and the popular PPO-clip objective and provides global converge guarantees on the blueprint of (Agarwal, 2020). It also proposes a range of policy optimization algorithms, depending on the details of the classification algorithm that is used, and empirically evaluates some of them."," This paper reinterprets the theory of PPO-clip based on the hinge policy optimization. They prove the global convergence of PPO by introducing some assumptions. Besides, they generalize the algorithm to a new family of policy-based algorithms by regarding the policy as a generalized classifier.",0.1308411214953271,0.30434782608695654,0.18300653594771238
1196,SP:71274cc432cc95a2d80418365896096b875be5c1,"The paper revisits two methods, Linear and Gaussian, as described in the literature, to probe language models based on individual neurons. The paper suggests that these methods contain two limitations - 1. by ranking the neurons on a linguistic task, the methods conflate between ranking quality and the probe's classification quality; 2. the probing methods do not take into account whether the individual neurons are at all used by the model in the downstream linguistic tasks. Finally, the paper presents a new probing method, which does not rely on training a classifier, and shows that this simple method is able to discern among the neurons better than the preceding two methods in the literature. ","This paper responds to several recent works focused on identifying important individual neurons for particular classifying tasks. They consider 2 existing methods which rely on an external probe to rank the neurons in a network. They also introduce a method that does not rely on a probe, instead ranking neurons according to the difference between their values across labels.  The primary focus in this paper is on two claimed flaws of the existing neuron ranking methods. The first is that the authors feel evaluation of the neuron rankings is unfair because a high quality probe can have higher performance on a worse ranking, simply because it is better able to take advantage of the data that is offered. The second is that not all rankings actually point to neurons that are specialized for a particular task or label, instead just indicating highly informative neurons.  In analyzing these two flaws, the authors develop evaluation metrics for the rankings of these neurons. They consider a ranking better if the neurons encode information that is specific to the label while maintaining the particular lemma being encoded. They also consider the ranking to be better if removing the features indicated damages the performance of the language model. They test two ways of modifying the network to remove important neurons, first by ablating the neurons and then by learning a geometric translation that moves a word towards a different attribute label.  They also consider the ranking better if a ranking from top to bottom outperforms a random ranking, which outperforms a reversed ranking. This seems like a fairly weak standard to hold a ranking to, but some rankings fail to adhere to it.",0.2719298245614035,0.11151079136690648,0.15816326530612243
1197,SP:7139396d6c963f47a49ef43997d1c2a57a2181c8,"The idea of having a separate class for out-distribution is a very interesting idea but unfortunately previously explored. In fact, in machine learning and NLP there is the OOV class which sometimes people in computer vision also use. Some of the claims in the paper can be further substantiated or explored. For example in abstract there is a simple claim that is presented too strong: We also demonstrate that training such an augmented CNN with representative out-distribution natural datasets and some interpolated samples allows it to better handle a wide range of unseen out-distribution samples and black-box adversarial examples without training it on any adversaries. This claim is bigger than just CNNs and needs to be studied in a theoretical framework not an empirical one. Also, one simple way to stop these adversarial cases would be to explore using Sigmoid as opposed to softmax. In general it is very unlikely that you will be able to choose every variation of out-distribution cases. Much easier if you just try to solve the problem using a set of n Sigmoids (n total number of classes) and consider each output a probability distribution. ","The paper propose to incorporate an additional class for adversarial and out-distribution samples in CNNs. The paper propose to incorporate natural out-distribution images and interpolated images to the additional class, but the problem of selecting the out-distribution images is itself an important problem. The paper presents a very simple approaches for selecting the out-distribution images that relies on many hidden assumptions on the images source or the base classier, and the interpolation mechanism is also too simple and there is the implicit assumption of low complexity images. There exists more principled approaches for selecting out-distribution images that has not considered here like those based on uncertainty estimation or recently proposed direct out-distribution detectors.",0.13333333333333333,0.2184873949579832,0.1656050955414013
1198,SP:714e3ea5fb183b203c2d6f62293f754124524418,"This paper presents Self Imitation via Reduction (SIR) an approach to learning long-horizon tasks by successively reducing it to easy to solve tasks, generating solutions to these easier tasks and self-imitation on successful task solutions. This is done by training a goal-conditioned policy together with a universal value function. When given a task that cannot be solved via the current policy, SIR searches for an intermediate state that divides the task into two easily solvable sub-tasks; this search is carried out by maximising the (composed) value of the sub-trajectories under the current policy. The policy is then executed for these sub-tasks in sequence; success in both these sub-tasks means a solution for the full task is now found. This solution is used as a demonstration that the policy can use for self-imitation via an advantage weighted behavioural cloning objective. This is combined with the policy loss of standard actor-critic algorithms such as SAC and PPO in both the off-policy and on-policy settings respectively and shows significant performance improvements compared to baselines on several long-horizon tasks such as robotic pushing, stacking 3 blocks and a multi-room maze task. ",This paper proposes a new method that combines task reduction and self-imitation learning for goal-based reinforcement learning problems. The idea is to decompose a hard task into two subtasks (subgoals) such that the solution to one of them is already known. Self-imitation learning is used to quickly learn to reproduce such successful trajectories. The experimental result shows that the proposed method outperforms the baseline SAC + HER and SAC + SIL as well as hierarchical architectures such as HIRO and DSC.,0.12,0.2926829268292683,0.1702127659574468
1199,SP:71511ac32bc7e86a19296e8b049f38bd43e31d29,"Based on recent progress in unbiased MCMC sampling the paper proposes an unbiased contrastive divergence (UCD) algorithm for training energy based models. Specifically they developed an unbiased version of the gibbs sampling contrastive divergence algorithm for training restricted Boltzman machines. The authors demonstrate their method on a toy dataset, simulated data, as well as a reduced version (only the zero digits) of the MNIST dataset and compare the results with the standard Contrastive divergence and Persistent Contrastive Divergence methods.","The paper proposes an algorithmic improvement that significantly simplifies training of energy-based models, such as the Restricted Boltzmann Machine. The key issue in training such models is computing the gradient of the log partition function, which can be framed as computing the expected value of f(x) = dE(x; theta) / d theta over the model distribution p(x). The canonical algorithm for this problem is Contrastive Divergence which approximates x ~ p(x) with k steps of Gibbs sampling, resulting in biased gradients. In this paper, the authors apply the recently introduced unbiased MCMC framework of Jacob et al. to completely remove the bias. The key idea is to (1) rewrite the expectation as a limit of a telescopic sum: E f(x_0) + \sum_t E f(x_t) - E f(x_{t-1}); (2) run two coupled MCMC chains, one for the “positive” part of the telescopic sum and one for the “negative” part until they converge. After convergence, all remaining terms of the sum are zero and we can stop iterating. However, the number of time steps until convergence is now random.",0.2911392405063291,0.12432432432432433,0.17424242424242423
1200,SP:715a15ec1c82c4035af24af0827861ab787d817e,"This paper proposes a novel optimization framework for Out-Of-Distribution (OOD) generalization problems. OOD generalization problem is one of the most important problems in today's machine learning,  and it is highly non-trivial to investigate it at the optimization framework level. The proposed framework focuses on the integration of latent heterogeneity discovery and invariant learning on representation level, by introducing neural tangent kernel (NTK). Theoretical analysis is also conducted to verify the mutual promotion of these two modules. Experiments show that the proposed method can significantly outperform the commonly used and latest optimization algorithms.","This paper studies the out-of-distribution (OOD) generalization problem. It proposes a Kernel heterogeneity & Invariance Learning method, which jointly learns both the latent heterogeneity exploration and invariant learning in kernel space. This paper provides strong theoretical guarantees for the proposed method. We know the proposed method makes clear improvements over related baselines in OOD scenarios from the empirical results.",0.22916666666666666,0.36666666666666664,0.28205128205128205
1201,SP:71b2e4fade72b5f739fb6c5a4c996aa8804e458f,"The paper focuses on improving object localization, though the title highlights ""interpreting deep neural network"" which is another area. It analyzes the classifier weights for image classification, and compute the derivative of the feature maps from the network for a sensitivity map of the image. Then it learns a simple linear mapping over the sensitivity map for bounding box regression. Experiments report competitive performance.","The paper presents a method to perform object localization by computing sensitivity of the network activations with respect to each pixel. The key idea is that the representation for classification implicitly contains object localization information since the object classification is done by detecting features of an object in an image. The localization information is extracted as a form of sensitivity map which indicates each pixel’s contribution to the final classification decision, and is subsequently used for regressing the bounding box. The proposed method outperforms other baseline methods and achieves reasonable performance when compared with slower state-of-the-art deep learning techniques for object localization.",0.328125,0.19811320754716982,0.24705882352941178
1202,SP:71b7633050462a3cfc3d64e81ae3f6cec758f068,"In this paper the authors adopt prior work in image inpainting to the problem of 2d fluid velocity field inpainting by extending the network architecture and using additional loss functions. Specifically, the U-net network is extended with a DenseBlock in the middle, and a separate branch of the network is added which predicts the stream function (a different representation of the velocity field which guarantees incompressibility). The additional losses are L1 for various derivatives of the flow field (Jacobian, divergence, vorticity). Experiments presented in the paper show that these new elements improve the flow field error compared to a baseline model originally developed for image inpainting. The suggested application for this model is filling gaps in experimental measurements that are missing or impossible to obtain, and where such a model could be computationally cheaper than an actual fluid solver.","I am not an expert in recent Navier-Stokes approaches, but note that there is a lot of recent work in physics aware modeling.  Specifically the sections on e.g. loss seem to have a lot of prior work. It’s difficult for me to judge the exact amount of novelty in this paper with respect to the physics. With respects to the DL part it looks like it’s mainly minor modifications to the known U-net architecture. ",0.10714285714285714,0.189873417721519,0.136986301369863
1203,SP:71be5d3799276330663155b5c9c04b4a8074e800,"The paper proposes a novel combination of prototype learning and deep nearest neighbor learning in order to achieve an embedding of the input data that is more friendly for prototype learning while maintaining the computational efficiency and intepretability of a prototype approach. In more detail, the approach first trains a Multi-scale deep nearest neighbor network to embed the input data. Then, it jointly learns a prototype layer and a fully connected layer which outputs class logits based on distances to prototypes. Finally, the learned prototypes are replaced by the closest sample from the actual training data to enhance interpretability. In experiments on MNIST, FashionMNIST, CIFAR-10, and ImageNet, the paper shows that the proposed approach outperforms state-of-the-art prototype learning.","The paper introduces a novel an interpretable neural network for classification tasks that works by assigning input cases to prototypical cases based on their euclidean distance in an embedding space learned by the network. This is achieved by minimizing a loss function consisting of three components: cross entropy loss; distance between each case and the prototype with the same class, distance between each prototype and the closest case to it. The proposed method is specially useful when classification at fine-grained level is performed where in addition to the class to which an instance belongs, predicting the subclass is desirable as well. Experimental results are provided in the paper that validates the merits of the method compared to a set of variations of the proposed method and a state of the art approach as well.",0.23577235772357724,0.21481481481481482,0.22480620155038758
1204,SP:71cba50055f4eaa6e1cc1f3cc40789788f26d60d,"The paper proposes a self-supervised method to fit a template (represented as a union of Coons patches) to a certain 2D sketch. It derives a way to build a proper template, uses a network to predict the patches' parameters, and proposes a union of different losses. The qualitative results of the method are shown in several different objects. ",This paper presents a method that leverages parametric surface patches as the fundamental representation in the task of shape modeling and reconstruction. This method requires a pre-generated template for each shape category. Several losses are specially designed to regularize the generation of the surface patches. Empirical results have demonstrated the performance of the proposed method in sketch-based shape reconstruction and 3D shape interpolation.,0.2711864406779661,0.24615384615384617,0.25806451612903225
1205,SP:71d2c08c45a1f4635bb51699e5833c74699731f2,"This work studies a number of curriculums for faster training of neural networks. They first propose a curriculum named DCL+ that is designed to order data points based on their alignment of gradient with the direction of optimization. This curriculum depends on the evaluation of individual gradients of datapoints as well as an approximation to a local optima. Next, they study a number of easy-to-compute statistical measures for ordering data points.","The paper contains two curriculum learning algorithms of which one assume knowledge of the parameters found by the baseline, uniform-sampling, model to push updates in that direction, and the second orders images according to an increasing stddev/entropy of pixels. While the first approach is impractical because of the strong assumption, the second approach demonstrates small gains that lie within random variance (Fig. 5, Fig. 6) and would be not straight-forward to apply to non-image data e.g. text. These reasons make the paper hard to accept.",0.1506849315068493,0.12222222222222222,0.1349693251533742
1206,SP:71d504ec722cacab616fca85dd2937b93e71caaf,"This paper proposes a new architecture, R-Transformer, that blends the Transformer networks and the recurrent networks, so as to better capture both the long- and short-term features. By injecting a local RNN layer at every level of the network, the authors hoped to enhance the Transformer's ability to model locality structure. To demonstrate the modeling power of R-Trasnformer, the paper evaluates the effectiveness of R-Transformer on 4 different sequence tasks (seqMNIST, polyphonic music, character- and word-level PTB).","The paper introduces the R-Transformer architecture which adds a local RNN layer before each attention layer in Transformer. The authors claim state-of-the-art performance but only test on tiny tasks where Transformer models have not been heavily optimized and omit the main problem with RNNs - namely their speed. It is an interesting paper still and the locality is a nice way to remedy the speed problem, but the paper lacks a true study and ablations on this main limitation. In summary: the main new idea of the paper is to make RNNs local in Transformer (trying to add RNN layers has been explored before). This idea could be a good tradeoff between full RNN (slow) and no RNN (lack of context), but the following is missing: (1) ablations on speed vs results by locality window, (2) experiments on more widely reported and larger data-sets and models, at least including some language modeling task (wiki or lm1b) and some translation task (like en-de). Without these results, we cannot recommend to accept this paper.",0.25301204819277107,0.11864406779661017,0.16153846153846155
1207,SP:71f7eaa182cb9a6bb9e669e0e3df9e0251e81641,"The authors introduce a novel distance function between point sets, based on the ""permutation invariance"" of the zeros of a polynomial, calling it ""holographic"" distance, as it essentially depends on all the points of the sets being compared. They also consider two other permutation invariant distances, and apply these in an end-to-end object detection task. These distance functions have time-complexity O(N^2) unlike the previously proposed ""Hungarian distance"" based on the Hungarian algorithm which is O(N^3) in general. Moreover, they authors show that in two dimensions all local minima of the holographic loss are global minima.","This paper proposes a new loss for points registration (aligning two point sets) with preferable permutation invariant property. For a 2D point set, the idea is to define a complex polynomial with the points (interpreted as complex numbers) as roots. To compare two point sets, the loss eventually boils down to evaluating the complex polynomial at all target points. The loss can be extended to high-dimensional point sets without the same theoretical framework. It is a sum over each target point the product of the distance of between the target point and all points of the source set. The claimed advantage of the proposed distance is it is more efficient compare to other metric such as Hausdorff distance or the sum of squared distance between matched point pairs (SMD). Experiments show that the proposed loss can be used in training.",0.20588235294117646,0.14893617021276595,0.1728395061728395
1208,SP:720aa05838e9926dafd1161847b197b8f2f8a64a,"This paper investigates the problem of learning new branching heuristics in SAT solvers. The idea is very simple: take MiniSat, remove the usual VSIDS heuristic, and replace it with a variable selection policy that has been trained from a deep reinforcement learning algorithm. The architecture advocated in the present study is based on GNNs coupled with usual DQN techniques. The resulting GQSAT heuristic is endowed with attractive properties: on random SAT instances, it outperforms VSIDS and generalizes relatively well to other SAT distributions. ","The paper proposes learning a branching heuristic to be used inside the SAT solver MiniSat using reinforcement learning. The state is represented as a graph representation of the Boolean formula as in previous works, and the policy is parameterized as a graph neural network. At each step of an episode the policy selects a variable to branch on and assigns a value to it. The episode terminates once the solver finds a satisfying assignment or proves unsatisfiability. The reward function encourages the policy to reach terminal state in as few steps as possible. The policy is trained using DQN. Results on randomly generated SAT instances show that the learned policy is able to solve problems with fewer steps than VSIDS, the branching heuristic commonly used by state-of-the-art solvers.",0.24096385542168675,0.15267175572519084,0.18691588785046728
1209,SP:722584f20a74efbfb6e50fb795aa33a39d73f13b,"This work presents 1) Semi-Relaxed Quantization (SRQ), a method that targets learning low-bit neural networks, 2) DropBits, a method that performs dropout-like regularization on the bit width of the quantizers with an option to also automatically optimise the bit-width per layer according to the data, and 3) quantised lottery ticket hypothesis. SRQ is an extension of Relaxed Quantization (RQ), which is prior work, in two ways; firstly the authors replace the sampling from the concrete relaxation during training to deterministically selecting the mode (which is non-differentiable) and, secondly, they propose a specific straight-through gradient estimator (STE) than only propagates the gradient backwards for the elements that were selected in the forward pass. DropBits is motivated from the perspective of reducing the bias of the STE gradient estimator by randomly dropping grid points associated with a specific bit-width and then renormalising the SRQ distribution over the grid. This essentially induces stochasticity in the sampling distribution for the quantised value (which was removed before by selecting the mode in SRQ). The authors further extend DropBits in a way that allows for learning the drop probabilities for each bit-width, thus allowing for learning mixed-precision networks. Finally the authors postulate the quantised lottery ticket hypothesis, which refers to that “one can find the learned bit-width network which can perform better than the network with the same but fixed bit-widths from scratch”.","This paper deals with network quantization. It proposes Semi-Relaxed Quantization (SRQ) that uses a multi-class straight-through estimator to effectively reduce the bias and variance, along with a new regularization technique, DropBits that replaces dropout regularization to randomly drop the bits.  Extensive experiments are conducted to validate our method on various benchmark datasets and network architectures.",0.08403361344537816,0.3448275862068966,0.13513513513513514
1210,SP:7227922e5ec088fabf0fa9c0584ee4f5c1f3887a,"This paper proposed a new sampling method to train GCN in the mini-batch manner. In particular, unlike existing methods which samples the mini-batch in the node-wise way, GraphSAINT proposed to sample a mini-batch in the graph-wise way. As a result, GraphSAINT uses the same graph across different GCN layers, while most existing methods use different graphs across different GCN layers.  In addition, the authors show that this sampling method is unbiased. Extensive experimental results have shown improvement over existing methods. Overall, this idea is interesting and well presented. ","Scaling GCNs to large graphs is important for real applications. Instead of sampling the nodes or edges across GCN layers,  this paper proposes to sample the training graph to improve training efficiency and accuracy. It is a smart idea to construct a complete GCN from the sampled subgraphs.  Convincing experiments can verify the effectiveness of the proposed method.  It is a good work.",0.11827956989247312,0.1746031746031746,0.14102564102564102
1211,SP:725bd7a5265c0426b0424b213af01cc90834a442,"This paper sets out to build good bilingual word alignments from the information in an NMT system (both Transformer and RNN), where the goal is to match human-generated word-alignments as measured by AER. At least that’s how it starts. They contribute two aligners: one supervised aligner that uses NMT source and target representations as features and is trained on silver data generated by FastAlign, and one interpretability-based aligner that scores the affinity of a source-target word-pair by deleting the source word (replacing its embedding with a 0-vector) and measuring the impact on the probability of the target word. These are both shown to outperform directly extracting alignments from attention matrices by large margins. Despite the supervised aligner getting better AER, the authors proceed to quickly discard it as they dive deep on the interpretability approach, applying it also to target-target word pairs, and drawing somewhat interesting conclusions about two classes of target words: those that depend most of source context and those that depend most on target context.","This paper empirically evaluates whether NMT can predict word alignment. This is done by measuring the alignment error rate between silver-data generated from FastAlign and various methods to extract alignment from NMT. The conclusions are that NMT attention does not predict alignment well, and the proposed method of training an additional alignment extraction model performs better. ",0.09090909090909091,0.2807017543859649,0.13733905579399142
1212,SP:72719789a5653ae47a06265616e77c12fe9da7d4,"This paper studies the problem of learning both the distance metric and a linkage rule from clustering examples. Suppose we have L metrics d_1, …, d_L and L’ linkage rules for hierarchical agglomerative clustering, D_1, …, D_L’ where each rule is a 2-point-based merge function (i.e. computes the distance between some two points in the clusters, examples of such functions are single-linkage and complete-linkage). The paper considers the problem of finding the convex combination of the distance functions and linkage rules which best fits the data. The main result (Theorem 1) is an \tildeO((L’ + L)^2 L’ /eps^2) uniform convergence bound on the number of clustering instances which are required to learn up to expected loss \eps the best possible convex combination. The key technical part of the proof is showing that for any fixed clustering the loss function is piecewise-constant with a small number of simple pieces. The overall approach is based on Balcan et al.’17 who solve the case when the distance metric is known but the linkage rule is to be learned and Balcan et al. ‘19 who give techniques for the piecewise constant case. Some further results are given which are specific to learning a mix of two merge functions under a single distance metric and the best combination of two metrics when using the complete linkage merge function. Experimental results are given on MNIST, CIFAR-10 and some other fairly small datasets.",This paper proposed a data-driven method of selecting a linkage-based clustering algorithm from a large space. The space of algorithms is parameterized by two sets of parameters which indicate the convex combinations of metrics and merge functions. They analyze the sample complexity for small generalization error. An efficient algorithm for searching an empirically optimal algorithm is proposed.,0.08064516129032258,0.3389830508474576,0.13029315960912052
1213,SP:727502b110dd9d104b7ae9caa72a6e5f9c119a8d,"This paper proposes a dual-path CNN architecture with complementary roles (FineNet and CoarseNet) which is inspired by parvocellular and magnocellular pathways in the primate brain. The CoarseNet receives blurred inputs and has large kernels while FineNet received high-resolution input, is deep and has small kernels. It is shown that this architecture improves the robustness in object recognition performance over single-pathway architecture and could replicate the behavioral responses in humans during a classic psychological experiment (backward masking). ","This paper proposed a two-pathway neural network to mimic the interplay between the parvocellular (slow and fine-grained) and magnocellular (fast and course) pathways in neural systems. The two pathways are named as FineNet and CourseNet. During inference, the FineNet received recurrent feedback signals from the CoarseNet via an attention layer and memory. During training, cross-entropy loss are used for both pathways, and an ""imitation"" loss is used to encourage the CoarseNet pathway to mimic the FineNet ",0.21518987341772153,0.21518987341772153,0.21518987341772153
1214,SP:7286d578f6acf486a688b7631e16c483efb6a540,"The authors replace the divergence-based constraint in trust region policy optimization model with an alternate distance measure, which is added to the objective function with a multiplier (beta).  In fact, the parameter beta plays a role that is similar to a Lagrange multiplier, if the new distance measure is introduced as a constraint. The authors explain the shortcomings of KL-divergence and the solutions obtained with other methods but they do not provide a sufficient discussion how and why their simple approach overcomes those concerns. For instance, why would the new measure encourage exploration and what is the effect of large beta value on this?","This paper introduces POP3D, an on-policy policy gradient algorithm that is a variant of TRPO and PPO. While TRPO uses a particular penalty function to keep the policy from being updated too aggressively, POP3D uses an alternative objective function that lower bounds the square of the total variance divergence between two policy distributions. The authors argue that this alternative formulation results in an algorithm that is sample-efficient, like PPO, but that is more effective at keeping policy updates from overshooting. The authors also argue that this new formulation helps users to avoid the arguably challenging process of selecting penalty constants, as required (for instance) by TRPO.",0.1509433962264151,0.14814814814814814,0.14953271028037385
1215,SP:728f326478128c886426a8b9b103db36a47aa5a5,"This paper studies an RPM problem (ride-pool matching problem) for on-demand transportation services. This problem is recently studied in various papers, but it is hard to choose a good matching by just using a bipartite graph matching due to the future demands, and it is an online decision-making problem.  A recent breakthrough, NeurADP by [Shah et al. 2020], has shown a good performance, but the proposed approach in the paper, CEVD, achieved much more performance gain (reported as 3.8%-9.76%), which has a significant impact on the ToD service. An essential technique of the proposed CEVD is considering the effect of other agents (i.e., other vehicles) when estimating the value of actions.","This paper considers the ridesharing matching problem and builds the solution upon NeurADP. The main contribution over NeurADP is that the action values of each agent (vehicle) takes into account the impact of its action on the neighboring agents within the same cluster, which is obtained through clustering of the intersections on the road network. The impact of agent's action on neighbors is measured by the neighboring agents' independent values weighted by their action probabilities conditional on the agent's action. Benchmarking was performed on the NYC taxi data set against NeurADP. Results on different values of tolerance for delay, capacity, and number of vehicles are reported, and a significant improvement is demonstrated in all cases. ",0.15254237288135594,0.15384615384615385,0.15319148936170213
1216,SP:7293079c6a09c5a4959ebfa52c04517377b7b623,"In this paper, the authors propose a method for pruning the convolutional filters. This method first separates the filters into clusters based on similarities defined with both Activation Maximization (AM) and back-propagation gradients. Then pruning is conducted based on the clustering results, and the contribution index that is calculated based on backward-propagation gradients. The proposed method is compared with a baseline method in the experiments. ",This paper proposes a new method to prune filters of convolutional nets based on a metric which consider functional similarities between filters. Those similarities are computed based on Activation Maximization and gradient information. The proposed method is better than L1 and activation-based methods in terms of accuracy after pruning at the same pruning ratio. The visualization of pruned filters (Fig. 3) shows the effectiveness of the method intuitively. ,0.2537313432835821,0.2463768115942029,0.25
1217,SP:729875841367d2056fbff987e38ab882131d8ffc,"The mental fatigue is an important factor in road accidents. Finding a direct mapping between EEG features and reaction time is difficult and error-prone, combining the noise measurement of EEG and individual variation of RT.  The authors introduce a measure called BDrank based on partial ordering instead of regression. Formulating the measure as a MAP problem, the authors propose a generalized EM algorithm for prediction. An online extension, relying on iterative L-BFGS optimization over mini-batches. ","The paper proposes an algorithm for mental fatigue monitoring, relating a subjects' EEG signals to their reaction time (RT) during a simulated driving task, as an ordinal regression problem. The authors argue that RTs could be heavily skewed and/or non-smooth, making traditional regression approaches unstable due to outlier values. They propose a brain dynamic ranking algorithm,  BDrank, using a generalized EM algorithm to estimate its parameters, and compare it to support vector regression and Logistic Ordinal Regression, where they show improved performance by accuracy and root mean squared error (RMSE) over a database of 44 subjects.",0.24358974358974358,0.19387755102040816,0.21590909090909088
1218,SP:72bbc4f02bdaf85da48d797942c0fba7e4cb0881,"This manuscript models the conditional joint distribution over variables by using Copula models and copula vines.  The experimental data shows that when the observed variables are highly correlated that the proposed approach improves estimation of entropy over competing benchmark approaches (MINE and KSG) when the variables are highly correlated. Synthetic results demonstrate good improvements, and application to real scientific data seems promising.","The authors exploit the expressive power of Copula mixtures to model time-varying multi-modal data, and employ Gaussian Processes to model the time-varying copula parameters. They demonstrate the efficacy of their method using information theoretic metrics on a synthetic dataset and a real-world joint neural-behavioral dataset from a neuroscience experiment.  Results demonstrate that the proposed techniques are comparable to the state of the art nonparametric methods, while being more scalable due to the use of stochastic optimization based methods that are commonly used with parametric methods. ",0.1935483870967742,0.13333333333333333,0.15789473684210525
1219,SP:72f151a2ffa8c63b2d7740ba2d2074ca6125c3ba,"In this manuscript, the authors analyze the dynamics of training deep linear neural networks under a generalized family of natural gradient methods that apply curvature corrections. They first show that the learning trajectory (direction of singular mode dynamics) in natural gradient descent follows the same path as gradient descent, while only accelerating the temporal dynamics along the path. Moreover, the authors show that the learning trajectory in layer-restricted approximations of natural gradient descent can significantly differ from the true natural gradient. Also, the authors proposed a fractional natural gradient that applies partial curvature correction which in addition to faster convergence, neutralizes vanishing/exploding gradient problems. ",Authors analyse curvature corrected optimization methods in the context of deep learning. They build their analysis on Saxe et.al.s work. They show that curvature corrected methods preserve properties of SGD. They also show the disadvantages of layer restricted approximations. They show the importance of time scales in optimization. The paper looks to deep learning from a dynamical systems perspective and hence their experiments are fitting to this framework.,0.16037735849056603,0.24285714285714285,0.19318181818181818
1220,SP:72f25cb455c7d0e0a2ce818d3baab4a916376dd3,"The paper studies Byzantine robustness in the context of distributed learning from heterogeneous datasets. This problem has been widely studied previously, but under the additional assumption that the data of the good workers is i.i.d.. The authors give examples of situations and poisoning attacks with which current defences designed for the i.i.d. situation can be overcome.  They also propose a simple resampling scheme that can be used as a preprocessing step before applying any standard robust aggregator from the i.i.d. literature. They provide theoretical guarantees for their resampling scheme when used together with KRUM. The also test their algorithm against the i.i.d. baselines and multiple attacks. ","Many existing researches on distributed deep learning works in byzantine robustness in a centralized PS setting under the assumption of i.i.d. data distribution on workers, e.g. KRUM. This paper presents a simple resampling scheme that adapts the existing robust algorithms to heterogeneous datasets (referred as KRUM-RS later in this review). It firstly proposes two new attacks under non-iid data distribution that fooled byzantine fault tolerant algorithms like KRUM, Coordinate Median (CM), and RFA (Normalized Median-NM or Geometric Median-GM). Then it proposes the RS algorithm and proved its theoretical convergence guarantee the of KRUM algorithm over non-iid data, and when the parameter server (PS) does not control the dataset distribution. Experiments showed the convergence guarantee over KRUM and even CM, NM/GM algorithm. ",0.19298245614035087,0.16923076923076924,0.18032786885245902
1221,SP:730c95c4ef5534877dcbd535e53dc8ba4879ed36,"This paper studies weight modularity in neural networks (NNs). In particular, given a NN trained to perform a task, a subset of weights are identified which in isolation perform well on a subtask of the original task. Such subsets are inspected to understand the extent to which they are specialized or reused across different subtasks of the original task. To identify subtask specific weights, a mask is learned that minimizes loss over a subtask when applied to the original NN's frozen weights. This process is carried out using gradient based optimization techniques (Adam). Extensive experiments are performed across various datasets and architectures. The paper concludes that while NNs seem to exhibit module specialization, they fail to exhibit reuse.","The paper presents an empirical study of whether modularity can emerge within neural networks. It starts by proposing a novel definition of modularity that identifies modules by their functionality. To discover the module that implements a specific target functionality, the paper proposes to first pretrain the full network on the original task, then freeze the pretrained weights, and train a binary mask for each weight using Gumbel-Sigmoid. The training objective for the masks is given by the target functionality (e.g., a subtask of the original task), plus some sparsity regularization. The paper then investigates the discovered modules in terms of specialization, reusability, and compositionality. The main findings are: (1) Neural nets tend to satisfy specialization but not reusability; (2) Weight sharing between modules tends to be affected more by whether I/O are shared than by task similarity, and there tends to be less sharing in larger networks; (3) When trained on algorithmic tasks, neural nets fail to learn compositional rules, and thus generalize poorly; (4) CNNs trained for image classification contain class-specific, non-shared weights in the feature detectors.",0.226890756302521,0.14754098360655737,0.17880794701986752
1222,SP:731300fd76e291c578ca23406efd2d149fb30df0,"The authors are analyzing to which extent dropout is regularizing the training stage of deep networks, showing that high-order interactions are discouraged, this being a proxy for a better generalization capability once spurious co-adaptations are removed. In an extended mathematical analysis, the authors carry out their arguments taking advantage of the weighted analysis of variance, showing results on both the expected dropout rate and the impact on gradients while back-propagating. Experimental results are paired to the paper to demonstrate that changes the steady-state optima of the model. ","This paper analyzes Dropout through the lens of k-way interactions. The central claim of this paper is that Dropout reduces interaction effects. This is shown through both theory and experiment. The theory suggests that a higher dropout rate reduces the effective learning speed of higher-order interactions. Experiments suggest that increasing the dropout rate reduces the functional magnitude of higher-order interactions, even to some extent in real data.",0.15384615384615385,0.2,0.17391304347826086
1223,SP:735cdc64faed0eb28babb286e250fd3fbb8d9047,"The paper proposes a new formulation for inverse reinforcement learning that aims to address the _bias against policies with longer mixing times_. The key contribution of the paper is the proposal of an alternative optimality criterion that arguably addresses the aforementioned bias by considering, for a given policy, the value  $L(\pi,c)=E_{p_0,\pi}\left[\sum_{k=0}^\infty\eta(k)\sum_{t=0}^\infty\gamma^tc_{t+k}\right]$  instead of the more standard definition  $L(\pi,c)=E_{p_0,\pi}\left[\sum_{t=0}^\infty\gamma^tc_{t}\right],$  where $c$ is such that $E[c_t\mid s_t,a_t]=c(s_t,a_t)$.  To solve the IRL problem associated with this new optimality criterion (or, rather, a regularized version thereof) the paper proposes the use of maximum causal entropy IRL, which can roughly be broken down in two subproblems:  - Given a candidate cost function, $\hat{c}$, find a candidate policy, $\hat{\pi}$, that minimizes $L(\hat{\pi},\hat{c})$. In a sense, $\hat{\pi}$ is the ""optimal"" policy given the cost function $\hat{c}$. The paper proposes the use of soft actor-critic approach (although other value-based approaches could be used).  - Given the expert policy, $\pi_E$, and the candidate policy, $\hat{\pi}$, come up with a candidate cost function $\hat{c}$ such that the expert policy has a low cost and other policies have a high cost, which the paper shows that can be done by minimizing a measure of divergence between the (weighted) distributions induced by $\hat{\pi}$ and $\pi_E$.   The resulting algorithm is a variation of the generative adversarial IRL approach of Ho and Ermon, that the experiments suggest may be able to better recover the expert's policy.","This paper points out that the classical IRL approach has a tendency to match those occupancy measures that favor short-term behavior. To address this issue, a reformulation is proposed based on GAIL in order to put more emphasis on matching longer-term behavior. Specifically, the main difference is to replace the standard objective (i.e., the expectation of Q function over some initial state distribution) with the expectation of Q function over both the initial and an $\eta$-weighted future state distribution, where $\eta$ is some probability distribution over the support set of nonnegative integers. Built on this formulation, this paper proposes GIRL (and the resulting algorithm MEGAN), which follows the framework of GAIL to learn a policy that matches the $\eta$-weighted variant of occupancy measure of the expert policy. Experimental results on MuJoCo are provided to demonstrate the effectiveness of GIRL.",0.11224489795918367,0.22916666666666666,0.1506849315068493
1224,SP:73630ddbe2f83647f099f921abb79b2c0f937aa9,"This work explores instance-wise layer re-ordering in transformers. The key idea is to incorporate classifiers that predict the ordering of sub-layers (self-attention, cross-attention, feed-forward) from the averaged input sequence representation, one classifier each for the encoder and the decoder. During training the model uses a soft Gumbel-noised output of the classifier to combine the outputs from stacks with differently ordered sub-layers. During inference the argmax of the classifier prediction is used to generate the output sequence. The model is trained with two auxiliary losses: (i) A loss to ensure the expected output of the classifiers is uniform and (ii) A loss to ensure the classifier output for each individual sample is distant from uniform.","This paper studies the influence of the arrangement order for the internal structure in a single-layer Transformer (they named it as layer order) on the performance. It makes a hypothesis that different layer order has an impact on the performance of the model, and the hypothesis is verified by experiments. Based on this hypothesis, a lightweight layer order predictor is designed to predict an input-related layer order, and through reinforcement learning with two auxiliary loss, the model can not only be trained by diverse layer order, but also make unambiguous layer order prediction as far as possible. The IOT structure proposed in this paper has been evaluated on several datasets of machine translation, abstract summarization and code generation. Compared with the traditional transformer structure, it has been improved consistently, which shows the effectiveness of the proposed structure.",0.1721311475409836,0.1510791366906475,0.16091954022988503
1225,SP:7364fb042f9091dc6655340d13396f57d47a4c31,This work investigates the effect of out-of-distribution data on machine learning models on healthcare applications. The authors first display a decrease in model performance on near and far out-of-distribution samples for 3 health applications. They then assess the performance of 3 techniques for out-of-distribution detection and build a confidence score from this binary classifier. The confidence score is assessed in a user-study as a complementary piece of information to be presented to the user.,"This paper touches on a very interesting and important problem in the applied machine learning field, the trustworthiness of ML models, how to measure it, and its effect on user experience. The paper presents a very nice introduction to the topic and opens the problem in the context of out-of-distribution detection. Three different approaches for out-of-distribution detection are benchmarked on several datasets and ML methods. Furthermore, a confidence score is proposed to translate the out-of-distribution scores into more interpretable scores for the users. A user study is further conducted to evaluate the effect of using confidence scores on the trust level of human participants.",0.3333333333333333,0.24545454545454545,0.28272251308900526
1226,SP:737ec0b9d0df72ef8c1db34a89773a627105b240,"The paper focuses on learning a navigation policy for a vision-and-language navigation problem. In this problem, the agent are given a language instruction and are asked to follow the instruction to navigation in a simulated 3D room. Unlike baselines which maximize the probability of selecting an action given an instruction, the authors proposed to apply the Bayes rule to maximize the probability of generating the instruction given an action. The authors claim that this gives better generalization in unseen environments.","The paper addresses the problem of vision-and-language navigation (Anderson et al., 2018). The idea of the paper is to use a generative policy where a distribution over all instruction tokens given the previous actions is computed. The agent takes the action that maximizes the probability of the current instruction. The paper reports the results on R2R and R4R datasets.",0.23170731707317074,0.3114754098360656,0.2657342657342658
1227,SP:73bf13710be8ac67ecba0e706e128b807d9d64a5,"In this paper, the authors claimed that uniformity in embedding space if the key for good generalization, and then propose an adversarial training based method to improve the uniformity of feature space. The claim is from previous work, thus the key contribution is the way to impose such regularization. The method itself makes sense to me. ","The authors argue that uniform priors for the high-level latent representations improve transferability, which is beneficial in a number of tasks involving transference. The approach is evaluated on deep metric learning, zero-shot domain adaptation and few-shot meta-learning. The authors propose a uniformity regularization term on the latent representation, implemented as an adversarial discrepancy. The results show consistent improvement in the different tasks.",0.19642857142857142,0.16666666666666666,0.180327868852459
1228,SP:73cca0ea28b63d6d962c9a831627423947503ae7,"This paper proposes an extension of the RL as Inference framework, and demonstrates how to use it to express an object-centric RL model and train it on simple environments. It appears to be a combination of NEM [1] with a simple TD-learning objective on top. Results are a bit hard to interpret but seem promising.","The authors propose a framework for joint perception and control as inference (PCI) to combine perception and control for the case of POMDPs. The authors particularly focus on the case of hidden perceptual states linked to small image observations, which are composed of pixels belonging to up to exactly one object each. Their main proposal is denoted as OPC, which stands for object based perception and control, which serves the purpose of automatically discovering objects from pixels while controlling the system. ",0.15789473684210525,0.1111111111111111,0.13043478260869565
1229,SP:73d7bceeae0307819f03d69e3799969808e20137,"This paper proposes a new architecture and training method to learn tasks that require hard attention control. Specifically, the paper proposes to learn the “glimpse agent” (which controls the hard attention window) by task-agnostic loss that seeks to maximize information gain by the glimpse to the learned world model. The authors also proposed a specific architecture that incorporates consecutive glimpses to learn the world model. ","This work presents a method for learning a hard attention controller using an information maximization approach. As the authors point out, such a method could be very useful for reasoning in terms of high-dimensional observations, like vision. In brief, the method learning to choose the next attention position to be the most informative by maximizing the uncertainty of the next observation. Uncertainty is quantified using a spatial memory model that is trained to reconstruct and predict the scene. The authors validate this approach by showing that the resulting attention mechanism can be used for two simple downstream tasks. The resulting agent outperforms others trained using baseline attention mechanisms: a hard attention mechanism that is trained on task reward (""environment""; similar to Mnih et al 2014), as well as models that attend to random positions or to the agent's location.",0.30303030303030304,0.14184397163120568,0.19323671497584544
1230,SP:7407a512d600fce6161821f605b77b1df19cb1da,"The authors propose to make practical the high dimensional analysis of the logistic regression performed by [Sur and Candes]. Indeed, [Sur and Candes] proved that logistic regression in the classical regime (number of samples going to infinity while the dimensionality is fixed) is biased and must be corrected for modern applications where the number of samples and their size are of the same order of magnitude. However, in [Sur and Candes]'s paper, the asymptotic analysis depends on parameters that are difficult to estimate since they depend on ground truth parameters (regression parameter $\beta$). The authors of the present article propose a fast estimation method.","The paper is based on a work by Sur and Candès (2019) who propose a way to correct the bias of the MLE estimator and correct confidence intervals and p-values for logistic regression. The results in Sur Candes are asymptotic results n \to \infty but assume a fixed aspect ration $p / n = \kappa$ where p is the number of regression coefficients. The results have  been refined in Zhao et al (2020),: in Zhao, the regressors are Gaussian but with an arbitrary covariance matrix whereas the regressors are spherical Gaussian in Sur Candes  (the distribution of the regressor plays a key role to compute the correction factor).   The original algorithm by Sur and Candes require to estimate the signal strength, defined as the $\gamma^2 = Var(\beta^T X)$. This is of course challenging because the parameter is unknown. The authors proposed to use the ""corrupted signal strength, defined as $\Var(\hat{\beta}^T X)$ where $\hat{\beta}$ is the MLE (it is claimed that the corrupted signal strength has been introduced in Zhao (2020) but on the arxiv version of this paper I did not find such quantity). The correction factors can be computed by solving an equation to involving the corrupted signal strength. The purpose of this paper is to compute an estimator of the corrupted signal strength. ",0.2857142857142857,0.13574660633484162,0.18404907975460122
1231,SP:7414e95e25417652c729da914dff9d116c083282,"This paper presents a method for adversarial attacks on object detectors by exploiting relevance maps that are originally intended for model interpretation. Unlike most of the existing methods that attack detection scores directly, the proposed approach focuses on suppressing the relevance map associated with target objects by image perturbation. The idea is interesting and demonstrates good transferability on the tasks of object detection and segmentation. ",This work proposes to attack object detectors by targeting their relevance maps of the different detected objects. The proposed RAD attack shows better black box transferability across different detectors on MSCOCO dataset. The relevance maps are calculated based on SGLRP act as an attention mechanism to the attack to focus on relevant regions in the more meaningful image and hence produce more transferable attacks. ,0.26153846153846155,0.265625,0.26356589147286824
1232,SP:7419b8bf021dbef66e8483d178ef9838bc790a48,"This paper proposes an unsupervised method for learning node embeddings of directed graphs into statistical manifolds. Each node in the graph is mapped to a distribution in the space of k-variate power distributions, endowed with the KL divergence as asymetric similarity. The authors propose an optimization method based on a regularized KL divergence objective. They also propose an approximation of this objective based on finite neighborhoods, with a separate treatment of infinite distances based on a topological sorting. They also introduce a natural gradient correction to the gradient descent algorithm in this setting. They validate the fitness of their approach by showing that asymmetric distances in the graph translate into correlated asymetric distances between the node embeddings for various datasets.","This paper proposed another graph embedding method. It focuses on directed graphs, and it embedded the graph nodes into exponential power distributions, which include the Gaussian distribution as a special case. The method is implemented by optimizing with respect to the free distributions on a statistical manifold so as to achieve the minimum distortion between the input/output distances.  The method is tested on several directed graph datasets and showed superior performance based on several metrics.",0.19008264462809918,0.3026315789473684,0.23350253807106602
1233,SP:745b6d9c4d1e7c3d0b52c91984356c66e3c7ba5b,"Authors revise the one-shot NAS algorithm in this work. One-shot NAS that employs a supernet to share the weights between subnets is an efficient NAS algorithm. Authors develop a new training paradigm to train the supernet sufficiently. Specifically, they uniformly sample a single path from supernet at each iteration to make the training effective and stable.","This paper presents a new one-shot NAS approach. Parameter updating and structure updating are optimized separately. In the process of parameter optimization, different from the previous methods, the network samples the structure according to the uniform probability distribution. This sampling method can avoid the coupling caused by optimizing the structural parameters at the same time. After training the supernet, the network uses the genetic algorithm to search the structure.",0.1896551724137931,0.15714285714285714,0.171875
1234,SP:7460e4f19c4708b96f43a922a2e527f91da3afca,This paper studies the effectiveness of several Neural Architecture Search (NAS) methods comparing it with that of random policy search. The paper concludes that none of these methods for a CNN (trained using CIFAR-10) and RNN model (trained using PTB) are statistically significantly better than the random search. The authors suggest that this is due to the weight sharing used by the NAS algorithms to accelerate the network training. ,"This works studies the evaluation of search strategies for neural architecture search. It points out existing problems of the current evaluation scheme: (1) only compares the final result without testing the robustness under different random seeds; (2) lacking fair comparison with random baseline under different random seeds. The authors analyzed three popular NAS methods with weight sharing (ENAS, DARTS, NAO), and showed that they don't significantly improve upon random baseline on PTB and CIFAR-10. On a reduced search space of RNN and CNN (NASBench), they showed that the three methods fail to find the best performing architecture. Then they compared search with and without weight sharing and showed the correlation between architecture performance under the two conditions in a reduced search space, which indicates the weight sharing is a potential cause for the suboptimal performance.",0.32857142857142857,0.1678832116788321,0.22222222222222224
1235,SP:746ebd0772b2236009e7ff32cf8669f8bc8b6615,"This paper defines precise semantics of disentanglement representations and presents evaluation metrics to evaluate such representations. The authors provides information-theoretic characterization disentangled representations along three dimensions: informativeness, separability, and interpretability; and propose metrics to measure them. The authors argue that:- Informativeness can be defined as the mutual information between a particular representation (or a group of representations) w.r.t the data---I(x,z_i) - Separability between two representations can be achieved if they do not share any common information about the data---I(x,z_i,z_j) = 0 - Interpretability with respect to a concept is achieved if a representation contains information about the concept---I(z_i, y_k) = H(z_i) = H(y_k).The authors define a disentangled representation as a representation that is fully separable and fully interpretable and propose a suite of metrics to evaluate disentangled representations.Finally, the authors evaluate several representation learning methods (FactorVAE, betaVAE, AAE) using these metrics on toy and real datasets.","The paper presents a new set of metrics for evaluating disentangled representations in both supervised and unsupervised settings. Disentangled representations are evaluated along three dimensions: informativeness, separability, and interpretability. While previous work offers metrics for similar dimensions (e.g., (Eastwood & Williams, 2018)), the paper suggests that the metrics of the submission are superior to (Eastwood & Williams, 2018), based on a comparison between FactorVAE and Beta-VAE.",0.1402439024390244,0.3484848484848485,0.2
1236,SP:74aafec80535022cbdd83067763fd7bced294ace,"This paper proposes to analyze the loss of neural networks in the Fourier domain. Since this is computationally expensive for larger-dimensional datasets, the analysis instead first projects the data onto the principal component of the data, and then using a Gaussian kernel estimation (which has nice properties in the Fourier domain). The analysis finds that DNNs tend to learn low-frequency components before high-frequency ones.","The paper studies the training process of NNs through the lens of Fourier analysis. The authors argue that during the training process, NNs will first learn low frequencies part of the function first and then the high frequency part. To verify this claim empirically, the author propose two methods: 1. examine the convergence of different frequencies in a pre-selected direction in the frequency space during training; 2. examine the convergence rate of the 2-norm of low v.s. high frequencies during training.  Through the experimental results of these two methods, the authors conclude that NNs learn the low  frequency components before the high frequency components. The authors also discuss a potential application of this observation to solving high dimensional PDEs: coupling DNNs training (good at learning low frequency components) with the Jacobi method (good at learning high frequency components). Finally, the authors also provide some theoretical intuition (Thm 1., 2.) why low frequency components are learned faster and an explanation why NNs could generalize well on images but perform poorly on tasks like learning parity functions. ",0.3582089552238806,0.1348314606741573,0.19591836734693877
1237,SP:74d5861aae5a9f0c6c828c8aef757d965772ea4d,"This work investigates an interesting direction of improving robustness of classifiers against adversarial attacks by using generative models. The authors propose the *deep Bayes classifier*, which is a deep LVM based extension of naive Bayes. Furthermore, the authors extensively explore 7 possible factorisations of the classifier. Thorough experiments are conducted to assess the capability of defending or detecting adversarial examples.  Besides, the authors incorporate discriminative features to generative classifiers and demonstrate clear robustness gain.","This paper aims to test the robustness of generative classifiers [1] w.r.t. adversarial examples, considering their use as a potentially more robust alternative to adversarial training of discriminative classifiers. To achieve this, *Deep Bayes*, a generalization of the Naive Bayes classifier using a latent variable model and trained in a fashion similar to variational autoencoders [2] is introduced, and 7 different latent variable models are compared, covering a spectrum of generative or discriminative classification models, with or without bottlenecks. Their DFX and DBX architectures in particular closely match traditional discriminative classifiers, without and with a latent bottleneck.",0.24324324324324326,0.18181818181818182,0.20809248554913296
1238,SP:74e6032281e4470acb02303c8c6a319cfb896f28,The paper proposes a sparse canonical correlation analysis method based on l_0 norm. A continuous relaxation scheme is adopted for solving sparse CCA. The proposed model is then extended to nonlinear function estimation and combined with deep neural networks. Experimental results on synthetic and real-world datasets demonstrate the effectiveness of the proposed methods.,The paper proposes a new method for l0-CCA using stochastic gating which allows for an efficient algorithm and also permits a deep-version of the l0-CCA. Results are shown on synthetic and real-world datasets that highlight the superior performance of the proposed approach.   Main Contributions:   1). The paper proposes a new approach for l0-CCA that uses a continuous relaxation of a bernoulli random variable via stochastic gating.   2). The paper extends the proposed method to l0-deep-CCA which allows non-linear interactions between the two CCA views.  3). Results are shown on synthetic and real-world datasets which show the superior performance of the proposed l0-CCA methods.,0.45454545454545453,0.22123893805309736,0.29761904761904767
1239,SP:74f9a1349122d297e05afde2037dee3cbcde4ee6,"In this paper, the authors propose a sparse momentum algorithm for doing efficient sparse training. The technique relies on identifying weights in a layer that do not have an effect on the error, pruning them, and redistributing and growing them across layers. The technique is compared against other recent algorithms on a range of models.","This paper proposes an algorithm called Sparse Momentum for learning sparse neural networks. They claim to maintain sparse weights throughout training while achieving dense network performance levels. They also show their method improves training speed up to 5.61x faster training. The provides a decent motivation for why sparse networks can be helpful. The related work section is well summarized and they emphasize that the current work's primary motivation is to reduce training time while maintaining performance. They compare their method with other methods that also maintain sparse neural networks throughout training and involve single training phase, which is fair. Their method consists of primarily 3 phases - i) pruning weights ii) redistribution of weights iii) regrowing of weights based on the exponentially smoothed momentum term for each layer. The method is well explained and motivation is clear. Edge case was also explained for more clarity. However, there is something that needs more clarification in Pg-3, 3rd line, they say the 3 components of the algorithm i) ii) and iii) can be tackled independently with a divide and conquer strategy to gain some computational benefits. In my understanding, the method performs these 3 steps sequentially after each epoch. Not sure how divide and conquer strategy can be used here ?",0.2909090909090909,0.0761904761904762,0.12075471698113208
1240,SP:7506acf48272f5455ce8192cda8ccd390ef2c618,This paper proposes Narrow-Band Parallel Transport Convolution (NPTC) for point cloud data. The general idea is to use gradients of some distance function to define the vector field. The authors use voxelization to approximate the point cloud in a narrow-band covering the point cloud so that distance function can be calculated. The authors also discuss how to compute the distance function and the vector fields on point clouds. Experimental results on classification tasks and segmentation tasks are provided. ,The authors propose NPTC a new convolutional operator for 3D point clouds embedded on a 2D manifold based no parallel transport defined by a narrow-band approximation. The method combines voxelization within a local neighborhood in 3D (narrow band) and geometric convolution. Experimental results are presneted for a range of classification and segmentation tasks that are similar to the state-of-the-art.,0.2,0.25396825396825395,0.22377622377622378
1241,SP:750c6f227be89cc4638eb4adf33f29da8072be36,"The authors aim to increase diversity in machine translation using a multinomial latent variable that captures uncertainty in the target sentence. Modeling uncertainty with latent variables is of course relatively common in ML, and this work has similarities with latent variables models for MT [Zhang et al., 2016] and for other generation tasks such as dialogue [Serban et al., 2017; etc.]. The key difference is that the authors here use a Mixture of Expert (MoE) approach while most relevant prior works use variational approaches. Experiments show improvements in diversity over variational NMT [Zhang et al., 2016] and decoding-time approaches (e.g., diversity constraints [Vijayakumar et al., 2016]).","This paper studies the diverse text generation problem, specifically on machine translation problem. The authors use a simple method, which just using a single multinomial latent variable compared with previous approaches that using multi latent variables. They named the approach: Hard-MoE. They use parallel greedy decoding to generate the diverse translations and the experiments on three WMT datasets show the approach make a trade-off between diversity and quality.",0.16666666666666666,0.2571428571428571,0.20224719101123595
1242,SP:750e99e86aaf85e443cab440f4dbd480ba2dd0d1,"In this work, the authors study the escaping saddle points problem for nonconvex optimization. Previously Jin et al. proposed a perturbed accelerated gradient descent (AGD) method which finds $\epsilon$-second-order stationary points in $O(\log^6 n/\epsilon^{1.75})$ number of iterations, where $n$ is the dimension. By utilizing a refined perturbed negative curvature estimator, the authors successfully improves the dependence of dimension from $\log^6 n$ to $\log n$. Experiment results suggest that their algorithm performs well in practice. ","This paper provides an improved method for computing stationary points of nonconvex functions. The authors give an algorithm which, given an $L$-smooth $\rho$-Hessian Lipschitz nonconvex function $f$, computes an $(O(\epsilon), O(\sqrt{\rho \epsilon}))$-second order stationary point of $f$ using $O(\eps^{-7/4} \log n)$ gradient computations of $f$. This matches the $\epsilon$ dependence  achieved by several previous works in the area (for example [6,7,20]) but  improves the dependence on $\log n$, where $n$ is the dimension, by polynomial factors. The algorithm is also of similar simplicity to the previous state-of-the-art method given in [20], and combines the perturbed AGD framework given there with some clever observations to achieve the result.",0.2804878048780488,0.19008264462809918,0.22660098522167488
1243,SP:7535989fca66c0c4e072af700c3dbf5c9f2e42f2,"This work presented State-Noisy Markov Decision Process (SN-MDP), where there is a noise generating mechanism (either from the environment noise or from the adversary), and the theoretical properties (such as convergence and contraction) for corresponding (expected) Bellman operator and distributional Bellman operator were proved. The theoretical analysis was done for both tabular and linear funcion approximation settings. Especially in function approximation setting, authors characterized the robustness blessing of distributional RL based on histogram distributional loss and analyzed how the noise factor affects TD learning by using influence function that utilizes the perburbation method. Empirical analysis was done for DQN and QRDQN by varying noise standard deviations and the position of noise (state/successor state or both), which aims to support the authors' intuition coming from their theorems. ","This paper studies the robustness of distributional reinforcement learning, in particular the robustness on state observations, which have been demonstrated in a few papers on adversarial attacks to deep reinforcement learning. Compared to existing works on robust reinforcement learning on state observations, the main difference in this work is that it considers the distributional RL setting and also considers noise during training time. Theoretically, the authors find that distributional RL can be more robust under this setting, via the lens of Lipschitz continuity of the loss function and the influence function. The findings are also verified empirically on 4 benchmarks.",0.13178294573643412,0.17,0.14847161572052403
1244,SP:7552f3439cddd41bcf5b2c8f6f563558e07dfd5e,The proposed approach involves creating adversarial examples in a training-free manner by manipulating the frequency components of the image. High -frequency information is used from simple geometric patterns and combined with low-frequency component from the input to create a hybrid image. The resultant image is shown to fool classifiers under multiple settings which presents an easy way to construct adversarial examples.,The authors propose a new method for generating adversarial images for image classifier. This is a No-Box attack named Hybrid Image Transformation (HIT) or hit attack which is both model free and data-free (no training required). In the experiment section the authors show the efficacy of the proposed attack on the ImageNet dataset for different DNNs.,0.12698412698412698,0.13793103448275862,0.13223140495867766
1245,SP:758e3d852e162f93a9984eac06c0b23cd67bc727,"This paper proposed a simple yet effective approach for data poisoning attack targeting a few ""clean-label"" victim images, using the idea of gradient matching (cosine similarity maximization) between the gradients of adversarial and clean losses. Although the attack model still requires knowing the network architecture (gray-box setting), the resulting poisoned datasets are more effective against different initializations, and some techniques (e.g. model ensemble, multiple restarts) are proposed to further boost the attack performance. The attack results are significantly better than the compared poisoning attacks, and the authors show effective attacks on the ImageNet dataset as well as Google Cloud AutoML with the poisoned data. The authors also discussed the proposed attack on some defenses, showing that the poison has limited change to feature distribution, and differential privacy can mitigate the attack but at the cost of reduced utility (clean accuracy).","This paper introduces a novel targeted clean-label poisoning attack, expected to be more efficient and scalable than current ones. The attack is formulated as a bilevel problem which is then solved with a (fast) heuristic approach based on aligning the gradients of the inner and outer objective functions. A theoretical analysis is also reported to show that this strategy consistently finds a descent direction for the outer objective, asymptotically converging to (a local) minimum. ",0.1258741258741259,0.24,0.1651376146788991
1246,SP:759c0a0298f9845f41d6b556a2187867230a0ca5,"The paper proposed FedDEC, a novel approach to conduct model updates aggregation in federated learning. The main motivation of this paper is to decouple the aggregation of normal model weights and statistics in BNs separately such that both data and model heterogeneity can be handled. Theoretical analysis indicates that the proposed FedDEC method enjoys a good convergence guarantee. Extensive experimental results are provided to show that FedDEC enjoys high efficiency and better model accuracy under the non-IID environment compared to the considered baseline methods.","This paper introduces an aggregation mechanism designed for neural networks with batch normalisation layers. This mechanism relies on two parts: probabilistic mixing weights of the loss function and the use of a weighted pool estimator for aggregating the BN variance parameters. The mixing weights are derived from a GMM with variational inference. A convergence result in the *convex* case is provided. Experimental results on 3 image datasets show that this approach yields better results than other standard FL algorithms (FedAvg, FedProx, q-FedSGD, FedMA…) as well as a better resilience to heterogeneity (understood as class imbalance).",0.16470588235294117,0.14583333333333334,0.15469613259668508
1247,SP:759f85692cb4edfe6521d013dbbb55e20a458a4b,This paper asks the interesting question of whether you need individual neuron (or even population level) class selectivity at intermediate stages in order to have good classification performance. The authors introduce a regularization term to the loss that controls the amount of selectivity in the units of the network. They find that the selectivity of the units in standard networks can be reduced while maintaining classification performance. ,"This paper examines the impact of forcing units in a CNN to be more or less “class-selective” – i.e. respond preferentially to one image class compared to another.  The approach taken is to include a regularizer in the loss that directly penalizes or encourages class selectivity in individual units. They report that penalizing class selectivity at intermediate layers has little-to-no effect on classification performance, and in some cases mildly improves performance. They authors conclude that class selectivity is not an essential component of successful performance in CNNs, and that methods which use class selectivity to interpret CNNs should be approached with caution. ",0.31343283582089554,0.2,0.24418604651162795
1248,SP:75b5d32a5a6bc3373309ee3e9ad7507d23221f19,"To approach ""reasoning after memorization"", the paper presents a Continual Memory (CM) framework using a memory-augmented neural network (MANN) and self-supervised training. In particular,  the CM  compresses the input sequence into a matrix memory using self-attention mechanisms and gated recurrent update (GRU). Then together with a Transformer decoder, the memory is used for downstream reasoning tasks without the need of referring to the original input sequence.  Moreover, the framework is simultaneously trained with auxiliary losses to enforce memorization capability. A variety of experiments demonstrate promising results, in which the CM outperforms two MANN baselines and shows competitive performance against state-of-the-art methods. ","In this paper, the authors propose the Continual Memory (CM) targeted towards a reasoning scenario called “reasoning after memorization”. The main goal of CM is to enable long-term memorization as opposed to memory networks that suffer from gradual forgetting. They evaluate their model both on synthetic data as well as a few downstream benchmarks. ",0.11214953271028037,0.21818181818181817,0.14814814814814817
1249,SP:75d17035de7c88ebb45e60795d3acd8f0e93b84b,"This paper proposes an adaptive margin-based adversarial training (eg. MMA) approach to train robust DNNs by maximizing the shortest margin of inputs to the decision boundary. Theoretical analyses have been provided to understand the connection between robust optimization and margin maximization. The main difference between the proposed approach to standard adversarial training is the adaptive selection of the perturbation bound \epsilon. This makes adversarial training with large perturbation possible, which was previously unachievable by standard adversarial training (Madry et al.) Empirical results match the theoretical analysis.","This paper proposes a method, Max-Margin Adversarial (MMA) training, for robust learning against adversarial attacks. In the MMA, the margin in the input space is directly maximized. In order to alleviate an instability of the learning, a softmax variant of the max-margin is introduced. Moreover, the margin-maximization and the minimization of the worst-case loss are studied. Some numerical experiments show that the proposed MMA training is efficient against several adversarial attacks. ",0.22988505747126436,0.26666666666666666,0.24691358024691357
1250,SP:75fbb95d000d888615a32a695fd6c673055b3678,"The authors propose a simple algorithm for using online learning from implicit human feedback to improve systems that operate in the contextual bandit setting. The main idea is to capture the presence/absence of corrective actions and use this information to infer a reward signal that the system can use to make decisions later. The proposed method is instantiated for text-entry tasks as a system called XT2, and the authors perform extensive empirical evaluation that seems to show that the system is very successful.","This work presents a method for online learning of an assistive typing user interface (XT2) with implicit user feedback. User inputs for such an assistive typing interface are assumed to be in the form of eye gaze or handwritten characters. However, the implicit human feedback is assumed to be backspaces typed on a keyboard. Backspaces are used to delete words predicted by the assistive typing interface based on the user’s input. The online learning of such an interface to improve its assistive performance and adapt to the user over time is framed as a contextual bandit problem. A reward prediction network is trained to predict the use of backspaces (implicit feedback) by the user. This reward prediction network combined with the default interface policy using Baye’s theorem is used to update the policy of the typing interface. The experimental results with two user studies reveal that the presented method performs better than a non-adaptive default interface, stimulates user co-adaptation to the interface, and offline learning accelerates online learning.",0.3058823529411765,0.1511627906976744,0.20233463035019456
1251,SP:761207caf0d1b23f060e3957a6309bc6d76819a6,The authors evaluate convolutional autoencoders (CAE) by varying the size (width & height) and depth of the bottleneck layer on three datasets and compare test and training performance. They furthermore evaluate the quality of the bottleneck activations for linear classification. The authors also investigate the belief that a bottleneck layer of size equal to the input image will copy the image. ,"This paper studies some of the properties of fully convolutional autoencoders (CAE) as a function of the shape and total size of the bottleneck. They train and test CAEs with bottlenecks consisting of different ratios of spatial resolution versus number of channels, as well as different total number of neurons. The authors investigate which type of change in the bottleneck is most influential on training behavior, generalization to test set, and linear separability for classification/regression. Their first main finding is that the spatial resolution of the bottleneck is a stronger influencer of generalization to the test set than the number of channels and the total number of neurons in the bottleneck. The second main finding is that even when the total number of neurons in the bottleneck is equal to the data input size, the neural network does not appear to simply learn to copy the input image into the bottleneck. ",0.48333333333333334,0.19078947368421054,0.27358490566037735
1252,SP:76143383d6721e00317c6a3f0b04929f89c8b982,"The authors introduce Abelian group networks (AGN) that explicitly model the operational relation between elements in an Abelian group. The authors prove that the design has the ability to model such relations and present feasible neural network realizations. The authors also prove the ability of AGN to learn representations of multisets. The authors design experiments to test AGN's ability to model word analogy by viewing the ""a:b = c:d"" relation as $c - a + b$. The results seem to suggest that AGN outperforms MLP baselines always and word vectors in some cases. However, closer examinations reveal concerns about their strength and validity to support the efficacy of AGN.","This paper introduces a new kind of neural network for multisets of vector inputs. Whereas DeepSets uses a function h(x, y) = g(f(x) + f(y)), the proposed model uses h(x, y) = f^{-1}(f(x) + f(y)), where f is an invertible neural network. It applies this network to the problem of learning word analogies.",0.07339449541284404,0.13793103448275862,0.09580838323353293
1253,SP:7618656900318448b5c9fd7ce2fb33bab3384a4c,"In this paper, the authors introduce an algorithm to learn a stable controller using deep NN actor-critic method. They define the stability in the mean cost criteria,  which is used to constrain the critic network as a Lyapunov function. In addition, the semi-positive definiteness of the Lyapunov function is enforced by constructing the critic.","In this work the authors studied the model-free RL approach for learning a policy with stability guarantees. Leveraging the Lyapunov stochastic stability criterion, instead if minimizing the cumulative cost (plus a soft entropy), they propose optimizing an objective function with a specific Lyapunov critic, which is a specific critic function that satisfies the Lyapunov criterion to guarantee stability. They also show in several Cartpole, Mujoco, and Repressilator experiments that this approach is more robust to perturbations (such as sinusoids), where the agent are more robust to dynamic uncertainties and disturbances. ",0.30357142857142855,0.18681318681318682,0.23129251700680273
1254,SP:761efdd848e9b8f43b17473ad774449ae002eeb3,Authors offer an alternative for masked LM pretraining that's more sample-efficient called replaced token detection. Their method basically replaces certain input tokens with alternatives which are sampled from a generator and train a discriminative model to determine whether its generated or real. The work shows empirical success getting better results than GPT with a fraction of the compute on GLUE and others.,"The paper proposed a novel sample-efficient pretraining task. One inefficiency of BERT is that only 15% tokens are used for training in each example. The paper introduced a generator+discriminator framework to optimize the utility of training examples. The generator task is the MLM which predicts the masked word. The author adds a discriminator to further learn from the example by classifying each word to be either generated or original. In this way, more words can be used. This method looks as only adding the discrimination task after BERT pretraining task. But, the authors later show that the best GLUE scores can be obtained only when both generator and discriminator are co-trained. Moreover, the adversarial ELECTRA perform worse. All these observations are interesting. It will be helpful if the authors provide more empirical analysis why the adversarial ELECTRA perform worse or failed. Is it because the GAN is hard to train or the adversarial task doesn't fit the pretraining? ",0.21875,0.08641975308641975,0.12389380530973453
1255,SP:76350402213f8b49bdab9d191d991a18b3c5364d,This paper addresses the problem of evaluating dialogue state trackers (DST)’s generalization ability to novel and realistic dialogue scenarios that do not exist in the dataset. It proposes a model-independent approach to evaluate DST systems with the idea of counterfactual conversation generation. The proposed approach is integrated with three recent DST models and evaluated on MultiWoZ dataset. ,"This paper presents an interesting approach to generate dialogs in a controllable fashion to evaluate a Dialog State Tracking system on a data distribution which is different from the training/test data. The proposed approach first generates a turn-level goal by adding or dropping a slot and then replacing slot values. In the second step, the proposed method generates counterfactual conversation conditioned on the dialog history and goal generated in the previous step. The authors show that evaluating current state-of-the-art DST model on MultiWOZ datasets with the generated counterfactuals results in significant performance drop. Additionally, human evaluation shows that the generated conversations perfectly reflect the underlying user goal. ",0.23728813559322035,0.125,0.16374269005847952
1256,SP:763cf5ceb0330e0c317f78438711e0fb6febe70d,"The paper conditions the value function on a representation of the policy. The representation can be based on a batch of state-action pairs or based on the policy filters. When conditioning on the representation of a new policy, the value function can better approximate the value of the new policy. Experiments show benefits on continuous control tasks.","The authors propose PeVFA: a value function able to evaluate the expected return of multiple policies. They do so by extending the conventional value function, allowing it to receive as input the parameter (or a representation) of the policy. The authors study the local generalization property of PeVFA, propose possible ways of encoding the policy parameters and compare traditional PPO with an extended version of PPO using PeVFA. While the idea of generalization among many policies is an interesting topic in RL, there are many theoretical and experimental issues that prevent acceptance. Moreover, the authors do not at all compare their approach to recent work which also uses value functions with policy parameters as input.",0.3103448275862069,0.1565217391304348,0.20809248554913296
1257,SP:768d2d6dcf6baec2092cb4587df7fe3566e4a27d,"This manuscript developed several algorithms (e.g., AMSGrad-EG, AMSGrad-EG-DRD) for nonconvex-nonconcave min-max optimization. The convergence result of AMSGrad-EG-DRD is shown under the one-sided MVI condition. Polynomial-time complexity results are established. Some toy experiments are conducted for GAN on MNIST and fashion-MNIST datasets.","This paper analyzes the performance of Adam-type algorithms (AMSGrad, to be specific) in nonconvex nonconcave minimax optimization. The authors propose that Adam-type algorithms can converge to a stationary point with the standard MVI assumption and an even weaker one-sided MVI assumption. The authors verify their claims using Experiments.",0.23076923076923078,0.23529411764705882,0.23300970873786409
1258,SP:76a052062e3e4bb707b24a8809c220c8ac1df83a,"Strong paper in the direction of a more biologically plausible solution for the weight transport problem, where the forward and the backward weights need to be aligned. Earlier work for feedback alignment has included methods such as hard-coding sign symmetry. In this method, the authors show that a piece-wise linear model of the feedback as a function of the input given to a neuron can estimate the causal effect of a spike on downstream neurons. The authors propose a learning rule based on regression discontinuity design (RDD) and show that this leads to stronger alignment of weights (especially in earlier layers) compared to previous methods. The causal effect is measured directly from the discontinuity introduced while spiking - the difference between the outputs of the estimated piece-wise linear model at the point of discontinuity is used as the feedback.","This paper considers the ""weight transport problem"" which is the problem of ensuring that the feedforward weights $W_{ij}$ is the same as the feedback weights $W_{ji}$ in the spiking NN model of computation. This paper proposes a novel learning method for the feedback weights which depends on accurately estimating the causal effect of any spiking neuron on the other neurons deeper in the network. Additionally, they show that this method also minimizes a natural cost function. They run many experiments on FashionMNIST and CIFAR-10 to validate this and also show that for deeper networks this approaches the accuracy levels of GD-based algorithms. ",0.2127659574468085,0.2830188679245283,0.242914979757085
1259,SP:76b0a90c46bc2151088210ca47ea4761706f1716,"This paper analyses the numerical invertibility of analytically invertible neural networks (INN). The numerical invertibility depends on the Lipschitz constant of the respective transformation. The paper provides Lipschitz bounds on the components of building blocks for certain INN architectures, which would guarantee numerical stability. Furthermore, this paper shows empirically, that the numerical invertibility can indeed be a problem in practice.","The paper claims that for invertible neural networks, mathematical guarantees on invertibility is not enough, and we also require numerical invertibility. To this end, the lipschitz constants/condition numbers of Jacobians of both the forward and inverse maps of invertible NNs based on coupling layers are examined mathematically and experimentally. The paper also displays cases that expose non-invertibility in these architectures via gradient-based construction of adversarial inputs, as well as a decorrelation benchmark task, and show that spectral normalization can be a remedy for stabilizing these flows.",0.3,0.20224719101123595,0.24161073825503354
1260,SP:76dd5e85169aea4045abea494d5e10909c5fee1f,"This paper takes a deep look at prioritized experience replay, a popular technique in deep reinforcement learning. The paper gives insights on why error-based prioritized experience replay can help when the importance ratio is unused. This paper also pointed out two limitations of prioritized experience replay, which are outdated priorities and insufficient coverage of state space, and the author proposed to use SGLD to solve the limitations. Experiments show that the proposed method leads to a good coverage of state space and improve the return of the training algorithm.","This paper proposes an alternative method for performing Prioritized Experience Replay (PER), which avoids issues of inadequate state coverage and staleness in priority scores. Their method is based on a result from stochastic langevin dynamics, which shows their specific stochastic gradient Langevin dynamics (SGLD) update to online states leads to the ground-truth PER distribution in the limit. Updating collected states this way and adding them to an additional ""stochastic-control queue"" from which sampled minibatch transitions are mixed with those sampled from a standard experience replay buffer. Empirically, this paper shows this SGLD-based method leads to a closer approximation to the ideal prioritized experience replay distribution over recent transitions than standard PER.",0.2,0.15789473684210525,0.17647058823529413
1261,SP:7733bd3495e737a6664928d1d5b01b5485bcce89,"This paper presents a new method for adversarial certification using non-Gaussian noise. A new framework for certification is proposed, which allows to use different distributions compared to previous work based on Gaussian noise. From this framework, a trade-off between accuracy and robustness is identified and new distributions are proposed to obtain a better trade-off than with Gaussian noise. Using these new distributions, they re-certify models obtained in previous work.","This paper investigates the choice of noise distributions for smoothing an arbitrary classifier for defending against adversarial attacks.  The paper focuses on the two major adversaries: \ell_2 adversaries and \ell_\infty adversaries. Theorem 1 quantifies the tradeoff between the choice of smoothing distribution which (1) has clean accuracy close to the original classifier and (2) promotes the smoothness of smoothed classifier (and hence adversarial accuracy).  For the \ell_2 adversary, the paper argues that Gaussian distribution is not the right choice, because the distribution is concentrated on the spherical shell around the x. Instead, the authors propose using a new family of distributions, with the norm square  (p_{|z|_2^2}) following the scaled \chi^2 distribution with degree d-k (Eq. 8). This allows an extra degree of freedom, and setting k=0 recovers the Gaussian distribution. For \ell_\infty perturbations, the paper suggests another family of distributions combining the \ell_2 and \ell_\infty norm (Eq. 9), and argues that it outperforms the natural choice of \ell_\infty norm-based distributions (Eq. 10).",0.1917808219178082,0.07954545454545454,0.11244979919678715
1262,SP:774027f8c53b842fa8ef0569dc1c9b2eaa82872b,"This paper extends the variational deep embedding VaDE model (a VAE-based clustering method) to integrate pairwise constraints between objects, i.e., must-link and cannot-link. The constraints are integrated a priori as a condition. That is, the prior over the cluster labels is conditioned on the constraints. The whole model, referred to as Constrained VaDE (CVaDE), takes the form of a conditional VAE tailored for constrained clustering. Experiments are curried out on various real-world datasets, and the proposed method is compared to VaDE as well as to recent and classical constrained clustering methods. ","This work proposes CVaDE which is an extension of variational based deep clustering model (VaDE) with additional incorporation of prior clustering preferences as supervision. These priors guide the underlying clustering process towards a user-desirable partitioning of input data. The priors are provided in the form of pairwise constraints indicating which pair of samples belongs to same or different class. Clustering process is modelled using variational Bayes in which the clustering constraints are incorporated into prior probabilities with varying degree of uncertainty. The empirical results shows that in comparison to unconstrained clustering the small amount of pairwise constraints significantly improves clustering performance. Further, it demonstrates CVaDE's robustness to noise, generation capability as well as successful incorporation of different desirable preferences to drive clustering performance towards completely different partitioning.",0.23958333333333334,0.17829457364341086,0.20444444444444446
1263,SP:775daca9461db973374fe00a116172aad817a6b8,"This paper proposes CorDial, a new method for dialog summarization. CorDial firstly constructs a coarse draft by generating intent and key phrases for every dialog turn, and splits the dialog into chunks by inserting special boundary tokens; then the segmented original dialog and the constructed draft are feed as input to generate the final summary. CorDial employs BART-xsum as its backbone model, which is a pre-trained language model finetuned on XSUM summary dataset. Experiment result on SAMsum dataset shows CorDial achieves SotA performance under both automatic evaluation metric and human evaluations.","This paper addresses the problem of abstractive dialogue summarization. Its key idea is to label an interrogative pronoun category and extract key phrases from each dialogue turn as weak guide for dialogue summarization. It also proposes a length-controllable generation method for final summary. The proposed approach is evaluated on the SAMSum as one of the largest abstractive dialogue summarization benchmarks, on which it shows competitive performance over recent models. ",0.16129032258064516,0.21428571428571427,0.18404907975460122
1264,SP:776851b803da21fa83071c6f5c41e82a1ccc765a,"This paper focuses on the problem of semi-supervised semantic segmentation, where less pixel-level annotations are used to train the network. A new one-stage training framework is proposed to include the process of localization cue generation, pseudo label refinement and training of semantic segmentation. Inspire by recent success in the semi-supervised learning (SSL), a novel calibrated fusion strategy is proposed to incorporate the concept of consistency training with data augmentation into the framework. Experiments on PASCAL VOC and MSCOCO benchmarks validate the effectiveness of the proposed method.  ","This work addresses the task of semi-supervised learning (SSL) in semantic segmentation. Following recent SOTAs in SSL, this work also advocates for the use of pseudo-labels on unlabeled data and heavy data augmentation. The main novelty of this work is the novel way to construct higher-quality pseudo-labels: besides the pixel-wise classifier's probabilistic outputs, the authors leverage as well CAM-based activation maps, named as SGC, as an additional pseudo-label source.  The final set of pseudo-labels is determined by linear combining the two soft pseudo-label sources with temperature adjustment. The authors conducted extensive experiments with lots of ablation studies to validate the proposed framework.",0.25555555555555554,0.20535714285714285,0.2277227722772277
1265,SP:7779d1953e3ed8adc93423c31c4479343c168e09,"This paper introduces L2ight, a framework for mapping a pre-trained machine learning model to an optical neural network implemented with MZIs. The framework also supports on-chip learning: this is done by fine-tuning the implemented weights to compensate for manufacturing imperfections in the chip, or to perform transfer learning from one domain to another.   To do so, L2ight first performs an identity calibration step, then map the pre-trained weights, and finally uses subspace learning to enable efficient model fine-tuning to a specific task or to a specific chip. The paper provides extensive empirical evidence motivating this approach, focusing on compute vision applications. It is able to deal with architectures orders of magnitudes larger than the current state-of-the-art.","Optical Neural Networks (ONN) with their attojoule per Multiply Accumulate energy efficiency and sub-nanosecond latency are becoming useful implementation hardware for large scale deep learning models and datasets. Despite their efficiency and speed, ONNs suffer significant loss in accuracy due to manufacturing defects/non-ideal device controls and circuit noises. Simulating these non-idealities during software training is not scalable.   Training ONN on-chip is a hard problem that is exacerbated due to above factors. This paper tackles the problem by proposing a three-stage learning framework L2ight. The three stages are variation-agnostic calibration, alternate-projection based parallel mapping and multi-level sparse subspace learning.   L2ight enables scaling up on-chip ONN training, for the first time to models with 10M params (1000x scalable than baseline). This scalability is built on top of an efficient training algorithm utilizing multi-level sparsity and a restricted subspace optimization step which enables sufficient adaptability for on-device learning and task transfer. L2ight also achieves 30x higher efficiency than prior art. Lastly, the subspace learning step is agnostic to device/process variation and mapping noise enabling robust implementation of deep neural networks (DNN).    ",0.1774193548387097,0.11518324607329843,0.13968253968253969
1266,SP:777d97a7493bec44126e7bd1b83fe15bc5f77ae8,"EDIT AFTER AUTHOR RESPONSE:  One concern I originally had was whether researchers would actually find this dataset useful, but the review by @Yh1E and @uke7 improved my impression of the utility of the dataset.  I am also pleased that the authors will comment more on the relation of their problem setup to classical MDP and POMDP frameworks.  Hence I am raising my score from 5 to 7.  This paper asks whether AI systems can demonstrate similar theory of mind (ToM) capabilities as human infants.  It identifies a number of key ToM capabilities that have been established in the cognitive science literature, such as learning preferences of observed agents, and predicting that agents will take the most efficient path to their goal.  The paper introduces a benchmark dataset with 2d and 3d videos with simulated agents for the purpose of testing ToM capabilities in AI systems.  Each task in the dataset consists of a familiarization phase with videos intended to allow learning of agent behavior, and then a test phase where the agent exhibits either expected or unexpected behavior.  Taking inspiration from the fact that human babies look longer at unexpected stumli, the paper introduces a ""violation of expectations (VoE)"" framework for evaluating AI systems.  Under this paradigm, an AI system is considered to demonstrate evidence of human-like learning if it has greater prediction error for video frames in the unexpected condition than in the expected condition for the testing episode.  It evaluates two recent approaches on this dataset, behavior cloning, and offline RL.","This paper presents the Baby Intuitions Benchmark (BIB) to test deep learning methods abilities’ to reason about how other agents will behave. BIB is inspired by human infants’ expectations about other agents, as clearly laid out in the paper. The authors include several different capabilities/tasks within the benchmark along with their developmental background, testing 3 different models across 5 different tasks. These models only perform well in the simplest of tasks, suggesting that the benchmark tests capabilities that are not trivial to acquire with current methods.",0.07480314960629922,0.21839080459770116,0.11143695014662758
1267,SP:778ec97ea45befde6a8cba2e505f92c5706185e4,This paper presents a SIFT-feature inspired modification to the standard convolutional neural network (CNN). Specifically the authors propose three innovations: (1) a differences of Gaussians (DoG) convolutional filter; (2) a symmetric ReLU activation function (referred to as a truncated ReLU; and (3) a projected normalization layer. The paper makes the claim that the proposed CNN variant (referred to as the EVPNet) demonstrates superior performance as well as improved robustness to adversarial attacks.,"This paper proposes a network model named EVPNet, inspired by the idea scale-space extreme value from SIFT, to improve network robustness to adversarial pertubations over textures. To achieve better robustness, EVPNet separates outliers (non-robust) from robust examples by extenting DoG to parametric DoG, utilising truncated ReLU, and then applying a projected normalisation layer to mimic PCA-SIFT like feature normalisation, which are the three novelties that the authors claim in this paper. In the experiments, FGSM and PGD are used to provide adversarial attacks, and experiments conducted on CIFAR-10 and SVHN reveal that EVPNet enhances network robustness.",0.2876712328767123,0.21,0.24277456647398843
1268,SP:77a021f5518dc4d5081ec7387b7940de4968ea86,This paper studies the theory of self-distillation in the kernel ridge regression setting. The authors extend the theoretical results in Mobahi et al. (2020) to further incorporate the ground-truth labels in the distillation objective and highlight that the ground-truth labels serve to dampen the sparsification and regularization of the self-distilled solutions.,"This paper presented a theoretical and empirical study of weighting the teacher outputs and the target outputs during self distillation. For an iterative self distillation process, a solution is shown to compute the fit at any step of the iteration given the first model. This was further related to classical kernel ridge regression with regularization.",0.2,0.2,0.20000000000000004
1269,SP:77b114448647f9b8edcd6dad7d8be6e152e44696,"The paper proposes a method to simultaneously learn effective representations and efficient exploration in a reward-free context. The algorithm iterates between minimizing a contrastive loss and maximizing an intrinsic reward derived from a k-NN entropy estimation of the state distribution. Then, authors empirically evaluate the method over a set of visual Mujoco tasks and Atari games.","This submission presents a technique for unsupervised pre-training of representations and policies for RL. Unsupervised representation learning has obtained impressive results in supervised scenarios, and adapting these methods to RL is an important research direction. One of the main challenges in the RL setting is that of defining the distribution of data to learn from, as well as sampling from it. The learned representations are unlikely to be useful for observations that are out of the pre-training distribution, so it is desirable to perform representation learning on data that is representative of the full state space. Previous works (Hazan et al., Lee et al.) proposed strategies to train agents that induce maximally entropic state visitation distributions, but they involve density estimation whose underlying assumptions are not well suited for pixel observations. The authors propose to overcome these limitations by using a particle based entropy estimate in the learned representation space. The pre-trained representations and policies can be used for RL from pixels, obtaining faster convergence and higher end scores than the considered baselines in both DMControl and Atari.",0.2413793103448276,0.07734806629834254,0.11715481171548116
1270,SP:77b9c09e04fa51dc104ced583ed8bbc270d73955,"This study proposes a novel method that can work well even the training data is corrupted by partial data from the unknown domain. Though it deals with the well-known problem called 'Noisy data/label', its approach is not the same thing as the previous works as it focuses on variational autoencoder on the task of novelty detection. And its arguments and statistical assumptions are followed by mathematical proofs. ","The paper seeks to address the problem of novelty detection under the circumstance of having high corruptions in the training data. This is different from most previous work, which often assumes that training dataset is pure. To address this issue, a VAE-based approach is adopted in this paper, with several modifications made to the vanilla VAE to promote the robustness of VAE in detecting outliers in the corruption circumstance. Among the modifications, the paper assumes the posterior is approximated by a two-component Gaussian mixture distribution, with each having a low-rank and full-rank covariance matrix, respectively. The paper hopes that the posterior of inliers (normal data points) can be represented by the low-rank covariance matrix, while that of outliers cannot. Another notable modification is that the Wasserstein-1 regularization is used to replace the KL-regularization in the ELBO, which is claimed to be more suitable to the low-rank modeling. Some experiments are conducted to evaluate the outlier detection performance of the proposed method under corrupted circumstance.",0.2028985507246377,0.08139534883720931,0.11618257261410787
1271,SP:77cbeaffd1cf539e8793dcf0e95f5bb9186cf973,"This paper proposes a secure federated learning framework against weight poisoning. The key component in the framework is the discretization mechanism which works well with a sufficient number of clients. Theoretical analysis of the robustness and convergence is provided. Lastly, numerical analysis is provided to verify the performance of the proposed method.","Federated learning (FL) has been shown to be vulnerable to weight poisoning attacks. An attacker who controls malicious clients can poison the clients’ model weights such that a backdoor to perform availability poisoning attacks, integrity backdoor attacks and inference attacks. In this work, the authors proposed a new FL algorithm called FedDiscrete, which probabilistically discretizes the clients’ model weights into two different values. The authors derived the convergence of FedDiscrete and empirically showed its performance against existing attacks. However, I am worried about the theoretical analysis on the robustness, as well as the empirical robustness against adaptive attacks.",0.2692307692307692,0.14285714285714285,0.18666666666666665
1272,SP:77d494504c452a54b670252891def572b91f066e,"The authors propose another method of doing population-based training of RL policies. During the training process, there are N workers running in N copies of the environment, each with different parameter settings for the policies and value networks. Each worker pushes data to a shared replay buffer of experience. The paper claims that a natural approach is to have a chief job periodically poll for the best worker, then replace the weights of each worker with the best one. Whenever this occurs, this reduces the diversity within the population.","This work presents a distributed framework for off-policy RL consisting of multiple agents that are trained in parallel while also being regularized to be similar to the current best policy. Maintaining a population of agents can help mitigate issues due to convergences to local optima. The method is evaluated on standard continuous control tasks, and shows some performance improvements over methods that train just a single agent. Ablation experiments are also conducted to evaluate the effects of different design decisions.",0.13333333333333333,0.14814814814814814,0.14035087719298248
1273,SP:77d59e1e726172184249bdfdd81011617dc9c208,"The paper proposes a quantum computer-based algorithm for semi-supervised least squared kernel SVM. This work builds upon LS-SVM of Rebentrost et al (2014b) which developed a quantum algorithm for the supervised version of the problem. While the main selling point of quantum LS-SVM is that it scales logarithmically with data size, supervised algorithms shall not fully enjoy logarithmic scaling unless the cost for collecting labeled data is also logarithmic, which is unlikely. Therefore, semi-supervised setting is certainly appealing. Technically, there are two main contributions. The first is the method of providing Laplacian as an input to the quantum computer. The second contribution, which is about the computation of matrix inverse (K + KLK)^{-1}, is a bit more technical, and could be considered as the main contribution of the paper.",This paper developes a quantum algorithm for kernel-based support vector machine working in a semi-supervised learning setting. The motivation is to utilise the significant advantage of quantum computation to train machine learning models on large-scale datasets efficiently. This paper reviews the existing work on using quantum computing for least-squares svm (via solving quantum linear systems of equations) and then extends it to deal with kernel svm in a semi-supervised setting. ,0.1417910447761194,0.25333333333333335,0.1818181818181818
1274,SP:77e60bbe1d3357adcdbe9c340b2f081cbce95090,"The authors present empirical results about the correlation between the activations in a neural network across time for a fixed pair of images.  They show that for the same pair of images xi and xj, the activations change over time until they settle when the learning rate is sufficiently small. The authors claim that this provides insight into why neural networks generalize, by arguing that the network uses different features at different epochs during training.  ","This paper proposes a different look at why neural networks generalize despite optimizing to zero training error, over-parameterization, etc.  The contribution is mostly experimental in the sense of computing various statistics of a model during training and correlating those statistics with generalization performance.  The core idea is to define ""image functions"" which are determined by the training image and the current training iteration.  Correlation statistics on these functions for different and same training images show patterns in the training dynamics, which may indicate generalization for example as training continues towards zero error the statistics still vary.  The paper focuses on classification with CIFAR10 and ImageNet with AlexNet, VGG, and ResNet models.  In particular the results are specialized for ReLU networks training with SGD.",0.16,0.0967741935483871,0.12060301507537688
1275,SP:781801713deb9efac5404cb98f6c40c83244cc14,"This paper introduces a method for doing knowledge distillation with noisy labels. The contribution consists on representing distilled labels as a weighted moving average of the predicted labels from a teacher as it trains (using noisy one-hot encoded labels). Finally, a student is trained using the distilled labels.","This paper proposes an explanation for the success of distillation. It first experiments with synthetic Gaussian data. On synthetic data, it shows that distillation works better from an early-stopped model. It probes why, and finds that, when the one-hot label is far from the true conditional distribution, the early-stopped model’s distribution tends to be closer to the true distribution than either the one-hot label or the converged model. The early-stopped model is better because, over the course of training, the model tends to produce a distribution close to the true one before finally overfitting the one-hot label. Some examples show similar patterns for real-world networks/datasets, provided the predictions over training are smoothed. Motivated by these results, the paper proposes to use an averaged distribution of labels from different steps of training rather than the distribution at the end of training, and shows that this improves performance by a little bit.",0.2653061224489796,0.08176100628930817,0.125
1276,SP:7819ce9440a684398e2958e908a55022ac70b890,"The paper proposes an ensemble distillation approach, in which one network is used as feature extractor and ""two heads"" (two networks representing teacher and student) are added to the network for self-distillation. The multiple teacher predictions can be generated through by adding multiplicative Gaussian noise. The distillation approach follows Malinin et al. [1] who proposes to model the predictive distribution with a Dirichlet and predicts the parameter of the Dirichlet distribution (instead of predicting the Categorial distribution). This approach can be both used for model distillation and ensemble distillation. The authors evaluated their models on CIFAR-100, LSUN, SVHN w.r.t. classification performance, calibration and out-of-distribution detection.","This paper contributes to neural network classifier training and uncertainty prediction.  It proposes a self-distribution distillation method that can train a single model to estimate uncertainties in an integrated training phase.  Also, it is flexible to be extended to build ensembles of models in the training phase and efficiently deployed in the test phase. Experiments are done on both classification and out-of-distribution detection tasks to show effectiveness.",0.17117117117117117,0.2714285714285714,0.2099447513812155
1277,SP:781c51554cfd04222ef6c6c92648d1824e054ae1,"In this work, the authors tackle the problem of span-based copying in sequence-based neural models. In particular, they extend the standard copying techniques of  (Vinyals et. al., Gulcehre et. al., etc.) which only allow for single-token copy actions. Their span-based copy mechanism allows for multiple tokens to be copied at a time during decoding via a recursive formulation that defines the output sequence distribution as a marginal over the complete set of action combinations that result in the sequence being produced. The authors also propose a span-based beam decoding algorithm that scores output sequences via a sum over the probabilities of action sequences that produce the same output. ","This paper study the problem of editing sequences, such as natural language or code source, by copying large spans of the original sequence. A simple baseline solution to this problem is to learn a sequence to sequence neural network, which generates the edited sequence conditioned on the original one. This method can be improved by adding a copying mechanism, based on pointer networks, to copy tokens from the input. However, most of such existing approaches can only copy one input token at a time, which is a limitation when most of the input should be copied, which is the case for most editing tasks. In this paper, the authors propose a mechanism that can copy entire spans of the input instead of just individual tokens. In that case, a particular sequence can often be generated by many different actions (eg. copying individual tokens, pairs of tokens, or the whole span). It is thus important to marginalize over all the actions that generated a particular sequence. This can be done efficiently, using dynamic programming, if the probability of an action depends on the generated tokens only, but not on the sequence of actions used to generate them. In the case of neural network, this means that the decoder of the model takes the tokens as input, instead of the spans. To represent spans, the authors propose to use the concatenation of the hidden states corresponding to the beginning and end of the span. Then the probability of copying a span is obtained by taking the dot product between this representation and the current hidden state of the decoder, and applying the softmax. The authors evaluate the proposed approach on the following tasks: code repair, grammar error correction and edit representations (on wikipedia and c# code).",0.2920353982300885,0.11224489795918367,0.16216216216216217
1278,SP:784bb8350a1f8d1f69734ecaa8395fc4a67b1abf,"The paper is concentrated at dealing with the data missing problem of MTPP and applies an AAE for the “incomplete multi-categorical MTPPs”.  First, the problem description appears questionable. Point processes are a class of stochastic processes for modelling discrete event sequences in a continuous time domain. They are statistical models and have a well-defined mathematical meaning. The expression of “incomplete point process” is quite confusing. One possible reason is that the authors fail to distinguish between the model and the data. One can say “incomplete data” or “incomplete observations of a model”, but “incomplete model” is not acceptable unless properly defined. Therefore, the proposed method seems not specifically for point processes but for the sequential data. ","The authors propose a method for multi-category marked temporal point processes (MTPPs) generation with sparse, incomplete, and small training dataset. They apply Adversarial Autoencoder (AAE) and feature mapping techniques, which include a transformation between the categories and timestamps of marked points and the percentile distribution of the category.  The paper shows effectiveness and robustness of the proposed method by comparing with Markov chain approach on three datasets: Radicalization Dataset, Mimic III Dataset and Stack Overflow Dataset.",0.1440677966101695,0.22077922077922077,0.17435897435897435
1279,SP:784d0a4ec96148d255be2b193a4fa45437f03105,"This work applies a recent approach to maximum cardinality matching due to to Lahn and Raghvendra to a special case relevant to the machine learning community. Namely, they analyze the performance of this approach on delta-disc graphs in the service of computing popular distance metrics. Comparisons are made to the classic Hopcroft-Karp approach with empirical validation.","This paper gives a fast and practical algorithm for computing approximate max cardinality matching in unit disc planar graphs. It's based on a recently improved bound that utilizes the (2-level) partition tree in more redundant manners. The implemented algorithm was tested on moderate datasets of around 10^6 vertices, and a performance gain by a factor of 4 or so was demonstrated.",0.15517241379310345,0.140625,0.1475409836065574
1280,SP:7883aef70e8fefe38482cd2baeb645e94b21c4d2,"The paper at hand introduces Neurally augmented ALISTA (NA-ALISTA) which is an extension to the previously proposed analytical learned iterative shrinkage threshold algorithm (ALISTA). Both algorithms belong to the class of learned optimization algorithms for solving the compressed sensing problem, i.e., methods that have parameters which are learned via backpropagating through multiple iterations of the algorithm. The key novelty of the NA-LISTA is the LSTM network used to predict thresholds and stepsized used by the algorithm. The experiments show that this adaptive approach improves the performance of ALISTA.","This paper extends the framework of ALISTA, a variant of learned ISTA called Neurally Augmented ALISTA (AG-ALISTA), which significantly reduces the number parameters in the model (down to 2 scalars per layer, one for step size and the other for the threshold in soft-thresholding function). Specifically, the authors use a LSTM to generate these two parameters in each layer along iterations, taking reconstruction error related signals as input. This method is based on (1) the previous previous finding of the relation of the step size and threshold with the $\ell_1$ signal recovery error; and (2) the empirical observation of the correlation between the $\ell_1$ signal recovery error and reconstruction error. Experiments in synthetic setting show the superiority of AG-ALISTA over ALISTA and other variants that follow it, especially in settings where the compression ratios are challenging, which is claimed to be more realistic in real-world settings.",0.2857142857142857,0.17105263157894737,0.2139917695473251
1281,SP:789952dc98861a18ec301641a66f64eabc8a6e13,"Motivated by the sort-and-smooth graphon estimator of Chan and Airoldi, 2014, this paper proposes two new clustering algorithms (graph distance based spectral clustering and similarity based semidefinite programming) for multiple graphs observed without vertex correspondence. The idea is to use the graphon approximation method to obtain a histogram estimator with the same number of bins for each graph and subsequently apply an existing spectral clustering approach on the graphon based distance matrix. Theoretical properties of their approach are studied (under reasonable smoothness assumptions on the generating process i.e. graphon) and consistency is established. The graph distance metric is applied to test for similarity of two collections of graphs.  ","The paper proposes a graph distance based on graphons that can operate on the small sample size regime; this is possible by exploiting a large number of nodes. The proposed paper is meant to address two shortcomings that the authors have found in the literature:  - a lack of study of current graph processing methods beyond graph-level classification, and  - a lack of theoretically sound methods.    The paper also shows theoretical guarantees associated with two existing clustering methods and a two-sample statistical tests when operating with the proposed distance.  ",0.17117117117117117,0.21348314606741572,0.19
1282,SP:78d4c2c77089404286de268b9865fd1981b61883,"The authors introduce BabyAI, a platform with the aim to study grounded language learning with a human in the loop. The platform includes a *simulated* human expert (bot) that teaches a neural learner. The current domain used in a 2D gridworld and the synthetic instructions require the agent to navigate the world (including unlocking doors) and move objects to specified locations. They also introduce ""Baby Language"" to give instructions to the agent as well as to automatically verify their execution.","This paper presents a research platform with a simulated human (a.k.a bot) in the loop for learning to execute language instructions in which language has compositional structures. The language introduced in this paper can be used to instruct an agent to go to objects, pick up objects, open doors, and put objects next to other objects. MiniGrid is used to build the environments used for this platform. In addition to introducing the platform, they evaluate the difficulty of each level by training an imitation learning baseline using one million demonstration episodes for each level and report results. Moreover, the reported results contain data efficiencies for imitation learning and reinforcement learning based approaches to solving BabyAI levels. ",0.2625,0.17796610169491525,0.2121212121212121
1283,SP:78f30ff42b38782a096376e39364151da28d1812,"This work presents FOSAE++, an end-to-end system capable of producing ""lifted"" action models provided only bounding box annotations of image pairs before and after an unknown action is executed. Building on recent work in the space, the primary contribution of this work is to generate PDDL action rules. To accomplish this, the authors introduce novel 'params' function that use the Gumbel-Softmax function to implement a differentiable mechanism for selecting which entities are relevant to the current action and feeds them into the new 'bind' and 'unbind' functions that select those elements in the tensor predicting their relevance. Overall, this work is a meaningful contribution in the direction of generated lifted action models without direct labeled data.","This paper addresses the problem of learning dynamics model directly from raw sensory inputs. The authors propose an unsupervised end-to-end model that can perform high-level tasks planning on raw observations. This work extends Asai et al. 2020, 2019 etc, and with improved symbol generation and lifted PDDL. The authors follow the experimental setup as seen in prior work, where three artificial environments (blocksworld, MNIST 8-puzzle, and sokoban) are used for planning. ",0.11764705882352941,0.18666666666666668,0.14432989690721648
1284,SP:78faeffc7a6d60225bded8a9e6eee2aa369138fc,"This paper aims to propose a new GNN for heterogeneous graphs, which is scalable to large-scale graphs. The proposed idea is to leverage an existing model called SIGN, which simplifies GCN by dropping the non-linear transformation from intermediate layers, and extend it to heterogeneous graphs. The results on several benchmark datasets show the proposed approach is better and faster than baselines.","The authors propose a method to broaden the scope of SIGN, a technique recently introduced for single-relational graphs. The method allows SIGN to also be applied to multi-relational graphs (often called heterogeneous or knowledge graphs in different communities). In SIGN, various powers of the Laplacian are precomputed. For each power, the features of the nodes of a node’s neighborhood are averaged and (e.g., with an MLP) projected into a node vector representation. This is then used to classify the node. ",0.19047619047619047,0.14285714285714285,0.16326530612244897
1285,SP:791463405deae8b2ebe7e98d38022bfa866d02cd,"The paper introduces a predictive state representation (PSR)-based MARL framework. The framework uses a graph representation to model the interactions between agents. Performance bounds are given for the learned predictive state representation.  With the MAPSR, individual policies are trained by replacing the partial observation o with PSR Q. The experiments results show the advantage of the proposed method compared with the baselines experimented in the paper. ","The authors present a framework and method in which predictive state representations for multiple agents simultatneously acting and interacting within an environment. This is presented in a general way, where predictive states are Hilbert space operators which when applied to sequences of observations and actions appropriately predict the predictions of these state representations. The key advance in this work is to apply this existing PSR framework to networks of agents, with 3 types of agent network: static complete graph (all agents affect all others experience); static non-complete graph (only some agents affect one another); and dynamic non-complete graph (agents affect one another in a time varying way). A number of theoretical results are presented, including PAC bounds for the approximators in the framework.  The authors then present two closely related methods to learn policies alongside these multi agent PSRs in an online way. The first MAPSRL-1 is akin to the independent actor critic (Foerster et al., 2017) and thus may suffer from the apparent non-stationarity of the environment from the perspective of any one agent. MAPSRL-2 addresses this by incorporating the PSR information from other agents into the policy gradient update.  The paper presents a series of experiments based on environments encoded in the  OpenAI Gym MAMujoco system. These are environments presented in previous papers and there are a broad selection of these.  ",0.31343283582089554,0.09210526315789473,0.14237288135593218
1286,SP:792688942b9ebce1d30ed067109066ebeaf1236a,"This paper considers a new and complex setting involving domain adaptation, federated learning, and knowledge distillation: Under the premise of protecting privacy, one needs to deploy a compact model from a source central server to target client devices and requires the model to learn new knowledge with target unlabeled client data while remembering knowledge of source data on the central server. Generally, the authors propose a source-target unified knowledge distillation scheme. Within this scheme, the authors propose solutions to tackle corresponding difficulties with this setting. Specifically, to avoid the low inference accuracy due to low model capacity, a large source central model is adapted to target clients with SHOT (ICML'20). A lite-residual hypothesis transfer method is proposed to keep memory-efficient adaptation on target clients. A collaborative knowledge distillation method is proposed to defy catastrophic forgetting of source knowledge. To protect the privacy of target clients, a secure aggregation method is used. The authors validate the effectiveness of the proposed scheme on three domain adaptation datasets. ","A compact model deployed to a device may not work well if this device has a different data distribution. This work proposes to load a large pretrained model onto a device and then adapt it to the target data on the device. As directly training the full large model is too memory-heavy, this work proposes to adapt the large model's knowledge by training only part of its parameters on the local device data. To then transfer global model knowledge to the compact model this work proposes a collaborative knowledge distillation. ",0.14792899408284024,0.2717391304347826,0.19157088122605365
1287,SP:794393405d88536ffc86021bf4939b168ff7f791,"This paper works on unsupervised discovering keypoints in an Atari game frame to help improving Atari game performance. The keypoint discovery is based on predicting ""predictable"" local structure. I.e., the authors consider points that can not be predicted from its neighbor as good. Experiments show the learned keypoints performs better on 3 Atari games (Table. 1) than a counterpart keypoint discovery method, Transporter. ","The authors tackle the problem of self-supervised representation learning, and validate their approach on downstream Reinforcement Learning tasks. Building on the insight that predictability in local patches is a good inductive bias for salient regions that characterize objects, the authors propose a well-reasoned, well-engineered and thoroughly validated pipeline for learning object keypoints without supervision. The authors present a wide range of ablative studies to validate their design choices, and demonstrate the superiority of their method both illustratively as well as quantitatively on a number of standard Atari benchmarks. ",0.140625,0.0989010989010989,0.11612903225806452
1288,SP:794bafd503d3cee3060a5c8ba489ca141d0d3e5e,"The paper studies the problem of learning invariant visual representations for reinforcement learning. Specifically, it builds on prior work Deep Bisimulation for Control (DBC) (Zhang et al), which learns an image representation predictive of rewards and dynamics and uses it with SAC. This paper makes a few modifications on top of DBC, specifically (1) instead of a single state embedding, it learns two separate ones (one for rewards and one for dynamics), (2) instead of using L1 distance in the embedding space to measure distance it instead uses a learned MLP which predicts distance, (3) using gradients from SAC it learns to dynamically adjust the balance between the dynamics weight and reward weight, and (4) adds image augmentation to the training. Experiments indicate on Distracting Control that on 2/4 tasks it matches DrQ and DBC and on the other 2 tasks outperforms them. Ablations suggest that all components are important, particularly (1) and (2).","This work considers the problem of learning representations of high-dimensional pixel observations for RL. High-dimensional pixel observations often include many task-irrelevant details and ideally, an effective representation of such observations should only encode the task-relevant details. To implement this intuition, this work proposes to learn a two-part representation based off of a bisimulation metric. Two states that have similar first parts of the representation should exhibit similar reward structure, and two states that have similar second parts of the representation should exhibit similar dynamics structure. This work evaluates this learned representation on several continuous control tasks with distracting backgrounds and on CARLA, and shows that the proposed learned representation improves over baselines.",0.16129032258064516,0.21367521367521367,0.18382352941176472
1289,SP:794d8a1cf74a54e0d0b73832c44d05074ba9a246,"The paper presents an unsupervised approach for learning landmarks in images or videos with single objects by separating the representation of the image into foreground and background and factorizing the representation of the foreground into pose and appearance. It builds upon previous work [Jakab 2018, Lorenz 2019] who proposed to train by reconstructing the original image from one version of the image with perturbed appearance and another with perturbed pose. It extends this approach by introducing an additional separation of foreground and background in the image. ","The paper presents an unsupervised method to get disentanglement of pose, appearance, background from both images domain and video domain. 5 sub-network are used to model pose, appearance, foreground, background, and decoders.  Their methods let the network focus more on the foreground to regress the landmark and improve state-of-the-art performance on landmark regression (unsupervised.), video prediction and image reconstruction. ",0.20930232558139536,0.2857142857142857,0.24161073825503357
1290,SP:79570f7ba5c60925f5612cf5e1f8b46a5332d880,"This paper provides a method for using a VAE with proxy variables to estimate CATE in a model with latent confounding by recovering a conditional distribution over the latent confounders. Building upon results from Khemakhem et.al. 2020, the confounding can be identified if the latent variable is parameterized by an exponential family distribution dependent on the proxy variable, and the outcome variable is an injective function of the latents with (small) additive noise. Conceptually, the paper is similar in goal to Louizos et al. 2017, with the main difference seeming to be a stronger theoretical base.","The present paper introduces Counterfactual VAE (CFVAE), a generative learning method to estimate treatment effects under a latent unconfoundedness assumption. It builds on variational autoencoders (VAE) to learn causal representations. The authors provide identification results using recent results on nonlinear ICA (Khemakhem et al., 2020). They show that the confounder is identifiable up to an affine transformation.",0.16494845360824742,0.2807017543859649,0.20779220779220778
1291,SP:7975585d96507de92ea59435396a8ed2fcc91008,"This paper proposes a generative model as an extension of FineGAN that aims to learn a disentangled representation for image shape and appearance across different domains rather than ""intra-domain"" disentanglement. To this end, the authors adopt the prior that features that correspond to an object's appearance should preserve frequency histograms. In order to incorporate this prior into the differential learning procedure, they learn a library of convolutional filters using a contrastive learning framework. They provide many convincing baselines and comparisons to related work and are able to attain reasonable results for style/content transfer between unrelated domains.","The submission describes a method to disentangle shape and appearance of images across two domains such that new images can be generated that have appearance and shape from either of these domains while still being visually convincing. Starting from an established method (FineGAN) to disentangle shape, appearance, background identity as well as a set of ""nuisance"" factors such as pose in one domain, the paper proposes to add a loss term that aims at retaining appearance when moving from one domain to another. This additional loss term essentials tries to keep the low-level image statistics between two images when both of them are generated with the same appearance, but possibly different shapes. It is trained such that it is invariant to the nuisance parameters (same object under differing views has same statistics), but discriminative towards the object appearance (different objects from the same view have differing statistics). The low level features are expressed as histograms of responses of convolution filters over the masked foreground pattern. The paper provides empirical evidences in the form of example images where appearance and shape are combined from two different domains (out of cars, birds, dogs, animals) as well as proxy measurements for the quality of the transfer: (a) how much do the low-level statistics differ in terms of $\chi^2$ distance, (b) how well is shape disentangled under changing appearance by measuring the foreground overlap between samples, (c) a user preference study (which method transfers shape and appearance better?). The results are compared to some relevant baselines (FineGAN, CycleGan, AdaIn, MUNIT), and show moderate improvements over those.",0.25252525252525254,0.09433962264150944,0.13736263736263735
1292,SP:797a59091f5ce57f264400b8fa7e0b485584338c,"The paper propose a network compression algorithm by exploiting a reformulation of activation function as proximity operator. The latter is an optimization problem whose optimality condition reveals constraints on the weight matrix W of the neural net. The main idea is then to ""biasedly"" select W as a minimizer of a sparsity inducing penalties under a relaxation of the previous optimality conditions. The authors provide details on solving such problem as well as numerical experiments that leads to similar results than competitors.",In this paper the authors propose a new model compression method based on subdifferential inclusion. The key idea is to make the outputs of the neurons in the sparse and dense networks at the same input close enough. They rewrite the activation function as the proximity operator of a proper convex function and finally formulate the compression problem into a constraint minimization problem using the technique of subdifferential inclusion. They conduct a series of experiments to evaluate the performance of their proposed methods.,0.21951219512195122,0.21686746987951808,0.2181818181818182
1293,SP:799f1f3b28f7fa2eed16c3aa894cbea04c32233d,"This paper studies the Pseudo-dimension (also the VC-dimension for the classification task) of a class of learning models (including linear regression (Eq. 4) and classification (Eq. 5), and completion (Eq. 6) ), of which the weights are modeled by tensor networks (TNs). In the work, the authors give an upper bound on the Pseduo-dimension of the models (Thm. 2) and a generalization bound for classifiers (Thm. 4). Furthermore, the authors also discuss the lower-bounds for several specific TN models to demonstrate the tightness of the obtained upper-bounds up to a $\mathcal{O}(\log(p))$ factor.",This work considers the tensor network methods in machine learning. The major contributions are some new lower and upper bounds on the pseudo-dimension for a large class of TN models. The derived results can be applied to machine learning tasks which involves the tensor decomposition models.,0.1414141414141414,0.2978723404255319,0.1917808219178082
1294,SP:79a050f3b4f6466e5bee5533a7b018b2f200cb01,"The author studies the quantization strategy of CNNs in terms of Pareto Efficiency. Through a series of experiments with three standard CNN models (ResNet, VGG11, MobileNetV2), the authors demonstrated that lower precision value can be better than high precision values in term of Pareto efficiency under the iso-model size scenario. They also study cases with and without depth-wise convolution, and propose a new quantization method, DualPrecision. DualPrecision empirically outperformed 8-bit quantization and flexible quantization methods on ImageNet.","This paper studies the accuracy vs model-size trade-off of quantized CNNs under different channel width multipliers. The authors demonstrated that while all-to-all convolution works well under low bit settings, depthwise conv needs a different sweet spot. The authors then proceed to use the insight to design quantized cnns that have two different schemes for depthwise and normal conv.",0.1375,0.1774193548387097,0.15492957746478875
1295,SP:79c210d864f10eeaff9033fa95b89b5b47dd0083,"The authors present a new neural network system that can reason over entities. The solution should be applicable to any tasks that require visual reasoning.  Specifically, the NPS algorithm is: ``` for every step in a sequence:     update the slots (entities)     compute attention between slot queries and rule keys to select a rule     compute attention between primary slot queries and all slot keys to get contextual slot     apply the rule MLP to the primary and contextual slot values     add the result to the primary slot ``` Slots can either be updated in parallel (i.e., there is only one slot updated per step) or in sequence (i.e., multiple slots can be updated per step).  They compare sequential vs parallel rule application on 4 tasks: - given a transformation and mnist digit, predict the digit with the transformation applied - given two x,y coordinates predict the result of an arithmetic change (e.g., subtract the ys from one another) applied - for a stack of falling shapes, predict the bounding box of each object in future frames - predict the next frame of billiard balls bouncing around  They compare NPS to GNNs and related methods on four tasks. The goal of each task is to predict latent states in future frames: - physics env: blocks of unknown weight interacting with one another - Atari games (pong, space invaders, freeway, breakout, qBert) - sprites (moving objects of different shapes)","This paper proposes Neural Production Systems (NPS) which is a (neural) rule-based learning system that operate on explicit entities. The main idea is to extend traditional Production systems to be end-to-end learnable with neural networks. Unlike previous NN systems that model entity-wise interactions such as GNN, NPS allows sparse interactions between entities which is favorable in certain scenarios. ",0.06086956521739131,0.22580645161290322,0.09589041095890412
1296,SP:79c4e8896d036ead564e12d86b7ed8a4796b472a,"The authors propose a framework to generalize transformers to any order permutation invariant data, especially hypergraphs. While the generalization itself is incremental compare to [20], the naïve approach gives unbearable computational complexity. Hence, the authors propose a series of tricks to lower the computational complexity which is their main contribution.","In this paper, the authors proposed a transformer layer that generalizes the equivariant linear layers with self-attention to higher order tensor input. They defined the attention coefficient for each equivalence class $\mu$ with indices satisfied $(i, j) \in \mu$ to reduce unnecessary computation between queries and keys matrices. To further reduce the computation complexity of higher order transformers, the authors provides 3 steps of approximation: i) a lightweight linear layers defined only for subset of equivalence class to decouple the indices $i$ and $j$. ii) adding proxy hyperedges $E'$ that is contained in original hyperedges $E$ and help reducing the computation to only $m$ hyperedges across different layers. iii) a kernel trick to decompose the attention coefficients into kernel map of query and keyword matrices. ",0.3137254901960784,0.12698412698412698,0.18079096045197737
1297,SP:79ddf8eda1c2247a1fc928cd7f4ca3d1d95b6adc,This paper uses a meta-learning approach to solve semi-supervised learning. The main idea is to simulate an SGD step on the loss of the meta-validation data and see how the model will perform if the pseudo-labels of unlabelled data are perturbed. Experiments on classification and regression problems show that the proposed method can improve over existing methods. The idea itself is intriguing but the derivation and some design choice are not very well-explained.,"This paper proposes a semi-supervised approach to impute the labels of unlabeled samples such that a network achieves better generalization when it is trained on these labels. The proposed strategy can be easily used to improve the state-of-the-art semi-supervised methods. It mainly uses a validation data set to evaluate the updating rules of the unlabeled samples with pseudo-labels. The proposed method is applicable to both classification and regression problems including image classification and facial landmark detection tasks, which has shown in the experiments. But the following should be improved in the following aspects: ",0.3076923076923077,0.24242424242424243,0.2711864406779661
1298,SP:79dea85fe28b4d5efdfa61c1ae9fd18a6d402faa,"Authors propose a new adversarial training with domain adaptation method to overcome the weak generalisation problem in adversarial training for adversarial examples from different attacks. Authors consider the adversarial training as a domain adaptation task with limited number of target labeled data. They demonstrate that by combining unsupervised and supervised domain adaptation with adversarial training, the generalisation ability on adversarial examples from various attacks can be improved for efficient defence. The experimental results on several benchmark datasets suggest that","This paper addresses the generalization of adversarial training by proposing a new domain adaptation method. In order to have robust defense for adversarial examples, they combine supervised and unsupervised learning for domain adaptation. The idea of domain adaptation is to increase the similarity between clear and adversarial examples. For this purpose, in their objective, they are minimizing the domain shift by aligning the covariance matrix and mean vector of the clean and adversarial examples.",0.24050632911392406,0.25675675675675674,0.24836601307189543
1299,SP:79f20a38e4adada1f0757f8a01cd3d1b840b7b2e,"The paper proposes a spectral-based graph convolution layer, called Simple Spectral Graph Convolution (S$^2$GC), which is based on the Markov Diffusion Kernel (MDK). The authors show that S$^2$GC is capable of aggregating k-hop neighbourhood information without oversmoothing. The paper provides a spectral analysis on S$^2$GC and shows the connections to several previous methods, such as GDC, SGC and APPNP. The authors also show that their proposed S$^2$GC advantages from both spatial and spectral methods. They demonstrate that their S$^2$GC on a series of experiments, such as node clustering and node classification.","One of the most important component of GCN is coming with suitable graph filters and crucial towards designing better GCNs. In this regard, authors proposed Simple Spectral Graph Convolution with Markov diffusion kernel as a graph filter which combines strengths of both spatial and spectral methods. The paper is written-well and easy to follow.  Simplicity and empirically strong results are the main contributions of the paper. However, experiments on graph classification, comparison with other graph filters and theoretical justification can help make the stronger case.",0.18446601941747573,0.22093023255813954,0.20105820105820107
1300,SP:7a0df8dec9ab3e72c6daea7ed2288d1c59b6d2ec,"This paper introduced a novel method called Self-Organized Polynomial-time Coordination Graphs (SOP-CG), aiming to handle the decentralized constraint optimization problem (DCOP). This paper is well organized and the experiments are explicitly presented. Therefore, I think the work of this paper is very interesting and the contributions are sufficient.  ","This paper proposes an extension of deep coordination graph, called Self-Organized Polynomial-time Coordination Graphs (SOP-CG). Instead of pre-specified graph topology used in DCG, their method allows graph topology to be state-dependent, which is achieved by a coordinator agent, and the optimization of this agent is incorporated in a modified temporal difference learning paradigm. Two pre-specified undirected acyclic graph classes are used to ensure polynomial-time graph selection and accurate greedy action selection. The result on sensor network, grid world and MPE shows that such a trade-off between the representational capacity of graph topology and the computational accuracy can improve the performance of MARL and learn meaningful graph topology.",0.43137254901960786,0.19130434782608696,0.26506024096385544
1301,SP:7a0e649fb9f937acd9cbc350d34313a131d2afc0,The authors propose some changes to an existing approach called FullVAE for incremental metric learning for the problem of catastrophic forgetting. Both ConVAER and FullVAE use VAEs for generating feature representation prototypes that could be passed through the intermediate layers of a network. The proposed changes are the position of feeding the generated prototypes from the VAEs to the network and a modified VGG network instead of a simple ConvNet. They evaluate their method on 2 real-world datasets and show improvement compared to the baselines.,"This paper presents the method for incremental similarity learning using feature replay with VAEs. The experimental section investigates the impact of different loss functions on the final performance of the model. Yet, the discussion of the results lacks any insights which could be beneficial for the community. The idea to replay features instead of images is not novel and the proposed method is just a minor modification of the method introduced in the paper [1] (which was published on arXiv 4.10.2021 -- two days before the deadline of ICLR submissions). Due to the lack of novelty in this paper, it should be regarded as a form of ablation study for the paper [1] rather than a separate research paper.  [1] Incremental Class Learning using Variational Autoencoders with Similarity Learning, J. Huo et al. [2] GDumb: A Simple Approach that Questions Our Progress in Continual Learning, A. Prabhu et al. (edited) ",0.2441860465116279,0.1390728476821192,0.1772151898734177
1302,SP:7a1036316b35b30a7f81c2f0829396d5bc4a8533,"The paper propose an end-to-end technique that applies both spatial and temporal attention. The spatial attention is done by training a mask-filter, while the temporal-attention use a soft-attention mechanism.  In addition the authors propose several regularization terms  to directly improve attention. The evaluated datasets are action recognition datasets, such as HMDB51, UCF10, Moments in Time, THUMOS’14. The paper reports SOTA on all three datasets. ","This paper presents a novel spatio-temporal attention mechanism. The spatial attention is decomposed from the temporal attention and acts on each frame independently, while the temporal attention is applied on top of it on the temporal domain. The main contribution of the paper is the introduction of regularisers that improve performance and interpretability of the model.",0.21428571428571427,0.2631578947368421,0.2362204724409449
1303,SP:7a1fd3da1fb6af86b3a25f133d0cfe1fa23b71fa,"This paper revisits the A3C algorithm with TD(0) for the critic update to provide better theoretical analysis of A3C. A3C-TD(0) achieves linear speedup and it also matches our intuition. To show the empirical results, the authors provide convergence results of A3C-TD(0) with Markovian sampling in synthetic environments and speedup of A3C-TD(0) in CartPole and Seaquest.","This paper studied the two time scale A3C in discounted MDP based on recent development in the finite sample analysis of A2C. The sample complexity result in this paper matches previous result in two time-scale A2C in terms of the dependence of \epsilon, and this paper further shows the benefit of ""linear speed up"" brough by the structure of A3C. Given the practical usefulness of A3C, the result established in this paper is meaninful.",0.24193548387096775,0.2,0.21897810218978103
1304,SP:7a333ae10f9732f3e0bed9bf009914e5d1bc265f,"This paper proposes xERTE, a comprehensive set of strategies (i.e. a temporal relational attention mechanism and a human-mimic representation update scheme, temporal neighborhood sampling and pruning, etc.) for link forecasting in temporal knowledge graphs (tKGs). Experiments on real-world tKGs show significant improvements and better explainability on KG forecasting. ","Authors have presented a method to forecast future links on temporal knowledge graphs (KGs). They use attention mechanisms to extract a query-dependent subgraph. According to the authors, this extracted subgraph provides a graphical explanation of the prediction. Authors have performed an ablation study to denote the effect of different components (e.g., updating the representation of nodes, time encoding, sampling strategy) in their method. They have tested the performance of their approach on 3 datasets and have shown that their approach outperforms other baselines in terms of Hits and MRR.",0.17647058823529413,0.0989010989010989,0.1267605633802817
1305,SP:7a40b403f19e24b0004ecc7a0bf1d9ba8ceae1d5,"This paper proposes an implicit regularization for bimanual manipulation that enforces two robot arms to focus on different regions, which prevents both arms from performing on the same object at the same time. The proposed method realizes this idea by computing attention between robots and objects and then constraining dot product between attentions of two arms to not overlap. This effectively prevents the conflict between two arms by encouraging two arms to focus on different objects (sub-tasks), leading to efficient RL training and safe behaviors. The empirical evaluation demonstrates that the proposed method is generalizable to unseen situations thanks to the attention mechanism with the regularization.","This paper proposes an attention-based solution to dual-arm robot manipulation from sparse rewards that relies on a novel idea for intrinsic regularisation. The proposed regularisation term encourages each robotic arm to focus on separate subtasks and objects. The proposed approach aims to reduce the problem of extracting a dominating agent in collaborative settings and to reduce the number of collisions between operating robots in a shared workspace. This work is evaluated in simulation and the obtained results demonstrate the ability of the proposed solution, DAIR, to not only improve both the success rate and sample efficiency of the learning process but also to reduce the number of conflicts between the two operating arms. The approach is interesting and the result seem promising but I have some concerns and additional questions that I detail below.",0.2336448598130841,0.18382352941176472,0.205761316872428
1306,SP:7a420981b1627e310e77f84be095f948c6af3e84,"of the paper: In this paper, the authors make the following new argument: The aggregation processes of current popular GNN models such as GCN, GAT, PPNP, and APPNP can be treated as a graph denoising problem where the objective is to minimize a recovery error (a norm of noisy feature matrix, i.e. ||F-X||) plus a graph-based regularization (smoothness). This new view provides a way to build a GNN model, namely (Ada-)UGNN. Experimental results show the effectiveness of Ada-UGNN on the task of node classification and the task of preventing adversarial attacks on graphs.","1). The novelty and contribution are very limited. In literature, many papers have discussed the connection between different GNNs, typically, including aggregators and Updaters, such as discussed in “Deep Learning on Graphs: A Survey”. The submission only provides a kind of connection between GCN, GAT, PPPN and APPNP in the perspective of denoising. Compared with that, the survey paper actually connects many different GNNs. ",0.1326530612244898,0.203125,0.16049382716049382
1307,SP:7a47dd0e43f8e18913551cdb7207ad3333472e22,"This paper formulates a connection between the Fisher information matrix (FIM) and the spectral radius of the input-output Jacobian in neural networks. This results derive the eigenvalues' bound to theoretically study the convergence of several networks.  Here the upper bound further improves the upper bound of FIM derived in (Karakida et al., 2018). ",This paper analyses the training behavior of wide networks and argues orthogonal initialization helps the training. They suggest projections to the manifold of orthogonal weights during training and provide analysis. Their main result seems to be a bound on the eigen-values of the Fisher information matrix for wide networks (Theorem on pg 6). In their experiments they train Stiefel and Oblique networks as examples of manifold constrained networks and claim they converge faster than unconstrained networks.,0.24074074074074073,0.16883116883116883,0.1984732824427481
1308,SP:7a51f41e35fed4792b3ba09863834a7283e88c40,The authors proposes a novel approach in learning a representation for HRL. They define the notion of sub-optimality of a representation (a mapping from observation space to goal space) for a goal-conditioned HRL that measure the loss in the value as a result of using a representation. Authors then state an intriguing connection between representation learning and bounding the sub-optimality which results in a gradient based algorithm. ,"The paper studies the problem of representation learning in the context of hierarchical reinforcement learning by building on the framework of  HIRO (Nachum et al. (2018)). The papers propose a way to handle sub-optimality in the context of learning representations which basically refers to the overall sub-optimality of the entire hierarchical polity with respect to the task reward. And hence, the only practical different from the HIRO paper is that the proposed method considers representation learning for the goals, while HIRO was directly using the state space.",0.21428571428571427,0.16853932584269662,0.18867924528301885
1309,SP:7a6904083c223c746197e75e6b24d84107b50ab3,"The paper proposes a way to impose trust region restrictions via projections when doing policy optimisation in Reinforcement Learning. The projections have a closed form and enforce a trust region for each state individually. The authors propose three types of projections based on Frobenius, Wasserstein distances and KL divergence. They compare them to the existing methods (PPO, PAPI) and provide some insights about their behaviour.","In trust-region-based policy optimization methods such as TRPO and PPO, it is difficult to tune and lots of approximations are required. The authors try to solve this issue by introducing the closed-form derivation of trust regions for Gaussian policies with three different types of divergence (or distance). Based on the theoretical derivation, the differentiable layer is proposed, where the layer is built upon “old” policy during the trust-region-based policy updates. The difference comes from the use of various divergences (or distances) are given in theoretical and empirical ways. ",0.23076923076923078,0.16129032258064516,0.189873417721519
1310,SP:7a78356d71affb20e118d817bb2b0b5f34d8d075,"This paper studies the calibration of deep learning, which aims to make confidence store accurately describe predictions' correctness probabilities. The authors improve focal loss and propose a calibration-aware focal loss for better calibration.  The proposed approach adaptively adjusts the coefficient of focal loss according to the momentums and current predictions' confidence. The authors conduct experiments on SVNH, CIFAR10/100 datasets to verify the approach's efficacy. ","This paper considers the problem of model calibration. Existing works calibrates the model by post-hoc approaches or objective function tailored for calibration. The authors of the paper propose an adaptive version based on Focal loss, which regularizes the overconfidence of neural networks. They observe that although focal loss improves the calibration, it leaves out the under-confident samples. To mitigate the issue, they propose adjusting the hyper-parameter $\gamma$ in focal loss according to the model's under/over-confidence. Experiments on vision and NLP classification tasks showcase the effectiveness of the adaptive version.",0.3283582089552239,0.23157894736842105,0.2716049382716049
1311,SP:7ab75453e99ff53d62b1fdeeb02602cc8ecf94a6,"The paper tackles the identifiability problem in generative modeling, i.e., recovering the true latent representations from which the observed data originates. The paper argues that identifiable variational autoencoder (iVAE) suffers from intractability issue which leads to suboptimal solutions. The paper instead proposes an identifiable normalizing flows (iFlow) method as an alternative. The proposed iFlow outperforms iVAE in experiments using synthetic data. The paper is very well motivated and well supports its claim.","This paper is about learning an identifiable generative model, iFlow, that builds upon a recent result on nonlinear ICA. The key idea is providing side information to identify the latent representation, i.e., essentially a prior conditioned on extra information such as labels and restricting the mapping to flows for being able to compute the likelihood. As the loglikelihood of a flow model is readily available, a direct approach can be used for learning that optimizes both the prior and the observation model.	",0.1506849315068493,0.13253012048192772,0.141025641025641
1312,SP:7b33fcce5b967ebbee157b11803e21523ee9fda0,"This paper studies nonparametric planning in RL, building on prior work in two ways. First, the proposed method creates graph vertices corresponding to *clusters* of observations, rather than single observations. The motivation for this decision is that it leads to sparser graphs, making planning easier. The second idea is to use the graph for exploration by sampling goal states that are near the ""fringe"" of the graph. Experimental results suggest that the first idea increases performance (success rate and wall-clock time) on 2D navigation tasks. Additional experiments show that the second idea improves exploration.","This paper proposes a new method for learning graph representations of RL problems. The proposed method, named TOMA, creates a set of *landmarks*, each of which is a representatives state associated with a cluster of states in the original problem.  The clustering is induced via a locality sensitive embedding function. With this embedding, a graph of landmarks is created by sampling state trajectories, and then mapping each state to existing vertices (if a nearby vertex already exist), or creating a new vertex otherwise. To add robustness, an ensemble of embedding functions is used rather than a single estimator. Once the graph is build, the shortest-path to goals can be computed using a search algorithm (e.g., Dijkstra's algorithm). The proposed approach is evaluated on a set of benchmarks, and compares favorably in this problem with recent state-of-the-art graph learning algorithms for RL. ",0.23157894736842105,0.14965986394557823,0.1818181818181818
1313,SP:7b58625be5e935efe59d293b377ddf7abdd2c845,This paper presents a new image representation model based on wavelets and non-linear rectifiers that allows to synthesize complex geometric textures with a better visual quality than previous wavelet-based models.  The main interest of the paper is the usage of the mathematical results from Mallat et al 2020 and Zhang and Mallat 2021 on wavelet phase harmonics to image texture synthesis.   They also show that the PS model (Portilla & Simoncelli 2000) is a particular case of the wavelet phase harmonics-based (WPH) model. Both methods underline the importance of statistical dependencies between wavelet coefficients across scales. The specific choice of the parameters available for WPH is important to balance between reproducing good structural information and memorizing patterns from the observation.  ,"This work proposed a texture synthesis framework using the rectified wavelet coefficients. The paper claims that the proposed method cand achieve similar quality with the VGG feature based method (Gatys et al. 22015) and random filter based method (RF, Ustyuzhaninov et al 2017) and gets better quality than PS (Portilla & Simoncelli 2000, while requiring less number of statistics than RF. ",0.13114754098360656,0.26666666666666666,0.17582417582417584
1314,SP:7b69dc66e28d4bfe787c40ee087749f27ffe6b98,This work takes a step towards understanding the effect of automated selection of regularisation techniques and analyses the results across 42 structured datasets. It defines a search space over 13 regularisation techniques and employs one flavour of Bayesian Optimisation + Hyperband approach to find an optimal combination of regularisers. It concludes by substantiating three claims with corresponding experiments. ,"This paper provides an empirical study of combining different regularizers. Fourteen regularizers including batch norm, weight decay, etc. are considered. The authors use BOHB (Falkner et al. 2018) to optimize for whether each regularizer is active, and additional regularizer-specific hyperparameters. Using 40 tabular datasets, they show mixtures nearly always outperform tuning a single regularizer, and that the benefits of regularization improves for smaller datasets.",0.12280701754385964,0.1076923076923077,0.11475409836065573
1315,SP:7b714eb05f8e86b18444c8f39d89e566313988dc,"The paper proposes to distill the predictions of an ensemble with a multi-headed network, with as many heads as members in the original ensemble. Distillation proceeds by minimizing the KL divergence between the predictions of each ensemble member with the corresponding head in the student network. Experiments illustrate that the multi-headed architecture approximates the ensemble marginally better than approaches that use a network with a single head.","This work introduces a new method for ensemble distillation. The problem of making better ensemble distillation methods seems relevant as ensembles are still one of the best ways to estimate uncertainty in practice (although see concerns below). The method itself is a simple extension of earlier “prior networks”: the original method suggested to fit a single network to mimick a distribution produce by given ensemble, and here authors suggest to use multi-head (one head per individual ensemble member) in order to better capture the ensemble diversity. ",0.2028985507246377,0.16091954022988506,0.17948717948717946
1316,SP:7ba7db3bba0bb539fe00165024a483e9f59d5d35,"This paper attempts to improve the classic vision transformers, or specifically the DeiT model by introducing the Masked Attention Head. Instead of focusing on aggregating global information in the original self-attention heads, this paper introduce local information via the proposed Masked Attention Head into self-attention. Experiments on ImageNet show that the proposed approach does matter for lifting the model performance of the original DeiT model.","This paper proposes to bring locality into the attention module of vision transformers. This locality mechanism is brought by the introduced attention masks. Basically, the attention masks are binary and is likely to restrict the attention to the local field of a token. The local attention mask results in a block matrix before the application of Softmax function. Tokens with zero mask values are given a constant attention value of 1. Thus, those tokens are still involved in the computation. It is claimed that the binary masks is able to keep the global connection when necessary.",0.26865671641791045,0.1875,0.22085889570552147
1317,SP:7bcb6c07ef877e0648572f562977bb80f964b9b6,"The paper considers the important problem of lack of generalization of GNNs to graphs whose sizes are much larger than the graphs on which they were trained on. The authors propose a theoretical explanation by arguing that this lack of generalization is due to a mismatch in the “d-patterns” (essentially the pattern of neighborhood around nodes) between the training and test graphs. To improve generalization performance, they borrow ideas from domain adaptation and propose a pattern-tree based pretext learning task which improves classification accuracy compared to baseline pretext tasks in a range of datasets and tasks. ","This paper investigates the issue of generalizability of GNNs when trained on small graphs and tested on larger graphs, a common setting in graph learning. The paper argues that the ability of constant-depth GNNs to generalize is not dependent on the size difference, but on the difference in distributions of nodes' neighborhood features, which authors call ""d-patterns."" The paper shows theoretically that a GNN can be trained to achieve zero loss on small graphs, yet fail to generalize to larger graphs and the loss on these graphs will be dependent on the difference in d-pattern distributions.",0.21428571428571427,0.21212121212121213,0.2131979695431472
1318,SP:7bcf05b89cb5776ae03592d5619d859e5c8571bc,"The manuscript studies the problem of ensemble selection (pruning) with the ensemble consists of deep neural network models. The authors compare different diversity metrics, which they named collectively as Q-metric, visualize the accuracies of different ensembles on CIFAR-10 dataset where the ensembles are stratified by their sizes. Based on their observation,  the authors further propose HQ-metric, HQ(\alpha) and HQ(\alpha +K) to improve the diversity score from Q-metrics. The authors evaluate their strategies on CIFAR-10 and  on all of the Q-metircs  and show that those Q-metric, when incorporating their proposed strategies, in general, is capable of selecting ensembles of higher accuracy. ","The paper succeeds in developing diversity metrics that correlate better with ensemble accuracy than the original diversity metrics. However, this makes one wonder why one cannot just use ensemble accuracy directly. One can also use a combining scheme along the lines of (Freund, 1995) where it adds models that focus on the examples that will increase accuracy and allowing errors on examples where most of the models so far have either classified the examples correctly already or incorrectly (where there is no hope of recovery and so effort is not worthwhile). Additionally, the appendix has the algorithms and other substantive content that is central to the paper, which is not supposed to be the case.",0.1743119266055046,0.16521739130434782,0.16964285714285715
1319,SP:7be27202a84037a62bdc651fc24a8450325e0fd6,"This paper proposed an adaptive regularization method to handle heteroskedastic and imbalanced datasets, which are closer to real-world large-scale settings. The framework applies a Lipschitz regularizer with varying regularization strength depending on the particular data point. The authors first theoretically study the optimal regularization strength on a one-dimensional binary classification task. By applying some simplification, the result can be extended to high-dimensional multi-class tasks and finally HAR algorithm is proposed. Experiments show that HAR achieves significant improvements over other noise-robust deep learning methods on simulated vision and language datasets with controllable degrees of data noise and data imbalance, as well as a real-world heteroskedastic and imbalanced dataset. The experiments show great improvement. However, since the derivations involve many approximations, the reliability needs to be confirmed by more experiments.","The authors propose a novel regularization approach aimed at addressing issues of class imbalance and heteroskedasticity. This adaptive approach uses a Lipschitz regularizer with varying strength in different parts of the input space, regularizing harder in cases of rare and noisy examples. The authors derive the optional regularization strength in the one-dimensional setting, to set ground for the proposed approach and its application in higher-dimensional settings. The approach is evaluated on multiple image datasets, and a textual dataset - and compared to a number of baselines, including those involving noise-cleaning, reweigthing-based methods, meta learning, robust loss functions, as well as tuned uniform regularization. The improvements seem quite strong, and clearly demonstrate the utility of the proposed approach. The paper is well structured, clearly written - and was a pleasure to read.",0.22962962962962963,0.23308270676691728,0.23134328358208955
1320,SP:7c36047790a8d3e229748fea4d9ff7572a97fd0a,"This paper studies initialization techniques for deep ReLU networks from a theoretical standpoint and derives finite layer width concentration bounds to show that with the He initialization scheme, deep ReLU networks preserve the norm of the input sample during a forward pass and the norm of the gradient with respect to the output during a backward pass. The concentration bounds also suggest lower bounds on the width of the ReLU layers. The authors verify their theory with experiments on synthetic data.","This work considers random parameter initialization in neural networks (In particular the initialization presented in He et al.) and develops non-asymptotic bounds for the norms and gradients of neural networks during initialization. The authors show that the norms of the outputs and gradients (for gradients, under a different assumption on the dimension of the matrix) remain constant through the different layers. The results presented differ from previous work in that they give nice concentration bounds for such output and gradient norms. In addition the authors prove results in the case of infinite samples under the assumption that they arise from a finite dimensional space.",0.25925925925925924,0.2,0.22580645161290322
1321,SP:7c442073ca3d80b472665b8bd9ec3534ef010950,"This paper introduces a hierarchical extension to existing work in vision-based model predictive control. Here, a hierarchical model is optimised to find sub-goals that minimise the planning cost (bottleneck states), so as to allow for improved planning to goal states expressed in higher dimensional state spaces. As expected, results show that this hierarchy improves tasks execution success rates. ","This paper proposes a method, hierarchical visual foresight (HVF) that learns to break down the long horizon tasks into short horizon segments. It first generates the subgoals conditioned on the main goal. These subgoals are optimized to have meaningful states and used for planning. The experiments on Maze navigation, simulated desk manipulation, and real robot manipulation show significant performance gain over the planning method without subgoals and model-free RL. ",0.16666666666666666,0.14285714285714285,0.15384615384615383
1322,SP:7c6ed0cd5a38c1e0e613621bb987d2874ef334d5,"This paper makes several contributions:  	 1. In the episodic tabular setting, with adversarial rewards, unknown MDP dynamics and bandit feedback, it provides the first algorithm that achieves O(\sqrt T) regret bound using the regret decomposition approach, which is more computationally cheap than the approach presented in Jin et al. Typically result obtained by using this approach scales with the inverse of the visitation probability. However, here the results don't have this drawback.   	 2. For the linear case, the paper considers the setting with an infinite set of states and the algorithm has access to the simulator of the dynamics of MDP. Then it provides the algorithm that obtains T^2/3 regret without assuming that the smallest eigenvalue of the covariance matrix \Sigma_h is at least \lambda_min and T^1/2 taken this assumption. The latter improves the previous result in the considered setting, which was T^2/3 regret, assuming that the smallest eigenvalue of \Sigma_h is bounded away from zero. The only drawback is that the algorithm is more computationally expensive since it requires O(T^H) number of calls to the simulator. 	 3. The third result presented in the paper is in the same setting as above but without access to the simulator of MDP, which is a very challenging setting. The obtained regret bound is T^6/7, and it makes use of the assumption on the smallest eigenvalue of \Sigma_h.  4. All three results from above make use of dilated bonuses, which is the main contribution of this paper.  The use of the dilated bonuses that decrease the contribution to the regret, induced by the term appearing from the mismatch of q^*(x) and q(x), shows up in the analysis. To the best of my knowledge, this idea has not been considered before, and I think this idea is beneficial for future studies.  ","The paper studies the regret of policy optimization for adversarial MDPs with bandit feedback. It develops a general solution that adds dilated bonuses to the policy update for exploration and applies the algorithm to the tabular, linear-Q, and linear MDP settings.   It shows that such a solution improves and generalizes the state-of-the-art. ",0.06984126984126984,0.39285714285714285,0.11859838274932614
1323,SP:7ca5ba13170227684a45a4fef71675925b752f87,"Review: This paper studies distributed training of neural networks. The major obstacles in distributed training are communication costs and communication delays. In the literature there exists different methods which attempt to overcome these two issues but, as far as the authors claim, none of the existing algorithms succeeds in dealing with both these aspects at the same time. The authors propose a novel distributed method OLCO_3 which is designed to address both communication costs and communication delays. In particular, the authors propose two variants of the method: OLCO_3 TC which comprises pipelining and compensation, and OLCO_3 VQ which comprises pipelining with communication-dependent compressor. Both the versions of OLCO_3 are analyzed from a theoretical perspective: under some assumptions the authors conduct a theoretical analysis of the convergence of the proposed schemes. Finally, the method in its two variants is benchmarked and compared with state-of-the-art distributed algorithms. ","This paper proposes OLCO3, a new delay-tolerant SGD communication scheme and training framework for distributed deep neural network training. OLCO3 combines the existing ideas of Stale synchronous Parallel, batching the communication of doing multiple iterations, and gradient compression to achieve more communication efficiency. OLCO3 also uses staleness compensation and compression compensation techniques to improve model convergence under high stateness. Theoretical analysis shows that OLCO3 converges under SGD and momentum SGD. The evaluation was done with ResNet models on Cifar-10 and ImageNet datasets. Under a high staleness delay tolerance 56, OLCO3 achieves better convergence and has lower communication traffic than the baseline methods.",0.13071895424836602,0.19230769230769232,0.15564202334630353
1324,SP:7cb13cb3ce5fb5eed5174deb80d6ffe00aa3605b,"The paper demonstrates a method for constructing adversarial examples by modifications or perturbations to physical parameters in the scene itself---specifically scene lighting and object geometry---such that images taken of that scene are able to fool a classifier. It achieves this through a novel differentiable rendering engine, which allows the proposed method to back-propagate gradients to the desired physical parameters. Also interesting in the paper is the use of spherical harmonics, which restrict the algorithm to plausible lighting. The method is computationally efficient and appears to work well, generating plausible scenes that fool a classifier when imaged from different viewpoints.","This work presents a method to generate adversary examples capable of fooling a neural network classifier. Szegedy et al. (2013) were the first to expose the weakness of neural networks against adversarial attacks, by adding a human-imperceptible noise to images to induce misclassification. Since then, several works tackled this problem by modifying the image directly in the pixel space: the norm-balls convention. The authors argue that this leads to non-realistic attacks and that a network would not benefit from training with these adversarial images when performing in the real world. Their solution and contributions are parametric norm-balls: unlike state-of-the-art methods, they perform perturbations in the image formation space, namely the geometry and the lighting, which are indeed perturbations that could happen in real life. For that, they defined a differentiable renderer by making some assumptions to simplify its expression compared to solving a light transport equation. The main simplifications are the direct illumination to gain computation efficiency and the distant illumination and diffuse material assumptions to represent lighting in terms of spherical harmonics as in Ramamoorthi et al. (2001), which require only 9 parameters to approximate lighting. This allows them to analytically derivate their loss function according to the geometry and lighting and therefore generate their adversary examples via gradient descent. They show that their adversary images generalize to other classifiers than the one used (ResNet). They then show that injecting these images into the training set increase the robustness of WideResNet against real attacks. These real attack images were taken by the authors in a laboratory with varying illumination.",0.29411764705882354,0.11235955056179775,0.16260162601626016
1325,SP:7cd001a35175d8565c046093dcf070ba7fa988d6,"  This paper proposes using the features learned through Contrastive Predictive Coding as a means for reward shaping. Specifically, they propose to cluster the embedding using the clusters to provide feedback to the agent by applying a positive reward when the agent enters the goal cluster. In more complex domains they add another negative distance term of the embedding of the current state and goal state. Finally, they provide empirical evidence of their algorithm working in toy domains (such as four rooms and U-maze) as well as a set of control environments including AntMaze and Pendulum.","The paper proposes a reward shaping method which aim to tackle sparse reward tasks. The paper first trains a representation using contrastive predictive coding and then uses the learned representation to provide feedback to the control agent. The main difference from the previous work (i.e. CPC) is that the paper uses the learned representation for reward shaping, not for learning on top of these representation. This is an interesting research topic. ",0.20833333333333334,0.2777777777777778,0.2380952380952381
1326,SP:7ce03d70aa54266baea251240b597fb9e967f084,"This paper proposed a classification layer by randomizing the class representation vectors. This paper first analyses the class vector distributions between different training strategies, and then proposed the randomized class vector to improve the representation learning performance. The proposed model is further extended and analyzed for the fixed cosine-similarity maximization setting. The experiments demonstrate the effectiveness of the proposed method compared with the basic/vanilla baselines.","This paper introduces a new approach to learn a multi-class image classification model by fixing the weights of the classification layer. The authors propose to draw the class vectors randomly and set them as fixed during training instead of training them. They analyze this approach when a model is trained with a categorical cross-entropy and or softmax-cosine loss. The proposed approach is tested on 4 datasets: STL, CIFAR-10, CIFAR-100, TinyImagenet",0.23880597014925373,0.21333333333333335,0.22535211267605634
1327,SP:7cee15b5f46a918a6448434840696f3a0d3739ee,"This paper proposes regularizing learnable parameters of NNs to maintain the dynamical isometry during pruning and improve their accuracy. In the experimental analyses, the proposed OPP outperforms baseline methods on benchmark datasets.  The paper is well written in general, and the proposed methods are intuitive. In the experimental analyses, the proposed methods outperform baseline on various benchmark datasets. ","Dynamic isometry is shown to be a useful property that enable effective gradient propagation through the forward/backward. However, pruning will largely damage such a structure. This paper studies how to maintain the “dynamic isometry” property during pruning. Specifically, after getting an initial assessment of filter importance, the algorithm will maintain the partially kernel orthogonality of the important filters. They also propose to regularize the BN parameters to future boost the performance.",0.22413793103448276,0.18055555555555555,0.19999999999999998
1328,SP:7cef694906438e793f2303852173109b603e0dd5,"This paper proposes XMixup, a strategy for improving transfer learning in neural networks. Specifically, XMixup consists of mixup applied between target samples and source samples from the class pre-determined to be closest to target sample’s class. Experiments conducting transfer learning from pre-trained ImageNet to 6 smaller image classification datasets demonstrate XMixup to outperform the baseline approaches.",This paper proposes a simple variant for the mixup training mechanism for transfer learning problems: cross-domain mixup (XMixup). The key idea is to mix up the training samples from both domains where the samples are generated by nearest-center assignment in each class. Experiments on several datasets have shown its effectiveness in transfer learning compared to some SOTA methods.,0.2711864406779661,0.26666666666666666,0.2689075630252101
1329,SP:7d135321239a07037780cacf21aa5a8942973b63,"The authors are interested in the setting of predicting discrete outcomes within time intervals of interest (ex. 5-year survival, 10-year survival) from time-to-event data, i.e. the setting in which some observations may be right-censored. The conventional approach relies on inverse probability of censorship weighting (IPCW), which first estimates the distribution over time-to-censorship $p(c|x)$ (for example, via a Kaplan-Meier estimate), then re-weights the data to estimate the distribution over time-to-event p(t|x)$.   The authors instead propose *Inverse-Weighted Survival Games*, in which they learn *both* the time-to-censorship and the time-to-event distributions in a non-adversarial game, using each to re-weight the other's loss. On the theoretical side, they show that when the loss function is proper, the resulting game has the true distributions as a stationary point. Moreover, when the loss function is the Brier Score, this is the only stationary point. On the experimental side, they run experiments on simulations and public datasets (Survival-MNIST, METABRIC, SUPPORT) and show that IPCW games improve upon NLL-trained models in terms of concordance, KM-weighted log-likelihood, and KM-weighted Brier Score in the data-limited regime.","The paper introduces a non-adversarial approach for simultaneously learning events and censoring cumulative distribution functions (CDF) at prespecified discrete-time points by optimizing inverse weighted Brier score (BS) and Bernoulli log-likelihood (BLL). Further, the theoretical analysis illustrates that the proposed approach achieves data event and censoring distributions at stationary points. Experimental results on (semi-)synthetic and real-world datasets demonstrate that the proposed achieves better concordance, Brier score, and Bernoulli log-likelihood than an approach that optimizes the standard negative log-likelihood (NLL) given small sample sizes.",0.11165048543689321,0.25842696629213485,0.15593220338983052
1330,SP:7d26e683800476ec3617f4bdb759f690b3b7daed,"In this paper, the authors studied the soft labels for knowledge distillation from a bias-variance tradeoff perspective. Specifically, the authors first provide a mathematically descriptions of the bias-variance decomposition in knowledge distillation. Then, based on the theoretically analysis and experiments, the authors proposed an novel weighted soft labels to help the network adaptively handle the sample-wise bias-variance tradeoff.","The paper shows a new perspective of tackling the knowledge distillation problem. The author(s) have decomposed the expected student's training error into the bias, variance, and irreducible noise parts. This decomposition is further rewritten as two parts: one for bias reduction and another for variance reduction. The motivation is clearly explained and the experimental results show that this new approach can improve the model training performance of the student on both CIFAR100 and Imagenet. ",0.22580645161290322,0.18421052631578946,0.20289855072463767
1331,SP:7d2e5993fea3dc4fc8090cfe569d8206a16f7bfb,"This paper proposes to use similarity metric to generate pseudo alignments between source/target program pairs. Generated pairs are utilized to train program translation model. The paper described a simple greedy method to align both codes, and experimented 5 types of similarity metric as its inner measure. According to the experiments, the word mover's distance works notably well for this purpose, but other metric can also improve the translation accuracy significantly against random selection. The other experiment investigating a performance curve by changing noise ratio in the ground-truth parallel corpus hypothesized that certain amount of alignment errors can be acceptable since the actual performance can be maintained. The paper also challenged to construct translation systems between arbitrary pairs in 10 programming languages using the proposed framework and observed that the trained system works with certain accuracies.","This paper mines noisy parallel datasets of code by calculating the similarity between two non-parallel sets of documents. The authors first show that the document similarity methods can indeed align parallel documents and find that the word movers distance (WMD) is the most effective one. Then, the authors show the high tolerance of models trained with noisy datasets. Based on the two findings, the authors finally apply the proposed method to a large, non-parallel code dataset, and observe a performance boost of using a noisy parallel dataset compared to randomly paired datasets.",0.13768115942028986,0.20212765957446807,0.16379310344827588
1332,SP:7d3b2759cf0b3dfc61a0de94781dc460b29b5b84,"The work basically introduced a new way of looking at interpretability; instead of focusing on the source of activations in the network for a given input image, focus on the source of stability (non-active) neurons (in a ReLU network). The work starts by proving (although it is trivial) that in a ReLU (more generally any piece-wise linear) network, for a given input image, there is a locally linear relationship between a given neuron's activation and the image: v= w^T x + b. As the authors correctly mention, focusing on 'w' as the sensitivity analysis is basically the vanilla gradient method. The contribution, however, is focusing on the projection of bias and the introduced notion of 'centre'. With this provided notion, one can focus on the deactivated neurons in the network and how each input pixel is responsible for it. In other words, unlike previous work that focuses on the activation map, the authors correctly refer to the deactivated neurons as another source of the network's prediction.","This manuscript introduces a novel method to explain activities of ReLU-based deep networks by constructing a linear subnetwork which only contains neurons activated by the input. The status of each neuron can be obtained given any input sample. Moreover, the author applies the notion of “neuron’s center”, which is a neutral data point that is similar to actual input x, but with differences in particular objects to cause f(x) be positive. The activity of each neuron can be decomposed into the attribution of each input pixel, and this decomposition can also be used to measure the contribution of each pixel to the network stability. Overall, the proposed methodology is intuitive and distinctive to the state-of-the-art interpretability methods.",0.1588235294117647,0.21951219512195122,0.18430034129692832
1333,SP:7d5ca500bb1f17d91c8261ad94af85335278686a,"This paper presents an estimator that predict higher-order structure in time-varying graphs. The authors present an kernel-based estimator, prove that it is consistent when the indicator variable for whether a particular (d+1)-dimensional simplex is Bernoulli distributed with a function g. The authors prove that their estimator is asymptotically normal.  The authors also present some experiments on real-world data","This paper provide a method for high-order structure prediction problem. Specifically, the paper first defines a high-order structure on graphs named graph simplicial complex (GSC). Then the paper introduces a feature generation method used for the high-order structures. The features are also used in the proposed method for high-order structure prediction. The proposed method is based on a nonparametric kernel which carries the feature similarities of high-order structures. With this kernel the method uses a Bernoulli distribution for the prediction of the existence of the high-order structure in unseen times. ",0.203125,0.13541666666666666,0.1625
1334,SP:7d6388235c53030aa92499c15b4543f82b9ff27c,"The authors propose a scalable second order method for optimization using a quadratic loss. The method is inspired by the Neural Tangent kernel approach, which also allows them to provide global convergence rates for GD and batch SGD. The algorithm has a computational complexity that is linear in the number of parameters and requires to solve a system of the size of the minibatch.  They also show experimentally the advantage of using their proposed methods over SGD. ","Authors propose minimizing neural network using kernel ridge regression. (Formula 9 and Algorithm 1). Main difference of this method is compared to Gauss-Newton, is that it uses JJ' as curvature, which has dimensions b-by-by (batch size b), instead of J'J as curvature, which has dimensions m-by-m (number of parameters m).",0.14285714285714285,0.19642857142857142,0.16541353383458643
1335,SP:7d69ad75322ea8d15440567c810394321a4f1f34,"This paper tries to generate synthetic unobserved spectral imagery from a set of existing spectral channels. This is an image-to-image translation task, for which VAEs and GANs are effective to address. For this specific satellite band-to-band translation task, authors adopt the VAE-GAN framework (adding a skip connection between the input and generator), with a new added spectral reconstruction loss.  Experiments show the effectiveness of the proposed method.",This paper proposes a new method for image-to-image translation on multi-spectral imagery. The proposed method uses variational auto-encoders and generative adversarial networks to generate synthetic bands in satellite imagery.  Novelty of the proposed method is that the authors introduce a shared spectral reconstruction loss and skip connection to generate synthetic spectral bands. This allows to generate synthetic bands with higher accuracy that the original image-to image translation method.,0.25,0.2465753424657534,0.2482758620689655
1336,SP:7da0015ccf5079721e41222defec7247a46647d2,"This paper describes a multi-task video classification and captioning model applied to a fine-grained object relationship video dataset, for a range of different classification and captioning tasks at different levels of granularity. This paper also creates a new video action dataset around kitchen objects and actions.  Finally, the paper includes an empirical study on both the multi-task performance and transfer learning performance between the two datasets considered.",Paper Summary - This paper presents an approach for fine-grained action recognition and video captioning. The authors train a model using both classification and captioning tasks and show that this improves performance on transfer learning tasks. The method is evaluated on the Something-Something v2 dataset as well as a new dataset (proposed in this paper). The authors also evaluate the benefit of using fine-grained action categories vs. coarse-grained action categories on transfer learning.,0.2571428571428571,0.23684210526315788,0.2465753424657534
1337,SP:7dace4ef94b6bd673112dda394ef5225f62df0b4,"This paper proposes a novel attack approach with a purpose of disrupting the automatic speech recognition system. The proposed method, called Neural Voice Camouflage, works in real time by forecasting attacks ahead of time when they are added to speech streams. The authors conducted experiments with the LibriSpeech dataset, and showed that the proposed model outperforms the conventional methods with or without defense mechanisms on the task of speech recognition (performance measured by WER/CER).","This paper proposes a Neural Voice Camouflage (NVC) method that has three important characteristics, which are essential for an NVC method to be used in practical scenarios: general, real-time, and robust. Since the proposed method trains a model to learn predictive attacks without any constraints about input and output, it can be applied to any vocabulary in a real-time scenario, and it is also difficult to defend the attack. On the contrary, the previous gradient-based adversarial attacks take a lot of time to compute the attack, so it is difficult to be used in a real-time scenario. Other than that, other previous methods are trained to attack only a few target words or utilize a pre-defined frequency region that can be easily filtered out.  In experiments, this paper shows that the proposed method is really effective by showing that the WER&CER of an ASR model significantly increases with the method compared to other NVC methods. Furthermore, this paper conducts various analyses on the behavioral characteristics of the method that can give many insights for future work. Moreover, various experiments, which are conducted with considerations about the situation where the method is used in the real world, are also shown in this paper.",0.3333333333333333,0.1201923076923077,0.17667844522968196
1338,SP:7db5acb622d42134949e6aa08fbcf0c4d40bf83c,"The authors introduce and formalize the concept of Invariant Learning Consistency (ICL), which is motivated by the idea that ""good explanations are hard to vary"" in the context of deep learning. Instead of using the arithmetic mean to pool gradients (logical OR), the authors propose to use the element-wise geometric mean of gradients with a logical AND masking. Experimental results on both synthetic and real-world data sets are reported under the setup of supervised learning and reinforcement learning. ","this work posits that invariant mechanisms exist in a dataset. a machine learning algorithm that is trained using gradient descent usually averages gradients across examples. the thesis is that by averaging gradients, information is lost. the method posits that in a gradient descent algorithm, instead of an arithmetic average, a geometric (or karcher) mean can be used to preserve information about invariant mechanisms - while ignoring confounders. there are difficulties in a straightforward application of the geometric mean, so a simple heuristic algorithm is developed, involving masking gradients depending on whether the sign of the gradient agrees across a batch of examples (or, whether some agreement threshold is reached). this algorithm is tested on a synthetic dataset, a semi-synthetic task on CIFAR-10, and coinbase, an RL algorithm. ",0.2625,0.1640625,0.20192307692307693
1339,SP:7dc520ce87edf76ac948de085da9855d2f32c7ab,"This paper proposes an algorithm allowing ""cooperation"" between agents in multi-agent reinforcement learning, modeling agents as nodes in a graph. Each agent having only a partial view of the environment, the proposed algorithm uses multi-head attention as a (graph) convolution kernel but otherwise remains similar to the DQN algorithm. Performance is evaluated on three tasks using the MAgent framework.","This paper introduces Graph Convolutional Reinforcement Learning (referred to as DGN). DGN is a Deep Q-Learning (DQN) agent structured as a graph neural network / graph convolutional network with multi-head dot product attention as a message aggregation function. Graphs are obtained based on spatial neighborhoods (e.g. k nearest neighbors) or based on network structure in the domain. DGN considers a multi-agent setting with a centralized learning algorithm and shared parameters across all (controlled) agents, but individually allocated reward. Further, the paper considers environments where other non-learning agents are present which follow a pre-trained, stationary policy. In addition to the attention-based multi-agent architecture, the paper introduces a regularizer on attention weights similar to the use of target networks in DQN, to stabilize training. Results demonstrate that the proposed model architecture outperforms related earlier agent architectures that do not use attention or use a fully-connected graph.",0.3114754098360656,0.125,0.1784037558685446
1340,SP:7dd326afe8e4e148955d98fb30d561b9e6be5ba9,"In this paper, the authors focus on the problem of meta-reinforcement learning (meta-RL). Specifically, the authors consider the setting of meta-RL for goal reaching tasks where each task corresponds to an unknown goal. Existing meta-RL algorithms directly train for a policy that output low level actions, which might be inefficient in this goal-reaching setting. In this paper, the authors combine the hierarchical RL framework of HAC[1] with the probabilistic task context inference method of PEARL[2], and propose the meta-goal generation for hierarchical RL (MGHRL) algorithm. In this algorithm, a two layer hierarchical policy is used where the high level policy generate goals for the low level goal-reaching policy to reach. In order to adapt to an unknown goal, the high level policy is conditioned on the output of a task inference module to generate goals for the unknown ground truth goal. The goal-reaching policy would then use the generated goal to interact with the environment.","This paper studies the problem of leveraging past experience to quickly solve new control tasks. The starting point (and perhaps the main contribution) is the observation that some tasks have similar high-level goals, while differing in how those goals are achieved. To that end, the paper introduces an meta-RL algorithm that, given a new task, attempts to solve it by adapting a high-level, goal-setting module, and learn a new, low-level policy to reach each commanded goal. The proposed method might be viewed as a combination of PEARL [Rakelly 19] and HAC [Levy 19]. The proposed method is compared against state-of-the-art hierarchical RL and meta-RL methods on four robotic manipulation tasks. The proposed method outperforms the baselines on each task.",0.18181818181818182,0.234375,0.20477815699658705
1341,SP:7de6af53023cffa071bb69c37c0c3a021ec8a99e,"The authors propose the generative model that produces 3d conformations from a molecular graph based on predictions of local structures. First, for each anchor atom, the model predicts relative 1-hop positions of neighboring atoms, then predicts torsion angles. Finally, assemble the molecule in the deterministic way given predicted components. The authors comprehensively evaluate the model on the recently proposed dataset GEOM and compare it with state-of-the-art neural-based conformer generators and special software.  The paper's main contributions are: the authors propose a principal novel scheme for conformation generation that avoids expensive molecular geometry optimization used in current state-of-the-art neural conformer generators, still being translation, rotation, and reflection equivariant. The proposed model outperforms other baselines in both speeds of conformation generation and diversity of generated objects. ","This paper introduces GeoMol, an end-to-end learning method for molecular conformation generation.  It is based on the construction and alignment of elements of local atomic structure, is efficient in its parameterization of geometric degrees of freedom, and is SE(3) invariant.  It achieves competitive performance on the GEOM-DRUGS and GEOM-QM9 tasks.",0.08270676691729323,0.2,0.11702127659574467
1342,SP:7ded50d27f7af0a20575038f245fec224285d066,"The scheme proposed breaks down the information in a block of an image into orthogonal basis functions (DCT is used) to make a progressively better reconstruction of the original image block with the addition of more basis functions used (like an nth order Taylor expansion).  The increasing spatial frequency components are known to be perceptually less sensitive (they need to include this) in images, so the low freq components can be presented first.  Each freq component is encoded into spikes sequentially, thereby staging the more perceptually important information first, with less important info coming later.  This reorders the presentation of information to allow a tradeoff of image quality with time/latency.","This paper proposes an encoding method based on the Discrete Cosine Transform (DCT) for Spiking Neural Network (SNN). The key idea is to decompose an image into different frequency components and feed them to the SNN sequentially. Compared to the Poisson coding method used in most SNN studies, the proposed encoding method significantly decreases the latency that the SNN needs for image classification while having minimal accuracy decease. ",0.12612612612612611,0.20588235294117646,0.15642458100558657
1343,SP:7def75e4937f11e2c20c7694f54d512a08eb64d6,"This paper studies the latency reduction of Vision Transformer model. The proposed pruning method w.r.t importance score is trained with the full pre-trained model using knowledge distillation, with latency aware regularization. In addition, the author designed a new architecture NViT with a parameter redistribution. The experiments evaluated the proposed methods with respect to the accuracy, FLOP reduction, and parameter reduction.","This paper applies latency-aware global structural pruning to vision transformers (ViTs), which results in redistribution of the model parameters and better a speed-accuracy tradeoff. Compared to Deit-B, the pruned vision transformer model (NVP) is 1.85x faster with almost no performance loss. Based on the insights discovered in the pruning process, the paper also presents the novel vision transformer (NViT) architectures. NViT outperforms Deit on ImageNet, CIFAR, and iNat benchmarks with similar running times.",0.23809523809523808,0.19480519480519481,0.21428571428571427
1344,SP:7df555a331258498231c1bcafa3705165ed0aa62,"This paper considers the task of multilingual fact linking, where the goal is to link abstract representations of facts to their language-specific representations in multiple languages. The challenge is that although ""worldly facts"" themselves are language-agnostic, annotations of how they appear in text form (e.g., described in a sentence or named) are often restricted to only a few languages. The proposed task of multilingual fact linking seeks to link KG facts with their mentions in multilingual text, even when the label of the fact doesn't match the language of the text (e.g., matching <NYC, country, USA> to a Hindi text that expresses this).","This paper studies the problem of fact linking -- linking facts from a knowledge graph (KG) to a given sentence where the fact is mentioned. More specifically, recognizing the sparsity and skewness of KG entity and relation labels in terms of language coverage, this paper proposes to study the multilingual setting, where the input sentence is in an underrepresented language and one needs to link KG facts, often only expressed in more high-resource languages, to the input sentence. A new test set for 6 Indian languages is created by manually translating sentences from WebRED with professional translators. The paper also proposes a model for this task based on the Dual Encoder - Cross Encoder architecture, but unlike conventional Cross Encoder, it follows mGENRE and proposes a constrained autoregressive decoder to generate valid facts. It is shown that the proposed model outperforms re-ranking based Cross Encoders by a large margin on the new test set.",0.23148148148148148,0.16233766233766234,0.19083969465648853
1345,SP:7dffea29b6080871ab1737a0032361627fb8f5aa,"This paper concerns the limitation of the quality-only evaluation metric for text generation models. Instead, a desirable evaluation metric should not only measure the sample quality, but also the sample diversity, to prevent the mode collapse problem in gan-based models generation. The author presents an interesting, but not too surprising finding that, tuning the temperature beam search sampling consistently outperform all other GAN/RL-based training method for text generation models. The idea of sweeping temperature during beam search decoding is not new in the NLP community, which limits the novelty of this paper. What’s more, some parts of the experiment results is also somehow not new, in the sense that the SBLEU vs Negative BLEU tradeoff curve is also shown in [1,2,3,4].","Recently many language GAN papers have been published to overcome the so called exposure bias, and demonstrated improvements  in natural language generation in terms of sample quality, some works propose to assess the generation in terms of diversity, however, quality and diversity are two conflicting measures that are hard to meet. This paper is a groundbreaking work that proposes receiver operating curve or Pareto optimality for quality and diversity measures, and shows that simple temperature sweeping in MLE generates the best quality-diversity curves than all language GAN models through comprehensive experiments. It points out a good target that language GANs should aims at. ",0.11627906976744186,0.14423076923076922,0.12875536480686695
1346,SP:7e0bdc833324174b53617123d8268988c0263a34,"This paper proposes a new type of model called a hierarchical multimodal VAE (HMVAE) that captures modality-specific variations using latent variables dependent on a shared top-level variable, in a manner similar to a multi-layer hierarchy. Their assumption is that modality-specific variations can sometimes depend on the structure shared across modalities which motivates their design decision to have modality-specific variables dependent on a shared top-level multimodal variable, which is in contrast to existing works on multimodal generative models that factorize into marginally independent latent variables to capture modality-specific variations (in other words not depending on a shared top-level multimodal variable).  Experimental results show promising performance on the CUB and the Oxford Flower datasets and outperform existing methods in sample generation quality and quantitative measures as the held-out log-likelihood.",The authors propose a Hierarchical framework for multimodal learning HMVAE. They define modality specific latent factor as well as the shared latent factor across multiple modalities. They represent modality-specific variations using latent variables dependent on the shared top-level variable. They parameterize the posterior distribution over the shared latent variable using a mixture of experts. The modality specific latent factors are adaptive inferred with both bottom-up and top-down information. They evaluate the proposed method on the Oxford Flower and the CUB datasets with various cross-modal experiments. ,0.21897810218978103,0.3333333333333333,0.2643171806167401
1347,SP:7e304a42b85f2a7fbc9a3ade7d104d93277f964a,"The authors propose an extension to the ALISTA algorithm. Momentum is added to the update rule to speed up convergence, and parameters are adaptively determined per layer, rather than learned over a training distribution. Such adaptivity was recently proposed in the NA-ALISTA algorithm as well, but this solution is more light-weight. HyperLISTA was shown to converge faster and to lower optimum than ALISTA (and variants thereof) in a synthetic data setup. ","This paper proposes an ultra-light variant of LISTA, called HyperLISTA, for solving sparse linear inverse problems. The authors’ adaptive parameterization reduces the training of HyperLISTA to only tuning three instance- and layer-invariant hyperparameters. HyperLISTA is theoretically proved and empirically observed to have super-linear convergence rates: the first time ever so in LISTA literature. It also leads to superior test-time adaptivity. ",0.136986301369863,0.15625,0.145985401459854
1348,SP:7e40bed85094593ff4cfac5122544f15215b6439,"This paper studies the few-shot outlier detection setting where a few examples from outlier classes are provided to the ODD detector.  The main motivation behind this work are situations that require high level of ODD detection. It is shown that classifiers trained by fine-tuning large-scale pre-trained transformers are significantly better at near-ODD detection. Simulations are performed on well-known data sets for visual classification and genomic sequences. Performance evaluation are reported in term of AUROC scores. However, it would have been more convenient to report results in terms of FPR at 95% scores which allow to better understand if the performance gains with respect to similar methods are relevant. The reported gains are not very significant but consistent.  ","* The paper presents detailed experiments which show that pre-trained large scale transformers significantly improves OOD detection performance. * The paper especially focuses on the case where in-distribution (InD) and OOD samples are close to each other (near OOD) (e.g. when CIFAR100 is InD and CIFAR10 is OOD, SoTA AUROC is improved from 85% to 96% ). * It is demonstrated that transformers can yield better well-separated representations for each class on InD dataset compared to ResNet without even fine tuning on InD samples. Separation of the representations become even better after fine-tuning in InD dataset (see Fig. 1). This motivates that transformers can be better for OOD detection compared to ResNet-like architectures and improves the SoTA. * The paper presents experiments in different settings on multiple datasets: * First, OOD detection performance between CIFAR10 <-> CIFAR100 is evaluated. The results demonstrate that fine-tuning transformers significantly improves SoTA OOD detection performance. Additional experiments are presented where it is assumed that a few examples from each class of target OOD dataset is available (called outlier exposure). This leads to further boost in OOD detection performance. * The second experiments are performed on a genomics dataset where InD dataset consist of 10 known bacteria classes and OOD dataset consist of another 60 bacteria classes which are not seen during training. The results are consistent with the CIFAR10-CIFAR100 experiments.  * Finally, experiments on multimodal text-image models are presented where candidate labels are used for OOD detection. The results show that it leads to significant performance improvement.",0.22764227642276422,0.11067193675889328,0.14893617021276595
1349,SP:7e456aff1e90c9f11b51c22e9ec7132eca76d700,"In this paper, the authors intend to accelerate on-line reinforcement learning with off-line datasets. To achieve this goal, they propose an algorithm called advantage weighted actor-critic (AWAC), which uses an implicit constraint to reduce accumulated bootstrapping error when doing off-line training and reduce the conservation when doing on-line fine-tuning. The experiments show that the proposed method can learn difficult, high-dimensional, sparse reward dexterous manipulation problems from human demonstrations and off-policy data.","This paper studies shorting coming of existing off-policy methods when it comes to prior data and fine-tuning and shows that those existing methods can't effectively utilize previously collected data with online updates. To address this problem, they propose to constraint policy updates with respect to behavioral policy. Their proposed method is built mainly on the top of AWR [1]. ",0.1518987341772152,0.1935483870967742,0.17021276595744683
1350,SP:7e4c98b19256f0aa9035a430e32fd2594f8adee9,"This paper proposes a method for estimating the probability deinsity distribution on a low-dimensional manifold embedded in a high-dimensional space using Normalizing Flow (NF). The problem is that the universality of NF is limited because low-dimensional manifolds are not diffeomorphic with respect to high-dimensional Euclidean space. The proposal of this study is to make NF applicable by inflating low-dimensional manifolds with Gaussian noise. Then, after the transformation is obtained, the probability distribution on the original low-dimensional manifold can be obtained by deflation.","In this paper, the authors address main limitations of Normalizing Flows (NFs) method for estimation of density functions on manifolds. Since NFs requires the support of density function to cover the whole Euclidean space, they propose to add noise (inflate) to apply NF. The paper is nicely written with clear introduction of basic concepts very useful for non-expert readers. They provide theoretical guarantees on the variance and type of added noise that make the method work and illustrate with synthetic experiments.",0.18181818181818182,0.1951219512195122,0.18823529411764706
1351,SP:7e51fa9afc6a36b771f966b8f615449dab0191bf,"This paper tracks the problem of learning the entire Pareto front to allow the user to select a desired Pareto optimal solution by one inference procedure without retraining the model. The high-level idea is to learn the entire Pareto front simultaneously using a single hyper network, which receives as input the desired preference vector and returns a Pareto-optimal solution whose loss vector is in the desired direction. The paper gives an early trial to build a toolbox to allow users to get a desired solution by a single inference procedure.","The paper proposes a method for multi-objective optimization. The key idea is to learn the entire Pareto front at once by training a hypernetwork that takes preference vector as an inputs and outputs network parameters, which corresponds to a point on the Pareto set with the desired trade-off specified by the preference vector. Specifically, the hypernetwork is a multi-head network where each head outputs a weight tensor of a module in the target network. The method improves HV from the baselines, in several multi-task learning problems, including image classification, regression and, mixed classification and regression.",0.25,0.23232323232323232,0.24083769633507854
1352,SP:7e56b172f24cf317f1e6f9971ca258b65b4d2a32,"The paper presented a novel method that extracts object priors from egocentric videos to guide the learning of a robotic agent to interact with objects. The key idea is to model the presence of objects and their co-occurrence from naturalistic activities in first person videos (so called activity context), which can be further used as an auxiliary reward in RL for learning to perform complex object manipulation tasks. The proposed method was demonstrated in a simulated robotic learning environment, with promising results across several tasks. ","This paper introduces an approach to discover activity-context priors, that is, for a given object, the environment states that are preconditions for attempting given activities with objects. Such priors are acquired from in-the-wild egocentric videos that are captured from a camera that is worn by people performing daily activities. A visual model is trained to detect how humans prepare their environment for their activities from egocentric videos. Video-based priors are then used as auxiliary rewards to encourage agents to seek out similar activity-context states. The proposed approach accelerates learning and generalises to unseen environments. ",0.23255813953488372,0.20202020202020202,0.2162162162162162
1353,SP:7e75b1311a12b8c0353180183447e529683a88d6,"This paper focuses on issues in the popular PBT algorithm for hyperparameter optimization. It investigates the 1) step size (which is typically a constant multiplier) 2) the variance induced by better weights and 3) the greediness of the algorithm, which they refer to as short-term vs. long term effects. These issues are well motivated, and it is intuitive that they are flaws in the original algorithm. The proposed approach is to use Differential Evolution which the authors claim makes the hyperparameter selection more robust. The paper also introduces a new library for online hyperparameter tuning.","The paper provides a new variant of PBT which utilizes ideas from differential evolution and cross-over. The original PBT and even initiator PBT do not perform crossover on the hyper-parameters, and insufficient cross-over may cause PBT to perform greedy in the initial phases which ends up with a suboptimal convergence. The investigation of better cross-over in PBT is itself an interesting research direction and the authors demonstrated its effectiveness in standard benchmarks and data augmentation tasks. The improvements of ROMUL-PBT are also helpful to the community since PBT has been applied in a variety of real world applications.",0.16666666666666666,0.1553398058252427,0.1608040201005025
1354,SP:7eaef5cc44106d1428d3348c3f731da8fae8db2e,"The paper highlights the difficulty of training with large action space in reinforcement learning. This is usually difficult due to the vast number of possibilities during exploration. They address this issue by studying existing approaches of splitting the action into a finite number of sub-actions and then sampling each sub-action independently or auto-regressively. This leads to a reduction in the candidate actions during exploration which would improve the sample efficiency.  Also, This splitting is referred to as “Factorization of Action Space”. ","The paper studies policy optimization in multidimensional action spaces. They consider atomic factorization of the action space (i.e. action space is factored into sub-action spaces, one per action dimension). In this setting, the authors consider two well-known policy representation techniques: 1) independent sub-policies (diagonal-covariance policies over the sub-action spaces) and 2) sequential/autoregressive policies (an ordering of the sub-action spaces is assumed a priori and the sub-policies receive as input the state and the selected sub-actions for the preceding sub-action spaces). The authors develop methods based on these two factorization techniques for discrete versions of PPO and SAC (called FPPO and FSAC) and evaluate them on Gym Platform, Google Football, and discretized MuJoCo tasks.  ",0.2261904761904762,0.1532258064516129,0.18269230769230768
1355,SP:7ec1aeb5e1e9e0ef6759fa1d57de00d2170526c8,"This paper proposes a way to apply various variance reduction/momentum based method to the federated learning scenario, especially when there is distribution drift among the clients. The main claim of this paper is that the global statistics (momentum, control variance et al) should be update at the server side only, which is helpful to reduce the bias of these terms. The paper also provides convergence analysis for their methods and attains the best convergence result for their MimeMVR method.","The paper proposes a new framework for solving federated learning. The authors consider a specific setting that there are many clients, and each client is allowed to compute the full gradient. The authors claim that the current setting’s main issue is the client drift, and the proposed framework can reduce such an issue and thus achieve a faster convergence rate. Here are my main concerns of the current paper:",0.2125,0.24285714285714285,0.22666666666666668
1356,SP:7f1af600e64c0ad693a9b1cc198bbaf39cd884c6,"The paper presents SEED RL, which is a scalable reinforcement learning agent. The approach restructure the interface / division of functionality between the actors (environments) and the learner as compared to the distributed approach in IMPALA (a state-of-the-art distributed RL framework). Most importantly, the model is only in the learner in SEED while it is distributed in IMPALA. ","This paper presents a scalable reinforcement learning training architecture which combines a number of modern engineering advances to address the inefficiencies of prior methods. The proposed architecture shows good performance on a wide variety of benchmarks from ALE to DeepMind Lab and Google Research Football. Important to the community, authors also open source their code and provide an estimate which shows that the proposed framework is cheaper to run on cloud platforms.",0.25,0.20833333333333334,0.22727272727272727
1357,SP:7f210a3382b6840f84b182f0c72b9de2e89b0fe0,"The paper presents a generative approach to modeling physical systems with high-dimensional, nonlinear dynamical systems such as those found in fluid mechanics. The authors provide a physics-motivated hierarchical model for high-dimensional time series and a variational inference method for inferring latent variables and dynamical system parameters. They demonstrate its performance on simulated fluid mechanics prediction tasks.","The paper proposes a generative model for learning a low-dimensional representation of a dynamical system from high-dimensional observations. The novelty of the approach is to introduce two latent spaces, one representing the standard physics-agnostic latent space learned from the data and one representing physics-motivated variables. The goal is to learn the dynamics of the first layer, denoted by z_t, which is a coarse-grained representation of the dynamical system and mostly captures the slow processes that drive the system. ",0.2033898305084746,0.14285714285714285,0.16783216783216784
1358,SP:7f3dfc4a045d780299123b42cc712b3d7171e8eb,The paper tries to ask if there is a good neural net architecture that works as effectively as gradient boosting decision trees on tabular data. The authors propose an architecture (NODE) that satisfies this conditions. NODE is an architecture consisting of differentiable oblivious decision trees that can be trained end to end via back propagation. The paper is readable and the experiments are well presented. They make use of an alpha-entmax transformation to obtain a differentiable architecture. The approach seems well motivated in the literature. It is unclear how novel the contribution is. It is unclear if in the experimental section the datasets used are standard for this classes of tasks. Would be good to mention if it is the case. ,"This paper introduces a new method to make ensembles of decision trees differentiable, and trainable with (stochastic) gradient descent. The proposed technique relies on the concept of ""oblivious decision trees"", which are a kind of decision trees that use the same classifier (i.e. a feature and threshold) for all the nodes that have the same depth. This means that for an oblivious decision tree of depth d, only d classifiers are learned. Said otherwise, an oblivious decision tree is a classifier that split the data using d splitting features, giving a decision table of size 2^d. To make oblivious decision trees differentiable, the authors propose to learn linear classifiers using all the features, but add a sparsity inducing operator on the weights of the classifiers (the entmax transformation). Similarly, the step function used to split the data is replaced by a continuous version (here a binary entmax transformation). Finally, the decision function is obtained by taking the outer product of all the scores of the classifiers: [c_1(x), 1-c_1(x)] o [c_2(x), 1-c_2(x)] ... This ""choice"" operator transforms the d dimensional vectors of the classifier scores to a 2^d dimensional vector. Another interpretation of the proposed ""differentiable oblivious decision trees"" is a two layer neural network, with sparsity on the weights of the first layer,",0.2540983606557377,0.13777777777777778,0.1786743515850144
1359,SP:7f4c42d8f72214b7a2ffc295358fd0e8f8a4103e,"This paper proposes a range of algebraic model extraction attacks (different from the prevalent learning-based approaches) for transformer models trained for NLP tasks in a grey-box setting i.e., an existing, public, usually pretrained encoder, with a private classification layer. Through attacks on different sizes of models and a range of downstream tasks, they observe that only a portion of the embedding space forms a basis of the tuned classification layer’s input space, and using a grey-box method, this can be algebraically computed. The pretraining-finetuning experiments on different tasks also show the smallest number of dimensions needed for high-fidelity extraction, and also that the model extraction attacks effectiveness decreases with fine-tuning the larger models base layers---which is an insight that is very useful for a lot of interpretability/probing work.","This paper is an interesting study of algebraic model extraction attacks on modern NLP models based on BERT. Model extraction is the setting where a malicious attacker tries to reconstruct a copy of a black-box inference API without access to the original training data. Prior work [1] showed these attacks are possible on BERT models using a distillation-like learning method, using gibberish sequences of words as queries to the API. However, these attacks needed large number of queries for success. This work adopts a different strategy --- equation solving the parameters of the neural network using least square linear algebra methods. This not only allows extraction with lesser queries, but also ensures greater similarity between the API and extracted model (""high fidelity"", [2]). The attacks in this paper work perfectly in settings where BERT is frozen and a single classification layer is fine-tuned. However, the attacks are not as effective in the more practical setting where BERT is fine-tuned, and the authors perform a thorough analysis varying critical hyperparameters.",0.2246376811594203,0.18023255813953487,0.19999999999999998
1360,SP:7f6ac27e9ec6db3f4860406263b59f88c2cfeacc,"The paper introduces the concept of node-specific information (NSI) to model that nodes in a graph may have private information that other nodes cannot have access to. The paper uses Neural Relation Inference (NRI), a framework published in 2018 based on variational inference, to uncover the hidden relations of nodes in the graph. For instance, in a driving scenario, different cars can be nodes in a graph with their publicly visible trajectory and their private information about the intention (e.g. desired destination), which is not shared with other nodes. The encoder and decoder in NRI are modified such that NSI stays private and is not shared with other nodes. The paper considers problems that require uncovering the interactions of entities in a multi-agent dynamical system. The evaluation is based on the accuracy of future trajectory prediction. The paper demonstrates the effectiveness of the idea on three different datasets, one action-conditional dataset and two goal-conditional datasets.","**Summary**: This paper introduces a neural relational inference model that makes use of the hidden features of each node in a variational inference framework. Specifically, the hidden/individual information is modeled as private node in the graph. Importantly, the task assumption made by the authors is that these individualized features cannot be observed by other entities.   **Contributions**:  1. The authors claim be to the first to study the use of individualized information for each entity in this direction. 2. The proposed approach achieve state-of-the-art results while only introducing minimum additional computational complexity. ",0.15625,0.2631578947368421,0.19607843137254902
1361,SP:7f6ef5f3fa7627e799377aa06561904b80c5c1c4,"This paper proposes a novel direction for curriculum learning.  Previous works in the area of curriculum learning focused on choosing easier samples first and harder samples later when learning the neural network models.  This is problematic since we need to first compute how difficult each samples are, which introduces computational overheads.  In this work, the paper propose to gradually learn with a class-wise perspective instead.  The neural network has only access to the labels of certain classes (chosen randomly) in the beginning, and the samples that belong to the rest of the classes are treated as unseen samples but with a label forced into the last class.  Then, the true labels of unseen classes are gradually revealed, and this is repeated until in the final incremental step, all labels are revealed.  The method further has an adaptive compensation step, which use a less peaked distribution label for supervision only for the incorrectly predicted samples.  The experiments show that with only the first step, the proposed method is worse than the original batch learning, but by adding the second label smoothing step, there is improvement over the original batch learning setup.","This paper makes the observation that a curriculum need not depend on the difficulty of examples, as most (maybe all) prior works do. They suggest instead a curriculum based on learning one class at a time, starting with one and masking the label of all others as 'unknown' (i.e. treating them as negative examples), and unmasking classes as learning progresses. This is the ""incremental labels"" part. They make another observation, that label smoothing is applied to all examples regardless of difficulty, and propose an alternative ""adaptive"" version where labels are smoothed only for difficult examples. This is the ""adaptive compensation"" part.",0.13612565445026178,0.2549019607843137,0.1774744027303754
1362,SP:7f894264c42d9e9670233250810e71c20d2f7fcf,"This paper proposed value target lower bounding as a simple modification to the Bellman operator that intends to improve convergence speed. It proves that using such a lower bound in the Bellman backup does not change the fixed point in the tabular setting. The paper then proposes two instantiations of particular value target lower bounds: first by using the return in deterministic episodic MDPs and second by hindsight relabeling in goal-directed tasks. Finally, the paper offers some experiments using the proposed lower bounds. ","This paper proposes a new RL algorithm based on a modified Bellman backup equation. The main idea is to estimate the value of a state in multiple ways (using a Q function and using Monte Carlo returns) and then to take the maximum over these estimates. The paper shows that, if all estimators are lower bounds on the true value, then the proposed method converges to the optimal policy. Experiments confirm that the proposed method outperforms standard Q learning (i.e., with regular Bellman backups) on some tasks.",0.21428571428571427,0.20454545454545456,0.20930232558139536
1363,SP:7f95a11596f1b1321a691b1b45cff3de69027aaf,The paper introduced Equivalent-Policy Invariant Comparison (EPIC) pseudometric to compare different reward functions directly without training a policy function. The authors provide an interesting direction for inverse reinforcement learning. The EPIC distance gives a bound on the regret between policies optimizing for one of the two reward functions relative to the other. The authors also conduct a didactic example to demonstrate efficacy.,"The paper introduces a pseudometric on reward functions, EPIC (Equivalent-Policy Invariant Comparison), based on the potential-based reward shaping (Ng. 2020). It formally analyzes the EPIC distance in detail and demonstrates its usefulness in comparing learned reward functions without the necessity of optimizing reward-specific policies. The empirical results show that the EPIC is more predictive of the policy returns than some baseline variants and robust to visitation distributions, even in unseen test environments. ",0.25396825396825395,0.21333333333333335,0.2318840579710145
1364,SP:7fa47de279e72f0782efd67722919321badcb022,"The authors propose a method for fast and efficient classification of sequential data. The guiding principle is that for some data modalities it is not necessary to see the whole sequence in order to make a fairly certain classification. Their model reduces inference time by learning a rank code that is inspired by spiking neural networks. Reported results show improved inference times in two toy sequence classification tasks, temporal MNIST, and in Google Speech Commands classification (compared to models without optimizing timing of inference through learning a rank code). Increasing inference speed comes with a minimal decrease in accuracy, the authors, however, introduce and show the effectiveness of a regularization term that allows for tuning of this speed-accuracy trade-off. ","The authors introduce a new way to train RNNs using rank order coding (ROC). With ROC the label is given by the first readout unit to reach a threshold. As soon as this happens, the processing is stopped, and BPTT is used from that particular time step, using the predictions at that particular time step and the ground truth. This will encourage the neuron with the right label to be as active as possible at that particular time step, and thus its threshold will tend to be reached earlier in the future. This is desirable, as the latency of the decision will decrease. Furthermore, the speed-accuracy trade-off is tunable by varying the threshold.  The authors validate their idea using LSTMs on two toy problems, and then on MNIST and on the Google Speech Command dataset.",0.1652892561983471,0.145985401459854,0.15503875968992248
1365,SP:7ff567aac68a3492029136828f1b45dd7c358e8a,"This paper describes a pre-processing method to reduce certain statistical disparities in the classifier obtained from the training data. The proposed approach involves learning a latent probability model that simulates the training data. The authors then manipulate the learned model to generate ""counterfactual"" samples that belong to the membership of underrepresented demography. A more ""fair"" classifier is trained on the manipulated data mixing with the ""counterfactual"" samples.","This paper combines counterfactual modeling with adversarial training for fair machine learning tasks. For a given fairness metric chosen from a variety of canonical examples, the method ensures fairness by augmenting the data with counterfactual examples during training. The approach has potential, which is best demonstrated on examples where the counterfactual data generation is interesting, like the CelebA data.",0.20588235294117646,0.23728813559322035,0.22047244094488191
1366,SP:8033aa140ced2ef797bb83036759dd73acca5623,"This paper proposed a new adversarial attack method based on model-based RL. Unlike existing adversarial attack methods on deep RL, the authors first approximate the dynamics models and then generate the adversarial samples by minimizing the total distance of each state to the pre-defined target state (i.e. planning). Using Cartpole, Fish, Walker, and Humanoid, the authors showed that the proposed method can pool the agents more effectively. ",  This paper looks at a new framework for adversarial attacks on deep reinforcement learning agents under continuous action spaces. They propose a model based approach which adds noise to either the observation or actions of the agent to push the agent to predefined target states. They then report results against several model-free/unlearned baselines on MuJoCo tasks using a policy learned through D4PG.,0.2,0.21875,0.20895522388059704
1367,SP:80376e14141e0c667c4e1c1568ca9d545a1c5fbd,"This paper introduces a novel policy architecture (AGILE) for RL agents that learn action interdependence from a varying action space. A graph attention network is used to calculate the action utility and to summarize the action set input. Authors argue that this architecture allows the RL agents’ to learn action relations that lead to optimal behaviour in a changing action space environment. This architecture is then evaluated in three benchmark domains. Further evaluations are done in the recommender systems context, with both simulated systems and using real-world data. Results seem to indicate that the proposed method outperforms non-relational RL methods in most cases.","This paper tackles an RL problem setting in which the actions available to an agent vary from episode to episode, and the optimal action in some states depends on the other actions that are available. The authors’ approach to this setting is to use a graph neural network to process all available actions, both to summarise the available set and to produce a relationally-informed representation for each action. These are then fed, with the state, into a utility function to give an action value or logit. Experiments in a number of benchmarks show the value of including information about the available actions.",0.19047619047619047,0.1941747572815534,0.1923076923076923
1368,SP:80503d1fec17a71f526e1bf17459a7379f89383b,"This work proposes the Graph Deformer Network (GDN), whose key component is the proposed Graph Deformer Convolution (GDC). The GDC is based on the attention mechanism, where a fixed number of query vector comes from a clustering process of some randomly sampled nodes (In my opinion, the q vector in the paper should be named the key vector instead query vector, according to [1]). The attention thus yields a fixed number of ordered vectors as outputs, where an anisotropic convolution can be applied on. Experimental results on both node and graph classification tasks demonstrate the effectiveness of the proposed GDC.","In order to perform anisotropic convolution on graphs, this paper proposes to project a local neighborhood into a unified virtual space by introducing anchor nodes. A theoretical analysis is provided to show the expressive power of the proposed graph deformer operation on graph isomorphism test. Extensive experiments are performed on several node classification and graph classification datasets.",0.14,0.24561403508771928,0.17834394904458598
1369,SP:80632a67c24d9245fb6e89efcfd666a44a5df74d,"This paper presents two approaches: one called SENSE-S for embedding nodes in attributed networks; the other one called SENSE for embedding a sequence of nodes. SENSE-S follows the structure of Skip-gram model. The main difference is that SENSE-S considers both node and words in node content as input and output for learning their embedding. For generating embedding vector for a sequence of nodes, SENSE takes summation of cyclically shifted unit-vectors constructed by SENSE-S on nodes in a sequence.    ","The paper proposes node embedding methods for applications where nodes are sequentially related. An example application is the ""Wikispeedia"" dataset, in which nodes are connected in a graph, but a datapoint (a wikispeedia ""game"") consists of a sequence of nodes that are visited. Each node is further attributed with textual information.",0.11904761904761904,0.19607843137254902,0.14814814814814814
1370,SP:807c7df69d51b93b5a0da3ea56506a9bfadd0595,"Training deep neural networks is typically done using gradient-based methods with either pre-defined learning-rate schedules or off-the-shelf adaptive optimizers (such as Adam). The former can not reliably align with the non-linear loss landscape, while the latter add additional hyperparameters to tune. This paper proposes an algorithm for automatically tuning a learning-rate schedule. The method works by modelling the training dynamics and adapting the learning-rate to optimize performance on the validation set. The method does end up introducing additional hyperparameters,","This paper uses Bayesian optimization (BO) to dynamically tune the learning rate during the course of training of DNNs.  In every stage of training, the algorithm firstly uses BO to explore different learning rates with the help of a parametric exponential model for learning rate extrapolation, and then applies the selected learning rate at the current stage. The algorithm is applied to the training of state-of-the-art DNN models, and is shown to outperform the original learning rate schedules, as well as other methods for learning rate scheduling.",0.1839080459770115,0.17777777777777778,0.1807909604519774
1371,SP:808b08e83e4d42d970bdb394e229860cc584e475,"The paper introduces a new approach to combine small RBMs that are pretrained in order to obtain a large RBM with good performance. This will bypass the need of training large RBMs and suggests to break them into smaller ones. The paper then provides experimental evidence by applying the method on ""invertible boolean logic"". MCMC is used to find the the solution to large RBM and compare it against the combined solutions of smaller RBMs.","The paper proposes learning Restricted Boltzmann Machines for solving small computational tasks (e.g., 1-bit addition) and composing those RBMs to form a more complex computational module (e.g., 16-bit addition). The claim is that such an approach can be more data efficient than learning a single network to directly learn the more complex module. Results are shown for addition and factoring tasks.",0.14666666666666667,0.16923076923076924,0.15714285714285714
1372,SP:809b794b29e96574749b880e6daeee0c1d04994c,"This paper proposes a new approach to mitigate the catastrophic forgetting for continual learning. The model is composed to the neural architecture search and parameter learning based on the intuition that largely different tasks should allow to use different network structure to train them. In structure learning, they introduce three candidate to decide network architecture, reuse, adaptation and new. In the experiments, they show that their model outperforms SGD and EWC.","The proposed approach aims to mitigate catastrophic forgetting in continual learning (CL) problems by structure learning: determining whether to reuse or adapt existing parameters, or initialise new ones, when faced with a new task. This is framed as an architecture search problem, applying ideas from Differentiable Architecture Search (DARTS). The approach is verified on the Permuted MNIST dataset and evaluated on the Visual Decathlon, showing an improvement.",0.19718309859154928,0.208955223880597,0.20289855072463767
1373,SP:80bfa04747c12a3218946b708d6b394485c2dcc5,"The paper considers the problem of low precision stochastic gradient descent. Specifically, they study updates of the form x_{t + 1} = Q (x_t - alpha * g_t), where g_t is a stochastic gradient, and Q is a quantization function. The goal is to produce quantization functions that simultaneously increase the convergence rate as little as possible, while also requiring few bits to represent. This is motivated by the desire to perform SGD on low precision machines.",This paper discusses conditions under which  the convergence of training models with low-precision weights do not rely on model dimension. Extensions to two kinds of non-linear quantization methods are also provided. The dimension-free bound of the this paper is achieved through a tighter bound on the variance of the quantized gradients.  Experiments are performed on synthetic sparse data and small-scale image classification dataset MNIST.,0.16883116883116883,0.19117647058823528,0.1793103448275862
1374,SP:80d8f2ef8e3b7ad7f8407b80f29c70111d80e22e,"The paper performs the analysis of the GAN latent spaces from the geometric perspective, inducing a metric tensor in the latent space from the LPIPS distance in the image space. The main authors' finding is that under such metric, the latent spaces of typical GANs are highly anisotropic, which can be exploited for more effective GAN inversion. Furthermore, the authors show that eigen vectors of the metric tensor often correspond to interpretable latent transformations.","This work intends to explore the geometry of the latent space and proposes to define the distance in latent space as the distance between the corresponding generated images and use the Hessian of that squared distance as metric tensor to define the manifold. Using Learned Perceptual Image Patch Similarity (LPIPS), they show that the Hessian can either be computed through backpropagation or if that is not efficient, it is sufficient to iteratively compute the eigenvectors corresponding to the largest eigenvalues. With the proposed method, the empirical observations showed 1) the impact of those eigenvectors through examples, 2) consistent geometric local changes over different positions in the latent space, and 3) the impact of top eigenvectors on particular layers. Further, the authors discuss three areas of possible application (gradient-based GAN inversion, gradient-free image search, interpretable axes discovery).",0.28378378378378377,0.15217391304347827,0.19811320754716982
1375,SP:80d95638850c9ff81a9b271d28a8aecf238497e6,"This paper proposes a new method on training energy-based models with maximum likelihood. Instead of using MCMC approaches to sample from the EBM, authors follow previous work on training neural generators for faster sample generation. In particular, authors consider a special generator where the output is convolved with Gaussian noise. The score function of this generator can be estimated with self-normalized importance sampling, which is then used to estimate the entropy term through the reparameterization trick. Authors demonstrate that their new method is able to train EBMs efficiently, and improves the stability and performance of JEMs compared to MCMC-based training approaches.","This paper presents a method for improving training of energy-based models. Rather than drawing samples using persistent contrastive divergence / MCMC, this approach parameterizes a separate model, which is trained to directly output samples. This effectively adds an additional KL divergence to the objective. The authors use a particular form of sampling model (a latent Gaussian model), borrowing a few tricks for getting entropy estimates out of the model. Results are demonstrated on a few qualitative setups, but most of the results are centered on improved JEM on sample quality, out-of-distribution detection, and semi-supervised learning. The main benefit of the approach seems to be speed and stability, however, the authors also claim that minimal tuning is needed.",0.22115384615384615,0.19166666666666668,0.20535714285714288
1376,SP:80f793ccbecb41ebf9e5d562f1588c9541b2ba72,"In this manuscript, the authors study the trajectory of mirror descent to optimize the unregularized empirical risk functional to solve low-rank matrix estimation problems. They characterize the trajectory of mirror descent with different mirror maps and showcase an implicit bias towards certain structures in solutions. In particular, when equipped with either the spectral hypentropy map or spectral entropy map, they show that mirror descent converges to a global minimizer that minimizes a particular quantity depending on the singular values of the resulting matrix. This quantity interpolates between the nuclear norm and Frobenius norm for the spectral hypentropy map and is a linear combination of the nuclear norm and von Neumann entropy for the spectral entropy map. They also show algorithmic guarantees for mirror descent to solve matrix sensing and matrix completion problems that operate with sample complexities on par with traditional nuclear norm minimization approaches, without explicit regularization. Finally, a connection between gradient descent over the parameterization $UU^T - VV^T$ and mirror descent is shown and toy experiments show mirror descent and gradient descent behave similarly.",The paper provides the convergence analysis of mirror descent for matrix sensing to particular minimum norm solutions. The updates that are studied are induced by the hypentropy and von Neumann divergences. The authors analyze multiple interesting cases including matrix completion and the case where the instances satisfy the RIP. They also provide some experimental evaluations to validate their findings.,0.10674157303370786,0.3220338983050847,0.16033755274261605
1377,SP:80ff74500bb5ad72b0f34b92d782fe09374e0f08,"This paper proposes a simple improvement to methods for unit pruning. After identifying a unit to remove (selected by the experimenter’s pruning heuristic of choice), the activation of that unit is approximately incorporated into the subsequent unit by “mean replacement”. The mean unit activation (computed on a small subset of the training set) is multiplied by each outgoing weight (or convolutional filter) and added to each corresponding bias instead. Experiments show this method is generally better than the typical method of zero-replacement before fine-tuning, though the advantage is smaller after several epochs of fine-tuning.",This paper presents a mean-replacement pruning strategy and utilizes the absolute-valued Taylor expansion as the scoring function for the pruning. Some computer vision problems are used as test beds to empirically show the effect of the employment of bias-propagation and different scoring functions. The empirical results validates the effectiveness of bias-propagation and absolute-valued Taylor expansion scoring functions.,0.14285714285714285,0.22580645161290322,0.17500000000000002
1378,SP:810aaef2f0ad54bbd1a57053bae7860324e17602,"This paper proposes DEMI, a discriminative approach to estimate mutual information (MI). The main idea is that, instead of learning (generative) distributions of joint and marginals, learning a single likelihood ratio that is discriminative and hence more tractable: a posterior $p(z | x, y)$ trying to distinguish between the joint distribution $p(x, y)$ and the product distribution $p(x)p(y)$. Once the posterior is learned, it can be used to estimate the MI.","This paper proposed a discriminative estimator for mutual information, to alleviate the shortcomings of the existing estimators such as MINE and SMILE. A classifier was built to decide whether the sample is drawn from the joint distribution or the independent one (product of marginals). Theoretical justification and experimental results were provided to support the proposed estimator. The paper was written with clarity and easy to follow.",0.24,0.2727272727272727,0.2553191489361702
1379,SP:810e4d1edb1d7aa02ef0777f45ce4db3263d551c,"The paper studies effectiveness of self-training to improve test time performance when the distribution of test data is not similar to the training data. The paper more specifically focuses on source-free domain adaptation settings where the source target data is not available. In this setup self-training has been tested as an additional step on top of  different robustness and adaptation approaches such as robust pretraining, unsupervised domain adaptation and self-supervised pretraining. The paper shows improvement on multiple ImageNet variants and CIFAR10-C, and also introduces ImageNet-D dataset as a new benchmark. ImageNet-D has been produced by matching label space of IN datasets with DomainNet data provided in Visual domain adaptation challenges. The main contribution of this paper is to perform a systematic and large study of self-training as a method to deal with distribution shifts.","This paper provides an in depth empirical evaluation of classical self-training techniques such as pseudo-labelling and entropy minimization on test performance under domain shifts. The authors stress that, although simple, these techniques consistently improve the robustness to distribution shifts regardless of model architecture or pre-training techniques used. This makes them especially useful to practitioners applying machine learning algorithms to real problems where distribution shifts are prevalent. The authors claim state-of-the-art adaptation results on a number of popular dataset corruption benchmarks, and present a new challenging dataset for evaluating the robustness of deep vision models.   ",0.14084507042253522,0.2,0.16528925619834714
1380,SP:812c4e2bd2b3e6b25fc6869775bea958498cbfd1,"This paper tackles an issue imitation learning approaches face. More specifically, policies learned in this manner can often fail when they encounter new states not seen in demonstrations. The paper proposes a method for learning value functions that are more conservative on unseen states, which encourages the learned policies to stay within the distribution of training states. Theoretical results are derived to provide some support for the approach. A practical algorithm is also presented and experiments on continuous control tasks display the effectiveness of the method, with particularly good results on imitation learning followed by reinforcement learning.","This work presents the value iteration with negative sampling (VINS) algorithm, a method for accelerating reinforcement learning using expert demonstrations.  In addition to learning an expert policy through behavioral cloning, VINS learns an initial value function which is biased to assign smaller expected values to states not encountered during demonstrations.  This is done by augmenting the demonstration data with states that have been randomly perturbed, and penalizing the value targets for these states by a factor proportional to their Euclidean distance to the original state.  In addition to the policy and value function, VINS also learns a one-step dynamics model used to select actions against the learned value function.  As the value function learned in VINS is only defined with respect to the current state, action values are estimated by sampling future states using the learned model, and computing the value of these sampled states.",0.18556701030927836,0.1232876712328767,0.14814814814814814
1381,SP:813473d94da9db192e13548da7f92149773062a5,"The generalization performance of learning algorithms characterizes their ability to generalize their empirical behavior on training examples to unseen test data, which provides an intuitive understanding of how different parameters affect the learning performance and some guides to design learning machines. Different from the traditional error analysis, this paper focuses on bounding the divergence bettween the test error and the training error by the the corresponding distillation error and distillation complexity, e.g., test error  is bounded by training error + distillation error + distillation complexity. The current learning theory analysis may be important to understand the theoretical foundations of distillation strategy in deep networks. However, some theoretical issues should be illustrated to improve its readability, e.g,. ","The paper overall is of good quality. The story of the work is well-written which makes the contributions easier to digest. One suggestion would be to comment a bit more on the relevance of the margin distribution for readers that are unfamiliar with it, for instance, in Figure 1, the term margin distribution is thrown without explaining why one should look into it. ",0.10344827586206896,0.1875,0.13333333333333333
1382,SP:813bacb9aed3dba22dc9c379793d87506d53f362,"This paper tackles the problem of learning an encoder and transition model of an environment, such that the representation learnt uses an object-centric representation which could favor compositionality and generalisation. This is trained using a contrastive max-margin loss, instead of a generative loss as previously explored. They do not consider RL or follow-up tasks leveraging these representations and transition models yet.","This paper aims to learn a structured latent space for images, which is made up of objects and their relations. The method works by (1) extracting object masks via a CNN, (2) turning those masks into feature vectors via an MLP, (3) estimating an action-conditioned delta for each feature via a GNN. Learning happens with contrastive losses, which ask that each feature+delta is close to the true next feature, and far away from other random possibilities. Experiments in simple synthetic environments (e.g., 2D geometric shapes moving on a black background) show encouraging results. ",0.140625,0.09375,0.1125
1383,SP:814c416499bba8dfbf99ef716c350bb9256c2dbd,This paper proposed a novel approach to jointly model text and stock price information and fuse them for stock market forecasting. It encodes text and stock price information in parallel and then fuses them using a co-attention transformer. Empirical results over a real-world dataset and trading simulations demonstrate that the proposed approach can outperform the existing baselines.,"This paper proposes a method to fuse tweets and stock prices for stock trend prediction flexibly. The authors claim that the proposed method outperforms other existing fusing methods. Furthermore, according to the results of the market trading simulation, this method achieves higher profits than other methods. ",0.2033898305084746,0.2608695652173913,0.2285714285714286
1384,SP:81704b6fef077ebf35d792cdb2104722c207bb06,The paper proposes a multi-scale feature fusion block and inserts the block into ResNet backbones for object detection. It is very similar to the inception block in IneceptionNets. The only difference is the proposed feature fusion contains feature map upsampling and downsampling (resize and resize^{-1}) for different branches. The paper has some merits as follows.,"In this paper, the authors study the problem of scale-friendly feature fusion for object detection. Specifically, the authors propose to process features at each layer of a feature pyramid network at multiple scales and fuse them back into a single scale. To be specific, they resize features at a layer into multiple scales, process these rescaled features independently, rescale them back into the original scale and combine them with the original features.",0.22807017543859648,0.1780821917808219,0.2
1385,SP:817a0c0cab1ac7a905446a7e140caa021b3d34fa,"the paper proposes a method for unsupervised disentangling of both discrete and continuous factors of variation in image data. It uses an autoencoder learned by optimising an additive loss composed of Mutual Information (MI) I(x;y,z) between the image x and the discrete+cts latents (y,z) and the reconstruction error. The mutual information is shown to decompose into I(x,y), I(x,z) and TC(y;z), and the I(x,z) is treated in a different manner to I(x,y). With Gaussian p(z|x), and it is shown that I(x,z_k) is maximal when p(z_k) is Gaussian. So KL(p(z_k)||N(0,1)) is optimised in lieu of optimising I(x,z), and I(x,y) (and TC(y;z)) is optimised by using mini-batch estimates of marginal distributions of y (and z). The paper claims improved disentangling of discrete and continuous latents compared to methods such as JointVAE and InfoVAE.","* This paper proposed a principled framework for auto-encoding through information maximization. A novel contribution of this paper is to introduce a hybrid continuous-discrete representation. The authors also related this approach with other related work such as \beta-VAE and info-VAE, putting their work in context. Empirical results show that the learned representation has better trade-off among interpretability and decoding quality.",0.07272727272727272,0.1875,0.10480349344978164
1386,SP:81a5cf3803c6147275da2679d511a38e44c5ebdd,"In this papers, the authors introduce a new technique to output uncertainty estimates from any family of neural nets. The key insight in this paper is that when considering existing SGD methods the following behavior occurs: if we think of ""easy"" and ""hard"" to classify datapoints, a NN trained with SGD will output good uncertainty estimates early on in training, but once the network focusses on tuning the parameters for the hard cases, the uncertainty estimates for the easy datapoints deteriorates. The algorithms proposed by the authors takes an existing uncertainty method (or confidence score function) and uses intermediate snapshots of SGD training to improve the final uncertainty estimates. Note that the focus in this work is on ranking uncertainties (and the authors suggest to leave calibrating uncertainties to existing methods).","The proposed methodology draws on the connection between boosting in ensemble learning and SGD for training DNNs, whereby misclassified instances are implicitly targeted in later training iterations once easier examples have been classified correctly. The authors observe that this incurs a trade-off in which easily-classified examples become susceptible to overfitting at later stages in the training procedure when the network parameters adapt to fit more complex examples. Two early stopping algorithms are proposed in order to mitigate this issue. The first approach, PES, is more robust, but too computationally expensive to be applied in practice; on the other hand, AES approximates the former procedure by directly assuming that easier training examples will be learnt earlier on in the training procedure. The proposed technique is shown to calibrate the confidence scores obtained from state-of-the-art approaches for training deep nets, resulting in substantial performance improvements with respect to the proposed E-AURC metric. ",0.183206106870229,0.15384615384615385,0.1672473867595819
1387,SP:81b19cb59aad98ed3845ab403a9468d9f7bb1445,This work explores a rule learning approach (R5) for 2 relation prediction tasks (CLUTRR and GraphLog). The proposed approach starts by finding connecting paths between the two query entities. Then it recursively merge relation pairs until it consists of a single relation output. The merging process is controlled by a policy/value network trained with episodic rewards. The rules are induced whenever the output relation matches the gold relation -- in a fashion similar to that of curriculum learning.   Experiments show that R5 generalizes better than previous approaches such as Graph Attention Networks (GAN) and Conditional Theorem Provers (CTPs) especially when generalizing to paths longer than those from the training set. ,"This paper presents a novel method for rule induction. The main idea is to apply reinforcement learning in the task of relational pathfinding within a finite Herbrand base. The reinforcement learner uses MCTS to find the best routes to establish the path in between the two arguments of training examples, while the useful actions (which are length-two relational paths) are maintained in a hash table as the induced ruleset. Experimental results has shown the effectiveness of the proposed method.",0.14545454545454545,0.2,0.16842105263157894
1388,SP:81cd76230b5fb152f865202149938069ef659ae7,"In this paper, the authors mitigate the data-hungriness of the CLIP model. The authors propose three directions: single-modality self-supervision; multi-view multi-modality contrastive learning, and nearest-neighbor supervision. With the proposed three components, the authors can achieve better or comparable results with CLIP with more than 4x fewer data.","The paper proposes DeCLIP to further utilize the data potential by adding three training objectives to CLIP pre-training: 1) inspired by SimSiam and BERT, self-supervised objectives are added to both image and text; 2) they generate different views for both images and text, and apply contrastive objectives; 3) they sample neighbor text as additional positive examples.  DeCLIP improves data efficiency. With web-crawled data, DeCLIP outperforms CLIP counterparts with 4.5x smaller amount of data. In addition, while introducing addition objectives and especially different views increases per-batch compute time by 1.5x, the authors show that DeCLIP still outperforms CLIP when given the same compute time budget.  ",0.20754716981132076,0.1,0.13496932515337423
1389,SP:81d02cae96de58b1b7c74e7522cc82f61b782417,"This paper introduces DiffSim, a programming language for high-performance differentiable physics simulations. The paper demonstrates 10 different simulations with controller optimization. It shows that the proposed language is easier to use and faster than the other alternatives, such as CUDA and TensorFlow. At the end, the paper provides insightful discussions why the gradient of the simulation could be wrong.","This paper describes DiffSim, a differentiable programming system for learning with physical simulation. The system (built on the Taichi system) allows users to specify a forward simulation in a Python-like syntax, after which the program is compiled and iteratively run in both forward-mode and gradients computed for system parameters and controllers, as desired. A variety of simple simulations are included, demonstrating that the automatically generated CUDA code runs as fast as hand-written CUDA code (and noticeably faster than TensorFlow or PyTorch implementations), while requiring far fewer lines of code. The final section details two issues--time of  impact errors due to discrete time intervals and gradient explosions with long time horizons--and some potential solutions.",0.2833333333333333,0.1440677966101695,0.19101123595505617
1390,SP:81d2d5d9bfe2974415843ec016c72b80a761a20e,"This paper proposes a Bayesian optimization algorithm in the context of federated learning. The whole framework is built on top of generalized Bayesian learning. To overcome the locality of clients' distributions, the authors propose their solution as an integration of Partitioned Variational Inference (PVI) and Stein Variational Gradient Descent (SVGD). Numerical experiments have been conducted on a synthetic dataset and some standard benchmark datasets, and evaluated on both regression and classification tasks.","This paper proposes distributed SVGD, which maintains N particles both on the server and on the client. The communication between the server and the client is conducted by uploading/downloading these N particles. The learning of local client is formulated as inferring corresponding tilted distribution. Experiments are conducted on synthetic Gaussian 1D mixture, Bayesian logistic regression on Covertype and Twonorm dataset and Bayesian NN on the UCI dataset.",0.2222222222222222,0.23529411764705882,0.22857142857142856
1391,SP:81eb96286ff437475310246667130918695e12b6,"This paper’s main idea is refreshing and attractive: proposing a defensive method called nasty teacher, to avoid knowledge leaking or cloning through KD. A nasty teacher model is a specially trained network that yields nearly the same performance itself, while significantly degrading the performance of student models learned by imitating it. The standing point for machine learning IP protection is novel and hasn’t seen many discussions before. The introduction section motivated the study clearly and nicely. The method and experiments demonstrate a promising first step towards protecting machine learning IPs. ","This paper explores an interesting and novel research problem: how to make a teacher model undistillable. This can be a promising countermeasure to model extraction/stealing. The proposed Nasty Teacher approach is a two stage method, which first trains a good teacher network, then utilizes a self-undermining KD strategy to further distill the good teacher network to a bad one. Overall, this  Nasty Teacher approach can reduce the performance of the student network by ~5% in most cases. Although the performance decrease is not huge, the proposed approach is promising and can be a very useful baseline for this new research direction. A set of ablation and understanding experiments have also been conducted to support the effectiveness of  Nasty Teacher. ",0.25,0.19008264462809918,0.21596244131455397
1392,SP:81ec2c343c6a792251a62e680683c75ef0662ad6,"The paper attempts to understand the latent structure underlying knowledge graph embedding methods. The work can be seen as an extension of understanding of PMI-based word embedding methods. They categorize knowledge graph relations into three categories based on their relation conditions: Relatedness (R), Specialisation (S), and Context-shift (C). For each category, they evaluate a representative of different types of knowledge graph embedding methods. Through results, they demonstrate that a model’s ability to represent a specific relation type depends on the limitations imposed by the model architecture with respect to satisfying the necessary relation conditions.","This paper proposes to provide a detailed study on the explainability of link prediction (LP) models by utilizing a recent interpretation of word embeddings. More specifically, the authors categorize the relations in KG into three categories (R, S, C) using the correlation between the semantic relation between two words and the geometric relationship between their embeddings. The authors utilize this categorization to provide a better understanding of LP models’ performance through several experiments.",0.18556701030927836,0.2465753424657534,0.21176470588235294
1393,SP:81f57d07fde2be3b6443182c11b29f45c222ea37,"The paper proposes a novel way to formulate intrinsic reward based on optical flow prediction error. The prediction is done with Flownet-v2 architecture and the training is formulated as self-supervision (instead of the ground-truth-based supervised learning in the original Flownet-v2 paper). The flow predictor takes two frames, predicts forward and backward flows, then warps the first/second frame respectively and compares the warped result with real frame. The comparison error serves as the intrinsic reward signal. The results are demonstrated on 7 environments: SuperMario + 5 Atari games + ViZDoom. On those environments, the proposed method performs better or on-par with ICM and RND baselines. ","The authors study the problem of exploration and exploitation in deep reinforcement learning. The authors propose a new intrinsic curiosity-based method that deploys the methods developed in optical flow. Following this algorithm, the agents utilize the reconstruction error in the optical flow network to come up with intrinsic rewards. The authors show that this approach boosts up the behavior of the RL agents and improves the performance on a set of test environments. ",0.1559633027522936,0.22972972972972974,0.18579234972677594
1394,SP:81fbf84fa8d4abe4588fc5a0d711003b07667e78,"The author proposes a novel deep neural network, which leverages the intrinsic knowledge of low-level vision and Taylor’s Approximations, for the image restoration tasks. The author found that the main part and derivative part of Taylor’s Approximations takes the internal similarity as the high-level structure and spatial details of image restoration, respectively. From this, the author breaks down the restoration process into two manageable steps, corresponding to the mapping function and derivative function, respectively. The proposed framework is orthogonal and can be easily integrated into existing deep learning-based methods. The idea of using Taylor’s Approximations to guide deep network design for image restoration is quiteThe limitation and potential negative societal impact of their work have been discussed in their paper. interesting. ","This paper aims to develop an image restoration framework through a combination of Taylor’s Approximation and deep learning to break the entire recovery process into two manageable steps. Specifically, the former learns high-level contextualized information, and the latter combines it with the degraded input to progressively recover local high-order spatial details. Several promising methods are integrated with the proposed framework and achieve some improvement. Ablation studies about Taylor’s order are also conducted to provide a comprehensive analysis. ",0.16535433070866143,0.25925925925925924,0.20192307692307696
1395,SP:8208b999d9994f1bbee5f5c4806cc4c7b8b1ea8f,"This paper proposes two improved strategies for fine-tuning XLM (a multilingual variant of BERT) for cross-lingual NLI. First of all, it shows that fine-tuning a single model on the combination of all languages (the original English data from MultiNLI and their MT translation into the rest of languages) performs better than fine-tuning a separate model for each language. Furthermore, they show that minimizing the L2 distance between the English training sentences and their MT translation into the rest of languages, which does not explicitly use any labels in the foreign languages and is presented as a way of performing cross-lingual knowledge distillation, also performs better than zero-shot transferring a regular model fine-tuned in English.","First, the authors propose to train a model for natural language inference (NLI) on multiple languages simultaneously. In particular, they translate English examples into all target languages and fine-tune a pretrained language model on all thereby obtained data at once. This is different from the previous state-of-the-art approach which consisted of, after translating from English into target languages, fine-tuning one NLI model for each language individually. The authors show that their approach is superior to training individual models for each language. For evaluation, XNLI is used.",0.19834710743801653,0.26373626373626374,0.22641509433962265
1396,SP:820a879346c3ba370348f1086dab5b9c256175e9,"The paper proposes a new generative model for unsupervised learning, based on a diffusion random walk principle inspired by the manifold learning literature. The basic idea is to (probabilistically) map points to a latent space, perform a random walk in that space, and then map back to the original space again. Learning of the suitable maps is achieved by casting the problem in a variational inference framework.","The paper studies the problem of density estimation and learning accurate generative models. The authors start from the observation that this problem has been approaches either using variational inference models, that scale very well but whose approximations may lead to degenerate results in practice, and diffusion maps, that scale poorly but are very effective in capturing the underlying data manifold. From here, the authors propose integrating the notion of random walk from diffusion maps into VAEs to avoid degenerate conditions. The proposed method is first defined in its generality, a practical implementation is presented, theoretical guarantees are provided, and empirical evidence of its effectiveness is reported.",0.208955223880597,0.1320754716981132,0.16184971098265893
1397,SP:8214a2ec3d58d4fef82265c8f99e1cbb830873aa,"This paper presents audio-visual object classification and motion prediction work on a novel dataset of 60 different objects rolling around in a bin tilted to and fro by a robot, with video and 4-channel audio recordings of the object impacts.   The data is rather novel, is large enough to do ML (around 17 hours of eventful audio/video) and is to be publicly released.  The model architectures  are not of theoretical novelty.   However, the experiments are somewhat interesting.  It was found that the audio contains significant object classification information.  The audio was also good for predicting the trajectory of the object.  This might not be surprising since the microphones are geometrically arranged and may contain directional information along with information about velocity and/or distance traveled.   Overall the experiments are rather thin with only a few experimental results.   A more thorough undertaking might be expected for ICLR papers, with more novel theoretical development and more extensive experiments.  ","This paper studies the role of audio in object and action perception, as well as how auditory information can help learning forward and inverse dynamics models. To do this, the authors built a 'tilt-bot', which tilts a box and the object within to collect data (sound & vision) of object interactions. The authors then tested how audio embeddings help object recognition and forward model prediction. ",0.1069182389937107,0.26153846153846155,0.15178571428571427
1398,SP:821a79f69a9c3a8e5aea0cba53e1f1c5b7d9fe49,"In this paper, a (variance-based) risk-aware transfer method for multi-task RL is proposed.  In the theory part, GPI and GPE (and the notion of successor features) are extended to entropic utility (for the risk-aware transfer).  Based on the results in the theory part (specifically, the GPE/successor features parts), the successor feature for entropic utility is proposed to use for risk-aware setting.  In the experiment part, the proposed method is evaluated in the Four-room and Reacher environments.  ","This paper considers safety in transfer RL, and proposes a method, called Risk-aware successor features, that exploits the task structure to avoid risks and achieve task generalization between tasks with shared dynamics and different goals. The entropic utility is introduced to represent risk-awareness and specialized to entropic Q-value with bellman update. Risk-aware GPI and GPE are extended from GPI, GPE, and proved its convergence. Experiments on two domains show the method outperforms previous works.",0.21686746987951808,0.23076923076923078,0.22360248447204972
1399,SP:821ad1017b8aa20f5b6bc3fcc56844ae87d983e2,"This paper presents an auto-regressive method for generating layouts by sequentially synthesizing new elements. The architecture is not dramatically new, but it is well-justified and analyzed, and there are some interesting tweaks. The results are strongest in that they show good performance of essentially the same architecture and hyperpameters across quite different domains: to my knowledge such variety has not really been demonstrated for any of the assembly-based generative models I'm familiar with.","This work proposes a model to generate scene layouts by treating the scene as a composition of primitives, such as instance class, coordinates or scales. The model is a Transformer architecture, that attends on all previously predicted or given instance primitives. The probability of a scene layout is defined with a joint distribution, modeled as the product of conditional distributions using the chain rule. The model predicts an end of sequence token, that allows the generated layouts to have variable size. Moreover, the model allows to either complete an existing incomplete layout or to generate one from scratch. The paper presents experiments in four datasets, spanning different data domains, including 2D and 3D data.",0.14285714285714285,0.09649122807017543,0.11518324607329843
1400,SP:82228b43db88274a90aa34ff6b67f53bed74b539,"This paper studies the variance of stochastic gradient in SGD conditioned on the initialization point. It shows that the variance of stochastic gradient is a decreasing function of minibatch size for linear regression and deep linear network. Compared with previous works that show similar the results for one step in SGD, the results in this work only rely on initialization point. ","The paper shows that the variance of the gradient has an inverse dependence on the batch size in linear networks, subject to the knowledge of the initial weights. The main novelty of the paper is the computation of an exact dependence between batch size and variance of the gradient in the linear regression setting. In addition to that, the authors conduct a lot of experiments involving non-linear networks and real-world datasets, that show the inverse dependence of the variance of gradient and batch size throughout the training.",0.3114754098360656,0.21348314606741572,0.25333333333333335
1401,SP:823860fad022b8abde97b597f8b3881453489dc1,"This paper proposes a novel loss function to account for imperceptible, geometry-aware deformations of point clouds. The loss is used in two cases: generating adversarial point clouds to attack representative models of point set classifiers, and generating cooperative point clouds to improve classification confidence or accuracy. The combined geometry-aware objective is well-introduced, which mainly contains Chamfer distance term, Hausdorff distance term and local curvatures consistency term. The authors apply the geometry-aware objective to generate adversarial point clouds by adopting the framework of C&W attack. For generating cooperative point clouds, the authors introduced a training procedure to reduce the overfitting of the deformed point clouds. Most of the experiments are well-conducted, and demonstrate the effectiveness of the proposed loss function. ","This paper describes a new targeted adversarial attack against 3D point cloud object classifiers that is robust to several countermeasures. The attack finds a point of the target class that is close to the original point cloud in terms of a more complicated metric that combines the Hausdorff distance, the Chamfer distance, and a curvature distance measure. The proposed attack is 100% successful against several different state of the art classifiers on a dataset of 1024-point clouds sampled from 25 instances of CAD models of each of 10 common objects without any countermeasures.  When the Random Removal countermeasure is used, the attack is still successful almost 50% of the time even when 256 points are removed as compared to two other attacks that are only ~17% successful. When the SOR countermeasure is used, the attack is 60% successful when 64 points are removed as compared to <1% for the comparison attacks. The attack can also be used in reverse for data augmentation in training and can cut error rates almost in half.",0.208,0.15028901734104047,0.174496644295302
1402,SP:8268301968d5bb106483c7603117df2335d64610,"MED-RL This paper studies foster diversity in ensemble of DRL networks by regularization methods. The paper is an empirical one and compared five ensemble methods with and without their diversity algorithm in six Mujoco and six Atari games, and showed some results.  The algorithm proposed is a modification of MaxMinDQN by Lan et.al. with a regularization. ","The paper considers a problem of ensemble-based deep RL methods that ensembles of critic networks converge to the same point in the representation space. To address it, the paper proposes a regularization technique that forces representations of a critic network to be dissimilar from those of other critic networks in the ensemble. It is empirically shown that this regularization technique improves the sample efficiency and asymptotic performance of baseline algorithms.",0.1896551724137931,0.15492957746478872,0.17054263565891473
1403,SP:8283eb652046558e12c67447dddebcb52ee9de94,"The paper studies self-supervised learning from very few unlabeled images, down to the extreme case where only a single image is used for training. From the few/single image(s) available for training, a data set of the same size as some unmodified reference data set (ImageNet, Cifar-10/100) is generated through heavy data augmentation (cropping, scaling, rotation, contrast changes, adding noise). Three popular self-supervised learning algorithms are then trained on this data sets, namely (Bi)GAN, RotNet, and DeepCluster, and the linear probing accuracy on different blocks is compared to that obtained by training the same methods on the reference data sets. The linear probing accuracy from the first few conv layers of the network trained on the single/few image data set is found to be comparable to or better than that of the same model trained on the full reference data set.","This paper explores self-supervised learning in the low-data regime, comparing results to self-supervised learning on larger datasets.  BiGAN, RotNet, and DeepCluster serve as the reference self-supervised methods.  It argues that early layers of a convolutional neural network can be effectively learned from a single source image, with data augmentation.  A performance gap exists for deeper layers, suggesting that larger datasets are required for self-supervised learning of useful filters in deeper network layers.",0.1554054054054054,0.2987012987012987,0.20444444444444446
1404,SP:82afe0f6d661432c3124eb14e9a83699e251143d,"In this paper, the authors developed GCN on multi-relational graphs and proposed CompGCN. In comparison with existing multi-relational GCN, CompGCN leverages insights from knowledge graph embedding and learns representations of both nodes and relations, with the aim to alleviate the problem of over-parameterization. Moreover, to improve the scalability w.r.t. the number of relations, the initial relation representations are expressed as a linear combination of a fixed number of basis vectors. In contrast to existing works, the basis vectors are only defined for initialization but not for every GCN layer. The authors also compared the proposed CompGCN with other existing GCN variants and summarized the relationships between CompGCN and other models. In the experiments, three tasks including link prediction, node classification and graph classification were performed to evaluate the performance of the proposed method. By comparing with existing methods, the effectiveness of the proposed method was demonstrated.","This paper proposes a graph convolutional  network based model for joint embedding of nodes and relations in a multi-relational graph. The framework comprises of node/relation embedding, nonparametric compositional operation as in knowledge graph embedding, and finally convolution operation with direction specific weight matrices. The performance is evaluated on link prediction, and node/graph classification tasks.",0.13245033112582782,0.3508771929824561,0.19230769230769232
1405,SP:82b3049ba37482bbbd54b7e88daf183a5a06962e,"The paper attempts to investigate how memory architecture affects learning performance of POMDP agents. It focuses on a very simple two-arm bandit problem with two hypotheses for their probabilities. Two memory structures are considered: random access memory and memento memory. For each memory structure, one policy is provided with a kind of asymptotic optimal performance. Simulation results for simple gradient based learning algorithms are shown under the two memory structures. ","This paper tackles a two-armed bandit problem (of means $Ber(1/2+\mu)$ and $Ber(1/2-\mu)$, respectively) when memory is limited. Specifically, they model this problem as a POMDP (or, alternatively, hypothesis testing), where the hidden state determines the mean of each arm. The author claim that this simple model might provide some insights on memory architecture in general POMDPs (namely, how the history representation affects the learning process). The authors describe two memory architectures:  (i) A general finite-state machine ('RAM'), which transitions based on the played arm and its reward. Specifically, they focus on the column of confidence policy (CCP). The memory structure - a chain where each end of the chain represents an arm. $+1$ reward moves the state towards an arm and $-1$ moves it away, except for the end states that have low escape probability. The policy - playing the arm that its end-state closer to the current state.   (ii) History is presented as a memory buffer with the last arm plays and their rewards('Memento'). In this case, the authors present a policy that plays the same action sequence cyclically ('necklaces'). These cycles are chained in a Gray-ordering and the policy moves between cycles (change one action) only if a full cycle indicates that this switch is beneficial.  The authors analyze the (stationary) probability of playing the worse actions and show that the RAM model enjoys better (lower) probability. Finally, the authors try to learn a policy when relying on either RAM or Memento architectures. They showed that a random initialization, the Memento memory performs better, while imposing structural constraints that correspond with the suggested policies in (i) and (ii) make RAM memory perform better.",0.23943661971830985,0.05985915492957746,0.09577464788732394
1406,SP:82d842008ef479c32545afd952f9d7db15a0baf5,"This paper introduced an alternative sampling method, with an application on generative models, by convolving an unknown distribution $p_x$ with a factorial kernel called multi-measurement noise model (MNM). The resulting M-density $p_y$ is smoother (easier to sample from), and is permutation invariant. Two factorial kernels, Poisson and Gaussian MNMs, are introduced for the convolution, and can be connected to Bayes estimator, and the learning of parametric energy and score functions. Two parameterization schemes are proposed for modeling the energy and score functions of the Gaussian M-density respectively. Empirical results on FFHQ-256 dataset are very impressive. The main contribution is the usage of factorial kernels, which is a direct extension of smoothing a density in non-parametric density estimation, and is not used for generative models before.","Given $n$ independent samples $x_i$ in a space of dimension $d$ drawn from an unknown distribution $p(x)$, this paper is interested in drawing new samples independent of $x_i$ but coming from the same unknown distribution p(x).   The classical approach consists of learning $p(x)$ from $x_i$ (i.e., approximated by $\tilde{p}(x)$) and sampling new points according to the approximated version $\tilde{p}(x)$, which remains a difficult task given sometimes the highly non-convex character of $p(x)$.   For these reasons, the authors propose to noise the data $x$ using $M$ different channels whose noise levels are chosen to obtain data denoted $y$. Since the level noise of each channel is known, this allows using a Bayesian estimator $\hat x(y)$ to find the samples in the original space. The advantage of this approach is that the Bayesian estimator depends on the density $p(y)$, which allows, thanks to a chosen parameterization of $p(y)$ (which therefore leads to a parametrization of $\hat{x}(y)$), to find the optimal parameters through a least-square objective by minimizing $\|x-\hat{x}(y)\|^2$ on the training data. The Bayesian estimator thus allows generating new samples using the optimized density $p^{\star}(y)$ with the corresponding optimal parameters.   The authors make a connection between the proposed method and some methods of the literature constituting new intuitions, different views of algorithms proposed in the literature. The experiments conducted suggest the efficiency of the algorithm to generate the most diverse samples",0.21212121212121213,0.11023622047244094,0.14507772020725387
1407,SP:82efc301ca1c955bf0ed5531a876c1fbd2083e81,"This paper introduces actions as a co-predictor of next-states and the predicted (from current and next state) in the context of (model-based) RL. In addition they incorporate the idea of using a JSD-based objective do prediction (as the Deep InfoMax paper), which is novel to RL. The enforce a linear structure between current / next states and actions with an additional sparse nonlinear term computed from both current states and actions. From this, they are able to quantify the amount of novelty in the representation space as a measure of exploration, which can be used as an intrinsic reward.","The paper proposes an approach for exploration via reward bonuses based on a form of surprise. The surprise factor is based on the next state of a particular transition, and the error in the embedding space to satisfy a linear dynamics formulation. The embedding space of the states and actions are optimized to increase the mutual-information in predicting next state, and current action - encouraging meaningful embeddings with more training, and hence gradual fading away of the extrinsic rewards.",0.19607843137254902,0.25316455696202533,0.22099447513812157
1408,SP:82f5968efa5604cda6804cbd87b1ebb6582d1b4e,"The task of identifying a physical system on a graph is addressed. While the main part of the to-be-estimated model is assumed to be linear, the proposed model needs a nonlinear part (which is modeled by a neural net) due to the presence of unobserved nodes. The authors use a combination of a sparse linear model and a neural net, which is basically the same as the model in [Li & Weng, KDD 2021]. They consider some regularization terms to maximize the use of the physics part of the model. They examine the performance of the proposed method on several datasets.","The paper proposes ATN to model and identify physical systems. Here, the physical systems are grids consisting of measurement sensors: because the sensor configuration is not perfect, there can be unobservable parts in the grid system. The authors assume that there are physics bases that can represent the output with a linear mapping. Thus, they firstly use a linear LASSO regressor (PNN in the paper) that transforms observable physics bases to the output. The possible remainder (due to the noise or unobservable physics) is modeled via a more complicated neural network (VNN in the paper). These two networks are integrated into a single skip-connection block. They are trained by MSE, with enforcing the PNN part predict the output mostly, to exploit the bias of physics. In addition, the authors suggest the use of siamese networks that measure the distance between PNN and VNN: then an adversarial learning loss is added to guarantee the outputs of PNN and VNN to be far from each other and play their respective roles more concisely. ATN outperforms its counterparts for some physical system datasets.  ",0.2549019607843137,0.143646408839779,0.18374558303886926
1409,SP:8308cf00214c52728e41e952dc10bd51e7226bf7,"It is very interesting and attractive to investigate the algorithmic instabilities for the famous Nesterov accelerated gradient descent method. This concepts  are very related to ordinary differential equation, such as initialization stability corresponding to continuous dependence of solution about initialization for long time. The uniform stability is for the objective function. The authors tries to use the so-called uniform stability to describe the NAG under noise cannot obtain the desired result.   The new concept --- uniform stability is a novel point.  ","This paper studies the stability of Nesterov accelerated gradient in the initialization and in the sense of uniform stability. The authors prove lower bounds on the stability parameters, that diverge exponentially in the number of iterations, by building clever one-dimensional adversarial examples. This proves that in the general convex smooth case, Nesterov accelerated gradient can be a lot more instable than in the quadratic case. ",0.18518518518518517,0.22727272727272727,0.20408163265306123
1410,SP:8323e9c866137e2f5c7a692bbeb89cce8d2fd6df,"This paper proposed a new network pruning method that generates a low-rank binary index matrix to compress index data, and a tile-based factorization technique to save memory. The binary index can achieve larger compression ratio than the CSR index, and the  low-rank binary index can further reduce memory usage. The results for various networks, including DNN, CNN and LSTM, have shown the effectiveness of the propsoed method. The paper is well-written and easy to follow.","The paper addresses the problem of reducing the computational complexity of neural network pruning. Main idea is to compute a low-rank approximation of the binary index matrix used to represent the structure of the pruned network. In the considered setup, the binary index matrix is the (sparse) boolean matrix associated with the nonzero network's weights. As low-rank decomposition of binary matrices is a hard problem, the authors propose a method to approximate the solution by computing a more standard non-negative matrix factorization. ",0.26582278481012656,0.2441860465116279,0.2545454545454545
1411,SP:834027963c400b77f2d47151b621b666cea971a3,"This is a theoretical work on understanding the intrinsic limits of various data sources that are used for reward learning in RL. In particular, by considering the infinite data limit of the data source, they study the level of reward ambiguity that can be obtained for a given downstream task. For example, for the expert behavior data source, they characterize the reward transformations that are determined by the optimal Q-function. Similar attempts have been made previously for specific data sources and specific planning algorithms (Ng & Russell, 2000). However, this work makes substantial contributions by conducting this study in a unified and rigorous way for variety data sources and downstream tasks. ",This paper characterizes the partial identifiability of data sources and the reward function. Then it analyzes the impact of this measure on the optimum and the algorithms. Some implications are given.,0.0990990990990991,0.3548387096774194,0.15492957746478872
1412,SP:8347824ba3fc1c854115f6a776ac159d9978071a,"This paper focuses on federated learning on non-IID features. This is a crucial problem when applying federated learning. The authors propose a new federated learning scheme, called ADCOL (Adversarial Collaborative Learning) for non-IID features. Specifically, the server is designed to train a discriminator to distinguish the local representations from local parties. While the local parties train the local models and expect the representations not to be distinguished by the discriminator. Authors conduct experiments on multiple parties where the data have heterogeneous features but share the same labels and label distribution and the results clearly show the effectiveness.","This paper studies federated learning when different devices have non-iid features. To address the heterogeneity problem,  it proposes a federated learning scheme called ADCOL based on adversarial learning.  In ADCOL, the devices transfer local representations to the server while sending the discriminator to the devices. The server aims to distinguish the devices' local representations, while the devices aim to train local models that generate non-distinguishable representations. To make the representations non-distinguishable, ADCOL adds an additional regularization term to the devices' loss functions. This practice aims to maximize the probability that the discriminator cannot distinguish the local representations. The experimental results show that the proposed method has some advantages over several baselines.",0.3939393939393939,0.34210526315789475,0.3661971830985915
1413,SP:834881c613fe0577da917a8eb0104a37cb65a6bb,The author(s) propose a quickest change detection technique under known parameter scenario. They use a Markovian dynamics to generate the pre and post change-point distributions and use a Shirayev test-statistic based on the asymptotic behavior of the optimal delay under know parameters. The proposed methodology is validated on synthetic data and a multitask reinforcement learning example. There are several issues which restricts the paper to reach an optimal level. These are highlighted below,"This paper studies the quickest change detection for Markovian data, when both the parameters of pre- and post-change distributions are unknown. The main contribution is a scalable algorithm that sequentially estimates the unknown parameters and plug-in to classical detection schemes to get the stopping rule. A notable feature is that this is a joint estimation and detection framework. And the authors incorporate several tools, like SGD, annealing, penalization, into the detection task, which turns out to have good performance compared with existing benchmarks. ",0.2631578947368421,0.23529411764705882,0.24844720496894407
1414,SP:834d63ae7b52ef284c72e35188bb5722141fcd5d,"This paper defines a new task for clinical data by combing multi-modal and multi-task settings into one task. It collects a dataset called M3 as the benchmark for the multi-modal and multi-task benchmark in the clinical domain. The dataset has 6 prediction tasks, i.e., in-hospital mortality, decompensation, length of stay, phenotyping, readmission, and long-term mortality, and it has 4 modalities, i.e., physiological time series, clinical notes, tabular data, and waveforms. Specifically, this paper also provides a multi-modal multi-task model where the time series data are encoded by LSTM, clinical notes are encoded by text CNN and tabular data are also encoded by existing methods.  In experiments, the authors conduct an ablation study and compare the proposed method with the method of Harutyunyan et al. and Khadanga et al.","This paper discusses the Multi-Modal Multi-Task MIMIC-III (M3) dataset and benchmark, which extends previous efforts in this space to provide a benchmark on the MIMIC-III dataset. In particular, this work considers the inclusion of multiple modalities, including time series, clinical notes, ECG waveforms, and tabular input. It also defines six clinical tasks, some of which overlap with existing efforts and others which appear to be new.",0.18115942028985507,0.35714285714285715,0.2403846153846154
1415,SP:8357fc2c4234854bf476afd5305b1191ef56c11a,"This paper presents a multi-frame super-resolution method applied to satellite imagery. It first estimates a reference image for the multiple input LR images by median filtering. Then it pairwise encodes the reference image and each of the multiple images in a recursive fashion then fuses the corresponding feature maps with residual blocks and bottleneck layers until only one feature maps for the entire multiple images obtained. In other words, LR images are fused into a single global encoding. Then, it applies a standard upsampling network to obtain the super-resolved image this image is fed into a network that estimates only the translational shift, and the shifted image with the estimated translation parameters finally resampled. ","This paper proposes an end-to-end multi-frame super-resolution algorithm, that relies on a pair-wise co-registrations and fusing blocks (convolutional residual blocks), embedded in a encoder-decoder network 'HighRes-net' that estimates the super-resolution image. Because the ground truth SR image is typically misaligned with the estimation SR image, the authors proposed to learn the shift with a neural network 'ShiftNet' in a cooperative setting with HighRes-net. The experiments were performed on the ESA challenge on satellite images, showing good results.",0.18803418803418803,0.25287356321839083,0.2156862745098039
1416,SP:8361d709b85b1c717e2cf742dab0145fae667660,"This paper explores how graph neural networks can be applied to test satisfiability of 2QBF logical formulas. They show that a straightforward extension of a GNN-based SAT solver to 2QBF fails to outperform random chance, and argue that this is because proving either satisfiability or unsatisfiability of 2QBF requires reasoning over exponential sets of assignments. Instead, they show that GNNs can be useful as a heuristic candidate- or counterexample- ranking model which improves the efficiency of the CEGAR algorithm for solving 2QBF.","This paper investigated the GNN-based solvers for the 2-Quantified Boolean Formula satisfiability problem. This paper points out that GNN has limitations in reasoning about unsatisfiability of SAT problems possibly due to the simple message-passing scheme. To extend the GNN-based SAT solvers to 2-QBF solvers, this paper then turns to learn GNN-based heuristics that work with traditional decision procedure, and proposes a CEGAR-based 2QBF algorithm.",0.1686746987951807,0.19718309859154928,0.1818181818181818
1417,SP:836cc391b0123c787ff4871813ed9f739045330f,This paper discusses the use of a reconstruction network which is fed an internal representation of a deep network and is trained to reconstruct the input. The classification and reconstruction networks are trained simultaneously with a combined loss function. Various experiments are carried out to test whether this approach can help investigate adversarial examples and the quality of learned features for transfer learning.,"Claims: The authors present perceptual regularization as a method for learning a visualization of deep representations for promoting interpretability and understanding of vulnerability to adversarial attacks. Second, they show their method can explain negative transfer to new tasks. Finally, they show that the representations learned with this regularization method transfer to unseen tasks better than without the reconstruction regularization.",0.15873015873015872,0.1694915254237288,0.16393442622950818
1418,SP:836de33d05125c0f6f805a38d340f6ceae4f22d7,"The paper describes an approach to analyze radio data with ML-based speech keyword techniques. The authors identify keywords related to agriculture and build a model that can automatically detect these keywords of interest. Their contribution is the proposed model relies on relatively simple neural networks (15-layer 1-D CNNs) to achieve keyword detection of low resourced language (e.g., Luganda). Therefore, they are capable of monitoring food security concerns in rural areas.",This paper presents a very interesting application of speech keyword spotting techniques; the aim is to listen to continuous streams of community radio in Uganda in order to spot keywords of interest related to agriculture to monitor food security concerns in rural areas. The lack of internet infrastructure results in farmers in rural areas using community radio to share concerns related to agriculture. Therefore accurate keyword spotting techniques can potentially help researchers flag up areas of interest. The main engineering challenge that the study deals with is the fact that there isn’t a lot of training data available for languages like Lugandu.,0.21621621621621623,0.1553398058252427,0.1807909604519774
1419,SP:8396c93d47a3bad4245917bc5d84713c9c6fa039,"The authors propose a probabilistic framework to improve the classification accuracy in instances when there exists missing data in the multi-modality datasets (where one of the modalities is the predictive label; however, this label is not assumed missing). To this end, they propose a generalized softmax function as the joint distribution of all modalities and the label, from which conditional distributions are derived, for computing the maximum likelihood estimate (MLE). Experimental results on eNTERFACE and RAVDESS datasets demonstrate improvements in classification accuracy over baselines. In addition, the authors investigate the influence of the influence of the backbone models and the fusion functions. ","This submission proposed a maximum likelihood estimation framework combined with a generalized softmax function to resolve multimodal emotion recognition with missing modality. Two emotion recognition datasets are used in experiments to make comparison with several baseline methods. The results suggest that the proposed approach outperforms these compared methods. Moreover, according to the authors, the end-to-end nature of this framework makes it more efficient than previous works.",0.1262135922330097,0.19117647058823528,0.15204678362573099
1420,SP:839f449191ae3ff1016d4321d9e1926c5f883a78,"This paper studies the label solicitation strategy in active learning. In particular, it focuses on the expected loss reduction (ELR) strategy, analyzes its problem, and modifies the original ELR method to make sure the active learner converges to the optimal classifier along learning iterations. The paper provides theoretical guarantees on the new method’s convergence. In the experiment, the proposed method is evaluated on synthetic data and UCI data. The improvement margin over the existing method is very limited.","This paper provides an interesting algorithm to address the previous Bayesian active learning query strategy in (binary) classification. By the simple modification, the algorithm can overcome the drawbacks of ELR in the convergence to the optimal classifier parameterized by $\theta_r$. In experiments, the proposed algorithm can achieve the advantages of ELR and BALD simultaneously. ",0.22784810126582278,0.32727272727272727,0.26865671641791045
1421,SP:83b01ca44305349cd2c83fe8df54d4e46539f1d8,The paper proposes to use the HSIC metric in order to impose view feature dependency on the image identity during self-supervised learning (SSL). The authors made non-trivial efforts in both deriving the SSL-HSIC approach and theoretically linking SSL-HSIC with the existing mainstream SSL approaches. Empirical results show that the method offers competitive results. ,"  This paper proposed a new loss function for self-supervised learning using the Hilbert-Schmidt Independence Criterion (HSIC) to measure the kernel space dependence between the learned latent representation of images and their augmented versions. The main contribution is that authors demonstrated the connections between the proposed framework and InfoNCE, metric learning and Maximum Mean Discrepancy, respectively. An algorithm with random fourier feature kernel estimation is proposed and the method is shown to have comparable performance with state-of-the-art self-supervised learning (SSL) paradigms. The sample complexity and bias analysis for kernel estimation are provided. ",0.22807017543859648,0.13402061855670103,0.1688311688311688
1422,SP:83c5fa9ad4b7e0de17e75d4575316e84ad21a5b5,"The paper proposes learning a TSP solver that incrementally constructs a tour by adding one city at a time to it using a graph neural network and MCTS. The problem is posed as a reinforcement learning problem, and the graph neural network parameters are trained to minimize the tour length on a training set of TSP instances. A graph neural network architecture called Static Edge Graph Neural Networks is introduced which takes into account the graph of all cities in a given problem instance as well as the partial tour constructed so far in an episode. The network predicts probabilities for the remaining cities to be selected as the next city in the tour, which is then used to compute a value function that guides MCTS. Results on synthetic TSP instances with 20, 50, and 100 cities show that the approach is able to achieve better objective values than prior learning-based approaches. Applying AlphaZero-like approaches to TSP is an interesting test case for understanding how well they can work on hard optimization problems.","In this paper, the authors introduce a new Monte Carlo Tree Search-based (MCTS) algorithm for computing approximate solutions to the Traveling Salesman Problem (TSP). Yet since the TSP is NP-complete, a learned heuristic is used to guide the search process. For this learned heuristic, the authors propose a Graph Neural Network-derived approach, in which an additional term is added to the network definition that explicitly adds the metric distance between neighboring nodes during each iteration. They perform favorably compared to other TSP approaches, demonstrating improved performance on relatively small TSP problems and quite well on larger problems out of reach for other deep learning strategies.",0.14285714285714285,0.23148148148148148,0.17667844522968199
1423,SP:83c6819a4c6458305ec079213fb6fb3ffdcfdcb8,"This paper considers the support size estimation problem using a random sample from the unknown distribution and access to some predictor of the element frequency. Under that setting, the paper improves the estimator by Wu & Yang (2019) by refining the approximation interval promised by the predicted frequency. A theoretical upper bound on the sample complexity is proved in Theorem 1 using the proposed algorithm, and it is nearly optimal as shown by the lower bound in Theorem 2. The algorithm is empirically evaluated by both real and synthetic datasets. The empirical performance improves existing algorithms of WY and CR in most cases. ","Estimation of the size of the support of a distribution over a discreet domain is a fundamental problem. In the standard setting, this problem is theoretically well-understood with matching upper and lower bounds. The authors assume additional access to a constant approximation of the density function at each point, and then show that this can provably reduces the sample complexity. In particular, they offer matching upper and lower bounds in this setting. While the upper bound is a twist on the existing state-of-the-art method, the lower bound seem to deviate from that. ",0.21568627450980393,0.22916666666666666,0.22222222222222224
1424,SP:83cd863b7aa4f2820d7f6a79a79bcbbc92d64c21,"The authors present a method for generating sequences from code. To achieve this, they parse the code and produce a syntax tree. Then, they enumerate paths in the tree along leaf nodes. Each path is encoded via an bidirectional LSTM and a (sub)token-level LSTM decoder with attention over the paths is used to produce the output sequence.  The authors compare their model with other models and show that it outperforms them on two code-to-sequence tasks. An ablation study shows how different components affect the model's performance.","This paper presents a new code-to-sequence model called code2seq that leverages the syntactic structure of programming languages to encode source code snippets, which is then decoded to natural language using a sequence decoder. The key idea of the approach is to represent a program using a set of randomly sample k paths in its abstract syntax tree. For each path, the path is encoded using a recurrent network and concatenated with the embeddings of the two leaf terminal values of the path. The path encodings are then averaged to obtain the program embedding, which is then used to initialize a sequence decoder that also attends over the path embeddings. The code2vec model is evaluated over two tasks: 1) Code summarization: predicting a method’s name from its body, and 2) Code captioning: generating a natural language sentence from method’s body depicting its functionality. The code2seq model significantly outperforms the other baseline methods, and the ablation study shows the importance of various design choices.",0.3076923076923077,0.1686746987951807,0.21789883268482488
1425,SP:83ec0703579f5229b242bfdc2029dd916caffa75,The paper proposes a hybrid approach which combines evolution and RL. The key idea is to conduct tournament selection over a population of architectures with learned mutations. The mutations are defined as the output of an RNN controller which either reuses or alters the sequence descriptor of the parent at each step. The proposed hybrid architect is evaluated on both synthetic and text classification tasks and then compared against pure evolutionary and RL-based agents.,"The paper introduces a novel way to do architecture search that uses an RNN to guide the mutation operation. The method and the motivation of the idea as long with the related work are all clearly described. However, the experiments section does not show a big uplift of the method versus the baselines and the number of types of tasks is relatively small (artificial and text). ",0.22666666666666666,0.25757575757575757,0.2411347517730496
1426,SP:83f5e4ad9fa7ca35ada3a63eb113b1b1827b2926,"1. This paper proves that SGD converges to a global minimum in certain non-convex problems assuming the loss function satisfies a growth condition. The proof relies on assuming that the initial Jacobian matrix is non-singular and shows that it stays non-singular since SGD iterates remain close to the initialization.  2. The paper then applies the above analysis to a two-layer neural network and proves that a subquadratic scaling on the width is sufficient for global convergence assuming the minibatch size grows with the number of training samples. For constant batch size, it requires quadratic over-parameterization. Furthermore, an interpolation between subquadratic and quadratic scaling is given depending on the batch size. ","This paper proved that a two-layer neural network with smooth activation and proper initialization can converge linearly to a global minima of training loss using mini-batch SGD when the width is larger than $\Omega(m^2/\sqrt{b})$ where $m$ is the number of training data and $b$ is batch size. As the batch size increases, this provides an interpolation between the quadratic result for SGD and the sub-quadratic result for full-batch GD. To prove this result, the authors first provide a general convergence result for SGD on a particular class of functions and then apply this framework to 2-layer neural networks to derive the width requirement.",0.22608695652173913,0.23214285714285715,0.22907488986784144
1427,SP:8467ec8e80c64d6648e1053b1f7cb593de940132,"This work mainly focuses on designing a new dynamic network for large-scale image recognition problems. Specifically, the author discussed the weakness of the existing dynamic convolution operations, and based on the analysis the author proposed a novel framework with the name ODConv. Extensive experiments confirm the superiority of the proposed new framework.","The authors present ODConv, a type of dynamic convolutional operation. ODConv combines two prior ideas, i.e. (1) filter recalibration with attention in SENet and (2) additive kernels in CondConv/DyConv, and also generalizes to all remaining dimensions of convolutional filters. The authors propose to use ODConv as drop-in replacements for regular convolutions in standard CNNs. Experiments and analysis over several tasks demonstrate that ODConv has noticeable advantages over alternatives and offers a good tradeoff between performance and compute. ",0.1320754716981132,0.0875,0.10526315789473684
1428,SP:84d3ab8eb02111204e89559450fe3062212bcc9d,"The authors in this paper, inspired by the applications of min-max optimization in GANs, study the problem of min-max optimization for convex-concave functions. The main contribution of the paper is proving novel convergence results for Forward-Backward-Forward (FBF) algorithms as well as Optimistic Gradient Descent Ascent (OGDA) based on tools from monotone inclusion problems. Their convergence results cover both deterministic and stochastic settings and the rates of convergence for suitably chosen gap function are non-asymptotic. Finally, they apply their algorithms both on toy problems but also on training GANs on CIFAR-10.","This work studies minimax optimization (a.k.a saddle-point problems) with nonsmooth regularizers. By leveraging the monotone operator theory, the authors propose to use the forward-backward-forward method so as to avoids the notorious limit cycling problem. The classical FBF method requires two gradient evaluations per step, the authors introduce a new algorithm which reuses the past gradient in the same way as OGDA. In the setting of convex-concave minimax optimization, the authors claim to prove novel convergence rates for both methods. ",0.16494845360824742,0.18823529411764706,0.17582417582417584
1429,SP:852ee74381bfef42fbef5d0e9c474788793d384b,"The authors use transformers pre-trained on machine translation tasks on the integration and differential equation datasets proposed by  Lample and Charton (Deep Learning for Symbolic Mathematics, ICLR 2020). They show that pre-training on ""pure language"" tasks help models, in terms of learning speed, accuracy, and, to a lesser extent, out of distribution generalization. Pre-training on different language pairs, on the other hand, has little impact on performance.","This work investigate the problem of whether pretraining on language task such as machine translation could help with solving symbolic mathematics problems. Specifically they focused on solving symbolic integration and differential equations using the dataset similar to [Lample & Charleston, 2019]. The authors argued that finetuning a pretrained transformer model could get similar or better accuracy with fewer epochs. They then investigated the effect of the choice of language pairs and how the model works under domain shifts.  ",0.21428571428571427,0.19480519480519481,0.20408163265306123
1430,SP:8542f8a0aa1e9305f5e0424b325f8c7cba563f24,"The paper develops a method for private neural-network-inference via utilization of Yao's garbled circuits (GC) protocol. In order to keep the computation complexity manageable - the main practical hurdle for  GC - the paper proposes utilization of a neural network architecture search, coupled with restricting weights to ternary alphabet and binary activation. The neural architecture search is conducted via a variation of the ""DARTS"" approach of Liu et. al (ICLR 2019), that accounts for model complexity in the cost function. The paper performs extensive experiments against comparable protocols in their evaluation for MNIST and CIFAR10, and show improvements along some factors.  ","The paper aims at developing an efficient neural network architecture with reduced computational cost under a cryptographic primitive where data on the client side and model on the server side are kept confidential. The motivation is that the existing works have focused on developing cryptographic techniques in a fixed network architecture and have not considered the neural network optimization perspective to enhance the efficiency of existing cryptographic computations. The paper then leverages the flexibility of the network structure while ensuring comparable accuracy and tries to find an architecture that provides a significant reduction in runtime while incurring negligible impact on prediction accuracy. Garbled circuits are chosen as the cryptographic primitive due to its compatibility with a wide range of computations, including non-linear functions. The paper then investigates how to reduce the private inference cost by incorporating two protocols: first one is neural architecture search for efficient private inference where a neural operation is penalized based on its computation and communication overhead, and the second one is to train models with ternary parameters which allows reducing the number of model parameters by introducing sparsity. Sparsity leads to a reduction in computation and communication overhead. However, to maintain a certain level of accuracy, the network needs to be scaled which incurs an increase in the runtime. Accordingly, a trade-off between efficiency and accuracy has been demonstrated with experiments on the CIFAR and MNIST datasets for varying regularization parameter and scaling factor.",0.27450980392156865,0.11618257261410789,0.16326530612244897
1431,SP:857b454e408e1ad21ccb9372ad5feb89d95cb055,"This work focuses on bilevel optimization. The key innovation here is the warm start, which enables improved complexity bounds (under some settings). The analysis nicely builds on singularly perturbed systems (SPS). Numerical tests are also provided on both synthetic and real problems, where the merit of warm start is demonstrated.","The paper studies the problem of bi-level optimization. In particular, it considers algorithms based on inexact implicit differentiation, where the inner problem and the implicit differentiation are not solved exactly. Warm-up is used when solving the inner problem and implicit differentiation. The convergence of the proposed method is analyzed by viewing the iterates of the proposed method as a dynamical system using the idea of singularly perturbed systems. ",0.18,0.12857142857142856,0.15
1432,SP:85884c827deebdf6be8feacefde4800e4837b55a,"This paper addresses multi-lingual speech synthesis, where one ASR model is responsible for recognizing speech in multiple languages.  In this example the authors look at 11 languages with between 80 and 4 hours of training data.  The ""long-tail problem"" (which isn't clearly stated) that this work is addressing is that the discrepancy in available training data leads to a discrepancy in performance.  The paper sets out two goals 1) ""to improve the overall performance of multilingual ASR tasks"" and 2) (implicitly) to flatten the distribution across languages.","The paper proposes three additions to improve a monolithic multilingual end-to-end ASR system. The problem of training a monolithic multilingual ASR system is that using data from multiple languages does not necessary improve over individual monolingual systems. The three additions are a large multilingual language model, the use of language adapters, and smoothing on the token probabilities. Mixing the three additions in a specific way helps improve the average word error rates.",0.14444444444444443,0.17567567567567569,0.15853658536585363
1433,SP:858c51d7156c834550593f4c1dc8172df5af0663,"This paper introduces and explores the task of active 3D reconstruction using visual and haptic data. Instead of relying on static data to perform reconstruction, the learning process is guided by exploration, from which new data can be accounted for in the reconstruction process by the proposed model. In order to enable this setting/task, the authors develop a simulator that provides both visual and touch signals that are fed to the model, and an environment for training and evaluating policies.","This paper presents an approach for active 3D reconstruction of objects based solely on touch, and optionally together with vision. The main idea is active perception -- estimate where to touch/see the object in order to better reconstruct it. The proposed method to solve this involves a neural network that fuses touch and vision signals to estimate 3D shape, and a policy that predicts where to touch next for best reconstruction performance. Data comes from a simulator that produces both touch and image signals (from the ABC dataset).",0.2716049382716049,0.25,0.2603550295857988
1434,SP:85960c4b263657c555864e5203386bba26f4f77d,"This paper studies the extended versions of a previously proposed algorithm called EF21. The paper includes several variants of EF21 such as stochastic optimization, partial participation, variance reduction, momentum, etc. The theoretical analysis for each extension is given and experiments on real world datasets are conducted.","Error feedback (EF) is a technique for ensuring convergence of biased contractive compressor. However, it achieves suboptimal convergence rate when full gradient is used. Recently, EF21 was introduced to mitigate the theoretical deficiencies of EF. This paper studies several extensions of EF21 including EF21 with stochastic gradient, variance reduction, heavy momentum, partial participation, bidirectional compression, and proximal gradient. The paper establishes the convergence results for the six variants and conducts experiments on several small datasets.",0.3695652173913043,0.22666666666666666,0.28099173553719003
1435,SP:859e6be6784f83c885d384954c106b3e9f1bf39f,"The paper claims to exhibit a connection between differential privacy and neural network pruning. The main result is that, for a single layer network with Gaussian weights that depend on the privacy parameters, there exists a differentially private function which approximates the pruned network in $L_2$ distance. This is proved by bounding the sensitivity of the network and adding Laplace noise so that the resulting function satisfies differential privacy and approximates the function defined by the pruned network. According to the authors, these results mean that “ network pruning can be an effective method to achieve differential privacy”",Overview: This paper aims to establish a theoretical connection between differential privacy and magnitude based pruning. The authors show theoretically that outputs of pruned single layer neural networks have some similarity to outputs of the same network with differential privacy added. The paper then empirically demonstrates that model inversion attacks are harder against magnitude pruned neural networks.,0.20408163265306123,0.3508771929824561,0.25806451612903225
1436,SP:85a8e18145acb8bc9d79e188c173ac2c1d1007ed,"The paper extends recently proposed BatchRenormalization (BRN) technique which uses exponential moving average (EMA) statistics in forward and backward passes of BatchNorm (BN) instead of vanilla batch statistics. Motivation of the work is to stabilize training neural networks on small batch size setup. Authors propose to replace EMA in backward pass by simple moving average (SMA) and show that under some assumptions such replacement reduces variance. Also they consider slightly different way of normalization without centralizing features X, but centralizing convolutional kernels according to Qiao et al. (2019).","The paper proposes a new approach for batch-normalization. Standard approaches are sensitive to the batch size, because small batches will lead to unstable statistics. So when the mini-batch is small, the performance can drop significantly. The paper addresses this issue by analyzing extra statistics in the batch normalization and introducing moving average statistics, weights centralization and a slightly modified normalization. The proposed method does not require large batch sizes and nonlinear operations, but still maintain the robustness. The theoretical analysis and guarantees are provided as well. Experiments on typical datasets demonstrate the effectiveness of the proposed trick.",0.1590909090909091,0.1414141414141414,0.1497326203208556
1437,SP:85bec3a997bfbed2252e9549d7a9856d35890241,"The paper proposed a method for network quantization. Similar with the work of ""HAQ: Hardware-Aware Automated Quantization with Mixed Precision""(CVPR 2019), the proposed method is based on reinforcement learning. The contribution of the work is on the kernel-wise quantization, i.e., assigning different bitwidth to different kernels in one layer. And in the experiments, the proposed method clearly outperformed the state-of-arts of network-wise and layer-wise quantization methods.","This paper proposes a new method for quantizing neural network weights and activations that uses deep reinforcement learning to select the appropriate bitwidth for individual kernels in each layer. The algorithm uses a reward function that weights accuracy of the quantized model with latency, energy, and FPGA area, and leverages a high level and low-level controller to create quantized models that can take into account these factors. Compared to prior approaches taht only perform layer-wise instead of kernel-wise quantization, the quantized models can achieve better performance, or latency.",0.24324324324324326,0.1978021978021978,0.21818181818181817
1438,SP:85cc769dc87f910a4aff638f833764ebbac63418,"In this paper, the authors consider the problem of learning model parameters of a switching nonlinear dynamical system from a dataset. They propose a new variational inference algorithm for this model-learning problem that marginalizes all discrete random variables in the model using the forward-backward algorithm and, in so doing, converts the model to one with a differentiable density, so that the gradient of the variational objective can be estimated with the low-variance reparameterization estimator. The authors also point out an issue in choosing a variational objective; the standard ELBO objective is not suitable for their learning problem, because it leads to a model that does not use discrete random variables meaningfully. To overcome this issue, they suggest a new improved objective and a learning procedure, which encourage the learned model to use discrete variables for capturing different modes of dynamics. The proposed variational inference algorithm was applied to three datasets, and in all these cases, it showed promising results.",This paper proposes a method to segment time series into discrete intervals in an unsupervised way. The data is modeled using a state space model where each state consists of a discrete and a continuous part. The discrete state denotes the segment the system is currently in and the continuous state which is conditioned on the discrete one denotes an uninterpretable feature vector. The transition distributions are non-linear. The observation at each time step is high-dimensional and produced by an emission distribution whose parameters are given by a neural network which takes in the continuous state. Learning and inference is done by maximizing the evidence lower bound (ELBO). Problems with the discreteness of latent variables is circumvented by marginalizing (collapsing) them out using the forward-backward algorithm. Problems with making discrete states meaningful when there are non-linear transitions/emissions is addressed by annealing. This annealing scheme forces the conditional distributions on the discrete state to have high entropy (be close to a uniform distribution) at the start by adding a term to the ELBO objective and the multiplier of this term is decreased as the training progresses. There are actually two terms to do this since one alone didn't work.,0.19135802469135801,0.15196078431372548,0.16939890710382513
1439,SP:85d86e241a772c7b195fbc189ab6df0c67872ceb,"This paper aims to improve the robustness of ensembles of neural networks to adversarial attacks. If the models in the ensemble are susceptible to similar attacks, then the ensemble is also vulnerable. This has been shown to be true in practice (He et al.). The authors propose appending distance map layers (DMLs) to the learned representations (i.e., in place of logits) of the member models. The DMLs measure distance to randomly initialized centers using a learned Mahalanobis distance metric. A fraction of the distance matrix, M, is learned such that member M's are approximately mutually orthogonal (thereby decorrelating predictions), and the entries have low L1-norm. The member models' top predictions for each sample are then aggregated by majority vote. The introduction of DMLs is shown to improve robustness to adversarial attacks without a large degradation in accuracy on benign samples. Randomizing the distance metric a bit helps with robustness as expected but hurts benign accuracy also as expected.","This paper concerns on developing neural network ensembles that can avoid adversarial attacks. The authors propose a new concept of Distance Map Layers (DML) that can be used as the one just before the final layer in a neural network for classification. DML is mainly used to improve the diversity of predictions from the ensemble members, and is defined to be the Mahalanobis distance between an input vector and a output center which may correspond to a class. Each member in the ensemble will learn a different Mahalanobis measure, encoded in the inverse covariance matrix (M), as well as the centers. The training tries to ensure that any two different ensemble members should have inverse covariance matrices of small $L_1$ norms and pair-wise orthogonality, and their set of centers should be far from each other. The authors further propose a randomized DML in which a noise is added to M to help the ensemble to be more robust. To validate the effectiveness of their approach, 3 datasets, 3 network architectures, and 5 adversarial attacks are used in evaluation. Their extensive experiments demonstrate that the DML-based ensemble can perform significantly better than the one without DML, and the randomized DML can perform much better than DML. ",0.2111801242236025,0.16346153846153846,0.1842818428184282
1440,SP:86076eabb48ef1fe9d51b54945bf81ed44bcacd7,"This paper list several limitations of translational-based Knowledge Graph embedding methods, TransE which have been identified by prior works and have theoretically/empirically shown that all limitations can be addressed by altering the loss function and shifting to Complex domain. The authors propose four variants of loss function which address the limitations and propose a method, RPTransComplEx which utilizes their observations for outperforming several existing Knowledge Graph embedding methods. Overall, the proposed method is well motivated and experimental results have been found to be consistent with the theoretical analysis.","In this paper, the authors investigate the main limitations of TransE in the light of loss function. The authors claim that their contributions consist of two parts: 1) proving that the proper selection of loss functions is vital in KGE; 2) proposing a model called TransComplEx. The results show that the proper selection of the loss function can mitigate the limitations of TransX (X=H, D, R, etc) models.",0.17777777777777778,0.2318840579710145,0.20125786163522014
1441,SP:860fadd8179582b24954784b0020a94a322e4675,"The article ""Efficient Wrapper Feature Selection using Autoencoder and Model Based Elimination"" considers the problem of feature selection for a broad class of machine learning models. The authors argue that it is important to consider the relevance of features for the considered supervised ML problem and redundancy of features. They propose the wrapper feature selection method based on this paradigm and report the results of the experimental comparison of the method with some approaches from the literature.","In this paper, the authors present an iterative approach for feature selection which selects features based both on the relevance and redundancy of each feature. The relevance of each feature is determined using a mild variant of the Feature Quality Index; essentially, the relevance is computed as the loss in model performance when setting each feature value to the mean and measuring the change in performance. Similarly, the redundancy of each feature is determined by comparing the reconstruction loss of an autoencoder when setting the feature value to its mean for all training samples. These two values are combined to give a single score for each feature at each iteration. The feature with the worst value is removed. A limited set of experiments suggests the proposed approach mildly outperforms other efficient feature selection methods.",0.2987012987012987,0.17164179104477612,0.21800947867298578
1442,SP:863551f0ff2b3fc2b24a545a18b9fb4f5e513a9f,The paper proposes an extension to Tail-adaptive flows for learning the tail behavior of target distributions using normalizing flows. The authors propose to learn the tail behavior by learning flows that match the tail properties of the marginal distributions. They achieve this by using a source distribution consisting of marginal distributions with tail properties matching the target distribution. The tail coefficient of the source distribution is set in a data-driven manner using estimators that can estimate this tail coefficient. ,"This paper focuses on understanding the tail behavior of normalizing flows through a mathematical and statistical way. Motivated by Jaini et al 2020's work on learning long-tailed distribution via triangular flows, this work proves that the marginal tailedness can be controlled by the tailedness of the marginals of the base distribution in flow-based models. Based on this theoretical insight, the authors propose a new algorithm by leveraging a data-driven permutation scheme to enable a correct tail behavior of the target distribution.    ",0.2962962962962963,0.2823529411764706,0.2891566265060241
1443,SP:8671654fe46f948a79f905bd815939dc284ca873,"The paper explores multi-task learning in embodied environments and proposes a Dual-Attention Model that disentangles the knowledge of words and visual attributes in the intermediate representations. It addresses two tasks, namely Semantic Goal Navigation (SGN) and Embodied Question Answering (EQA), using a simple synthetic environment. The paper compares against a few simple baselines and baselines adapted from models in each task.","The paper describes a Dual-Attention model using Gated- and Spatial-Attention for disentanglement of attributes in feature representations for visually-grounded multitask learning. It has been shown that these models are capable of learning navigational instructions and answering questions. However, they addressed two limitations of previous works about visually-grounded embodied language learning models.  The first is the inability to transfer grounded knowledge across different",0.2222222222222222,0.21212121212121213,0.21705426356589147
1444,SP:8674a490809de44ceedfbfce7a48920a11390355,"This paper focuses on the quantization of ConvNets. This paper proposes a learned linear symmetric quantizer to reduce the precision of weight, bias, and activation. The proposed approach works as the following: for a pre-trained neural network, it computes the new weight and activation as a product of a quantized value with a scaling factor. The quantization is based on a simple linear, symmetric function as in equation (1). The value of the scaling factor is searched by ""simulated gradient"" or exponential moving average during re-training. Next, batch normalization is fused into convolution, and the scaling factor and biases are re-calculated. Last, the scaling factor on the convolution is merged with bias terms, to remove the need for multiplication in hardware implementation. Since bias terms usually have a much larger dynamic range, higher precision is used to represent biases. Experiments show that the method achieves competitive results compared with previous quantization methods, and the quantized models can be deployed on hardware more easily. ","This paper proposes a linear symmetric quantizer for integer accelerators called LLSQ, which learns the quantization scaling factor using simulated gradient as update policy. Their main contribution is enabling inference on integer-only hardware by covering all parameters of all operators in convolutional networks, including weight, bias, activation and scaling factor. To address the quantization noise issue in bias parameters, they adopt Straight-Through Estimator and fine-tune the parameters after quantization. To improve inference efficiency, they apply BN layer fusion. They conduct experiments on public datasets for image classification and object detection to conclude that LLSQ achieves lower accuracy degradation compared to previous work. Finally, they test the quantized model on a specialized integer accelerator, showing the feasibility of the quantization on real hardware.",0.1927710843373494,0.256,0.21993127147766325
1445,SP:867abb284e5b683b26f2c03b70c872554dd241ca,"This paper proposes a new contrastive method for unsupervised video domain adaptation. This method employs temporal contrastive learning based on graph convolution and back ground mixing approach for enhancing action similarity, so called CoMix.  Additionally, for tagert domain, CoMix uses a pseudo label-based target domain contrastive learning. The authors evaluate CoMix on UFC-HMDB, Epic-Kitchen, and Jester datasets with intensive comparison and ablation studies. ","In this paper, the authors tackle the problem of video domain adaptation for the task of action recognition. To align source and target domain features, they propose to use contrastive learning instead of domain adversarial learning. For contrastive learning, two instances of different speeds from the same video constitute a positive pair. Two instances of different speed from the different video constitute a negative pair. In addition to the contrastive learning, they propose the background mixup in order to bridge the domain gap between source background and target background. They also incorporate target pseudo-labels to learn more discriminative target classifier. They validate the efficacy of the model on the publicly available benchmarks: UCF-HMDB, Jester and Epic-Kitchens.  The claimed contribution of the paper are as follows.  1) Introducing a new UDA framework, Contrast and Mix (CoMix): contrastive learning with speed, and background mixup for bridging the domain gap  2) Integrate the pseudo labeling for UDA  3) Extensive experiments on three datasets, and achieving state-of-the-art performance on UCF-HMDB and Jester. ",0.2727272727272727,0.10285714285714286,0.14937759336099585
1446,SP:86823c4b45c78992ca5925cd1fb0e241e42a56ea,"This paper proposes a deep learning framework for approximating ecological inference for estimating voting propensities based on demographic aggregates. This is an important problem, as EI has become a court standard for evaluating racially polarized voting in gerrymandering cases for the Gingles factors. Additionally, the increased attention on building coalition districts and availability of individual level data means that this is a problem that is likely to have a large impact in the next redistricting cycle that begins next year. ","This paper takes an approach to ecological inference inspired by deep learning. Ecological inference is the problem of learning individual labels when only large sets of aggregated data are available. It requires a way to estimate label propensities as a function of covariates. This paper proposes combining a multi-level model with deep learning to estimate voter propensities. The model is then applied to Maryland 2018 midterm election data, and is validated with demographic-level polling data (treating the polling data as ground truth) and with known vote correlations.",0.2,0.1797752808988764,0.18934911242603553
1447,SP:868493ffb117e15730ab87159ba934b93b0bf8e4,"The authors propose a deep equilibrium (DEQ) layer that provides certifiable robustness via the interval bound propagation technique. This involves augmenting the original fixed point condition considered in DEQs with two additional fixed point conditions, one for each bound. The main contribution is a theoretical result that says that when parameterised in a certain way, this IBP-DEQ admits a unique fixed point (Theorem 3.1, 3.3), and also that the model provides valid IPB (Proposition 3.2). Motivated by a theoretical result (Proposition 3,7), the authors show empirically that such restrictions imposed by the specific DEQ and parameterisation achieve comparable or improved performance compared with explicit models on MNIST and CIFAR10.",The paper presents a new class of neural networks called IBP-MonDEQs that are an extension of the recently introduced implicit networks MonDEQs. The authors identify a class of weight matrices of the network that ensures that fixed point of the implicit layers exist with respect to the interval analysis and is unique. The construction of IBP_MonDEQ is motivated by the goal of obtaining networks that can be certified to be robust. The authors then train such networks comparing against explicit networks of the same architecture constructed using the certified IBP training. The results show that IBP-MonDEQs can obtain better certified robustness than explicit networks on the MNIST and CIFAR10 dataset.,0.20175438596491227,0.20353982300884957,0.2026431718061674
1448,SP:86972f8c4420d86b88dfcf2aaf13b88d53b98de5,"The paper proposes an extension of the Shapley values, namely, the joint Shapley values which measure a set of features' average effect of a models prediction. The uniqueness of the joint Shapley values is proved. Moreover, training details and tuning parameters are provided in the accompanying code.","This work introduces ""joint Shapley values"", which directly extend Shapley’s axioms and intuitions: joint Shapley values measure a set of features’ average effect on a model’s prediction. This work naturally extends Shapley's axioms from a single feature, to sets of features. In a nutshell: joint Shapley values measure the average marginal contribution of a set of features to a model’s predictions. This work presents rigorous mathematical results for the joint Shapley values approach. This approach is then evaluated on several datasets, including: (i) simulated data, (ii) Boston Housing data, (iii) Movie Review data.",0.44680851063829785,0.21649484536082475,0.2916666666666667
1449,SP:86b2d288cccd05f632414e500f86103956f62ab9,"The paper conducts a large-scale evaluation of the impact of curriculum learning (CL) in image classification. The paper progresses nicely through a sequence of well-thought research questions and experiments, with the key findings stated up front. In particular, the notion of ""implicit curriculum"" is shown to exist. Prior findings around when CL is helpful (limited training, label noise) are confirmed, which is nice. Overall, this methodical empirical evaluation comes away with a clear set of takeaways, empirically ""summarizing"" a lot of prior work on CL and the training of deep models. Some discussion about why CL helps when training is limited or data has label noise (or next steps) would strengthen the paper a bit more.","The paper provides a comprehensive analysis of the benefits of curriculum learning in different application scenarios. This includes investigating the phenomenon of implicit curricula, showing if the examples are learned in a consistent order across different architectures, and exploring the influences of explicit curricula in the standard and emulation settings. The paper empirically shows that curriculum learning has marginal benefits for standard training, but is helpful when the training time is limited or the training data is noisy.",0.2033898305084746,0.3076923076923077,0.24489795918367346
1450,SP:86b5887f47a2acc510a7fb242214a6bece82f682,"The paper attempts to establish the asymptotic accuracy of the ""RNN"" (but not the RNN models that are well-known in the literature - see the below comments) as a universal functional approximator. It considers a general state space model and uses feedforward neural nets (FNN) to learn the filtering and forecast distributions. Based on the well-known universal approximation property of FNNs, the paper shows that their RNN-based filter can approximate arbitrarily well the optimal filter. ","This paper shows that RNN (of infinite horizon) can be universal approximators  for any stochastic dynamics system. It does that by using the Bayesian framework of filtering, which shows that if sufficient statistics given the observations so far can be computed at each stage of filtering, then the expected hidden states at each stage can be estimated as well. The paper then follows this framework by constructing deep neural network mapping from “observations so-far” to “sufficient statistics” and by universal approximation theorem this is possible. Then as long as after each stage, the image of such a mapping is bounded into a certain region, and if the mapping is contractive (|C_\psi C_\phi| < 1), this can be applied to arbitrarily long sequence (and thus infinite horizon). ",0.2077922077922078,0.125,0.15609756097560976
1451,SP:86bd95d8a233760200cafb7cb72ac48a7d50b7d1,"The paper presents a regularization technique for conditional density estimation. The method is simple: adding noise to the data points, and training on the noisy data points. The paper also further gives an interpretation of the method, as a form of smoothing the curvature of the density function. It further proves the consistency of the method.","The paper considers the problem of parametric conditional density estimation, i.e. given a set of points {(x_n, y_n)} drawn from a distribution $p(x,y)$, the task is to estimate the conditional distribution p(x|y). The paper considers parametric estimation where in given a parametrized family of distributions f_{theta} we wish to minimize the likelihood of seeing the given data over theta. The parametric family in a lot of applications consists of highly expressive families like neural networks, which leads to the issue of overfitting in small data regimes. This has been tackled via regularization over the parameter space which might be hard to interpret as the associated inductive bias is not well understood and depends on the parametric family under consideration. On the other hand the paper proposes to add explicit noise in the examples used during training, i.e. irrespective of the optimization procedure (which could be mini-bath sgd) the paper proposes to draw examples from the data set, explicitly add noise onto the examples and create a proxy objective over the augmented data set. ",0.375,0.11475409836065574,0.17573221757322174
1452,SP:86c007cb8af744f84b03a3a424da380984309ae8,"This paper introduces a strategy for controlling the beta value of a beta-VAE during training using approaches from control theory that allow it to target a designated level of KL divergence between the encoder distribution and the prior.  This is done in a way that aims to achieve good reconstructions while maintaining disentangling performance.  It can be viewed as a refinement of the ControlVAE approach of Shao et al 2020, varying only in the specifics of the strategy used.","In $\beta$-VAE, one challenge is to choose the hyper-parameter $\beta$ that controls the trade-off between the reconstruction quality and the disentanglement. This paper proposes a method called DynamicVAE. Rather than using a fixed hyperparameter $\beta$, the method leverages a modified incremental Proportional-integral (PI) controller, which dynamically tunes $\beta$ at different stages of training. The method is tested on benchmark datasets.",0.1625,0.203125,0.18055555555555558
1453,SP:86d37b08b4c0ab21d139c57bbe3b9e5535eeb3f9,"This paper proposes a zero-shot voice style transfer (VST) algorithms that explicitly controls the disentanglement between content information and style information. Experiments show that the proposed algorithm can achieve significant improvement over the existing state-of-the-art VST algorithms. There are two major strengths of this paper. First, it motivates the algorithm design from an information-theoretic perspective. Second, the performance improvement is significant.","This submission proposes a training approach for voice style transfer using encoder-decoder framework and content and style representations. The approach combines multiple mutual-information (MI) based terms into a single objective function. One of the MI based terms is the MI between content and style representations. By minimising mutual information between these representations, the training approach yields models where these representations are disentangled. Experimental results show that this approach leads to improved performance in speaker verification and speech similarity tasks. Experimental results in challenging zero-shot conditions also demonstrate improved performance in speaker verification, speech naturalness and speech similarity tasks. ",0.24242424242424243,0.15841584158415842,0.19161676646706585
1454,SP:86d5de1d34c881a60c55c4bf5c7b250c430beba3,"The paper proposes learning a batch mode active learning (AL) policy as a weighted ensemble of existing AL techniques (or agents). In the proposed method, the ensemble weight vector (\beta) is learnt from data. AL is simulated on a set of training tasks where performance for various choices of \beta are estimated using a Monte Carlo approach. Subsequently, the optimal choice of \beta is found using tree Parzen estimators, a black box hyperparameter optimization technique. Experimental results are shown on Checkerboards, Fashion MNIST, bAbI and 10 UCI datasets. ","The paper ""Learning Active Learning in the Batch-Mode Setup with Ensembles of Active Learning Agents"" proposes to deal with the problem of active learning via a weighted ensemble of agents. Each agent sequentially selects data to include in the batch to be labelled according to specific heuristics. Finally, the various agents are weighted according to parameters found by a gradient-less approach. ",0.2159090909090909,0.30158730158730157,0.25165562913907286
1455,SP:86ed253fe1f1c48ec1f909f10a5473c4cf27fa83,"The authors present a formalization of a simple biological network (the mushroom body of the fruit fly), that allows very efficient “biologically inspired” word embeddings. They train this network to generate both static (context-independent) and context dependent embeddings, and evaluate these embeddings using several metrics comparing mainly to GloVe embeddings, and to some extent to BERT embeddings. Although the results are sometimes inferior, they are overall comparable, and importantly achieved at significantly lower computational resources. The main contribution of this work is not this specific network formalization (which is nice), but rather demonstrating that formalizing biological networks can generate more efficient algorithms, that achieve results comparable to the complex algorithms used ubiquitously.","Although the paper does not say so, my understanding is that the proposed word embedding method actually first perform Kmeans-like clustering on the context vector shown in Figure 2. In the binary word embedding of each word, we set the dimensions corresponding to the k closest cluster centers to 1 and 0 otherwise. Most parts of the paper are describing how the simple word embedding method is related to the neural system of a fruit fly and showing the method achieves comparable performance compared with GloVe in word similarity tasks, context-sensitive word similarity datasets, and document classification tasks.",0.11504424778761062,0.13,0.12206572769953052
1456,SP:8719843b0fa8359a27642c1ffe94e17b748a0a60,"The paper presents a class-agnostic method for tracking multiple moving objects (MOHART) that extends an existing single-object tracking method (Hierarchical Attentive Recurrent Tracking, HART). Similarly to HART, MOHART utilizes an attention mechanism and LSTM units. The extension form HART to MOHART is done in two main steps: HART is applied to multiple objects in parallel, with a presence variable attached to each, and a permutation-invariant network that learns the interactions between the objects.","This paper deals with the problem of multiple object tracking and trajectory prediction in multiple frames of videos. The main focus is adding a relation-reasoning building block to the original HART framework. With multiple objects, the key is to be able to learn the permutation invariant representation during potential changing and dynamic object trajectories. The paper also uses toy examples to show that the proposed block of relation reasoning is not necessarily beneficial when the object trajectory is less random and more static. Finally, experiments on real data demonstrate that the proposed method that accounts for relation reasoning is helpful by a limited magnitude.",0.2236842105263158,0.1619047619047619,0.18784530386740333
1457,SP:8727fc719e0ff6d9c7d4b22cd8ce1007193dc722,"The paper proposes a modification to the traditional conditional GAN objective (which minimizes GAN loss as well as either L1 or L2 pixel-wise reconstruction losses) in order to promote diverse, multimodal generation of images. The modification involves replacing the L1/L2 reconstruction loss -- which predicts the first moment of a pixel-wise gaussian/laplace (respectively) likelihood model assuming a constant spherical covariance matrix -- with a new objective that matches the first and second moments of a pixel-wise gaussian/laplace likelihood model with diagonal covariance matrix. Two models are proposed for matching the first and second moments - the first one involves using a separate network to predict the moments from data which are then used to match the generator’s empirical estimates of the moments (using K samples of generated images). The second involves directly matching the empirical moment estimates using monte carlo.","The paper describes an alternative to L1/L2 errors (wrt output and one ground-truth example) that are used to augment adversarial losses when training conditional GANs. While these augmented losses are often needed to stabilize and guide GAN training, the authors argue that they also bias the optimization of the generator towards mode collapse. To address this, the method proposes two kinds of alternate losses--both of which essentially generate multiple sample outputs from the same input, fit these with a Gaussian distribution by computing the generating sample mean and variance, and try to maximize the likelihood of the true training output under this distribution. The paper provides theoretical and empirical analysis to show that the proposed approach leads to generators that produce samples that are both diverse and high-quality.",0.1597222222222222,0.17424242424242425,0.16666666666666666
1458,SP:874a441d5c5c7582a1d548bc5d0c635ed032434f,"This work derives a new upper bound on the dynamic regret for online convex optimization in the restricted setting where the comparison sequence is made up of the minimizers x^_1,...,x*_T of the loss sequence. There are three main parameters that control regret in this case: the path length C_T = ||x*_2-x*_1||+...+||x*_T-x*_{T-1}||. The squared path length C_T = ||x*_2-x*_1||^2+...+||x*_T-x*_{T-1}||^2. And the sum G_T of squared loss gradient norms evaluated at x*_1,...,x*_T. ","This paper studies the dynamic regret of online multiple mirror descent, which is online mirror descent with M repeated steps on each of T sequential loss functions. The authors show three bounds for the dynamic regret of OMMD, which generalizes OMGD [Zhang et al. '17]: C_T (the path length of the minimizer sequence), S_T (the sum of squared segment lengths), and G_T (the squared dual gradient norm of the points played).",0.24210526315789474,0.3108108108108108,0.27218934911242604
1459,SP:87557044cd905fece8d7b30ad412f7002821cff0,"This paper aims to improve the training of recurrent neural networks (RNN) with ReLU activations by optimizing in the path space instead of the weight space. Studies on multi-layered perceptrons (MLP) and convolutional neural networks (CNN) have shown that these architectures are positively scale invariant (PSI), however traditional SGD optimizes in the weight space that does not have this property. It has been shown in prior work that this mismatch can slow down the optimization process for SGD and it has been demonstrated that optimizing in the so called path space, which has the PSI property, can be faster and more efficient.  The authors of this paper aim to extend an existing path-space framework (G-SGD) that is used for ReLU networks to facilitate RNNs.  To tackle the challenge posed by the time-dependency of RNNs, they use a static representation, called reduction graph, to define the path space. First, they prove that any path in the original RNN graph can be easily obtained from paths in its reduction graph by simple operations. Then, they define the basis for the path space in the reduction graph, and show that basis paths are sufficient to represent the output of the RNN. They propose a method (Skeleton method) to generate a basis path in the reduction graph and specify an equivalent of the G-SGD algorithm for RNNs.  Through numerical simulations they demonstrate that (1) G-SGD for RNNs has a fairly low additional computational cost compared to SGD and (2) G-SGD for RNNs achieves better test accuracy compared with SGD and an additional path space based approach.","This paper proposes a parameter space, called path space for RNNs with ReLU activation. For the construction of the path space, this paper utilises a reduction graph approach to minimise the difficulty brought by the parameter-sharing scheme in RNNs. Furthermore, the authors propose a Skeleton method for the efficient identification of basis path for RNNs in reduction graph.",0.10780669144981413,0.4915254237288136,0.17682926829268292
1460,SP:877723e2a9a0694074f81584bfdfb78497991dc1,"The authors tried to understand the generalization benefit based on the invariant transformation by improving the sample covering number. Although the paper focuses on an interesting question (how model invariance helps generalization), it seems that it is still not in its best shape. I believe this paper will benefit from (a) careful polishment on the writing, (b) some more insightful results, and (c) more experiments on some complex datasets.","The paper provides a bound on the Rademacher complexity of a class of Lipschitz and transformation-invariant functions by upper bounding the covering number of the function class by a similar covering number which uses a ""sample cover induced by data transformations"". This is the induced covering number which accounts for transformations of the original sample set and can be smaller due to the transformation invariance of the function. This directly gives improved generalization bounds for transformation-invariant functions. The paper gives some helpful intuition and simple cases where these bounds may be applied.  Furthermore, the paper presents experiments in which the sample covering number induced by different transformations is approximated, and the generalization ability of a model which is trained to be invariant to those respective transformations is shown to be strongly correlated with the sample covering number. ",0.2318840579710145,0.11510791366906475,0.15384615384615388
1461,SP:87a576813eef2a9cb69b80f1ff69967587d4ea66,"This paper studied the regret analysis of reinforcement learning under the tabular setting and the LDP (local differential privacy) constraint. The authors first showed a minimax lower bound that, unlike the additive dependence on $\varepsilon$ under the JDP (joint differential privacy) constraint, the stronger LDP constraint must incur a minimax regret multiplicative in $1/\varepsilon$. Then the authors provided a general paradigm of the upper bound analysis: find private versions of aggregated statistics (rewards, number of visits), and then carry out an optimistic policy (called the LDP-OBI algorithm) based on (UCBs of) these noisy statistics. Depending on the usage of different private mechanisms, a regret multiplicative in $\sqrt{K}/\varepsilon$ could be obtained, but with worse dependence on other parameters $(H,S,A)$. Discussions and numerical experiments on the result are also provided. ","This paper introduces the concept of Local Differential Privacy for RL, a stronger notion of privacy than Joint Differential Privacy for RL. The authors both prove a regret bound for LDP in RL and provide a novel algorithm that achieves good regret in this setting. Furthermore, empirical experiments are provided that validate the method.   ",0.16417910447761194,0.4074074074074074,0.2340425531914894
1462,SP:87c8b3db03cad51afd2f60d7335c2a687fe3d35f,"The paper focuses on the theoretical understanding of offline reinforcement learning. Assuming weak coverage (Assumption 2.1), which appears to be necessary, the authors propose a double variance deduction learning algorithm. The algorithm has two key components: variance reduction (Eq. (2)) that decompose the key estimation of P_t(\cdot|s,a)V_{t+1} into two components that are estimated separately at different stages; and doubling where parameters are instantiated twice. The authors show strong theoretical results of the proposed algorithm: (new) order-optimal sample complexity for the stationary case, order optimal results for the finite-horizon non-stationary setting and improved results for the infinite horizon discounted setting.","The papers presents an algorithms called OPDVR (Off-Policy Double Variance Reduction) based on variance reduction, which is seemingly designed with offline RL in mind, even though the main attribute of offline RL (data constraint and lack of support) is fully missed. The paper contains several theoretical results; their core contribution (among others) is for the stationary case, where transition probabilities are not function of time. They basically present a sample complexity that grows with $H^2$, an improvement over previous results by a factor of $H$. The authors provide similar result for the infinite-horizon (discounted) case as well, and expand their findings for the non-stationary case too.   Main weakness: While this paper is a nice theoretical contribution, discussions on the ""practical"" impact of the basic assumptions, and how they can be relaxed to become useful in real-world, are missing, [see the comments below]. ",0.20909090909090908,0.1564625850340136,0.17898832684824906
1463,SP:87d54568606a9c1f752dae1420484a7b02a7ab1f,"This paper argues that hyperbolic and other non-exponential discounting mechanisms have been more utilized by humans and animals for value preferences than exponential discounting as widely used in RL literature. The authors claim that hyperbolic discounting mechanisms are especially preferred in the setting of maintaining uncertainty over the prior belief of the hazard rate in the environment and propose an efficient approximation of the Q function with hyperbolic and other non-exponential discounting mechanisms as a weighted sum of Q-functions with the standard exponential discounting factor. The paper shows empirical evidence that hyperbolic discounting function can more accurately estimate the value in a vanilla Pathworld environment and also demonstrate that the approximated multi-horizon Q functions can improve performance on ALE, which is largely attributed to learning over multi-horizons as an auxiliary task.","The paper investigates hyperbolic discounting as a more biologically plausible alternative to exponential discounting in reinforcement learning. First, it formulates a notion of hazard in MDPs as constant exponential discounting and shows that hyperbolic discounting is consistent with uncertainty over the hazard rate. The paper then shows how value functions learned with exponential discounting can be used to approximate value functions with other forms of discounting. Specifically, the paper shows in section 4 how exponentially-discounted value functions can be used to approximate hyperbolically discounted value functions. The paper then presents experiments on a small MDP and Atari 2600 games, showing that learning discounted action values with many different discount rates as an auxiliary task improves performance on most Atari games.",0.25735294117647056,0.2892561983471074,0.2723735408560311
1464,SP:87fa8f6e7f423de00befb4c1384376192f992252,"This paper studies the performance degradation of a Maximum Causal Entropy learner under a transition dynamics mismatch between the expert and the learner in the imitation learning setting. The authors show that the performance of the learner is bounded by the $L_1$ distance between the transition dynamics of the expert and the learner.    Using Two-Player Markov games, the paper proposes an algorithm to robustly obtain a policy under transition dynamic mismatch and shows how it performance against MCE. ","They address the problem where the imitator should imitate an expert, but the expert's environment (MDP M^E) is unknown, and there is no access to it; instead, the imitator can just train in some M^L that may have a different dynamics (but nonetheless, we want to optimize the original experts reward -- independently of the dynamics).  They first derive some bounds on performance loss, given a bound on the deviation between the dynamics (sec3), and if a solution of the occupancy matching nonetheless exists. While one could simply train the imitator in M^L or some M^train to match the experts occupancy (under M^E), based on sec3, they propose a more systematic approach of optimizing over some worst case over possible environments (adversarial-Markov-game) to find a good imitator policy in spite of perturbation of dynamics (sec4).  Generally they assume finite state/action spaces.",0.2625,0.14093959731543623,0.18340611353711792
1465,SP:87fb323fc2a1b385c9a695c7669f509c835ef0aa,"This paper presents C&S method that predicts node labels in the transductive semi-supervised node classification setting. C&S uses the three-stage-pipeline approach. First, label probabilities are predicted with simple and scalable classifiers such as MLP. Then, the predicted errors are diffused over graphs. Finally, the labels are further smoothened to give the final node label prediction. The authors demonstrate that their simple C&S approach beats many existing GNN approaches.","This paper shows modified label propagation can perform better than GCN. The idea is as follows: it first uses MLP on node features to get the initial labels, and then use two steps--correction and smoothness to postprocessing the labels. And this postprocessing is based on the traditional label propagation algorithm. It shows that this simple method matches GCN performances on various datasets. ",0.17567567567567569,0.20634920634920634,0.1897810218978102
1466,SP:88108abfa920eda1a0766301bdfd70113f61f8b3,"- This paper presents a simple but effective method rooted in trust region theory for fine-tuning pre-trained models without 'representational collapse'. Compared to previous methods (such as SMART by Jiang et al. (2019)), the newly proposed methods (R3F and R4F) are computationally simple while achieving more strong performance on several NLP tasks including GLUE, XNLI and summarization. The authors also introduce the concept of 'representational collapse', which means the degradation of generalizable representations of pre-trained models during the fine-tuning stage. Moreover, they empirically demonstrated that SMART and their proposed methods are effective in relieving representational collapse, compared to typical fine-tuning based on normal gradient descent (i.e., one without constraints).",The paper proposes a method for finetuning pre-trained models that ensures the generalization ability of the representation is maintained. The key innovation is that the computationally expensive ascent step in the mirror descent method of SMART can be replaced by simply injecting noise. The results support the hypothesis that this works well for keeping the generalization-ability of the model. The authors also define the degradation of the generalizability of the representation during finetuning as “representational collapse”. ,0.17543859649122806,0.2564102564102564,0.20833333333333331
1467,SP:88170f916a95afae92471abb76d9c6f8c47812de,"This paper proposes a new action poisoning framework to mislead the agent to learn a target policy. In a white-box setting, the paper introduces $\alpha$-portion attack that is guaranteed to conduct a successful attack with sublinear cost. In a black-box setting, the paper proposes an adaptive attack scheme called LCB-H that nearly matches the performance guarantees of the white-box attack method. With a case study on attacking UCB-H, the authors show that the proposed attack strategy can manipulate the learner with a logarithm cost, matching the main claim of the paper.","The paper studies poisoning attacks in reinforcement learning that override an agent's actions in order to force the policy of interest (target policy). The problem of 'action poisoning' is formulated in an episodic reinforcement learning framework, where the attacker experiences the cost of poisoning actions (equal to the number of poisoned/changed actions) and the loss of not fully forcing the target policy (equal to the number of times target policy was not followed). The paper formally studies white-box and black-box poisoning, developing a principled way of performing action poisoning attacks with provable guarantees. The main algorithmic contribution of this paper is an algorithm called LCB-H that has provable bounds on the cost and loss of poisoning. The numerical experiments are conducted to demonstrate the efficacy of the proposed black box attack. ",0.27835051546391754,0.19852941176470587,0.2317596566523605
1468,SP:88181a6db5701fbd9a096e08d5f892d6c1bea0e9,"The reviewed paper explores the relationship between the quality and spatial distribution of the saliency maps produced at inference time and the model's generalization performance. The authors employed a number of existing methods as well as proposed and implemented their own technique (ActDiff) to align saliency maps with causally plausible regions. All methods were applied on synthetic and real-world data in a series of clever experiments, showing little correlation between saliency map spatial alignment and performance on unseen data.","This paper focuses on the confounder problem that spatially-seperated image regions (e.g. shoulders of xray images) might spuriously correlated with the target (e.g. pneumonia). If given a human-labeled region that is deemed important, we can decrease this spuriousness by regularizing the model toward the important region. They not only compare with several existing saliency-based methods (RRR and GradMask), but also propose 2 new methods (ActDiff, Adversarial) inspired from domain adapataion literature that the representation of the classifier should be similar between original image and the masked image (the image that the non-important region is shuffled). They compare in 1 synthetic dataset and 2 xray datasets. They show that (1) these methods (sometimes) hurt generalization when spuriousness does not exist, and (2) the model's saliency map is only weakly correlated with generalization performance, and thus doubting the validtiy of using saliency maps for diagnosing whether a model is overfit to spurious features.",0.20987654320987653,0.10759493670886076,0.14225941422594143
1469,SP:881f632bbadf0cac11ec1e466f02b26762f67073,"This paper analyzes the shortcoming of VAE objective, and propose a regularization method based on a selection mechanism that creates a fictive data point by explicitly perturbing an observed true data point. It is lead to Wasserstein distance between representations. Experiments are made on three datasets; ColorMNIST, MNIST, and CelebA, which shows superior performance on adversarial accuracy while similar accuracy to VAE on nominal accuracy.","This paper studies the vulnerability of representations learned by variational auto-encoders (VAE). It first show that the learned representation of VAE is susceptible to small changes, similar to the adversarial examples in supervised learning setting. Then propose a regularization method, called smooth encoder, to improve the robustness of the representation. Experiments are conducted on several benchmark datasets to show the effectiveness of the method. ",0.23076923076923078,0.23076923076923078,0.23076923076923078
1470,SP:8846907bdbc8c93f43abdd4fac5f496a6bc15468,"The paper answers the question how complex inference models need to be to accurately estimate posterior distributions. The conclusion is when a latent Gaussian model with N parameters satisfies (1) strong invertibility, (2) 3-th smoothness, the posterior can be approximated by a deep latent Gaussian model with O(N) parameters. A special case is also given to show that strong invertibility is necessary to the conclusion.","This purely mathematical paper investigates the important question of how does the necessary level of complexity of an inference subnetwork depend on the the complexity of the corresponding generative subnetwork, in a VAE model. The paper introduces a specific measure of invertibility, and uses it to show that a generative subnetwork that is sufficiently strongly invertible only requires an inference model at similar complexity, while some ""non-invertible"" generative subnetworks will require an exponentially more complex inference subnetwork. The paper provides a lengthy and comprehensive proof of both.",0.22388059701492538,0.17045454545454544,0.1935483870967742
1471,SP:8861e607941d5f65eae84cb2f2ac04066254b18a,"In this paper the authors propose a metric based model for few-shot learning. The goal of the proposed technique is to incorporate a prior that highlight better the dissimilarity between closely related class prototype. Thus, the proposed paper is related to prototypical neural network (use of prototype to represent a class) but differ from it by using inner product scoring  as a similarity measure instead of the use of euclidean distance. There is also close similarity between the proposed method and matching network ","The stated contributions of the paper are: (1) a method for performing few-shot learning and (2) an approach for building harder few-shot learning datasets from existing datasets. The authors describe a model for creating a task-aware embedding for different novel sets (for different image classification settings) using a nonlinear self-attention-like mechanism applied to the centroid of the global embeddings for each class. The resulting embeddings are used per class with an additional attention layer applied on the embeddings from the other classes to identify closely-related classes and consider the part of the embedding orthogonal to the attention-weighted-average of these closely-related classes. They compare the accuracy of their model vs others in the 1-shot and 5-shot setting on various datasets, including a derived dataset from CIFAR which they call Hierarchical-CIFAR.",0.23809523809523808,0.14184397163120568,0.17777777777777778
1472,SP:88b2afe2bf0d9c8befc4e638357618ff14f97319,"This paper is concerned with finding local minima, or second order stationary points of a function $\mathbb{R}^d \to \mathbb{R}$. The key contribution of the paper is to combine the ideas of stochastic gradient descent (SGD) and compressed gradient descent (CGD). This leads to an algorithm which takes care of both the convergence rate and communication complexity, and is favorable for distributed computing. Theoretical results of the convergence and communication complexity are rigorously established, and some empirical studies are conducted. ",It has been proven in previous works that SGD can escape saddle points existing in non-convex objective functions and find local minima. This paper considers non-convex optimization problems in the distributed setting where the gradients communicating between workers and the parameter server are compressed to reduce the communication cost. It shows that when the compression technique is either \mu-compression or Random-K compression then SGD can still escape from saddle points. Their analysis shows that under some reasonable assumptions the compressed SGD can reach \epsilon-SOSP after O(\epsilon^{-4}) iterations. ,0.13414634146341464,0.11702127659574468,0.125
1473,SP:88cb554b701d1a519fd8ab50197cad2fd2810536,"This work introduces a model for incorporating language explanation feedback for domain adaptation with limited labeled data from the target domain. To get this feedback, users are provided with a heat-map of feature attribution scores which they may use to provide feedback on down-weighting / up-weighting attribution scores of certain features, along with labels. Crucially, this paper proposes an approach to convert specific feedback provided on one example, into an abstract template which can then be instantiated on other examples, thus improving coverage of the explanation to many more examples. Finally, this feedback is used to construct a loss which essentially guides the model to up-weight/ down-weight certain feature attribution scores, and this loss along with log-likelihood on the small number of collected labels is used to adapt the model. From experiments, we see that this approach does better than various versions of fine-tuning, hence demonstrating the efficacy of explanations.","The paper deals with the problem of spurious patterns generally learned by a language model. They address this problem by refining the model using compositional explanations. First, they obtain annotation from human workers and then obtain first-order logic from them that map and explain internal features of the model. These updated explanations are used to update the model. They show their results in hate speech and sentiment classification datasets.",0.08333333333333333,0.18571428571428572,0.11504424778761063
1474,SP:88d2b8efd477ec41d0bb7720d3a1ce366e1c3060,"The paper proposes to use ELMO embeddings to improve the precision on the first step of the DeepBugs tasks defined by Pradel and Sen (2018). This first step is an artificial problem created by taking real programs (with and without bugs, but assuming almost all of them are correct) and introducing bugs of certain type into the programs. Then, a classifier needs to distinguish between the real and the artificial set. This classifier is then to be used as a checker for anomalies in code and the anomalies are reported as bugs, however the paper skips this second step and only reports results on the first classification problem.","This paper leverage recent advances of ELMo in context embedding and apply it in the source code embedding. With the help of ELMo, source embedding can take the three benefits: (1)  Surrounding names provide indirect information about possible values the variable could take; (2) an variable’s value evolves through the program execution can be captured; (3) open a gate for the reuse of the ptr-trained model. To evaluate the effectiveness of the proposed approach, authors conduct experiments on the downstream task of the bug detection. ",0.14814814814814814,0.1839080459770115,0.1641025641025641
1475,SP:88d76eb27624b3649620b3585e15777f18e7e631,"This paper bridge the performance between single-step adversarial training and multiple-step adversarial training. The author proposed a Nuclear Norm regularizer in adversarial training (NuAT) which enhancing optimization to use joint batch-statistics of adversarial samples. Moreover, the author also utilizes the weight averaging method to boost the current performance. This work shows outstanding robust performance with significantly low computational cost.","The paper addresses the performance gap between single-step and multi-step adversarial training by introducing a Nuclear Norm regularizer to improve the adversarial robustness of models in single-step adversarial training. It shows that this regularizer encourages function smoothing near clean samples by incorporating joint batch-statistics of adversarial samples, which leads to increased robustness. The authors also use exponential weight-averaging and a 2-step variant of the proposed defense to further improve the performance. Experiments on MNIST, CIFAR-10 and ImageNet-100 demonstrate that the proposed method outperforms single-step adversarial training methods and is competitive with multi-step methods in terms of robustness (while being more computationally efficient).",0.5,0.2767857142857143,0.3563218390804598
1476,SP:88ffd6498b2250b6b86a0e711446384df9285669,"The authors study the lottery ticket hypothesis  for generative adversarial networks. Specifically, they attempt to answer the following questions: the existence of winning tickets in GANs; the effect of discriminator pruning in finding such winning tickets; the effect of initialization during the rewinding steps; and finally if the subnetworks found transfer across datasets. They provide extensive empirical evidence using that ```winning' tickets exist in GANs. Further they show that iterative magnitude pruning and channel pruning successfully find such `winning' subnetworks. They analyse the effect of discriminator pruning and find that initialization during the rewind step matters more than the actual pruning of the discriminator. Finally, they show state-of-the-art results on GAN compression through channel pruning.","In this paper, the authors provide an empirical study on lottery ticket hypothesis on GANs. To do this, the authors use two GAN models and two datasets: SNGAN/CycleGAN and CIFAR-10/horse2zebra. Extensive experiments show that matching subnetworks can be found using unstructured magnitude pruning and channel pruning and they are transferrable to other tasks. The performance of subnetworks found is competitive and even surpasses state-of-the-art performance.",0.22033898305084745,0.36619718309859156,0.2751322751322751
1477,SP:89066c89279656a9a92ccaf38e5cbdffe4461ea5,"The paper presents a model for inferring the solution of a constraint satisfaction problem over boolean variables expressed in *Conjunctive Normal Form (CNF)*. The proposed model builds on existing works which represent the factor graph of the CNF as a bipartite graph, and use a graph neural network for the learning task. It re-defines the graph to facilitate the message passing among the nodes which are in the same part of the graph (i.e. CNF variables/clauses). It also introduces a cross-attention mechanism between the nodes belonging to different parts. ","This paper presents Heterogeneous Graph Transformer (HGT), a new architecture that combines useful properties of GNNs and Transformers to design HGT for combinatorial reasoning problems, particularly Boolean Satisfiability (SAT). The idea of combining these two powerful models is appealing. The motivation behind considering both homogenous attention (between two literals, or between two clauses) and heterogenous attention (between a literal and a clause) seems new and interesting too. However, there are several missing pieces in the paper in the present form, as outlined below.",0.16129032258064516,0.18072289156626506,0.17045454545454544
1478,SP:891db9f5c3c7f981f4b9e37e36436a471f65117a,"This paper presented a denoising adversarial autoencoder for sentence embeddings. The idea is that by introducing perturbations (word omissions, etc) the embeddings are more meaningful and less ""memorized"". Evaluations include measuring sentence perplexity in generation/reconstruction, tense changing via vector arithmetic, sentiment changes via negative/positive vector additions, and sentence interpolations. ","The paper ""Denoising Improves Latent Space Geometry in Text Autoencoders"" tackles the problem of text autoencoding in a space which respects text similarities. It is an interesting problem for which various attempts have been proposed, while still facing difficulties for encoding in smooth spaces. The paper proposes a simple (rather straightforward) approach based on adversarial learning, with some theoretical guarantees, which obtains good performances for reconstruction and neighborhood preservation. ",0.13725490196078433,0.10144927536231885,0.11666666666666668
1479,SP:8939f2377046904b82dd2b219dc2df9b008078b4,This paper studies the channel-collapsed problem in CNNs using 'BN+ReLU' . The Channel Equilibrium block which consists of batch decorrelation branch and adaptive instance inverse branch are proposed to reduce the channel-level sparsity. Experiments on ImageNet and COCO demonstrate that the proposed CE block can achieve higher performance than the conventional CNNs by introducing little computational complexity. The author also discuss the relationship between the proposed method and Nash Equilibrium.,"The authors point out that CNNs can develop collapsed channels that limit their capacity. They propose to remedy this with batch decorrelation (BD), which focuses on ensuring that channels play an equal role in the feature map and are less likely to collapse. The claim is supported with experiments on CIFAR10, ImageNet and COCO.",0.18055555555555555,0.24074074074074073,0.20634920634920634
1480,SP:893cf4309c06b75e6891831e684f59e4806d35b3,"The paper establishes optimal regret bounds of the order O(\sqrt{T}) for Follow The Regularised Leader (FTRL) and Online Mirror Descent (OMD) for convex loss functions and potentials (a.k.a. Riemannian regularizers) that are, respectively, Lipschitz continuous and strongly convex with respect to a given Riemannian metric. These conditions naturally generalize the classical conditions typically considered in the literature, which are defined with respect to a global norm and, as such, are not well-suited to problems where the loss functions and its gradient present singularities at the boundary of the feasibility region. The authors suggest a principled way to choose both the Riemannian metric and the potential function based on the singularity landscape of the gradient of the loss function. Via standard online-to-batch conversion, the authors also address the offline setting and give O(1/\sqrt{T}) error bounds for ergodic averages in convex problems and for last iterates in non-convex problems satisfying a weak secant inequality. The authors include numerical experiments involving a Poisson inverse problem.","This paper investigates online and stochastic convex optimization problems in which the objective function is not Lipschitz continuous. The originality of this study lies in the use of Riemannian geometry. Specifically, the standard condition of Lipschitz continuity is replaced with a more general condition involving Riemannian distances and called Riemann-Lipschitz Continuity (RLC). Based on an appropriate definition of Riemannian regularizer and a generalization of Fenchel coupling to Riemannian geometry, the authors provide $O(\sqrt T)$ regret (resp. risk) bounds for the online (resp. stochastic) mirror descent algorithm, under the Riemann-Lipchitz condition. The performance of the algorithm is validated on Poisson inverse problems.",0.1676300578034682,0.27884615384615385,0.20938628158844766
1481,SP:894dddca0a75e8ac6e32583238fa19efce663601,"This submission studies the dynamics and convergence properties of ""deep equilibrium models"", which are parametric fixed-point iterations corresponding to the infinite depth limit of ""weight-tied"" neural networks. As the authors point out, these networks differ from deep linear networks and networks in the NTK scaling in that the optimization remains nonlinear w/r/t the parameters. The authors prove two results: first, they establish linear convergence to the global minimum under the relatively strict assumption of a ""local"" PL-inequality; secondly, they show that the dynamics of the deep equilibrium models differs from gradient descent dynamics and, in fact, is related to a trust region Newton method.","The paper discusses the theory of deep equilibrium models with linear activations. The model weights are softmaxed to ensure that inference converges to a fixed point, a necessary condition for training deep equilibrium models. The paper then analyzes the gradient flow dynamics of such models. The main result is that linear-rate convergence is guaranteed for a class of loss functions, including quadratic and logistic losses, when training with gradient flow. This conclusion is supported by experiments conducted in a teacher-student-like setup, where the labels are generated by a teacher deep equilibrium model, showing that training does converge in practice.",0.1834862385321101,0.19607843137254902,0.18957345971563985
1482,SP:896dd94d4cc173ade6a6f4f8d5a3b2c6c0b23e9a,"The paper proposes a method MixFeat for regularizing deep neural networks models, aiming at avoiding overfitting in training. The MixFeat interpolates, based on a careful selected mixing ratio, the hidden states (feature maps) of two randomly selected examples. Unlike MixUp, the MixFeat does not interpolate the labels of the two selected examples and the feature interpolation processes are conducted in the hidden space. Experiments on both Cifar10 and Cifar100 show that the networks with MixFeat improve their predictive accuracy as well as outperform networks with Mixup as regularizer.   ","This paper follows a recent trend to improve generalization by mixing data from training samples, in this case by mixing feature maps from different samples in the latent space. One of the feature maps is added as a kind of perturbation to the other one, so only the label from the main feature map is used as the learning target. MixFeat, the proposed method of adding ‘noise’ from another learning sample is tested on CIFAR-10 and CIFAR-100 with different architectures. The authors claim that the proposed method makes the latent space more discriminative. Multiple experiments show that it helps to avoid over-fitting. ",0.2159090909090909,0.18095238095238095,0.19689119170984454
1483,SP:896e4cb1fcd0dbbb9ecaa510dd5052721d46c68f,"This paper deals with the problem of finding an adversarial examples when only the output of a model can be evaluated, but not its gradient. The key idea of the paper is building a Gaussian MRF (a Gaussian with a sparse inverse covariance matrix with a special band structure) to maintain a model for the gradients for predicting search directions. The approach is sensible and uses the FFT trick applicable for diagonalizing covariance matrices with circulant structure.","In this paper, the authors propose a method for black box adversarial image generation. The idea is to learn a parameterization of a precision matrix so that gradients of a network's loss are assumed to be drawn from a corresponding Gaussian. The parameters of this model are fit efficiently using the spectral theorem that their particular parameterization of the precision matrix allows them to use. Gradient estimation is then viewed as a Gaussian conditioning problem given observations (see last equation on page 5).",0.22077922077922077,0.20238095238095238,0.2111801242236025
1484,SP:8971d18110014de85c721169795edb6c101a3706,"This paper proposes to use k-step RWR to capture long-range structural information as a part of node features, so as to overcome the limitation of GCN that it cannot infer long-range dependencies. However, the methodology is incremental and cannot easily be applied to real-world large-scale networks. In summary, the originality and significance are limited (please see detailed comments in the following).",This paper studies GCNs when long-range dependencies have been added to the model as a regularizer. The regularizer proposed in this work is based on a random walk with restart (RWR) approach as RWR encourages the model to consider long-range dependencies. This paper shows that infusing the long-range dependencies using RWR regularizer improves the performance of some models for node classification and graph classification.,0.21212121212121213,0.208955223880597,0.2105263157894737
1485,SP:8978070ba2f95ffbae3ccbd067ba614126da3843,"The paper is dedicated to the sparse generalised eigenvalue problem (SGEP), which consists in recovering the leading generalized eigenvector corresponding to the largest generalized eigenvalue of the matrix pair (A,B). The authors consider the noisy version of A and B: \tilde{A} and \tilde{B}. The main challenges are: problem NP hard because of the subset selection problem (the sparse support size is unknown); the noisy matrices may be ill-conditioned to that algorithms requiring their inverse may not work. The contributions of the authors are as follows: derivation of an error bound between the true sparse eigenvector and the solution of the SGEP; derivation of the conditions for support recovery for potentially non-convex penalty functions; an ADMM based algorithm is proposed to solve the SGEP.",The paper studies a class of sparse generalized eigenproblems which encompasses several common problems in machine learning. For this class of problems it gives upper and lower perturbation bounds which are shown to be rate-optimal. The authors then present an optimization problem with a non-convex penalty function and show that it can be used to estimate the sparse leading eigenvector. The theoretical results are validated numerically using synthetic data in the experimental section.   ,0.1328125,0.22666666666666666,0.16748768472906403
1486,SP:89a1b45eb1420f7259acaf8289fcd30523941e03,"To accelerate the privacy-preserving inference through convolution neural networks (CNNs) with homomorphic encryption (HE), the authors aim to reduce the number of homomorphic operations (HOPs) required for the algorithm to save the data needs to be transferred while preserving prediction accuracy.  Using a LOLA method as a baseline, the authors used Halevi-Shoup (HS) which requires much fewer rotations operations in general. In the experimental results, the HS method requires half of the operations in comparison to the LOLA method. By further simplifying the structure of the network, only about 20% of HOPs are required. These simplifications bring about 1% and 27% accuracy loss. ","The paper considers the problem of privacy preserving inference on deep learning models using homomorphic encryption. HE is a special type of encryption that allows one to perform certain types of computations while the data is encrypted. However, the catch is HE based inferences can be significantly slower than the non-private counterparts. The paper claims to improve upon the existing state of the art HE based inference approaches significantly -- two orders of magnitude.",0.18095238095238095,0.25675675675675674,0.21229050279329612
1487,SP:89a7b0e7a6b9dc575b6686ac9bad37853b82c321,"This paper studies the Q learning in episodic learning from a Lagrangian formulation of the Q-form Bellman optimality equation.   On the theory side, this paper studies the (1) fixed point of the bellman optimality operator when the discounting factor for non-terminal states are 1; (2) strong duality of the considered constrained optimization, i.e., saddle point,  reformulation; and (3)maximin type saddle points.  On the empirical side, this paper studies the efficacy of the minimax imitation learning algorithm for a machine translation application. ","In this work, the authors consider nonlinear Q-form Lagrangian function and show corresponding strong duality property. The main contributions are 1) the new proof of showing the duality gap as zero from a minmax perspective; 2) the generality of the theory with applications to machine translation tasks. A imitation learning algorithm is proposed as well and it turns out that it works well compared with the existing one.",0.17647058823529413,0.21739130434782608,0.19480519480519481
1488,SP:89be1ce836e3d70ed1465208bfa9120eca302ccf,"This submission addresses the problem of limited diversity in GANs due to not modeling underrepresented samples. The authors propose two metrics based on the log-density ratio (LDR), namely, its mean and variance over time. This allows the model to monitor underrepresented and underrepresented samples. Then, the authors propose a training method where data is sampled according to an heuristic based on those two metrics. The results outperform other related methods used for the same purpose, across different architectures and datasets.","The paper proposes a scoring to measure to what extend an image in a dataset is characterized by an under-represented visual appearance. GANs fail to accurately model these under-represented modes of the data distribution or drop them completely. Here, the score is based on the discriminator predictions on real images, and is used as a basis for score-weighted sampling of real data during training, to show under-represented real images more often. The method is shown to improve mode coverage and to result in better image quality/diversity than the considered baselines. ",0.18518518518518517,0.15789473684210525,0.17045454545454544
1489,SP:89dc84f203effa2b434cdf323ff251043336754e,The paper presents a novel pretext task for self-supervised video representation learning (SSVRL). The authors design several surrogate tasks for tackling intentionally constructed constrained spatiotemporal jigsaw puzzles.  The learned representations during training to solve the surrogate tasks can be transferred to other video tasks. The proposed method shows superior performances than state-of-the-art SSVRL approaches on action recognition and video retrieval benchmarks. ,"In this paper, the authors extend the self-supervised 2D jigsaw puzzle solving idea to 3D for self-supervised video representation learning. To make the 3D jigsaw puzzle problem tractable, they propose a two-fold idea. First, they constrain the 3D jigsaw puzzle solution space by factorizing the permutations into time, x, and y dimensions and by grouping pieces. Second, since the constrained 3D jigsaw is still intractable, they propose four surrogate tasks of the 3D jigsaw: 1) LLCD (detecting largest continuous cuboid), 2) CSPC (3D permutation pattern classification), 3) CLSC (contrastive learning over permuted clips), 4) CCMR (measuring the global continuity of the permuted clips)",0.24615384615384617,0.1509433962264151,0.18713450292397663
1490,SP:89f08ed7e079513f1b0d449a3ca52309cd644c39,"The paper proposes an approach, called the Variational Bandwidth Bottleneck (VBB), capable of compressing only a part of the input and still learn representations that are informative of the output. The approach is motivated from the following perspective -- there might be situations where a ``part’’ of the input is privileged in the sense that it may be costly / wasteful to maintain access to all the time, thereby rendering the standard IB pipeline infeasible (as it requires unrestricted access to the entire input). By breaking down the input into standard (always available) and privileged (not always available) components, the paper proposes a module that decides whether to access the privileged input during compression based on the standard input. The goal is to be able to decide when to access privileged information and not how to break the overall input into standard and privileged components. The approach tackles a narrow subset of problems compared to the standard information bottleneck. The authors show the applicability of the proposed approach in reinforcement learning setups -- specifically, (1) when to access an expensive model-based planner for goal-driven navigation; (2) when to access goal-information in goal-driven navigation and (3) treating communication in a multi-agent cooperative setting as ``privileged’’ information. The experimental results demonstrate that VBB accesses privileged information in a feasible and minimal manner and results in better generalization performance.","This paper proposes a type of conditional Information Bottleneck (IB) that addresses the following problem: given that some features may be expensive to obtain for use in prediction, when should they be obtained such that the overall benefit outweighs the cost? A variant of the IB is proposed to model this question. However, optimization is intractable. The paper replaces a certain non-differentiable operation by a deterministic neural network which outputs the probability of seeking the expensive features. The main application here is reinforcement learning, where an agent could compute some plan or communicate with other agents at a cost, and the goal is to solve the task more efficiently while making use of this additional information. It is shown that the proposed method, VBB, makes judicious use of the limited number of costly feature acquisitions it makes, resulting in improved task performance across 3 tasks.",0.14035087719298245,0.2191780821917808,0.1711229946524064
1491,SP:89ffd39dd2f60a2ee0b3e382f3bfde2681405e4d,"Some popular methods like VDN and QMIX focus on the monotonic factorization of joint-action value function, which is not realistic in non-monotonic cases when the agent’s best action depends on other agents’ actions. This phenomenon is common. For example, in the prisoner’s dilemma the value function can be monotonically decreasing in each of the agent’s local value function. One of the effect this paper focuses on is that the monotonically factorization lacks the representational capacity to distinguish the values of coordinated and uncoordinated joint actions during exploration. This effect is well explained in the predator-prey game example, where both VDN and QMIX have undesired performance. ","The paper develops and evaluates an algorithm for decision making in the CTDE MARL setting (centralized training and decentralized execution for multiagent reinforcement learning). That is, the concern is how to use closely supervised training to produce agents that can work independently toward a common goal. The problem is formalized in the DEC-POMDP (decentralized partially observable Markov decision process) setting.",0.0990990990990991,0.18032786885245902,0.12790697674418602
1492,SP:8a2a437441032f68341e305c568f59643a1c81e8,"The paper proposes an uncertainty driven acquisition for MRI reconstruction. Contrary to most previous approaches (which try to get best reconstruction for a fixed sampling pattern) the method incorporates an adaptive, on-the-fly masking building (which is similar in spirit to Zhang at al. 2019). The measurements to acquire are selected based on variance/uncertainty estimates coming from a conditional GAN model. This is mostly an ""application"" paper that is evaluated on one dataset.",The paper describes a method for accelerating MRI scans by proposing lines in k-space to acquire next. The proposals are based on posterior uncertainty estimates obtained from GAN-based reconstructions from parts of the k-space acquired thus far. The authors address an interesting and important problem of speeding up MRI scans and thus improving the subject's experience. The proposed method achieves better posterior uncertainty and SSIM scores than competing methods.,0.2,0.2054794520547945,0.2027027027027027
1493,SP:8a4326afcfba180c749fbe48687afad320021e47,"This paper proposes a new method to fit a recurrent spiking neural network (RNN) to neural data, which consists in simultaneously maximizing the likelihood of the spike trains observed (MLE), while fitting other observables such as averaged activity over trials (PSTH) and noise correlations (NC). On real neural data (monkey V1, rat retina), the method is shown to better capture these other observables compared to models only trained on MLE. On semi-synthetic data (artificial network fit to match the V1 dataset with additional hidden neurons), the method is shown to slightly better reflect the underlying connectivity profile compared to a method trained only on MLE.","This paper introduces a novel approach to fitting spiking network models to neural data. The proposed method uses differentiable recurrent spiking networks, which are fit to the data by minimising a loss function with the help of recent techniques such as the straight-through gradient estimate. The key novelty is to generalise the loss function to be minimized, to include not only the likelihood of the data, but also a number of regularizing terms that depend on desired spike train statistics, such as the PSTH or the noise correlations. These domain-specific terms in the loss function help with breaking degeneracies in the model, and with improving fit quality in the face of model misspecification. After a theoretical analysis of the properties of the proposed loss function(s), the paper shows examples of applications of the technique to some simulated data. A comparison to a state-of-the-art generative model for population spike trains, and an example of usage of the proposed method on a large database of experimental recordings, are presented in the supplementary material.",0.27358490566037735,0.1638418079096045,0.20494699646643108
1494,SP:8a6de840ca758da3973655a8a478e83f8edde474,"This paper studies how over-parameterization plays a role in GAN training. Theoretically, it shows that a GAN with over-parameterized 1-layer neural network generator and a linear discriminator can converge to global saddle point via stochastic optimisation. Similar results are obtained for nonlinear generators and discriminators under some conditions. It also provides empirical results to support its findings. ","This paper studies the effect of model over-parametrization in GANs. While there is a lot of work on this in the supervised learning setting of classification/regression there is not much in the GAN framework where the minimax objective function complicates such an analysis. This paper considers two types of training of the GAN model, one with the simultaneous gradient descent ascent and one where the discriminator is trained to optimality for every generator update. It provides global convergence results under both algorithms in the case of a generator network with one hidden layer that is large enough and a linear discriminator.",0.2833333333333333,0.1650485436893204,0.2085889570552147
1495,SP:8a74c9817b1871bf13674d8b0e1b092ffd257183,"Building on the work of (Gygli et al., 2017), this paper introduces a training algorithm for energy-based models for structured prediction. Similar to Gygli et al. (2017), they train an energy-based discriminator, which matches the energy value of structured outputs with their target values assigned by a value function.","This paper effectively learns a variant of a Deep Value Network (Gygli et al 2017), a model consisting of an energy network that assigns scores to input-output tuples that is trained to mimic a task-specific loss. The primary differences between the model presented in this work (titled LDRSP) and DVNs are twofold: first, the initial label prediction used at test time for inference is the output of a model rather than being initialized to all zeros. Second, a GAN-inspired loss is used to train both the scoring function and the initial prediction estimator. This new setup is compared against a variety of recent structured prediction methods on the tasks of multilabel classification, semantic segmentation, and 3-class face segmentation.",0.2549019607843137,0.10655737704918032,0.15028901734104044
1496,SP:8a7d41e17157971d368e584c9f0aa7132a361a80,"This paper aims to improve low-depth MSAs, when a protein of interest only has a small number of known evolutionarily related sequences. This is a well motivated problem. MSAs are commonly used for a variety of purposes. Methods to enhance low-depth MSAs can be very useful. In particular, this paper focuses on using MSAs for contact prediction as a down-stream task. I'm not sure if contact prediction is the best use case for this, but it's a well-studied task for proof of concept.","The paper proposes a new object called Neural Potts Model (NPM) to train a Transformer to learn the local energy landscape of protein sequences. The problem of modeling energy landscapes using the power of techniques in natural language processing (NLP) is a timely and interesting problem. However, there are some concerns that limit the strength and the main claim of the paper that needs to be addressed. ",0.14606741573033707,0.19402985074626866,0.16666666666666666
1497,SP:8a8ee9de77204eab83867e7170e01e24f0e2d81e,"This paper studies differentially private federated learning and its intrinsic robustness against data poisoning attacks. Theoretically, the authors build two definitions for certified robustness against data poisoning attacks, draw the connection with user-level and instance-level differential privacy. The key proof is based on the definition of individual privacy and group privacy. Empirically, the authors verify the correctness of the bounds by performing real attacks. I think the main contribution is to establish the robustness bound.","## Update after rebuttal and discussions  I thank the authors for taking the time to discuss the issues pointed out in the reviews at length. Unfortunately, I am still not convinced that the paper is ready for publication. My main concerns:  1) There are now experiments in the updated paper claimed to be DP which are not (median clipping).  2) I continue to have doubts about the subsampling amplification. Simply stating that the sampling is random is not good enough, since the key issue is the added uncertainty due to the subsampling: if the sampling does not increase the adversary's uncertainty, there is no amplification. As an immediate remedy, I suggest the authors state the threat model more clearly.  3) I still think the paper can be improved a lot by taking the time to rewrite it focusing on the main contribution of certified robustness under DP and clarity of the presentation.  ---  The paper looks at the robustness properties of differentially private (DP) federated learning (FL), focusing on learning classification models from labeled data. The main idea is to turn DP privacy guarantees into certifiable robustness properties. The authors look at 2 certifiable properties, namely, certified prediction (data poisoning does not alter most likely label), and certified attack cost (there is a lower bound on the loss the given attack tries to minimize). They continue to show that DP models in general guarantee these on some level that depends on the privacy bounds. The paper also presents several DPFL learning algorithms for user and instance-level DP.",0.2727272727272727,0.08171206225680934,0.125748502994012
1498,SP:8a9d38f92030daeccbe4a9d4489d116d3316d519,"The paper investigates the connection between symmetries in the neural network architectures and the loss landscape of the corresponding neural networks. In the previous works, there was shown that the two local minima of a neural network can be connected by a curve with the low validation/train loss along the curve. Despite the loss on the curve being close to the loss at the end points, there are segments of the curve on which the loss in higher than loss at the local minima. To overcome this problem, the authors proposed two-step procedure: 1. Align weights between two neural networks 2. Launch the path finding algorithm between aligned weights. In other words, the authors proposed to connect not original local minima but local minima that parametrize the same functions as the original ones, but have a different order of neurons. The authors also proposed PAM algorithm where they iteratively apply path finding algorithm and weights alignment algorithm.","Given two parameters theta_1 and theta_2 of the same architecture, the authors propose to learn a minimal loss curve between theta_1 and P theta_2, where P is a permutation matrix yielding another equivalent parameterization of the same network. The authors show that either by initializing P with neuron alignment or by optimizing P jointly with the curve, one can find a parameter-space with better accuracy and loss than by just learning a curve between theta_1 and theta_2. The authors also show that initializing P is sufficient to obtain these gains, avoiding the complexity of also optimizing for P. Furthermore, they show that ensembles across models from these curves have a very mild gain in accuracy to those of non-aligned curves.",0.14465408805031446,0.1796875,0.16027874564459932
1499,SP:8a9e9fec36d06b122a226ccac91a869963b148b2,"The paper focused on the issue of learning a policy for a given task using the learned representations a pre-trained VAE. The authors visualize that using a learned latent space of a pre-trained VAE is not good enough for learning policies and propose a solution for this problem: back-propagate gradient policies through the VAE encoder. The authors proposed two versions on this method, one with pre-training and one fully online.","This paper proposes a method for reinforcement learning with representations learned from a VAE. The VAE is used to encode the states (images) and the mean of the posterior is used as input to the policy. The VAE is trained using the variational lower bound and the policy is optimized using PPO. The model can be jointly trained with VAE and RL losses from scratch, or the VAE can be pre-trained and fixed, or pre-trained and finetuned.",0.21621621621621623,0.20253164556962025,0.20915032679738563
1500,SP:8ab44295af08f56cc4486f603e7b3c8167d156ce,"The paper proposes applying transformer models to modeling physical systems. The state at each time step is embedded into a continuous vector using a pretrained encoder-decoder model based on Koopman’s theory. The experiments are performed on three physical systems and generally show that (1) a transformer model outperforms alternative machine learning methods, (2) a transformer model with the proposed embedding outperforms transformer models with alternative embeddings based on autoencoders or PCA, and (3) more transformer layers help (but only slightly).","The paper proposes to use transformers for modelling dynamical systems. The transformer is combined with a linear dynamical system to enforce Koopman features and is trained using the reconstruction and prediction loss. Finally, the proposed algorithm is applied to the different tasks with 1, 2 & 3 dimensions. On each simulated task the proposed algorithm marginally outperforms sufficient baselines.",0.1951219512195122,0.27586206896551724,0.2285714285714286
1501,SP:8ade33116fbf73f44de1023349f61464bbae3ba2,"This paper proposes a model that, given one graph, predicts a sequence of edits that transforms this graph to the next one in a sequence of evolving graphs. To this end, it proposes the graph edit network (GEN), which is a linear output layer that transforms node embeddings to a set of scores that are then used to deterministically select graph edits. The space of edits predictable by this model covers the full space of graph changes. The paper moreover shows that, given a graph matching and a pair of graphs, we can algorithmically find a near-optimal graph edit sequence for generating training data. Finally, the paper demonstrates the model's capabilities on a set of synthetic benchmarks.","Graph Editing is a prominent research area which overlaps a variety of fields in computer science. As a typical example, a series of graphs - each obtained from its predecessor - can naturally represent the evolution of a system over time. From this viewpoint, it would be natural to obtain a means of predicting how such a series of graphs will evolve over time. The authors introduce a simple output layer (called ""GEN"") that can be used in graph neural networks to do precisely that.",0.14285714285714285,0.20481927710843373,0.16831683168316833
1502,SP:8afa601f36fdecbcca39ca4b514c896cc73893cf,"This paper studies the single reward episodic MDP problem with the model-based TS algorithm. Assuming the given model class satisfies realizability, regularization property, bounded Eluder dimension, low covering number, and the true dynamics is the stochastic control model under gaussian noise transition (eq 5), the authors show the polynomial Bayesian regret guarantee. In addition, experiments on OPENAI MuJoCo is conducted.","This paper studies the problem of learning representations for RL. On the theory side, the paper considers the setting where the state-transition is a nonlinear function of the past state-action plus additive noise, and develops a no-regret algorithm. On the empirical side, the paper shows that an adaptation of this algorithm on real-world RL tasks could perform better than existing model-based algorithms.",0.22950819672131148,0.208955223880597,0.21875
1503,SP:8b35f7c054e1ac74e0ad260add9723766df8613d,"This paper extends the Wasserstein Autoencoder (WAE) work by splitting the divergence on the variational marginal into 2 terms, akin to what was done in TC-VAE. This enables directly controlling the explicit contribution of the total correlation term, which is likely to contribute to disentanglement more directly. They explore 2 variations of their model, based on different estimators of the TC term (TCWAE-MWS, using minibatch-weighted sampling; TCWAE-GAN, using a density ratio trick).","This paper addresses disentanglement in the latent space of autoencoders. To this end, it combines ideas from four existing papers, namely the reconstruction loss of the Wasserstein autoencoder, the regularization term decomposition from the total correlation autoencoder, and entropy estimation using minibatch-weighted sampling or the density-ratio trick. This combination certainly makes sense, as it brings together methods that have previously been shown to work well in isolation.",0.2236842105263158,0.2463768115942029,0.23448275862068965
1504,SP:8b44a01fccccbcbe0b91b819c1525b30693a7bd8,"This paper proposes a decentralized attribution to the generative model trained on the same dataset. The goal is to distinguish the user-end generative models, and thus facilitates the IP-protection. The idea is to use orthogonal keys to distinguish the generated samples from authentic data. Furthermore, this paper provided theoretic insights into the proposed method. Experimental results on MNIST and CelebA datasets backup the claims. ","Fake content produced by generative models is of great concerns. This paper investigates attribution techniques to identify models that generated the content. The key theoretic result is the derivation of the sufficient conditions for decentralized attribution and the design of keys following these conditions. Thee paper shows that decentralized attribution can be achieved when keys are orthogonal to each other, and belonging to a subspace determined by the data distribution. Results are validated on two datasets, MNIST and CelebA. ",0.2878787878787879,0.24050632911392406,0.2620689655172414
1505,SP:8b45533993822064150ae1adb3900d48ad87b2fb,"The paper proposes a method for compression of neural network weights. The proposal turns weight tensors into matrices, factorizes these matrices into a rank-k factorization via PCA, applies quantization to the factor matrices, and additionally makes the right (latent) matrix sparse. An algorithm is presented, with two different thresholding options (per-iteration, or one-shot). In experiments, these ideas lead to an accuracy/compression tradeoff which is either competitive with or better than previous state-of-the-art across all compression ratios investigated.","This paper introduces a novel method of weight compression. Weight tensors are stored as sparse, quantized matrix factors, and the underlying matrix factorization problem can be considered as a quantized sparse PCA problem and be solved through iterative projected gradient descent methods. The authors' method  is applicable to both moderate and extreme compression regimes, and is claimed to achieve or be on par with state-of-the-art trade-offs between accuracy and model size.",0.2261904761904762,0.25333333333333335,0.23899371069182387
1506,SP:8b53c4b0f0f7f21e08342cdceaddabc457fc8aee,"The paper presents a novel approach for learning a generative model where different factors of variations can be independently manipulated. The method is build upon  the GAN framework where the latent variables are divided into different subsets (chunks) which are expected to encode information about high-level factors of variation. To this end, a Siamese Network for each chunk is trained with a contrastive loss minimizing the distance between generated images sharing the same factor (the latent variables in the chunk are equal), and maximizing the distance between pairs where the latent variables differ. Given that the proposed model fails in this fully-unsupervised setting, the authors propose to add weak-supervision into the model by forcing the Siamese networks to  focus only on particular aspects of generated images (e.g, color, edges, etc..). This is achieved by applying  a basic transformation  over the input images in order to remove specific information. The evaluation of the  proposed model is carried out using the MS-Celeb dataset where the authors provide qualitative results.","The paper proposes a framework for learning interpretable latent representations for GANs. The key idea is to use siamese networks with contrastive loss. Specifically, it decomposes the latent code to a set of knobs (sub part of the latent code). Each time it renders different images with different configurations of the knobs. For example, 1) as changing one knob while keeping the others, it expects it would only result in change of one attribute in the image, and 2) as keeping one knob while changing all the others, it expects it would result in large change of image appearances. The relative magnitude of change for 1) and 2) justifies the use of a Siamese network in addition to the image discriminator in the standard GAN framework. The paper further talks about how to use inductive bias to design the Siamese network so that it can control the semantic meaning of a particular knob. ",0.18023255813953487,0.20261437908496732,0.19076923076923077
1507,SP:8b572d1f037184bb002765442e1ab35f57a1f084,"This paper considers the L2 normalization of samples “z” from a given prior p(z) in Generative Adversarial Netowks (GAN) and autoencoders. The L2 normalization corresponds to projecting samples onto the surface of a unit-hypersphere. Hence, to attempt to justify this normalization, the authors rely on some already established results regarding high dimensional hyperspheres. In particular, the focus is on the fact that, the Euclidean distance between any given point on a hypersphere and another randomly sampled point on the hypersphere tends to a constant, when the number of dimensions goes to infinity. This result is then used to show that the Wasserstein distance between two arbitrary distributions on a hypersphere converges to a constant when the number of dimensions grows. Based on this result, the authors claim that projecting the latent samples onto the surface of a hypersphere would make GAN less sensitive to the choice of the prior distribution. Moreover, they claim that such normalization would also benefits inference, and that it addresses the issue of variational inference in VAE.","This paper proposes a novel autoencoder algorithm, named Spherical AutoEncoder (SAE). In this paper, the authors argue that the sphere structure has good properties in high-dimensional. To leverage the properties, proposed algorithm centerizes latent variables and projects them onto unit sphere. To show the empirical performance of the proposed approach, the authors perform image reconstruction and generation using FFHQ dataset and MNIST dataset.",0.10404624277456648,0.28125,0.1518987341772152
1508,SP:8b679a434b4b83a626a6dafc1891068800c737a5,"The paper proposes to add a KL-divergence regularization to the objective of regularized continual learning in order to encourage the output prediction to be close to a uniform distribution over classes (i.e., increasing the entropy). They argue that this regularization makes the local minima flat and thus less prone to forgetting. They try to build a theoretical connection using results from information projection but there is still a large gap. In experiments, they show on several benchmarks that applying the KL divergence regularization to different regularization-based continual learning brings improvements. ","The authors argue that achieving wide local minima during the training of tasks, is beneficial for continual learning. The plausible intuition (explained in Fig. 1) is that it is easier to find a parameter setting that is beneficial for all tasks when tasks have wide local minima. They enforce wide local minima by adding an entropy loss to the classifier ( a known strategy). The loss is further combined with any weight regularization loss, like EWC, SI, MAS. ",0.17204301075268819,0.2077922077922078,0.18823529411764708
1509,SP:8bbe82adfc0485dd3fcf411b1d0f52cc2f90e859,"The authors propose to augment the Variational AutoEncoder [1] with a latent prior modeled by a Gaussian Latent Tree Model [2], allowing to introduce a hierarchical structure of clusters in the learned representation. The LT-VAE not only learns the location of each cluster to best represent the data, but also their number and the hierarchical structure of the underlying tree. This is achieved by a three-step learning algorithm. Step 1 is a traditional training of the encoder and decoder neural networks to improve their fitting of the data. Step 2 is an EM-like optimization to better fit the parameters of latent prior to the learned posterior. And step 3 adapts the structure of the latent prior to improve its BIC score [3], which balances a good fit of the latent posterior with the number of parameter (and thus complexity) of the latent prior.","This paper introduces a new VAE model, the latent tree VAE (LTVAE), which aims to learn models with multifaceted clustering, that is separate clusterings are enforced on different subsets of the latent features.  This is achieved using a tree-structured prior on a set of discrete ""super latent variables"" (Y_1,...,Y_L) that identify which cluster the datapoint falls into for each separate facet (i.e. there is a separate clustering associated with each Y_n).  The subset of the standard latent variables z then form a Gaussian mixture model (GMM) for each Y_n.   Both the structure of this setup (i.e. the associated graphical model) and the parameters (i.e. means and variances of the clusters) are learned during training.  This introduces a number of computational challenges not usually seen in for VAE training, for which, seemingly well thought through, novel schemes are introduced, most notably a message passing scheme for calculating gradients of the log marginal p(z).",0.19863013698630136,0.17901234567901234,0.18831168831168832
1510,SP:8bbf8ac04f86085bfff8c946e16ffcece6e4065e,"This paper studies the correlation between the flatness of the converged local minimum and the margin. The authors report experimental results that verify the positive correlation. They suggest using margin-based measures to assess the generalizability. Also, the authors argue that large-batch optimization does not have enough time to maximize margins and hence generalize worse and suggest using it to replace the “misleading folklore” that small-batch methods generalize better because they are able to escape sharp minima. In addition, the authors significantly narrowed the margin which would have violated the policy: “Tweaking the style files may be grounds for rejection.”","The paper presents empirical evidence that the output margin - as a measure of the confidence of a multiclass predictor - is strongly correlated to the Hessian trace when using cross-entropy loss with softmax. Moreover, the paper presents a method for estimating the Hessian trace using the input norm and softmax output. This estimation is inspired by linear classifiers and shows a strong correlation with the Hessian trace. ",0.11764705882352941,0.1791044776119403,0.14201183431952663
1511,SP:8bdeb36997d6699e48511d9abac87df8c14bd087,"The paper introduces a novel tensor decomposition that is reminiscent of canonical decomposition (CP) with low-rank factors, based on the observation that the core tensor in Tucker decomposition can be decomposed, resulting in a model interpolating between CP and Tucker. The authors argue that a straight application of AdaGrad on this decomposition is inadequate, and propose Ada^{imp} algorithm that enforces rotation invariance of the gradient update. The new decomposition is applied to ComplEx model (called PComplEx) that demonstrates better performance than the baseline.","In this paper, a tensor decomposition method is studied for link prediction problems. The model is based on Tucker decomposition but the core tensor is decomposed as CP decomposition so that it can be seen as an interpolation between Tucker and CP. The performance is evaluated with several NLP data sets (e.g., subject-verb-object triplets). ",0.21176470588235294,0.3157894736842105,0.2535211267605634
1512,SP:8be64c1f03d32e6be9088572692563996ab09713,"The paper shows that, under a mild separability condition, the number of connections in a ReLU network required to memorize N data points is of order $\sqrt{N}$ (up to logarithmic factors). This result improves upon the recent work of Park et al. (2021), and matches the previous lower bound. One key proof-technical innovation is pairing _both the input and label informations_ for each partition and encoding them at stage 2, whereas the previous approach focused on the input only. Authors also refine the framework to incorporate the bit-precision constraints, based on which Telgarsky's bit extraction technique can be used.","This paper studies memorization capacity of deep ReLU networks. For arbitrary $N$ data points in a ball of size $r$ satisfying minimum separation $\delta$, the authors show that there exists a ReLU network of constant width and depth $\tilde O(\sqrt{N})$ that perfectly memorizes the entire dataset (Theorem 3.1). This means that memorizing arbitrary $N$ data points can be done using only $\tilde O(\sqrt{N})$ parameters, when depth increases with $N$. Combined with a classical upper bound on VC dimension (Goldberg and Jerrum (1995)), the construction is optimal up to log factors. Theorem 3.1 is extended to the case of fixed depth $L \leq \sqrt{N}$ (Theorem 5.1) and fixed bit complexity per parameter (Theorem 6.2), and these additional results are also optimal modulo log factors.",0.18446601941747573,0.14393939393939395,0.16170212765957448
1513,SP:8bfc8e4206a0b5a2a71dafe22fb42ff9264a1475,"This paper considers augmenting the cross-entropy objective with ""complement"" objective maximization, which aims at neutralizing the predicted probabilities of classes other than the ground truth one. The main idea is to help the ground truth label stands out more easily by smoothing out potential peaks in non-ground-truth labels. The wide application of the cross-entropy objective makes this approach applicable to many different machine/deep learning applications varying from computer vision to NLP. ","The paper deals with the training of neural networks for classification or sequence generation tasks, using a cross-entropy loss. Minimizing the cross-entropy means maximizing the predicted probabilities of the ground-truth classes (averaged over the samples). The authors introduce a ""complementary entropy"" loss with the goal of minimizing the predicted probabilities of the complementary (incorrect) classes. To do that, they use the average of sample-wise entropy over the complement classes. By maximizing this entropy, the predicted complementary probabilities are encouraged to be equal and therefore, the authors claim that it neutralizes them as the number of classes grows large. The proposed training procedure, named COT, consists of alternating between the optimization of the two losses.",0.25,0.16101694915254236,0.19587628865979378
1514,SP:8c168e9fb22c78e446487b4c0c4b3a1e27a716aa,"This paper proposes STRATA, a novel adversarial attack against source code models, more precisely against code2seq. The attack strategy can be applied under black- or white-box threat models, targeted or untargeted. Adversarial training is based on STRATA adversarial examples is proposed to render the models robust. Experiments are performed on Java code datasets of variable sizes.","This paper proposes STRATA, a simple adversarial attack against the code2seq model. The key idea is to replace local variable names in the input code with other randomly chosen sub-tokens with embedding vectors of relatively high L2 norms. Meanwhile, they observe that such tokens often appear frequently in the training set, thus alternatively they can simply use frequently appeared tokens as the target to perform the attacks. In this way, they can attack the model in the black-box scenario, without the knowledge of the model parameters and the training data, as long as they can roughly approximate the frequency distribution of different code sub-tokens in the training set. They evaluate their approach on code2seq models trained for the Java code, and compare with existing attacks against code2seq models. They first show that the 5-same attack, i.e., repeating a sub-token 5 times and concatenating them as the new local variable name, is the most effective attack. This attack decreases the F1 scores more compared to the baseline attack from prior work. In addition, they show that by adding STRATA adversarial examples for adversarial training, the new model becomes more robust to their proposed attacks.",0.3508771929824561,0.10050251256281408,0.15625000000000003
1515,SP:8c174c4e2b083f7313ad07aabbb7a3520d017499,".** In this work, the author(s) have presented an approach to identify valid perturbation operations that can be applied to the model inputs, which can be exploited to boost model robustness via purposefully corrupting the inputs during training. A weakly supervised setting has been assumed, such that pairs of valid perturbations (x, x') are available to support the identification. Technically, a conditional variational auto-encoder is trained to capture possible variations, where the perturbated inputs are used for reconstruction. The latent codes are treated as source space disruptions, concatenated with the original input x to reproduce x'. The author(s) provided empirical evidence to support their claim, along with some theoretical justifications. ","This paper addresses the problem of constraining adversarial image perturbations to be similar to some natural class of perturbations. This would allow natural perturbations to be treated with the same rigor (e.g. quantifiable attack and defense strengths) as standard adversarial perturbations. Standard adversarial perturbations are arbitrary perturbations of an image that are within a certain $\mathcal{l}_p$-ball around the datapoint in pixel space. They are otherwise unconstrained and therefore appear as unstructured noise. Instead, the paper proposes to train a conditional autoencoder to generate perturbed versions of clean images from pairs of clean and perturbed images. The autoencoder can then be used to generate new perturbations that are similar to the training data. Adversarial versions of these perturbations can then be defined in the latent space of the autoencoder, rather than in pixel space. The paper provides theoretical arguments that perturbations generated in this way are close to the perturbations used for training. Using these learned adversarial perturbations, models can then be trained that are robust to them.",0.19642857142857142,0.1286549707602339,0.15547703180212016
1516,SP:8c255c1dffc7b31f0d966d8543ac8c46e5cc826e,"In this paper, the authors study the graph contrastive learning problem and propose an information-aware approach called InfoGCL. The motivation for this work is that all recent graph contrastive learning approaches are customized, and it is an open question how to build the graph contrastive learning method for particular tasks and datasets. The authors' method decouples the typical graph contrastive learning into three modules and formalizes how to find the optimal of the three modules into three optimization problems. Experimental results on both node-level and graph-level tasks demonstrate the advantages of the proposed method.","This paper proposes InfoGCL, a general framework for graph contrastive learning framework design. More specifically, InfoGCL investigates the optimal (and practically optimal) option for three modules in graph contrastive learning, i.e. view augmentation, view encoding and representation contrasting. Experimental results have proven effective over various benchmarks compared with groups of the kernel, supervised and unsupervised. ",0.17525773195876287,0.30357142857142855,0.2222222222222222
1517,SP:8c2af21c8521cb0009076ad7baab1655c34c0bb9,"This paper proposes a methodology for training any binary classifier from only unlabeled data. They proved that it is impossible to provide an unbiased estimator if having only a single set of unlabeled data, however, they provide an empirical risk minimization method for only two sets of unlabeled data where all the class priors are given. Some experiments and comparisons with state-of-the-art are provided, together with a study on the robustness of the method.","The authors introduce the task of learning from unlabeled data clearly and concisely with sufficient reference to background material. They propose a learning approach, called UU, from two unlabeled datasets with known class priors and prove consistency and convergence rates. Their experiments are insightful to the problem, revealing how the two datasets must be sufficiently separated and how UU learning outperforms state-of-the-art approaches. The writing is clear and the idea is an original refinement of earlier work, justified by its exceeding state-of-the-art approaches. However, the paper needs more experimentation.  ",0.23376623376623376,0.18947368421052632,0.20930232558139536
1518,SP:8c4998635e9a0430be550ddcec157f2df08ae267,This paper derives finite-sample bounds for off-policy TD learning algorithms. The main idea is to propose a generalized Bellman operator and rewrite the off-policy TD learning as stochastic approximation algorithms. Then it remains to show under what kind of conditions this generalized Bellman operator is a contraction mapping. The proof technique can be used as a general tool to derive finite sample bounds for existing off-policy learning algorithms. ,"The authors propose a unified framework for understanding several existing tabular off-policy TD algorithms for policy evaluation. Central to this new framework is a generalized Bellman equation and its contraction. The unified framework provides new insights about the bias-variance trade-off of those existing algorithms, as well as finite sample analysis.",0.2222222222222222,0.3018867924528302,0.25599999999999995
1519,SP:8c94149941c39da4ae567d924ac7925fa314e145,"This paper formulates a denoising diffusion probabilistic model, but with Gamma distributed noise instead of Gaussian noise. The claim is that the Gamma noise model shares many of the same useful properties as the Gaussian model (eg a variational bound on data log likelihood, and repeated application of Gamma noise remains Gamma distributed, etc).  And they show, empirically, that the Gamma model produces superior results on image generation (eg on the CelebA and LSUN Church datasets) and on speech generation (eg on the LJ dataset). ","## Summary This paper explores the use of a non-Gaussian diffusion process for Diffusion Probabilistic Models.  Unlike the original work by Ho et al., the authors replace the diffusion process with a Markov chain with transition kernel defined by a Gamma distribution.  They show that the similar (and necessary) properties of Gaussian distribution that enable training DPM in practice also hold true for Gamma distribution.  The main motivation why Gamma distribution is used seems to be that Gamma distribution is more expressive than Gaussian due to having an extra parameter.  The authors experimentally verify the performance gains on a few datasets. ",0.2,0.16831683168316833,0.1827956989247312
1520,SP:8cbce41127c32edb148b2d6713f4ecec0efc6ff9,"This paper mainly studies the generalization performance of stochastic algorithms. Compared with previous results which rely on Lipschitz condition, this paper assumes smoothness condition and Polyak-Lojasiewicz Condition, and then prove the excess generalization bound that is a summation of $\frac{1}{n\beta}$ and empirical optimization error. This result looks impressive, not only because the first term looks shaper than previous $\frac{1}{\sqrt{n}}$ of generalization bound , but also it implies optimization benefits generalization, which may help understand some empirical observations in modern machine learning. What's more, authors analyze some common stochastic algorithms as concrete examples to show the corresponding theoretical guarantee.  Besides, the whole paper is well-written and easy to follow. ","This paper studies the generalization performance of stochastic algorithms in nonconvex optimization with gradient dominance condition. In detail, the authors suggest that for any algorithm, its generalization error can be bounded by $O(1/(n\beta))$ plus the optimization error of the algorithm, where $\beta$ is the gradient dominance parameter. The main idea for the authors to obtain such an improved bound is an advanced analysis based on a weaker on-average stability measure. ",0.1896551724137931,0.2972972972972973,0.23157894736842105
1521,SP:8cc8c5179965778ba6b0c6e9a38eeac3d903f579,"The paper is about adversarial attacks and highlights a security weakness of skip connections in ResNet-like CNNs, namely: skip connections make it easier to obtain adversarial examples. This observation leads to new approach to adversarial attacks, named Skip Gradient Method (SGM), which weights the residual gradient w.r.t  the skip connection gradient. The approach is validated on a variety of image classification attack scenarios (e. g. white-box and transfer attacks) using two families of source models (ResNet and DenseNet). The results show the superiority of SGM when comparing to other adversarial attack scenarios.","This paper proposes a modification to standard Projected Gradient Descent to improve transferability of adversarial examples, when the source model is a ResNet-like model containing skip connections. The method, Skip Gradient Method (SGM) modifies the backwards pass to scale down the gradient computed in each residual branch of the model, before these gradients are combined with the gradient from the skip connection. This thus upweights the gradients from the skip connections as opposed to residual modules. The paper demonstrates significant improvements in the single-model black-box transfer setting, against a variety of undefended and defended models.",0.23958333333333334,0.23469387755102042,0.2371134020618557
1522,SP:8cfafcf0de6de33a8fd298593eeea82376b4697a,"This paper considers the problem of offline, model-based reinforcement learning, wherein a dynamics model is learned from offline data, and subsequently, simulated trajectories in this learned model are used to train a policy. A major challenge in model-based offline RL is how to handle the inevitable distributional shift that occurs when the learned policy is deployed on the true system. Previous works have proposed to mitigate this issue by considering a pessimistic MDP, wherein the reward function is augmented by a measure of the model mismatch between the estimated and true dynamics to obtain an MDP on a which a policies expected return is a lower bound for its expected return on the true dynamics.  This paper compares a collection of prior work following this general approach, but differing in hyperparameters such as the formulation of the model mismatch penalty, rollout horizon, and number of models used the ensemble dynamics model. The paper applies Bayesian optimization to offer insights as to which choices are most effective on two test domains, the Hopper and Half-Cheetah.","Offline RL has seen an explosion of interest in the past year or so, with model-based RL methods being the state of the art (or close to it) on commonly studied benchmark tasks (like D4RL and RL Unplugged). This paper takes a retrospective view on model-based offline RL to benchmark/evaluate different design choices in recent papers. Based on experimental evaluations, the paper makes a number of interesting observations and suggestions for improvements such as longer rollout horizons and penalties more closer to OOD detection rather than uncertainty estimation, among others.",0.12429378531073447,0.23655913978494625,0.16296296296296298
1523,SP:8d4e00c5a4fac78c1fa8a9161fd4e5c72f7ad508,"This paper proposes a H divergence that is a generalization of many popular f divergences and IPMs. The paper gives an empirical estimator with convergence rates for this divergence, where the rates are very fast when the two distributions are equal. The paper shows how the empirical estimator has practical use for two sample tests and measuring the corruption of a sample. The proposed H divergence is ""useful"" when the two distributions are close to each other, but as the authors acknowledge in the future work, it is an open question whether it could be ""useful"" in other cases.","The distance or divergence between two probability distributions is essential for machine learning. This paper introduces a new class of divergence functions based on optimal decision loss function. They first introduce a class of entropy functional, namely the loss function depending on the action and state. This type of function extends the classical entropy function, including negative Boltzman-Shannon entropy. Using it, they further construct a divergence based on the mixture of probability densities.  Several propositions and numerical experiments demonstrate the effectiveness of proposed divergence functions. ",0.15151515151515152,0.1744186046511628,0.16216216216216217
1524,SP:8d751df2c357c435f1e46f81d4e28b1661aa6aad,"This short, interesting paper provides a theoretical analysis to explain why we may expect to see bandpass oriented filters arise as a result of the convolutional structure of deep networks. The explanation boils down to the fact that the eigenfunctions of convolutions correspond to bandpass filters. This can explain surprising phenomena: bandpass filters arising when training on random noise inputs. The paper could have been even more interesting if some or more of the other questions had been considered:","This paper proposed a hypothesis on why neural network learns oriented bandpass filters. While most existing work attribute this phenomenon to image structures, this paper suggests that it might be a property of convolution. In particular, it shows Fourier basis are eigenfunctions of convolution, and band pass filters are eigenfunctions for the generalized eigen problem of convolution given a windowed weighting function, which corresponds to a windowed Fourier transform. ",0.16455696202531644,0.18840579710144928,0.17567567567567566
1525,SP:8d7ad283640648010986d77969506a28725b2e2a,"This paper proposes a new approach to regularize on-policy methods utilizing two soft trust region terms. The first term encourages the new policy to stay close to old policy like PPO and the second term enforces the new policy to stay close to the combination of past policies called virtual policy. The virtual policy is built by a convex combination of past policies in the memory through attention weights. The motivation to use attention is to ensure the virtual policy has good performance on current data. To evaluate their method, this paper uses 3 control tasks (i.e. Pendulum, LunarLander and Bipedal- Walker), MiniGrid library for sparse reward environments evaluation, 6 Mujoco tasks, and 6 Atari games.","In this work, the authors propose the use a trust-region method in the vein of Proximal Policy Optimization (PPO). In contrast to previous work, the author propose to use two trust regions instead of a single one. Instead of constraining the policy to stay near to the previous policy, the author's proposed algorithm includes an extra virtual policy constructed from a memory buffer of past policies.",0.1864406779661017,0.3235294117647059,0.23655913978494625
1526,SP:8d80ab2c84cae404e404a09f674bf9335f564975,"This paper introduces a deep learning based digital contact tracing method to minimize the spread of COVID19. The proposed method is based on locally processed information collected on the mobile app. Unlike the most commonly used digital tracing approach that sends quarantine recommendations to all recent contacts of a newly diagnosed person, the developed method in this paper considers all the information related to the users and the ones who have been in contacts with them in order to make user specific recommendations. This is not an easy problem because of different conflicting factors involving in making recommendation decisions, i.e. user privacy, mobility restrictions, and public health. The proposed method, called proactive content tracing, is a set-based architecture (that uses attention) and perform distributed inference to preserve privacy.","In this paper the authors propose a novel method of contact tracing which they dub Proactive Contact Tracing (PCT). PCT is aimed at detecting an individual's infectivity given locally observed information (and history), as can be carried on say a mobile device. As the name suggests, being able to estimate infectivity given this local information is useful in large part due to the fact that individuals can be asymptomatic, or they can have significant infectivity before demonstrating symptoms if they are to be symptomatic. Proactively estimating infectivity levels thus provides another tool in combatting viral spread through proper containment protocols. ",0.14615384615384616,0.18811881188118812,0.1645021645021645
1527,SP:8d95af673099b1df7b837f583aa55678d67c5bd6,"This paper presents an approach towards extending the capabilities of feedback alignment algorithms, that in essence replace the error backpropagation weights with random matrices.  The authors propose a particular type of network where all weights are constraint to positive values except the first layers, a monotonically increasing activation function, and where a single output neuron exists (i.e., for binary classification - empirical evidence for more output neurons is presented but not theoretically supported).  This is to enforce that the backpropagation of the (scalar) error signal to affect the magnitude of the error rather than the sign, while preserving universal approximation.  The authors also provide provable learning capabilities, and several experiments that show good performance, while also pointing out limitations in case of using multiple output neurons.","This paper examines the question of learning in neural networks with random, fixed feedback weights, a technique known as “feedback alignment”. Feedback alignment was originally discovered by Lillicrap et al. (2016; Nature Communications, 7, 13276) when they were exploring potential means of solving the “weight transport problem” for neural networks. Essentially, the weight transport problem refers to the fact that the backpropagation-of-error algorithm requires feedback pathways for communicating errors that have synaptic weights that are symmetric to the feedforward pathway, which is biologically questionable. Feedback alignment is one approach to solving the weight transport problem, which as stated above, relies on the use of random, fixed weights for communicating the error backwards. It has been shown that in some cases, feedback alignment converges to weight updates that are reasonably well-aligned to the true gradient. Though initially considered a good potential solution for biologically realistic learning, feedback alignment both has not scaled up to difficult datasets and has no theoretical guarantees that it converges to the true gradient. This paper addresses both these issues.",0.20634920634920634,0.14772727272727273,0.17218543046357615
1528,SP:8d9605171acd6c661b43648ad897a66665e5ea9f,"This paper analyzes the frequency spectrum of adversarial perturbations during normal training. The authors show that the low frequency component (LFC) of adversarial perturbation is increasing during training, but it is not increasing fast enough, so the LFC of adversarial perturbation is not as dense as the input natural images which obey the power law. Therefore, the log-spectrum difference of adversarial examples will express a HFC-concentrated phenomenon. The authors used theory and experiments to demonstrate this point.","This submission deals with understanding the gradient based adversarial examples. For this means, it analyzes the adversarial examples in the frequency domain, where it identifies that the ratio of high-frequency and low frequency parts is quite large in adversarial examples compared with the natural ones. As a result, it proposes to apply a low-pass filtering to the data that can significantly improve the model robustness. Some experiments for CIFAR-10 classification are performed to support the main conclusions.",0.21518987341772153,0.2125,0.2138364779874214
1529,SP:8dd0ec8f16a72dad739f6e31b9ced0a8e8989b9e,"This paper proposed a method to hide information in the parameters of neural network models. To avoid significant perturbation, the paper only considers embed the information in the fraction bits of the parameters. The paper considers hiding the information in either the least significant bits of the most significant bits. Hiding in the least significant bits is harder to be detected but the message can also be easily removed without much degradation in the model performance. On the other hand, information  hiding in the most significant fraction bits will be very hard to remove without model performance degradation but also harder to embed the message for the same reason. Sensitivity analysis to select least sensitive parameters to use and fine-tuning after embedding to recover the model performance can be two remedies.","This paper highlights and studies the interesting possibility of hiding information within neural network weights, which is a form of steganography. The sensitivity of different neural network layers to perturbations is evaluated, and based on this a technique for hiding information is proposed and demonstrated. It is shown that it is possible to hide information in the weights of a number of standard baseline neural networks without being easily detectable.",0.12121212121212122,0.22857142857142856,0.15841584158415842
1530,SP:8dfdda094c86d5c8fc9c9e1815cb2fe86e9ea3d3,"The paper develops a variational framework for general diffusion processes. A continuous-time ELBO is developed that extends the ELBO of discrete-time diffusion processes. They use this to show that optimizing the score matching loss corresponds to maximizing a lower bound on the log marginal likelihood.  More specifically, the paper makes use of the Fokker-Planck/Kolmogorov forward equation along with the Feynman-Kac formula to express the marginal density of the generative diffusion process. Since the resulting expression is intractable, a change-of-measure is applied, introducing a variational approximation $\mathbb{Q}$ to $\mathbb{P}$. $\mathbb{Q}$ is chosen such that the Radon-Nikodym derivative $\frac{d\mathbb{Q}}{d\mathbb{P}}$ can be expressed using Girsanov theorem. From this, a continuous-time ELBO is obtained. Finally, through a specific choice of the drift coefficient $a$ in the inference SDE, a connection between the ELBO and score matching is established.",This paper presents a framework for studying continuous diffusion models. Thanks to this it demonstrates the plug in generative model corresponds to a continuous version of the discrete diffusion models and is equivalent to minimising an ELBO on the likelihood of the model.  It does so by first transforming the change of density associated to the SDE into a second order linear differential equation and then expressing its solution as an expectation over another SDE. Solving this expectation is performed via variation inference on the Brownian paths and yields the continuous-time ELBO. This CT-ELBO is then compared with its discrete time counter part. Finally it is compared to the score matching loss which demonstrates the soundness of such method for learning the generative model and continuous time diffusion models. ,0.21052631578947367,0.24427480916030533,0.22614840989399296
1531,SP:8e33b79fc250a1a58df2de4c39ca89784eb40143,"The paper proposes ""Reinforced Few-Shot Acquisition Function Learning"" (FSAF), a meta-learning approach for designing few-shot acquisition functions (AFs) for Bayesian Optimization (BO).   The authors map BO onto an reinforcement learning (RL) problem, i.e., identify the AF with an RL policy which proposes evaluation points, given the current state of the optimization in form of the Gaussian Process (GP) posterior (and further features). The authors develop a Bayesian version of Deep Q-learning (DQN), leveraging Stein Variational Gradient Descent (SVGD), and combine it with ideas from Bayesian MAML (BMAML) to meta-train an initial AF on function samples from GP priors. This initial AF can be adapted to a family of target optimization problems using a few (~1-5) context optimization problems from this family for fast (few-shot) adaptation.   The method is evaluated on various sets of optimization problems, showing favorable performance compared to existing hand-designed AFs (EI, PI, GP-UCB, MES) as well as the transfer-learning approach MetaBO [1].","This paper proposes to learn a general quickly-adaptable acquisition function (AF) using reinforcement learning. Particularly, it first connects AFs in BO with Q functions in RL, and then learns an adaptable AF with DQN + MAML. In order to mitigate the overfitting problem, it considers a Bayesian approach and applies Bayesian MAML. The empirical performances on a variety of black-box functions show very promising performance compared to many baseline BO algorithms.  Exploring the connection between AFs in BO and Q functions in RL is very interesting and novel AFAIK. Presenting BO as a RL problem allows one to learn a non-myopic AF which is also a good property compared to standard myopic AFs. Besides, training a fast adaptable AF at the presence of meta-data (tuning data of similar functions) is a nice contribution although there has been some prior work on learning an adaptable GP model.  The extensive experiments and ablation are useful and convincing.  My main concern of the paper that prevents me from giving a higher rating is on the use and the required amount of meta-data. Please see my question in below.",0.1686746987951807,0.14814814814814814,0.15774647887323942
1532,SP:8e483c23c389c435087e6ad05f0540f6d77c9334,"The authors of the paper propose a novel loss function termed the golden symmetric loss to tackle the important problem of learning with noisy labels. The proposed loss function, in essence, involves the use of a corruption matrix to correct the regular cross-entropy loss and, at the same time, to estimate the relative weighting of the corrected cross-entropy loss and that of reverse cross-entropy loss.  A series of empirical experiments were conducted to demonstrate the effectiveness of the proposed method. ","The paper proposes a golden symmetric loss method that combines cross entropy loss and reverse cross entropy loss, and at the same time performs forward loss correction for cross entropy loss, under the problem where we have noisy training labels and clean training labels. It shows theoretical results showing the robustness of cross entropy loss under forward loss correction, and shows that it can be regarded as a generalization of Ghosh et al. 2017's analysis. Empirically, it shows how loss correction on reversed cross entropy or the symmetric cross entropy performs worse compared with only cross entropy, and propose to use forward loss correction only on cross entropy term.",0.3132530120481928,0.23636363636363636,0.2694300518134715
1533,SP:8ead93266a4847d000548d8b05896b522d51e5f6,"The authors address the problem of discovering and predicting with hierarchical structure in data sequences of relevance to planning. Starting with the kinds of data that have been used recently in video prediction, the authors aim at learning a sequence of keyframes (i.e., subsets of frames forming the overall sequence) that in a suitable sense ""summarize"" the overall trace. As they rightly note, many alternate models struggle with making good long term predictions in part because they focus on all levels of prediction equally.","The paper introduces a model trained for video prediction hierarchically: a series of significant frames called “keyframes” in the paper are first predicted and then intermediate frames between keyframes couples are generated. The training criterion is maximum likelihood with a variational approximation. Experiments are performed on 3 different video datasets and the evaluation is performed for 3 tasks: keyframe detection, frame prediction and planning in robot videos.",0.12941176470588237,0.16417910447761194,0.14473684210526316
1534,SP:8ebf216575b171e681939ab6440df2a71d7c1966,"The paper starts from the Linear Symmetry-Based Disentanglement (LSBD) in [1]. The existing approaches to evaluate disentanglement require the supervision of the dataset and it is impossible for the unlabeled data. In this regard, the authors propose the new quantifying metric for disentanglement under the 'limited supervision' setting. Also, under this metric, authors provide a VAE-based framework that exploits limited supervision for the proposed metric.","This paper follows on the work of Higgins et al. 2018 that used linear symmetry based disentangled (LSBD) representations where real-world transformations provide some structure in the data that can be leveraged. The main contribution of this paper is to provide a metric to measure the quality of disentanglement in the learned representation. The paper makes some assumptions on the samples in the dataset and assumes that there are some group actions that relate one data point to another. Under this assumption, the paper derives a simple and easy-to-compute disentanglement measure. Second, this paper shows a method that can work with partial supervision to learn disentangled representation. This is done by using some data with supervision on the underlying transformation between the data points, and another set of data points where no labeling information is given. The proposed method uses a diffusion variational autoencoder. ",0.3582089552238806,0.16326530612244897,0.22429906542056072
1535,SP:8ec794421e38087b73f7d7fb4fbf373728ea39c7,"This paper considers learning low-dimensional representations from high-dimensional observations for control purposes. The authors extend the E2C framework by introducing the new PCC-Loss function. This new loss function aims to reflect the prediction in the observation space, the consistency between latent and observation dynamics, and the low curvature in the latent dynamics. The low curvature term is used to bias the latent dynamics towards models that can be better approximated as locally linear models. The authors provide theory (error bounds) to justify their proposed PCC-Loss function. Then variational PCC is developed to make the algorithm tractable. The proposed method is evaluated in 5 different simulated tasks and compared with the original E2C method and the RCE method. ","This work proposes a regularization strategy for learning optimal policy for a dynamic control problem in a latent low-dimensional domain. The work is based on LCE approach, but with in-depth analysis on how to choose/design the regularization for the \hat{P} operator, which consists of an encoder, a decoder, and dynamics in the latent space. In particular, the author argued that three principles (prediction, consistency, and curvature) should be taken into consideration when designing the regularizer of the learning cost function - so that the learned latent domain can serve better for the purpose of optimizing the long-term cost in the ambient domain. ",0.19834710743801653,0.22641509433962265,0.21145374449339208
1536,SP:8ef105e3182737dfc50be0d20883ab2fe2fc3610,"In this paper, the authors consider the problem of compressed sensing where the underlying signal of interest is captured and restored based only on sparse measurements: Specifically, this paper focuses on the scenario of Deep Probabilistic Subsampling (DPS) which finds sparse measurements in the way that the models designed to solve specific learning problems based on these measurements are jointly optimized. The authors extend DPS to a sequential framework that iteratively and actively selects the next measurement points: The proposed approach encodes the information accumulated until a time step into a context vector which is updated, and used in selecting the next point, in an LSTM-like framework (see minor comments below). In the experiments with two toy problems (including MNIST) and an MRI reconstruction problem, the authors demonstrated that the proposed Active DPS (ADPS) outperforms DPS (in toy problems) and three other compressed sensing algorithms (for MRI reconstruction).","This paper develops methods to perform active subsampling. That is, given some downstream task like classification or image reconstruction, it sequentially selects which elements of an image or signal to sample so as to perform said task. It does so by extending the Deep Probabilistic Subsampling (DPS) method developed by Huijben et al. The proposed method is applied to two problems as well as a simplified, low-resolution MRI reconstruction problem.",0.11409395973154363,0.23943661971830985,0.15454545454545457
1537,SP:8f20db15399c5c60d0aa8e1502f1ea43c2dcd4c8,"This paper explores adversarial examples by investigating an invertible neural network. They begin by first correctly pointing out limitations with the commonly adopted ""l_p adversarial example"" definition in literature. The main idea involves looking at the preimage of different embeddings in the final layer of an invertible neural network. By training a classifier on top of the final embedding of the invertible network the authors are able to partition the final embedding into a set of ""semantic variables"", which are the components used for classification of the classifier, and a set of ""nuisance variables"" which are the complement of the logit variables. This partition allows the authors to define entire subspaces of adversarial images by holding the logit variables fixed and varying the nuisance variables, and applying the inverse to these modified embeddings. The authors are able to find many incorrectly classified images with this inversion technique. The authors then define a new loss which minimizes the mutual information between the nuisance variables and the predicted label. ","This paper studies a new perspective on why adversarial examples exist in machine learning -- instead of seeing adversarial examples as the result of a classifier being sensitive to changes in irrelevant information (aka nuisance), the authors see them as the result of a classifier being invariant to changes in relevant (aka semantic) information. They show how to efficiently find such adversarial examples in bijective networks. Moreover, they propose to modify the training objective so that the bijective networks could be more robust to such attacks.",0.11904761904761904,0.23529411764705882,0.15810276679841898
1538,SP:8f5230bf3c19417980b10112488d1c7a8f1177f4,The goal of this work is to enable existing pre-trained transformers (e.g. GPT-2) to operate over long input contexts. This is achieved by breaking the input sequence into segments and processing each segment through the transformers while allowing tokens in the current segment to attend over a summary vector of the tokens in the previous segment. The summary vector is created as a weighted combination of the tokens in the summarized segment. Thus the summary vector introduces recurrence where each segment can use information from the previous segment. These modifications yield a better language model for long input texts. ,"The paper proposed to add a recurrent component to pretrained transformers. The component pools the hidden states of a context window and passes it to the next context window as an additional input to the self-attention layer. The component reduces the memory usage at both training and inference time, and enables the Transformer model to work on a longer sequence. The component is evaluated on two language modeling datasets and outperforms baseline models.",0.13725490196078433,0.1891891891891892,0.1590909090909091
1539,SP:8f8b8725508f06303fd8cb959f8fcb00455f4ba7," This paper proposes an alternative to stochastic line search which is based on forwarding step model building which corrects the direction of move and its magnitude at the same time. In its proposed algorithm it first checks if the given step size satisfies the stochastic line search. If yes then just use the step size and do the SGD update. Otherwise, it builds linear models around two points and combines these two models and minimizes this new model and this becomes the new iterate value.   ","The authors proposed a method called stochastic model building (SMB) that uses a combination of existing techniques to get faster convergence in stochastic non-convex optimization. In particular, they use a stochastic adaptation of the model-building globalization strategy from Oztoprak and Birbil (2018), in which the deterministic Armijo condition check is also computed using stochastic gradients. By re-writing their update as a preconditioned SGD step, they are able to bound the spectrum of the preconditioner. This allows them to obtain convergence results for smooth and non-convex objectives by directly invoking the analysis of Wang et al. (2017). Experiments demonstrate that with additional heuristics, their proposed method can outperform state-of-the-art optimizers on common deep learning benchmarks.",0.16470588235294117,0.11570247933884298,0.13592233009708735
1540,SP:8f949e0793cdee7336cf2c40803cb47202fef232,"The paper proposes N2O, a tool for probing the similarity among sentence embedders. Given two sentence embedders, N2O measures the amount of overlap of the k-nearest neighbor sets reported by the two embedders, averaged over a sample of probing queries. Cosine similarity is used as the similarity metric. The paper computes all-pair N2O scores for common sentence embedders and analyzes the results.","The paper proposes a method to estimate the similarity of sentence embedders called N2O with the goal to better inform embedder choice in downstream applications. For two embedders A and B, N2O samples sentences called queries from a corpus, uses A and B to compute embeddings for each sentence, determines the k nearest neighbors (= other sentences from the corpus) for each sentence, and computes the overlap of the resulting sets of neighbors. Nearest neighbors are computed with Cosine similarity.",0.3125,0.25316455696202533,0.27972027972027974
1541,SP:8f9cb8909c5c46521d26f872c904b5a0c50c8ce9,"This paper introduces AlignKGC, a neural model that performs knowledge graph completion (KGC) on multilingual knowledge graphs that have entity and relation overlap. AlignKGC makes use of some of this overlap during training to optimize its parameters for two auxiliary tasks, entity alignment (EA) and relation alignment (RA). The resulting model demonstrates strong empirical results on DBP5L for all three tasks, and the paper demonstrates through extensive experiments the efficacy of each model components introduced.","This paper explores how entity alignment (EA), relation alignment (RA), and knowledge graph completion (KGC) can benefit each other. It proposes a model which jointly optimizes the three tasks using a linear combination of their losses. A contribution within this is a method for aligning relations in the absence of gold entity alignments. KGC is evaluated on each of 5 languages for which a KG is available, and EA & RA are evaluated jointly. The paper is easy to follow throughout.",0.2,0.1875,0.19354838709677422
1542,SP:8fa7e40de8cef28991e918a6ff372dfac981df6c,"This paper proposes to consider the problem of transfer in the context of sequential decision-making -- in particular reinforcement learning -- from the view-point of learning transferable credit assignment capability. They hypothesize that by learning how to assign credit, structural invariants can be learned which the agent can exploit to assign credit effectively and thus learn more efficiently in new environments (be it in-domain or out-of-domain). They pose the credit assignment problem as learning to predict (sparse) rewards at the end of sub-trajectories, finding the extent to which past state-action pairs appear to be responsible for these rewards (by means of the reward-prediction training), and creating a dense reward function via reward shaping (such that the set of optimal policies does not change). This is appealing as no modifications are needed to the RL algorithm/architecture. To examine their hypothesis, they created a method, called SECRET, based on self-attention and supervised learning to train credit assignment capability offline: sample many trajectories (often a mixture of expert and non-expert ones) from the source distribution, train a self-attentive seq2seq model to predict the rewards in these trajectories offline. Once this model is trained, they apply this model to a relatively small set of sampled trajectories from the target distribution and obtain the attention weights. Then, they use these attention weights as a proxy for credit assignment and, thus, use them to form a reward redistribution function. In their experiments, they show that the average attention weights actually signal the state-actions at which the future reward is triggered. They also show in their experiments that SECRET improves learning performance on in-domain transfer learning (larger mazes), as well as an out-of-domain case (with modified dynamics).             ","This work focuses on credit assignment using a self-attention module for transfer RL problems. Specifically, the reward signals are assigned backward to previous states according to the attention weights. This can be helpful especially when the reward signal is sparse. Experiments on the newly proposed Triggers environment and the DMLlab keys & doors environment show that the proposed algorithm, SECRET, can speed up training in the transferred environment.",0.06802721088435375,0.29411764705882354,0.11049723756906077
1543,SP:8facdf5c306fe8f0e82a7072ebb51ce7efd0df7f,"This paper analyzes the bias of models in pool-based active learning settings where the sampling procedure is probabilistic (non-deterministic). It proposes two unbiased estimators of the population risk that weight the loss for each sampled data point. Empirical experiments demonstrate that these unbiased estimators work well for active learning settings with under-parameterized models, but are less effective for over-parameterized models. For the latter case, the authors provide meaningful insights into why biased estimators of population risk may actually be beneficial for over-parameterized models.","The authors consider the bias (in the risk) introduced by active sampling strategies with respect to the true underlying data generating distribution. They then propose two estimators of the risk -- SURE and PURE -- that are unbiased and asymptotically consistent under certain assumptions. The authors consider two toy examples where they show the existence of active learning bias, and the effect of removing this. In particular, the authors notice that while training a linear regression (based on actively acquired datapoints) with their unbiased risks improves test loss, the opposite happens for a Bayesian Neural Network (BNN). They then provide a potential explanation for this phenomenon. ",0.2159090909090909,0.18269230769230768,0.19791666666666666
1544,SP:8fc1395223e3afe44e5c4ce3ed21bd94388a0411,"This paper presents a new dataset for continuous control tasks based on the DeemMind control suite, but with varying backgrounds, colors and lighting/camera conditions. Instead of the fixed appearance in the original suite the frames from this dataset contain a lot of varying structure. The purpose of the dataset is to measure the generalization and transfer abilities of pixel-based continuous control agents across different visual variations.","This paper extends the DeepMind Control Suite benchmark by adding a series of visual variations across different tasks (e.g. lighting, color, background, textures, camera angles etc.). They also contrast a few recent self-supervised learning and data augmentation RL methods and measure these agents’ ability to generalize and transfer across a variety of visual variations provided by their benchmark. They also investigate different aspects of the variation in the scene that these agents seem to be most affected by.",0.20588235294117646,0.175,0.18918918918918917
1545,SP:8fc97dbc3d6e099b49cb402a6057a41dbe72ac9f,This paper proposes scaled uncertainty prediction in the context of unsupervised domain adaptation. The problem in unsupervised domain adaptation is to obtain predictions in a target domain where no (or few) labels are available. A secondary problem then is the calibration of predictive uncertainties in the target domain. This paper proposes a model of uncertainty proportional to the (log) of density ratios between domains. Results include ECE and Brier scores on two common Domain Adaptation datasets. ,"This paper focuses on the problem of uncertainty calibration under distribution shift. By using a domain classifier in the distributional robust learning (DRL) framework, the authors estimate the density ratio between the source and target domain to achieve well-calibrated predictions under domain shift. A regularized DRL framework is further proposed to promote smoothed model prediction and improve the calibration. Experiments on Office31, Office-Home, and VisDA-2017 demonstrate the superiority of DRL over empirical risk minimization (ERM) and the temperature scaling method measured by expected calibration error (ECE), Brier Score, and reliability plots.",0.25,0.20212765957446807,0.22352941176470587
1546,SP:8fce429bf3b980f2f41e5305fd35604dbfe83508,"The paper analyses several consistency (stability) properties of the unfolded adjacency embedding (UASE), a spectral embedding method for dynamically evolving graphs. Specifically it is shown that UASE yields cross-sectionally and longitudinally stable embeddings. This is contrasted with other (spectral) embedding methods which generally do not achieve these properties.","The paper studies the problem of stability of an embedding of a dynamic network. This corresponds to deriving a time varying vectorial representation for each node such that nodes behaving similarly at a given time have similar positions (cross-sectional stability), and a node behaving similarly across different times has a constant position (longitudinal stability). Assuming  a dynamic random geometric graph model, the authors show for this model that (1) the unfolded adjacency spectral embedding (UASE) procedure satisfies the aforementioned stability properties, and (2) other methods such as omnibus or time-averaged spectral embedding lack one form of stability.",0.2857142857142857,0.1414141414141414,0.18918918918918917
1547,SP:8ff1115adfd50e2c1512534ec8b90f91e0c0c331,"The paper methodically analyses the settings and choices used when training neural networks (specifically CNNs) via the DP-SGD algorithm and suggests changes to the standard procedures that empirically lead to higher accuracies despite the added noise. The main statement of the paper is quite simple: optimize hyperparameters for the model that you're training (DP-SGD) rather than the model it is inspired by. Yet, the findings an recommendations may be useful for practitioners.","This paper presents experimental evidence that learning with privacy requires approaches that are not identical to those used when learning without privacy. These approaches include re-considering different model choices (i.e., its structure and activation functions), its initialization, and its optimization procedure. With these changes, they show that it is possible to obtain state-of-the-art results for some canonical learning tasks.",0.13333333333333333,0.15625,0.14388489208633093
1548,SP:9002e8827008fb50594757c4aab871b9cb29963b,"This paper studies how temperature scaling affects training dynamics of neural networks (with softmax layer and cross-entropy loss). The theoretical analysis shows that neural networks trained with smaller inverse temperatures (beta) exit the linear regime faster, which implies better performance. Experiments on image classification and sentiment analysis confirm that tuning temperature improves neural network generalization, even for state-of-the-art models.","This paper investigates how the inverse temperature parameter $\beta$ in the softmax-cross-entropy loss impacts the learning and the generalization. In the theory part, this paper introduces the concepts of early learning timescale and nonlinear timescale, and shows how the learning dynamics depend on the parameter $\beta$. The empirical investigations are carried out with wide Resnets on CIFAR10, Resnet50 on ImageNet, and GRUs on IMDB. The results suggest that the optimal $\beta$ is architecture sensitive. ",0.25396825396825395,0.21052631578947367,0.2302158273381295
1549,SP:900ada28e9a27c6ad856871ad5f04c50dc95e023,"The paper proposes the use of ""Copulas"" to capture dependencies among agents in multi-player environments. The authors argue that prior work(eg GNN, VAE, LSTM etc based) do not leverage the common structure among agent behaviour. They explain how the copula can more efficiently encode the dependency among policies, as compared to simply factorizing. The authors provide empirical results on real world and synthetic datasets, showcasing superior performance against baseline approaches.","The paper proposes a multi-agent imitation learning method that learns a joint policy for all agents from offline demonstrations. The key idea is to first learn a marginal policy for each agent using behavioral cloning, then fit a copula function that captures dependencies between the agents' policies. Experiments with particle simulations, simulated driving, and simulated RoboCup suggest that this approach could potentially outperform prior methods.",0.1527777777777778,0.16666666666666666,0.15942028985507248
1550,SP:901c17ac44336aac0aafd475c62e50c51b314057,"The paper present ELLA, a three-part solution to instruction following tasks with a high-level instruction and a pre-defined set of low-level instructions:  1. a termination classifier is trained offline to identify the completion of a low-level goal at a state; 2. a relevance classifier is learned online to predict a binary relevance of a low-level goal to a high-level goal. 3. reward shaping is used to encourage low-level goals suggested by the relevance classifier.  ELLA is shown to improve sample complexity on 5/6 BabyAI tasks of diverse environment and instruction complexities, compared to an ablation PPO model with reward shaping, and a baseline model LEARN.","This paper presents a reward shaping approach that provides immediate rewards through the achievement of low-level sub-tasks. The authors assume a problem where a high-level task given in the natural language in a sparse reward environment consists of several low-level sub-tasks, and aim to guide the agent to effectively explore using task structure. Two components (termination classifier and relevance classifier) are proposed, and reward shaping is performed using them. Finally, the authors demonstrated the results on BabyAI, a grid world platform for instruction following tasks. ",0.18421052631578946,0.23333333333333334,0.20588235294117646
1551,SP:902b1484ef76a82c7a43a9eac6e65c5e08f8345a,"The authors introduce ReSWAT, a method for transformation-resilient watermarking of images via adversarial training. The high level idea is to learn a watermark/detector pair (W,D). W can be any transformation (in this paper, an l-infty bounded perturbation) that imputes an imperceptible distortion to a given input, while D is a detector that distinguishes watermarked from non-watermarked images. There is an additional requirement that the detector should be robust to simple transformations such as rotations, cropping, flipping, and contrast enhancement. ","This paper is about a novel method to add watermarks to images and audio that is highly robust to several transformations that is closely related to gan methods. The idea is that the watermark signal is learned concurrently to the detector network, which share similarities to a generator and detector networks. Five standard attack transformations are considered and a specific optimization to reduce the transferability of the watermark is considered. The method is compared against Broken arrows on Cifar10 and Imagenet. It shows similar or better performance for Gaussian noise attack given the same amount of perturbance allowed in a signal while very much better performance for the other attacks. Going beyond the five attacks, the paper also includes an estimation of the probability of confidence of finding watermarked images given a fixed l2 norm radius. Finally the method is also tested on audio on a proprietary dataset with a deepspeaker architecture which still shows very good performance and it is confirmed by a human evaluation where participants found the watermarked audio not significantly worse or degraded.",0.20238095238095238,0.096045197740113,0.1302681992337165
1552,SP:9043128647ca5b26b38c11af6fddf166e012a390,"The paper proposes a meta reinforcement learning algorithm called MetaGenRL, which meta-learns learning rules to generalize to different environments. The paper poses an important observation where learning rules in reinforcement learning to train the agents are results of human engineering and design, instead, the paper demonstrates how to use second-order gradients to learn learning rules to train agents. Learning learning rules in general has been proposed and this paper is another attempt to further generalize what could be learned in the learning rules. The idea is verified on three Mujoco domains, where the neural objective function is learned from one / two domains, then deployed to a new unseen domain. The experiments show that the learned neural objective can generalize to new environments which are different from the meta-training environments. ","This paper presents a novel meta reinforcement learning algorithm capable of meta-generalizing to unseen tasks. They make use of a learned objective function used in combination with DDPG style update. Results are presented on different combinations of meta-training and meta-testing on lunar, half cheetah, and hopper environments with a focus on meta-generalization to vastly different environments.",0.12878787878787878,0.2833333333333333,0.17708333333333334
1553,SP:9069605b56fbdb1ae6ea1179e56a2e3f4c12045d,"This paper presents a dialogue response generation model based on the framework of adversarial autoencoder. Specifically, the proposed model uses an autoencoder to encode and decode a response in a dialogue, conditioning on the context of the dialogue. The RNN encoded context is used as the prior of the latent variable in the autoencoder, and the whole dialogue (context + response) is used to infer the posterior of the latent variable. The inference is done by the adversarial training to match the prior and the posterior of the latent variable. Besides constructing the prior with a single Gaussian, the variant of the proposed model is also proposed where the prior is constructed with a Gaussian mixture model.","This paper uses Wasserstein GAN in conditional modeling of the dialog response generation. The main goal is to learn to use two network architecture to approximate the posterior distribution of the prior network. Instead of a KL divergence, like in VAE training, they use adversarial training and instead of using softmax output from the discriminator, they use Wasserstein distance. They also introduce a multi-modal distribution, GMM, while sampling from a the posterior during training, prior during the test time. The multi-modal sampling is based on gumbel-softmax over K possible G-distributions. They experiment on Daily Dialog and Switchborad datasets and show promising improvements on qualitative measures like BLEU and BOW embedding similarities, as well as qualitative measures including human evaluations comparing againsts substantial amount of baselines.",0.19827586206896552,0.17829457364341086,0.18775510204081636
1554,SP:906e0447c7ae0b27e107132f3795a83d4b7e48e6,"The paper presents a new SDE solver for the reverse process in score-based models. The algorithm is fast and offers high quality, and avoids some hyperparameter tuning. There is theoretical analysis on the stability and bias of the algorithm. The paper also has experiments comparing the proposed algorithm to several baseline methods. ","Score-based/diffusion-based generative models can achieve high sample quality. However, their sampling speed is slow due to the large number of evaluations required by numerical SDE solvers. This works aims to accelerate the sampling process by using a more efficient SDE solver. The proposed approach generates data 2 to 10 times faster than the baselines while achieving reasonably well sample qualities.",0.22641509433962265,0.19047619047619047,0.2068965517241379
1555,SP:90770091765daddb1479bb8adbb2b5631171d269,"Ensembles of probabilistic models (e.g. for classification) provide measures of both data uncertainty (i.e. how uncertain each model is on average) and model uncertainty (i.e. how much the models disagree in their predictions). When naively distilling an ensemble to a single model, the ability to decompose total uncertainty into data uncertainty and model uncertainty is lost. This paper describes a method for ensemble distillation that retains both types of uncertainty in the case of classification. The idea is to train a prior network (i.e. a conditional Dirichlet distribution) to model the distribution of categorical probabilities within the ensemble. Both total uncertainty and data uncertainty can then be computed analytically from the prior network.","This paper notes that ensemble distillation (EnD) loses the distributional information from the original ensemble, which prevents users of the distilled model from being able to obtain estimates of its knowledge uncertainty. It proposes the challenge of distilling the ensemble in a way that preserves information about the ensemble distribution, so that knowledge uncertainty can still be extracted from the distilled model. It names this task ""Ensemble Distribution Distillation (EnD^2)"". It then proposes using Prior Networks (introduced in Malinin & Gales 2018) as a solution, and proceeds to evaluate it with a series of experiments -- first obtaining some intuition from spiral dataset, then more rigorously on benchmark image datasets (CIFAR10/100/TinyImageNet).",0.15384615384615385,0.16071428571428573,0.1572052401746725
1556,SP:909aed1f85884ac86edbb664e8617ef711a47eb0,The authors state a clear hypothesis: it is possible to extract syntactic information from contextualized word vectors in an unsupervised manner. The method of creating syntactically equivalent (but semantically different) sentences is indeed interesting on its own. Experiments do support the main hypothesis -- the distilled embeddings are stronger in syntactic tasks than the default contextualized vectors. The authors provide the code for ease of reproducibility which is nice.,"This paper aims to disentangle semantics and syntax in contextualized word representations. The main idea is to learn a transformation of the contexualized representations that will make two word representations to be more similar if they appear in the same syntactic context, but less similar if they appear in different syntactic contexts. The efficacy of this transformation is evaluated through cluster analysis, showing that words better organize in syntactic clusters after the transformation, and through low-resource dependency parsing. ",0.17647058823529413,0.1518987341772152,0.163265306122449
1557,SP:90b93c165039046b77b5c3ee1df5b1090bfd0f42,This paper studies meta-learning in multi-agent reinforcement learning. It proposes a meta multi-agent policy gradient method that considers the learning processes of other agents in the environment for fast adaptation. This method can be seen as a unified framework of previous methods (Al-Shedivat et al. (2018) and Foerster et al. (2018a)). The method outperforms previous methods in two matrix games and 2-agent HalfCheetah.,"This paper points out that a key challenge in MARL is the non-stationarity of other agents' policies, as opposed to previous papers which only account for non-stationarity of the environment. The paper extends (Al-Shedivat et al., 2018) by directly conditioning the meta-policy on a distribution of other agents' policies. In my opinion, the major contribution of this paper is a new multiagent meta learning theoretic framework that explicitly accounts  for the dynamics of all agents. ",0.23529411764705882,0.20253164556962025,0.21768707482993196
1558,SP:90cd795a78c403b27c768be54597bd04cc0fbaa3,"This paper proposes the softmax gradient tampering to modify the gradients in the backward pass to enhance the accuracy. The predicted probability value is transformed using a power-based probability transformation, and the gradient profile is more smooth. The experimental results show the slight accuracy increase.","In this paper, the authors propose a technique called Softmax Gradient Tampering, which transforms the predicted output class probabilities to improve training performance of neural networks. The authors show that the proposed technique results in a smoother output probability distribution for lower values of the hyperparameter $\alpha$. On standard benchmarks on the ImageNet and CIFAR-10 datasets, the authors show that the proposed method results in better training accuracy performance as well as improved generalization performance.",0.3695652173913043,0.2236842105263158,0.2786885245901639
1559,SP:90f424a96631bc8acfa842459eb7aa592d0f2bac,"This paper presents an approach for biasing an agent to avoid particular action sequences. These action sequence constraints are defined with a deterministic finite state automaton (DFA). The agent is given an additional shaping reward that penalizes it for violating these constraints. To make this an easier learning problem for the agent, its state is augmented with additional information: either an action history, the state of the DFA, or an embedding of the DFA state. The authors show that these approaches do reduce these action constraint violations over not doing anything about them.","This paper presents an DFA-based approach to constrain certain behavior of RL agents, where ""behavior"" is defined by a sequence of actions. This approach assumes that the developer has knowledge of what are good/bad behavior for a specific task and that the behavior can be checked by hand-coded DFAs or PDAs. During training, whenever such behavior is detected, the agent is given a negative reward, and the RL state is augmented with the DFA state. The authors experimented with different state augmentation methods (e.g. one-hot encoding, learned embedding) on 3 Atari tasks.",0.25806451612903225,0.24742268041237114,0.25263157894736843
1560,SP:90f90a6bb1e055d5cf386162c2e1d17a95d4db29,"The paper aims to study the effect of stability on generalization of a particular off-policy policy evaluation algorithm. Specifically, the authors study a version of Fitted Q-evaluation where the iterative procedure is instead thought of as a gradient update and is performed by only partially fitting the new Q-function to the current target Q function. The authors look at a linear function approximation setting and connect the recent results on stability of stochastic gradient methods (Hardt et al, 2016) with their method and show stability results, and connect that with overfitting of the policy evaluation scheme. The authors discuss the effect of the number of updates performed in each epoch during the partially fitted linear-update scheme and further show empirical simulations.","As far as I can see, this work tries to leverage the connection between stability and generalization studied in supervised learning settings, and tries to build a similar connection for batch RL settings. To reason about stability in a batch RL problem, this work proposes a modified definition of stability that takes into account the two different distributions involved: the distribution generated by the interaction between the environment and the policy that generated the data, and the distribution corresponding to the policy being evaluated. Then the main result of the paper (Theorem 1) proposes an upper bound on the stability for fitted expected SARSA (and linear value function approximation).",0.176,0.2018348623853211,0.18803418803418803
1561,SP:91139c0d3614e87c45be3e66110fb01813492e06,This paper provides a variety of studies to understand the generalization gap between known and novel classes in one-shot object detection. The studies are carried out by using siamese Faster R-CNN framework on four benchmark datasets. The most notable observation was that it was more important to increase the number of object category than to increase the number of instances per each category in order to reduce the generalization gap. This observation is very useful to anyone planning to build a dataset for this task or implement the appropriate method. Figure 5 is very important and well presented to support the main claim.,"The paper suggests that a major factor for increasing few-shot performance in the few-shot object detection task is the number of categories in the base training set used to pre-train the few-shot model on a large set of data before it is adapted to novel categories using only a few (or even 1) examples. This effect is measured by the authors by trying out the existing Siamese few-shot detector on 4 datasets: PASCAL, COCO, Objects365, and LVIS showing that the gap in performance on the seen training and the unseen (novel) testing categories is reduced when the base dataset has more classes (e.g. on LVIS where there are more than 1K classes, this ""generalization"" gap is shown to be minimal). The authors also quantify empirically the effect of increasing the model size and of prolonging the training schedule on this gap. As well as testing on COCO classes while training on LVIS.",0.20952380952380953,0.13924050632911392,0.1673003802281369
1562,SP:911e9288b3fc37197681962df1df1db17fcffd52,"This work proposes ELF, a newl method to do line search. The key idea is to fit a low order polynomial of the empirical loss (by sampling multiple batches) along the direction of a mini-batch gradient. The method stays computationally efficient by only computing the step size every so often. Experiments on a variety of image classification tasks show that ELF is competitive to GOLS1, PLS, PAL, SGD, and Adam, while taking less time to train.","The paper tackles an important issue, namely how to tune the step sizes in SGD during the training, trying to approximate step sizes which would be used in GD (even though the search direction is still noisy). Relevant prior work is cited. The method is simple and easy to understand. Step sizes are kept piecewise constant over updates. New batches are sampled, and the loss values along the search line are fitted with a low-order polynomial. There is some heuristic to choose the interval around 0 for the step. Importantly, these batches are sampled from the validation set. While this sounds very elaborate to find the minimum of the approximation, they later say they are just trying for sufficient descent along the line. Compared to previous work, the method is simple and seems quite robust. As drawbacks, the method seems pretty expensive, and it has a large number of free parameters that need to be chosen.",0.2597402597402597,0.12738853503184713,0.17094017094017094
1563,SP:913965fb0d96422d092b90304a652255f57f2a3c,"This paper describes a deep learning architecture for representing and performing classifications on protein structures.  The representation involves three different distances: Euclidean distance and the shorted path between two atoms, where edges are either along covalent bonds or also include hydrogen bonds.  Each atom has a vector of associated features, and convolution is accomplished by defining a kernel on all three distances and then summing the features of each neighboring atom, weighted by the kernel value.  The paper also proposes three protein-specific pooling operations to cope with the large input size when representing all atoms in a protein.","The authors describe a method to transform 3D protein structures for supervised machine learning. Their method introduces a convolution operation that considers both the intrinsic distances between atoms as defined by their bond structure and the extrinsic distances as defined by 3D proximity. They also introduce interpretable pooling operations developed using known biology of the amino acids. Overall, the method is effective and straightforward to follow due to having avoided unnecessary complexity. The figures greatly aid the reader.",0.16161616161616163,0.20512820512820512,0.18079096045197743
1564,SP:913e4b2754a85df298f868cd55e0f40b3e4e88a4,"This paper proposes a new deep learning architecture called ST-GNN that learns representations on graphs that evolve over time. Their work focuses on developing an interesting time-varying convolutional architecture, which exploits the graph-time underlying structure of the signals, processing across both the graph and time domains. The authors introduce new graph shift operators (GSO), time shift operators (TSO), followed by a linear combination of those which results in a space-time shift operator termed STSO. The advantage of this paper is that it can handle continuous-time graph signals and the stability of this proposed architecture is studied theoretically (Section 4) with a significant result outlined in Proposition 1 of the paper where the difference between the space-time graph filters of the original graph and the perturbed graph are upper bounded by the order of error introduced.    ","This paper introduces a new spatio-temporal Graph Neural Network, ST-GNN, for making predictions on temporal network. Its proposed space-time convolution operator is a composition of temporal convolution and graph diffusion. The paper further proves that under practical conditions their ST-GNN with Integral Lipschitz filters is stale to small perturbation in both time and graph domain. ",0.1347517730496454,0.3220338983050847,0.19
1565,SP:914f06bae289e10ae114cc43130751b8a8859b46,"This paper analyzes the role of learning rate in re-training after pruning, building on previous findings that changing the learning rate schedule of re-training can result in higher accuracy than low-learning-rate fine-tuning. The paper proposes several learning rate schedules to compare, specifically a cyclic learning rate (gradually ramping up to and back down from the maximum learning rate schedule used during the original training phase) and a compressed version of the original learning rate schedule, and shows that these learning rate schedules outperform standard fine-tuning and also learning rate rewinding, showing that the findings of prior work come from using a higher learning rate in general and not any specific schedule. The paper than shows that choice of re-training learning rate schedule can have more impact on final accuracy than choice of saliency metric.","The authors conducted a comprehensive set of experiments on choices of learning rate schedules for re-training/fine-tuning during iterative or after 1-shot pruning of deep convnets.  Empirically, they reported that high learning rate (LR) is particularly helpful in recovering generalization performance of the resultant sparse model.  The results are purely empirical, well-documented observations from well-designed experiments, which is of practical value in practice of network compression, and the consistent, somewhat surprising observation raises interesting questions.  ",0.1347517730496454,0.2375,0.17194570135746604
1566,SP:915803c7eee23272e85bb7933618a240f57d6c36,"The authors propose a search for neural architectures with different resource requirements by training a single model only. Furthermore, models found at the end of the search require no additional post-processing and are ready for deployment. A weight-sharing technique is applied to make this happen. The authors argue that there are multiple adaptions required to make it work. This includes the child model sampling strategy, use of model distillation, weight initialization, learning rate schedule, regularization and batch norm calibration.","This paper presents a method for architecture search in deep neural networks in order to identify scaled-down networks that can operate on resource limited hardware. The approach taken in this paper is different from other approaches, which train a single big model then fine tune smaller models for specific hardware, or use distillation to train progressively smaller models. Here, a single model is trained in a manner that allows subsequent slicing to smaller models without additional training required. The authors employ a variety of strategies to get this to work well, including specific initialization techniques, regularization methods, learning schedules, and a coarse-to-fine optimization method to obtain the smaller models. The authors demonstrate SotA performance on ImageNet relative to other techniques.",0.2345679012345679,0.15447154471544716,0.18627450980392157
1567,SP:9163fcb6581b48b4abdbcb046e4b46cb0bb4d0fc,"**The main idea of the paper**  This paper combines two powerful ideas, 1. unsupervised keypoint extraction for objects and 2. object-centric representation for forward modeling. KINET first detects objects' key points in the video in an unsupervised manner and extract object-centric representation for future prediction. Experiments are conducted in a new dataset built on MuJoCo and the performance in table 1 shows the proposed framework achieves better performance than the baseline methods.","The paper proposes a keypoint-based forward dynamics model for generalization to unseen number of objects. The model employs unsupervised keypoint extraction methods from the literature, infers probabilistic graph representations over the keypoints, and makes forward predictions by message passing. The model is evaluated on multi-object manipulation tasks. It is shown that the model prediction error is close to that of a graph net with access to groundtruth object positions. The model is also shown to converge to the goal configuration faster than the baselines.",0.21621621621621623,0.18604651162790697,0.2
1568,SP:916a926ade24fe69c246bd54d314087bafb1b5b8,"# Summary & Contributions * This paper examines a variational approach to reinforcement learning, leveraging occupancy measures over previously visited and future state-action pairs in order to address the exploration challenge. * The author propose a variational approximation to the so-called ""conditional occupancy"" of the current behavior policy denoting the distribution over future state-action pairs. The approximation is used to induce broader state visitation from the behavior policy, coupled with a standard actor-critic algorithm. * Empirical results show considerable performance gains in simpler continuous control problems and matching performance against baseline methods in more high-dimensional control tasks.","The authors address the problem of exploration in reinforcement learning. They suggest applying the maximum entropy principle over the state space and try to maximize the make the occupancy of the policy as entropic as possible while still optimizing the original goal of maximizing cumulative reward. They claims include an algorithm that does this using a replay buffer and off-policy learning, which improves sampling efficiency, in sparse and dense reward settings, in classic motor control benchmarks.",0.17525773195876287,0.22077922077922077,0.1954022988505747
1569,SP:916fbf4e8da5fb73f5012ec5711662cd9be2e067,"This paper aims to answer a very important and difficult question, i.e., given a clustering application what are the desirable qualities (i.e., similarity indices) to have. This work argues that there are so many clustering similarity indices with (sometimes) disagreements among them. The authors run experiments on 16 real-world datasets and 8 well-known clustering algorithms and provide a theoretical solution and a list of desirable properties that can help practitioners make informed decisions. Moreover, the authors also discuss the important pros and cons of the similarity indices in the context of the applications.","Cluster Similarity Indices (CSIs) take as input two clusterings A, B and assign a similarity score for the given pair of clusterings. The index calculates a score based on the number of pairs of elements that clustered together on both clustering (N++), those that are not clustered together in non of A,B (N--), those that are clustered together in A but not in B (N+-), and vice versa (N-+). CSIs can be used to evaluate clusterings produced by different algorithms with respect to some reliable reference clustering on a single instance, and choose the one that is the closest to the reference clustering (indicated by the CSIs). The selected clustering algorithm can be then applied to different instances of the same kind where we do not have a reference clustering. ",0.1958762886597938,0.1450381679389313,0.16666666666666666
1570,SP:91933924103285d6fcac3649cf407b7021371625,"The paper proposes a model-based asynchronous multi-fidelity method to optimize hyperparameters and perform a neural architecture search (NAS). The paper begins by addressing the differences between synchronous and asynchronous scheduling in Successive Halvining (SH) and its variants. It also analyzes the different stopping rule criteria. Based on these insights, the paper proposes a unified approach called BOBSTER that combines asynchronous scheduling and multi-fidelity Bayesian optimization. The authors empirically demonstrate that BOBSTER can find the optimal hyperparameters (architecture) more efficiently in terms of wall-clock time than other state-of-the-art algorithms on NAS, image classification task, and language modelling task.","This paper has proposed to exploit a GP model to represent the correlation between configuration-rung tuples (as is typical in multi-fidelity BO) in asynchronous successive halving (ASHA) (Li et al. 2018), which has resulted in performance improvement over the state of the art, as shown in the experimental results. The experimental results are extensive and compelling. Introducing a GP to model the correlation between configuration-rung tuples in the existing ASHA work offers minimal technical merit though. Can the authors elaborate on whether there is any nontrivial, novel technical challenge with such an integration? This question does not seem to be adequately addressed in the paper.",0.15384615384615385,0.14814814814814814,0.1509433962264151
1571,SP:91d14609f187639dc495365f2c40bd319d8b988b,"The authors introduce EvoGrad, a method for approximating second order gradients for use in Meta-Learning applications. The method approximates the inner loop of optimization with ""evolutionary"" update. The authors show their method is more computationally efficient than the T1-T2 method, yields good approximations to the second order gradients and is able to converge in the toy setting, and achieves better results than MetaWeightNet, a second order method, on a cross-domain few-shot classification task. ","The paper presents an efficient gradient-based meta-learning algorithm based on evolutionary techniques. The proposed algorithm doesn’t require second order gradient computation, and thus, is more efficient. The proposed approach was evaluated on two meta-learning tasks for few-shot feature-wise transformation and noisy label learning, on which time and memory efficiencies were demonstrated.",0.16883116883116883,0.22807017543859648,0.19402985074626866
1572,SP:91fbd1f4774de6619bd92d37e1a1b1e7f2ed96f3,The paper proposes an extension to the Viper[1] method for interpreting and verifying deep RL policies by learning a mixture of decision trees to mimic the originally learned policy. The proposed approach can imitate the deep policy better compared with Viper while preserving verifiability. Empirically the proposed method demonstrates improvement in terms of cumulative reward and misprediction rate over Viper in four benchmark tasks.,"The paper proposes a method (MOET) to distillate a reinforcement learning policy  represented by a deep neural network into an ensemble of decision trees. The main objective of this procedure is to obtain an ""interpretable"" and verifiable policy while maintaining the performance of the policy. The authors build over the previously published algorithm Viper (Bastani et al, 2018), which distillates deep policies into a single decision tree using the DAGGER procedures, i.e. alternation of imitation learning of an expert policy and of additional data-sampling from the newly learned policy. In the VIPER algorithm decision trees are chosen because their structured nature allows to formally prove properties of the policy they represent when the environments dynamics are known and expressible in closed form. ",0.3230769230769231,0.1693548387096774,0.2222222222222222
1573,SP:920a85e9bb41f314245b46027fd4551346215dc3,"This paper tries to introduce stochasticity over context representation to enable the neural networks to search for effective representation so as to avoid getting trapped into local optima. The basic idea is to formulate the posterior probability of context representation via a mixture gaussian model. The standard attention model SA can be thought of as a special case of the proposed method. The proposed method outperforms a number of baselines on ADS, video captioning, and machine translation datasets.","This paper presents a new way to construct the context vector in seq2seq networks. Specifically, the context vector in the proposed model is treated as a latent variable with a normal prior. The posterior is ""defined"" as a mixture of the latent presentations of the input sequence and the mixing weight is the attention. To do inference, maximising VAE-like ""ELBO"" is used. The proposed model is reported to achieve better performance in the seq2seq tasks including document summarisation and video caption.",0.21794871794871795,0.2073170731707317,0.21250000000000002
1574,SP:92370bd193d2a808b6803cb3a22ab3d690f1e13d,"In this paper, the authors investigate non-autoregressive translation (NAT). They specifically look into how using different auto-regressive translation (AT) models for knowledge distillation impacts the quality of NAT models. The paper is well organised and the experiments are sound and interesting, shedding light on an aspect of NAT models that's been rather dismissed as secondary until now: the impact of varying AT knowledge distillation.","The paper analyses recent distillation techniques for non-autoregressive machine translation models (NAT). These models use a autoregressive teacher (AT), which typically perform better. However, AT models can not be parallelized that easily such as the NAT models. The distillation has the effect of removing modes from the dataset which helps the NAT models as they suffer from the averaging effect of maximum likelihood solutions. The authors analyze why such distillation is needed and what the effect of the complexity of the training set is and further propose 3 methods to adjust the complexity of the teacher to the complexity of the NAT model.",0.29850746268656714,0.19230769230769232,0.23391812865497075
1575,SP:9240db905d01022b6dc03f6789c3c853d8c84b4b,"This work explores the disentangling properties of contrastive methods. The authors discover that contrastive methods, particularly BYOL, learns disentangled representations with just a change of normalization method in the encoder. The work also proposes a new concept called ""group disentanglement"", which is a relaxed version of the original disentanglement. BYOL learns representations with group disentanglement and achieves SOTA on disentanglement benchmarks on not only synthetic image datasets but also a real world dataset.","This paper makes an interesting empirical observation - BYOL representations have better disentanglement properties, according to some metrics, than current specialized methods. Furthermore, the authors found that the selection of the normalization function affects the results. The authors also claim the dimensions are ""group disentangled"" although this is only shown on one dataset.",0.2054794520547945,0.28846153846153844,0.24
1576,SP:924990a4586c7570f0b6a9d4f58d94ad8f4f5cc4,"This paper introduces several autoencoder (AE) regularization terms that aim at reproducing continuous realistic deformation by interpolating latent codes of images. The authors assume there is a continuous process generating the data and introduce three novel loss terms (in addition to the standard AE reconstruction loss). The first term is a GAN loss for decoded interpolated latents $\hat{x}(\alpha)$ where this terms makes sure the interpolated latents are decoded to images similar to the train images. The second term is called cycle-consistency and enforce injectivity of the decoder. The last term is enforcing smoothness of the decoded image as a function of the interpolated latent. Combining these three losses with the original loss leads to natural interpolations of latents that enjoy both smoothness and realism.  The method is tested on a synthetic ""pole shadow"" example, and COIL 100. The method seem to improve upon several baselines on these datasets. ","This paper focused on developing a new regularization technique for autoencoders, which shapes the latent representation to follow a manifold that is consistent with the training images and that drives the manifold to be smooth and locally convex. The authors suggest that the manifold structure of continuous data must be considered to include the geometry and shape of the manifold. The new interpolation regularization mechanism consists of an adversarial loss, a cycle-consistency loss, and a smoothness loss. So the architecture of the proposed model includes a standard autoencoder, a discriminator and the loss mentioned above. ",0.15894039735099338,0.25,0.19433198380566802
1577,SP:925ffc4463ef78ca77f5ae77a63b86d7fa87a1cd,"This paper presents a novel approach (DG-Net) to “generate” a dynamic structure for the neural network, by learning to predict and select the edges between computational nodes in an end-to-end manner. The method is based on a gating mechanism, applied on top of a fully connected graph (similar to the connectivity in a DenseNet), designed to control the quantity of information received from each previous layer. The experiments show consistent improvement in image classification (ImageNet) and object detection (COCO).","This work proposes a novel method, called Dynamic Graph Network (DG-Net), for optimizing the architecture of a neural network. Building on the previous work introduced by (Xie et al., 2019), the authors propose to consider the network as a complete directed acyclic graph (DAG). Then, the edge weights of the DAG are generated dynamically for each input of the network. At each node of the network, the authors introduce an extra-module, called router, to estimate the edge weights as function of the input features.",0.24390243902439024,0.23255813953488372,0.2380952380952381
1578,SP:927a1f8069c0347c4d0a8b1b947533f1c508ba42,"The main claim of this paper is that a simple strategy of randomization plus fast gradient sign method (FGSM) adversarial training yields robust neural networks. This is somewhat surprising because previous works indicate that FGSM is not a powerful attack compared to iterative versions of it like projected gradient descent (PGD), and it has not been shown before that models trained on FGSM can defend against PGD attacks. Judging from the results in the paper alone, there are some issues with the experiment results that could be due to bugs or other unexplained experiment settings. ","The authors claimed a classic adversarial training method, FGSM with random start, can indeed train a model that is robust to strong PGD attacks. Moreover, when it is combined with some fast  training methods, such as cyclic learning rate scheduling and mixed precision, the adversarial training time can be significantly decreased. The experiment verifies the authors' claim convincingly.",0.1368421052631579,0.22413793103448276,0.16993464052287585
1579,SP:9281a2478824e6b7b300fa7f11d61a5e5d6c1679,"This paper focuses on deriving explainable features for use in graph classification. To that end, they propose StructAgg that is essentially an aggregation process based on the structural roles of nodes that is then used in an end-to-end model. Experiments demonstrate the effectiveness of the proposed approach as it provides comparable performance while providing some explainability. This is an important unsolved problem, and this work provides one such approach to obtain more explainable and intuitive features/embeddings for graph classification.","This paper proposed the StructAgg, an aggregation algorithm in convolutional graph neural network that learns the structural roles for nodes in the graph embedding. In this algorithm, a structural representation of node is constructed through concatenation of latest p layers of node presentation in graph neural network, which consists of information from the p-hop neighborhood. The paper is good quality and its demonstration is clear.  The idea behind is original. However, learning embeddings through concatenation of multiple layers of neural representation is not completely new. The contribution of this paper to the community is not ground-breaking as well.  From the experiment results, it is hard to stress its significance as in most of times this method does not beat the state-of-the-art algorithms. ",0.21951219512195122,0.14173228346456693,0.17224880382775118
1580,SP:92b53426c0008d9890df2c2213da536c132b1046,"This paper introduces a variational generative model based on Neural Cellular Automata (NCA). The model is called the Variational NCA (VNCA).  The VNCA is designed for images:   - The encoder is a typical convolutional neural network.  - The decoder is an NCA that iteratively refines the image, alternating convolutions and upsampling up to the desired image size. The upsampling process is loosely inspired by mitosis in living cells.   The authors perform morphogenesis experiments on three datasets: MNIST, Noto Emoji, and CelebA. The results are good on MNIST, less so on the other two datasets, although there is clear evidence that the model can learn to generate meaningful images.  The authors also perform an experiment to see if the VNCA is robust to perturbations (occlusions) and show that the model has a reasonable degree of robustness even without ever seeing any perturbations at training time.","This paper proposes variational extension of Neural Cellular Automata for image generation. It performs experiments on MNIST, Noto Emoji and CelebA. The likelihood results are shown to be significantly behind SOTA on CelebA and also behind on other datasets. The paper provides qualitative analysis of the self-organized generation process and shows robustness to early-stage perturbations of latents.",0.19014084507042253,0.4576271186440678,0.26865671641791045
1581,SP:92bb35142d496d7afaa07a298a3bffabd00ec352,"The authors propose a learned model specialized on learning Lagrangian fluid dynamics for incompressible fluids. The model is a hybrid between a simulator with explicit advection, collision and pressure correction stages, and a learned model, trained by supervising each of those stages. The authors demonstrate improved stability/conservation of physical properties for a model, and some flexibility to the time-step being changed at test time.","The paper deals with the prediction of 3D Lagrangian Fluid Simulations. Therefore the problem is divided into 3 subproblems, oriented on numerical simulations. An advection part, where the acceleration of the particles is calculated, a collision step, where the boundary effects are included, and a pressure prediction part, where the pressure for maintaining the volume is determined. A graph-based network is used for each part, which is either node or edge-based according to the requirements. ",0.21212121212121213,0.18181818181818182,0.1958041958041958
1582,SP:92c0086763b9510afcb490beb863cbd8a5e550d3,"This paper proposed a causal-driven method aiming to resolve the black-box issue of DNNs. The proposed interventional black-box explanations method tends to be model-agnostic and can apply a variety of DNN models. In the experiments, the authors examined the proposed method on two well-known DNN architectures LeNet and ResNet18. ",The authors aim to give post hoc explanations of Neural Network classifier decisions. They do so by finding causal relationships between model parameters and classifier outputs. To this end model parameters are set to zero and the change in the models prediction is calculated. If the change in prediction exceeds a threshold the parameter is deemed relevant and used for construction of an attribution map.,0.18518518518518517,0.15384615384615385,0.16806722689075632
1583,SP:92d7b00137258b40bcaf13fd19e032cf4c40b3d8,"In this work, the authors propose a new model, named ConVIRT to learn the medical visual representation from paired image and textual data in an unsupervised strategy. In ConVIRT, they mainly use a contrastive loss with two modalities (images and texts) as inputs to learn the representation. The experimental results show their proposed model achieve higher performance than other methods in image classification and zero-shot retrieval tasks.","1. This paper tackles the medical image understanding problem. The aim of this paper is to learn a generic feature representation for medical image that could benefits downstream tasks like medical image classification, zero-shot classification. The main contribution of this paper is proposing a contrastive loss that the matched pair of image and text should have a higher corresponding score than the mis-matched pairs.",0.17647058823529413,0.18181818181818182,0.17910447761194032
1584,SP:92e58feb55f1f058d36bac600b9f8f196fe4cc43,"The paper proposed an algorithm to discover appropriate contact points for deformable object manipulation. A key component of the proposed algorithm is to use an optimal-transport approach that computes a transport priority score for each particle in the deformable body. This score is then used to guide a grid search procedure to determine the best initial contact point for the manipulation. For multiple manipulators, a pre-defined set of poses are enumerated to find the best pose to use. The proposed algorithm is evaluated on tasks that requires a single manipulation motion or a sequence of motions to shape a deformable object into desired shapes. The result shows improved performance compared to prior methods and enables completion of novel tasks that prior methods failed.","This paper proposes a method to solve the multistage manipulation tasks for soft materials. Differentiable physics has been used in controlling and manipulating soft materials since DiffTaichi. However, optimization methods based on local gradient information can be easily trapped in local minima. This paper divides a long task into small stages, within which the contact area will remain unchanged. The contact points are selected by choosing the regions with the largest transport priorities. The end effectors are then placed with poses from the candidate set. After running trajectory optimization using physics gradients, the final pose is finalized as the pose with minimum loss.",0.12,0.14563106796116504,0.13157894736842105
1585,SP:9318b2155b674b593441ffbb97b56c7ce57cb39a,"The paper proposes an extension of Decision Transformer (DT) that can work with distributions of features. A number of prior hindsight-based or context-dependent methods are shown to be special cases of a generic scheme called Hindsight Information Matching (HIM), where arbitrary statistics of future trajectories can be used for conditioning. Therefore, the proposed Distributional Decision Transformer (DDT) can be seen as a practical implementation of the HIM algorithm. Experiments on D4RL medium-expert data for HalfCheetah, Hopper, and Walker2D investigate generalization of DDT. Additionally, another extension of DT called Unsupervised Decision Transformer (UDT) is proposed and evaluated that learns the features and rewards in unsupervised manner.","This work discusses many prior methods under a Hindsight Information Matching (HIM) framework, where the methods can be interpreted as  trying to minimizing the KL divergence between the achieved statistic and some target statistic for a particular choice of statistic. The authors propose to replace the return-to-go conditioning in Decision Transformer with a distribution over some specified state features, which they name Distributional Decision Transformer (DDT). This work also proposes an unsupervised variant, Unsupervised DT (UDT), which does not need certain state features to be specified and can be interpreted as performing offline state-marginal-matching. The authors show in various MuJoCo settings (HalfCheetah, Hopper, Walker2d) that the proposed methods can learn to imitate target information statistics in offline RL and imitation learning settings.",0.25,0.21428571428571427,0.23076923076923075
1586,SP:931e06fb5e7c9eb9e66f88574b3bc7f18627c61b,"The authors propose a method to learn and improve problem-tailored PDE solvers from existing ones. The linear updates of the target solver, specified by the problem's geometry and boundary conditions, are computed from the updates of a well-known solver through an optimized linear map.  The obtained solver is guaranteed to converge to the correct solution and","This paper develops a method to accelerate the finite difference method in solving PDEs. Basically, the paper proposes a revised framework for fixed point iteration after discretization. The framework introduces a free linear operator --- the choice of the linear operator will influence the convergence rate. The paper uses a deep linear neural network to learn a good operator. Experimental results on Poisson equations show that the learned operator achieves significant speed-ups. The paper also gives theoretical analysis about the range of the valid linear operator (convex open set) and guarantees of the generalization for the learned operator. ",0.23728813559322035,0.14285714285714285,0.178343949044586
1587,SP:9328554224b618b5c1ab3190a51c86a35e2c7bfd,"This work proposed a new design for the image classification task named ConvMixer, which brings the idea from CNN to Visual Transformer. Unlike previous ConvNets, Transformer-based models, and MLP-based models, ConvMixer simply applies depth-wise (with skip connection) and point-wise convolutions on the patches. The key point authors claimed is that using patch embeddings is a powerful and important takeaway besides the architecture design. Experiments on ImageNet demonstrate the effectiveness of the proposed model.","The paper presents a very simple architecture which consist of patching the input image and then applying a combination of depth-wise and point-wise convolutions. In the paper, authors evaluate the performance of this model when used for image classification. In their main experiment, they train the architecture using only the ImageNet-1k dataset. On that experiment, they show how their simple architecture is competitive with state-of-the-art architectures. ",0.22077922077922077,0.2361111111111111,0.22818791946308725
1588,SP:934cb790cd96e5a81539938b05d63d0dcb82df0a,"This paper addresses when to use a single network model vs an ensemble of convolutional neural network models based on resource budgets. The authors challenge the notion that ensemble methods should only be used when resources are a non-issue. The authors compare single networks to width-equivalent and depth-equivalent ensemble methods for SVHN, cifar10, cifar100 and tiny imagenet across multiple network architectures and describe the 'Ensemble Switchover Threshold (EST)', the amount of resources beyond which ensembles provide better generalization accuracy than single models. ","This paper establish a robust and holistic framework to compare scaling up an ensemble with scaling up a single networks, where test accuracy, number of paramaters, inference time, memory consumption and training time to converge are considered.  To reduce the intractably large design space of scaling up an ensemble, the author mainly investigate two types of ensembles: depth-equivalent and width-equivalent ensembles.  Through extensive experiments on SVHN, CIFAR-10, CIFAR-100, and Tiny ImageNet with VGGNets, ResNets, DenseNets and WideResNets, the authors discovered an surprising and consistently emerging phenomenon named The Ensemble Switchover Threshold: When the amount of resources (measured by number of parameters, training cost) is beyond this threshold, ensembles methods provide better performance and computation trade-off. ",0.3411764705882353,0.24166666666666667,0.2829268292682927
1589,SP:935ed98ae6074d793f311b963ea3944a8e2c6293,"The paper provides two new generalization bounds for non-linear metric learning with deep neural networks, by extending results of Bartlett et al. 2017 to the metric learning setting. The two bounds have been called the 'sparse' and 'non-sparse' bounds and differ in the norm used for the last layer. Experiments are performed where it is shown that either bound may dominate on real datasets.","In this paper, the authors look at the Rademacher complexity of the family of Euclidean metrics learned on a data set via an $L$ layer network where the activations functions are Lipschitz. The idea behind the proof is to use the bounds for $\epsilon$ net for the embedding network from Barlett, Foster, and Telgarsky 2017. This net, then provides a net for space of metrics with only requiring a change in the constants. Using this net, the authors then use standard arguments to bound the Rademacher complexity.   Specifically for the metric learning setting they show that this bound can be improved. ",0.19696969696969696,0.12871287128712872,0.15568862275449102
1590,SP:9371386507f6840c71853847faddb3075eecbca8,"This paper aims to solve two common limitations in CAM-based methods, and proposes a new type of CAM (Pixab-CAM) that utilize pixel-wise weights instead of channel-wise weight. Meanwhile, the author also proposes to use adversarial attack as a novel evaluation metric. This work demonstrates to be superior to previous CAMs on corresponding metrics.","This paper proposes a method for generating an explanation map (Pixab-CAM) showing which part the CNN model for classification refers to in making a decision. Pixab-CAM utilizes how the classification results are changed by focusing or removing a specific region of the convolutional feature map. By using this, the authors claim that various problems (gradient saturation, single scalar value for a specific channel, dependency on the activation tensor) of existing CAM-based methods are solved. Experiments were conducted on various datasets and metrics, and through this, the effectiveness of the proposed method was verified.",0.21052631578947367,0.125,0.1568627450980392
1591,SP:93718c67acf28ab41a9a773b2c9ba58609c6c717,"This work introduces a method for topology optimization based on implicit neural representations.  The goal of topology optimization generally is to find optimal material distribution that produces the structure which is as stiff as possible. The key idea presented in this work is to use two neural networks: the density network, which implicitly represents optimal material density field, and the displacement network, which implicitly represents displacement field.  The optimization algorithm then proceeds by alternatively training these two networks, while applying additional filtering and ad-hoc supervision to steer the process to better optima. Evaluation is conducted on a set of standard 2D topology optimization tasks. ",The paper proposes a method for topology optimization (TO) in solid mechanics by modeling displacement and material densities as implicit neural networks. TO is a very important field in mechanics and it is exciting to see successful ML applications in the area. The paper shows that their method can solve for topologies under various load and displacement constraints in both 2D and 3D. ,0.1523809523809524,0.25396825396825395,0.19047619047619047
1592,SP:9378bcacf7befab93b6850366fea16d477c01dc6,"This paper proposed an adaptive quantized method which is derived by minimizing a constrained quantization error bound. The theoretical analysis suggests adjusting the quantization level according to the gradient norm, convergence rate of the model, and the current iteration number. Theoretical results show that the dynamic bits leads to better error bound than the fixed bits. The result is intuitive. Overall, the paper is clearly written. But the improvement is not significant enough to warrant a publication at ICLR.","1.	The authors considered uniform upper bound of the stochastic gradients g_i. The authors may argue that ""The classical theoretical analysis of SGD assumes that the stochastic gradients are uniformly bounded"". But one can even strongly argue that this bound is actually $\infty$. Moreover, an even stronger argument can be made that the above assumption is in contrast with strong convexity. Please see [""SGD and Hogwild! Convergence Without the Bounded Gradients Assumption"" by Nguyen et al.] as one of the instances. Please understand there are relaxed assumptions such as Strong growth condition on a stochastic gradient as in Assumption 4 of [1]. ",0.16455696202531644,0.1262135922330097,0.14285714285714285
1593,SP:93889307b8f8a3a63987db76cf053a5a33132f0b,"The paper ""Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow"" tackles the problem of discriminator over-fitting in adversarial learning. Balancing the generator and the discriminator is difficult in generative adversarial techniques, as a too good discriminator prevents the generator to converge toward effective distributions. The idea is to introduce an information constraint on a intermediate layer, called information bottleneck, which limits the content of this layer to the most discriminative features of the input. Based on this limited representation of the input, the disciminator is constrained to longer tailed-distributions, maintaining some uncertainty on simulated data distributions. Results show that the proposal outperforms previous researches on discriminator over-fitting, such as noise adding in the discriminator inputs. ","The authors propose to apply the Deep Variational Information Bottleneck (VIB) method of [1] on discriminator networks in various adversarial-learning-based scenarios. They propose a way to adaptively update the value for the bêta hyper-parameter to respect the constraint on I(X,Z). Their technique is shown to stabilize/allow training when P_g and P_data do not overlap, similarly to WGAN and gradient-penalty based approaches, by essentially pushing their representation distributions (p_z) to overlap with the mutual information bottleneck. It can also be considered as an adaptive version of instance noise, which serves the same goal. The method is evaluated on different adversarial learning setup (imitation learning, inverse reinforcement learning and GANs), where it compares positively to most related methods. Best results for ‘classical’ adversarial learning for image generation are however obtained when combining the proposed VIB with gradient penalty (which outperforms by itself the VGAN in this case).",0.20967741935483872,0.16666666666666666,0.1857142857142857
1594,SP:938f9b4e59217d2e78c405464b452ddc8ba5c459,"This paper proposes a new approach to training models robust to perturbations (or 'attacks') within an l_2 radius, by maximizing a surrogate---a soft randomized smoothing loss---for the *certified radius* (a lower bound for the l_2 attack radius) of the classifier.  This approach has the advantage of not needing to explicitly train against specific attacks, and is thus much faster and easier to optimize.  The authors provide certain theoretical guarantees and also demonstrate strong empirical results relative to two baseline approaches.","This paper improves the robustness of smoothed classifiers by maximizing the certified radius, which is more efficient than adversarially train the smoothed classifier and achieves higher average robust radius and better certified robustness when the radius is not much larger than the training sigma. It proposes a novel objective which is derived by decomposing the 0/1 certified loss into the sum of 0/1 classification error and 0/1 robustness error. Three conditions are identified to make the optimization doable. Two surrogate losses (CE and hinge loss on the certified radius) for the two 0/1 errors are proposed as upper bounds of the 0/1 loss. Certified radius is derived as a function of the logits of Soft-RS to make the hinge loss differentiable. Numerical stability of the proposed objective is also analyzed by showing its gradient is bounded.",0.2261904761904762,0.13380281690140844,0.16814159292035397
1595,SP:9395fc883c2947587ff26fd36ce0fc797d062f3e,"This paper presents Conditional Masked Language Modeling (CMLM), which integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. It is shown that the English CMLM model achieves strong performance on SentEval, and outperforms models learned using (semi-)supervised signals. It is also found that a multilingual CMLM model co-trained with bitext retrieval (BR) and natural language inference (NLI) tasks outperforms the previous state-of-the-art multilingual models by a large margin. The paper further proposes a principle component based approach to remove the language identifying information from the representation while still retaining sentence semantics.","The authors present conditional masked language modeling (CMLM), a new method for unsupervised pretraining, in which the skip-thought notion of conditioning on neighboring sentences is adopted for masked language modeling. The upshot of the proposed approach is that it generates single sentence embeddings that perform competitively on SentEval. In the multilingual setting, the authors combine their CMLM method with a bitext retrieval objective (selecting a sentence’s translation from the other sentences of the language in the batch) that increases performance on a version of the SentEval tasks translated into 14 other languages. In their analysis, the authors make further claims about multilingual embeddings capturing language ID information in their first principle components, a conclusion somewhat substantiated by their results. The authors provide a small amount of ablation experiments for experimental/model design choices.",0.27184466019417475,0.2074074074074074,0.23529411764705882
1596,SP:93c014b25cbb01bc2f2808750e351efa1210ed80,"Motivated by biological visual systems, this paper investigates whether the representations of convolutional networks for visual recognition are invariant to identity preserving transformations. The results show that empirically they are not, and they further propose a data-augmentation approach to learn this invariance. Since transformations can be automatically generated, this does not require additional manual supervision.","The paper proposes to explicitly improve the robustness of image-classification models to invariant transformations, via a secondary multi-task objective. The idea is that the secondary objective makes intermediate-layer representations invariant to transformations of the image that should lead to the same classification. The paper also establishes that the typical models do not actually learn such representations by themselves.",0.17857142857142858,0.16393442622950818,0.17094017094017094
1597,SP:93c22614fd0bac6891570912b18cd30a89a71e2e,"The authors propose a novel approach to estimate unbalanced optimal transport between sampled measures that scales well in the dimension and in the number of samples. This formulation is based on a formulation of the entropy-transport problems of Liero et al. where the transport map, growth maps and Lagrangian multipliers are parameterized by neural networks. The effectiveness of the approach is shown on some tasks.","In this paper the authors consider the unbalanced optimal transport problem between two measures with different total mass. The authors introduce first the now standard Kantorovich-like formulation, which considers a coupling whose marginals are penalized to look like the two target measures. The authors introduce a second formulation in (2), somewhat a Kantorovich/Monge hybrid that involves a ""random"" Monge map where the target point T(x) of a point x now depends also on an additional random variable z, to desribe T(x,z). The authors also consider a local mass creation term (\xi) to weight the initial measure \mu.",0.25757575757575757,0.16666666666666666,0.20238095238095238
1598,SP:93ca1ca8da285e1dbe05f3c83a51042ad0a1b3be,"In this paper the authors consider the problem of computing the number of communities K in an arbitrarily sparse graph generated under the Stochastic Block Model (SMB). Previous studies that consider the problem of computing K show theoretical guarantees only in graphs with average degree $\Omega(\log n)$. One of the previous studies (namely, [1]) has shown that  the number of communities equals the number of negative eigenvalues of the Bethe Hessian matrix for graphs with expected average degree $\Omega(\log n)$ under SBM. In this paper the authors show that with an appropriate scalar parameter for the Bethe Hessian matrix of graphs with average degree $o(\log n)$, the same property still holds, and thus obtain a method for computing K in graphs of sublogarithmic density. In particular, the authors give an interval for the choice of the $\zeta$ scalar that depends on several parameters of the underlying SBM distribution.","The authors propose a spectral framework using the Bethe Hessian matrix to infer the number of communities in sparse networks. The method relies on the eigendecomposition of the Bethe Hessian matrix for which negative eigenvalues are preserved and the number of such eigenvalues used to define the number of communities. In particular, theoretical guarantees for settings of the scalar of the Bethe Hessian matrix is derived including an associated spectral estimation procedure. ",0.19205298013245034,0.4027777777777778,0.26008968609865474
1599,SP:93f8114b248a8fbae75eadc40d70c6d38f3faff4,"The paper proposes an MCMC based sampling mechanism for GANs. In contrast to earlier work, the proposal distribution is conditioning conditioned on the previous state (here in latent space), which is supposed to help sampling efficiency. This is achieved by a clever re-parametrization of intermediate steps of the MCMC chain. As an example, the authors provide a Langevin version (which uses gradient information) of their method.","The paper proposes an MCMC sampling strategy for GANs. The idea is clear: for high-dimensional x, making a good proposal is difficult, so they propose to do that in the latent space.  Then they use a similar strategy as MH-GAN to compute a rejection strategy. The difference between the two methods is that proposal in MH-GAN does not depend on x while the proposed method does, and the argument is that it results in a higher acceptance rate. ",0.2835820895522388,0.2345679012345679,0.25675675675675674
1600,SP:940f5374980f33ee94784370eccd403e49c99ac3,The paper introduces a novel decentralized algorithm (LEAD) incorporated with compression that achieves linear convergence rate in strongly convex setting. The main idea is to apply and communicate the compression of an auxiliary variable instead of the primal or dual iterates.  Convergence analysis is provided for both deterministic and stochastic variants. Experiments shows the state-of-the-art performance. ,"This paper introduces a novel algorithm for decentralized optimization when nodes can only communicate a compressed signal with their neighbors. Unlike most decentralized methods with compression that are inspired by primal methods (DGD type methods), this paper introduces a new primal-dual algorithm with compression. The proposed method's main idea is borrowed from the NIDS algorithm, which converges linearly when the local loss functions are smooth and strongly convex. As the proposed LEAD method is based on primal-dual methods, it succeeds in improving the sublinear rate of primal-based methods. To the best of my knowledge, this is the first decentralized method that achieves a linear convergence rate in the setting that nodes use compressed signals. ",0.3220338983050847,0.16101694915254236,0.21468926553672316
1601,SP:941824acd2bae699174e6bed954e2938eb4bede1,"This work describes an efficient voice conversion system that can operate on non-parallel samples and convert from and to multiple voices.  The central element of the methodology is the AdaIn modification.  This is an efficient speaker adaptive technique where features are re-normalized to a particular speaker's domain.  The rest of the machinery is well motivated and well executed, but less novel.  This addition enables the voice conversion between speakers.","This paper presents a voice conversion approach using GANs based on adaptive instance normalization (AdaIN).  The authors give the mathematical formulation of the problem and provide the implementation of the so-called AdaGAN. Experiments are carried out on VCTK and the proposed AdaGAN is compared with StarGAN.  The idea is ok and the concept of using AdaIN for efficient voice conversion is also good.  But the paper has a lot of issues both technically and grammatically, which makes the paper hard to follow.",0.2222222222222222,0.1927710843373494,0.2064516129032258
1602,SP:9418d0fd67bfb4ff1a64c745cceeb0028ee7ecd0,"This paper studies the safe RL in the multi-agent setting. Specifically, the author leverage the theories from constrained policy optimization and multi-agent trust region learning to propose two algorithms: MACPO and MAPPO-Lagrangian. From the theoretical side, the author shows that in the idea setting, the proposed algorithm is guarantee to improve the objective function at iteration and the constraint satisfications can always be guaranteed. The author also demonstrate the effectiveness of their proposed algorithms in the new environment named ""Safe MAMuJoCo"".","This paper considers the multi-agent reinforcement learning (MARL) problem with safety constraints. The authors proposed two methods, Multi-Agent Constrained Policy Optimisation (MACPO) and MAPPO-Lagrangian, by leveraging the theories from both constrained policy optimization and multi-agent trust-region learning. Their method is shown valid both theoretically and empirically. My main concerns lie in their novelty compared with existing literature and the problem set.",0.2619047619047619,0.3333333333333333,0.29333333333333333
1603,SP:942e9e4be427dd59ec333c2a3073288c4c418cdc,"The paper proposes defective convolutional layers as a measure of defense against adversarial attacks on deep neural networks. This layer sets the outputs of a randomly sampled but *fixed* set of neurons in the convolutional layers to zero during training and testing. The authors claim that defective convolutional layers encourage the model to pick up features other than local textures, e.g. shape information. The shape-vs-texture tradeoff is supported by experiments showing that defective CNNs perform worse than normal CNNs on images with permuted patches and that adversarial examples with larger epsilons exhibit more semantic shapes. The detailed experiment section evaluates the method on transfer-based, gray-box and black-box adversarial attacks,	including Gaussian noise. Additionally, it provides ablation studies on the keep-probability and position of the defective layer.","The paper deals with robustness against adversarial attacks. It proposes to blank out large parts of the early convolution layers in a CNN, in an attempt to shift the focus from ""texture"" to ""shape"" features. This does seem to improve robustness against adversarial examples, with only a small decrease in general classification performance. The explanation for this, on the other hand, is not really convincing.",0.13533834586466165,0.27692307692307694,0.18181818181818182
1604,SP:943f1c5c3c9ba6d861df1a89eb9420d1f54d5573,"This paper proposes POLISH, an imitation learning algorithm that provides a balance between Behavioral Cloning (BC) and DAgger. The algorithm reduces the mismatch between the target policy and an expert policy on states obtained from starting at the target policy's state distribution and following the expert policy for a time segment of t steps. The claim is that a suitable t will keep the training states close to the target policy's state distribution and avoid the compounding errors that arise when the agent drifts away from its training distribution. The paper also explores the possibility of policy optimization by replacing the pre-defined expert policy in POLISH with a policy derived from Monte Carlo Tree Search. Theoretical and empirical analyses in the paper studies the effect of t and MCTS planning in POLISH on policy improvement.","This paper proposes POLISH, a reinforcement learning learning algorithm based on imitating partial trajectories produced by an MCTS procedure. The intuition behind this idea is that behavioral cloning suffers from distribution shift over time, and using MCTS allows imitation learning to be done on states closer to the policy's state distribution, which the authors justify using techniques similar to DAgger. The authors evaluate this method on continuous OpenAI Gym tasks, and show that it consistently beats a PPO baseline.",0.16666666666666666,0.2875,0.21100917431192662
1605,SP:944ebd7c4c81d2266fe950501917c948f6925bb2,"This paper investigate incorporating entity abstraction to transformer language models for text reasoning tasks. The paper proposes different methods to inject entity abstraction information into transformer LMs and experiments on a synthetic dataset show that the proposed method helps compositional generalization. However, experiments on two realistic datasets show that the proposed method fail to effectively improve performance.","The paper investigates the effect of incorporating entity type abstraction into pre-trained Transformers. To achieve that, the authors have tried five different architectures to build the abstraction aware model. The proposed model is tested on three NLP datasets for reasoning. Empirical results show that entity type abstraction is beneficial in formally defined logical reasoning environments with simple language. While for QA datasets with more natural language, the baseline is already very strong and the improvement of incorporating abstraction is minor.",0.2807017543859649,0.19753086419753085,0.23188405797101447
1606,SP:9459318b83cfeeaf7ba7efa3b8a188977d9e572a,"The paper conducts a thorough analysis of existing models for constructing knowledge graph embeddings. It focuses on attempting to remove confounding aspects of model features and training regime, in order to better assess the merits of KGE models. The paper describes the reimplementation of five different KGE models, re-trained with a common training framework which conducts hyperparameter exploration. The results show surprising insights, e.g., demonstrating that a system from 2011, despite being the earliest of the KGE models analyzed, demonstrates competitive results over a more recent (2017) published model.","The paper presents an experimental study about some KGE methods. It argues that papers often propose changes in several different dimensions, such as model, loss, training, regularizer, etc., at once without providing a sufficient investigation about the individual components' contributions. The experimental study considers two datasets (FB15k-237 and WNRR) and five different models (RESCAL, TransE, DistMult, ComplEx, ConvE). The models were selected using a quasi-random hyperparameter search, followed by a short Bayesian optimization phase to fine-tune the parameters. The performance of the best models found during this hyperparameter search are compared to first published results for the same model, as well as to a small selection of recent papers. To analyse the influence of single hyperparameters, the best found configuration is compared to the best configuration which does not use this specific value for the given hyperparameter.",0.21978021978021978,0.14285714285714285,0.17316017316017315
1607,SP:94608cc3860ff32d906d3895c83f7d8351f84015,"The paper advances state-of-the-art automated pen-testing tools for breaking defenses designed to protect deep neural networks against norm-based adversarial attacks as a search problem. The search process first considers techniques to simplify the network being attacked (called Network Transformations), followed by a search over the space of existing attacks (and common ways to modify these attacks). Given the search space is large, the authors try to improve the efficiency by leveraging sub-sampling methods.","One major challenge in the research on adversarial attacks is the absence of methods that can reliably evaluate an adversarial defense. One the one hand, many defense approaches end up targetting particular attack methods. On the other hand, some promising defense approaches are viewed skeptically due to possible new attacks that could break them even if none currently exists. This paper addresses this critical challenge of developing adaptive adversarial attacks by combining some basic building blocks based on a particular defense. The presented approach is shown to outperform AutoAttack - a popularly used baseline attack by community developing adversarial defenses.   The submission presents an automated approach to the discovery of adversarial attacks (along the lines of AutoAttack) by exploring the search space of adversarial attacks formed by varying three components: (i) parameterized attack algorithms, (ii) network transformations, and (iii) loss functions.   Overall, the paper is an interesting improvement over the state-of-the-art and clarification to some questions below will help the reviewer better appreciate its overall contribution. ",0.26582278481012656,0.125,0.1700404858299595
1608,SP:94d8eb827399e58de2a0aed1e5d3a1d629d7fcf7,"The paper investigates adversarial attacks on learned (fixed) policies. In particular, they devise optimal attacks in the sense that e.g. the agent’s objective should be minimised by the attacker. It is assumed that the attacker can manipulate the observed state of the agent at each time step during testing in a restricted way such that perturbations are small in the state or feature space. The paper derives attacker value functions when the attacker’s goal ist to minimise the original agent’s average cumulative reward and shows how to maximise them using gradient methods. In order to show when attacks are more likely to be successful, a theorem is presented and proved that shows that the resilience of a policy against attacks depends on its smoothness. Experiments show that a) attacks that are trained for optimality w.r.t. to minimising the average reward of the agent outperform a baseline method that only optimises a related criterion. b) Agent policies that are trained with DRQN, yielding a recurrent controller, outperform non recursive ones. ","The authors of this paper propose a novel adversarial attack for deep reinforcement learning. Different from the classical attacks, e.g., FGSM, they explicitly minimize the reward collect by the agent in a form of Markov decision process. Experiment results demonstrate that the proposed approach can damage the well-performed policy with a much bigger performance drop than gradient-based attacks.",0.10285714285714286,0.29508196721311475,0.15254237288135594
1609,SP:950c845314ba6a65208f78be3e42b47d79befd7f,"The paper proposes a new way to evaluate generative models that don't have tractable likelihoods, such as VAEs or GANs. Such generative models are composed of a prior over latent variables and a decoder that maps latent variables to data. The idea is to evaluate a trained model in terms of the best (lossy) compression rate that can be achieved by encoding a datapoint (e.g. an image) into the latent space, as a function of a permitted distortion between the datapoint and its reconstruction after decoding. The paper describes a method that estimates an upper bound on this rate-distortion curve using annealed importance sampling. The method is applied in evaluating and comparing a few VAE, GAN and AAE architectures on images (MNIST and CIFAR-10).","This paper presents a method for evaluating latent-variable generative models in terms of the rate-distortion curve that compares the number of bits needed to encode the representation with how well you can reconstruct an input under some distortion measure. To estimate this curve, the author’s use AIS and show how intermediate distributions in AIS can be used to bound and estimate rate and distortion. They apply their evaluation to GANs, VAEs, and AAEs trained on MNIST and CIFAR-10.",0.1953125,0.3048780487804878,0.23809523809523808
1610,SP:951b5c2a6eba45d57baecfde6cbfbc732e1347ba,"Authors propose a novel few-shot segmentation method by adopting dense Gaussian process (GP) regression to capture complex appearance distributions. To boot the performance, authors consider the uncertainty in the final segmentation. Authors exploit the end-to-end learning capabilities of the proposed method to learn a high-dimensional output space for the GP.  Authors report state-of-the-art results in two public few shot segmentation benchmarks.","This paper proposes a special Gaussian process (GP) named dense GP, to model a mapping between dense local deep features and their corresponding mask values. Based on this dense GP, a few-shot segmentation method named DGPNet is proposed. The authors claim that DGPNet is novel in that it can be applied to situations that unseen classes are not linearly separable, and can produce the uncertainty of its prediction as well. To support this they conduct series of experiments on PASCAL-5^i and COCO-20^i.",0.17647058823529413,0.13793103448275862,0.15483870967741936
1611,SP:95227057b7415d12701d2ad2986ef084ff6c28a7,"This paper describes a method for improving the (sequence-length) scalability of the Transformer architecture, with applications to modeling long-range interactions in musical sequences. The proposed improvement is applied to both global and local relative attention formulations of self-attention, and consists of a clever re-use (and re-shaping) of intermediate calculations. The result shaves a factor of L (sequence length) from the (relative) memory consumption, facilitating efficient training of long sequences. The method is evaluated on MIDI(-like) data of Bach chorales and piano performances, and compares favorably to prior work in terms of perplexity and a human listener evaluation.","This paper presents an implementation trick to reduce the memory footprint of relative attention within a transformer network. Specifically, the paper points out redudant computation and storage in the traditional implementation and re-orders matrix operations and indexing schemes to optimize. As an appllication, the paper applies the new implementation to music modeling and generation. By reducing the memory footprint, the paper is able to train the transformer with relative attention on longer musical sequences and larger corpora. The experimental results are compelling -- the transformer with relative attention outperforms baselines in terms of perplexity on development data (though test performance is not reported) and by manual evaluation in a user study.",0.22330097087378642,0.2072072072072072,0.21495327102803738
1612,SP:9524aa8fc58de90f31595c6f551b656e52896778,"Human mesh recovery methods commonly resort to 2D keypoint supervision to be able to handle in-the-wild images, as these often lack 3D ground truth. This submission argues that binary silhouettes are a better source of weak supervision and that classical segmentation techniques are less susceptible to domain shifts that 2D keypoint detectors. As such, silhouettes can be used to train shape and pose regressors on more heterogenous data without the need for annotating and retraining keypoint detectors, which this submission does: A SPIN-like method (Kolotouros et al., 2019) is proposed that replaces the keypoint-based loss and refinement, with a silhouette-based loss that allows for comparisons between the model and observed silhouettes. Key here is a differentiable skeletonisation operation that pares the silhouette down before applying the loss. The proposed method compares favourably against the state-of-the-art on a variety of datasets. The submission additionally demonstrates that the resulting scheme is more robust to adversarial perturbations than competing approaches.","This work proposes a novel method to tackle the lack of annotated data for 3D human pose recovery. The core observation is that silhouette estimation is not prone to domain gaps. Hence, the authors develop the topological skeleton, obtained from silhouette, to guide the training. ",0.07878787878787878,0.28888888888888886,0.12380952380952379
1613,SP:95408bc20d6c07d7f4d7239faf8f08969e2f8722,"This paper presents a framework for learning hierarchical policies using a latent variable conditioned policy operating at the low level, with model based planning at the high level. Unlike prior work which does hierarchical reinforcement learning, the key technical contribution of this work is that they use planning with a latent dynamics model as their high level policy. They demonstrate the method on a humanoid walking task in the DeepMimic [1] environment.","This paper proposes a latent variable model to perform imitation learning. The authors propose the model in the control-as-inference framework and introduce two additional latent variables: one that represents a latent state (z) and another that represents a latent action (h). For the generative model, the authors use a sequence latent variable model. For inferring the latent action, the authors use a particle filter. For inferring the states, the authors use an ""Adaptive path-integral autoencoder,"" though it was unclear where the controls ""u"" come from. (I assume u is the same as the actions, at which point inferring the states amounts to rollout the policy in the sequence latent variable model). The authors compare to not having the latent states and/or not having the latent actions, and demonstrate that they get better imitation learning scores.",0.2361111111111111,0.1223021582733813,0.16113744075829384
1614,SP:954686264f83d5d8a4ccaff7cc5130be733f7bb0,"This paper proposes a new approach for solving RL problems with sample complexity independent of the number of states. Rather than imposing structural assumptions, the authors consider access to weak learners and propose a way to combine these weak learners effectively to generate a near optimal policy. The sample complexity result is competitive and does not depend on the number of states, under the assumption of access to weak learners.","In this paper, the authors study boosting in RL, i.e., how to convert weak learners into effective policies. The authors provide an algorithm that improves the accuracy of the weak learners iteratively, and the sample complexity and running time do not explicitly depend on the number of states.   In order to overcome the non-convexity of the value function (with respect to the policy space), the authors use a non-convex variant of the Frank-Wolfe method together with recent advances in gradient boosting. ",0.32857142857142857,0.27058823529411763,0.2967741935483871
1615,SP:955ba7c70fa3640478b5ae1bb562025a1cb14a04,This paper presents a Transformer-based model called SCformer to perform long sequence time series forecasting. The key idea is to replace the canonical self-attention with efficient segment correlation attention (SCAttention) mechanism to capture long short-term dependencies. Experiment results on several datasets showed the effectiveness of the proposed method.,"This paper introduces a SCFORMER, which replaces the canonical attention in the Transformer with the segment correlation attention. The motivation of using the segment correlation is to reduce the memory usage of the scale-dot product attention of the Transformer. To further improve the performance, the paper proposes a dual task, which use the current time series to predict the past time series. ",0.29411764705882354,0.23809523809523808,0.2631578947368421
1616,SP:956a4740077d285cf5d544664a99ebd3338400aa,"This paper proposes a method for training an ensemble of classifiers for problems where spurious correlations may be present.  The models in the ensemble are encouraged to learn conditionally disentangled representations.  It is suggested that this disentanglement will result in the spurious correlations being consigned to a subset of the models in the ensemble.  The ensemble will then be ready to quickly adapt to a new data distribution without the spurious correlations, via selection of a single model that does not depend on the spurious correlations, or via reweighting of model outputs.","This paper proposes an approach of training an ensemble of DNN classifiers while also minimizing the total correlation (TC) between the last layers (learned feature representations) of the classifiers to increase robustness to spurious correlations.  To compute gradients for this new TC regularization term, they use the InfoNCE objective as a proxy, and minimize this, and then use alternating minimization to learn the parameters. The authors then test this on a variation of the Colored MNIST task, showing gains over baseline approaches.",0.2391304347826087,0.2682926829268293,0.25287356321839083
1617,SP:95782322a8951193e0690262f6a90d2ed5ed7463,"This paper studies, through a provable approach, whether abstaining (i.e., refusing to answer) can be beneficial for achieving small adversarial/robust error in settings where the input is potentially adversarially perturbed. The paper proves a separation between the power of models with and without abstain. In particular, it is shown that for a certain adversarial model (more about this below) when we force the model to answer without an abstain option, it will have high adversarial error, but when abstain is allowed, it can have small adversarial error as well as small abstention rate in certain settings. The paper then studies algorithms for robust contrastive learning in which they map the inputs into high-dimensional spaces and then aim to classify them using an abstain-enabled model based on 1-NN. The paper studies ways to adjust the parameters of the model as the data comes in an online fashion (divided into batches). They show how to achieve sublinear regret in such settings. They then compare linear classifiers with their own (1-NN style) classifiers and show advantages in robustness with such models when abstaining is allowed.","This paper proves some fundamental facts about classifiers that can't abstain (provide a non-classification) and their robustness to adversarial perturbations. In Sec. 4, they provide a result that such classifiers are always vulnerable to adversarial perturbations in a technical sense. In particular, there will always be a class in which most training examples can be randomly perturbed in a way that an incorrect label will result nearly half the time. In Sec 5, they propose a modified nearest-neighbor classification algorithm, with two parameters that control abstention and ""noise removal"". They provide upper bounds on error in a random subspace attack scheme, and refine/loosen these results in several more specific/general scenarios. In Secs. 6 & 7, they discuss methods to tune the two parameters and provide experimental evidence of their theoretical results.",0.11702127659574468,0.16296296296296298,0.13622291021671828
1618,SP:95a437dfc5ea49319e4f23691decffac1d4a74b3,"The authors propose a method for learning an augmentation pipeline for image recognition. As opposed to recent existing approaches such as AutoAugment or RandAugment, the authors do not seek for the augmentation pipeline iteratively. Instead they use a stochastic approach, where augmenters are split to three categories based on their complexity to be used by curriculum learning.","This paper aims to provide an effective augmentation strategy without the need for a separate search. The resulting method is called NOSE Augment, which is presented as a substitute for the previous AutoAugment type methods (e.g. Fast AutoAugment, Population Based Augmentation, RandAugment, Adversarial AutoAugment etc.) In parallel to this goal, the authors propose adding the mixing-based augmentation operations Mixup, Cutmix, and Augmix into the list of operations used in AutoAugment. Finally, authors also employ a curriculum of augmentation strength during training. ",0.21052631578947367,0.14457831325301204,0.1714285714285714
1619,SP:95a668e44a54b5e8def5ea2abb2e2a06026637b8,"The authors of this paper propose an compression technique for GNNs that was inspired by lifted inference. The compression consists of removing asymmetries by merging nodes. They define two algorithms for compression: a non-exact algorithm that merges two nodes that are ""functional"" equivalent and an exact algorithm that merges two nodes that are structurally equivalent.","The paper provides an interesting work in the scale/speed up of structured convolutional models. In particular, it proposes an idea using a technique named lifting which is used in scaling up of graphical models to detect the symmetries and compress the neural model such as Graph Neural Network. Authors show that this compression can lead to speedups of the models in many tasks.",0.14285714285714285,0.125,0.13333333333333333
1620,SP:95ba08c326437452098f9cc7d8b542a08bb747a3,"In this paper, the authors proposed a new representation of persistence diagrams that can include `''essential features''. Essential features correspond to the intrinsic topology of the underlying space that will not die during the filtration. To include the fact that the essential features are infinitely far from other normal features in the diagram, the authors proposed to use a Poincare ball representation, which maps the diagram into a disk whose boundary is infinitely far from inside. ","The authors propose to learn a representation for the persistence diagram (PD) in the hyperbolic space to incorporate the essential features (i.e., infinite persistence). The authors show that the hyperbolic representation has stability. Empirically, the authors illustrate that the hyperbolic representation for PD compares favorably with other baselines on graph and image classification.",0.19736842105263158,0.2777777777777778,0.23076923076923078
1621,SP:95db394e10cd433a8283269953ca17e8b8f46879,"This paper proposes to use auto-regressive sequence models with attention mechanisms to predict the evolution of physical simulations. Mesh-based discretizations are targeted, and hence the employed networks take the form of GNNs. The paper focuses on encode-process-decode structures, and a transformer is proposed as main method to predict future states in the latent space. This approach is evaluated with three CFD settings: an unsteady wake flow, a sonic backwards facing step, and a medical flow scenario. The results are additionally analyzed in terms of latent space and attention weight content. ","This work proposes a new algorithm combining graph-neural-network (GNN) and auto-regressive sequence models for physics prediction problems. The authors first use GNNs to compress the physical graphs, then use transformers to predict the next steps of the compressed representations, and finally use GNNs to recover the graph representations from the predicted representations. Through empirical studies, the authors show that this method outperform the previous SOTA model (MeshGraphNet) significantly, especially in the long-rollout prediction scenarios. The authors further analyze the models to understand the success and find that the ability of the transformer model to replay the earlier sequences seems to be the critical for the better performance especially in the scenarios with oscillations.",0.2127659574468085,0.17094017094017094,0.1895734597156398
1622,SP:95dffa3121696961419f11fb265f560c4358bd07,"This paper proposes Focal Transformer, which captures both local and global attention based on their design. It also follows the pyramid architecture so their model can be easily extended to detection and segmentation tasks. The result on image classification detection and segmentation are very promising. ","This paper proposes a focal version of self-attention module for vision transformers. The query is kept at high resolution, but the number of keys is reduced depending on the relative position difference. This proposed attention is implemented within multi-scale windows. It shows good performance on top of recent transformer advances, on ImageNet and COCO. ",0.2,0.16071428571428573,0.1782178217821782
1623,SP:95f32813140f9e12b9d0d6f3ecad90c1ad00b0a0,"The paper presents an empirical study (respectively meta-study) of large-scale supervised pre-training for image recognition tasks. By analysing lots of experiments with varying model sizes, dataset sizes and training durations, the paper reaches the conclusion that simply scaling them up for a generic pre-training task will not lead to proportional gains for downstream tasks that build on the pre-trained model. On the contrary, the paper suggests that with increasing pre-training effort the downstream performance will reach a saturation level below its Bayes error. Moreover, that saturation level appears to vary across different downstream tasks (i.e., image characteristics and class definitions), which is seen as a sign that a generic one-fits-all feature extractor cannot be found by just scaling up.","### What is the Problem / Question? There is a ongoing trend in ML right now of exploring larger and larger pre-trained (PT) models. In general, increasing the scale of these PT models has yielded better performance on downstream tasks, though this is not universally the case. This work analyzes the limits of this trend in the computer vision space, investigating how downstream task performance is impacted by scale of the PT model among other factors.  ### Why is it impactful? Pre-training large models is very expensive. This study has the potential to clarify when such large-scale PT is well-motivated, and when it isn't, which could yield significant benefits for future research.  ### Why is it hard? Why have previous approaches failed? Previous approaches have examined this question at a dramatically smaller scale than this study does. For example, Kornblith et al., 2019 examined on the order of 10s of models, as opposed to thousands of models as examined here, and the results found here are correspondingly more detailed than those found in the Kornblith et al. study. _Most critically, the authors here present data that strongly suggests that rather than a linear relationship between downstream and upstream task performance, we should instead expect a saturating, non-linear trend_, which suggests that continually training larger and larger models may not be as worthwhile as was traditionally assumed. The fact that this counters an established result in the literature is an important distinction, because my native assumption would've actually been consistent with the author's finding, so without the literature bias already existing, this finding would in my opinion be less impactful. However, because it is updating a held belief in the published results, it is much more important.  ### How do they solve / answer it? The authors profile a variety of models across different architectural choices, hyperparameter settings, etc. and compare upstream vs. downstream accuracy across various downstream tasks. They further examine a variety of additional angles within this study, including:   1) Quantifying the extent to which downstream performance is consistent across downstream tasks at a given level of upstream task performance,   2) How the internal representational space of these models can inform the extent of the saturation of the downstream task.   3) They examine in which cases upstream and downstream task performance may be at odds with one another   4) They profile their analyses under various dataset sizes, few-shot settings, and architectures. ",0.234375,0.07407407407407407,0.11257035647279551
1624,SP:95f3326dbff47ccad1f03b4529403aa0197bcba1,"This paper analyzes AMSGrad when applied to a broad family of nonsmooth, nonconvex, stochastic, constrained optimization problems. Convergence rates based on the norm of the Moreau envelope's gradient (although in a rescaled norm) are presented. The rates nearly match the O(1/T^{1/4}) rate of the subgradient method, off by a logarithmic term. The primary innovation in this work is tackling technical barriers to handle first and second order moment parameters that complicate analysis.","The paper provides a convergence analysis for the AMSGrad algorithm for the more general class of functions that are weakly convex. The convergence guarantee is comparable to existing results for SGD, and the main advantage is that the AMSGrad algorithm does not require knowledge of the weak convexity parameter and it automatically adapts to it. The paper extends the convergence analysis to other algorithms, such as SGD with momentum and the AdaGrad algorithm with scalar step sizes. ",0.16883116883116883,0.16883116883116883,0.16883116883116883
1625,SP:961781ea8113343d82568b49c26f0889d5632aba,"This paper proposes Episode Reinforcement Learning with Associative Memory (ERLAM), which maintains a graph based on the state transitions (i.e. nodes correspond to states, and edges correspond to transitions) and propagates the values through the edges in the graph in the reverse order of each trajectory. The learned associative memory is then used for the regularization loss for training Q-network. Experimental results show that ERLAM significantly improves the sample efficiency in Atari benchmarks.","The paper proposes a new method for organizing episodic memory in with deep Q-networks. It organizes the memory as a graph in which nodes are internal representations of observed states and edges link state transitions. Additionally, nodes from different episodes are merged into a single node if they represent the same state, allowing for inter-episode value propagation of stored rewards. The authors experimentally evaluate the method against reasonable baselines and show improved performance in the majority of tasks.",0.22666666666666666,0.2125,0.21935483870967742
1626,SP:961aaeff44c96bf59c9e778a609e3988bc9d89a6,"The authors present a new medical image-to-image generative model, called RegGAN, that combines an adversarially trained image generator with a registration module that enforces alignment between the generated image and ‘noisy’, (un)paired ground truth image. The aim of the network is to search for the single optimal solution to both image-to-image translation and registration tasks. The authors compared their proposed method against two other general model types, Pix2Pix (paired aligned data) and Cycle GAN (unpaired or misaligned). For training and testing, they use the BRATS dataset, which consists of brain tumor MRIs, and translate T1 to T2 images. The authors were able to show better performance on all major metrics for both paired and unpaired data. They showed that RegGAN was more resistant to label noise and increased stability during training.  ","The authors proposed a novel method for conducting image-to-image translation integrating registration network (RegGAN), and demonstrated the superior performance in T1 to T2 MRI image translation to the current methods based on Pix2Pix and cycle-consistency techniques. The RegGAN performed slightly better than Pix2Pix method even without added noise likely due to inherent misalignment from the image acquisition. While the Pix2Pix method deteriorates rapidly with the added noise, RegGAN was robust against noise similarly to CycleGAN (with better performance). The authors also experimented to train them with unpaired images, and RegGAN could generate T2 images more similar to the actual images than the other two methods. ",0.19117647058823528,0.24074074074074073,0.21311475409836064
1627,SP:962be382d6cbf5cfd5b3406e726ccf0b2a39e049,The paper proposes an active learning framework called SoCal that is consistency-based and can decide between whether to make use of the oracle to provide a label or to make use of a pseudo-label generated by the algorithm itself instead. The proposed method hopes to address resource-constrained active learning scenarios where the oracle is not always available or we wish to make use of the oracle as infrequently as possible. Experimental results demonstrate reasonable performance on four publically available physiological datasets.  Experimental results when the oracle is noisy is also reported.,The authors proposed a consistent-based active learning framework to annotate largely unlabeled physiological signals with the help of human annotators (oracles). The paper is well organized and easy to follow. It is somewhat novel to equipping active learning with consistency learning and selective classification. The experiments (along with the Appendix) give a comprehensive analysis of the method. ,0.14893617021276595,0.2413793103448276,0.18421052631578946
1628,SP:962c445bf9fa4cc39b00aa1a57073320ba145865,"This paper propose a heuristic algorithm for deciding which random variables to be Gaussianized early in flow-based generative models. The proposed algorithm involves first training a flow without multi-scale training, for example, 32*32*c  - 32*32*c - 32*32*c. Then, it computes the logdet term for each variable at each layer. It then spatially partition the first flow block by two halves of shape 16*16*2c based on max-pooling the logdet term. Then it recursively Gaussianize one half, and partition the other half as 8*8*4c, still using the pre-computed logdet tensors (Ld in the paper). After partitioning, they train a multi-scale model with the learned partition.","This paper presents a new multi-scale architecture for flow-based generative models. Unlike prior work on multi-scale flow architectures which use fixed dimension-splitting heuristics, the proposed approach learns which dimensions to process further. The features are chosen for further processing based on a heuristic motivated by each feature's contribution to the total likelihood. This contribution is given by the each features' contribution to the log-determinant term in the change of variables formula. The model is trained in a two-step process. First a flow model with no multi-scale architecture is trained. Then each feature's  importance is calculated based on its contribution to the log-determinant. Then these scores are used to rank the features for the second, multi-scale model which is retrained from scratch. The authors demonstrate the performance of their approach on density modeling on standard image datasets. They demonstrate an improvement over the standard real-nvp architecture.",0.23275862068965517,0.17197452229299362,0.1978021978021978
1629,SP:9631ec37258a40acaa6666ca4b66158d6fd9c3dc,"The paper studies two problems plaguing graph neural networks (GCNs/GNNs): 1) oversmoothing of GCNs/GNNs; and 2) GCNs/GNNs often do not yield good performance on heterophilous networks. The authors aim to develop a theory to explain these issues simultaneously, where a few lemmas and theorems were developed based on certain simplifying assumptions. Based on these theoretical results, the authors develop a generalized GCN (GGCN) with negative message passing. Evaluation is conducted and compared with the state-of-the-art.","Two issues confronting GCNs, heterophily and over-smoothing, share a common cause. This article asserts that the relative degree and homophily level account for node representation movement and further affect the likelihood of misclassification.   The contributions of this paper are as follows:  1) it attempts to establish a connection between heterophily and over-smoothing by identifying common causes;  2) it establishes that the relative degree and homophily level have an effect on the misclassification rate; and  3) it also designs and presents a model that allows for negative interactions between nodes, which is shown to be robust to over-smoothing and capable of achieving state-of-the-art performance on heterophily datasets.",0.20987654320987653,0.15178571428571427,0.17616580310880828
1630,SP:9699e0e908af5e3404df56498afe3d6c7333f431,"The paper proposes noise-robust contrastive learning to combat label noise, out-of-distribution input and input corruption simultaneously. In particular, this paper embeds images into low-dimensional representations by training an autoencoder, and regularizes the geometric structure of the representations by contrastive learning. Furthermore, this paper introduces a new noise cleaning method based on the structure of the representations. Training samples with confident pseudo-labels are selected for supervised learning to clean both label noise and out-of-distribution noise. The effectiveness of the proposed method has been evaluated on multiple simulated and real-world noisy datasets. ","The authors of the paper propose to use the contrastive loss, the mixup prototypical loss, and a reconstruction loss to regularize the learned representation in order to achieve robustness under various kinds of noise like label noise, out-of-distribution input, and input corruption. A noise-cleaning process based on the learned representation is also introduced to further enhance the results. Extensive experiments were conducted to demonstrate the effectiveness of the method. ",0.2653061224489796,0.3611111111111111,0.3058823529411765
1631,SP:969c99a939e5b56335f08b0d5828fa5a28842db0,"In this paper, the authors propose to use attention to combine multiple input representations for both query and search results in the learning to rank task. When these representations are embeddings from differentiable functions, they can be jointly learned with the neural network which predicts rankings. A limited set of experiments suggest the proposed approach very mildly outperforms benchmark approaches.","The paper proposed an attention-based deep neural network for implementing 'learning to rank' algorithm. Particularly, the proposed method implements a listwise approach which outputs the ranks for all search results given a query. The search results are claimed to be sorted by their degree of relevance or importance to the query. However, it is not clear to me how the ranking was decided in equation 6 by the softmax function. For example, as per section 4, the documents of the same topic are considered related, then how the proposed model was trained with one document having higher relevance than others in the same topic category.  ",0.21666666666666667,0.12264150943396226,0.1566265060240964
1632,SP:96a3d3453cca0349f176d351b653d25c94b77acb,"The paper introduces a new variant of asynchronous SGD, GA-ASGD, for distributed training. The goal is to mitigate the gradient staleness issue caused by asynchronously applying gradients to an old version of parameters. Prior work addresses this issue by penalizing the learning step of a worker linearly to its missed updates since getting a replica of parameters. However, that approach does not consider the differences between the old and new versions of parameters, which can cause over-penalization and under-penalization. The main contribution of this paper is to introduce a new way of measuring weight staleness and to explore the idea of penalizing the gradient itself to mitigate the staleness issue. The paper does a good job of discussing how GA can be applied to existing optimizers such as Adam. It performs empirical studies on ImageNet and Transformers-XL to conclude that GA-ASGD outperforms ASGD and the prior staleness aware approach. It also demonstrates the scalability of GA by scaling up to training with 128 asynchronous workers.","This paper studies training large machine learning models in a distributed setup. For such a setup, as the number of workers increases, employing synchronous stochastic gradient descent incurs a significant delay due to the presence of straggling workers. Using asynchronous methods should circumvent the issue of stragglers. However, these asynchronous methods suffer from the stale gradients where by the time a worker sends the gradients to the master server, the model parameters have changed based on the gradients received from other workers. This leads to severe performance degradation in the models trained by using asynchronous methods, especially where the number of workers scales.",0.13529411764705881,0.22330097087378642,0.1684981684981685
1633,SP:96afb20c4d7fe41c083a0217c9cb8d1f21a73a15,"This paper proposes a neural network (NN) quantization based on Mirror Descent (MD) framework. The core of the proposal is the construction of the mirror map from the unconstrained auxiliary variables to the quantized space. Building on that core, the authors derive some mapping functions from the corresponding projection, i.e. tanh, softmax and shifted tanh. The experimental result on benchmark datasets (CIFAR & TinyImageNet) and basic architectures (VGG & ResNet-18) showed that the proposed method is suitable for quantization. The proposed method is a natural extension of ProxQuant, which adopted the proximal gradient descent to quantize NN (a.k.a $\ell_2$ norm in MD). Different projections in NN quantization lead to different Bregman divergences in MD. ","This paper proposes a Mirror Descent (MD) framework for the quantization of neural networks, which, different with previous quantization methods, enables us to derive valid mirror maps and the respective MD updates. Moreover, the authors also provide a stable implementation of MD by storing an additional set of auxiliary dual variables. Experiments on CIFAR-10/100 and TinyImageNet with convolutional and residual architectures show the effective of the proposed model. ",0.19658119658119658,0.32857142857142857,0.24598930481283418
1634,SP:96e936fc1cf2e77c2bf154a66da19aa9a1f68400,"The paper presents the first large scale CAD construction sequence dataset together with environment that allows us to synthesize 3D CAD from these sequences. The dataset and environment are essential building blocks for applying machine learning algorithms to CAD design process. Furthermore, the paper proposes comprehensive evaluation metrics and a baseline method for predicting the sequence of 3D CAD design from a CAD model. ","The paper describes a new dataset of 3D geometry construction sequences based on sequential sketching (i.e. sets of two-dimensional curves) and extruding (i.e. axes, angles and distances for extrusion profiles from sketches) combined with Boolean solid geometry operations. The dataset comprises the resulting objects as well as the human designed sketch-extrude sequence that lead to the object geometry. The 8625 objects are available in three different geometry representations (boundary representation, mesh, and construction sequence in structured format). Furthermore the submission describes a new infrastructure (""gym"") to train and evaluate algorithms that estimate such construction sequences, as well as evaluation metrics to gauge the efficiency and effectiveness of such estimation algorithms. The paper also provides a reference method for sequence estimation based on imitation learning as well as several baselines and their empirical evaluation with respect to the posed benchmarks.",0.265625,0.11888111888111888,0.1642512077294686
1635,SP:97138888ff5e94c0c460690fd21246ab1bf5a39b,"In this paper, the authors proposed a discriminability distillation learning (DDL) method for the group representation learning, such as action recognition recognition and face recognition. The main insight of DDL is to explicitly design the discrimiability using embedded class centroids on a proxy set, and show the discrimiability distribution w.r.t. the element space can be distilled by a light-weight auxiliary distillation network. The experimental results on the action recognition task and face recognition task show that the proposed method appears to be effective compared with some related methods. The detailed comments are listed as follows, ","This paper studies how to aggregate features from group inputs. The paper proposes  Discriminability Distillation Learning (DDL) to compute the aggregation coefficients. The method assumes that each sample has a discriminability property that is directly related to the task. The authors define this property and propose to learn such property by an auxiliary network. Such a network can be used in many models without affecting their original training procedure and is able to improve the performances on many tasks, including set-to-set face recognition and action recognition. The experimental results are comprehensive and convincing.",0.23469387755102042,0.24210526315789474,0.2383419689119171
1636,SP:971a6f6ec230b9804ce5c14fa75eb1a2cf516249,"This paper proposes to use contrastive learning to learn representations from cardiac signals (ECGs). The model incorporates ECG domain knowledge, patient-specific, and relationships between multiple leads (channels), in the learning process. The targeted task is very important, enormous ECGs are collected and stored, but seldom people are mining them as they are unlabelled. This paper might reinvigorate them. ","This work presents a new self-supervised training framework for multi-channel ECG signals. The authors use contrastive learning by exploiting the fact that a single patient can generate multiple ECG signals, and there are multiple views (i.e. leads) for the same ECG signals. Compared to popular self-supervised training methods BYOL and SimCLR, the proposed method shows superior performance on the arrhythmia classification task for 4 different datasets in various scenarios.",0.2033898305084746,0.1643835616438356,0.18181818181818182
1637,SP:97237fefef6ae3891e0d3558373cccf759002ab5,"This paper studies a new model of locally sensitive hashing (LSH) that is inspired by the fruit fly Drosophila's olfactory circuit. Instead of mapping each input to a low-dimensional space, such LSH methods (FlyHash) map given $d$-dimensional inputs to an $m$-dimensional space such that $m \gg d$. However, these mappings enforce sparsity on the hash maps such that only $k$ out of $m$ coordinates of the output of the hash map are non-zero.","This paper introduces a variant of FlyHash for similarity search in vector space. The basic idea is motivated by the intuition: the original FlyHash method is data-independent, so can we improve FlyHash's locality sensitivity by learning from data. It does so by learning the weights of the projection layer and uses winner-take-all sparsification to generate sparse binary hash code. This leads to the bio-inspired hashing algorithm (BioHash).  The paper argues that by taking into account the density of data, the learned projection helps to further push similar entities to have hash codes that point in similar direction while repelling dissimilar objects in opposite directions. Experiment results are reported on MNIST and CIFAR10, and the proposed approach demonstrates better retrieval precision results compared to several other hashing based methods. ",0.23076923076923078,0.13533834586466165,0.17061611374407581
1638,SP:974f46bba59746cb294a5107730c8bc0d27cca85,"The paper describes a training scheme based on decomposing input features into two parts which have different training dynamics: a low rank ""factor feature"" computed using PCA on the raw features, and a high rank ""residual"".  The former is processed  by a very shallow network, while the latter passes through the full network, and parameters for each are updated with different learning rates.  Experiments show that the proposed algorithm can speed up wall-time to  a certain accuracy on MNIST and CIFAR10 classification, across several neural network architectures and optimizers.","In this paper, a learning method that accelerates the training of DNN is proposed. Given an input X, the proposed method decomposes X as X = BZ + E where BZ is a low-rank approximation of X and E is the residual term. E is used as an input of DNN and Z is used as an additional feature of the input of the last layer. Experiments using MNIST and CIFAR10 show that the proposed method accelerates the speed to reduce the training loss. ",0.2111111111111111,0.2289156626506024,0.21965317919075145
1639,SP:975ca0db2d36004b48911303fd7fd8b61e956774,"This paper aims to study when hidden units provide local codes by analyzing the hidden units of trained fully connected classification networks under various architectures and regularizers.  The main text primarily studies networks trained on a dataset where binary inputs are structured to represent 10 classes with each input containing a subset of elements indicative of the class label.  The work also studies fully connected networks trained on the MNIST dataset (with the addition of some pixels indicating each class label).  After enumerating the number of local codes observed under these different settings, the authors conclude the following: (1) ""common"" properties of deep neural networks & modern datasets seem to decrease the number of local codes (2) specific architectural choices, regularization choices & dataset choices seem to increase the number local codes (i.e. increasing dropout, decreasing dataset size, using sigmoidal activations etc.).   The work then state that these insights may suggest how to train networks to have local codes emerge.  ","I have a lot of questions about the data used in the experiments. They are created according to the method explained in “Data design” (p.2). It is also summarized in the last paragraph of the first section as follows: ”there are 1/10 input bits that are always 1 for each class and these are the invariant bits, the 0s of each prototype are then filled in with a random mix of 1 and 0 of a known weight”. What is the intention behind this way of creating data? How general are the data created in this way as well as the analyses based on them? It seems to me that the data and thus the analyses lack the generality needed for the purpose of understanding behaviors of neural networks on real tasks/data. ",0.1320754716981132,0.15555555555555556,0.14285714285714288
1640,SP:9766ea2942d933a8bcf240338cbadedf9d4aa897,"Paper addresses the problem of cross-domain object detection. The formed source domain detectors (in the form of Faster R-CNN), learned in a supervised manner, are adopted to perform well on the target domain where no annotations are available. The key to the approach is separate adaptation of the classification head and the regression head within Faster RCNN. This leads to the proposed D-adapt, namely Decoupled Adaptation, that decouples the adversarial adaptation and the training of the detector. In addition, classification and detection heads are adopted in tandem. Experiments show that the proposed D-adapt strategy achieves state-of-the-art results on four cross-domain object detection tasks.","The authors propose a tailored method, named Decoupled Adaptation (D-adapt), for cross-domain object detection. The conventional domain adaptation techniques hurt the discriminability of the detector and ignores the adaptation on bounding box regression. In order to avoid hurting the discriminability of the detector, the authors propose to decouple the adaptation modules from the detector, which achieves the parameter independence. In addition, the authors propose the module for adapting the bounding box regression. Due to the decoupling property, the proposed D-adapt framework is compatible to many off-the-shelf detectors. The experimental results are very promising.",0.26126126126126126,0.29591836734693877,0.27751196172248804
1641,SP:9774f39a520317f2d547b5ab2690f59473d20f8e,"This paper describes a technique for creating adversarial images where the added perturbations are not only imperceptible to machines, but also to human observers. The authors describe why this might be beneficial. The method works by finding labels that are not too far from the source image's ground-truth labels, and moving the source image in that direction. To find the target label, the authors use a threshold on the confidence of predicted ground-truth labels. The authors test their algorithm using a newly proposed metric of how much a method allows imperceptibility for a human observer. They show that their method creates images whose perturbations are more impercetible to humans, compared to other methods, but are also imperceptible to machines.",This paper proposes a method to create adversarial perturbations whose target labels are similar to their ground truth. The target labels are selected using an existing perceptual similarity measure for images.  Perturbations are generated using a DeepFool-like algorithm. Human evaluation supports that the pair of the generated images and target labels are more natural to humans than prior attack algorithms.,0.18032786885245902,0.36065573770491804,0.24043715846994537
1642,SP:97873277c2891819393aeebbd3256b7445794e89,"The paper proposed a minimal design API (or mostly API?) of machine learning framework called Flashlight. The key argument of the paper is that Flashlight is modular and agile. The Flashlight captured the key aspects of machine learning frameworks: Tensor and Operation, Memory Management, and Distributed. There are some evaluations to argue the benefit of Flashlight.","The paper describes the design philosophy and structure of the Flashlight deep learning framework. Flashlight is modular, small, and narrowly oriented toward systems researchers. Rather than (or in addition to) high level productivity, Flashlight focuses on internal and external simplicity of ML tools. The authors evaluate Flashlight by training several standard reference models and it achieves slightly better performance than PyTorch or TensorFlow ",0.25,0.2222222222222222,0.23529411764705882
1643,SP:978b2e085614592b4d8503ea2cc17ff5f0510539,Proposes contrastive learning method for conditional text-generation. Here we maximize similarity (of representations) between source and target sequences (positive) while minimizing similarity with false targets (negative). Additional positives and negatives are created in the sequence representation space by adding perturbations to decoder (output) hidden states to minimize/maximize conditional likelihood p(y|x). It is shown this works a lot better than the naive contrastive approach of sampling random non-target sequences.,"This paper proposes to add contrastive learning to the sequence-to-sequence generation problem. More specifically, the authors apply a contrastive loss on the globally pooled hidden representation of the generated hidden states. The key novelty is to apply adversarial gradients to obtain both hard negative and hard positive examples. The proposed method can improve a state-of-art pretrained transformer model (T5) on 3 tasks: machine translation (WMT16 En-Ro), abstractive summarization (XSum), and question generation (SQuAD).",0.1506849315068493,0.14102564102564102,0.1456953642384106
1644,SP:978d7d3c9a76378109869dc4c235c5d6a4359ca1,"This paper considers learning informative priors for convolutional neural network models based on fits to data sets from similar problem domains.  For trained networks on related datasets the authors use autoencoders to obtain an expressive prior on the filter weights, with independence assumed between different layers.  The resulting prior is generative and its density has no closed form expression, and a novel variational method for dealing with this is described.  Some empirical comparisons of the deep weight prior with alternative priors is considered, as well as a comparison of deep weight samples for initialization with alternative initialization schemes.  ","This paper proposes the ‘deep weight prior’: the idea is to elicit a prior on an auxiliary dataset and then use that prior over the CNN filters to jump start inference for a data set of interest.  Both explicit and implicit priors are considered, with the latter having the benefit of increased flexibility but having the drawback of a lack of a parametric form to plug in to the ELBO.  The authors address this last point by extending the ELBO appropriately.  Experiments are performed testing the prior’s ability to capture trained filters (Figure 1), provide a good initialization (Figure 2), improve sample efficiency (Figure 3), improve training speed (Figure 4).  ",0.15306122448979592,0.13513513513513514,0.14354066985645936
1645,SP:979cb5eda94e85ac70c6652abb1580295f39c46b,"On the basis of existing topic modelling approaches, the authors apply a transfer learning approach to incorporate additional knowledge to topic models, using both word embeddings and topic models. The underlying idea is that topic models contain a global view that differs on a thematic level, while word embeddings contain a local, immediate contextual view. The combination of both local and global view transfer to enhance a topic model is the main contribution of this paper, especially when using multiple sources (therefore the title: multi-source multi-view transfer).","The paper proposes a multi-source and multi-view transfer learning for neural topic modelling with the pre-trained topic and word embedding. The method is based on NEURAL AUTOREGRESSIVE TOPIC MODELs --- DocNADE (Larochelle&Lauly,2012). DocNADE learns topics using language modelling framework. DocNADEe (Gupta et al., 2019) extended DocNADE by incorporating word embeddings, the approach the authors described as a single source extension of the existing method.",0.1797752808988764,0.23529411764705882,0.2038216560509554
1646,SP:97bd209e33851a48ea9e5c3cab5c3888438e5189,"The paper considers the problem of interpreting the predictions for survival analysis using topic models. The classical survival analysis problem assumes each datapoint is a subject (X,Y,\delta) where X is a feature vector and Y is a life time or a censoring time depending on whether the subject is dead (when delta=1) or alive (when delta=0). The usual objective here is to predict survival times. The authors assume the features in X are interpretable readings (eg ""low blood pressure"") and indicate the number of times that reading was observed. Under this setting, such features can also be seen as words with datapoints being (BoW) documents. The goal then becomes that of finding topics that help predict life times on unseen subjects.","The paper addresses the problem of survival analysis (predicting time until, e.g., death) using topic modeling. The point of introducing topic modeling here is to gain better insight into what helps predict survival times of unseen test subjects. This contrasts with much of the earlier work in survival analysis, which is mainly or only concerned with getting the best prediction without concern with the “thematic structure” of features. Such a thematic structure could be useful to clinicians, but analysis of the learned topic structure by clinical experts is apparently left for future work. Empirical results on pancreatitis and metabric datasets show that the methods of the paper are comparable to several established baselines.",0.2,0.21929824561403508,0.20920502092050208
1647,SP:97bf1da27f21e03aedf82818498273acf15146c9,"This paper presents CrowdPlay, a crowdsourcing platform to collect human demonstrations for any MDP. It also accompanies a dataset of human gameplay on Atari games with multi-agent and some multi-behavior aspects. The paper benchmarks existing offline RL algorithms on this dataset, and details incentive design mechanisms for future crowdsourcing jobs.","This paper proposes a novel framework CrowdPlay for crowdsourcing human data based on standard RL environments. This CrowdPlay pipeline not only supports recruiting different users from different channels to collect multimodal behaviors and data but also designs diverse and real-time incentive mechanisms to guarantee and improve the quality of data. Furthermore, the authors present a dataset, which is publicly available, along with benchmarks on Atari 2600 games, to enable further research on Imitation Learning and Offline Learning.",0.2692307692307692,0.1794871794871795,0.2153846153846154
1648,SP:9808959923ae82ab4eef5cd27682dc15d489ed4b,"The paper describes a way of adding a new inductive bias to RL algorithms, namely ""taking irreversible actions is bad"". The notion of reversibility is defined formally, together with a process for estimating it from samples. Experimentally, it is shown that using the new inductive bias helps achieving improved return on a number of toy benchmarks as well as on Sokoban.","This paper introduces a self-supervised way to measure the reversibility of events. This is done by learning a classifier that takes as input two states from a trajectory and predicts which came first. The paper provides strong theoretical motivation for using this as a measure of reversibility. They then run experiments that use this reversibility metric in two ways: Reversibility-Aware Exploration (RAE), which penalizes the agent with a negative reward when it does an action that is not reversible enough; and Reversibility-Aware Control (RAC), which uses rejection sampling to ensure that actions sampled from the policy are reversible.   In the experiments, it is shown that: (1) reversibility is a strong intrinsic reward, capable of training a Cartpole agent without access to the true rewards; (2) in Sokoban, using IMPALA+RAE results in improvements in sample efficiency; and (3) using a classifier learned using offline data, they show RAC is capable of avoiding irreversible side effects during the whole training process in a custom grid world environment as well as enabling a Cartpole agent with a random policy to perform optimally using only rejection sampling to avoid irreversible actions.",0.36065573770491804,0.11518324607329843,0.1746031746031746
1649,SP:980bf7bae69465dcc77d6629d15d6581873d5d7f,"The paper presents a visually-guided interpretation of activations of the convolution layers in the generator of StyleGAN on four semantic abstractions (Layout, Scene Category, Scene Attributes and Color), which are referred to as the ""Variation Factors"" and validates/corroborates these interpretations quantitatively using a re-scoring function. The claim of the paper is that there is a hierarchical encoding in the layers of the StyleGAN generator with respect to the aforementioned ""Variation Factors"".  Figure 3(a) illustrates how these ""Variation Factors"" emerge in the layers of the StyleGAN generator.","The paper proposes an approach to analyze the latent space learned by recent GAN approaches into semantically meaningful directions of variation, thus allowing for interpretable manipulation of latent space vectors and subsequent generated images.  The approach is based on using pre-trained classifiers for semantic attributes of the images at a variety of levels, including indoor room layout, objects present, illumination (indoor lightining, outdoor lighting), etc. By forming a decision boundary in the latent space for each of these classifiers, the latent code is then manipulated along the boundary normal direction, and re-scored by the classifiers to determine the extent to which the boundary is coupled to the semantic attribute.",0.2222222222222222,0.18018018018018017,0.1990049751243781
1650,SP:9824d6fb46e2ad9c55ae3e55171792ad83c14d8b,"This paper tackles zero-shot and generalised zero-shot learning by using the per-image semantic information. An instance-based loss is introduced to align images and their corresponding text in the same embedding space. To solve the extreme imbalanced issue of generalized zero-shot learning, the authors propose to scale the prediction scores of seen classes by a constant factor. They demonstrate technic contributions on CUB and Flowers datasets and the results achieve the state-of-the-art.","The paper proposes to to use four different losses to train a joint text-image embedding space for zero-shot learning. The four losses consist of a classification loss given text descriptions, a classification loss given images, two contrastive losses given pairs of text and images. The paper also discusses how to balance seen and unseen classes, and it seems that, empirically, embeddings for seen classes are closer together while the embeddings for the unseen classes are further apart. A scaling factor that makes sure these distances are comparable for seen and unseen classes is introduced, and the paper gives an explanation for such a scaling. The final performance on the CUB and FLOWERS data set is impressive.",0.25316455696202533,0.1694915254237288,0.20304568527918782
1651,SP:9861ba00add665c624c186f948063da0cdff0cff," This paper studies the problem of fair classification when the dataset is adversarially perturbed. In particular, the authors considers two models of adversarial perturbation -- (1) adversarial sampling (outlier data points are chosen adversarially), and (2) adversarial labeling (labels of a fraction of data points are chosen adversarially). Based on no-regret online gradient descent algorithm, the authors propose an algorithm that uses existing fair classifier as an oracle and produces a classifier that is both fair and robust to adversarial perturbations.  The main contribution of the paper is evaluation of robustness of fair classifiers. The main message of the empirical evaluation is the following. First, there is a large relative drop in accuracy for all fair models because of adversarial perturbations. Second, adversarial bias increases the accuracy gap across different groups, and thereby further increases the cost of fairness.","Intuitively, the same amount of data poisoning will have a larger impact when the learner is solving a constrained optimization problem than an unconstrained one.  This paper proposed an attack algorithm specifically designed for such fair learners and showed that fair learning algorithms are more vulnerable to adversarial data poisoning attacks.  The problem studied in this paper is of high importance.",0.12949640287769784,0.29508196721311475,0.18000000000000002
1652,SP:988bef6944b23b10e3b73b3745d4b399805faa32,"This paper presents a technique for computing approximate ordinary differential equation (ODE) solution posteriors. As shown in previous work [31], the state solutions of mechanistic ODE systems can be approximated by an extended Kalman filter. The authors further extend this methodology by conditioning the filter on observed sequences. Unlike its Monte Carlo alternatives, the resulting inference scheme computes approximate posteriors in a single forward-backward pass. The synthetic data experiments demonstrate that both the state and parameter trajectories are accurately inferred. The vanilla method and a variant that allows non-negative state estimation are tested on a COVID-19 dataset, implying interpretable findings that agree with government measures.","The paper ""A Probabilistic State Space Model for Joint Inference from Differential Equations and Data"" describes a method of how to estimate latent functions in ordinary differential equations using measuremt data on observed parts of the model. This is achieved by combining a (single!) run through an ODE solver with a suitable probabilistic framework (Bayes filter).",0.1111111111111111,0.21428571428571427,0.14634146341463417
1653,SP:98a52d7970d0d39f8e14f6b5679f8383a3f0e8b1,"The paper proposes a method to calibrate the underlying distribution of a few samples in the few-shot classification scenario. The idea is to estimate a feature distribution of a few samples of a novel class from base class distributions. The authors assume that every dimension in the feature vector follows a Gaussian distribution. Based on the observation that the mean and variance of the distribution with respect to each class are correlated to the semantic similarity of each class, base class distribution can be transferred to the novel class distribution. After distribution calibration, features can be generated from the calibrated distribution and the generated features are used to train classifiers. SVM and logistic regression classifier are used to verify the approach on the mini-imagenet and CUB datasets.","This paper identifies the problem of biased distributions in few-shot learning and proposes to fix it. In few-shot learning, only a few samples per class are available; this makes estimating the class distribution difficult. The paper proposes a distribution calibration algorithm that makes use of the meta-train class distributions to calibrate the few-shot class distributions. Once calibrated, more samples are drawn from this distribution to learn a classifier that generalizes better. This approach does not require additional learnable parameters and can be (potentially) built on-top of any pre-trained feature extractor. Empirical results show that this approach achieves state-of-the-art results on Mini-ImageNet and CUB.",0.2558139534883721,0.2920353982300885,0.2727272727272727
1654,SP:98b0a5ae859842cc7be026c40255afb4c1a0e7d0,"This paper presents a method to learn an acoustic model for phoneme recognition with only the training input acoustic features and a pretrained phoneme LM. This is done by matching the output phoneme sequence distribution of the training set with the phoneme LM distribution. The cost function is proposed by extending a previously proposed unsupervised cost function (Empirical-ODM) to the segmental level, and integrating an intra-segment cost function to encourage the frame-wise output distribution to be similar to each other within a segment. The authors conducted thorough experiments on TIMIT phoneme recognition and demonstrated impressive results.","This paper proposes a new approach to do unsupervised phoneme recognition by learning from unlabelled speech in combination with a trained phoneme language model. The proposed loss function is a combination of a term encouraging the language model of predicted phonemes to match the given language model distribution, and a term to encourage adjacent speech frames to be assigned to the same phoneme class. Phoneme boundaries are iteratively refined using a separate model. Experiments where a hidden Markov model is applied on top of the predicted phonemes are also performed.",0.24242424242424243,0.26666666666666666,0.253968253968254
1655,SP:98db562b40246e689a13aa290e72031ef2bcea8d,"This paper proposes a new approach for how to analyze the ruggedness of the surface of the neural network loss. Specifically, the paper proposes to apply harmonic distortion on the weight-to-output (w-o) maps. That is, the method casts the w-o functions in the Fourier domain and then aggregate the surface characteristics by virtue of averaging the different order Fourier coefficients. The  paper shows that non-linearities are responsible for blueshifting with deeper layers, that is for ""transferring more energy"" on the higher frequencies. The consequence is rougher surfaces, as well as higher frequencies for gradients, which can lead to exploding gradients in the deeper layers. The remedy is with skip connections and feature averaging, which although are methods already known to improve trainability, the paper corroborates that they also make sense in terms of said approach. The paper conducts various empirical and ablation studies, providing evidence of the claims.","The papers proposes an interesting analysis that links several aspects of architectural design in Deep NNs to the spectral analysis and observed roughness. Different activations functions are considered in the study, mainly centered on deep CNN with or without skip connections (in the framework of ResNet v1 and v2). The starting point, which is not novel, actually, but relevant, is that specific types of non-linearities introduce harmonic distortions, and the effect is potentially amplified when multiple non-linearities are stacked. Theoretically, the paper shows that there is a concrete link between architectural choices in the network design and the blueshift in the frequency domain. Experimentally, the observations support the mathematical analysis. All in all, some of the conclusions regarding trainability of CNN architectures with skip connections have been already noted and do not seem greatly new, but the paper introduces a nice perspective to see this phenomenon in another light. ",0.1830065359477124,0.18543046357615894,0.18421052631578946
1656,SP:98df8621044599cf615f32412eb38d812d5be743,"Overview: This work proposes a new NAS benchmark based on the results of surrogate models prediction. This surrogate model is able to predict all architectures in DARTS search space, which is about 10^18 possible architectures. The author compared the predict performance among different type of surrogate models and also leveraged surrogate models to investigate different NAS methods.","This work explored how to use surrogate models to expand the existing (and limited) neural architecture search -- NAS -- benchmark. The new expanded benchmark is named as surrogate NAS benchmark. All codes are open-sourced, which demonstrated the good reproducibility of this work. The authors have conducted extensive experiments to demonstrate the usability of this new surrogate NAS benchmark and showed much analysis of existing NAS methods on this new benchmark.",0.25862068965517243,0.21428571428571427,0.23437500000000003
1657,SP:990b89c67a3b387fc3fa66cd535edb91418d7da1,The paper looks at learning a policy from multiple demonstrators which should also be safely improved by an reinforcement learning signal. They define the policy as a mixture of policies from the single demonstrators. The paper gives a new way to estimate the value function of each policy where the overall policy is defined as mixture of the single policies. The paper subsequently looks at the standard error of the value function estimation and then define the policy improvement step in the presence of value estimation error. The resulting reroute constraint for the policy improvement step is evaluated on the taxi toy task as well as on 4 different atari domains. ,"In this paper, the authors study the problem if learning for observation, a reinforcement learning setting where an agent is given a data set of experiences from a potentially arbitrary number of demonstrators. The authors propose a method which deploys these experience to initialize a place. Then estimate the value of this policy in order to improve it.",0.16216216216216217,0.3103448275862069,0.21301775147928995
1658,SP:9931805320f74c84bfd1f8068117dbcc57641df0,"This paper addresses hierarchical deep reinforcement learning (RL), an important problem in control learning and RL. Based on my understanding of this paper and recent prior work, the most important difference between the proposed approach (HiDe) and other recent approaches, such as HIRO and HAC, is that the top-level goal proposal policy uses a learned planner based on VIN and a learned attention mask to decide on a subgoal. There are also other differences, e.g., this policy outputs a goal position that is relative to the agent's position, rather than an absolute position. HiDe seems to demonstrate impressive transferability to both unseen mazes and new agent embodiments, which are important problems to address for hierarchical RL.","The paper proposes a neat framework for creating HRL framework that will be able to generalize its application to slightly different environment layout. This is done via an image-based top-down from as input to the high level. An intermediate layer is used to help create more fine-grained goal specification for a final goal-based control layer. These layers are trained together using HAC. Overall, the method shows promise but there needs to be more analysis to understand which parts of this combination of ideas are the most important. The results are also only shown for a single environment. Last, the generalization analysis in the paper does not appear to be overly thorough. It would be good to perform this on more than one type of environment also the random environment is not very random.",0.14285714285714285,0.12408759124087591,0.1328125
1659,SP:993930791c2d4699190c699e147ecc0518a4c6b4,"The paper studies risk-sensitive reinforcement learning with the entropic risk measure and function approximation. A meta algorithm based on value iteration is first proposed, then the paper proposes two concrete instantiations, one for linear function approximation and one for general function approximation. Regret bound for both algorithms depend sub-linearly in the number of episodes, and the linear one depends polynomially on the ambient dimension, whereas the general one depends polynomially on the Eluder dimension.","This paper proposes a risk-sensitive algorithm with function approximation in reinforcement learning. To handle the uncertainty, the proposed algorithms consider an entropic risk value function controlled by a risk parameter, which provides a unified framework for both risk-sensitive and risk-averse settings. The main contribution of this paper is to provide theoretical guarantees for the proposed algorithms. ",0.19736842105263158,0.2542372881355932,0.2222222222222222
1660,SP:993d684939ae8074669ba646e49b48ba6b2bf0b9,"This paper takes a fully Bayesian approach to Gaussian Process (GP) active learning by using MCMC sampling to consider multiple model hypotheses from a full posterior, from which it selects examples for GP regression using two new active learning strategies --- Bayesian Query-by-Committee (B-QBC) and Query by Mixture of Gaussian Processes (QB-MGP). B-QBC queries the data point that maximizes the disagreement between the sampled models’ mean values. The idea is that this should provide the highest information about the optimal posterior mode. QB-MGP uses a combination of B-QBC with entropy sampling. The authors evaluate these strategies against several baseline active learning methods on several simulators.","This paper introduces two new active-learning strategies for Gaussian process regression, based on a fully-Bayesian treatment of GPs. Instead of using fixed hyperparamers obtained by maximizing the marginal log-likelihood of the GP model, the authors suggest learning a posterior belief over GP hyperparameters, and make use of the full distribution to design more effective active-learning methods.  In practice, this results in two concrete proposals:  1) a strategy that is similar to query-by-committee, where the committee is formed of multiple GPs sampled from the hyper-posterior (B-QBC). 2) a variant that combines a notion of disagreement with the predictive uncertainty (QB-MGP)  These methods are then compared to others on 8 synthetic datasets.",0.23423423423423423,0.2184873949579832,0.22608695652173913
1661,SP:99532b87b80a2915e725473a1feecff213def1f5,This paper considers training an adversarially robust model in a semi-supervised setting. The authors propose an ensemble-based algorithm for this goal. The algorithm uses a regularization term to induce diversity in the ensemble. The algorithm also leverages the idea of multi-view training in semi-supervised learning to make use of unlabeled data. The experimental results show that the proposed algorithm outperforms several baselines.,"This work introduces ARMOURED, a new method for learning models that are robust against adversarial attacks. The method uses **multi-view**-learning (as in using multiple models with different parameters to cast their votes/views on a given sample), semi-supervised learning to pseudo-label new data based on a consensus, and a diversity regularizer. The approach is evaluated in CIFAR-10 and SVHN against recent baselines in the presence of white-box attacks. The results yield by ARMOURED in these scenarios are superior.",0.22727272727272727,0.17857142857142858,0.2
1662,SP:996e66b927181eb325cadb345bb51e96b8d46923,"The paper proposes two approaches (i.e., PATE-FL and Private-kNN-FL) to train a differentially private global model in a federated setting based on [1] and [2]. In PATE-FL, each client first trains a teacher model using their local dataset. The teacher models are used to make noisy predictions on a public dataset. Then, the public dataset with predicted labels is used to train a final model. In Private-kNN-FL, instead of training a teacher model, the prediction depends on the labels of the nearest neighbors. The experiments show that PATE-FL and Private-kNN-FL can outperform DP-FedAvg in terms of agent-level DP and instance-level DP, respectively.",Federated learning enables distributed clients to train a model without sharing the data with each other. This is typically achieved by a gradient descent type algorithm such as federated averaging. The paper argues that federated learning via gradient updates has issues and proposes to use a voting based method for training machine learning models using unlabeled global data.,0.09565217391304348,0.1896551724137931,0.12716763005780346
1663,SP:9977ed83006cd0ccbf385f26220aa9395a723157,"The authors present a method for tackling the problem of over-smoothing in graph convolutional networks. Specifically, this is achieved by explicitly modelling a latent graph which, ideally, would be a graph which connects an observation to all other observations of the same class and no observations of a different class. In practice, there is only an uncertain picture of this latent graph as in many applications the labels must be estimated for unlabelled observations. The authors present an EM variational algorithm for approximating both this latent graph and using it to improve the estimation of a GCN. The authors demonstrate that the proposed method performs favourably on a battery of test against an array of existing methods for solving the node classification problem. ","This paper proposes a method to alleviate the over-smoothing problem of GNNs. The key idea is to generate a latent graph structure via leveraging stochastic block model to approximate the observed graph structure and label information. The learned latent graph is expected to have a clear community structure with dense intra-class edges and sparse inter-class edges, so that labels of unlabeled nodes are better predicted based on the latent structure. The whole framework is well designed as an MLE problem, with EBLO solved by an alternate EM style algorithm. Both E-step and M-step are assumed to enhance each other's performance, but this point is not clearly validated in the experiments. Also, it is good to see some discussions on the relationship between the proposed framework and dropedge and adaedge methods. Overall, the idea makes sense in terms of joint topology optimization (via SBM) and node classification. The methodology is designed well as an MLE problem. The paper writes well and the experimental results demonstrate effectiveness to some extent.",0.25806451612903225,0.1839080459770115,0.21476510067114093
1664,SP:998b957bfb35d2c7c7aa08e433fb4aed556e2c44,"The information bottleneck (IB) is an information theoretic principle for optimizing a mapping (encoding, e.g. clustering) of an input, to trade off two kinds of mutual information: minimize mutual information between the original input and the mapped version (to compress the input), and maximize mutual information between the mapped input and an output variable. It is related to a minimization of an (expected) Kullback-Leibler divergence betwen conditional distributions of an output variable.","This paper proposes a new ""dual"" variant of the Information Bottleneck framework. The IB framework has been the subject of many papers in past years, with a focus on understanding the inner workings of deep learning. The framework poses machine learning as optimizing an internal representation to tradeoff between retaining less information about the input features and retaining more information about the output label (prediction). The existing framework measures the retained information about the prediction via mutual information, which can be expressed as a KL divergence. The new dual framework reverses the arguments of this divergence.",0.25675675675675674,0.19791666666666666,0.22352941176470587
1665,SP:99a3db8fd1a8bbbde0338a4927c74ed71594aaf2,"This paper proposes to use a monotonic quantile function for distributional RL by: (i) estimating the quantile values at the supported quantiles via a cumulative sum of non-negative incremental value, and (ii) interpolate the quantile values at the unsupported quantiles via linear combination of the nearest supported quantiles. The paper then also proposes to estimate the exploration bonus for each state using random network distillation. It then conducts experiments in Atari games to verify some conclusions.  ","This paper studies distributional RL and proposed two extensions. One is a method to enforce a non-decreasing ordering of quantile functions by a linear and non-negative increments. The other is extends the idea of DLTV which adds exploration bonus in action selection by using the random network distillation method, which in particular, using a measure of inconsistency between target network and predictor networks as a frequency measure of sampled states. ",0.24675324675324675,0.2638888888888889,0.25503355704697983
1666,SP:99b3ac117a5c787653031eb169f0104a8594c088,"This paper presents BVAE-TTS, which applies hierarchical VAEs (using an approach motivated by NVAE and Ladder VAEs) to the problem of parallel TTS.  The main components of the system are a dot product-based attention mechanism that is used during training to produce phoneme duration targets for the parallel duration predictor (that is used during synthesis) and the hierarchical VAE that converts duration-replicated phoneme features into mel spectrogram frames (which are converted to waveform samples using a pre-trained WaveGlow vocoder).  The system is compared to Glow-TTS (a similar parallel system that uses flows instead of VAEs) and Tacotron 2 (a non-parallel autoregressive system) in terms of MOS naturalness, synthesis speed, and parameter efficiency. ","Neural models that autoregressively generate mel spectrograms from text (or phonemes), such as Tacotron, have been used to generate high quality synthetic speech. However, they suffer from slow inference speed due to their autoregressive nature. To alleviate this, non-autoregressive models have been proposed, such as FastSpeech and Glow-TTS. The proposed model, BVAE-TTS, is yet another non-autoregressive speech synthesis model (outputting spectrograms), with two key advantages over the aforementioned models: (a) no autoregressive teacher model is required, as in FastSpeech, which simplifies training, and (b) fewer parameters are needed than in Glow-TTS, since there is no bijectivity constraint (allowing a more expressive architecture to be used). Models are compared with inference speed and MOS, and BVAE-TTS compares favorably on both both metrics when compared to Glow-TTS.",0.13559322033898305,0.12121212121212122,0.12800000000000003
1667,SP:99b801c2541124ead1b8ff8904e7aa82c422c37c,"This paper proposes a new adaptive method, which is called AvaGrad. The authors first show that Adam may not converge to a stationary point for a stochastic convex optimization in Theorem1, which is closely related to [1]. They then show that by simply making $eta_t$ to be independent of the sample $s_t$, Adam is able to converge just like SGD in Theorem2. Theorem2 follows the standard SGD techniques. Next, they propose AVAGRAD, which is based on the idea of getting rid of the effect of $\epsilon$. ","In this paper the authors develop variants of Adam which corrects for the relationship of the gradient and adaptive terms that causes convergence issues, naming them Delayed Adam and AvaGrad. They also provide proofs demonstrating they solve the convergence issues of Adam in O(1/sqrt(T)) time. They also introduce a convex problem where Adam fails to converge to a stationary point.",0.13636363636363635,0.19047619047619047,0.15894039735099338
1668,SP:99c86132921975cd676c3ee593274679890cfc57,"This paper is about test-time adaptation (TTA), in particular about improving the recently published test-time training (TTT) approach. It provides an analysis about conditions that can lead to TTT failures, and overcome them with a method that relies on i) feature alignment and ii) more sophisticated self-supervised learning (SSL) objectives (when compared with the TTT's seminal work). The method is compared against other recent TTA approaches, showing good performance on standardized benchmarks.","This paper focus on improving the generalization of deep neural networks in the presence of distributional shift at test time i.e., unsupervised source-free network adaptation on data distribution that is different from training. They follow the footsteps of a prior work by Sun et al. [8] and leverage an auxiliary task at test time. However, this work points out that test time training with auxiliary tasks like rotation prediction need not necessarily encourage the network to improve its generalization on the main task. Thus, the authors propose to transfer the benefits of self-supervised learning (SSL) to the main task by introducing an online feature alignment strategy that utilizes offline feature summarization statistics collected on the original training (source) data and also choosing more suitable SSL task like contrastive learning instead of rotation prediction. Tthey denote the resulting approach as TTT++. Results and comparison to existing techniques are shown on popular datasets like cifar10-c, cifar100-c, cifar10.1 and VisDA-C.",0.25,0.11585365853658537,0.15833333333333335
1669,SP:99d5b859a30f1825f5a21fb62fdf7a918b838b95,"This is an optimization algorithm paper, using the idea of ""extragradient"" and proposing to combine acceleration with proximal gradient descent-type algorithms (Prox-SVRG). Their proposed algorithm, i.e., accelerated variance reduced stochastic extra gradient descent, combines the advantages of Prox-SVRG and momentum acceleration techniques. The authors prove the convergence rate and oracle complexity of their algorithm for strongly convex and non-strongly convex problems. Their experiments on face recognition show improvement on top of Prox-SVRG as well Katyusha. They also propose an asynchronous variant of their algorithm and show that it outperforms other asynchronous baselines.","The paper proposes an optimization method for solving unconstrained convex optimization problems where the objective function consists of a sum of several smooth components f_i and a (not necessarily smooth) convex function R. The proposed method AVR-SExtraGD is a stochastic descent method building on the previous algorithms Prox-SVRG (Lin 2014) and Katyusha (Zeyuan 2017). The previous Prox-SVRG method using a proximal operator is explained to converge fast but leads to inaccurate final solutions, while the Katyusha method is an algorithm based on  momentum acceleration. The current paper builds on these two approaches and applies the momentum acceleration technique in a stochastic extragradient descent framework to achieve fast convergence.",0.19387755102040816,0.16964285714285715,0.18095238095238095
1670,SP:99e7452e7b7c5a1071af9370aa61acad39f99833,"The paper studies the effect of various data augmentation methods on image classification tasks. The Authors propose the Structural Similarity (SSIM) as a measure of the magnitude of the various types of data augmentation noise they consider. The Authors argue that SSIM is superior to PSNR as a measure of the intensity of the noise, across various noise types.","This paper aims at analyzing the effect of injecting noise to images as data augmentation in training CNN for the image classification task. Based on the SSIM metric (which is shown to be a better metric than PSNR), different noise level on a set of different kinds of noise are explored. Experimental results on two sub-datasets of ImageNet suggest that Speckle noise would lead to better CNN models.",0.3050847457627119,0.2608695652173913,0.28125
1671,SP:99fd9fac1678bb46d41967f397f237561a3890d3,"This paper proposes to use hypernetwork to prevent catastrophic forgetting. In deep learning, the information of the samples are converted to parameters during the training process, however, future training process could interfere with the information from the previous tasks. One of the method to prevent forgetting is to use reheasal, which retrains the network with previous data. The mechanism of this work is to store the previous samples as a trained point in the parameter space, so that a set of points in the original space is stored and thus rehearsed as one point in the parameter space, this saves both the memory and computation.","Paper proposes a method for CL. The method is based on hypernetworks. These networks are a metamodel, which produce the parameters (from a task-conditioned embedding) which will be used in the main network. Preventing forgetting in the main network is now, replaced by preventing forgetting in the hypernetwork. This is done by imposing a regularization on the hypernetwork outcome, imposing that the generated weights should be similar for previous tasks (similar to Li & Hoiem who impose this on the network outputs). In addition, the paper proposes chunking, which refers to using an additional set of chunk, embeddings which are shared for all tasks, which allow compressing the hypernetwork. Furthermore, they propose an extension that allows for image replay (this is not an easy extension and an impressive contribution on itself, but maybe confusing for the current paper).",0.21904761904761905,0.16666666666666666,0.18930041152263374
1672,SP:9a4c3ea3b70f57c94a649f12b8c85c35e6b3b189,"Paper proposed an ensemble learning approach for the low-data regime. Paper uses various sources of diversity - pre-training, fine-tuning and combined to create ensembles. It then uses nearest-neighbor accuracy to rank pre-trained models, fine-tune the best ones with a small hyper-parameter sweep, and greedily construct an ensemble to minimize validation cross-entropy. Paper claims to achieve state-of-the art performance with much lower inference budget. ","[Summary] This paper presents different ways of creating ensembles from pre-trained models. Specifically, authors first utilize nearest-neighbor accuracy to to rank pre-trained models, then fine-tune the best ones with a small hyperparameter sweep, and finally greedily construct an ensemble to minimize validation cross-entropy. Experiments on the Visual Task Adaptation Benchmark show the efficacy of the approach in selecting few models within a computational budget.",0.4583333333333333,0.4782608695652174,0.4680851063829787
1673,SP:9a53b280d3f22c78dab771243688789d7e8cad12,"This paper proposes the concept of decision state, which is the state where decision is made “more” dependent to a particular goal. The authors propose a KL divergence regularization to learn the structure of the tasks, and then use this information to encourage the policy to visit the decision states. The method is tested on several different experiment setups.","The authors propose a new regularizer for policy search in a multi-goal RL setting. The objective promotes a more efficient exploration strategy by encouraging the agent to learn policies that depend as little as possible on the target goal. This is achieved by regularizing standard RL losses with the negative conditional mutual information I(A;G|S). Although this regularizer cannot be optimize, the authors propose a tractable bound. The net effect of this regularizer is to promote more effective exploration by encouraging the agent to visit decision states, in which goal-depend decisions play a more important role. The idea of using this particular regularizer is inspired by an existing line of work on the information bottleneck.",0.3559322033898305,0.17647058823529413,0.2359550561797753
1674,SP:9a703a4562558d32a372047cd46cfe57b3695d38,"This work introduces a simple technique to obtain uncertainty estimates for deep neural networks. This is achieved by having a set of random networks (i.e. neural networks where their parameters are randomly initialized) and then computing an uncertainty value based on the difference in the predictions between those random networks and networks that are trained to mimic them on a finite collection of points. The authors further show that this method results into uncertainties that are conservative, meaning that they are higher than the uncertainty of a hypothetical posterior, and concentrate, i.e. they converge towards zero when we get more and more data. The authors further draw connections to ensemble methods and discuss how such a method can be effectively realized in practice. They then evaluate their approach on an out-of-distribution detection task, they measure the calibration of their uncertainty estimates and finally perform a small ablation study for their concentration result. ","This paper introduces a new method for uncertainty estimation which utilizes randomly initialized networks. Essentially, instead of training a single predictor that outputs means and uncertainty estimates together, authors propose to have two separate models: one that outputs means, and one that outputs uncertainties. The later one consists of two networks: a randomly initialized “prior” which is fixed and is not trained, and a “predictor”, which is then trained to predict the output of the randomly initialized “prior” applied to the training samples.  ",0.1282051282051282,0.24096385542168675,0.16736401673640167
1675,SP:9a71fc1f596ef67bf5228d779246f8e9ae04c8e0,"This paper investigates fine-tuning BERT for few-sample datasets. Notably, the authors find debiasing omission in BERT-adam. They find original debiased adam is better than BERT-adam. Besides, they also find re-initializing top layers can speed up learning and achieve better performance. These two findings are interesting. Another finding fine-tuning BERT for Longer is incremental to some extend.","Large language models (LM) architectures, such as BERT, XLNet, etc., are not generally trained from scratch, but rather used as pretrained models. Among all, BERT is one of the most widely used ones, and its use on downstream tasks mainly consists on a stage of fine-tuning, where the new layers added are trained, and the rest of parameters of the network are left unfrozen, and hence are adjusted slightly to better fit the new task. However, this step of fine-tuning BERT is known to be quite unstable, and depends on a large set of factors, especially the initialization. Since the final performance on these downstream tasks can vary notably, different approaches has been proposed to circumvent this, but still the most common solution consists simply on choosing the best performing model, from a few random initialisation, using the validation set. ",0.1774193548387097,0.07746478873239436,0.10784313725490195
1676,SP:9a8e18adead7601ee9403757b2b5dd7c554fc501,"This paper introduces an interesting new approach for learning a classifier on homomorphically encrypted data. A few important assumptions are made: only very few features (one to three maybe) are privacy-protected and the modeler is able to build a regression model on a part of the dataset. Next, further training data including private features are used to convert the initial model into a Ridge regression model. The key innovation is that the encrypted computation step can be isolated to make it very simple when few features are encrypted.  ","This study considers a situation that a part of unencrypted samples are available while the other samples are provided with encrypted by FHE (or LHE). First, the modeler trains a logistic regression model with unencrypted samples. By using this model, given encrypted samples,  the modeler obtains the encrypted logits. To absorb the difference of sample generating distributions of non-private samples and private samples, moment matching is applied on encrypted logits (I could not understand why this works).  Then, ridge regression is solved with the encrypted logits with labels, in that the solution can be obtained in an analytic form instead of iterative methods as logistic regression regularly requires. **Due to the lack of a detailed description of the security model and global information flow of the protocol, this summary might be wrong.  ",0.23595505617977527,0.15789473684210525,0.18918918918918917
1677,SP:9a904b1fc758f8875bf1f6c2c483ebfadbebb9e8,"This paper proposes a 3D pretraining method for molecular property prediction. As 3D information is infeasible to compute at the scale required by real-world applications, this paper reasons about the geometry of molecules given only their 2D molecular graphs.   During pretraining with molecules whose 3D information is known beforehand, this paper uses a 2D GNN to encode these molecules. Then, it maximizes the mutual information between 3D summary vectors and the encoded representations for injecting 3D information into the representations. During fine-tuning, the model can take 2D molecules as input. The pretraining phase ensures that the representations during fine-tuning contain latent 3D information.   The paper pre-trains on three datasets, QM9, GEOM-Drugs, and QMugs, and tests on both quantum mechanical properties (QM9 and GEOM-Drugs) and non-quantum properties (10 datasets, e.g. HIV and BACE). The paper claims that significant improvements are obtained for quantum mechanical properties. Also, the method does not suffer from the negative transfer. ","The authors present 3D Infomax, a graph neural network (GNN) pre-training solution that leverages 3D information to generate better learned embeddings and improve performance on down-stream prediction tasks where 3D information would be useful but not easily obtainable.  The approach is useful for a range of downstream tasks involving molecules, including ones that are quantum mechnical, biological, and pharmacological in nature.  They also demonstrate that the use of multiple 3D conformations (thereby encoding the inherent flexibility of molecules) further improves performance.",0.09876543209876543,0.1927710843373494,0.13061224489795917
1678,SP:9a9d54a9a5e8ca271738073bbffad9bc0807651d,"The authors propose a modification of existing adaptive variants of SGD to avoid problems with generalization. It is known that adaptive gradient algorithms such as Adam tend to find good parameter values more quickly initially, but in the later phases of training they stop making good progress due to necessarily low learning rates so SGD often outperforms them past a certain point. The suggested algorithm Padam achieves the best of both worlds, quick initial improvements and good performance in the later stages.","The idea is simple and promising: generalize AMSgrad and momentum by hyperparameterizing the p=1/2 in denominator of ADAM term to be within [0,1/2], with 0 being momentum case.  It was good to see the experiments use non-MNIST data (e.g. ImageNet, Cifar) and reasonable CNN models (ResNet, VGG).  However, the experimental evaluation is not convincing that this approach will lead to significant improvements in optimizing such modern models in practice.  ",0.13414634146341464,0.14666666666666667,0.14012738853503184
1679,SP:9a9f3e72c593cec2d406c6eca03e1bb2efa019d7,"The authors the Locally Valid and Discriminative (LVD) method to construct confidence intervals. The idea has three steps. (1) First is to take the embeddings from a neural network and train a kernel regression model on the task, learning a Gaussian kernel $K$. (2) Second is to, on a separate held-out ""conformal"" set, compute the residuals between the model and ground truth labels. (3) Third is to, at inference time, compute the empirical desired $(1-\alpha)$ interval on the ""conformal"" set residuals, where each residual is re-weighted according to $K(x', x)$ where $x'$ is the query of interest. LVD has the appealing property that it is compatible with any (potentially pre-trained) deep learning model, with no further further training necessary.  The authors prove that under appropriate assumptions LVD achieves *local coverage*, i.e. coverage not only marginal over the entire feature space, but at a particular query $x$. Empirically they demonstrate that LVD improves upon popular neural network predictive uncertainty methods on the well-known UCI datasets. They evaluate in terms of Mean Absolute Deviation, Marginal Coverage Rates, and Tail Coverage Rates (which is defined as the coverage rate for the left and right 10% of the tails of labels $y$).","The authors propose a new method for locally valid (e.g. marginal coverage guarantees) and discriminative prediction* intervals by connecting two ideas: kernel regression and conformal inference. They evaluate their method on a suite of small to medium scale regression tasks and find that the proposed approach is locally valid   *note that the authors refer to these intervals as _confidence_ intervals which I believe to be an error. CIs seek to cover a population parameter, which for regression would be the true, unknown, and underlying mean function (which can only be assessed via a simulation). What the authors propose are _prediction_ intervals which seek to cover draws from this distribution and are inclusive of distributional noise, c.f. this reference for more:  https://www.stat.cmu.edu/~ryantibs/papers/conformal.pdf ",0.12682926829268293,0.1984732824427481,0.15476190476190474
1680,SP:9ad896111e20da136d179dcd72aad658eba76d93,"GraphNVP is the first paper to introduce the concept of ""invertible flow"", that is to construct the invertible mapping from latent vector z to the graph G. By constructing the mapping from G to z, GraphNVP first changes the discrete feature vector into continuous variables, then update this matrix representation by scaling and transforming functions (Eq. (2)-(5) in this GRF paper). In each iteration the matrix is only updated by one row (one slice for the tensor), while keep other rows intact. Then for constructing the inverse mapping, we can first sample a random vector and then apply the “inverse” of the update rule to recover the edge matrix and node matrix respectively.","The paper introduces an invertible deep generative model architecture for modeling molecular graphs. The model is based on graph residual flows (GRF), which is a graph variant of normalizing flows. The GRF model is a refinement of the GraphNVP generative model, which is also invertible,  but which does not seem to work very well for sparse low-degree graphs (such as molecular graphs). ",0.10526315789473684,0.19047619047619047,0.13559322033898305
1681,SP:9aea99f6d15886147e932ee5de55dc24a00cbb67,"This paper proposed a framework to continuously learn object-centric representations and formulate the problem by projecting the object representation space to the hypernetwork parameters for the segmentation task. The data are sampled from marginals where only one instance mask is collected in each scene. The representation learning incorporates the base representation learning, redundancy removal, and forgetting prevention.  The experiments study the impact of \tau under different metrics.    ",This paper presents a new framework to learn object-centric representations. The model is composed of a segmentation network and a hypernetwork. The hypernetwork takes the latent representation of a certain object as input and predicts the weights for the segmentation network. The latent representation and the hypernetwork are jointly optimized to maximize the discrimination power of the segmentation network. The framework also introduces a sparse representation mechanism so that each object can be represented in some base object representations. ,0.3382352941176471,0.2875,0.3108108108108108
1682,SP:9afba78dbb1607966ebd8b973563bb07efd8377b,"The paper proposes a novel approach to graph representation learning. In particular, a graph auto-encoder is proposed that aims to better capture the topological structure by utilising a neighbourhood reconstruction and a degree reconstruction objective. An optimal-transport based objective is proposed for the neighbourhood reconstruction that optimises the 2-Wasserstein distance between the decoded distribution and an empirical estimate of the neighbourhood distribution. An extensive experimental analysis is performed, highlighting the benefits of the proposed approach on a range of synthetic datasets to capture structure information. The experimental results also highlight its robustness across 9 different real-world graph datasets (ranging from proximity-oriented to structure-oriented datasets).","This paper studies the problem of graph representation learning with graph autoencoder. The paper argues that most GNNs are designed for semi-supervised learning and cannot learn task-agnostic embedding. As a result, the paper proposes a graph autoencoder architecture that trains the GNN in an unsupervised manner. The key idea is to develop a decoder to reconstruct both the node degree and feature distribution. Experimental results show that the results outperform existing autoencoder baselines in several datasets.",0.18181818181818182,0.2564102564102564,0.2127659574468085
1683,SP:9b2ac905ecf71d7207dab06d2367d7259ac4968b,"This work proposes a hybrid backbone which combines existing MV2 block and new MobileViT block for efficient classification, detection and segmentation. The core idea with MobileViT block is to use both convolution and self-attention block to aggregate local and global feature, respectively. Experiments on IN-1K, COCO and PASCAL VOC have shown quite promising results.","This paper introduces a lightweight and general-purpose vision transformer, termed MobileViT, for mobile devices. It attempts to build a model which can combine the strengths of CNNs and ViTs to build a light-weight and low latency network for mobile vision tasks. MobileViT achieves top-1 accuracy of 78.4% on ImageNet-1k dataset (classification task), 27.7 mAP on MS-COCO dataset (object detection task), and 79.1 mIOU on VOC 2012 dataset (semantic segmentation task).",0.25,0.1794871794871795,0.208955223880597
1684,SP:9b43409b72248a99e5271fe974f39077767bd50a,"This paper uses a synthetic two-dimensional dataset to visualize the importance of different data points on machine learning model performance. In particular, they used a multi-layer perceptron as the model, and they used four different schemes by which to measure the importance of individual data points. Not surprisingly, they show that regions of data that are misclassified tend to have relatively high importance in determining model performance. However, there are notable differences among the different schemes in their performances. This paper discusses the nature of those differences.",The paper proposes a new method for identifying important points in a dataset given the task of classification. The paper introduces a new valuation function. The paper takes into consideration other methods that deal with the same problem and reevaluated them using the new scoring function. The scoring function focuses on the effect points have on the decision boundary. The results show that the most valuable points are not the ones close to the boundary but the misclassified ones. The result is interesting but not surprising. ,0.1797752808988764,0.18604651162790697,0.18285714285714283
1685,SP:9bc5be7060804da42581342ed69d6cd6cf2c90f3,"The paper suggests two approaches to combine the concepts of robust Markov decision processes (MDPs) with that of constrained MDPs. In the first approach, called R3C, a worst-case setting is used for both the expected total discounted rewards criterion and the constraints on the state-action pairs. The robustness is defined with respect to all possible choices (from an uncertainty set) of transition-probability functions. In the second approach, called RC, only the constraints should be robust against all possible transition probabilities. The paper studies the value functions and the corresponding Bellman operators of these problems and argues that, in both cases, these operators are contractions in the supremum norm. Finally, numerical experiments are presented on RWRL problems, such as the cart-pole and the walker, showing the effect of using the redefined operators.","The standard Reinforcement Learning framework is limited in many ways, and numerous variants have been introduced to deal with aspects such as partial observability, temporal abstraction, safety, domain transfer, etc. Yet, these issues are often studied separately and it is often unclear how to combine them together. This is the ambitious challenge taken by this paper, which attempts to bridge the two separate settings of Robust MDPs, which aim at considering ambiguity in the dynamics, and Constrained MDPs, which aim at enforcing the satisfaction of a constraint on an expected cost signal. The authors propose the formulation of two objectives, that merge the two aspects and include both a worst-case evaluation over the ambiguity set and a constraint violation penalty term. The ways of dealing with both issues are fairly standard (Lagrangian relaxation of the constraints with alternating optimization, and worst-case evaluation over a finite set of simulated transitions in practice), but their combination seems novel and relevant. These objectives come with the corresponding Bellman Expectation operators, which allow to evaluate the current policy (critic) and provide a feedback (gradient) for the actor to ensure robust constraint satisfaction. The applicability of the proposed approaches is demonstrated on a benchmark of Mujoco tasks, where they are shown to compare favorably to several baselines.",0.23703703703703705,0.14953271028037382,0.1833810888252149
1686,SP:9bc80503d9771b780501b2dacac2cc37e4f5cd95,"In this paper, the authors introduce a repository of datasets for several atomistic learning tasks. These datasets are processed into a simple and standardized format. A systematic benchmark with atomistic learning methods is presented, showcasing the value of using 3D atom-level data instead of 1D or 2D features. The authors argue that these datasets will serve as a stepping stone for machine learning researchers interested in developing methods for atomistic learning and rapidly advance this field. The paper also presents the best practices for each of the tasks, as well as the splitting and filtering criteria to ensure generalizability and reproducibility.","This paper presents a large benchmark of machine learning tasks for molecules represented by the 3D coordinates of their atoms. The benchmark is a combination of existing data sets and newly created ones, and covers a variety of applications and tasks, from small molecules to RNA or protein structures, and including classification, regression and ranking tasks. In addition, three deep-learning algorithms are implemented and evaluated on these benchmarks, and compared to state-of-the-art methods that do not use 3D information, and empirically demonstrate the benefit of incorporating 3D information in the networks.",0.18627450980392157,0.2,0.19289340101522842
1687,SP:9be34b13f59e6e33820e863d7ed33f0479fc368e,"The paper proposes a new efficient method for denoising diffusion probabilistic models (DDPM) (generative models that optimize for the closest solution on a manifold) based on the observation that this can be seen a solving a set of differential equations on a manifold. This allows efficient pseudo numerical methods to be applied here which have many advantageous properties over classical optimization methods, including less optimization steps and guaranteed manifold solutions due to separating the gradient part from the transfer part in the optimization. Results are shown on four datasets comparing to two reasonable but not sota baselines. ","Highlighting the high computational complexity for sampling from Denoising Diffusion Probabilistic Models (DDPMs) (e.g. wrt GANs), authors build on the connection between diffusion processes and ODEs to propose efficient (pseudo-)numerical methods so as to sample data from the data manifold. The main idea is to combine the discrete update proposed in DDIMs, with a fourth-order gradient estimation given by the Runge-Kutta or linear multi-step methods. The motivation being that such gradient estimator should yield trajectories that stay closer to the data manifold. They empirically assess their method(s) on CIFAR10 and CelebA in terms of sample quality (measured by FID), and show that they get a ~x20 speed-up wrt DDIMs or a significant improvement in FID with the same number of steps. ",0.20618556701030927,0.15625,0.17777777777777776
1688,SP:9be76bd104a9119c6aa5480f7cb70aba77519907,"This paper proposes a simple improvement to recurrent network architectures for language modeling. The idea is to insert a single additional layer into a network with one or more recurrent layers, just before the output layer (Eq. 6). This is termed a ""dual connection"" and it combines the output of the last recurrent layer directly with the input to the network at the current step. The paper presents the results of adding this modification to both LSTM and Mogrifier-LSTM networks on the Penn Treebank and WikiText-2 datasets. ","This work revisits the LSTM architecture. They propose to modify a recurrent architecture by adding a direct connection between the input and the output of the recurrent module, called ""dual"". They also consider a double-layer LSTM, where the output of the recurrent module is obtained by the concatenated application of two LSTM layers. In experiments, the dual modification can get consistent improvement.",0.2247191011235955,0.31746031746031744,0.2631578947368421
1689,SP:9bfef79b508f28c0988d14dc972702ea0dc99d7e,"The authors perform an extensive study investigating the stem of ViT models and replacing it with one that consists of a stack of downsampling 3x3 convolutions. The study reveals that this simple change makes ViT training more robust, faster to converge, but also scales better (cf. i21k pre-training).","The paper studies the impact of stem in ViT. Specifically, the authors propose to replace the patch-based stem in ViT with a standard, lightweight convolutional stem, and show that this simple revision leads to substantially improved stability wrt the choices of optimizers and several other hyper-parameters. The resulting model achieves comparable performance with strong convnets baselines when trained on ImageNet-1K and has better accuracy-speed tradeoff than both ViTs and convents when trained over larger dataset (ImageNet-21K).",0.24489795918367346,0.14814814814814814,0.1846153846153846
1690,SP:9c00384d154224a1d849aa254aab6eec214a75d9,"This paper proposes Expectigrad, which is a new optimizer for nonconvex optimization. The main idea is to consider arithmetic mean of squared gradients instead of exponential moving average and to use a normalization factor that takes into account the number of nonzeros observed during the run of the algorithm, for each component. The algorithm is analyzed for solving smooth nonconvex optimization and its practical performance is investigated.","This paper proposes the Expectigrad algorithm that normalizes the exponential moving average (EMA) of first moments on the fly. This avoids normalizing historical gradients by future gradients. The normalization factor is an unweighted average, instead of an EMA, of the historical second moments. For the special case where the EMA constant of the first moment is zero, the paper shows that Expectigrad converges to the optimum on the online convex problems proposed by Reddi et al. (2018) for which the vanilla ADAM fails to converge. For general stochastic smooth convex problems with bounded stochastic gradients, the paper shows that the convergence rate of mini-batch Expectigrad is $O(1 / \sqrt{T} + 1 / b)$ where $b$ is the mini-batch size.",0.2835820895522388,0.15833333333333333,0.2032085561497326
1691,SP:9c05898952af007c390c3a6cc385746daad29e65,"This paper considers a case in the cooperative multiagent reinforcement learning where one single agent can behave adversarially. It claims that the performance of the whole MARL system  would deteriorate significantly  and demonstrate this phenomenon both theoretically and empirically. Then the author proposes a solution, i.e. , solving the correlated equilibrium in the game.  To seek  the correlated equilibrium, the author introduces a global random variable z and adds a mutual information regularization term.  Indeed this idea is easy to follow since it directly follows the definition of the correlated equilibrium. At last, it tests the algorithm in the SMAC environment and compares it with QMIX algorithm.","The paper addresses the issue of robustness in cooperative multi-agent RL setups, where the inclusion at test time of an agent that makes error or is even adversarial can drastically decrease performance. The main idea is to compute a correlated equilibrium, by allowing all agents policies to depend on a common signal. To encourage the actions of the agents to correlate, they add a mutual information loss (i.e. a retrodiction that encourages the global latent to be predictable given the action taken). ",0.17757009345794392,0.2261904761904762,0.19895287958115185
1692,SP:9c19d065e31d1eaf67f87f7549ae3c2ebbd5a57f,"The authors present a novel method for generating images from sounds using a two parts model composed by a fusion network, aka. multi-modal layers, for learning sound and visual features in a common semantic space, and two conditional GANs for converting sound features into visual features and those into images. To validate their approach they created an ad-hoc dataset, based on Flickr-SoundNet dataset, which contains 104K pairs of sounds and images with matching scene content. Their model was trained as two separate models, the fusion network was trained to classify both images and sounds minimizing their cross-entropy and their L1 distance, while the two conditional GANs were trained until convergence penalizing the discriminator to prevent fast convergence.","This paper addresses the problem of generating images from sound. The general idea is to use conditional GANs. In particular, two stacked conditional autoencoder GANs, where the autoencoders have a U-Net architecture. First, sound features are mapped into multimodal features that contain image feature/class information. Such multimodal features condition the generation of image features with an initial GAN, and the image features condition the generation of the output image with a second GAN. Although the problem itself is rather difficult, the solution is almost entirely based on previous work. The most novel part of the paper is the learning of the multimodal features. The final results are not very compelling, the literature review is very limited. There is a very high-level description of the approach with very few details, which leave the reader with a lot of unanswered questions. There is no attempt to compare with previous work, the architecture is not studied in depth with an ablation study, or compared with more interesting baselines, other than verifying that images can be generated from features (something not very surprising, given StackGUN!). Probably the more important verification is that the multimodal feature can embody some class information. Overall it seems to be a limited contribution.",0.19834710743801653,0.11594202898550725,0.14634146341463414
1693,SP:9c4bfe5e2bd7e16ad54d8b37b67f9d86192f9124,"The authors identify and address the problem of sub-optimal and myopic behaviors of self-imitation learning in environments with sparse rewards. The authors propose DTSIL to learn a trajectory-conditioned policy to imitate diverse trajectories from the agent’s own past experience. Unlike other self-imitation learning methods, the proposed method not only leverages sub-trajectories with high rewards, but lower-reward trajectories to encourage agent exploration diversity. The authors claim the proposed method to be more likely to find a global optimal solution. ","The paper addresses the challenge of hard exploration tasks. The approach taken is to apply self-imitation to a diverse selection of trajectories from past experience -- practice re-doing the strangest things you've ever done. This is claimed to drive more efficient exploration in sparse-reward problems, leading to SOTA results for Montezuma's Revenge without certain common aides.",0.18823529411764706,0.26666666666666666,0.2206896551724138
1694,SP:9c54758e7833e0c193817bdf1d1fa5b875902153,"The paper describes dynamic residual adapters designed to adaptively account for latent domains, and weighted domain transfer. This framework injects adaptivity into networks, preventing them from overfitting to the largest domains in distributions, a failure mode of traditional models that are exposed in latent domain learning. The approach closes a large amount of the performance gap to domain-supervised solutions. ","The authors propose a method for latent domain learning, where input data come from different domains and the domain labels are unknown. The proposed method consists of two parts: dynamic residual adapter and weighted domain transfer. The dynamic residual adapter acts as a mixture of expert layer. And the weighted domain transfer which augments the dataset by interpolating between different input pairs. Empirical results show that when combined together, the proposed method perform better than training a regular model.",0.23333333333333334,0.17721518987341772,0.20143884892086333
1695,SP:9c63124b50d33e18039aee328c72b438a8503b85,The authors propose an interesting hierarchical reinforcement learning method that makes use of visual inputs as well as proprioception for locomotion of humanoid agents. The low-level controllers make use of “motion capture” data and are expected to form a set of movement primitives that can be used by a higher-level controller that has vision and memory. Their method is tested on a variety of tasks and different choices of low-level controller are explored.,"This paper proposes a hierarchical reinforcement learning (HRL) method for visual motor control of humanoid agents. The method is decomposed into a high-level controller that takes in visual input and proprioceptive information, and a low-level controller (they compare may ways of doing this) that takes care of the agent’s motor control. In experiments, the proposed method is tested on a variety of RL tasks where the many low-level controllers presented in the paper are compared against each other.",0.34210526315789475,0.3170731707317073,0.32911392405063294
1696,SP:9c77f92d9933964d7066aec0e5d3e33bb2ee1745,"The authors present new insights on PCA analysis by reconceiving it in terms of a Nash equilibrium among different players, related to the different components. The importance of an objective function minimizing the off-diagonal elements of R is emphasized. The insights lead to parallel algorithms and are demonstrated on large scale problems, which is nice. Overall the new insights can be very valuable and also inspiring for future work and for new developments,  from a broader perspective.","Principal component analysis (PCA) is a well-known dimensionality reduction and feature learning technique in the literature that leads to uncorrelated features. While there are a plethora of algorithms for PCA, along with accompanying analysis, a majority of these works have been developed from an optimization perspective. This paper differs from existing works in that it motivates the $k$-PCA problem, which involves learning the $k$-dominant eigen vectors of the sample covariance matrix, as a competitive game between $k$ players in which each player is supposed to estimate one of the eigen vectors and the PCA solution is the unique strict-Nash equilibrium. The main contributions of the paper in this regard are the following:",0.19230769230769232,0.12931034482758622,0.15463917525773196
1697,SP:9ca6bd1dd9323faf06e5f065fdbcc07f8727d7ba,"This is an interesting paper which proposes a novel angle on the problem of learning long-term dependencies in recurrent nets. The authors argue that most of the action should be in the imaginary part of the eigenvalues of the Jacobian J=F' of the new_state = old_state + epsilon F(old_state, input) incremental type of recurrence, while the real part should be slightly negative. If they were 0 the discrete time updates would still not be stable, so slightly negative (which leads to exponential loss of information) leads to stability while making it possible for the information decay to be pretty slow. They also propose a gated variant which sometimes works better. ","This paper introduces antisymmetric RNN, a novel RNNs architecture that is motivated through ordinary differential equation (ODE) framework. Authors consider a first order ODE and the RNN that results from the discretization of this ODE. They show how the stability criteria with respect to perturbation of  the initial state results in an ODE  in a trainability criteria for the corresponding  RNN. This criteria ensures that there are  no exploding/vanishing gradients. Authors then propose a specific parametrization, relying on antisymmetric matrix to ensure that the stability/trainability criteria is respected. They also propose a gated-variant of their architecture.  Authors evaluate their proposal on pixel-by-pixel MNIST and CIFAR10 where they show they can outperforms an LSTM.",0.18421052631578946,0.17796610169491525,0.1810344827586207
1698,SP:9ca7082f4aa0970c3c35409c9f259e5ad844c553,"This paper presents Spatial Planning Transformers (SPTs); neural network modules that perform spatial planning over grid-like state spaces. The paper also goes on to present the idea that differentiable mapping and differntiable planning modules could be trained end-to-end, for better performance. This is evaluated against two baselines (value iteration networks (VINs) and generative path planning networks (GPPNs)) on small-scale navigation and manipulation tasks.",The paper provides an interesting direction in the field of spatial path planning. The method is interesting as it is fully learnt in an end to end fashion. The key idea is to use a transformer like architecture to model long range dependencies. Also the paper extend its findings to out of distribution maps and  the cases where the ground truth map is not known to the agent. ,0.13432835820895522,0.1323529411764706,0.1333333333333333
1699,SP:9cd250ea2dc64cfc216a6ed964c18fec7b6b4a35,"This work extends the applicability of the spline theory of deep networks explored in previous works of Balestriero/ Baraniuk. The previous works setup DNs as layer-wise max-affine spline operators (MASOs) and recovers several non-linearities practically used as special cases of these MASOs. The previous works already recover RELU variants and some downsampling operators that the current submission characterizes as ""hard"" quantization.","At the core of this paper is the insight from [1] that a neural network layer constructed from a combination of linear, piecewise affine and convex operators can be interpreted as a max-affine spline operator (MASO). MASOs are directly connected to vector quantization (VQ) and K-means clustering, which means that a deep network implicitly constructs a hierarchical clustering of the training data during learning. This paper now substitutes VQ with probabilistic clustering models (GMMs) and extends the MASO interpretation of a wider range of possible operations in deep neural networks (sigmoidal activation functions, etc.).",0.21875,0.14583333333333334,0.17500000000000002
1700,SP:9cd9e1fafaf913e257518c2cf9def669891a0b19,"(Here and below, I will write ""smooth"" in the sense of differentiability, and ""gradient Lipschitz"" for ""smooth-in-the-optimization-sense"")  The authors prove that in the noisy oracle model (so function values and gradients are noisy, not exact), there is no accelerated Riemannian gradient descent algorithm (Nesterov-type acceleration) that succeeds whp uniformly over all manifolds and all geodesically convex functions. To show this, they study the minimization of a particular smooth geodesically convex function on the hyperbolic plane $\mathbb{H}^2$, namely the the intrinsic distance to a fixed point ${x}^{\star}$ (i.e. ${x} \mapsto \mathrm{dist}({x}, {x}^{\star})$), and prove the lower bound with this function; they also establish that this function is not pathological among functions on the hyperbolic plane in the sense that its gradient-Lipschitz constant is of near-minimal size. The proofs use elementary properties of the hyperbolic plane -- gradient and Hessian expressions for the distance, and the fact that ball volumes in the hyperbolic plane are exponential in the radius -- as well as a reduction to a ""noisy query game"" problem on which the lower bound is established. ",The paper presents a lower bound on the complexity of a noisy gradient oracle for minimizing a strongly convex real-valued function defined on the hyperbolic plane. This gives answers regarding the acceleration phenomenon on Riemannian manifolds and limitations of previous works. A lower bound on the condition number of a strongly convex function in the hyperbolic plane is also provided.,0.12234042553191489,0.3770491803278688,0.1847389558232932
1701,SP:9d2476df24b81661dc5ad76b13c8fd5fd1653381,"This paper studies the privacy issue of widely used neural language models in the current literature. The authors consider the privacy implication phenomena of two model snapshots before and after an update. The updating setting considered in this paper is kind of interesting. However, the contribution of the current paper is not strong enough and there are many unclear experimental settings in the current paper.","This paper looks at privacy concerns regarding data for a specific model before and after a single update. It discusses the privacy concerns thoroughly and look at language modeling as a representative task. They find that there are plenty of cases namely when the composition of the sequences involve low frequency words, that a lot of information leak occurs.",0.2,0.22033898305084745,0.2096774193548387
1702,SP:9d274b117553a5c6aa2b7f4cea7e9fec37b2563e,"This paper studies the problem of distributed convex optimization, where each of $N$ machines holds a local function $f_i$, and a coordinator aims to minimize the global objective $\sum_i f_i$ by using a limited amount of communication with local machines. The main contribution of this paper is a $\tilde{\Omega}(Nd)$ bits lower bound on the total communication cost. The lower bound is constructed by considering quadratic local functions and reducing the minimization problem to mean estimation and two-party communication problems. Finally, the authors show that the lower bound can be attained when $f_i$'s are strongly convex and smooth. ","The paper shows lower bounds for distribution optimization. For the standard distributed optimization setting with N machines each of which holds a d-dimensional function f_i and the goal is to minimize \sum_{i=1}^N f_i(x), the paper shows that \Omega(Nd log(d/N\eps)) bits of communication are necessary to obtain an \eps sub-optimal solution. The result holds both for randomized and deterministic algorithms.   The paper also shows a new upper bound derived using a variant of quantized gradient descent. The upper bound nearly matches the lower bound for well-conditioned problems (when the overall problem has a constant condition number).  The lower bounds are shown via interesting applications of standard communication complexity machinery. The upper bound follows via relatively simple modifications to existing quantization techniques.",0.3142857142857143,0.24812030075187969,0.27731092436974786
1703,SP:9d58dff3946cc3ebd5f5272deab9c5ccddd48efc,"The paper proposes a new method for building graph convolutional neural networks. It shows, that during the building of the network, instead of stacking many layers and adding the residual connection between them, one could employ a randomly-wired architecture, that can be a more effective way to increase the capacity of the network and thus it could obtain richer representations. The proposed method is an interesting direction in the field of graph convolutional neural networks. The new method could be seen asa generalization of the residual networks and the jumping knowledge networks.","This paper utilizes Randomly Wired architectures to boost deep GNNs. Theoretical analyses verify that randomly wired architectures behave like path ensemble and it enables adaptive receptive field. Experimental results on three non-popular datasets demonstrate the strength of the proposed model. Overall, the idea is interesting. Yet this paper can be made better through the following aspects:",0.12903225806451613,0.21052631578947367,0.15999999999999998
1704,SP:9d6a017b80845249601f40d6e8c4f98cbbe78f56,"The authors show empirically that Sparse MOEs and Ensembles have complementary features, and suggest that combining the two should lead to improved performance. Authors build on the Vision Transformer (ViT) for their experiments. To efficiently combine Sparse MOEs and Ensembles, the paper presents Partitioned Batch Ensembles (PBE), where the parameters of the self-attention layers are shared, and an ensemble of Sparse MOEs are used for the MLP layers of the Transformer blocks.  ","The paper investigates the benefits of combining (Sparse) Mixture of Experts (MoE) and ensembling. Sparse MoE’s employ conditional computation to reduce computational and environmental costs of DNNs while maintaining (or increasing) performance. On the other hand, ensembling models has been shown to achieve the highest robustness in the presence of dataset shift, e.g., higher accuracy and better estimation of uncertainty.  The present submission empirically demonstrates that Sparse MoE’s can be ensembled to attain the benefits of both techniques simultaneously, i.e., conditional computation (with its implications to scalability) together with robustness in the presence of dataset shift. The main components of the approach are: 1) Disjoint MoE’s as ensemble members. 2) Tiling of representations which enables all ensemble members to compute the output for a batch in a single forward pass.  A number of experiments compare predictive performance vs computational cost for the proposed approach (pBE), vision Sparse MoE’s (V-MoE) and Vision Transformers (ViT). The results show that, under some conditions, pBE displays the known benefits of Sparse MoE’s and ensembling, which leads to performance gains w.r.t. ViT and V-MoE under metrics like accuracy, negative log-likelihood (NLL) and expected calibration error (ECE).",0.2602739726027397,0.09359605911330049,0.13768115942028986
1705,SP:9d8ad0b90a6758f7a724a3298794b5536073142a,"This paper proposes a compression method based on spectral analysis. The basic idea is to analyse correlation between responses of difference layers and select those that are more relevant discarding the others. That, in principle (as mentioned in the paper) differs from other compression methods based on compressing the weights independently of the data being used. Therefore, in theory (nothing shown), different task would provide different outputs while similar works would compress in the same manner. ","The paper proposes to prune convolutional networks by analyzing the observed correlation between the filters of a same layer as expressed by the eigenvalue spectrum of their covariance matrix. The authors propose two strategies to decide of a compression level, one based on an eigenvalue threshold, the other one based on a heuristic based on the KL divergence between the observed eigenvalue distribution and the uniform one. This is a bit bizarre but does not require searching a parameter. Once one has decided the number of filters to keep, one can either retrain the network from scratch, or iteratively remove the most correlated filters, which, unsurprisingly, work better.",0.19736842105263158,0.1388888888888889,0.16304347826086957
1706,SP:9da1f7bd8d52bdd28891ec3e0c7eef7d367a5eea,"The authors proposed a unique learning scheme for representation disentanglement. However, unlike infoGAN or ACGAN which explicitly learn disjoint feature representations for describing the attributes of interest (via unsupervised and supervised settings, respectively), the authors chose to address this task in a questionable ""weakly supervised setting"". More specifically, the authors chose to train AE-like model using pairwise images, which the difference between each pair of the inputs is only associated with one attribute of interest (e.g., angle, position, etc.). ","The paper presents a new, more complex, dataset for the use of disentangled representation learning. The dataset is based on real and simulated images of the trifinger robot platform. There are 7 factors of variation with high-resolution measurements of these factors. The dataset contains over 1 million simulated images and another ~1000 annotated images of a real trifinger robot arm.",0.13580246913580246,0.18032786885245902,0.15492957746478872
1707,SP:9da6cd132a934387f69fe759dbe5b1d2853242c5,The paper deals with where the information is in a deep network and how information is propagated when new data points are observed. The authors measure information in the weights of a DNN as the trade-off between network accuracy and weight complexity. They bring out the relationships between Shannon MI and Fisher Information and the connections to PAC-Bayes bound and invariance. The main result is that models of low information generalize better and are invariance-tolerant. ,"This paper presents a theoretical account of information encoded within deep neural networks subject to information theoretic measures. In contrast to other efforts that examine information encoded in weights, this work emphasizes the effective information in the activations. This characterization is further related to information in the weights, and a theoretical justification is made for what this means with respect to properties of generalization and invariance in the network. ",0.20512820512820512,0.2318840579710145,0.217687074829932
1708,SP:9dbd1488470372dae1baf3d391124e2abac8ea53,This paper proposes to study an interesting problem of how color informaiton is structured in the variational autoencoders (VAEs). Several instances of VAEs are trained in an unsupervised manner to perform color space conversion. Both low-level and high-level evaluations are performed to study the local statistics and global content of converted images. Several interesting conclusions are drawn from the experiments that help interpret the encoding process of autoencoders.,"The motivation for this paper is quite hard to understand. A VQ-VAE is directly applied to convert an image from one colour space to another one. However, the colour space transform is human-defined, usually involving linear and a few non-linear (like selecting the maximum value is HSV) procedures. In this case, the latent space of VQ-VAE should be collapsed into this simple equation easily. The analysis of this paper does not teach us any additional knowledge.",0.17142857142857143,0.15,0.16
1709,SP:9dd4f766fe241af2769fe6b013869c7fc3903fcf,"The authors present a large synthetic dataset for 3D scenes with templated descriptions.  They then use the model of Eslami 2018 to this new domain.  The previous work appears to already introduce all the necessary mechanisms for 3D generalization from multiple viewpoints, though this work embeds language instead of a scene in the process.  Minor note: A bit more discussion on this distinction would be appreciated.  Also, it appears that the previous work includes many of the rendered scenes also present here, so the primary focus of this paper is on the use of a language encoder (not necessarily a trivial extension).","This paper presents a system to map natural language descriptions of scenes containing spatial relations to 3D visualizations of the corresponsing scene. The authors collect a dataset of different scenes containing objects of varying shapes and colors, along with several descriptions from different viewpoints. They train a model based on the Generative Query Network, to generate scenes conditioned on multiple text descriptions as input, along with associated camera angles. Empirical results using human evaluators demonstrate better performance compared to baselines and the authors perform a good analysis of the model, showing that it learns to ground the meaning of spatial words robustly. ",0.17647058823529413,0.17647058823529413,0.17647058823529413
1710,SP:9de6cee2ba08db0f6086702122bb484aa48532f9,"This paper focuses on semi-supervised few-shot learning with multi-modality data. The authors introduce an uncertainty prior of an infinite Gaussian model, integrating multi-modality information from image and text data into a heterogenous variational autoencoder. Meanwhile, a new variational lower bound is derived for the inference of parameters. In addition, a GAN is developed for the data sparsity in few shot learning. Experimental results demonstrate the effectiveness of the proposed method to some extent.","The paper presents a cross-modal semi-supervised few-shot learning approach for image classification. The idea is to train variational auto-encoder (VAE) with both image and text data for learning a feature representation. Then features are extracted from a test sample and assigned to the class of the closest prototype train sample. In addition, a generative adversarial objective is employed for learning the latent code of the VAE. Since the proposed idea is meant for learning from noisy labels, there is an uncertainty prior in the image features as part of the infinite Gaussian mixture distribution. The approach is evaluated on standard few-shot learning benchmarks which are modified to account for the noise labels. The results are promising compared to the prior work. ",0.36363636363636365,0.2222222222222222,0.27586206896551724
1711,SP:9e29ce1a12dcefdf8967043213fe722158e69e7d,"The authors propose to optimize the continuous representation of molecules in a latent space learned by a fragment-based variational autoencoder using an evolutionary algorithm. To improve the quality of the generated molecules over time, they use new generated samples as augmented data to fine-tune the generative model in each iteration. Experiments are conducted to demonstrate the effectiveness of the proposed algorithm compared with Bayesian optimization-based methods.","The paper proposes to tackle multi-objective optimization of molecular properties by combining a genetic algorithm with a fragment-based generative model of SMILES strings. Using a generative model allows to perform evolution in the latent space, as opposed to molecule space. Experiments show the model can produce a rich Pareto front of samples, outperforming bayesian optimization ran in the latent space of the same generative model.",0.2608695652173913,0.26865671641791045,0.2647058823529412
1712,SP:9e36913574414b98fd6c4a66061cf0216dcc536b,This paper is about the task of object detection in the setting of few-shots dataset. The problem is addressed in the learning scheme of meta-learning paradigm: the proposed meta-rcnn trains the popular faster-rcnn on several tasks of few shots object detection while the RPN and the object classification networks are meta-learned among the tasks. Compared to previous work the paper introduces the meta learning framework and several changes to the faster rcnn detector. A prototype representation is derived from the standard RPN network and its proposed bounding box. An attention mechanism choose the object of interest and is used to train the final RPN and classification network. Experiments on the popular Pascal Voc 2007 and ImageNet-FSOD show that the proposed system have state of the art performance.,"The paper proposes a method for few-shot object detection (FSOD), a variant of few-shot learning (FSL) where using a support set of few training images for novel categories (usually 1 or 5) not only the correct category labels are predicted on the query images, but also the object instances from the novel categories are localized and their bounding boxes are predicted. The method proposes a network architecture where the sliding window features that enter the RPN are first attenuated using support classes prototypes discovered using (a different?) RPN and found as matching to the few provided box annotations on the support images. The attenuation is by channel wise multiplication of the feature map and concatenation of the resulting feature maps (one per support class). After the RPN, ROI-pooling is applied on the concatenated feature map that is reduced using 1x1 convolution and original feature map (before attenuation) being added to the result. Following this a two FC layer classifier is fine-tuned on the support data to form the final ",0.22556390977443608,0.17341040462427745,0.19607843137254902
1713,SP:9e712c6f60b19d9309721eea514589755b4ce648,"This paper studies loss landscape of Non-negative matrix factorization (NMF) when the matrix is very large. It shows that with high probability, the landscape is quasi-convex under some conditions. This suggests that the optimization problem would become easier as the size of the matrix becomes very large. Implications on deep networks are also discussed. ","The paper derives results for nonnegative-matrix factorization along the lines of recent results on SGD for DNNs, showing that the loss is star-convex towards randomized planted solutions. The star-convexity property is also shown to hold to some degree on real world datasets. The paper argues that these results explain the good performance that usual gradient descent procedures achieve in practice. The paper also puts forward a conjecture that more parameters make the loss function easier to optimize by making it more likely that star convexity holds, and that a similar conclusion could hold for DNNs.",0.23214285714285715,0.1326530612244898,0.16883116883116886
1714,SP:9e9ae7233f8037f5ae0ef4b641027dd46b997324,"The paper proposes a benchmark for the evaluation of unsupervised learning of object-centric representation. The benchmark consists of three datasets, multi-object tracking metrics and of the evaluation of four methods. The proposed dataset consists of three sets of video sequences, procedurally generated, which are either generated from slight variations of existing works (Sprites-MOT) or on the basis of existing datasets (dSpirites, Video Object Room). For evaluation, authors propose to use a slight variation of the protocol of the MOT challenge for evaluation (with the addition of a Mostly Detected measure which does not penalize ID switches). As part of the  paper, they also evaluate and discuss the performances of four object-centric representation models, one of them (Video MONet) being an extension of an existing approach, proposed as part of this paper, and the remaining being state of the art approaches for the task.","The paper presents an empirical evaluation of a number of recent models for unsupervised object-based video modelling. Five different models are evaluated on three (partially novel) benchmarks, providing a unifying perspective on the relative performance of these models. Several common issues are identified and highlighted using challenge datasets: The reliance on color as a cue for object segmentation, occlusion, object size, and change in object appearance. The paper concludes with several ideas for alleviating these issues.",0.1292517006802721,0.24675324675324675,0.16964285714285715
1715,SP:9eab3cf385659c991a434ef1975118cc72c1dc38,The paper proposes two approximations to the Shapley value used for generating feature scores for interpretability. Both exploit a graph structure over the features by considering only subsets of neighborhoods of features (rather than all subsets). The authors give some approximation guarantees under certain Markovian assumptions on the graph. The paper concludes with experiments on text and images.,"This paper provides new methods for estimating Shapley values for feature importance that include notions of locality and connectedness. The methods proposed here could be very useful for model explainability purposes, specifically in the model-agnostic case.  The results seem promising, and it seems like a reasonable and theoretically sound methodology.  In addition to the theoretical properties of the proposed algorithms, they do show a few quantitative and qualitative improvements over other black-box methods.  They might strengthen their paper with a more thorough quantitative evaluation.",0.1896551724137931,0.12790697674418605,0.1527777777777778
1716,SP:9ed2924f9f5890e7e790b6f16702efdd93319421,"In this paper, the authors study the variance reduced TD (VRTD) algorithm, by Korda and Prashanth (2015)  (KP15), for policy evaluation in RL. They first highlight technical errors in the analysis of KP15, and then provide new convergence analysis for this algorithm. The new analysis is based on a new technique to bound the bias of the VRTD gradient estimator, and shows the advantage of VRTD over vanilla TD (the analyses by Bhandari et al. 2018 and Srikant and Ying 2019), both in terms of variance and bias, that are reduced by increasing the batch size. The authors show that while the variance and bias of vanilla TD are both of O(\alpha) (where \alpha is the step-size), they are of O(\alpha/M) and O(1/\sqrt{M}) (where M is the batch size) in VRTD. This shows that a good convergence is possible for VRTD without reducing the step-size \alpha, that causes slow convergence, by increasing the batch size M. In the middle of their analysis, the authors propose a slight modification of VRTD for the case that the samples are obtained iid from the stationary distribution of the evaluating policy, and provide its analysis. Finally, the authors provide simple experiments to support their theoretical findings.  ","The paper is on temporal difference learning, specifically variance reduction of it. As per the claims of the paper, a previous method from (Korda and La, 2015) had technical errors, which the paper corrects and provides a better analysis of variance reduction. In the end, the paper focuses on the variance of the gradient estimator in temporal difference learning, and on analysis of the bias error. The final method is validated on two experiments with iid and Markovian sampling.",0.12380952380952381,0.3291139240506329,0.17993079584775087
1717,SP:9edba7a5df96fc829c9dcb01715e0f00c5aa2f31,"In this paper, the authors study an interesting problem, i.e., heterogeneous domain transfer such as knowledge transfer between an image domain and a speech/audio domain. In particular, the proposed solution contains two major steps: (i) pre-train each domain via VAE or GAN, and (ii) train a conditional VAE in semi-supervised manner in order to bridge two domains (see Section 2.2). Experiments on three public datasets (including three cross-domain settings) show the effectiveness of the proposed two-step solution.","The authors demonstrate that it is possible to transfer across modalities (e.g., image-to-audio) by first abstracting the data with latent generative models and then learning transformations between latent spaces. We find that a simple variational autoencoder is able to learn a shared latent space to bridge between two generative models in an unsupervised fashion, and even between different types of models (e.g., variational autoencoder and a generative adversarial network). Some detailed comments are listed as follows, ",0.14285714285714285,0.15,0.14634146341463414
1718,SP:9ef06b25ac4a048d02a32376f5ac24e1ea8f546a,"This paper combines gradient-based NAS (DARTS-like algorithm: MileNAS) with Federated Learning (FL) setup, to improve both global and personalization performance with learned neural architecture. Since both NAS and FL learning are based on gradient, the extension to FL setup becomes intuitive and effective. Empirically FedNAS shows improved performance comparing to existing FL methods. ","The authors employ an existing neural architecture search method in the federated learning setting.  Specifically, the authors propose FeNAS and extend an existing NAS method MiLeNAS into federated learning to address the data heterogeneity problem and conduct personalization.  The experiments show that the proposed method is able to achieve improvement compared to some other federated learning methods. ",0.2,0.19298245614035087,0.19642857142857145
1719,SP:9ef265599f0065faadcb80c57cd845c76ef70ecf,"This paper considers the problem of changing environments for LQR. The authors model this through the use of a decoder that maps an incoming context (C,D) to the LQR matrices (A,B). They provide an algorithm for this setting based on a UCB strategy, prove sample complexity and regret bounds, and experimental results.","In order to generalize the RL agent to unseen environment, in this work the authors studied the theoretical learning problem of building a decoder on top of linear continuous control using linear quadratic regulator (LQR). They presented a simple, UCB-based algorithm that refines the estimates of the encoder while doing LQR and balances  the exploration-exploitation trade-off. In the online setting, the proposed algorithm has a O(\sqrt{T}) regret bound, where T is the number of environments the agent played. This also implies after certain exploration, the agent is able to transfer the learned knowledge to obtain a near-optimal policy to an unseen environment. To justify their theoretical bounds the authors also present experiments that demonstrate the effectiveness of the algorithm.",0.25925925925925924,0.112,0.1564245810055866
1720,SP:9f1c2067aa3da35a6ab9946ab3bb143b36213da1,"The paper proposes a method to predict protein functions from Gene Ontology (GO) and protein sequences. The protein sequences are embedded with a pretrained protein language model (SeqVec) and the GO network is modelled with a graph convolutional neural network. The method was benchmarked using CAFA3 competition datasets. Improved model performance was shown against a Naive baseline, DIAMONDScore, DeepGoCNN, and TALE.  ","This paper presents a model to predict Gene Ontology (GO) term annotations for protein function. The model uses an existing method, SeqVec [2], to encode the protein sequence and a GCN on the Gene Ontology (GO) DAGs to encode the structure of term relationships. Like in DeepGOA[1], the graph is weighted by functions of term frequencies. Sequence embedding is reduced via FC layers to dimension d, where d is equal to the DAG depth for the ontology being predicted. The final prediction is a dot product between the GCN encoding and the reduced sequence embedding. The model largely combines these two existing models.  [1] Zhou, Guangjie, et al. ""Predicting functions of maize proteins using graph convolutional network."" BMC bioinformatics 21.16 (2020): 1-16.   [2] Heinzinger, Michael, et al. ""Modeling aspects of the language of life through transfer-learning protein sequences."" BMC bioinformatics 20.1 (2019): 1-17.   [3] Cao, Yue, and Yang Shen. ""TALE: Transformer-based protein function Annotation with joint sequence–Label Embedding."" Bioinformatics 37.18 (2021): 2825-2833.",0.36065573770491804,0.12790697674418605,0.18884120171673818
1721,SP:9f3699227642cf22c764b80be6bb9917fc7bce8a,"This paper proposes a relative self-attention layer for the Transformer model. The relative self-attention of two atoms consists of their relative distance, their shortest path distance in the molecular graph, and their physiochemical. The proposed relative molecule attention Transformer can be first pretrained with a contextual property prediction task and then a graph-level prediction task. The pretrained Transformer can be finetuned on downstream molecular property prediction tasks and achieves excellent performance.","The paper proposes a new transformer network architecture to pre-train the molecule datasets. Based on the Molecule Attention Transformer, the proposed model, R-MAT, incorporates a few handcrafted features into the self-attention layer of a transformer architecture. The features can incorporate distances between atoms from multiple perspectives. The experimental results show that the pre-trained model is useful to predict various properties of molecules.",0.17567567567567569,0.19696969696969696,0.18571428571428572
1722,SP:9f713e213bde5ac69147e961004757cf0b6ae956,"In the same vein as Hewitt & Manning 2019, the authors present an extremely lightly parametrized “probe” model to determine the presence of syntactic structure in the embedding space of BERT models. While Hewitt & Manning examine the Euclidean distance between linearly transformed token embeddings and its correlation with parse tree distance and depth, this work examines a different distance function based on distances in hyperbolic space. They find that this distance measure, for an equivalent or lesser number of parameters, better reproduces the syntactic properties. This suggests that the BERT model may operate simply, but on a non-Euclidean manifold, in order to work with syntactic information.","This paper proposes probes based on hyperbolic embedding spaces, and compares them to the behaviour of Euclidean probes from recent work. The main result is that these probes allow for better recovery of syntactic properties of sentences from contextualized word embeddings compared to context-independent ones, when comparing them to euclidean probes. Similar results are presented  on sentiment analysis, even though no results are presented for context-independent word embeddings.",0.10377358490566038,0.15714285714285714,0.12500000000000003
1723,SP:9f7cb04c86bbb406040abc73f4f940af0c667d64,"The paper contributes to explaining why saliency measures used for pruning trained models may (or may not) also be effective for pruning untrained or minimally trained models, by developing the relationship between those saliency measures and different forms of the norm of model parameters based on the evolution of model parameters via gradient flow (basically derivatives w.r.t. time). This result leads to several interesting interpretations that could shed some light on on-going efforts to understand recent methods of pruning early-on (e.g., pruning at initialization or after minimal training) and potential extensions to existing saliency measures. The idea of employing gradient flow is novel for its purpose and seems to be accurately executed.","This paper proposes a detailed analysis on pruning heuristics, and its applications to early pruning. It thoroughly analyzed magnitude-based pruning, loss-preservation based pruning, and gradient-norm based pruning. The paper demonstrated the results on CIFAR-10 and CIFAR-100 datasets. it's very timely research to guide the audience which heuristic is better. My major concern is the novelty over existing pruning heuristics, since the techniques have all been proposed before. The other concern is the evaluation and the scale of the dataset. Given the results in table 2 different by less than a percent, and Cifar training is very noisy, it's hard to tell the difference. Just like the Lottery Ticket hypothesis works on Cifar but does not work on ImageNet, different pruning heuristics needs to be verified on the large scale ImageNet dataset in order to be convincing. ",0.15384615384615385,0.1258741258741259,0.13846153846153847
1724,SP:9f8b2c2983b0825ed4867509162980586d12cde1,"This paper aims to address a failure mode in the traditional single-step adversarial training known as catastrophic overfitting. They show that compared to the common practice of generating the adversarial perturbation, adopting larger random initialization and avoiding clipping the perturbation can effectively mitigate catastrophic overfitting. The effects of these two techniques are analyzed empirically in detail, followed by a comprehensive comparison to other methods.","This paper methodically studied the catastrophic overfitting in fast adversarial training (Fast-AT), and revisited the role of noise and clipping operation in Fast-AT. Based on the empirical findings, this paper discovered that the absence of clipping as well as using stronger noise could help avoid catastrophic overfitting. The author further proposed Noise-FGSM, utilizing single-step FGSM and noise-augmented samples to generate adversarial examples for training. Empirical studies showed the superiority of N-FGSM both in terms of performance and speed. ",0.23076923076923078,0.17857142857142858,0.20134228187919467
1725,SP:9f8b8c56abc19f30f03426367ab036ba47bc1f27,"This paper proposes a  knowledge distillation (KD) approach for self-supervised learning (SSL) with small neural network models. The authors first observe that the state-of-the-art contrastive learning-based SSL does not obtain good performance on small models, due  to the larger  model capacity required for instance discrimination. To tackle this problem, they propose a SEED, a  KD method where the smaller student model learns to mimic its larger teacher model’s similarity distribution between an instance and its augmented views, using a cross-entropy based objective. The authors perform various experiments to show that -- 1)  SEED obtains substantial improvement in SSL-based imagenet classification performance for small models as compared to SSL training without SEED, 2) the performance gains are also substantial for transfer learning on other classification tasks, 3) the performance gains are smaller for downstream tasks of object detection and instance segmentation, with performance gains reducing for the larger COCO dataset, as compared to VOC, 4) SEED is robust to choice of SSL method, and performs better than other KD approaches.","The paper address the problem of knowledge distillation in self-supervised learning, where the representational knowledge from the larger model (i.e., teacher) is used to guide the learning of a smaller model (i.e, student). To achieve this, an instance queue is used to compute the similarity score between teacher model features and the feature of a given image, and the learning objective is to minimise the cross-entropy loss of the similarity between teacher and student models. The paper provides comprehensive empirical results to justify the efficacy of the proposed approach.",0.1534090909090909,0.2903225806451613,0.20074349442379183
1726,SP:9f8f21efc3a1b9f47e34a3ecb2f5092897217362,"This paper proposes a reinforcement learning algorithm FMDP-BF for episodic Factored MDPs. Similar to previous works, FMDP-BF follows the principle of ""optimism in the face of uncertainty"" to efficiently explore to achieve low regret. Compared to algorithms for general MDPs, FMDP-BF leverages the factorization structure of FMDP and results in exponential regret reduction in the size of the sate space. Compared to previous results for FMDP, the proposed algorithm utilizes Bernstein-type confidence bounds and new bounds on the factored transitions to reduce the regret order. The paper also connects a class of constrained RL to FMDP and  provide a sample efficient for the constrained RL problem.","The authors study the factor MDP problem in an online and episodic setting. They provide two main contributions on this question. First, they propose an OFU type algorithm which enjoys a better regret bound than Osband & Van Roy (2014) by a factor of  $\sqrt{nH \Gamma}$. The improvement is brought about by a refined consideration on the confidence radius' dependence on the variances of the rewards, which carries a similar idea to the design of UCBVI-CH by Azar et al. 2017 for the tabular case.  The second contribution is on the generalization to an episodic FMDP with knapsacks problem, where the authors generalize the approach in the first contribution to provide a regret bound. ",0.17272727272727273,0.16521739130434782,0.16888888888888887
1727,SP:9fa6596a6fa0d1363852455b53f196fbfe956729,"The proposed work focuses on kernel pruning. The core idea revolves around grouping filters using a similarity criterion and removing common convolutional kernels with the group. The proposed work explores optimal grouping schemes for filters and after pruning unwanted filters, the retained filters are restructured and the network can be fine-tuned to recoup prediction accuracy. ","The authors present a new metric to determine the similarity between different grouped kernels and prune the unimportant $k\times k$ slices out of a 3D filter. They utilize the Lottery Ticket Hypothesis and propose a greedy search strategy to overcome the challenge of a huge search space. The experiment results show that the one-shot scheme can still be comparable to two-stage leading methods on the CIFAR-10 dataset, with a slightly lower training cost. The empirical success of this paper may serve as proof of the existence of the Lottery Ticket Hypothesis.",0.21428571428571427,0.12631578947368421,0.15894039735099338
1728,SP:9fad18ae03570219f7b9fd631dc6eccbbb41fa30,"In this paper, the authors propose the usage of complex numbers in deep neural networks. Would be good to know that complex numbers, n x n matrices, quaternions, diagonal matrices, etc. all can be used in neural networks. The authors also claims benchmark performance in large-scale image classification and language modeling.","The authors propose AlgebraNets - a previously explored approach to replace real-valued algebra in deep learning models with other associative algebras that include 2x2 matrices over real and complex numbers. They provide a comprehensive overview of prior methods in this direction and motivate their work with potential for both parameter and computational efficiency, and suggest that the latter is typically overlooked in prior literature. The paper is very well-written and follows a nice narrative, and the claims are mostly backed empirically with experimental results. ",0.23076923076923078,0.1411764705882353,0.17518248175182483
1729,SP:9fb55d0a15ec18451c466359467659dcee7ae3d9,"The paper proposes a Variational IB based approach to learn action representations directly from video of actions being taken. The basic goal of the work is to disentangle the dynamic parts of the scene in the video from the static parts and only capture those dynamic parts in the representation. Further, a key property of these learned representations is that they contain compositional structure of actions so as to their cumulative effects. The outcome of such a method is better efficiency of the subsequent learning methods while requiring lesser amount of action label videos. ",The authors propose a way to learn models that predict what will happen next in scenarios where action-labels are not available in abundance. The agents extend previous work by proposing a compositional latent-variable model. Results are shown on BAIR (robot pushing objects) and simulated reacher datasets. The results indicate that it is possible to learn a bijective mapping between the latent variables inferred from a pair of images and the action executed between the observations of the two images. ,0.1702127659574468,0.19753086419753085,0.18285714285714283
1730,SP:9fbad6b7a8485b00a2b22a46dca0f672f624c501,"The aim of this work is to improve interpretability in time series prediction. To do so, they propose to use a relatively post-hoc procedure which learns a sparse representation informed by gradients of the prediction objective under a trained model. In particular, given a trained next-step classifier, they propose to train a sparse autoencoder with a combined objective of reconstruction and classification performance (while keeping the classifier fixed), so as to expose which features are useful for time series prediction.  Sparsity, and sparse auto-encoders, have been widely used for the end of interpretability. In this sense, the crux of the approach is very well motivated by the literature.","The paper presents a new approach for improving the interpretability of deep learning methods used for time series. The is mainly concerned with classification tasks for time series. First, the classifier is learned in a usual way. Subsequently, a sparse auto-encoder is used that encodes the last layer of the classifier. For training the auto-encoder the classifier is fixed and there is a decoding loss as well as a sparsity loss. The sparse encoding of the last layer is supposed to increase the interpretability of the classification as it indicates which features are important for the classification.",0.1981981981981982,0.2222222222222222,0.20952380952380953
1731,SP:9fdc1a88425fd5d103163f7bbcbafc7ca7fe81be,"This paper studies a very interesting phenomena in machine learning called VSP, that is the output of the model is highly affected via the level of missing values in its input.  The authors demonstrate the existence of such phenomena empirically, analyze the root cause for it theoretically, and propose a simple yet effective normalization method to tackle the problem. Several experiments demonstrate the effectiveness of this method.","This paper provides a novel solution to the variable sparsity problem, where the output of neural networks biased with respect to the number of missing inputs. The authors proposed a sparsity normalization algorithm to process the input vectors to encounter the bias. In experiments, the authors evaluated the proposed sparsity normalization model on multiple datasets: collaborative filtering datasets, electric medical records datasets, single-cell RNA sequence datasets and UCI datasets. Results show that the proposed normalization method improves the prediction performance and the predicted values of the neural network is more uniformly distributed according to the number of missing entries.",0.2835820895522388,0.19,0.2275449101796407
1732,SP:9fe7211c656c5142368a867229540e5653a5edab,"The reviewed paper presents a completely unsupervised framework Meta-K for predicting the number of clusters. The approach advocated in the paper comprises two main parts: autoencoder for feature extraction and multilayer perceptron (MLP) for predicting the number of clusters. Autoencoder is used if necessary to decrease the dimensionality of the input data. The MLP is trained using policy gradient optimization schema to predict the best (according to silhouette score) number of clusters k in the given dataset. Overall, the authors show that their approach achieves near-optimum results on both a number of synthetic datasets as well as on two well-known computer vision datasets: MNIST and FMNIST.","The paper uses policy gradients in a bandit setting to learn the optimal number of clusters, k,  in k-means clustering based on the silhouette score. Finding k that leads to the highest silhouette score is a more specific problem that what the paper title promises. The approach is well-described and supported by experiments on simulated and real-world data.",0.1743119266055046,0.3114754098360656,0.2235294117647059
1733,SP:9feb34bfbe8bfbf1a99d90a74f36b2b0c7dc9985,"Real-world data contains noise in the annotated labels. To mitigate, the authors propose a supervised learning approach, Robust Temporal Ensembling (RTE). RTE combines 1) task loss correction, which is a generalized cross entropy loss, 2) different augmentations resulting from AugMix technique and the Jensen-Shannon divergence (JSD), 3) the ensemble consistency regularization and pseudo labeling.","This submission deals with robust supervised learning in the presence of noisy labels. The label noise is modeled using a probabilistic (and conditionally independent) transition matrix that changes the label of one class to another one. In order to classify with noise, the network is trained with a mixture of three known losses including: 1) generalized cross entropy (GCE) rejects the outlier labels, 2) JSD divergence to assure the soft-max distribution matches the augmented data distributions, and 3) an ensemble consistency regularization (ECR) that penalizes the inconsistencies of the augmented data based on the mean teachers. Experiments with CIFAR-10, CIFAR-100, and ImageNet classification indicate substantial gains compared with state-of-the-art alternatives. ",0.30357142857142855,0.14655172413793102,0.19767441860465115
1734,SP:9ff37d6e42ec5a081da498ccb44513a87af6ab78,"==+== A. Paper summary ==+==   This paper presents EuclidNet, a method to replace multiplication in traditional ConvNet with l2 or Euclid distance. Results show that fine-tuning from a pretrained CNN to a EuclidNet can achieve similar or better results compared to traditional ConvNet and Addernet.","This work proposes EuclidNet, which replaces the multiplication in DNN with squared differences with less logic gates. It is proved to be as expressive as convolution networks and able to be trained in GPUs with at most 2x more time. The experiments are conducted on ResNet@CIFAR-10 and ImageNet.",0.18181818181818182,0.16,0.1702127659574468
1735,SP:a013c72647ecd00dc627a8e501a8c171a870e3e6,"of the paper*: This paper studies the problem of robustness against word substitutions. The authors propose a novel Adversarial Sparse Convex Combination (ASCC) method in which they model the word substitution attack space as a convex hull and leverages a regularization term to enforce perturbation towards an actual substitution. Based on the ASCC, they also propose ASCC-defense, which leverages ASCC to generate worst-case perturbations and incorporates adversarial training towards robustness. Experimental results show that their method outperforms the existing SOTA on two tasks -- sentiment analysis and natural language inference.","In this paper, the authors aim to build a robust model against word substitution attacks. Unlike previous work, they consider a convex hull as the perturbation region instead of a norm-ball or a hyper-rectangle. From their derivation, perturbed words can be viewed as the linear combinations of substitutions and perturbations can be viewed as the corresponding normalized weights. Therefore, they can adversarially train the perturbations and model to obtain a robust model and robust word embeddings. The authors also design a regularizer to encourage the sparsity on perturbation weights. The experimental results show that the proposed model is indeed more robust than other baselines. In addition, they show that the learned word embedding can be a good initialization for training robust models.",0.23076923076923078,0.1693548387096774,0.19534883720930232
1736,SP:a020f6bca5d85f83d595e5b724e32394009dcd7e,"The paper proposes a neural topic model which log-likelihood is regularized by Sinkhorn distance, instead of following Variational AutoEncoder (VAE) approach. The proposed model is hence cannot be interpreted as a probabilistic generative model. Still, with respect to metrics such as Topic Coherence and Topic Diversity which don't require probabilistic interpretation of topic model, the proposed model performs very well across five standard benchmark datasets for topic modeling.",The paper proposes a neural topic model derived from the perspective of optimal transport (OT). Topic embeddings are learned as part of the training process and is used to construct the cost matrix of the transport.  The cost function based on the OT distance is further improved by combining with the cross-entropy loss and by using the Sinkhorn distance to replace the OT distance.,0.2,0.2153846153846154,0.20740740740740743
1737,SP:a02b08206bf5b7026e1c35f23d2810cffa529d1f,"This paper deals with the theoretical study of the gradient dynamics in deep neural networks. More precisely, this paper define a notion of incremental learning for a particular learning dynamics and study how the depth of the network influence it. Then, the authors show two cases where it applies: matrix sensing, quadratic neural networks and provide intuitions on how it could also apply to linear convolutional networks. ","This paper studies the phenomenon of incremental learning in several deep models. It starts with analyzing the optimization dynamics of a toy model, and showing that it follows incremental learning, a notion defined clearly in the paper. In particular, it shows that depth affects the strength of incremental learning in the sense that when the depth of the model is increased (especially when going from N=2 to N=3), the maximal initialization value with which incremental learning can occur is increased. In this sense, deeper models experience incremental learning more easily. The paper then moves on to other “deep linear“ models, including matrix sensing, one-hidden-layer quadratic neural networks and diagonal/convolutional linear neural networks, derives ODEs for the evolution of the singular values in the learned models, which is argued to also lead to incremental learning.",0.373134328358209,0.17985611510791366,0.24271844660194175
1738,SP:a037146bb5c073f2764346596ec1f13c7391d894,"This paper presents an empirical study of the attention mechanism in the graph attention networks (GAT).  The study reveals that the attention patterns largely depend on the dataset, on some datasets they are sharp, but on others the attention patterns are almost uniform and not so different from the uniform aggregation weights in GNNs that does not have attention.  The authors further tried to utilize these findings and attempted to do attention-based graph sparsification, and showed that they can get a similar level of performance with only a fraction of the edges in the original graph if they do the sparsification based on the attention weights.","This paper carries out several kinds of analysis on the GAT networks of Velickovic (2018), which augment GNN updates with multihead self attention. Three standard attention types are compared, on several different datasets, and differences between uniform attention and learned attention are reported. An experiment is carried out where low-attention edges are pruned.",0.1308411214953271,0.25925925925925924,0.1739130434782609
1739,SP:a0537bc2883ff413f0ffafc44a53a65be9fc7738,"This paper investigates the effectiveness of model cascades in computation/accuracy tradeoff improvement.  A straightforward procedure is used, where all combination-permutations of a handful of models are evaluated in a cascade, and exit thresholds are determined by choosing best computation work within accuracy degradation constraint (or, best accuracy given computation constraint).  The resulting cascades perform significantly better than larger single models (more accurate or fewer flops depending on comparison).  Most significantly, the paper provides extensive evaluations on the degree of these gains for three model families (EfficientNet, Resnet, and MobileNetV2). ","The work provides an empirical accuracy-efficiency comparison of model ensembles and cascades of shallow models against single deeper models. The main finding, which supports previous results, is rather interesting: compositions of shallow models tend to provide better efficiency-accuracy trade-off than single deep models. This finding has been extended here to the ImageNet classification task with three architecture families (ResNet, EfficientNet and MobileNet), with further examples on video recognition and semantic segmentation.",0.17582417582417584,0.21621621621621623,0.19393939393939394
1740,SP:a078647f423f16068679fd5621f3600f1d96f7bf,"The paper approaches the CMDP problem, in which one wishes to learn a max return policy subject to trajectory-based constraints.  The paper proposes a technique based on the introduced concept of ""backward value functions"".  These functions satisfy a sort of Bellman equation.  The paper proposes a safe policy improvement step based on these value functions, with theoretical guarantees on the safety of the resulting policy.  The method is evaluated on gridworlds and mujoco tasks, showing good performance.","This paper presents a new approach for solving Constrained MDPs. Because the cost constraint is cumulative, the best action depends on the cumulative cost so far. They address this issue by learning a backward value function of the estimated cumulative cost so far. Their theoretical results show that the same properties for forward value functions hold here for backwards ones. They are then able to use the forward and backward cost estimates to constraint the actions selection, by adding a safety layer to the algorithm. The results show that the method does a better job of meeting safety constraints than the Lyapunov based method.",0.20512820512820512,0.15384615384615385,0.17582417582417584
1741,SP:a08c91391aee4c0a73b034f1e56c2852f0babd14,"This paper studies the problem of recourse actions (a.k.a. counterfactual explanations) while considering data distribution shifts or model shifts. The proposed Distributionally Robust Recourse Action (DiRRAc) framework has the ability to generate valid recourse actions when model parameters shift over time. DiRRAc adopts the distributionally robust optimization technique and the paper proposes a projected gradient descent method to solve the optimization problem. Experiments are conducted with both synthetic and real world data, and the results have shown that DiRRAc methods can generate recourse actions with higher validity than two existing methods.","The paper provides a framework for recourse (i.e. counterfactual explanations) that is robust to shifts in the model. They formulate the robustified recourse setup as a min-max optimization problem, where the max is over a neighborhood around the distribution over model parameters. The model parameters are drawn from a mixture of K distributions, so that the neighborhood is specified by Gelbrich distance on each component.   They propose a finite-dimensional version of the robustified optimization problem, which can be optimized using projected gradient descent. They evaluate their approach on the German credit dataset, the Small Business Administration dataset, and the Student performance dataset, each of which demonstrates a different type of data distribution shift. ",0.21505376344086022,0.1724137931034483,0.19138755980861244
1742,SP:a08f4c4a6f2f44502d681ff98e9eeaf83259257b,"The paper analyzes the generalization ability of SGD for pairwise learning problems. The authors prove better generalization error bounds incorporating some variance term or the optimal error. They also provide a new SGD with O(n) computation per trial whose generalization bound is state-of-the-art. Furthermore, they show results for strongly convex losses and non-convex losses.  ","The paper seeks to develop new generalization and excess risk bounds for pairwise learning using SGD. The goal is to achieve error rates with near-optimal dependence in the number of gradient evaluations. To this end, stability properties of SGD are analysed and used to obtain the generalization/excess risk bounds. ",0.1864406779661017,0.21568627450980393,0.2
1743,SP:a0ba8e10e93f74cf923317f94b7dcd7f880d04c3,This paper extends GraphSAGE in several dimensions: 1) applying attention when aggregating neighbors (already used by GAT and many other approached); 2) Ensembling node embedding by applying DualENC multiple times on positive pairs selected by random walk (this is doing aggregation of neighborhood again); and 3) adding global bias. All this makes the proposed method an incremental extension of existing solutions.  There is no theoretical justification why these extensions should work.,"This paper proposed a dual graph representation method to learn the representation of nodes in a graph. In particular, it learns the embedding of paired nodes simultaneously for multiple times, and use the mean values as the final representation. The experimental result demonstrates some improvement over existing methods. Overall, the idea is presented clearly and the writing is well structured. But the novelty is limited. Specifically, ",0.14084507042253522,0.15151515151515152,0.14598540145985403
1744,SP:a0cbc9dde2539645b847f40af560afe953f001ee,This paper focuses on the problem of multi-agent reinforcement learning (MARL) for CTDE scenario which is well studied in recent literature.  The work discusses shortcomings of actor-critic methods for MARL and proposes a solution using linearly factored critic. The paper is somewhat difficult to read and can be made better by deferring the details about previous methods to appendix. However my main concern is with the problem of centralized-decentralized mismatch (CDM) motivated in the paper and its proposed solution itself. ,"In the context centralized training distributed execution in cooperative multi-agent reinforcement learning (MARL), the paper proposes an architecture to learn a decomposed action value function expressed as a weighted sum of the agent's individual functions (plus an additional weight). Those weights are themselves learned and depend on the observed history. Thanks to this decomposition, gradients can be decomposed over each agent. The authors propose to use a combination of off-policy (using tree backup) and on-policy (using TD(\lambda) methods for estimating the decomposed critic. They formulate both a deterministic and stochastic decomposed policy gradients, which are analyzed theoretically to some extent and evaluated experimentally.",0.21686746987951808,0.16666666666666666,0.18848167539267016
1745,SP:a0d07d2ab41a2c13a2be8f2fb99548828d6ae991,"This paper proposes a new approach for active learning by interactively discovering weak supervision. Instead of asking human to annotate data points, the method collects feedback about candidate label functions, from which a model learns to identify promising label functions. With the final set of label functions, they train a classifier with the estimated labels on unlabeled data. They conduct experiments on text classification datasets with both oracle and human feedback, and show a large improvement compared with traditional active learning.","This paper proposes a new framework for interactively selecting labeling heuristics in a weakly supervised setting. The main idea of the proposed approach is to combine weak supervision and active learning. Compared to the previous work which relies on human manually create labeling functions (the abstraction of the weak supervision), this work defines a family of labeling function and uses an active learning method to interactively identify a set of labeling functions that maximizes the utility based on the usefulness by the users. The experiment results showed that the proposed approach outperforms other baseline methods.",0.24691358024691357,0.21052631578947367,0.22727272727272727
1746,SP:a0ef19c6a049abf1f8ca56c4ac0fe4a7b01976ac,The authors present a novel deep learning representation for jointly modelling longitudinal measurements and dynamic time-to-event analysis where there are competing risks for a given event. The authors incorporate patient-level historical data using an RNN which allows updating of individual-level (i.e. personalized) risk predictions as additional data points are collected. This method (Dynamic-DeepHit) makes no assumptions about the underlying stochastic processes. The authors further evaluate the clinical utility of these methods in terms of interpretability of variable importance and dynamic risk predictions.,"The authors propose Dynamic-DeepHit, a survival analysis framework for modeling longitudinal data with multiple competing risks. As opposed to previous works, Dynamic-DeepHit can model survival events (e.g. death, cancer relapse) which can be driven by multiple, potentially competing, underlying risks. The proposed model uses an RNN shared across multiple risks for processing past-to-recent measurements, and multiple feedforward nets that accept the most recent measurements and the hidden layer of shared RNN. Joint predictions (across time and competing risks) are made using a softmax layer. The model is tested on two datasets where Dynamic-DeepHit outperforms other baselines.",0.18181818181818182,0.1568627450980392,0.16842105263157894
1747,SP:a0f0c22c89062e6b5170705a54cb38cbf7b041c9,"This paper wants to establish tight theoretical lower-bounds on the minimum width required by a ReLU neural network to approximate ""almost all"" functions up to epsilon where the distance of approximation is defined using the Lp-norm. The paper improves the previously known bounds which lied in the range of d+1 and d+4 to exactly d+1. One of the results of this paper is to establish that this bound is exactly d+1 (I am summarizing the result while ignoring some precision/nuances). This result holds only when the distance is measured using the p-norm where p is finite. In the infinity norm setting, they show that this minimum width actually is indeed not a universal approximator. However, to ensure that the claimed minimum width also holds in the infinity-norm setting, they modify the activation functions to also allow for the threshold functions which is 1 if larger than 0 and 0 otherwise.","The paper studies the minimal neural network width needed for universal approximation. While previous papers on the subject merely provided lower and upper bounds, this paper derives exact bounds on the minimal width. The paper considers both ReLU networks, as well as general activation functions, and examines approximation under both uniform norm and $L_p$ norm. In the case of functions with high-dimensional outputs, the derived bounds are better than previously thought ($d_x + d_y + 1$ to $\max(d_x + 1, d_y)$), with possible implications to practical  network design.",0.12578616352201258,0.21739130434782608,0.1593625498007968
1748,SP:a0fa3a2620b05676185a997067aa3e514cd56a35,"The paper studies the exposure bias in auto-regressive neural language models. This problem is known to cause incremental performance degradation, and attempts to mitigate this problem have received significant attention in the community (using, e.g., RL and GANs). The paper claims that prior work has mostly focused on addressing the problem rather than measuring how severe the exposure bias problem actually is. Despite extensive previous work on mitigating exposure bias, the paper suggests that the exposure bias is not “large enough [to] induce drastic performance loss during generation” (e.g., a human evaluation controlling for exposure bias show relative differences of only < 3%).","This paper makes a key observation: “exposure bias” is blamed for many of the issues with Neural Language Generation but it lacks both a concrete definition or any obvious evidence that it truly exists. The authors begin by defining exposure bias as the decrease in quality and relevancy (to the conditioning text) in generations as the model conditions on its own output. A limited qualitative study fails to find evidence of exposure bias, and the authors propose two metrics, EB-M and EB-C, to measure the quality and relevancy degradation, respectively. Quantitative results find that degradation on these two axes as the model conditions on itself are either minor or non-existent. To calibrate our understanding of these metrics, the authors do a human study as well as comparing two GAN frameworks. In the discussion the authors discuss limitations of the work, mostly that the given metrics are not a complete notion of evaluation and connect their work to related literature.",0.2,0.12962962962962962,0.15730337078651685
1749,SP:a1131568815adfe8079cb12991b6a6efbe238586,"The paper proposes a new graph neural network based on a continuous time flow. Each node is given a pre-processed position from an off-line node embedding method, then both the position and a vector of node features (together called Z) are changed during the flow. The flow changes Z by the average difference of Z of adjacent nodes, weighted by a scaled dot product attention. Additionally, a node-wise initial encoder and final decoder is used. The flow is computed via explicit adaptive or fixed integration and the backward pass via the adjoint method. The authors propose various extensions, including having dynamic adjacency via kNN and using hyperbolic positional space. The authors claim their method is motivated as a discrete analogue of a Beltrami flow.","I have read the authors' responses, comments from the other reviewers, and the discussion here. The authors have answered my questions satisfactorily. Hence, I am increasing my score to 7.   This paper derives a new class of GNN using ideas from differential geometry. It proposes discretization of the PDE associated with the Beltrami flow for the design of the GNN. Although the explicit discrete approximation of the Beltrami flow on a graph has many interesting similarities to existing attention mechanisms, this framework can be more general with the use of sophisticated differential equation solvers, as presented by the authors. The paper also brings out interesting connections between their model and existing GNN architectures, which in itself, is a nice contribution of this work.  ",0.1732283464566929,0.17886178861788618,0.17600000000000002
1750,SP:a11a05bf95d8dcd7adb929912430615c73f4b531,"This paper performs an empirical evaluation of generalization by TD methods with neural nets as function approximators. To quantify generalization, the paper considers the change in the loss function at similar states to the one where the update rule is being applied (where “similar” is usually defined as nearby in time). It comes to a variety of conclusions including that TD(0) does not induce much generalization, that TD(0) does not induce as much generalization as supervised learning, and that the choice of optimizer and objective changes the behavior according to their generalization criteria in various ways.","The manuscript is analyzing the ""generalization"" in TD(lambda) methods. It includes supervised learning from trajectories, on-policy imitation learning, and basic RL setting. Moreover, memoization performance has also been measured. Main conclusion is the fact that TD(0) performs very similar to tabular learning failing to transfer inductive biases between states. There are also additional surprising results about optimization.",0.09183673469387756,0.15,0.11392405063291139
1751,SP:a11b3a9eb5377bf4777c87f5212e2ee9fe310cfe,"This paper considers the problem of limited budget Bayesian optimization when the cost of each experiment is unknown and must be estimated by running the experiment. This is an interesting problem introduced in the BO community recently. This paper improves upon previous approaches by treating the problem as a constrained MDP. At each step, the method performs a look-ahead and chooses the next point that maximizes a N-step reward within a budget constraint. The experiments show improved performance over the baselines.","This work proposes a global optimization method for black-box functions, where an evaluation budget is restricted and an evaluation cost is also unknown. By applying a lookahead strategy, the authors introduce a new acquisition function, a budgeted multi-step expected improvement (B-MS-EI). It is based on a popular acquisition function, expected improvement, and it solves an optimization problem under the setting of heterogeneous and unknown evaluation costs in a non-myopic manner. Finally, the authors demonstrate that the proposed method outperforms the baseline, EI-PUC in various experimental circumstances.",0.1927710843373494,0.17391304347826086,0.18285714285714286
1752,SP:a1269282da0327aa083fa21ef352a5451667f925,"The paper proposes combining the MixUp data augmentation method with teacher-student distillation to improve the fine-tuned performance of BERT on benchmark NLP tasks (GLUE). The problem is important, well-motivated and of interest to a broad base of NLP researchers and practitioners. The paper is clear, and generally well-written, although the idea itself is not surprisingly novel (somewhat of a low-hanging fruit), from the experimental results, the method improves upon baselines, and so the real-world impact could be high, especially given its simple implementation.","This paper applies mixup (Zhang et al., 2018) to augment training data to improve knowledge distillation in NLP tasks . Mixup was originally proposed to augment data for continuous data. To apply mixup to textual data, this paper applies mixup to the word/token embeddings instead of the tokens themselves. Some theoretical analysis has been done, and the experimental results show improved metrics over baseline methods such as DistillBERT.",0.15730337078651685,0.20588235294117646,0.17834394904458598
1753,SP:a13b7c970bfcd4b06913233730bc5a7e1552dd4c,"The paper considers online optimization with zero-order oracle. Motivated by nonstationarity of the objective function, impracticality is underlined for the two-point feedback approach. Instead, staying in the one-point setting, the proposed approach reuses the objective value from the previous round of observations, which is called as residual feedback. The variance of the corresponding proxy for the subgradient is estimated under more relaxed assumptions than existing in the literature. The proposed approach leads to smaller variance and better regret bounds. Regret bounds are proved for smooth/non-smooth convex/non-convex cases, the non-convex case being analyzed for the first time in the literature. Numerical experiments show that the practical performance of the proposed gradient estimator is better than that of the existing one-point feedback methods and is close to the performance of the one-point approach with two observations per round. The latter approach can be impractical for some applications.   ","This manuscript considers online zeroth order optimization and it develops a gradient estimator based on one query per function. In particular, the proposed method mimics two-point estimators by evaluating two consecutive functions at perturbations of an iterate, as shown in equation (3). Although one-point gradient estimates are possible, they have impractically large variances. Given this limitation and the wide need of zeroth order optimization (in particular in RL), the study of two-point estimators is important. ",0.11612903225806452,0.23076923076923078,0.15450643776824033
1754,SP:a14d3997b4df7d1d7e4627989bd040004f2935f6,"This work proposes a probabilistic data imputation model for multivariate time series. The proposed method uses a conditional diffusion model to estimate the (masked) conditional distribution of missing data given observed values. To utilise information from observed values, the authors employ a neural attention mechanism to capture spatiotemporal dependencies of time series. The authors use self-supervised learning for training the model.  In experiments, the author demonstrate competitive performance of their method against a number of comparable methodologies on time series imputation and forecasting tasks. ",This paper focuses on the problem of the probabilistic imputation of missing data in time series. This work proposes a novel approach for probabilistic imputation based on the score-based diffusion models. Experiments on time series imputation tasks show that the proposed method achieves better performance than the current SOTA methods in this space.  ,0.18823529411764706,0.2962962962962963,0.2302158273381295
1755,SP:a17218a21d8f69f2848a248c8658df81c8a68924,"The work applies and adjusts contrastive learning in the subject area of pre-training language models. The work first identifies the challenges with the current landscape of Masked Language Models with limits to learning sentence-level representations and semantic alignments in sentences of different languages. To take care of these gaps, the authors propose using HCTL as an approach that can learn more universal representations for sentences across different languages. The work builds on top of the BERT models, with the adjusted contrastive learning objective goal.","The paper proposes a pre-trained language model variant which extends XLM-R (multilingual masked model) with two new objectives. The main difference to most other models is that the new losses are contrastive losses (however, as pointed out by the authors, other contrastive losses had been used before in e.g. ELECTRA). The first additional loss is a sentence-level one - where a [CLS] token is trained to be close to the positive sample, the paired sentence, with other sentences as negative samples. The same is done at word level, where the bag of words constructed from two sentences becomes the set of positive samples and other vocabulary words are negative samples. ",0.1744186046511628,0.13274336283185842,0.15075376884422112
1756,SP:a17ac22a13579b5d19c4a6dcea8530c9caead79e,"The paper tackles the issue of explaining periodic behavior that can occur when jointly training neural networks using batch normalization and weight decay, and that causes training to alternate between phases of instability and stability. The authors give a theoretically reasonable explanation of why this phenomenon occurs. They derive the notion of delta-jumps in parameter space that are responsible for training instabilities, and derive theoretical bounds based on parameter norm, effective gradient norm, and learning rate. They investigate this mechanism empirically by training scale-free CNNs on the CIFAR-10 and CIFAR-100 dataset classification task, and also extend their analysis to more practical scenarios, showing that the periodic behavior can still be produced in less artificial settings.","In this paper, the authors look at scale-invariant networks trained with SGD using both batch normalization and weight decay. They study the contradiction between the equilibrium presumption and the instability presumption and claim that the training process converges to a consistent periodic behavior which includes some instabilities during training but does not lead to failure. They define the notion of delta-jumps for the dynamics of training and conjecture that the delta jumps are necessary for destabilization of the dynamics. Extensive empirical experiments are provided for supporting the claims. ",0.21008403361344538,0.2777777777777778,0.23923444976076552
1757,SP:a1893fe10c2060687e3c5061db3fb4adc055a8b3,"This paper empirically explores heuristics commonly used in deep learning: learning rate restarts, warmup and distillation. The authors utilize two recently proposed tools for neural network analysis: mode connectivity (MC) finding a low loss pathway between two given points in the space of DNN parameters and CCA measuring the correlation of  DNN layer activations. Conducting a set of experiments and analyzing the results the authors refine the intuition behind the considered heuristics and dynamics of corresponding training procedures. ","In this paper, authors propose a set of  control experiments in order to get a better understanding of different deep learning heuristics: stochastic gradient with restart (SGDR),  warmup and distillation. Authors leverage the recently proposed mode connectivity (which fits a simple piecewise linear curve to obtain a low loss path that connect two points in parameter space) and CCA is a way to compute a meaningful correlation of the networks activations. All the experiments are done using a VGG-16 networks on CIFAR10.",0.3333333333333333,0.3132530120481928,0.3229813664596273
1758,SP:a199489c162c1b433e63d5aeee3d69ada321d32a,"This paper studies the inductive bias of neural nets by considering the toy example of learning an identity map through a single data point (and hence the NNs are always overparametrized). The authors compare CNNs versus FCNs, and find that CNNs tend to “generalize” in terms of actually learning the concept of an identity, whereas FCNs are prone to memorization. The authors also present results under various different settings such as changing the filter size or the number of hidden channels of CNNs. The conclusion is that the simpler the network architecture is, the better it generalizes. Another observation is that deep CNNs exhibit extreme memorization.","This paper studies the inductive bias in deep neural networks. The authors train several FF image recognition networks and many CNN variants on a single image, and observe that most networks fall into one of two categories: either memorizing the output of the single training sample, or learning the identity function and generalizing to new, unseen images. The paper is clearly written, present a broad set of experiments, and provides interesting insights, that are somewhat surprising.",0.19811320754716982,0.27631578947368424,0.23076923076923078
1759,SP:a1c64c4684a1e422bad35d2c4bbd3fc74388fd7e,The paper describes a sampling distribution construction over examples from which to draw mini-batches to train multi-classification models. A distance function on examples is described wherein an example's current (softmax) label probabilities and correctness are taken into account. The bounded distance function supports quantization of example distances and then subsequent sampling from an exponentially decaying probability mass function defined over the binned examples. Results from experiments implementing the proposed method and some baselines on three image classification datasets are provided.,"The paper introduces an adaptive importance sampling strategy, as opposed to uniform sampling, for batch normalization. The key idea is to assign higher importance to those correctly classified training samples with relatively smaller soft-max prediction variance, hopefully to push the deep nets to learn faster from uncertain samples near the decision boundary. Experimental results on several benchmark datasets (MNIST, CIFAR-10) and commonly used deep nets (LeNet, ResNet) are reported to show the power of boundary batch selection in improving the overall training efficiency.",0.14457831325301204,0.1411764705882353,0.14285714285714285
1760,SP:a1cb44f75e6ce83ead86c295ca0a1c51e3a4f456,"The paper combines optimal control and reinforcement learning (RL) for the execution of robotic manipulation tasks with variable goals. The approach learns, on the one hand, an image-based predictive model using a deep neural network and, on the other hand, a distance cost function using Q-Learning. These model and cost function are used to define the next action to execute using model predictive control (MPC). The cost function is learned from task-agnostic data by randomly generating goal states from the state space and including these goals as input variables in a Q-learning approach. This permits defining cost functions for MPC for variable goals. ",This paper proposes to learn functional distances to varying goals concurrently with a latent dynamics model from images. A network is trained to predict the Q-value of state action pairs for a sparse reward at the goal. This way the Q-function represents the shortest path distance to the goal. The paper also proposes a specific learning scheme for training the model from random rollouts in the environment. The learned distance function is used with the dynamics model for planning from start to goal images using model-predictive control (CEM). The approach is evaluated on simulated reaching and object pushing tasks. It is compared with state-of-the-art methods and demonstrates improved performance in some of the tasks.,0.21495327102803738,0.19166666666666668,0.2026431718061674
1761,SP:a1d1e8d13b1df53435caa45e5fed856fcdd1b6ec,"This paper proposes modifications and modular extensions to the differential neural computer (DNC). The approach is nicely modular, decoupling the data modules from algorithmic modules. This enables the authors to pretrain the data modules with supervised learning and to train the small algorithmic modules with neural evolution strategies (NES). NES is a global optimization method (which may be understood as policy gradients where the parameters of the neural policy are the actions) and consequently this enables the authors to use discrete selection mechanisms instead of the soft attention mechanisms of DNC.","This paper introduces a neural controller architecture for learning abstract algorithmic solutions to search and planning problems. By combining abstract and domain-specific components, the model is able to mimic two classical algorithms quite closely across several domains. The precision of the learning is very high; verified by generalization to substantially larger problem sizes and different domains. One notable conclusion is that Evolutionary Strategies is able to learn algorithmic solutions whose precision is on par with deterministic algorithms. The method of triggering learning based on curriculum level performance is a notable feature that nicely couples generalization progress with learning, and yields insightful learning curves.",0.16483516483516483,0.14423076923076922,0.15384615384615383
1762,SP:a21ff4f555b2f2acd797a3222242fbf70867b78e,"This paper presents an algorithm to find adversarial attacks to binary neural networks.  Binary neural networks uses sign functions as nonlinearities, making the network essentially discrete.  Previous attempts at finding adversarial attacks for binary neural networks either rely on relaxation which cannot find very good adversarial examples, or calling a mixed integer linear programming (MILP) solver which doesn’t scale.  This paper proposes to decompose the problem and iteratively find desired representations layer by layer from the top to the input.  This so called Integer Propagation (IProp) algorithm is more efficient than solving the full MILP as it solves much smaller MILP problems, one for each layer, thus each step can be solved relatively quickly.  The authors then proposed a few more improvements to the IProp algorithm, including ways to do local adjustments to the solutions, and warming starting from an existing solution.  Experiments on binary neural nets trained for MNIST and Fashion MNIST show the superiority of the proposed method over MILP and relaxation based algorithms.","The authors study the problem of generating strong adversarial attacks on binarized neural networks (networks whose weights are binary valued and have a sign function nonlinearity).  Since these networks are not continuous (due to the sign function nonlinearity), it is possible that standard gradient-based attack algorithms are not effective at producing adversarial examples. While this problem can be encoded as a mixed integer linear program, off-the-shelf MILP solvers are not scalable to larger/deeper networks. Thus, the authors propose a new target propagation style algorithm that attempts to infer desired activations at each layer (from the perspective of maximizing the adversary's objective) starting at the final layer and moving towards the input. The propagation at each layer requires solving another MILP (albeit a much smaller one). Further, in order to prevent the target propagation from discovering assignments at upper layers that are unachievable given the constraints at lower layers, the authors propose two heuristics (making small moves and penalizing deviations from the previous target values) to obtain an effective attack algorithm. The authors validate their approach experimentally on MNIST/Fashion MNIST image classifiers.",0.23353293413173654,0.20855614973262032,0.22033898305084745
1763,SP:a27b9b91520ec4d7e1cabce40411ff8a10dea9c8,"This work uses the idea of variational inference to map categorical data to continuous space affording the use of normalizing flows. Authors use several ideas to increase their framework's applicability--factorized distribution assumption, use of multi-scale architecture for step-generation, and permutation invariant components—achieving favorable results on several problems. The approach seems to be especially useful when data is non-sequential.","The paper considers the problem of modeling discrete distributions with normalizing flows. Authors propose a novel framework “Categorical Normalizing Flows”, i.e CNF. By jointly modeling a mapping to continuous latent space, and the likelihood of flows CNF solves some of the bottlenecks in current algorithms. With experiments on some synthetic domains, and benchmarking tasks like Zinc250, the authors empirically demonstrate that CNF-based algorithms perform competitively and often improve significantly on related approaches like Latent NF, discrete flows.",0.1875,0.1518987341772152,0.1678321678321678
1764,SP:a27d66876fcdc3f3871485445e09041a8927b147,"the paper aims to explain the success of BYOL, a recently proposed contrastive method that mysteriously avoids the trivial constant solution without requiring negative samples. The paper proposes a new loss named RAFT. Compared to BYOL, RAFT is more general since it subsumes a variation of BYOL as its special case, and contains a cross-model term to be maximized which regularizes the alignment loss and encourages the online encoder to ""run away"" from the mean teacher.","The paper provides a new perspective on the BYOL self-supervised learning method. First, the paper introduces an upper-bound objective, BYOL', that is easier to analyze than BYOL because it is composed of two well understood losses: an alignment loss and cross-model loss. Further, it shows empirically that optimizing BYOL' is similar to optimizing BYOL. Second, the paper introduces the RAFT method which maximizes the alignment loss instead of minimizing it. The paper proves that under some assumptions, such as a linear predictor function, optimizing BYOL' is equivalent to RAFT. Based on this analysis, the paper explains why the predictor function is essential for BYOL and why it is hard to achieve convergence.",0.2857142857142857,0.19130434782608696,0.22916666666666666
1765,SP:a289020322570c222c7bfdd2c6da0bd2cac95381,"This paper proposed a convolutional tensor-train (CTT) format based high-order and convolutional LSTM approach for long-term video prediction. This paper is well-motivated. Video data usually have high dimensional input, and the proposed method aims to explicitly take into account more than one hidden representation of previous frames - both lead to a huge number of parameters. Therefore, some sort of parameter reduction is needed. This paper considers two different types of operations - convolution and tensor-train (TT) decomposition - in an interleaved way. The basic model considered in this paper is a high-order variant of convolutional LSTM (convLSTM).",This paper proposes a method that saves memory and computation in the task of video prediction by low-rank tensor representations via tensor decomposition. The method is able to outperform standard convolutional lstm and other methods by using less parameters when testing it in the Moving MNIST and KTH datasets. The authors also present a proof to validate their method.,0.12871287128712872,0.21666666666666667,0.16149068322981366
1766,SP:a2a80f52b722eafc6b8d751ecfeb8f85dacfe0b8,The paper proposes a cross-lingual data augmentation method to improve the language inference and question answering tasks. The core idea is to replace a port of the input text (such as one of the sentence in a sentence pair in the language inference tasks) with its translation in another language. The authors empirically show that deploying the XLDA data augment improves the baseline methods for both the XNLI language inference data sets and the SQuAD task. ,"The paper provides an analysis of a cross-lingual data augmentation technique dubbed XLDA, which consists of replacing parts of an input text with its translation in another language. Building on the mBERT approach, the authors show that at fine-tuning time it is beneficial to augment the training set of XNLI with cross-lingual hypotheses and premises instead of in-language pairs. For each language in XNLI, they show results by augmenting with each of the 14 other languages in the dataset, and show significant improvements over per-language performance.",0.3246753246753247,0.27472527472527475,0.2976190476190476
1767,SP:a2ee061eda974bd5c2c854e1c65e157e8d95c6cb,"The authors argue that we should evaluate the robustness of NLP models near their decision boundaries, and argue that contrast sets and counterfactual examples cannot fullfill this purpose. The authors propose to find examples near the decision boundary using the largest eigenvalue of the Fisher information matrix, arguing that this value gives us a sense of how stable the model prediction is near the input. To verify that FIM can identify examples where the prediction is unstable, and perturbation leads to larger prediction change, the authors use some heuristic adversarial attacks: first identify tokens to replace using integrated gradients, then replace the tokens with synonyms (to confirm the prediction is sensitive) or antonyms (to confirm that the prediction is insensitive).","This paper proposes an analysis technique for studying the 'difficulty' of a pair of test dataset examples in NLP. The setup proposed by past work on Contrast sets and Counterfactual Examples (Gardner et al, 2020 and Kaushik et al 2020 respectively) is to manually construct two dataset examples (x,y) with different labels y, while the inputs x differ only minimally. This paper argues to compute the measure of a contrast / counterfactual example pair by extracting the largest Eigenvalue of a matrix (defined in part using the Fisher Information Matrix).",0.15833333333333333,0.2111111111111111,0.18095238095238092
1768,SP:a324d745f08a17a7b48caa2246a51f222107f31c,"The authors detail PUGAN, architectural changes to models for raw waveform generation with GANs. They do a good job of motivating the challenge of raw audio generation with GANs and of methods for progressive training. PUGAN incorporates U-Net modules in the generator (""Bandwidth expansion""), sinc convolution as bandlimiting inputs to the generators, and the ""style gan"" type method of adding the noise at each level of the generator. Using listener studies and inception score, they show modest improvements over the state of the art (at time of submission), WaveGAN. Notably, their architecture is also more computation and parameter efficient. ","The paper presents an approach based on generative adversarial models for the unconditional  generation of audio. The authors take inspiration from WaveGAN, to which they add more sophisticated upsampling blocks (called the bandwidth extension module) instead of transposed convolutions. They also propose to add a sinc convolution layer to the discriminators to improve training. Finally, they propose a progressive training scheme similar in spirit to the progressive training of GANs in images. Experiments are performed on generating audio pronunciation of digits, and the authors compare their work in terms of inception score, human evaluation and computation cost to WaveGAN.",0.19,0.1919191919191919,0.19095477386934676
1769,SP:a3911fe147060f3b790ea85cfaf18034add4368c,"This paper extends Jin et al. (2018)'s idea to infinite horizon and improves the best known sample complexity to $\tilde{O}(\frac{SA}{\epsilon^2 (1-\gamma)^7})$. The derivation is similar to Jin's paper except a very careful selection on the pseudo-horizon length $H$, where $H$ is given in finite horizon and work as the decaying rate for $\alpha_k$, but for infinite horizon when we need to decide how to pick $H$.","In this paper, the authors extend the UCB Q-learning algorithm by Jin et al. (2018) to infinite horizon discounted MDPs, and prove a PAC bound of \tilde{O}(SA/\epsilon^2 (1-\gamma)^7) for the resulting algorithm. This bound improves the one for delayed Q-learning by Strehl et al. (2006) and matches the lower-bound in terms of \epsilon, S, and A. ",0.2857142857142857,0.3384615384615385,0.3098591549295775
1770,SP:a396624adb04f88f4ba9d10a7968be1926b5d226,"This work proposes to use a combination of graph neural networks (GNNs) and proximal policy optimization (PPO) to train policies for generalized device placement in dataflow graphs. Essentially, (1) a GNN is used to learn representations of a dataflow graph (in an inductive manner), (2) a transformer is used to output a device placement action for each node in the graph, and (3) the entire system is trained end-to-end via PPO. Extensive experimental results show very impressive results compared to strong baselines.","In this paper the authors propose an end-to-end policy for graph placement and partitioning of computational graphs produced ""under-the-hood"" by platforms like Tensorflow. As the sizes of the neural networks increase, using distributed deep learning is becoming more and more necessary. Primitives like the one suggested by the authors are very important in many ways, including improving the ability of the NN to process more data, reduce energy consumption etc. The authors compared to prior work propose a method that can take as input more than one data flow graphs, and learns a policy for graph partitioning/placement of the operations in a set of machines that minimizes the makespan. This problem in principle is NP-hard as it entails both graph partitioning and graph scheduling as its components. The authors propose a heuristic that composes of two existing methods: graph neural networks are used to produce an embedding of the computation/data flow graph, and then a seq-2-seq placement network. The method is able to generalize to unseen instances.",0.27380952380952384,0.13068181818181818,0.1769230769230769
1771,SP:a39d669cce510debfadda370c1cb47d2eb960795,"This paper proposes a method for domain adaptation in RL where the source and target domains differ only in the transition distriubtions. A theoretical derivation based on RL as probabilistic inference is presented that starts with the objective of matching the desired distribution of trajectories in the target domain with the distribution achieved by the policy in the source domain. The final objective appears as a modification to the reward function while training in the source domain and is implemented easily with just two binary classifiers that predict the domain given either state-action or state-action-next-state tuples. Theorem 4.1 provides a theoretical guarantee on the performance of a policy trained on such a modified reward in the source domain by giving a bound on the performance in the target domain, under a very mild assumption that the optimal policy on the target domain achieves similar rewards when put in the source domain. Experiments are presented that show improved performance in terms of rewards vs experience on target domain on environments such as broken reacher, broken ant, etc (where the target domain has some ""broken"" component). Further, it is also shown that the reward modification on source visually matches the reward expected in target (Fig 4), that without the reward modification the policy usually exploits the source domain's transitions which cannot be exploited in the target domain, and finally, that safety emerges from the proposed objective.","The paper introduces DARC, a domain transfer algorithm motivated by maximum entropy RL. By introducing classifiers for the target and source domain, the reward function in the source domain can be modified such that it restricts the behavior of the optimized policy to transitions that reflect the target domain. In this way, the method achieves good domain transfer without having an explicit model.",0.1125,0.42857142857142855,0.1782178217821782
1772,SP:a3a46e67002f078845d83f3575b704160c30cffb,"This paper proposes the mean square error loss with whitening operation to project positive pairs closely to each others while projecting the different positive pairs far away from each other on a unit sphere. This way, similar to BYOL, this paper removes the construction of negative pairs while improving the MoCo-V2 slightly on not very challenging benchmarks. The authors can find my questions/comments in the list below.","The paper proposes to first do representation ""whitening"", so that the representations are scattered in the space and not collapsing to a single data point; then compute distance metric on top of that (e.g. Euclidean, cosine similarity). A nice thing about explicit scattering is that it does not require large numbers of negative examples to pull the features apart. Experiments are done on several toy datasets like CIFAR.",0.14492753623188406,0.14492753623188406,0.14492753623188406
1773,SP:a3b0ba1ccfe3c51dce09178aec1c4a4711129252,"This article study stochastic processes through the lens of kernel methods. The authors propose to use a generalization of kernel mean embeddings to define metrics between stochastic processes. In particular, they used these metrics to define a filtration-sensitive kernel two-sample test. Moreover, they showed how to use this new class of kernels in some learning tasks. ","This paper aims to construct a family of kernel mean embeddings that capture filtration information from stochastic processes. This is achieved through the use of the signature kernel, a characteristic kernel defined on pairs of paths that can be evaluated by solving a hyperbolic PDE, and by forming conditional kernel mean embeddings of the stochastic process conditioned on its own filtration up to some time in the past.  The resulting conditional kernel mean operator itself is a stochastic process, and thus this construction can be repeated to produce higher ordered conditional kernel mean embeddings of the original stochastic process. The corresponding MMD defined from the conditional kernel mean embeddings at each order can then be used to measure distances between two stochastic processes at each order.  The first major contribution shows that higher ordered MMDs are stronger discrepancy measures than lower ordered MMDs (Theorem 2 and 4). They can then be used to perform a kernel two-sample test between paths from two stochastic processes. In particular, the paper focuses on using the second order MMD and derive consistent estimators for it (Theorem 3).  The second major contribution applies these constructions for distribution regression on stochastic processes, where the input is a collection of sample paths and the output is a vector of scalars. This is done by embedding the sampled paths from the stochastic process into a kernel mean embedding through the signature kernel, then learning the mapping between this kernel mean embedding to the vector of scalar outputs. The authors pay strong attention to the application in financial markets where the functions of interest are often discontinuous with respect to the first order mean embedding, and show they can still be learned by proving that the RKHS induced in higher orders is dense in the space of functions of interest (Theorem 5).",0.5,0.09539473684210527,0.16022099447513813
1774,SP:a3b341958a07b30cebf8d58c821174faea8bafe4,"In this paper, the authors study statistical models based on the Kronecker-factored lattice (KFL) and investigated the condition that the monotonicity holds. The KFL provides efficient and flexible modeling for monotonic shape constraints. Furthermore, the ensemble of KFL is proposed, and its approximation ability is theoretically investigated. Some numerical experiments indicate that the KFL trains faster with fewer parameters with comparable prediction accuracy to existing methods. ","The paper proposes to use Kronecker factorization on a lattice for a monotonic lattice. Thanks to the factorization, the computational cost is improved to linear compared to exponential. The paper went on to extend to use an ensemble of KFLs due to each factorized lattice is too restricted. Compared with the baseline, monotonic KFL achieves good accuracy with much faster run times on the experiments.",0.1791044776119403,0.18461538461538463,0.18181818181818182
1775,SP:a3f8fc0a93ecd80f88cf808e8cd228588010b1b0,The authors propose using evolutionary computation (EC) to perform meta learning over the set of symbolic expressions for loss functions. It's a compelling idea that is well-motivated. They find that applying their EC method to mnist yields an interesting loss function that they name the 'Baikal loss.' Much of the paper is devoted to analyzing the properties and performance of the Baikal loss. ,"This paper proposes a very interesting idea of loss function optimization. At first sight, loss function is the goal of optimization and can not be optimized directly. However, the true goal of optimization is the final accuracy (for classification). So lots of loss functions can be designed and combined to form a large search space. In this paper, the authors adopt genetic programming to design loss functions hierarchically.  And experiments show that GLO (Genetic Loss-function Optimization) based loss function can achieve better results than cross entropy. ",0.18461538461538463,0.13793103448275862,0.15789473684210525
1776,SP:a3ff92cb6c426866827cb9d277e9720f2ab06e81,"This paper proposed a novel approach for learning disentangled representation from supervised data (x as the input image, y as different attributes), by learning an encoder E and a decoder D so that (1) D(E(x)) reconstructs the image, (2) E(D(x)) reconstruct the latent vector, in particular for the vectors that are constructed by mingling different portion of the latent vectors extracted from two training samples, (3) the Jacobian matrix matches and (4) the predicted latent vector matches with the provided attributes. In addition, the work also proposes to progressively add latent nodes to the network for training. The claim is that using this framework, one avoid GAN-style training (e.g., Fader network) which could be unstable and hard to tune. ","The paper proposes a method to tackle the disentanglement-reconstruction tradeoff problem in many disentangling approaches. This is achieved by first training the teacher autoencoder (unsupervised or supervised) that learns to disentangle the factors of variation at the cost of poor reconstruction, and then distills these learned representations into a student model with extra latent dimensions, where these extra latents can be used to improve the reconstructions of the student autoencoder compared to the teacher autoencoder. The distillation of the learned representation is encouraged via a novel Jacobian loss term that encourages the change in reconstructions of the teacher and student to be similar when the latent representation changes. There is one experiment for progressive unsupervised disentangling (disentangling factor by factor) on MNIST data, and one experiment for semi-supervised disentangling on CelebA-HQ.",0.168,0.15671641791044777,0.16216216216216217
1777,SP:a43b09142b12e0b68e3e658a9011068615c46481,"The authors try to tackle the problem of tool synthesis by using a classifier to guide the learning and exploitation of a generative model through activation maximization. Experiments are conducted on the proposed simulated reaching dataset on tool selection and tool imagination.  While the idea of synthesizing tools step by step continuously is interesting, the technical and experimental design make the problem over-simplified and thus raise some concerns. ","This paper presents a method with two goals: (1) estimate if a given tool can solve a given task, and (2) generate a tool that can solve a given task. One encoder maps a tool image and silhouette into a latent code, and a decoder maps this code into a mesh; another encoder maps a task image into a latent code; this code is concatenated with the tool code, then mapped to a task success probability. The networks are trained together, so that task success probability has some impact on the tool encoder's latent space. Results show that the model is largely successful in both tasks, but no challenging baselines are here. ",0.14492753623188406,0.08849557522123894,0.10989010989010989
1778,SP:a46f45942c037790b1e06fd37d0a63ce10701437,"This paper introduces a referential game in which a speaker “sees” an image and sends a discrete message of variable length to a listener. The message is designed to represent important patches in the input image. In addition to the speaker’s message, the listener is given a batch of images, one of which is an augmented view of the speaker’s input. The listener’s goal is to find this augmented view of the input image among all images in the batch. The speaker and listener are trained with self-supervision using InfoNCE loss. The learned communication protocol is evaluated on the underlying task as well as used as a pre-training step for the downstream task of classification.","The current work proposes to study a signaling game between two agents that uses image patches instead of the entire image. Within this framework, experiments show that the agents select important patches from the image and the emergent language captures semantic information about the patches. Further, the resultant agents are used as self-supervised image classifiers and compared against existing patch-based/self-supervisory methods to show superior performance.",0.125,0.21739130434782608,0.15873015873015875
1779,SP:a492824ed04e34de0d1a54373e4cc15348c14a45,This work analyzes the accuracy-privacy trade-off in ensemble learning by performing model inference attacks. The key finding of the paper is that the presence of an ensemble (that averages the predictions of individual learners) exacerbates the disparity between the confidence distribution of samples that were seen during training v/s those that weren't. They highlight how the main reason for this observation is the reduced agreement between base models for data points that were not seen during training. There is some evaluation of prior membership inference defenses in the ensemble setting.,This paper provide a systemantic analysis on the accuracy-privacy trade off for deep ensmebles. They show that the effectiveness of membership inference attacks is likely to increase when ensembling improves accuracy. The authors further study  the impact of various factors such as prediction confidence and agreement between models that constitute the ensemble.,0.20212765957446807,0.3584905660377358,0.2585034013605442
1780,SP:a49ea86558697b8b1b861f7847a8c1e34d53b9c9,"The paper studies the problem of designing approximately revenue-optimal auctions using corrupted / inaccurate priors, where inaccuracy is measured by the Kolmogorov-Smirnov distance, i.e., the maximum difference in the two CDFs.  The authors consider the multi-bidder single-item setting, and focus on the cases of regular and MHR prior distributions.  Notably, they do not assume bounded support.  The main results are almost matching (multiplicative) upper and lower bounds on the maximum revenue achievable given inaccurate priors with bounded KS distances to the real ones.  The authors further apply their results to sample-based settings, and derive similar upper bounds with polynomial number of samples from the inaccurate priors.","This paper studies the problem of learning revenue-optimal single-item auction using bidder valuation samples with adversarial corruptions.   The paper first studies the case when there’s a given distribution. When the true distribution is alpha-close to the given distribution in Kolmogorov-Smirnov distance, the paper shows an algorithm to to get at least 1-O(alpha) of the optimal revenue for regular distributions and at least 1-O(sqrt(alpha)) of the optimal revenue for MHR distributions. The paper also provides negative results to show the algorithms are tight.  The paper also gives an algorithm of approximating optimal auction when only samples from the given distribution are provided. ",0.25225225225225223,0.25225225225225223,0.25225225225225223
1781,SP:a49f7236b067ec4d09f71a2d9d5ed87421ac8351,"This paper introduces a new policy optimization method based on coordinate ascent. As the paper notes early on, the core of the proposed method is based on two central insights. The first is that coordinate ascent is a suitable approach for policy optimization as it decomposes the large search space (the policy space) into ""a sequence of sub-problems with smaller search spaces"". The second notes that the objective is in fact stochastic: The return can be thought of as a random variable distributed according to the mixture of a possibly stochastic control policy and the possibly stochastic transition dynamics of the environment. In contrast, prior black box approaches to optimization have tended to ignore this stochasticity in favor of optimizing for the expected return (the value). To account for this, the paper proposes a one-sided hypothesis test that can inform whether to update the policy based on the significance of a given rollout. Experiments are conducted on a continuous variant of the LunarLander-v2 domain and MuJoCo, contrasting estimates of the average return achieved by policies vs. iterations for the proposed method (HDCA), an evolutionary approach (ES), and Augmented Random Search (ARS). Results support the improvement of the approach over ES and ARS on this domain.","The paper proposes a derivative-free optimization algorithm which is applicable to stochastic black-box functions. (The target application area is reinforcement learning, but the algorithm is more broadly applicable.) The core elements of the algorithm are 1. Block coordinate ascent: Only a few parameters are optimized at each step, while the others are held fixed. The maximization is performed by random search over the parameters being optimized, so the function evaluations can be performed in parallel. 2. Hypothesis testing: Because of the high variability of Monte Carlo policy evaluation, a one-sided two-sample hypothesis test is performed to determine whether or not the candidate policy is in fact better than the current policy, and the policy is only updated if this is the case.  The proposed algorithm, hypothesis-driven coordinate ascent (HDCA), is compared to previous derivative-free optimizers proposed in the RL literature, where it is shown to require fewer iterations to converge on most tasks.",0.18269230769230768,0.2389937106918239,0.20708446866485014
1782,SP:a4a3e87e0ac3d6f419668800566cae74ece5edf0,"This paper performs an empirical comparison of models and CL methods in a generative setting. The main motivation of the paper is to make statements about which model/method combinations are best to use for generative tasks in the CL setting. In short, the paper provides an empirical analysis and evaluation of the combination of CL methods and generative models.","This paper evaluates and compares various methods for learning GANs in a Continual Learning setting, i.e., only some of the classes are available during training. It evaluates different continual learning methods including rehearsal, EWC and generative replay applied to training several deep generative models, like GAN, CGAN, WGAN, WGAN-GP, VAE and CVAE on MNIST, Fashion MNIST and CIFAR. The authors conclude with these experimental results that generative replay is the most effective method for such a setting, and found it is difficult to generate CIFAR10 images that can be classified successfully by an image classifier.",0.25,0.15463917525773196,0.1910828025477707
1783,SP:a4a47d63cd3c5c0b5c4f7e735f3a4f84528f5d5d,"This paper presents a novel SE(3)-invariant GNN model for predicting 3D geometry-dependent physicochemical properties of molecules. In particular, this method focuses on an important issue of how to handle the chirality of molecules in molecular GNNs. When a molecule takes a 3D shape, we have a degree of freedom to rotate every C-C single bond. To distinguish enantiomers (mirror-image molecule pairs), we also need to see whether two molecule pairs are superposable by these single-bond rotation operations. The developed method proposed a torsion-angle encoder having 1) an invariance to rotations about internal molecular bonds and 2) the ability to learn molecular chirality. Several empirical results are also reported. ","The paper focuses on improving the capacity of GNN models, using chirality identification as the case study. As an important character to represent the geometry in molecules, chirality has a fundamental impact on the molecule properties and downstream applications. It is a major extension of [1]. The distinguishing features are mainly based on the sinusoid transformations of torsion angles, which are invariant to the bond rotations.",0.14782608695652175,0.25757575757575757,0.1878453038674033
1784,SP:a4a5f09b1902bcee453422de9948593f3180af29,"The authors propose KAGAN, a novel method for knowledge graph (KG) alignments using GANs. In contrast to most other methods, KAGAN does not rely on a supervised setting where a set of already aligned triples is used as seed. In addition, the authors propose modifications such that their method can also integrate information about aligned triples.","The authors propose an unsupervised knowledge graph alignment framework, KAGAN, using adversarial training. Specifically, they utilize a triple discriminator to discriminate the aligned source triples and target triples, and a reward function to minimize the divergence between source triples and target triples. Also, they propose to leverage the lower bound of the mean KL divergence (mutual information) to resolve the mode collapse problem. The proposed method can be incorporated with a supervised method to be a weakly-supervised approach. Even though there are a family of unsupervised approaches for domain alignment, this paper is the first to solve the knowledge graph alignment problem in an unsupervised/weakly supervised way.",0.23214285714285715,0.11926605504587157,0.15757575757575756
1785,SP:a4b0890cdeb53d7ea32798703955b14baeb60715,"The paper focuses on alleviating the problem of ""catastrophic forgetting"", exhibited by neural networks learned with gradient-based algorithms over long sequence of tasks. In such learning scenarios, tuning of parameters over the new tasks lead to degradation of performance over the old tasks as the parameters important for the latter are overwritten. The gradient-based algorithms are unable to distinguish between the important and  the not-so-important parameters of the old tasks. Hence, one direction of works, including the proposed one, aim at identifying the most important parameters for all the old tasks and discourage modifications on those parameters during the training of the new tasks. ","This paper proposes a method for tackling catastrophic forgetting. Similar to previous methods such as EWC (Kirkpatrick et al., 2017), they penalize parameter updates that align with the Fisher information matrix of the previous tasks. This will prevent the model from changing the previously useful parameters. They try to match the result of previous fisher-based methods but at a lower computational cost. They propose using a low-rank approximation to the Hessian using Hessian-vector-product with two types of vectors: the momentum velocity vector and the largest eigen-vector of the hessian. Then they build a diagonal approximation to the Hessian.",0.18518518518518517,0.1941747572815534,0.1895734597156398
1786,SP:a4c83d83ac05511ae113d499f7e6e3beacbbfa68,"This paper presents an approach that learns a 'self-interpretable' model, which produces explanations that are invariant to certain user defined transformations. The attribution maps of traditionally trained models change when certain transformations (like rotation etc) are applied to the input, which could be seen as a disadvantage of these methods. Here the paper counteracts this by learning models that are self-interpreting (via higher level prototypes) and whose attribution maps are invariant to user-defined attributions.","The paper proposes SITE Self-Interpretable model with Transformation Equivariant Interpretation.  Features are first extracted by feature extraction network such as CNN/Resnet F(x) such that F(x)=z SITE uses generative model G that maps z to c prototypes each corresponds to a specific class. y_hat = softmax(G(z)^T x) where y_hat_i = softmax(w_i^Tz) so  w_i is the interpretation of the i-th prediction. The paper then proposes to to regularize the prototypes for an input image x, they enforce each generated prototype to be similar to its corresponding class’s latent representation. They also propose to regularize on the transformation equivariance property of interpretation produced by the model.  The paper also proposed self-consistency score to compare different interpretation methods. For an input x and transformation T and interpretation I(x) the self-consistency score is defined as the cosine similarity between the transformation of the interpretation to x and the interpretation of the transformed images cosine similarity(T(I(x)),I(T(x)) . Higher indicates a more robust interpretation.  The paper compared SITE interpretation with post hoc interpretability methods and the accuracy maintained by SITE with that of inherently interpretable architecture that exhibit a decrease in accuracy due to their interpretable nature. Comparison was done on MNIST and CIFAR10.",0.24675324675324675,0.08636363636363636,0.12794612794612795
1787,SP:a4f1727f7c84e23cf683786fc4e3be3f066c76d9,"The paper proposes a few modifications to the existing archiectures for perceptual image similarity that would be robust to the tiny shifts in the image. Specifically, the authors conduct an experiemnt that shows that humans mostly are not sensetive to small shifts of 1 or 2 pixels (Table 1), but most state of the art perceptual image similarity networks are sensetive to such shifts (Table 1 and Table 2). The authors discuss what parts of the network architecture might yield such sensetivity and offer a few modifications (Section 5). In Section 6, the authors perform extensive experiments to check the effectiveness of their suggestions. Finally the authors conclude that using anti-aliasing strided convolutions and pooling operators and reducing stride size are helpful to make a learned similarity metric shift-invariant. Their experiments show that by integrating these elements into a neural network, the learned metric is more robust against imperceptible shifts and more consistent with the human visual similarity judgment  (Table 1,2,3) . ","The authors propose to make perceptual similarity metrics (PSM) invariant to small-shifts (few pixels translation) and still consistent with human judgement. To this end, they use an approach based on network architectures to evaluate which elements (anti-aliasing, pooling, striding, padding, skip connection) can achieve shift-invariance.  The paper have multiple contributions: 1. A study on the human perception of small shift estimating their sensitivity 2. A study of the sensitivity of PSMs to small shift 3. A systematic study of neural network architecture elements in relation to shift-invariance 4. A updated/shift-invariant version of the LPIPS metric 5. An ablation study to evaluate which elements contribute or to shift-invariance ",0.1393939393939394,0.20175438596491227,0.16487455197132617
1788,SP:a50321f93f2b397c6edcc8e8b80d7ca4f06453b3,"This paper studies critical points of loss landscape of deep neural networks. The authors prove that all critical points of a narrow fully-connected network can be embedded to critical points of a wider network. Moreover, the degree of degeneracy of critical points of narrow networks increases under the described embedding. The critical embedding principle provides a new explanation of the existence of high-dimensional manifolds of critical points in the loss landscape of wide fully connected networks.  The embedding of a weight vector of a narrow DNN into the weight space of a wider DNN is defined as a composition of simple one-step embedding steps: at each step one neuron of a network is split into two with a specifically chosen assignment of input/output weights to both old and new neurons. The input weights for both new neurons are copied from the original neuron and output weights are re-parameterized via linear interpolation. The authors show that this one-step embedding preserves the output function of the network, criticality of a weight vector in the loss landscape, and increases the degree of degeneracy of the critical point.  The authors support the theoretical results with experiments on simple learning tasks (1D regression, classification on Iris and MNIST dataset). The experiments confirm the theoretical results: the embedding procedure preserves criticality and increases degeneracy.  ","The paper discusses the question of organization of loss surfaces of neural networks, in particular the connection between wider and narrower networks with respect to the critical points. The proposed analysis introduces an embedding that projects a narrower network into a wider network (at least by one neuron in at least one hidden layer) without changing its function (output) and also saving all its critical points. It is shown, that the introduced procedure of the mapping narrower networks into wider increases degeneracy of the critical points, i.e., increasing amount of zero valued eigenvalues.",0.14285714285714285,0.3404255319148936,0.2012578616352201
1789,SP:a511e63f6161aa1771206e48f944c02e811a51a3,"The paper introduces a new open-source simulation benchmark for soft robotics. The simulation environment builds on top of DiffTaichi, an existing differentiable simulator which enables end-to-end differentiability. The paper proposes 10 different tasks, each with 5 variations and evaluates both RL-based policy learning methods and gradient-based optimization methods on those tasks. The results suggests neither current RL-based methods nor gradient-based method can solve most of the tasks efficiently, especially for those require long-term planning.","In this work, the authors present PlasticineLab, a new framework for soft-body manipulation tasks for Reinforcement Learning and planning algorithms. The environment consists of a novel soft (i.e., deformable, plastic) material termed Plasticine which is complex to model and manipulate because of the inherently complex high-dimensional governing equations and the large number of degrees of freedom associated with soft materials. The PlasticineLab framework proposes 10 novel tasks involving manipulation of the soft plasticine material. The authors show thorough empirical analysis that traditional state of the art model-free reinforcement learning algorithms fail to effectively learn the task even after a substantial amount of training. Thus effectively showcasing the complexity of the proposed tasks and the inability of state of the art RL models to model the proposed tasks.",0.24390243902439024,0.15267175572519084,0.1877934272300469
1790,SP:a527aca3ea9653acb0d0a07eada4483414fd82e3,"The paper proposes learning a branching heuristic to be used inside a branch-and-bound algorithm used for solving integer programming problems corresponding to neural network verification. The heuristic is parameterized as a neural network and trained to imitate an existing heuristic called Strong Branching which is computationally expensive but produces smaller branch-and-bound trees than other heuristics. A graph neural network architecture is used to take the neural network being verified as input, and a message passing schedule that follows a forward pass and a backward pass along the network being verified is used. An online learning variant is also considered that fine tunes the learned heuristic at test time as a problem instance is being solved. Results for verifying large convolutional neural networks on CIFAR-10 show approximately 2x improvement in average running time of the branch-and-bound algorithm.","This paper deals with complete formal verification of Neural Network, based on the Branch and Bound framework. The authors focus on branching strategies, which have been shown to be a critical design decision in order to obtain good performance. The tactic employed here is to learn a Graph Neural Network (which allows to transfer the heuristic from small networks to large networks), using supervised training to imitate strong branching. The authors also discuss fallback mechanism to prevent bad failures case, as well as an online fine-tuning strategy that provide better performance.",0.13986013986013987,0.21739130434782608,0.1702127659574468
1791,SP:a5347c01c781befd65ffc3899fc313627891fd65,"The paper proposes a network architecture for MLP networks. The authors build upon work by Chen et al. (2019) to achieve whitening by batchnorm followed by dropout (IC Layer). Further they use skip-connections (He et al., 2016) in their architecture. The authors tested their approach in an ablation study for gender and age classification. With dropout included in their architecture, they computed the entropy values, which showed high values for some baby or kid faces, that were infrequent in the dataset.","This paper proposes a general architecture for MLPs. The main ingredients are skip connections and whitening. These methods have been proven to be effective in CNNs. The authors show that MLPs do benefit from them as well. The proposed skip connection (SO,SI - skip-out, skip-in) is added before the last ReLu (R) of each block. The whitening (BND) is implemented by a batch normalization (BN) layer followed by a dropout (D) layer before the fully-connected layer (FC). The proposed block is then: SO-BND-FC-R-BND-FC-SI-R-BND-FCS-R. While FC has the same number of input as output, FCS halves its number of output. The experimental section shows the performance of such MLPs, ablating skips and whitenings. Two datasets of faces are used (IMDB-Wiki and Adience) with 3 classification task of age and gender recognition.  ",0.1951219512195122,0.1111111111111111,0.1415929203539823
1792,SP:a5afbc98268d9495590e593abed021add38e5c1c,This paper proposes a new deep neural network (DNN) architecture to generate molecular 3D conformation. It derives its architecture starting from gradient-based updates for minimization of the molecule's energy function. Then the architecture becomes a repetition of vertex-wise aggregation layer of SE(3)-equivariant Transformer-based DNN. The architecture takes a molecule and 3D conformation pre-calculated from RDkit as input. The authors show how the proposed architecture generalize existing DNN architectures for molecular conformation generation. Empirical results demonstrate superiority of the proposed method. ,"This paper proposes a new method to generate molecular conformations (i.e., the spatial arrangements of atoms belonging to a given molecule). The method works by updating initial atom positions (which can be initialized either randomly or using an alternative conformer generation method) through an iterative process. Each iteration involves predicting the gradients associated with atoms' positions and then changing their coordinates by taking a step in this direction (Eqn. 1 & Fig. 1b).   The authors: 1. show how the parameterization of the gradients relates to how one models the conformational energy (Section 3.3); 2. demonstrate competitive performance on optimization (finding a single best conformer; Section 4.1) and generation (finding a set of relatively stable conformers; Section 4.2) tasks compared to previous benchmarks. This is judged in terms of (a) how well the generated conformers match up to ground truth conformers (e.g., Table 1) as well as (b) how well the generated conformers enable the prediction of molecular properties (Table 2). ",0.2413793103448276,0.12804878048780488,0.16733067729083664
1793,SP:a5b02af3879a1add513f148bc12934e814258b09,"The authors propose two new techniques that extract interpretable directions from latent spaces of pretrained GAN generators. Both techniques are very efficient and are shown to work with the state-of-the-art BigGAN models. Furthermore, the authors describe additional details of the method, like determining the transformation end-points, which are important for usage in the practical visual editing.","This paper studies transformations in GAN latent space that map to meaningful transformations in the generated data. The main contribution is to derive closed form methods for discovering latent transformations that correspond to 1) geometric changes and 2) changes that capture principle components of model variation. The paper also contributes new methods for nonlinear latent transformations, disentangled transformations, and an application to attribute transfer.",0.11666666666666667,0.109375,0.11290322580645161
1794,SP:a5b2b3f420b135829267204092e681f2b10d04fe,"This paper aims to model the complicated continuous time-series by using SDE for modeling the latent state trajectories. The authors claim that using SDE instead of ODE for the latent states has higher flexibility to capture more complex dynamics. Then they propose a continuous-time versions of variational evidence lower bounds (ELBO) which can be trained using ODE-RNNs as the inference networks. The proposed VSDN model has the capability to capture the latent state stochasticity not via the initial states but rather via SDEs, as opposed to other methods like latent ODE and latent SDE. ","This paper introduces a latent variable model for high dimensional stochastic time-series. The model is akin to a VAE with RNNs that incorporate time-series data. The authors introduce two variants of the model, one which only contains a feedforward RNN (filtering) and another that contains feedforward and feedback RNNs (smoothing).  The authors use two inference procedures for the model, one the standard VAE, and the other importance weighted IWAE.  The work is reasonably clearly presented and the experiments are multiple data sets are a nice addition.",0.20618556701030927,0.22727272727272727,0.21621621621621623
1795,SP:a5d36eaad88f8dad2eacddcbd03b070a46855605,This paper proposes a way to replace the main convolution layers in the HRNet with self-attention layers. A feedforward network with 3x3 depth-wise convolution is also proposed to replace the MLP in transformer. The proposed High-Resolution Transformer achieves performance improvements for dense prediction tasks such as pose estimation and semantic segmentation while saving memory and computation.,"In this paper, the authors proposed a new model framework (HRT) using transformers for dense prediction in computer vision tasks.  Comparing to conventional patch-based vision transformers for dense prediction (such as segmentation and human pose estimation), HRT has three key components: 1) pixel-based local-windowed multiheaded attention with reduced compute overhead; 2) Depth-wise convolution (inside FFN modules) to aggregate info across local-windowed attention 3) Multi-resolution framework to enhance the representation quality for dense predictions (instead of using deconv after patch-based  VIT transformer encoders).  Empirically on image classification, human pose estimation and segmentation tasks, the authors shows that HRT can attain higher accuracy at similar or lower param count / FLOPs than 1) conv / deconv baselines and 2) conventional patch-based ViT encoder + deconv baselines.",0.3050847457627119,0.13953488372093023,0.19148936170212766
1796,SP:a5e28d7de6baafd260cd39c1812059854ac452c0,"This paper introduces a novel exploitation of the centralized training for decentralized execution regime for Dec-POMDPs with publicly/commonly known actions.  In particular, the paper augments independent value-based reinforcement learning by allowing each agent to announce the action it would have taken, had it acted greedily. This relaxation is consistent with decentralized execution, at which time agents always act greedily and no counterfactual announcement is required. The paper demonstrates the utility of this trick in Hanabi, where it achieves strong performance when combined with distributed Q-learning and an auxiliary task. The paper is largely well-written.","The paper examines the problem of epsilon-greedy exploration in cooperative multi-agent reinforcement learning. Such exploration makes actions less informative to other agents because of the noise added to greedy optimal actions. The suggested solution is to consider two actions: one action is epsilon-greedy and it is passed to the environment, while another is fully greedy according to the agent’s strategy, and it is shown to another agents. At test time these two actions are the same. This idea is applied to Hanabi game; the self-play regime is examined. The suggested method is claimed to show state-of-art results in 2-5 players Hanabi. ",0.1919191919191919,0.1743119266055046,0.1826923076923077
1797,SP:a5e2f9ef73b07032e1e287bb62eb0f289d8ad7a9,"- In this paper, the authors propose a novel algorithm for pruning fully-trained ReLU neural networks. To motivate the algorithm, the authors first introduce a new network architecture with an affine skip-connection at each layer. Then the authors connect it to the theory developed in an `unpublished work`. They show that for such neural networks, the number of units in the original layer can be greatly reduced. The main idea of the proposed algorithm is basically to prune those neurons whose removal will not change the function a lot. To quantify this, the authors turn to the L2 norm of each neuron. Experiments on simple toy data and MNIST are conducted.","The paper suggests a pruning technique specific to ReLU networks by taking advantage of activation patterns and the separating hyperplanes. The technique consists of three steps: : (1) remove neurons that are never active and combine neurons that are always active, (2) remove neurons with little contribution to the output, and (3) use weighted k-means to combine other neurons. The method is evaluated on specific toy problems and the MNIST dataset.",0.16071428571428573,0.2535211267605634,0.19672131147540986
1798,SP:a5f75e1ad5a0650b7d39d4a0c74e1f20884f3680,"Contribution: Authors propose using a neural network to learn an approximate solution for desired boundary conditions in order to accelerate the semiconductor device simulation. They significately reduce the computational cost to calculate several unnecessary solutions when considering an initial solution sufficiently close to the final one by a convolutional neural network (CNN). To compute this initial solution, authors authors train a MOSFET based convolutional neural network. They empirically show that their proposed method accelerates the simulation by more than 12 times.","The paper proposes to use a CNN to compute an initial guess for the iterative Newton-Rhapson solution of a coupled PDE system used for semiconductor device simulation. To do so, the authors construct a ""device template"" which parametrizes the design space. The CNN then maps a device configuration in this 6-dim space to the predicted electrostatic potential in the form of a 64x64 grid. The authors provide an analysis showing why predicting the electrostatic potential alone is sufficient. Overall, this approach can provide a simulation speedup of 12x or more. The authors are also planning to publish the dataset generated for the paper.",0.20987654320987653,0.1619047619047619,0.1827956989247312
1799,SP:a6047a76fb92417053518625713c7174eab16680,"The paper adds an interesting new perspective to equivariant neural nets. However, the actual construction looks equivalent to steerable neural nets to me (see the papers by Cohen and Welling). The generalization of steerable nets has been published under the name ""gauge equivariant neural nets"", it would be very interesting to chart out the exact connections between these concepts. ","In this work, the authors employ concepts from group theory to turn an arbitrary feed forward neural network into an equivariant one, i.e. a network whose output transforms in a way that is consistent with the transformation of the input. To this end, the authors first introduce the basic concepts of group theory required to follow their work and provide a comprehensive definition of equivariance. They then explain how to equivarify (w.r.t. a finite group G) a given neural network, and present experimental results on rotated MNIST digits to support their approach.",0.1694915254237288,0.10526315789473684,0.12987012987012986
1800,SP:a637f040207332aff43cb9d801e4a879ba1dc701,"The authors introduce cell2state, an algorithm that incorporates both genetic barcoding coupled with single-cell sequenced data to model explicit state transitions of cell dynamics over time. Single-cell gene expression profiles are mapped to low-dimensional state vectors that are predictive of cell dynamics. Cell2state is evaluated using barcoded stem cell dataset (Biddy et al. (2018)) and simulation studies are also presented. The model demonstrates better results for cell state prediction, finding dynamically stable clusters, and reveals potential latent meta-states of the underlying cellular evolution process.  ","Authors proposed cell2state that could embed barcoded scRNA-seq trajectories into low-dimensional representation. Authors provided theoretic analysis of the embedding learnt by cell2state and demonstrated that the learnt embedding was almost lossless.  Authors applied this embedding framework on one barcoded scRNA-seq dataset (Biddy, et al., 2018) and demonstrated the learnt embeddings clearly distinguished different cell states. Furthermore, the learnt embeddings were able to substantially improve various downstream tasks other than identifying cell subpopulation. ",0.20454545454545456,0.24,0.22085889570552147
1801,SP:a64304c45675b73ff1d5a6b14f6044ab8a0f0aba,"The paper tackles Structure from Motion, one of the canonical problems in computer vision, and proposes an approach that brings together geometry and physics on one hand and deep networks on the other hand. Camera unprojection and warping (of depth maps and features) are used to build a cost volume onto hypothetical planes perpendicular to the camera axis. Similarly, various camera poses are sampled around an initial guess. A deep network regresses form the cost volume to a camera pose and a depth map. The method can be applied iteratively, using the outputs of the current stage as the initial guess of the next one. Training is supervised, and the the results are evaluated on multiple datasets.","The authors propose a SfM model which integrates geometric consistency with a learned pose and depth network. An initial estimate of depth and pose are used to construct pose and depth cost volumes, which are then fed into a pose regression and depth refinement network, to produce a new set of cost volumes, and so on. In this manner, the pose and depth estimation are improved iteratively.",0.1623931623931624,0.2835820895522388,0.20652173913043478
1802,SP:a6778e4fff4daf9de50ce2d1010aa748b0b9b088,"This paper tries to verify a hypothesis that language grounding DO help to overcome language drift when two agents creating their own protocol in order to communicate with each other. There are several constraints to enforce: 1) naturalness, say ""Englishness"", 2) grounded in visual semantics. The experiments prove that both constraints help the most (say, BLUE score). 1) w/o 2) restricts the vocabulary into a small set with the most frequent words, while 1) with 2) can resemble the original distribution. ","This paper poses and addresses the problem of language drift in multi-agent communication paradigms. When two pretrained natural-language agents are jointly optimized to communicate and solve some external non-linguistic objective, their internal communication often diverges to a code-like, unnatural communication system. This paper solves this “language drift” problem by requiring that the messages between agents be usable as inputs to an image caption retrieval system. They demonstrate that the jointly optimized agents perform best when regularized in this manner to prevent language drift.",0.15853658536585366,0.14942528735632185,0.15384615384615385
1803,SP:a6788a6cbd301cb34e8b8ed0fa34167c777d50ae,"The paper proposes a framework for weak supervision which works for both discrete and continuous labels. The proposed framework assumes the sources are coming from an exponential family distribution and generalizes the accuracy and correlation terms in previous approaches. They use a discriminative learning setting and use triplet methods in order to compute accuracies. They evaluated the performance for regression, ranking and hyperbolic and graph learning tasks.   The paper's main contribution is putting an exponential family distribution assumption which allows to use any metric space. In their experiments, they choose distances based on the problem and label type, mostly weighted L2 distance except hyperbolic dataset.      ","This work studies a weakly supervised learning setup of aggregating multiple weak sources of labels into high-quality pseudo labels for learning.   The proposed approach is based on building graphical models with the true labels as latent variables following existing techniques, but generalizes existing works in 1) supporting more types of task labels such as ranking, regression and in non-Euclidean spaces through approximating the graphical model terms using dot product between embeddings, and 2) algorithms for efficient learning under the embedding approximation and theoretical bounds on the estimation error using embedding-based approximation.   Experiments focus on comparing weakly supervised learning performance of learning a graphical model versus using majority vote on the newly supported tasks and fully supervised learning with varying amount of labels. Results show that learning the graphical model achieved better performance than majority vote and can achieve parity reach a certain level of fully supervision.",0.16981132075471697,0.12080536912751678,0.1411764705882353
1804,SP:a681ba4ac6dda87fa9501f27f7ba17dd08b54d6e,"The paper motivates and provides a model to generate video frames and reconstructions from non-sequential data by encoding time/camera position into the model training. The idea is to allow the model to interpolate, and more importantly, extrapolate from frames and learn the latent state for multiple frames together. The same techniques are also applicable to 3d-reconstruction.  JUMP is very closely related to GQN with the main difference being that the randomness in JUMP is learned better using a ""global"" prior. The evaluation is reasonable on multiple synthetic experiments including a 3d-scene reconstruction specially created to showcase the consistency capabilities in a stochastic generation. Paper is mostly clear but more priority should be given to the discussion around convergence and the latent state.","This paper presents a method for predicting future frames of a video (or unseen views of a 3D scene) in a ""jumpy"" way (you can query arbitrary viewpoints or timesteps) and ""consistent"" way (when you sample different views, the scene will be consistent). They use a VAE that encodes the input video in a permutation invariant way, which is achieved by summing the per-frame latent vectors. Then, they sample a latent vector using a DRAW prior. This latent vector can then be used to render the video/scene from different times/viewpoints via an LSTM decoder. They test the model on several toy datasets: they compare to video prediction methods on a dataset of moving shapes, and 3D viewpoint prediction on a 3D MNIST ""dice"" dataset.",0.14285714285714285,0.14173228346456693,0.14229249011857706
1805,SP:a6820b0338b6d70f8409499adb670080e3973a90,"In this paper, the authors propose a new bi-level optimization-based approach to handle the issue of [23], i.e., the proposed margin disparity discrepancy (MDD) measure conflicts with the H\DeltaH-divergence. The theoretical results are then applied to MDD and CDD, which gives the implicit task-driven discrepancy method, i-MDD and i-CDD. Experimental studies are done to verify the effectiveness of the proposed i-MDD and i-CDD.","The paper ""Implicit Task-Driven Probability Discrepancy Measure for Unsupervised Domain Adaptation"" proposes a probability discrepancy measure in the context of unsupervised domain adaptation while keeping the end goal, namely, minimizing the target domain risk, as part of the measure. The proposed measure, i-MDD, is based on a modification of the $\mathcal{H} \Delta \mathcal{H}$-divergence of Ben-David et al. (2010) and Marginal Disparity Discrepancy (MDD) of Zhang et al. (2019). The paper then discusses practical considerations like how to actually minimize the i-MDD, which is noted to be simplified due to the structure of i-MDD, and then finally discusses experiments.",0.3013698630136986,0.20754716981132076,0.24581005586592178
1806,SP:a685e4a6a1f6f3d69a9f0968145b6afd805dc5ab,"This work explores combining an RNN and a neural density estimator for forecasting in multivariate time series. RNN is stacked with a density estimator, MAF for best results, to forecast density of a multivariate time series at future time steps. In addition, variations of the architecture with attention and other density estimators are examined. The architecture, RNN+MAF and variants, is evaluated by CRPS score on several datasets.",The paper proposes a method to provide probabilistic forecasts of multivariate time-series taking dependencies between series into account even for large dimensions. The approach consists in using a normalizing flow to model the distribution of observations at a time-step condition on a state that can be obtained either with a RNN or a transformer. The motivation of using the normalizing flow is to be able to model various type of distributions without having to make specific hypothesis on the distribution which could hinder accuracy. Experiments are performed both on a synthetic task and on real-world datasets where accuracy is shown to outperform previous methods.,0.22058823529411764,0.14018691588785046,0.1714285714285714
1807,SP:a6950f04dd32e542da2dbb2ef34603274b2e178f,"The paper proposes a method to correct high-frequencies details in the textures of animated clothes. The main idea is to train a network to learn the 2D offset in the UV space for a given pose and view. The paper shows results using a t-shirt, on interpolating to novel views and 3D reconstruction by correcting the output of a state of the art method.","This paper presents a general approach to embed high frequency information into low-frequency data with a particular focus on improving the performance of virtual clothing. To address over-smoothing issues in the predicted meshes, authors proposed the texture sliding method that changes texture coordinates on each camera through the deep networks. The texture sliding neural network (TSNN) is trained using the ground truth offset computed for each camera and pose. ",0.19696969696969696,0.18309859154929578,0.18978102189781018
1808,SP:a69b08508dcfffcd0d1f64454e90d3ea2337cb5e,"In this paper, the authors present a new approach to combine the boosted decision tree classifiers with a graph propagation model, which is important in handling table input data. The approach casts the graph propagation as an optimization problem, where the input node features are generated by boosted decision trees. The gradient can be taken in the functional space to learn the decision trees to minimize a unified loss. The final algorithm is shown to minimize the unified loss in a principled manner. The superior performance is demonstrated over the existing BGNN model. ","The authors propose a new method for integrating graph-based models with boosting. This is done using the typical method involving residuals and weak-learners, but adding a step where information is propagated in the graph. The approach is also simple, as no GNNs or other auxiliary models are required. It is also shown how the meta-loss introduced by the authors provides convergence given some moderate assumptions. According to the experiments reported, the proposed model is better than the current state of the art in the considered domain.",0.22580645161290322,0.23595505617977527,0.23076923076923078
1809,SP:a69fd07798a781ba3b1f06d26c6c4554abcfd30f,"The authors are proposing an approach for unsupervised Federated Learning. The authors propose to use Emperical risk minimizing for unsupervised learning. The authors assign labels to each of the class and uses a prior for the classes so that each of the client can learn without any labels.  The authors have shown theoretical properties for their proposed solution. Theorem 1 showing that there is a map that that exist to transform the data to the classes, Lemma 2 shows that there is a transition function for each of the clients. The authors have also shown convergences of the algorithm by deriving the upper bound. ","This work presents a novel federated learning scheme to address the problem of learning from only unlabeled data. The main idea is clean and interesting, which constructs a global (server) model by aggregating the surrogate clients’ tasks from observing only unlabeled data for the classification tasks. The unlabeled data are transformed at each client to make them compatible with supervised federated learning; consequently, the learned models are transformed accordingly. Existing federated aggregation techniques, e.g. FedAvg, are applied on these transformed clients (where they call surrogate clients). Theoretical results are provided for learning the optimal model and experiments on benchmark and real data show superior performance compared to baselines. ",0.17307692307692307,0.1651376146788991,0.16901408450704225
1810,SP:a6a763428308aeb65687f2ba474984fc28b2f9ea,"The paper considers a multiclass classification problem in which labels are grouped in a given number M of subsets c_j, which contain all individual labels as singletons. Training takes place through an active learning setting in which all training examples x_i are initially provided without their ground truth labels y_i. The learner issues queries of the form (x_i,c_j) where c_j is one of the given subsets of labels. The annotator only replies yes/no according to whether the true label y_i of x_i belongs to c_j or not. Hence, for each training example the learner maintains a ""version space"" containing all labels that are consistent with the answers received so far for that example. The active learning process consists of the following steps: (1) use the current learning model to score queries (x_i,c_j); (2) query the best (x_i,c_j); (3) update the model.","This paper proposes active learning with partial feedback, which means at each step, the learner actively chooses both which example to label and which binary question to ask, then learn the multi-class classifier with these partial labels. Three different sampling strategies are used during active learning. Experimental results demonstrate that the proposed ALPF strategy outperforms existing baselines on the predicting accuracy under a limited budget.",0.10126582278481013,0.24242424242424243,0.14285714285714285
1811,SP:a6afe4079b1d42b36701f6c023b003b7a0e49a55,"The paper proposed a way to control the content output of a DNN-based language model (GPT-2 in the experiment, but not limited to it). It places an layer (CoCon) that can take an arbitrary phrase as the hint after generating the embedding but before generating the text. Experiments showed that the control is effective at directing the generated text. Examples confirmed that too. ","This paper tackles the problem of controlled text generation by converting it into a conditional text generation similar to (Keskar et al.19).  It proposes an architectural modification to the transformer LM used in GPT2,  Specifically, a CoCon layer is added as a separate transformer block in the middle allowing self-attention to be performed between the textual context representations LM_α(c) and the generations LM_α(x_{:t-1}) this is performed through concatenating the key and value matrices with the keys and values of the encoded textual context. Authors provide 4 different losses to train this additional layer. ",0.2153846153846154,0.1414141414141414,0.17073170731707316
1812,SP:a6d659731143b2b4b7c0b3940db926b80c2cf59f,"This paper introduces a particular learnable vector representation of time which is applicable across problems without the use of a hand-crafted time representation. Their representation makes use of a feed-forward layer with sine activations which operates on time data. As it is a vector representation, it combines well with other deep neural network methods. They motivate their problem well, explaining why time data is important to a variety of problems and situate their solution as an orthogonal approach to many current solutions in the literature. They make reference to fourier analysis as motivation for their representation. Finally, they provide experimental results to support their claims using fabricated and real-world time series datasets, as well as ablation studies to support their design decisions.","This paper proposes a simple representation of time (Time2Vec) for modelling sequential data. The idea is to apply multiple sine functions to the time with trainable period and offset and concatenate them together, which is similar to positional encoding [Vaswani et al.] except that the periods and offsets are learned. The results on several sequential modelling datasets show that Time2Vec performs better than naive representations and alternative baselines. ",0.136,0.25,0.1761658031088083
1813,SP:a6d815c0686325e7ed77cb2688a3bcb44a0c9e06,"The paper tackles a bandit setting similar to contextual bandits, where the feedback consists of the reward obtained from playing an arm, but also an additional random variable (the control variate) which is correlated with the reward but whose mean is known to the decision maker. Unlike in contextual bandits, the value of this control variate is not available at decision time but it is only revealed after the arm's play and can thus only be used to produce better estimates of the rewards of arms. The paper proposes the UCB-CV algorithm that builds confidence intervals that exploit this additional information to produce lower regret. The algorithm is accompanied by a regret analysis and experiments demonstrating the algorithm's performance and the decrease in regret that can be achieved based on the correlation coefficient between the reward and the control variates.","Starting from the hypothesis that smaller variance estimators of mean rewards result in better bandit performance, the authors leverage Control Variate (CV) theory to propose a bandit algorithm under the presence of auxiliary information about arm rewards.  The authors provide theoretical regret bounds of the proposed control variate based UCB algorithm (under the multivariate normal distribution assumption) and experimentally validate the performance on Gaussian and other distribution based assumptions.  The authors show that, as expected, the attained regret reduction is a function of how strongly correlated the reward samples and the observed control variates are.",0.1958041958041958,0.29473684210526313,0.23529411764705882
1814,SP:a6dfcd6335c24f1ee193abb860a5c67048be8c03,"The authors propose SPACE, an RL algorithm for learning a policy that maximizes reward while satisfying given constraints in a setting where a baseline policy is provided. They design a three-step update rule for learning such a policy and provide a finite-sample analysis of the resulting method in a simplified setting. They report numerical results in several domains that show how the proposed approach outperforms competitive baselines.","The paper considers the constrained Markov Decision Process (CMDP) problem where the goal is to maximize cumulative reward while satisfying the safety constraint on cumulative cost. Solving CMDP is challenging, and this paper proposes a shortcut by utilizing a given baseline policy. The idea of the proposed SPACE algorithm is to have three steps for each iteration of policy optimization. The first step is a trust region optimization step to optimize reward, the second step projects the policy to a region close to the given baseline policy, and the third step projects the policy to the constraint set. ",0.2318840579710145,0.16326530612244897,0.19161676646706585
1815,SP:a6f2ec5aa0023bb22ae2c128281a309cfacb1103,"This paper analyzes the behavior of Bellman update in cooperative multi-agent setting, when the value function has the form of a linear value decomposition of individual Q function per agent. The paper assumes no partial observability (i.e., all agents can see all states) and shows that under deterministic dynamics and factorizable Dataset, after one update, the individual Q function has close form, building connection with COMA. The paper then shows with this function class, the Bellman update might diverge in some MMDP. By extending to a broader function class, the Bellman update is close again. ","This paper is largely a theoretical undertaking and focuses on bringing new insights into the currently popular value decomposition schemes like VDN, QMIX etc. for multi-agent reinforcement learning. They find two major implications: 1) linear value decomposition leads to implicit difference based credit assignment, and 2) richer Q function classes like those of QTRAN, QPLEX can improve convergence because otherwise there is a risk of unbounded divergence.",0.12371134020618557,0.17647058823529413,0.14545454545454545
1816,SP:a7056ed3154309910542a66d52b98ea7a7e1ba4f,"The authors proposed to introduce a combination of a loss deviation term and a loss stabilization term to generate more consistent adversarial perturbations on medical images. The loss deviation term increases the divergence between the CNN prediction of an adversarial example and its ground truth label. At the same time, the loss stabilization term ensures similar CNN predictions of this example and its smoothed input. The authors tested against 3 different medical image datasets obtained by different modalities. The proposed strategy seems straightforward and the benefits are clearly demonstrated with these three datasets.","The authors present a universal medical attack method that can consistently produce adversarial examples across several medical imaging domains. The authors achieve this by developing a novel objective function that includes two terms, which they refer to as stabilized medical attack (SMA). The first term is the loss deviation term, inspired by the conventional fast gradient sign method, which enlarges the difference between CNN predictions and ground truth labels. The second term, a regularizer, is the loss stabilization term that enforces consistent predictions between the adversarial image and the Gaussian smoothed version of the adversarial image. The authors then provide an insightful interpretation of their SMA loss via KL divergence. The derivation demonstrates that perturbations consistently move towards a fixed location in the SAM objective landscape during successive iterations of gradient ascent. This method increases perturbation robustness by overcoming huge variations that result from different types of medical imaging data. The authors provide an illustrative figure (Fig.2) to demonstrate that both the variance and direction of the adversarial perturbation remain stable and consistent across multiple iterations, compared to using the deviation loss alone. The authors then perform an ablation study to demonstrate the DEV + STA loss results in a significantly greater reduction in model performance across medical imaging datasets compared to DEV loss alone. Finally, compared to the state-of-the-art adversarial methods, SMA results in the greatest reduction in performance for all datasets.",0.34408602150537637,0.13559322033898305,0.1945288753799392
1817,SP:a7207936657ad9e9582caf7d1521bb2f7f19f366,"The paper deals with one manifestation of safe exploration. Starting from a given safety function that classifies states as safe or unsafe, a modification of MBPO is used to change the Q-function in such a way that unsafe states should not be visited. The method is tested on two benchmarks.","This paper studies *safe* reinforcement learning (RL), in which an RL algorithm is tasked with learning a high-value behavioral policy while simultaneously minimizing the number of safety violations. To frame the work, the paper takes on a few key perspectives. First, that predicting only a few timesteps into the future is all that is needed to prevent safety violations. Second, that safety is defined in terms of the occupancy of set of states, as determined by the \textsc{Unsafe} predicate designed by an engineer. With this predicate in hand, a natural notion of an irrecoverable state is introduced, defined as those states that always lead to an unsafe state under any policy. Third, the paper assumes that environments are deterministic for the main analysis, and captures transition model uncertainty in the form of a next-state-set prediction.  With these perspectives in hand, the work establishes two primary contributions. The first is the formation of a safe proxy MDP, $\tilde{M}$, that uses a proxy reward and transition function. The proxy reward produces $-C$ for all unsafe states, where $C$ is a well chosen constant (to be returned to shortly). The proxy transition function replaces any unsafe transition with a self-loop. Hence, in reasoning with this proxy MDP, acting in an unsafe state will produce $-C$ reward indefinitely, thereby accumulating $C / (1-\gamma)$ value. By consequence, Prop. 1 illustrates that the Q values under the proxy MDP ensure safe actions always have higher values than unsafe actions. Then, section 3.2 takes this idea and extends it to the case when a model is being learned. In particular, it is assumed that the form of transition model learned is a ""set-valued dynamics model"" that maps each $(s,a)$ pair to a non-empty set of possible next states. With this definition of model, two Lemmas are introduced (1 and 2) that illustrate two things: First, that the cutely named ""Bellmin"" operator (which takes the s' achieved by minimizing Q w.r.t. possible next states in the set) is a $\gamma$-contraction (Lemma 1). Second, that a ""calibrated"" dynamics model (defined in Definition 2 as a set-valued model that always contains the true next-state in its next-state set) will ensure that the proxy Q function upper bounds the set-valued model's Q function. These two lemmas are used to Prove Theorem 1, which states that under a calibrated dynamics model, if there is an action with value greater than $r_{\min}/(1-\gamma)$, the greedy policy (w.r.t. $\underline{Q}$) will choose a safe action.  Then, following this analysis, the paper shifts focus on developing a practical, safe, model-based based algorithm (Algorithm 1, SMBPO). Experiments are conducted in two navigation tasks, hopper, and a cheetah variant, contrasting a variety of RL algorithms (many of which I was unfamiliar with). These include: MBPO, RRL-MF (recovery RL), LR (Lagrangian relaxation), SQRL (Safety Q-functions ), RCPO (Reward constrained policy optimization), and RSPO (Risk-sensitive policy optimization). The main quality explored here is the trade off each algorithm makes between performance and the number of safety violations.",0.47058823529411764,0.045889101338432124,0.08362369337979093
1818,SP:a727adb9f6aec44cd84d176e54d7578ed9ab023a,"The authors combine adversarial training with two methods that increase the entropy of the output distribution of neural networks (label smoothing and entropy maximization). The authors find that this combination of ideas increases adversarial robustness on standard benchmarks, especially in the regime of large perturbation budgets (e.g., 16/255 on CIFAR-10). The authors also investigate the effect of their methods on the classification margin to understand the increase in adversarial accuracy.","This paper investigates the complementary mechanisms of adversarial training and uncertainty promoting regularizers. In the field of adversarial machine learning, adversarial training as proposed by Madry et al. 2017 has been the common method. In the field of uncertainty regularization, maximum entropy and label smoothing have been the accepted methods. However, the combination of both has not been investigated before. The paper provides extensive experiments on these methods. The final section gives insights in the theory behind adversarial training and uncertainty promoting regularization, where they show that the combined method increases a notion of normalized margin and a notion of adversarial robustness. ",0.2602739726027397,0.18627450980392157,0.21714285714285717
1819,SP:a736d2fa98e58e22b69e55daf8b678d1583cc7e8,"This paper introduces a belief-propagation message-passing training algorithm for multi-layer neural networks. This algorithm is adapted to mini-batch training and biases distributions toward high entropy solutions. Empirical results show that neural networks with discrete weights and activations trained with this algorithm achieve comparable performance the same networks trained with SGD (BinaryNet), and can make approximate Bayesian predictions that have higher accuracy than pointwise solutions.","This manuscript provides an interesting try on alterative training algorithms for deep neural networks, based on (approximate) message-passing algorithms based on the well-known belief propagation (BP) algorithm.  In particular, the binary neural network is considered and four algorithms (BP, three variants of BP, i.e., BPI, MF, AMP) are proposed within a unified Posterior-As-Prior Update framework. Experiments are conducted on standard supervised classification tasks and continual learning settings, which shows comparable performances as standard SGD based methods.   ========================== After rebuttal: =========================  I have read the authors' feedback (many thanks for the detailed point-to-point feedback) and other reviewers' comments and modified the score accordingly. Overall, the proposed scheme is interesting, though strictly speaking the results are not very advantageous (at least from its current results) compared to traditional ones, and some of the comparisons seem not very reasonable/fair.   ",0.17647058823529413,0.08450704225352113,0.11428571428571428
1820,SP:a741950b8bdea3f1f6a62410ea8f5eb294e84f35,"This paper proposes using spectral normalization (SN) as a regularization for adversarial training, which is based on [Miyato et. al., ICLR 2018], where the original paper used SN for GAN training. The paper also uses the results from [Neyshabur et. al., ICLR 2018], where the original paper provided generalization bounds that depends on spectral norm of each layer. ","The paper first provides a generalization bounds for adversarial training, showing that the error bound depends on Lipschitz constant. This motivates the use of spectral regularization (similar to Miyato et al 2018) in adversarial training. Using spectral regularization to improve robustness is not new, but it's interesting to combine spectral regularization and adversarial training. Experimental results show significant improvement over vanilla adversarial training. ",0.20689655172413793,0.1875,0.19672131147540986
1821,SP:a743b4fc319d6ee0ed88ef0141eab91662f3a41e,"The paper studies (1) the relationship between the flatness of minima and their generalization properties, and (2) the connection between two measures of flatness, known as local entropy and local energy. Through a series of experiments, the authors show that the two measures are highly correlated and correlate well with generalization. They also empirically show that Entropy-SGD and Replicated-SGD, when used to explicitly optimize the local entropy, are able to flatter and better minima (in terms of lower generalization errors).","Authors essentially study the generalization properties of networks trained via two different algorithms, Entropy SGD (eSGD) and Replicated SGD (rSGD)  against networks trained via SGD. Both eSGD and rSGD are algorithms that have been previously designed using the notion of entropy guided modified loss function. In this paper the authors compare the performance of broadly these three categories of networks in terms of Local Entropy (Eq. 3) and local energy (Eq. 4) (i.e. difference in training error when the weights are perturbed by factor \sigma), which was developed in [1]. With this the authors aim to find a correlation between networks with close to zero entropy and networks with lower local energy. ",0.21951219512195122,0.1592920353982301,0.1846153846153846
1822,SP:a76c1a2b18015e647fa687abbb2840e2426b31f8,"This paper proposes a new model for learning partial differential equations from data. The PDE is first discretized then solved as an ODE. The dynamics function is learned with Message-Passing Neural Networks, where the function is split into a sum of physically informed terms. This splitting both improves model performance and makes the model more interpretable by disentangling the dynamics. The model is tested rigorously against multiple baseline models, and the results show the new model performs well.",The author proposes a method for forecasting in Partial Differential Equations by coupling Finite Element Method on an arbitrary grid with the learning of the dynamics from data. For this purpose a variant of message passing based graph networks is used. It is show in the paper that it's possible to incorporate priors on the structure of the PDE that results in an interpretable solution. The model also show more stability to changes of the mesh structure in test time (like superresolution) and to extrapolation than competitors. ,0.25316455696202533,0.22727272727272727,0.2395209580838323
1823,SP:a77494ee26aff245e217b630d3212aeee3d4496c,"This paper studies leveraging mode connectivity to defend against different types of attacks, including backdoor attacks, adversarial examples, and error-injection attacks. They perform a comprehensive evaluation to show the benign test accuracy and attack success rate over the models in the connected path between pairs of models with the same or different properties, e.g., both are attacked, both are benign, one attacked and one benign, etc., where the connected path is learned using existing algorithms to find the high-accuracy path over two different models. Their evaluation suggests that in certain attack scenarios, exploring the mode connectivity could help find a model that has a high benign accuracy, while with a significantly lower attack success rate than the models at the end points.","This paper proposes an adversarial defense method based on mode connectivity. The goal of the method is to repair tampered networks using a limited number of clean data examples. The authors consider two types of adversarial attacks: backdoor attacks and error-injection attacks. The proposed method takes two potentially tampered networks, then constructs a low-loss path connecting the weight vectors of the given models in the space of network parameters (the path is constructed using the small set of clean data examples), finally an intermediate point on the path is used as a weight vector corresponding to the “repaired” model. The authors analyze the properties of the paths and show that intermediate points on the mode-connecting paths deliver both high clean-data accuracy and low attack success rate. In the experiments the proposed method shows better results compared to baseline defense techniques including fine-tuning, training from scratch, and pruning followed by fine-tuning. The paper also analyzes evasion adversarial attacks from the perspective of mode-connectivity and observes the existence of barriers in the landscape of robustness loss on the paths connecting regular and adversarially-trained models.",0.296,0.19473684210526315,0.23492063492063492
1824,SP:a77bf951ae279e9c2cd14f7f1d8066e7be62db15,"Adversarial attacks for binary image classification are unique from traditional attacks on color images due to its limited available space for perturbation.  This paper proposes an algorithm that efficiently searches for valid attacks (both targeted and untargeted) which cause minimum flipped pixels. The proposed method is evaluated on digit classification, letter classification, and check processing systems. The baselines compared are mostly methods that were originally developed for color images.","The main question this paper aims to answer is how vulnerable binary image classification systems are.  This is an important question because of the application of such binary image classifications for check processing, invoice processing, and license plate registration. One also would think that such systems are less vulnerable to adversarial attacks given the simplicity of their inputs and the fact that most adversarial attacks are based on color or grey scale images.  The authors propose an adversarial attack algorithm called SCAR that efficiently flips the binary pixels with reasonable number of queries in order to confuse the classifier to return a desirable label with high confidence. The authors show that the proposed method outperforms the existing baselines on multiple data sets. Very interestingly, they also showed that their algorithm is able to attack the online deposit systems of US bank with a high success rate. Their example of a check with the amount of $401 that is minimally modified for the amount of $701  is quite significant given that the model had to change both the word and numbers on the check. ",0.30434782608695654,0.11475409836065574,0.16666666666666669
1825,SP:a77c90c209b32b8b5fce5f1ce55752a5b028cb7e,"This paper proposed a new dual generation model for learning representation by combining GAN and Autoencoder for 3D point cloud data. The idea is to add a regularization term over the GAN loss, and the regularization term measures the distance between the output of the encoder of Autoencoder and that of GAN by two point cloud metrics: Earth Movers's distance (EMD) and Chamfer pseudo-distance (CD). The experiment shows better representation are learnt by this dual generation model. The paper is in a good writing, and easy to read.","The paper focuses on designing a generative framework for 3-D point data clouds. These point clouds correspond to objects shapes in 3-dimensions. According to the paper, previous approaches for generating such 3-D point clouds involved autoencoder and GANs used separately. The authors propose a framework combining both autoencoder and GAN in a single network. The authors claim that part of the network learns effective latent space embedding for 3-d point clouds corresponding to different objects and thus the entire network is more effective in generating 3-d point cloud. Experimental results are presented to support the claims for efficient embeddings, and better generation of 3-d point clouds.",0.2111111111111111,0.16964285714285715,0.18811881188118815
1826,SP:a7a5a8dc7d3cbf7628878c285640dc8d670f71cf,"The paper deals with an intriguing point in RL -- how to correctly choose an adaptive $n$ for $n$-step bootstrap. From such a paper one might expect theoretical results on the tradeoff between bias and variance in the presence of off-policyness. However, as opposed to the picture portrayed in the first section, no such analysis follows. ","This paper provides a novel algorithm to estimate the optimal value of $n$ for $n$-step temporal difference methods. The paper derives an optimal value of $n$ based on minimizing a bias term, then utilizes intuition to derive an online approximation algorithm. The paper compares its adaptive $n$-step algorithm against fixed $n$-step values with both DQN and SAC empirically on several domains.",0.19298245614035087,0.171875,0.18181818181818182
1827,SP:a7b0b4f0962e1cc97b1e400a87e1b3738d168961,"This paper aims at matching people's voices to the images of their faces. It describes a method to train shared embeddings of voices and face images. The speech and image features go through separate neural networks until a shared embedding layer. Then a classification network is built on top of the embeddings from both networks.  The classification network predicts various combinations of covariates of faces and voices: gender, nationality, and identity.  The input to the classification network is then used as a shared representation for performing retrieval and matching tasks.","Authors aim to reveal relevant dependencies between voice and image data (under a cross-modal matching framework) through common covariates (gender, ID, nationality). Each covariate is learned using a CNN from each provided domain (speak recordings and face images), then, a classifier is determined from a shared representation, which includes the CNN outputs from voice-based and image-based covariate estimations. The idea is interesting, and the paper ideas are clear to follow.",0.15384615384615385,0.1917808219178082,0.17073170731707318
1828,SP:a7b23a4e9b5691cdb7722662704ff4feef18dcd6,"In distributed optimisation, it is well known that asynchronous methods outperform synchronous methods in many cases. However, the questions as to whether (and when) asynchronous methods can be shown to have any speed-up, as the number of nodes increases, has been open. The paper under review answers the question in the affirmative and does so very elegantly.","The authors design an accelerated, asynchronous block coordinate descent algorithm, which, for sufficiently small delays attains the iteration complexity of the current state of the art algorithm (which is not parallel/asynchronous). The authors prove a lower bound on the iteration complexity in order to show that their algorithm is near optimal. They also analyze an ODE which is the continuous time limit of A2BCD, which they use to motivate their approach.",0.13793103448275862,0.1111111111111111,0.12307692307692307
1829,SP:a7c5bc5a6764e8188597507fdde1cc3ad514d2ba,"This paper presents a new task (paired associate inference), drawn from cognitive psychology, which requires linking many pieces of information together to make inferences with long range dependencies. Experimental results show that standard memory architectures fail on these tasks. To redress this, the paper proposes a new memory architecture with several new features that allow for much better performance on the paired associate task. Finally, the paper undertakes systematic experiments on more traditional domains like shortest path problems, showing that the new architecture achieves modest improvements.","This paper proposes two main changes to the End2End Memory Network (EMN) architecture: a separation between facts and the items that comprise these facts in the external memory, policy to learn the number of memory-hops to reason. The paper also introduces a new Paired Associative Inference (PAI) task inspired by neuroscience and shows that most of the existing models including transformers struggle to solve this task while the proposed architecture (called MEMO) solves it better. MEMO also works well in the shortest path finding tasks and bAbI tasks.",0.18604651162790697,0.1797752808988764,0.18285714285714283
1830,SP:a7cbe71d5767df1afbc7795ff5ee10c6550dddca,"This paper studies the effect of padding on the Convolutional Neural Network. The authors try to answer the following questions: 1) what type of padding provides the most position information, 2) does the background value affects model accuracy when processing a patch on a canvas, 3) which part of the image suffers the most from the boundary effect, and 4) whether the position information provided by padding improves or degrades model performance. In order to answer these questions, the authors design multiple tasks and perform extensive experiments. The empirical results show that: 1) zero-padding provides the most location information compared with other common padding methods, 2) the background value of the canvas do affects the accuracy when processing a patch, 3) the boundary effect is not specific to the image boundary---the model is affected by the boundary over the entire image, and 4) the effect of padding on model accuracy depends on the task.","The paper seeks to understand how different padding modes and canvas colors affect the performance of a convolutional neural network in classification and semantic segmentation tasks. The question seems somewhat strange - surely a network should be able to counteract a consistent change in padding or background color. If there was a strong effect it would be an interesting finding indeed. Unfortunately, the paper fails to convince that any but the most obvious effects exist.",0.10897435897435898,0.22972972972972974,0.14782608695652172
1831,SP:a7ce1ce9bb4c234ad0ed9e01dc3cf84f141a2885,"This work proposes to leverage conformal embedding flows for modeling probability distributions on low-dimensional manifolds. Differing from other manifold-based flows, the proposed methods maintain tractable densities for low-dimensional latent space. The unique contribution enables fast sampling, invertibility for inference, and efficient likelihood estimation, which inherits from normalizing flows.   Existing approaches share the drawback that exact densities cannot be calculated through the dimensionality reducing step. In the paper, the authors present an approach that offers tractable density estimation and is straightforward to train by constraining this reduction to the class of conformal embeddings. ","Many datasets of interest that are modelled with normalizing flows are assumed to lie on a lower-dimensional manifold embedded in a higher-dimensional ambient space. Standard normalizing flows that are restricted to learn a *bijective* transformation are not well suited for modelling such data, as the target transformation between the lower-dimensional manifold space and the ambient space (in which said manifold is embedded) is *injective*.  In theory, an *injective flow* can be defined, where we'd parametrize an injective transformation that would only be invertible *for points on the manifold*. In practice there are two problems with this, however. First is that historically there's been much less work on designing flexible *injective* transformations, hence we don't have the same arsenal of invertible layers as we do for bijective flows. Second, the change-of-variable formula for an injective transformation includes a $\det J_f^T J_f$ term, where $J_f$ is the (rectangular) Jacobian matrix of the injective transformation $f$. This determinant, even if tractable, is typically overly expensive to compute exactly.  Authors of this work make an observation that in the bijective flow literature the game has always been to design parametric transformations $f$ that are restricted to be invertible, but *also* ones that have and easy-to-compute $\det J_f$. In line with this, authors propose a class of transformations that would have an easy-to-compute $\det J_f^T J_f$, specifically *conformal embeddings*. A conformal embedding $f$ is a transformation that preserves *angles*, but more importantly has a property that $J_f^T J_f$ is a scalar multiple of the identity, the determinant of which is simply the product of diagonal terms (i.e. an exponent of said scalar).   Authors consider a few examples of conformal embeddings (translation, scaling, an orthogonal transformation, zero-padding, etc.), which could be stacked in the same way as invertible layers are in a bijective flow. In addition, authors consider *piecewise* conformal embeddings, which are conformal *almost everywhere* (i.e. for all points except for a subset of measure zero), and can increase the expressivity of the otherwise simple conformal embeddings.  By using the conformal embeddings as injective transformations authors come up with the first injective flow with a tractable and *cheap-to-compute* density on the learned manifold. This allows said density to be used as a part of the training objective, even though an additional regularization term still needs to be included in the objective to prevent degenerate solutions. The method demonstrates excellent results on a synthetic 3D problem where the target density lies on a sphere, as well as the CelebA image dataset, where the visual fidelity of the samples is improved in comparison to the more expressive baseline flow.",0.28421052631578947,0.058695652173913045,0.0972972972972973
1832,SP:a7eaf12be994bfd19da12b089262215f4f683e58,"This paper proposes selective activation RNN (SA-RNN), by using an update coordinator to determine which subset of the RNN’s hidden state dimensions should be updated at a given timestep. The proposed loss term is then a sum of the original objective (e.g. classification) and a weighted sum of the probability that each dimension will be updated for each timestep. The method is evaluated on 3 time series datasets: Seizures, TwitterBuzz, Yahoo. ","A main problem with RNN is to update all hidden dimensions in each time step. The authors proposed selective-activation RNN (SA-RNN), which modifies each state of RNN by adding an update coordinator which is modeled as a lightweight neural network. The coordinator, based on the incoming data, makes a discrete decision to update or not update each individual hidden dimension. A multi-objective optimization problem is defined to both solving a sequential learning task and minimizing the number of updates in each time step. The authors evaluated their networks on three public benchmark datasets and achieved good results compared to the state-of-the-art ones.",0.2972972972972973,0.2037037037037037,0.2417582417582418
1833,SP:a80c724c969d4849f81a1df8e2c5902ab343e935,"Graph matching is a classic and import problem in computer vision, data mining, and other sub-areas of machine learning. Previously, the graph matching problems are often modeled as combinatorial optimization problems, e.g. Quadratic Assignment Problems. While these optimization problems are often NP-hard, researchers often focus on improving the efficiency of the solvers. The authors attack the problem in another way. They proposed an extension of graph embedding networks, which can embed a pair of graphs to a pair of vector representations, then the similarity between two graphs can be computed via computing the similarities of the pair of vector representations. The proposed model is able to match graphs in graph level as it can predict the similarities of the two graphs.",The authors present two methods for learning a similarity score between pairs of graphs. They first is to use a shared GNN for each graph to produce independent graph embeddings on which a similarity score is computed. The authors improve this model using pairs of graphs as input and utilizing a cross-graph attention-mechanism in combination with graph convolution. The proposed approach is evaluated on synthetic and real world tasks. It is clearly shown that the proposed approach of cross-graph attention is useful for the given task (at the cost of extra computation).,0.14516129032258066,0.18947368421052632,0.16438356164383564
1834,SP:a81ee1b76201649dc0d0653db304c7297befee33,"The paper studies optimization and generalization properties of deep relu networks trained with (stochastic) gradient descent on the logistic loss in the neural tangent kernel (NTK) regime. By using a new analysis that makes the ""linearized"" approximation as well as the L2 norm of the model in the approximate ""random feature"" kernel more explicit, the authors obtain results where the width only depends poly-logarithmically on the number of samples and 1/epsilon, for a test 0-1 loss of epsilon. This improves on previous analysis for deep networks, although it is similar to the two-layer result of Ji & Telgarsky.",The paper extends an existing proof for the sufficiency of polylogarithmic width for sharp learning guarantees of ReLU networks trained by (stochastic) gradient descent from shallow networks to deep networks. The theoretical analysis links the convergence of GD and SGD to the width of the network. The paper shows that polylogarithmic width is enough to give reasonable guarantees also for deep neural networks. It furthermore provides a generalisation bound in terms of network width.,0.21782178217821782,0.2972972972972973,0.25142857142857145
1835,SP:a826495e7d92c3cd68a71fc4961c296fec0307ed,"The paper performs a number of analyses centered around the ability of transformer-based language models trained on protein sequence data to learn representations useful for predicting protein secondary and tertiary structure (the latter as contact maps). Specifically, the paper studies several pre-trained transformer models by fitting an L1-penalized logistic regression to amino acid pair contacts. Several experiments are performed to showcase that (i) transformer-based representations can outperform state-of-the art methods based on MSA in terms of contact prediction precision; (ii) that the necessary information for contact predictions in these representations is learned in an unsupervised manner (and not by the logistic regression put on top of these representations); and (iii) that the contact prediction probabilities are reasonably well calibrated.","In this paper, the authors show that transformer protein language models can learn protein contacts from the unsupervised language modelling objectives. They also show that the residue-residue contacts can be extracted by sparse logistic regression to learn coefficients on the attention heads. One of the advantages of using transformers models is that they do not require an alignment step nor the use of specialized bioinformatics tools (which are computationally expensive). When compared to a method based on multiple sequence alignment, the transformers models can obtain a similar or higher precision.",0.168,0.23076923076923078,0.19444444444444445
1836,SP:a828fafc72ef2eb1190f4e7e9703f87d615bd040,"This paper proposes efficient mirror descent ascent (MDA) methods to solve the nonsmooth nonconvex-strongly-concave minimax problems. The SOTA convergence rates are established both for deterministic and stochastic settings. In practice, some experimetal results are provided to demonstrate the efficiencies of the proposed MDA methods. Overall, this is a very good paper.","This paper proposes a class of mirror descent ascent (MDA) methods for solving nonsmooth and nonconvex-strongly-concave minimax optimization problems by using dynamic mirror functions. It also studies the convergence properties of the proposed algorithms. In particular, the MDA method achieves a lower sample complexity by using the strongly-convex mirror function. The paper also provides some numerical experiments on fair classifiers and robust neural network training tasks to demonstrate the efficiency of the proposed algorithms. This paper first applies the mirror descent algorithm to nonsmooth minimax optimization. It provides a rigorous convergence analysis of the proposed algorithms. Overall, this paper is interesting and has some novelties. Thus I recommend accepting this paper. ",0.5283018867924528,0.24561403508771928,0.33532934131736525
1837,SP:a8329d28b1a840affeb0a6779a3361dd058294ef,"This paper presents an approach to multi-modal imitation learning by using a variational auto-encoder to embed demonstrated trajectories into a structured latent space that captures the multi-modal structure. This is done through a stochastic neural network with a bi-directional LSTM and mean pooling architecture that predicts the mean and log-variance of the latent state. This is followed by a state and action/policy decoder (both LSTMs) that recursively generate trajectories from latent space samples. The entire model is trained by optimising the ELBO on a set of pre-specified expert demonstrations. At test time, samples are generated from the latent space and recursively decoded to generate state and action trajectories. The method is tested on three low-dimensional continuous control tasks and is able to learn structured latent spaces capturing the modes in the training data as well as generating good trajectory reconstructions.","The paper proposes an imitation learning model able to generate trajectories based on some expert trajectories. The assumption is that observed trajectories contain multi-modal (i.e. style) information that is not naturally captured by existing methods. The authors proposed a VAE based architecture that uses a prior distribution P(z) to simultaneously generate (state-action) pairs based on a LSTM decoder (actually, one LSTM for the states and one interleaved LSTM for the actions). This decoder is learned using a classical VAE auto-encoding loss, observed trajectories being encoder through a bi-LSTM. Experiments are made on three toy examples: a simple 2d Navigation case exhibiting 3 different 'styles', a 2D circle example with also 3 different styles, and a zombie attack scenario with two different styles. The results show that the model is able to capture different clusters of trajectories. ",0.1891891891891892,0.19718309859154928,0.19310344827586204
1838,SP:a835aeeb4866b4b85159df0ec42a7885a97f567c,"The paper studies the connection between adversarial robustness and model capacity in the form of width. The key idea is to decompose robust accuracy into standard accuracy and stability---i.e., on what fraction of test inputs the prediction of the model cannot be changed by an adversary.  The authors find that while increased width tends to improve robust accuracy (as has also been previously observed) the gain are mostly coming from an improvement in the standard (test) accuracy of the model, while the stability of wider models is actually _decreased._ To counteract this phenomenon, they suggest increasing the regularization term corresponding to stability as the width of the model increases and indeed observe empirical performance improvements. The authors further support their hypothesis by theoretically analyzing the effect of width on robustness in an NTK setting and observing similar results. Finally, they propose a heuristic scheme for adjusting the stability regularization parameter during training and demonstrate promising results.","The paper discusses how the width of ResNets related to their robustness. They do adversarial training with a hyper-parameter for the strength of the robust regularization and show that making the model wider while keeping the hyper-parameter constant will increase clean accuracy but reduce the robust generalization.   They define a new metric, perturbation stability, which is the rate of samples keeping their label prediction under adversarial attacks, even if the label prediction is wrong without pertubations. The authors connect this metric to the local Lipschitzness and use it to study how the width of a network affects it. They show that both through an analytical calculation and empirical results that the local Lipschitz constant increases with the width of a network.  In further experiments the authors show that wider networks need a higher weight on the robust regularization loss to get optimal robust accuracy, while previous work often optimized this weight for smaller networks and then used the same value after increasing the width. The results are verified for other datasets and architectures and finally the authors present a strategy to adaptively choose the hyper-parameter for wider models by first optimizing it on smaller models and then optimizing during training to achieve the same ratio between natural loss and robust regularization loss for the wider model that was optimal for the smaller model. ",0.2468354430379747,0.17256637168141592,0.20312499999999997
1839,SP:a84141dacf9260f8c5dede0959fd4f58f29a51dd,"This paper describes an improved way to determine weight quantization bit lengths using reinforcement learning, by injecting model evaluation directly into action selection.  Building upon a DRL setup where the action at each timestep corresponds to selecting a bit value for each layer, the method adds a ""Q-value indicator"" function Q~ that selects among a set of candidate actions, and filters based on the model performance quantizing the layer to each level.  This seems to form a hybrid between DRL and greedy search, using a greedy criteria Q~ to filter proposals made by the DRL agent.  Experiments show very good performance, with similar or better quantization levels and accuracy as other DRL-based methods and much faster runtime.","This paper studies the DNN quantization using deep reinforcement learning. The paper proposes an augmented DRL which introduces a Q-value indicator to refine action selection. The proposed approach has been applied to several image classification baselines and has compared with several recent DRL based quantization approach, achieving a similar compression rate without accuracy decrease.  In addition, compared to previous methods, the learning speed has been improved by 4.5-64x. ",0.15126050420168066,0.2535211267605634,0.1894736842105263
1840,SP:a84853c2ccc676838a77ef3323d5eb60fb5b638b,"In this paper, the authors consider the task of adversarial/robust learning with respect to neural networks. The problem is a well-motivated one: suppose there is a neural network that on input a training set T={(x_i,y_i)} does a good classification job, but an adversary comes along and modifies some parts of T, then it is very possible that the neural network will classify almost incorrectly and hence isn't robust. In this paper they consider this setting and ask if we can naturally make neural networks robust. ","The contribution of the paper is threefold: First, it proposes a novel variation of AdderNet (Chen et al. 2020) that ensures the network is always 1-Lipschitz with respect to $\ell_{\infty}$ norm. The architecture allows one to generate robustness certificates with respect to $\ell_{\infty}$ norm with only a single forward pass, which is computationally cheap compared to many of the previous methods. Second, it analyzes the expressive power and robust generalization of the architecture. Finally, it proposes two training techniques (bias batchnorm and p-norm schedule) that overcome the optimization problem inherent with training $\ell_{\infty}$ Net and analyzes its empirical performance with respect to the previous methods.",0.16304347826086957,0.13636363636363635,0.1485148514851485
1841,SP:a84af29bb856abf8eebf6eb8ba8ffd18066f1550,"In this paper, the authors consider the global convergence and stability of stochastic gradient descent in a fairly general non-convex setting. They are able to remove the often-assumed unrealistic uniform bounded assumption on the noise, and also relax the global Holder assumption in the literature. Their discussions in Appendix A provide an example for which the uniform bounded assumption on the noise commonly assumed in the literature fails. Their global convergence says that under some relatively weak assumptions, SGD either diverges or the objective converges to a finite random variable and the gradient converges to zero. This excludes the bad outcomes, e.g. limit cycle or oscillation. Their stability result says that under a stronger assumption, SGD's objective converges to a finite random variable and the gradient converges to zero with probability one. ","In this paper, the authors study the behavior of SGD under very general assumptions. The existing global convergence of SGD requires two restrictive assumptions: a global Holder continuity for gradients and unrealistic noise models for stochastic gradients. This paper relaxes the global Holder continuity assumption to a local Holder continuity assumption, and consider general noise model assumptions. The main results include global convergence and stability. By global convergence, the authors show that either the iterates converge to a stationary point or they diverge. By stability, the authors show that the objective function remains finite along any iterate sequence. In the deduction, the authors introduce novel techniques to decouple some dependencies encountered in considering general assumptions. ",0.25,0.2956521739130435,0.27091633466135456
1842,SP:a85b6e1281b4c5f84e891b0897affe5971d4ff7a,"This paper considers zeroth-order method for min-max optimization (ZO-MIN-MAX) in two cases: one-sided black box (for outer minimization) and two-sided black box (for both inner maximization and outer minimization). Convergence analysis is carefully provided to show that ZO-MIN-MAX converges to a neighborhood of stationary points. Then, the authors empirically compare several methods on ",The paper presents an algorithm for performing min-max optimisation without gradients and analyses its convergence. The algorithm is evaluated for the min-max problems that arise in the context of adversarial attacks. The presented algorithm is a natural application of a zeroth-order gradient estimator and the authors also prove that the algorithm has a sublinear convergence rate (in a specific sense). ,0.21311475409836064,0.20634920634920634,0.20967741935483872
1843,SP:a870fafb1f9f799d7efcc9637f1cd48ab0e10bb9,"The paper proposes a linear time and memory attention mechanism that computes attention into two steps: In first step, an extra input ($P$) with fixed sequence length is introduced that summarizes the context to fixed length output sequence via packing attention. In the next step, the queries attend (unpack attention) to the fixed length summarized sequence resulting in a overall complexity that is linear in input sequences length. Experiments are conducted on LRA benchmark and other NLP tasks to show the effectiveness of the proposed method against other fast attention mechanisms. ","This paper proposes Luna, an approximation to the Transformer's softmax attention with linear (in sequence length) time and space complexity. The approximation works using two attention functions. The first packs the sequence into one of fixed length; the second unpacks this fixed length sequence into one whose length matches the original sequence. Experiments show that Luna is computationally efficient, and typically performs either competitively or better than baseline methods.",0.1978021978021978,0.2571428571428571,0.2236024844720497
1844,SP:a874a60746a5a996009f9175f88fcb82511239f2,"This paper combines the benefits of using joint steerable filters (using the SO(2) group) for designing rotation-equivariant CNNs with those of decomposing the filters (using Fourier-Bessel bases) for reducing the computational complexity. In addition, this leads to a compressed model and filter regularization. The authors give theoretical guarantees on the rotation equivariance and representation stability with respect to in and out of plane rotation. Empirical results show that the model attains better accuracy compared to CNNs and non-rotation-equivariant deep networks while using fewer parameters and also performs similarly to a rotation-equivariant model with much bigger capacity.","Group-equivariant deep networks are used as a solution for rotation-equivariance in CNNs. However, they are computationally expensive as the number of filters increases by a factor proportional to the number of groups. Inspired by ideas of filter decomposition used in CNN model compression, the authors of this work instead propose to use steerable filters across space and rotation, as basis filters for achieving rotation-equivariance, which leads to computational efficiency. ",0.1568627450980392,0.2222222222222222,0.1839080459770115
1845,SP:a877e36694e5ce6ac8fd441a765229a6574a3c16,"This paper proposes a novel interventional causal model selection (ICMS) score to select individualized treatment effects (ITE) models under the unsupervised domain adaption (UDA) setting. The problem is fundamentally challenging as counterfactual outcomes cannot be observed. The authors make an assumption that the underlying causal structure across domains remains unchanged when adapting the ITE models from one domain to another. The authors propose Theorem 1 that the conditional independence relationships in the interventional DAG are equal to that in the interventional distribution for the target domain, followed by augmenting the target domain data with the model's prediction of the potential outcomes. Then the model that generates the best augmented target data in the sense that matches best with the interventional DAG is selected. To access this fitness, authors use the negative log-likelihood of the interventional DAG given the augmented data on the target domain. Finally, results with both synthetic data and real-world COVID-19 dataset show improvement for all ITE models.","the paper attacks the problem of model selection for individual treatement effect (ITE) models when the domain of learning and prediction differ. Proposal is to use causal consistency as an additional ""regularizer"" in existing domain adaptation (DA) model selection methods. The ""regularizer"" would be scoring to which extent replacing factual outcomes by their counterfactual predictions would preserve conditional independence relations (induced by the causal graph) in the prediction domain. Experiments on a variety of datasets are conducted to show the added performance induced by using the ""regularizer"".",0.13414634146341464,0.25287356321839083,0.1752988047808765
1846,SP:a8937ce7ccd4a5a0daa3ef434aed388abb1ab0d8,"This paper focuses on the problem of identifying bad training data when the underlying cause is unknown in advance. Authors develop an algorithmic framework, DATASIFTER, for general robustness to bad training data. Empirical evaluation show efficacy of DATASIFTER in a wide range of tasks, including backdoor, poison, noisy/mislabel data detection, data summarization, and data debiasing","This paper proposes, *DataSifter*, an optimization-based, general-purpose framework for filtering ""bad data"" from a training set.  General-purpose broadly covers different data corruption types (e.g., adversarial perturbation, label noise, etc.), different model architectures, and performance metrics (e.g., test error).",0.17857142857142858,0.23255813953488372,0.20202020202020202
1847,SP:a89a7421e4d3b82156edcc03ff8b24fb4df8df41,"- This paper made a finding that weighting up  correct predictions for rare class examples also can help to improve the performance of imbalanced classification. In light of this finding, it proposes the Eureka Loss to add additional gradients for examples belong to rare classes in the high-likelihood area when correctly predicted. Experiments on several large-scale benchmarks demonstrate its effectiveness.","This paper deals with learning imbalanced class distributions.  First, it empirically finds that the high-likelihood area for the rare classes benefits classification. Then, based on the findings, it proposes a new learning objective called Eureka Loss, which can be viewed as a combination of the frequency-based and likelihood-based methods to reward the classifier when examples belong to rare classes in the high-likelihood area are correctly predicted. Empirical results on two typical tasks (i.e. image classification and language generation tasks) illustrate its superiority compared with other baselines. ",0.4098360655737705,0.27472527472527475,0.32894736842105265
1848,SP:a8cb23a70671d54f8784ac023bbecbcbd0bffcfa,"This paper proposes a way to attack and reconstruct a victim's neural architecture that is co-located on the same host. They do it through cache side-channel leakage and use Flush+Reload to extract the trace of victim's function call, which tells specific network operations. To recover the computational graph, they use the approximate time each operation takes to prune out any incompatible candidate computation graph. They show that they can reconstruct exactly the MalConv and ProxylessNAS. ",This work proposed a method to reconstruct machine learning pipelines and network architectures using cache side-channel attack. It is based on a previous proposed method Flush+Reload that generates the raw trace of function calls. Then the authors applied several techniques to rebuild the computational graph from the raw traces. The proposed method is used to reconstruct MalConv which is a data pre-processing pipeline for malware detection and ProxyLessNas which is a network architecture obtained by NAS. ,0.2875,0.2911392405063291,0.2893081761006289
1849,SP:a8d2b848db3e06293f0fd3c0a3a3a45e02dad92a,"This paper studies the detection and recovery problem in spiked tensor models in the form T = \beta v0^\otimes k + Z, where v0 is the underlying spike signal and Z is a Gaussian noise.  The authors claim that they propose a new framework to solve the problem, by looking at the trace invariants of tensors. The authors provide a detection algorithm (Algorithm 1) and a recovery algorithm (Algorithm 2), as well as the corresponding phases. The authors claim that: 1) they ""build tractable algorithms with polynomial complexity"", ""a detection algorithm linear in time""; 2) the algorithms are very suitable for parallel architectures; 3) an improvement of the state of the art for the symmetric tensor PCA experimentally. The authors furthermore discuss the asymmetric case and the multiple spike case.","The paper presents a pair of interesting algorithms using trace invariants to detect the signal in the signal-plus-noise tensor PCA framework.  The algorithms function by considering cutting an edge in the graph representation of the trace invariant, yielding a matrix whose leading eigenvector provides a (up to a rotation) estimate of the signal vector $v$.  This algorithm appears to be very interesting and works well in a series of simulations. ",0.13953488372093023,0.25,0.1791044776119403
1850,SP:a8e70c04bc1fdbb5fa33e164c705074b8221a12f,"This paper studied the problem of DNN training and generalization in vanilla architecture (without BN and Skip Connections in ResNets). It follows NTK theory and the approach of applying certain transformations to the activation functions. This work improves an existing work DKS, and solves its incompatibility to ReLU activations (""Leaky"" ReLUs). This work introduces the necessary modifications to the Q/C map conditions for using Leaky ReLUs and shows empirical improvement over DKS or an easier method EOC on ImageNet.","This paper mainly discusses the training of neural networks without residual connections. To close the gap between residual-free and regular models, an activation transformation technique named ""Tailored Activation Transformation (TAT)"" is introduced.  Compared to the state-of-art method DKS,  the proposed TAT can yield better results for models using ReLU-family activation. Overall the motivation is well-discussed and sufficient ablation studies are provided. ",0.1875,0.22727272727272727,0.2054794520547945
1851,SP:a8e7d4ce947d6525daace6f13bac6cfb3a68be6e,"This paper proposes an algorithm to control robots with a universal controller conditioned on the robot parameters, that are identified online using differential simulation. The idea is simple yet interesting: giving the controller explicit information about the system could definitely help performance. Estimating those parameters with differential simulation definitely makes sense. The approach could be valuable for helping robots handle internal or external changes during operation. The approach is evaluated on a series of rigid body control tasks, where it is on pair or better than previous solutions.","The paper tackles the problem of learning robot controllers that can handle changing or unknown environments. It proposes to use differentiable physics for online system identification and reinforcement learning for offline policy training. The differentiable physics module estimates simulation parameters from robot history and feeds this to the controller that is parameterized by these simulation parameters. They use domain randomization to ensure the universal controller conditioned on simulation parameters is robust to changing environments (simulation parameters). At test time, the differential physics simulation is used to estimate the simulation parameters to bias the controller to output controls for the 'correct' simulation parameters.  The proposed approached is evaluated against several benchmarks on the cartpole and a tabletop wiping tasks and has been shown to outperform the baselines, which include domain randomization and some domain adaptation approaches.",0.23863636363636365,0.15555555555555556,0.1883408071748879
1852,SP:a91c11b46a43d923fd699cdc35a6ef09b8f69a61,"The paper deals with efficiently incorporating CROWN into the branch-and-bound framework for complete verification. The authors propose to relax the split constraints using Lagrangian relaxation, and show how this can be done within the bound propagation framework. They also jointly optimise the intermediate bounds to tighter verification.  The technical contribution is fairly simple.  The method gives good improvements over existing complete verification methods. Authors have done a very good experimental evaluation, on different datasets and compared with many baselines.  The writing is good overall. Sections 2 and 3 are very well written. I have some comments which I have added in the main review.  The related work section and conclusion section need some work. ","The paper presents Beta-CROWN, a novel algorithm to compute bounds on the output of neural network activations. Beta-CROWN is designed to be employed within recent branch-and-bound frameworks [6, 10], resulting in an effective complete (or incomplete, when returning early) verification algorithm.  The authors build on the bounding algorithm presented in [43] (""alpha-CROWN""), which (with fixed intermediate bounds) is an effective solver for the popular triangle LP relaxation (Planet [14]) of ReLU neural networks. The main contributions of the paper are the following: - differently from alpha-CROWN, beta-CROWN can represent the effect that a ReLU split at the i-th layer has on the activations preceding it, leading to tighter bounds within branch and bound; - when jointly optimizing over intermediate bounds and output bounds, beta-CROWN shares fewer parameters between the various sub-problems, resulting in tighter final bounds.",0.1896551724137931,0.1527777777777778,0.16923076923076924
1853,SP:a92ce63df0b4384bf0304661c8a8c80553377d57,"The paper considers stochastic gradient descent with noisy gradients. In contrast to the standard setting (e.g., gradient Langevin dynamics) where additive Gaussian noise is added to the model gradient, this work focuses on additive perturbations of data instances. As a result of this, the optimization objective changes throughout the training process because the data is no longer static/fixed but assumed to be sampled from some distribution governing the perturbation process (see Eq. 3.3).",".** Authors present a novel theoretical framework for assessing the effect of data augmentation (e.g. mini batch SGD), noise addition and the learning rate setup in gradient-based optimization with overparametrized models. Despite the analysis is only performed for linear regression, results extend the well-known Monro-Robbins theorem on rates of convergence. The manuscript is a first step for future analysis of the aforementioned techniques with other type of models and/or loss functions.",0.14473684210526316,0.14666666666666667,0.1456953642384106
1854,SP:a96e9c050813608f1e198a8b6cdce1a6724060bd,"This paper studies homogenious networks, which is defined by the paper as networks that reuse building blocks with shared or different weights multiple times during the inference of the network. During the inference, the network iteratively use the same set of blocks to process input feature maps with different resolutions, and each step, the output feature map can be used by the prediction head to generate the output. This paper studies the cost of the network, in terms of MACs, parameters, memory footprints, and the accuracy vs. the number of iterations. The author noted that for the studied network, they need to increase the MACs by 3x in order to match the performance of regular networks. Despite this, this kind of homogeneous networks can be useful for novel hardware architectures with limited memory bandwidth. ","This paper proposes a homogeneous network structure for semantic segmentation, which optimizes for prediction accuracy, latency as well as memory footprint.  The paper studies anytime prediction setting and designs a re-usable single building block to reduce the memory footprint. Experimental results on CamVid data shows that it's possible to use a homogeneous network architecture to achieve competitive mIoU compared to previous work at the cost of increased MACs.  Experimental evaluation on larger datasets such as Cityscapes is prohibited due to memory constraints of the available GPUs. ",0.12686567164179105,0.19318181818181818,0.15315315315315317
1855,SP:a980ff820008da4302476e6c016fb2ee3f492d8f,"This paper proposes a new representation learning model for graph optimization, Graph2Seq. The novelty of Graph2Seq lies in utilizing intermediate vector representation of vertices in the final representation. Theoretically, the authors show that an infinite sequence of such intermediate representations is much more powerful than existing models, which do not maintain intermediate representations. Experimentally, Graph2Seq results in greedy heuristics that generalize very well from small training graphs (e.g. 15 nodes) to large testing graphs (e.g. 3200 nodes).","Graph representation techniques are important as various applications require learning over graph-structured data. The authors proposed a novel method to embedding a graph as a vector. Compared to Graph Convolutions Neural Networks (GCNN), the proposed are able to handle directed graphs while GCNN can not. Overall the paper is good, the derivation and theory are solid. The authors managed to prove the proposed representation is somehow lossless, which is very nice. The experiment is also convincing.",0.13924050632911392,0.14285714285714285,0.141025641025641
1856,SP:a98136d57d728039708c2cc72b3432ca6661b023,"The contribution of this paper is a method for testing the closeness of the probability distributions encoded by two different probabalistic circuits (PCs). The closeness tester (called Teq), assumes access to an approximate weighted counter and an approximate weighted sampler. Teq is described (in words and pseudo-code) and the bulk of the paper is devoted to proving (PAC-style) correctness of Teq (ie Theorem 1) and characterising its time complexity (Theorem 2). Empirical results are given supporting the correctness of Teq and the stated time complexity theoretical results on Teq.","This paper presents a statistical closeness test for evaluating whether the total variation distance between the probability distributions encoded by two circuits is below a lower threshold or above an upper threshold with a given confidence in polynomial time. The authors introduce the setting, present the algorithm and give a sample of the analysis by proving parts of the main result. The results are evaluated on public datasets.",0.25274725274725274,0.3382352941176471,0.2893081761006289
1857,SP:a989cb67eee0394de2476a69b5cc423727371f96,"The authors consider the setting of a RL agent that exclusively receives intrinsic reward during training that is intended to model curiosity; technically, ‘curiosity’ is quantified by the ability of the agent to predict its own forward dynamics [Pathak, et al., ICML17]. This study primarily centers around an initially somewhat surprising result that non-trivial policies can be learned for many ’simpler’ video games (e.g., Atari, Super Mario, Pong) using just curiosity as reward. While this is primarily an empirical study, one aspect considered was the observation representation (raw pixels, random features, VAE, and inverse dynamics features [Pathak, et al., ICML17]). In examining reward curves (generally extrinsic during testing), ‘curiosity-based’ reward generally works with the representation effectiveness varying across different testbeds. They also conduct more in-depth experiments on specific testbeds to study the dynamics (e.g., Super Mario, Juggling, Ant Robot, Multi-agent Pong) — perhaps most interestingly showing representation-based transfer of different embeddings across levels in Super Mario. Finally, they consider the Unity maze testbed, combining intrinsic rewards with the end-state goal reward to generate a more dense reward space. ","In this paper, the authors presented a large experimental study of curiosity-driven reinforcement learning on various tasks. In the experimental studies, the authors also compared several feature space embedding methods, including identical mapping (pixels), random embedding, variational autoencoders and inverse dynamics features. The authors found that in many of the tasks, learning based on intrinsic rewards could generate good performance on extrinsic rewards, when the intrinsic rewards and extrinsic rewards are correlated. The authors also found that random features embedding, somewhat surprisingly, performs well in the tasks.",0.10810810810810811,0.22727272727272727,0.14652014652014653
1858,SP:a9a78aeb40b9f8e747ee351dbfe343d7f6863e6f,"This work proposes Adversarial Reconstruction Network (ARN), a network architecture, and Max-margin Domain-Adversarial Training (MDAT), an objective and training procedure for unsupervised domain adaptation. Similar to domain adversarial approaches, the generator aims at finding domain invariant representation while the discriminator now monitors the reconstruction loss of the source and target data using hinge-like lose. The method is very similar to some of the existing works in the literature. Experiment results on the standard digit datasets and the WiFi gesture recognition dataset show that the proposed method outperforms other alternatives.","This paper proposed a new method for unsupervised domain adaptation. Different from a conventional domain classifier based adaptation, they propose to utilize the loss of autoencoder to extract domain-invariant features. They trained reconstruction network to reconstruct source examples well whereas making reconstruction loss of the target examples large with some margin. Their goal is to stabilize the training of adversarial training for domain adaptation, incorporate pixel-level information, and give interpretable learned feature space. They performed experiments on digits datasets and WiFi Gesture Recognition datasets. Through experiments, they have shown that their method shows better performance than baseline methods and their method is not parameter-sensitive, is stable and provides interpretable adaptation results. ",0.2826086956521739,0.22807017543859648,0.25242718446601936
1859,SP:a9be89f746c794d25c46d2da1feb6d06f93eb056,"This paper proposes a new mixup method that encourages diversity among the samples mixed from a minibatch of data in addition to saliency of each mixed sample. The authors formulate two objectives: 1. a BP set function (submodular + supermodular), and 2. a submodular relaxation obtained by modularizing the supermodular component. Then they solve this problem approximately with coordinate descent by modularizing wrt the update coordinate at each step. This approach outperforms mixup baselines on image classification and several other tasks (calibration, object localization, and robustness).","This paper proposes a new batch mixup method, co-mixup, to improve the networks’ generalization performance and robustness. It formulates the construction of a batch of mixup data by maximizing the data saliency measure of each individual mixup data and the supermodular diversity among the constructed mixup data. An iterative submodular minimization algorithm is used to solve the proposed problem through approximation. Promising empirical performance is reported on several tasks. ",0.25882352941176473,0.3142857142857143,0.28387096774193554
1860,SP:a9c2860abb6a9df585aecea0dfb9a833458f184f,"This paper argues that Artificial Neural Network (ANN) lack in biological plausibility because of the back-propagation process. Therefore, the authors provide an alternative approach, named neural net evolution (NNE) that follows evolutionary theory. This approach uses a large number of genotypes (in the form of vector with binary logits) that will evolve overtime during training. It does not require to calculate the gradient explicitly. The authors have conducted some experiments on MNIST using ANN with only one hidden layer. The experimental results show that the NNE can learn the classification task reasonably well considering that no explicit back propagation is used. ",In this paper the authors propose a method for training neural networks using evolutionary methods. The aim of developing this method is to provide a biological alternative to back-propagation. The authors prove that their method converges and with high probability succeeds in learning linear classification problems. Another method is also proposed which is linked to dopaminergic neurons.,0.13725490196078433,0.2413793103448276,0.17500000000000004
1861,SP:a9ce28f23686cc1280db9dcabc867c0545aa1bed,The paper considers estimating a signal tensor from noisy and incomplete measurements. A new models is proposed based on sign-ranks of tensors. Statistical estimation rates are provided (which pretty much follows standard template). Algorithms and extensive numerical results are provided selling the proposed model.   ,"This work studies the problem of tensor estimation from noisy observations with possibly missing entries. A nonparametric approach to sign tensor completion is developed. which can deal with both low-rank and high-rank tensor decomposition. Theoretical analysis is provided in terms of risk bound, estimation error, and sample complexity. ",0.2,0.18,0.1894736842105263
1862,SP:a9f4f82d999fac770dcd3b8b2aca5377c6d41e98,"The paper considers the rate-distoriton-perception trade-off setting, and studies what happens if we fix an encoder and train different decoders for different (D, P) targets. This is studied both theoretically and empirically. It is shown that for Gaussian sources, the rate penalty incurred by using a single encoder for multiple (D, P) target is zero. Empirically, it is shown that on MNIST and SVHN, jointly training decoders and encoders is only marginally better in terms of D-P than when using a frozen encoder.","The rate-distortion-perception (RDP) function[5,23] is a generalization of the classical rate-distortion (RD) trade-off in lossy compression to also measure realism, which establishes a theoretical footing for generative image/video compression, a topic of active research[1,11,17,25].  This paper studies the RDP function under the constraint of a shared encoder for multiple D-P points, both from the theoretical side and experimentally. This is of significant practical interest, as detailed below.",0.19540229885057472,0.21518987341772153,0.20481927710843373
1863,SP:a9ff7a5c458d390f57d69569ab561dc077a46238,"This paper presents some enhancements for Knowledge Tracing (KT), in which predictions are made about the odds of a student answering a question correctly given a sequence of correct/incorrect responses to previous questions.  The authors observe that the predictive model should obey certain 3 common sense constraints. If a question is replaced in the student's data by a very similar question, the prediction should not change much. If an additional correct question is added to the data, the odds of the student being correct on the next question should go up, and the odds should go down for questions being removed and/or added with incorrect responses.  The learning algorithm's objective function is augmented with additional terms which encourage the model to obey these constraints.","Knowledge tracing is a longstanding task in educational data mining and has been tackled by various studies. This paper proposed that three data augmentation methods (along with different types of regularization losses) can be applied to boost the performance of existing deep neural network models for knowledge tracing. Overall, the methods developed by this paper seem technically sound. In particular, the experiments are rather extensive, i.e., four widely-used datasets were employed in the experiments and different variants of the methods were investigated and compared. However, my biggest concern for this paper is its connection with previous studies and the design principles behind the proposed methods. To be specific, there are a few places that need to be further justified or a more clear explanation.",0.140625,0.14285714285714285,0.14173228346456693
1864,SP:aa0febaec3494ea69264d71d33081759037e5319,The authors present a neural network based method to solve a special class of integral equations. Their approach involves training a neural network with Legendre polynomial based activation functions to approximate the solution $y(x)$ for a given $x$. The network is trained in a supervised fashion to minimize a loss function with two term- (1) the $\ell_2$ error between the true solution and $y(x)$ and (2) the residual of the given integral  equation when analysed at $x$. They show impressive numerical results for several instances of VFH-IEs with very low errors. The primary contributions as claimed by the authors are the use of Legendre polynomial based activation functions and creating a differentiable approximation for the integral equation by using Legendre polynomials and Quadrature methods to analyse the integral. ,"The paper proposed the Legendre Deep Neural Network (LDNN) to solve Volterra–Fredholm–Hammerstein integral equations. Specifically, the network uses Legendre polynomials as the activation in the first layer and uses Gaussian quadrature to discretize the integral operator as a summation. The numerical examples are performed to verify the performance of LDNN. However, the method is not novel and the numerical examples are too simple.",0.17424242424242425,0.35384615384615387,0.23350253807106602
1865,SP:aa1054c1782ad4562ed402bb56f70f9287d197ce,"The paper presents a weakly supervised learning strategy, which exploits instance labels in a form of label prior distributions for training classifiers. The main idea of this work is to build an implicit generative model from a probabilistic label prediction network, which is then trained with an ELBO loss. The paper applies this framework to several types of weakly supervised learning scenarios, including classification with negative labels or labels from ranking, semantic segmentation and text classification from coarse labels, and other tasks with structured label priors, etc.  The experimental evaluation validates the efficacy of the proposed learning strategy on the aforementioned tasks with comparisons to the prior works. ","In this paper, the authors present implicit generative models in a free energy criterion with a combination of both the training of neural networks for label prediction and modeling of a label prior. They also discuss multiple sources of label priors to handle label uncertainty for coarse and imprecise data input. The extensive experiments conducted on five different tasks and the experimental results seem to well validate the efficacy of the proposed method.",0.17592592592592593,0.2602739726027397,0.20994475138121546
1866,SP:aa6d2086be2ef25c088c34228e64741115f133a6,"This paper introduces the General Language Understanding Evaluation (GLUE) benchmark and platform, which aims to evaluate representations of language with an emphasis on generalizability. This is a timely contribution and GLUE will be an impactful resource for the NLP community. This is mitigated, perhaps, somewhat by the recent release of decaNLP. But, as discussed the authors, this has a different focus (re-framing all tasks as QQ) and further does not feature the practical tools released here (leaderboard, error analysis) that will help drive progress.",The paper proposes a new benchmark for natural language understanding: GLUE. Models will be evaluated based on a diverse set of existing language understanding tasks which encourages the models to learn shared knowledge across different tasks. The authors empirically show that models trained with multiple tasks in the dataset perform better than models that focused on one specific task. They also point out existing methods are not able achieve good performance in this dataset and request for more general natural language understanding system. The work also collects an expert evaluated diagnostic evaluation dataset for further examination for the models.,0.16470588235294117,0.1414141414141414,0.15217391304347827
1867,SP:aabb111652a2063c12c8faf92abc12e446d5d377,"This paper delves into a stability analysis of reweighting and resampling for overcoming imbalanced data in supervised learning. Reweighting employs the use of importance ratios to modify a samples weight to the training in turn changing the effective distribution. There are several resampling procedures which all have a similar effect in the analysis, and the authors consider several algorithms for resampling in their experiments.  The reweighting approach, while convenient, leads to poorer stability under simplifying assumptions. While this is interesting in its own right, they show that under certain distributions of the data reweighting will actually not converge to the optimal minima, while resampling will. This is motivated by a large collection of work developing resampling methods for imbalanced data, which all come to similar conclusions (i.e. that following a resampling procedure outperforms a reweighting procedure in many, but not all, settings). They follow up with a SDE analysis in another toy problem, which they then extend to more realistic assumptions.","This paper provides an analysis of why resampling can be better than reweighting in some cases. By observing the behaviour of resampling and reweighting in simple optimizations with SGD, the theoretical results show that resampling tends to be more stable. The general analysis is based on SDE approximation. Experiments on classification and off-policy evaluation show that resampling can be better in some cases.",0.12345679012345678,0.3125,0.17699115044247787
1868,SP:aaef8d1191e00294b4906975362cb8f7f2bdea10,"The authors propose a new knowledge distillation method applicable to convolutional neural networks. Given the architecture of a student network, the teacher network is constructed by replacing each convolutional layer with a dynamic additive convolutional layer. In this way, the teacher network is guaranteed to be more capable than the student network. Then, the teacher and student models are trained together, minimizing their own training losses. In order to ""distill"" the student model, the student and teacher model are inter-connected in a way such that the student model receives gradient flow from the teacher network.","This paper suggests an interesting approach to knowledge distillation, which uses architectural properties rather than the loss function to encourage knowledge transfer between a teacher and a student. A student and teacher net are jointly trained on a prediction task, with forward connections from layers in the student net to layers in the teacher net. At test time, the teacher net can be stripped away. The method results in improvements in student performance compared to training the student without the teacher.",0.20833333333333334,0.24691358024691357,0.22598870056497175
1869,SP:aaf87fbde816b1f09befbefc7f9198022292e03a,"This work proposes a new framework, called LINGUINE, to produce high-quality sub-graphs that can assist in effective training of graph convolutional networks (GCNs) with a lower computational cost. The framework uses two consecutive components - (1) Bootstrapping, which learns a meta-model that can assign weights to nodes by being jointly trained with a proxy ‘light’ GCN model (2) Smart pruning, which uses the learned meta-model to perform pruning on the large graph as the GCN model trains on it using the student-teacher learning concept. The paper presents results that the bootstrapping method improves the accuracy of smaller GCN models on large graph classification tasks. The smart pruning method removes nodes that are hard to learn or have a high degree of neighboring nodes in the subgraph, thus reducing error. ","This paper proposes an approach to compute GNNs on pruned subgraphs. The authors use a ""meta-model"" to learn a good node pruning strategy during training. Then the meta-model is used to generate pruned subgraphs during inference. The proposed pruning algorithm can be applied to various graph samplers. The authors evaluate such pruning on two simple samplers, random node and random walk samplers.  Some theoretical analysis is performed. However, the analysis is not quite convincing. Evaluation on several graph benchmarks show that the proposed LINGUINE framework achieves good accuracy using pruned subgraphs. ",0.17293233082706766,0.24731182795698925,0.20353982300884954
1870,SP:ab030a8c07a5d9c3e0fa0a6b7cf224b4c23f68d1,"This work proposes a tree-based learning method for online 3D packing problem. Packing configuration tree nodes is constructed using heuristic-based tree expansion, which acts as the action space of deep reinforcement learning. The tree search schema is interesting, but this work still has lots of space to improve in terms of its methodology and experiments.","This paper addresses the problem of online 3D bin packing where the order of objects is out of the model's control and it must make placement decisions one object at a time. Training is framed as a deep RL problem closely following recent work [Zhao et al]. The main contribution is a rethinking of the state and action space which yields much better performance. Prior work trained models to predict placement in a voxelized grid that led to a large action space that could not scale well. Instead, this work represents existing objects and potential placement locations as nodes in a tree which are processed with a graph network. Given a new object, placement nodes can be heuristically instantiated to cover valid locations, and the model uses attention to output a distribution over these nodes and determine the object placement.",0.24561403508771928,0.09929078014184398,0.1414141414141414
1871,SP:ab1e96008989209a4c5423f723bfae327416e78a,"This paper is trying to bridge the gap between CNN and the human  visual system by proposing a metric  (angular visual distance) and validate that this metric is correlated to the human visual hardness and this metric has a stronger relation  compared to the softmax score which has been viewed as a metric measuring the hardness of images in CNNs. Furthermore, this paper proposed a reasonable explanation for this observation, i.e., the norm is possibly not correlated to the human visual hardness and validate through the experiment. Finally, this paper shows that this metric is also useful  in other applications. ","This paper defined Angular Visual Hardness (AVH) based on the angle between image feature embedding and the weights of the target class. The authors compared the correlation between AVH and human selection frequency with model confidence and feature norm. The results show that both AVH and model confidence have correlation, but AVH has a stronger correlation than model confidence. Differently from the conjecture of [41], feature norm was not correlated with human selection frequency. ",0.18811881188118812,0.25675675675675674,0.21714285714285714
1872,SP:ab387476cee484dbc8365b4d49cb597b14efac91,"This paper starts with the bold aim of extracting Montague's universal grammar from multiple languages. In order to do so, the authors train multiple language models where each LM is explicitly factorized into language-specific and language-independent representations. The authors then apply the GAN framework to the language-independent parts to enforce all languages to share the same latent space. The claim here is that the language independent parameters capture the essence of universal grammar. The authors show that their framework enables effective zero-shot learning of tasks over new languages (for example sentiment classifier learned on top of English data generalize to Chinese when trained on the universal grammar embeddings). ","This paper introduced a GAN-based method to learn language universal representations without parallel data. The model architecture is analogous to an autoencoder. The encoder is a compound of language-universal mapper plus a language-specific LSTM. For decoding, another language-universal module first map language-universal representation back to language-specific embedding space, then another LSTM decoder generates the original sentence. The authors used GAN to encourage intermediate representation to be language-universal. The authors tested the proposed method on zero-shot semantic analysis and NLI tasks and showed nice results.",0.18584070796460178,0.22826086956521738,0.20487804878048785
1873,SP:ab4f7885ce56867b46ac82f3ded3daa83f556c62,"The paper characterizes the intrinsic dimensionality of node features, graph structures, and representations learned by GNNs via the so-called Local Intrinsic Dimensionality (LID) measure, intending that it can benefit the community in understanding the difficulty of an underlying graph learning task. In addition, estimators for Feature LID (FLID), Structure LID (SLID), and Representation LID (RLID) were introduced. This work showed that real-world graphs have much lower intrinsic dimensionality when compared to their extrinsic dimensionality.  ","In this work, the authors investigate the Local Intrinsic Dimensionality (LID), especially the feature (FLID), structure LID (SLID), and Representation LID (RLID) of a graph. Through experimental analysis, the authors demonstrate that the FLID and SLID are well correlated with the graph complexity, and real-world graphs have a much lower intrinsic dimensionality. In addition, authors also interpret the over-smoothing problem associated with GNN models from the perspective of the SLID's convergence.",0.32894736842105265,0.33783783783783783,0.33333333333333337
1874,SP:ab4fbcfc2199b778ff071e8ccff33efc8c37e351,"The authors propose in this paper a new unsupervised graph representation learning method. The method leverages recent advances in graph coarsening, mainly Loukas' method. The key idea of the method consists in using a reconstruction target that is not the classical one in an auto-encoder setting. More precisely, the encoder takes as an input the original adjacency matrix and node features but the decode only aims at reconstructing the coarse adjacency matrix (obtained via Loukas' method). ","This work proposes an unsupervised hierarchical graph representation learning method, named BayesPool. The method learns a coarsening sequence of graphs together with the corresponding node representations. The coarsening sequence is learned using the method in Loukas (2019). The node representations are learned using an encoder-decoder structure, where the encoder encodes a graph to coarsened node representations, and the decoder decodes the node representations to a coarsened graph. The adopted objective function is analogous to VAE, except that the decoder does not aims to reconstruct an identical graph. Experiments on graph classification is performed on 5 different datasets, and competitive accuracy is achieved.",0.2857142857142857,0.21359223300970873,0.2444444444444444
1875,SP:ab5deaa838db01236f0d3db05b39e2f10e39184b,"This paper proposes to provide a novel gradient-based meta-learning framework (Meta-Graph) for a few shot link prediction task. More specifically, they generate an effective parameter initialization for a local link prediction model for any unseen graph by leveraging higher-order gradients and introducing graph signature function into graph neural network framework. The authors validate the proposed model through several experiments.","Overview: In this paper, a meta-learning approach is proposed to perform link prediction across multi-graphs with scarce data. To do so, each graph is treated as a link prediction ""task"". Different from the tasks in conventional meta-learning, the graphs here are generally non i.i.d. Based on the variational graph auto-coders, the method learns two important components: the global parameters used for GNNs and a graph signature function used to modulate the parameters of inference model based on the history of observed training graphs. ",0.2698412698412698,0.19101123595505617,0.22368421052631582
1876,SP:ab6f2c56bfe6fb6c479345d113e647ba9acf2035,"PAPER SUMMARY: This paper addresses the problem of encoding and decoding 3D chemical structures, with the ultimate goal of generating 3D crystal structures. The authors propose an auto-encoder framework for encoding the 3D locations of atoms in the crystal to a latent representation and then decoding that representation back into 3D structure. The paper's contributions can be summarized as follows:",The authors describe a method to encode and decode the position of atoms in 3-D molecules. An encoder-decoder architecture is used to create a representation of a molecule and to reconstruct the molecule from its representation. Then a second Neural Network segments the output and assigns an atomic number. Prior work on this task has used 1D (SMILES) and 2D (Graph) representations. The authors argues that exploiting 3D structure can create better representations.,0.24193548387096775,0.2,0.21897810218978103
1877,SP:aba5a1845cf2e38d592d640278f9ed0134a3d96d,"The paper introduces a novel way of learning Hamiltonian dynamics with a generative network. The Hamiltonian generative network (HGN) learns the dynamics directly from data by embedding observations in a latent space, which is then transformed into a phase space describing the system's initial (abstract) position and momentum. Using a second network, the Hamiltonian network, the position and momentum are reduced to a scalar, interpreted as the Hamiltonian of the system, which can then be used to do rollouts in the phase space using techniques known from, e.g., Hamiltonian Monte Carlo sampling. Finally, a decoder network can use the system's phase space location at any rollout step to generate images of the system. The HGN can further be modified, leading to a flow-based model, the Neural Hamiltonian Flow (NHF).","The authors present a method for learning Hamiltonian functions that govern a dynamical directly from observational data.  The basic approach uses three networks: 1) an inference network (I'm not clear why this is not just called an encoder), that maps past observations to a latent p,q space in a VAE-like fashion; 2) a Hamiltonian network that governs the time-evolution of the system over this latent state; and 3) a decoder network that outputs the observation from the latent state.  In addition to introducing this basic formalism, the ",0.20300751879699247,0.2967032967032967,0.24107142857142855
1878,SP:abd06100a48b4b5467cd63cd024d6387d163f96a,"This paper proposes an observation factorization method to avoid the influence of the irrelevant part on value estimation. Specifically, they design an entity-wise attention network with a masking procedure. This network is used to filter the irrelevant part of the original observation of each agent. Then the output is used to estimate the individual q-value, as well as input to the mixing network to generate the Q_tot. Two kinds of Q_tot are trained together by combing two loss functions linearly with a hyper-parameter. Experimental results show REFIL combined with QMIX surpasses vanilla QMIX and VDN in several SMAC scenarios.","This paper proposes to incorporate a masked attention mechanism in QMIX for value function factorization to disentangle value predictions from irrelevant agents/entities. The masking is based on a random sampling from the whole set of agents to from random subsets, based on which it can compute within-group and without-group Q-functions. The method is able to handle varying types and number of agents. The paper conducts experiments on a simple game to understand the effect, and then test on 3 SMAC games, which shows the effectiveness of the proposed REFIL method.",0.18269230769230768,0.20212765957446807,0.1919191919191919
1879,SP:abd06d2f55908d07477bc45cfd4f5bd474fb84c8,"This paper proposes POLAR, a reachability analysis framework for neural network-controlled systems. POLAR improves the previous Taylor model overapproximation approach in two aspects: 1) use Bernstein polynomial to overapproximates activation function; 2) use symbolic remainders to mitigate the so-called wrapping effect, that is, instead of computing an overapproximated interval at each step, keep track of linear transformation matrices to delay overapproximation as late as possible. The experimental evaluation compares POLAR with three other recent work and shows that POLAR achieves the best performance on almost all tasks.",The authors attack a significant problem or bounded-time reachability analysis of neural-network controlled systems (NNCSs). The method allows for verification of decision-making procedures applied by trained neural networks to systems with the known continuous model (continuous plants).  The claimed main novelty of the paper is the application of the basic Taylor Model arithmetic in combination with the univariate Bernstein polynomial interpolation to handle non-differentiable NN activation functions.  The algorithm is tested in a set of benchmarks introduced in the other related work.   The main theoretical result states that the TM flow pipes computed using the POLAR approach are state-wise approximations for the reachable sets.  ,0.2696629213483146,0.22018348623853212,0.24242424242424243
1880,SP:ac1536424c9e62fa3ea6c40507a90a720679b23d,"The authors learn structured communication patterns between multiple RL agents. Their framework uses a Structured Communication Network Module and Communication-based Policy Module. These use a hierarchical decomposition of the multi-agent system and a graph neural network that operates over the resulting abstract agent (groups). The authors evaluate on two environments, where this approach outperforms other ways to communication protocols.","This paper proposes a method of learning a hierarchical communication graph for improving collaborative multi-agent reinforcement learning, particularly with large numbers of agents. The method is compared to a suitable range of baseline approaches across two complex environments. The initial results presented seem promising, but further work is needed to ensure the results are reproducible and repeatable.",0.14754098360655737,0.15517241379310345,0.15126050420168066
1881,SP:ac3bde5bb8c4674166478734b66c277fc74f5053,"This paper proposes a new method for post-hoc correction in long-tailed recognition. Specifically, they leverage the idea of optimal transport (OT) and propose a linear mapping to replace the original exact cost matrix in OT problem. From the experiments, the proposed method can be combined with existing methods and boost their performance further. ","This paper contributes an extension of post hoc correction of long-tailed recognition with Optimal Transport (OT). Unlike the previous work (e.g. logit adjustment) which focuses on sample-wise correction, this work, on the other hand, considers the marginal distribution of the overall data for correction. The method is further extended by learning a cost matrix. Their experiments show the effectiveness of optimal transport in the long-tail recognition problem via comprehensive comparison with previous works in terms of performance and efficiency.",0.32727272727272727,0.21686746987951808,0.2608695652173913
1882,SP:ac5c618268cfa8b094aa4c7906c3bc6427035da5,"This paper studies model privacy and its privacy and utility tradeoff. In particular, the authors proposed information laundered model where the input and output of the true model are perturbed.  The objective is to minimize the KL divergence between the true model and laundered model with mutual information between input and output as constraints. Theoretically, they show the optimal condition of the above optimization problem and provides an iterative algorithm.","This paper aims to tackle the problem of model stealing/extraction, as in stealing a model that is deployed remotely, through API access. The threat model that they are aiming to protect against is not well-defined. The proposed method is information theoretic. They propose adding two modules (kernels) before and after the main deployed model, to ""launder"" information.  The loss function for achieving the desired modules consists of two main terms, for utility, and privacy of the model. The utility term tries to keep the expected value of the output being accurate high, while the privacy term (which are actually two terms for the two modules) try to decrease the MI between the true output/input and the laundered ones. They then offer an iterative approach for minimizing the loss. ",0.35714285714285715,0.19083969465648856,0.24875621890547264
1883,SP:ac65606f8823adff500d1e14e4f7fe5cac4e5b48,"This paper studies the positional encoding in BERT. It argues against the word—position correlations that are implicitly imposed by BERT’s treatment of positional encodings. The paper proposes to decouple the “content attention” (token to token) and “contentless attention” (position to position), and remove the so called heterogeneous interactions between tokens and positions. Further, it points out that it is problematic to treat the special [CLS] symbol as a token in calculating its positional encoding: per standard practice, [CLS]’s representation is used as a summary of the full sequence, and treating it as a token implicitly biases the sentence representation towards those tokens close [CLS]. To resolve this issue, the paper “hides” the position information of [CLS]. The proposed approach is built on top of BERT and evaluated on  the GLUE benchmark. Experimental results show that it outperforms the baselines.","The paper delves into the nature of positional encoding in Transformer and variants (especially BERT). The paper points out that, attention weight computation obtained from the addition of the word embedding and the position embedding in the first layer can be expanded into four terms, namely word-word, position-position, and two word-position (in both directions). The paper points out that word-position relationship is largely meaningless, which is also demonstrated via visualizing the values in pertained BERT. Then the paper proposes to remove these two terms when computing the attention. Secondly, the paper mentions that special tokens in BERT (e.g. [CLS]) should be treated in a different way than typical words. To do so, it proposes to replace the attention logic with a learnable parameter if the attention involves one or two special tokens. Both methods combined show a significant advantage on multiple GLUE tasks when applied to BERT.",0.21830985915492956,0.20394736842105263,0.2108843537414966
1884,SP:ac74f77f4d4c8c6c2ca9304bb1050aa22a87df63,"This paper presents a method for controlled text generation by using a new loss function (standard VAE loss with auxiliary losses added on). The method is tested on style transfer datasets: Yelp and Amazon. The central hypothesis is that when manipulating latent codes of a VAE, you can end up in low-density regions of the aggregated posterior. Such latent codes are rarely seen by the decoder so that quality of generation is low. To address this problem, they constrain the posterior mean to a learnt probability simplex and try to ensure that the simplex is densely filled. They do this by adding 2 regularizing losses to the VAE loss.","The paper ""On Variational Learning of Controllable Representations for Text without Supervision"" tackles the problem of latent vacancy of text representation via variational text auto-encoders. Based on the observation that a single factor of the sentence encoding gathers most of relevant information for classifying the sentence as positive or negative (sentiment classification), authors study the impact of manipulating this factor in term of the corresponding decoded sentences. They reasonnably claim that if such a manipulation fails at decoding accurate sentences, it is because we fall in representation areas that the decoder never seen during training. Thus they propose a way to constrain the posterior mean to a",0.19090909090909092,0.19444444444444445,0.1926605504587156
1885,SP:ac7517dabc5ac45ae486f427a2efeeed0191e5e7,"In stochastic convex optimization (SCO) characterized by the following objective for convex $f$, $$\min_w f(w) := \mathbb{E}_{\xi\sim \mu}[F(w; \xi)],$$ we typically assume repeated access to the noise distribution $\mu$, for sampling i.i.d. random variables $(\xi_t)_t$. This access can be used to obtain unbiased estimates $\nabla F(w; \xi_t)$ of the true gradient $\nabla f(w)$. This oracle access can be used to implement stochastic gradient methods, which are well studied and known to have optimal sample complexity under certain regularity conditions.   On the other hand in online convex optimization, at each time step, we obtain a loss function $f_t$ from some function class $\mathcal{F}$, and we have to minimize some notion of regret. This can be modeled like SCO by defining, $f_t:= F(.; \xi_t)$, but since there was no restriction on $f_t$'s, the $\xi_t$'s here can have arbitrary dependencies over time. In particular, they could be chosen adversarially.   In between both these extremes is the setting where $\xi_t$ could have some dependency structure. One such structure called $\phi$-mixing was introduced by [Agarwal and Duchi](https://arxiv.org/abs/1110.2529). Under this dependence assumption, they provide upper bounds on the convergence of SGD. This paper generalizes these upper bounds to a sub-sampling variant of SGD as well as mini-batch SGD. It shows that mini-batch SGD essentially attains the $1/\epsilon^2$ sample complexity of for i.i.d. sampling when there is a low level of dependence in $\xi_t$'s, and more generally improves over vanilla SGD across various levels of dependence captured by the $\phi$-mixing assumption.","This paper studies the sample complexity of a few variants of SGD in solving optimization problems over dependent data. The dependent data introduces non-negligible bias in SGD that slows down convergence of the algorithm, and this paper adopts \phi-mixing data dependence models, to quantify the level of dependence in the queried samples, and analyze how much the convergence of SGD can be slowed down in terms of the phi-mixing model. Then, this paper demonstrates the benefits of SGD with subsampling and mini-batch SGD over SGD for dependent data. ",0.09187279151943463,0.2826086956521739,0.1386666666666667
1886,SP:acba0ca082c22db2db7c00b34356c0e7ef5d601d,"This paper proposes an approach to introduce interpretability in NLP tasks involving text matching. However, the evaluation is not evaluated using human input, thus it is not clear whether the model is indeed meeting this important goal. Furthermore, there is no direct comparison against related work on the same topic, so it is not possible to assess the contributions over the state of the art on the topic. In more detail:","This paper tackles the problem of generating rationales for text matching problems (i.e., two pieces of text are given). The approach is in a similar spirit as (Lei et al, 2016) while the latter mainly focuses on one piece of text for text classification problems and this work focuses on generating pairs of rationales. The approach has been evaluated on NLI and QA datasets, which demonstrates that the generated rationales are sensible and comes at a cost of accuracy.",0.19718309859154928,0.175,0.18543046357615892
1887,SP:acbe524115cdc77725ef17505a7134d70720f7c6,"In this paper, the authors try to prove that overparametrized RNNs can efﬁciently learn concept classes consisting of one-hidden-layer neural networks that take the entire sequence of tokens as input. The training algorithm used is SGD with sufﬁciently small step size. Conceptually and technically, the introduced new ideas enable us to extract information from the hidden state of the RNN, which addresses a crucial weakness in previous work. In the end, the authors illustrate their results on some regular language recognition problems.","Reference [37] demonstrated that that SGD learns the recurrent weight matrix of an RNN with provable generalization if the number of training sequences is at least polynomial in the logarithm of the number of hidden nodes, and if the target function computes, at each time step, a sum of differentiable functions of linear transforms of previous  time steps.  This paper uses the same notation, and many of the same methods, but significantly extends the previous work  in the following way: the function class that can be computed is significantly expanded, to include sums of differentiable functions of linear transforms of the __concatenated sequence__ of inputs, not just transforms of individual inputs. In order to do so, this paper cosiders bounds on the input matrix (A) and recurrent matrix (W) sufficient to encode the entire sequence of inputs into the state vector.",0.20930232558139536,0.1276595744680851,0.15859030837004406
1888,SP:ad01c6b1219ff781129a7985c073e72ba5967763,The paper proposes a hybrid weights representation method where the weights of the neural network is split into two portions: a major portion of ternary weights and a minor portion of weights that are represented with different number of bits. The two portions of weights are differentiated by using the previous unused state of a typical ternary neural network since only three states are used out of the four states given 2-bit representation. The experiments are solid based on the selected baseline model on CIFAR-100 and Imagenet dataset.,"This paper is about quantization, and how to represent values as the finite number of states in a low bit width, using discretization. Particularly, they propose an approach to tackle the problems associated with previous ternarization which quantize weights to three values. Their approach is a hybrid weight representation method, which uses a network to output two weight types: ternary weight and sparse-large weights. For the ternary weight, they need 3 states to be stored with 2 bits. The one remaining state is used to indicate the sparse-large weight. They also propose an approach to centralize the weights towards ternary values. Their experiments show that their approach outperforms other compressed modeling approaches, and show an increase in AlexNet performance on the CIFAR-100 while increasing model size by 1.13%. ",0.24444444444444444,0.16666666666666666,0.1981981981981982
1889,SP:ad02657d8b6e822881aac3b489431e1ee0afeddc,This paper proposes to use the shift operation (Wu et al. CVPR 2018) in an axial manner for MLP-mixer architectures. The proposed method performs much better than previous MLP-based methods on ImageNet-1K and on par with Swin-transformer.,"The paper proposes a new architecture for computer vision that is inspired by (a) the Swin Transformer, (b) MLP-Mixer (and colleagues) and (c) CNN-like local context via shifts (like Shift, TSM, ViP, S2-MLP). The architecture is based on the Swin Transformer, removes the windowed-attention, and then adds ""local shifts"" of channels to introduce local context via MLP. The architecture is applied to ImageNet-1k classification, COCO detection, and ADE20k segmentation with good results relative to model size and performance. ",0.2926829268292683,0.14457831325301204,0.1935483870967742
1890,SP:ad18caffc90d3a99ed577cf062129c84dfccf57d,"The paper considers the problem of label recovery from data clustering. Generally speaking, these two tasks are unrelated: the label recovery is a supervised learning problem, where each data point has a unknonwn true label, and the goal is to infer the label for each data point; while the clustering problem is to group data together to minimize the generalized $k$-means cost (i.e., replace $\ell_2$-error with $\ell_p$-error in traditional $k$-means), which usually has nothing to do with labelings. Although the former task also induces a clustering (in which data points with the same label belongs to the same cluster), it can be a very bad solution for the later task, and vice versa. To distinguish, for a given data set, we say a clustering is a **true clustering** if it recovers the unknown labeling (up to permutations); while we say it is an **optimal $k$-means clustering** if it solves the second task, i.e., minimizes the generalized $k$-means cost function.  The paper shows that, when the *true clustering* satisfy certain regularity conditions, it can be recovered (up to ""refinement"") by (an $O(1)$ approximation to) the \emph{optimal $k$-means clustering}. The paper defines a **refinement** of labeling $z\in[K]^n$ to be another labeling $\tilde{z}\in[L]^n$ together with a mapping $\omega:[L]\mapsto[K]$, such that $\omega(\tilde{z}_i)=z_i$ for all $i\in[n]$. Intuitively one can think of this as breaking the *true clusters* further into multiple smaller clusters.  Per my understanding the main result can be summarized as follows. When the true clustering is itself a good clustering with respect to the generalized $K$-means cost (Theorem 1 and 2), or if the true clustering can be broken into $L>K$ smaller clusters which have small $L$-means cost (Theorem 3), then an $O(1)$-approximation for the optimal $L$-means clustering is also a good approximation for the true clustering, in the sense that it approximately induces a refinement of the true labeling. ","This paper considers the problem of label consistency in the generalized k-means problem in an overfit situation where the number of clusters $L$ used by a given clustering algorithm is more than the ground truth $K$.  The main contributions are:  1. Theoretical guarantees the above problem, under certain assumptions on the clustering algorithm, for both  exact and approximate label recovery. To the best of my knowledge, this is the first result in the context of the k-means problem.  2. The results are model-free, but strongly depend on the maximum or average distance of the points to true cluster center.  ",0.11078717201166181,0.37254901960784315,0.17078651685393256
1891,SP:ad4ab0f3fa32fd60cf01ee69259206d6d6f4ed22,"This paper focus on model-based RL on a POMDP setting (they call it ""meta RL""), where the policy and model need to infer the current hidden state according to history. It provides a theoretical relation between true environment returns and the returns from learned models in a POMDP setting. And it also provides a practical algorithm called M3PO and shows this algorithm is more sample efficient than some meta-RL baselines in some continuous control tasks.","The paper concerns model-based meta-RL. It exploits the fact that meta-RL can be formulated as POMDP in which the task indicator is part of the (unobserved) hidden state. Thus, the paper effectively analyzes and proposes model-based algorithms for POMDPs. The paper bounds the gap between the expected reward of a policy in the actual POMDP and the estimated model and then theoretically shows that this gap can be reduced when using dyna-style / branched rollouts instead of full rollouts under the learned model. Motivated by this finding, the paper proposes a Dyna-like algorithm for POMDPs. In the experimental evaluation, the paper compares its proposed method, M3PO, to two recent meta-RL approaches in a range of meta-RL environments for continuous control.",0.3246753246753247,0.1968503937007874,0.24509803921568632
1892,SP:ad4e8d1e16eeeff006f8568bd6bf2c0862621526,"This paper propose to study the generalization properties of GANs through interpolation. They first propose to learn a linear (and non-linear) interpolation in the latent space for a specific type of image transformation for example zoom, translation, rotation, luminance, etc... They show that linear interpolation in GANs can produce really realistic images along the path and enable to control and transform generated images to some extent. They then propose to measure to what extent the generated images can be transformed without ""breaking"".  Finally they show that the quality of the interpolation can be improved by learning the interpolation and generator jointly.","This work explores the extent to which the natural image manifold is captured by generative adversarial networks (GANs) by performing walks in the latent space of pretrained models. To perform these walks, a transformation vector is learned by minimizing the distance between transformed images and the corresponding images generated from transformed latent vectors. It is found that when traversing the latent space of the GAN along the direction of the transformation vector, that the corresponding generated images initially exhibit the desired transform (such as zooming or changing X position), but soon reach a limit where further changes in the latent vector do not result in changes to the image. It is observed that this behaviour is likely due to bias in the dataset which the GAN is trained on, and that by exploring the limits of the generator, biases which exist in the original dataset can be revealed. In order to increase the extents to which images can be transformed, it is shown that GANs can be trained with an augmented dataset and using a loss function that encourages transformations to lie along linear paths.",0.27450980392156865,0.15135135135135136,0.1951219512195122
1893,SP:ad5a9c6598151e60f84bf54984621a3832276c14,The paper proposed a multi-agent Q Learning algorithm with an entire IGM function class for cooperative games. The key idea is to leverage a duplex dueling network architecture to factorize the joint action-value function into individual action-value functions. The main contributions of the work lie in that the proposed method offered an highly scalable algorithms for cooperative tasks. Empirical results show that the method could achieve significant improvement in StarCraftII tasks.,"This paper proposes a novel value decomposition approach to learn decentralized Q function in multi-agent setting. This idea is to follow Individual-Global-Max (IGM) principle. The main contribution is to use dueling structure (Q_i = V_i+A_i) for each agent i, and separately combining advantage/value terms respectively to form a centralized Q and A terms for training. Such combinations keep the positive correlation constraint between Q_tot and individual agent Q_i in QMix (i.e,. \partial Q_{tot} / \partial Q_i > 0) via positive trainable module in neural network, implemented by multi-head attention, etc. ",0.1891891891891892,0.13861386138613863,0.16
1894,SP:ad8e2fe49ecd290848c910422f8ba49924d31065,"Summary of paper: - The authors identify a problem of ""capacity loss"" during RL training with neural networks, this is the problem of agents gradually losing the ability to fit new functions while trainig.  - The authors argue this is a key factor that hinders learning and is most prominent in sparse reward environments, propose 2 different measures of capacity loss and conduct empirical analysis to show this phenomenon exist in some Atari tasks.   - The authors present a number of empirical analysis on this problem, and propose a simple regularization scheme to mitigate this issue, and presented some analysis on the effect of this scheme, giving interesting insights.  - The proposed method improve performance especially on Montezuma's revenge when no specialized exploration techniques are used, supporting the paper's claims","Summary: - Over course of training, deep RL agents experience ""capacity loss"", where networks are unable to quickly fit new functions. This problem is further exacerbated by non-stationary predictions (such as bootstrapping) over the course of training. - To prove this problem, the author runs two experiments (Atari and MNIST), and show that training error against a randomly-initialized network increases over time. They also define effective dimension (rank of feature space) and show that effective dimension is tightly correlated with performance. - The authors introduce INFER, which regularizes Q-value loss with error w.r. to randomly initialized network, and evaluate this on Atatri-57, showing most benefits in sparse reward environments (Montezuma's revenge)",0.1953125,0.21929824561403508,0.20661157024793386
1895,SP:ad9f47b416f144d43c2c4f66599529e1bb49bca6,"The authors analyze the use of image transformation as a defense against adversarial examples, where a challenge is to prevent the deterioration of performance on clean images. To do this, they show that the softmax distributions for clean and adversarial images share similar ""features"", and therefore one can apply a trained distribution classifier which takes the softmax distribution to return the class label. This is as opposed to original approach of making a prediction for each sample (a random transformation of the input image) followed by majority voting.","This paper presents a novel defense method to make the classification more robust. The motivation is based on the observation: the distribution of the soft-max for the cleaned image and its transformed images for one class is similar to the distribution of the soft-max for the adversarial image and its transformed images for the same class, and the distributions of the soft-max for the cleaned image and its transformed images for different classes are different. Then, a distribution based method is proposed to classify the distribution of the soft-max for the cleaned (or adversarial) image and its transformed images. ",0.25,0.21359223300970873,0.23036649214659685
1896,SP:ada3d3555f409cc84a060f81d2e4934459fa731f,"Building on top of the domain randomization principle (used to train policies robust to domain-variations) to learn policies which transfer well to new domains, the paper proposes an approach to improve and speed-up learning / training over randomized environments. The paper operates in a settings where the policy to be transferred only has access to observations -- images, etc -- and not the complete underlying state of a (simulated) environment. The underlying idea is to -- (1) maintain two sets of actor-critic networks - a symmetric pair where the actor has access to the underlying state and an asymmetric pair where the actor has access only to image observations; (2) evenly gather experiences from behavioral policies of both actors and store them in a shared replay buffer and (3) learn to align the attention placed by the policies over objects in the environment for the state and observation based actors. The idea is to leverage privileged information about the state (which is strictly more informative compared to observations) to learn robust observation based policies. Experimental results indicate the proposed approach improves generalization performance compared to several ablations of the same on both in-distribution and out-of-distribution environments.","The topic addressed by the paper is domain adaptation and transfer learning in the text context of deep reinforcement learning, in particular the “sim2real” problem, where a policy is learned in simulation and should be transferred to a physical agent in a real-world scenario. The work builds on the existing “asymmetric DDPG” formulation (Pinto et al., 2017), which exploits the fact that full states are sometimes available in simulated environments but not during deployment. In Pinto et al., this is addressed by learning an actor taking as input observations, and a critic which has access to the state.",0.12690355329949238,0.25252525252525254,0.1689189189189189
1897,SP:adad16c183ae1c2806036fef3ae2f6038943ee33,"The paper gives ""almost private"" algorithms for problem of sign recovery of mean vector and of linear regression. The techniques follow their general framework of Median DC, which is similar to the well-known median-of-means approach. They give theoretical guarantees for the same, along with empirical results comparing with known differentially private algorithms and their non-private counterparts.","The paper considers the sign recovery problem in a distributed setting with privacy constraints. The paper proposes an algorithm “median divide-and-conquer (Med-DC)” which takes the sign locally in each machine and then takes the median globally. The paper shows that in the sparse mean estimation setting, Med-DC is correct with high probability under some assumptions and Med-DC satisfies a weaker notion of differential privacy proposed by the paper. The paper then extends this algorithm to the sparse linear regression setting. ",0.21666666666666667,0.15294117647058825,0.17931034482758623
1898,SP:adb7cbd7634b46d7388ac172ef3fbb03c89e6188,"This paper studies bandits and RL settings subject to a conservative constraint where the agent has to perform at least as well as a given baseline policy. It improves the existing lower bound for conservative MAB, and as the main contribution, obtains new lower bounds for conservative linear bandits, tabular RL and low-rank MDP. It also provides new upper bounds matching existing ones with different analyses.","This paper proposes a reduction-based framework for a large class of reinforcement learning algorithms, including bandits, linear bandits, tabular MDP and linear MDP. The authors notably propose a generic lower bound that holds for all the studied class of algorithms. The lower bound is built on the regret decomposition between the regret of the conservative baseline during the time when the budget is not reached, and the regret of a non-conservative algorithm that learns on the baseline. While the obtained lower in the bandit setting is not as tight as the one obtained in (Wu et al, 2016), this lower bound holds for a larger class of algorithms. Then, two generic algorithms are proposed for handling conservative reinforcement learning. Budget-Exploration consists in learning the non-conservative algorithm on the conservative baseline during a fixed period of time and then to play the non-conservative algorithm. The regret upper bound of Budget-Exploration matches the lower bound, but the knowledge of the baseline gap is need. The second algorithm LCBCE does not necessitate that the baseline gap be known. The idea of the algorithm is to compute an upper bound of the budget thanks to the lower bounds of rewards obtained by the non-conservative algorithm run on the baseline. The regret upper bound of LCBCE still matches the proposed lower bound. ",0.29850746268656714,0.08928571428571429,0.1374570446735395
1899,SP:ade2bc3c672043e09debf5ff560deb6eb9c16c1d,"The paper combines the FNO architecture with hypernetworks to learn the solution operator (flow map) of Markovian PDE systems. A hypernetwork whose input is the time domain (\R_+) is trained to output  the weights of a FNO which then acts on an initial condition to produce the PDE solution at the time  input to the hypernetwork. Training is done by uniformly sampling random times on a bounded input domain and exploiting the Markov property of the flow map, allowing to use as data only the initial condition  and the solution at a final time without a need for the entire time series. Numerical experiments showing  a modest improvement over the standard FNO are performed on the 1-d Burgers' equation, generalized Burgers' equation, and the Chafee–Infante equation as well as on the 2-d Burgers' equation, and the Navier-Stokes equation.","The paper presents a model and a loss function for approximation of the solution map of certain partial differential equations.  The idea is to use HyperNetworks: the mapping of the initial condition to time t done by model f($\theta$, x), and the parameters are predicted by another neural network. The models utilize the recently proposed Fourier Neural Operator (FNO) for the mapping model, and a fully-connected network for the hypernetwork. Several losses are proposed to ensure consistency of the proposed models, including the composition and reconstruction. The tests are done on a battery of examples, and compared to other neural network baselines the error is smaller. A theorem is proved, but is rather straightforward.",0.22535211267605634,0.27586206896551724,0.24806201550387594
1900,SP:ade8b6f55fb99d8ecca4a15e776cda7d570ad7c9,"This paper introduces a novel architecture for sequence modeling, called the trellis network. The trellis network is in a sense a combination of RNNs and CNNs. The authors give a constructive proof that the trellis network is a special case of a truncated RNN. It also resembles CNNs since the neurons at higher levels have bigger receptive fields. As a result, techniques from RNN and CNN literature can be conveniently brought in and adapted to trellis network. The proposed method is evaluated on benchmark tasks and shows performance gain over existing methods.","The authors propose a new type of neural network architecture for sequence modelling : Trellis Networks. A trellis network is a special case of temporal convolutional network with shared weights across time and layers and  with input at each layer. As stated by the authors, this architecture does not seem really interesting. The authors show that there exists  an equivalent Trellis Network to any truncated RNN and therefore that truncated RNN can be represented by temporal convolutional network. This result is not surprising since  truncated RNN can be  unrolled and that their time dependency is bounded.  The construction of the Trellis Network equivalent to a truncated RNN involves sparse weight matrices, therefore using full weight matrices provides a greater expressive power. One can regret that the authors do not explain what kind of modelling power one can gain with full weight matrices. ",0.29347826086956524,0.19148936170212766,0.23175965665236054
1901,SP:adf55a0c96d1e5ffb8016b8bec41aa0caca79793,"This work introduces a method to select instances from any set (stochastic subset selection, or SSS). The experiments demonstrate a diverse set of use-cases, including feature selection and core-set selection. The proposed approach is a two-stage method involving candidate selection (learning a function $\rho$ to determine a Bernoulli probability for each input) and AutoRegressive subset selection (learning a function $f$ to generate probabilities for sampling elements from a reduced set); both stages use the Concrete distribution to ensure differentiability.","This paper proposes a stochastic subset selection method for reducing the storage / transmission cost of datasets. The proposes method minimizes the expected loss over selected datasets. The data selection algorithm consists a candidate selection stage and an autoregressive selection stage, parameterized with neural networks, and are trainable by gradient methods. The authors formulate and tested their approach on four tasks. The problem formulation and methodology are technically sound. The proposed method also seems to be more general than competing methods, such as coreset.",0.1951219512195122,0.1927710843373494,0.19393939393939394
1902,SP:adf60fe287e9fcb67401f89701ba88b199df8700,"This paper suggests to use a generative model to address the problem of 'few shot' incremental learning. The idea is to classify input data by maintaining a population of prototypes and measuring the distance of the examples to be classified from these prototypes. As, each prototype represents a class, an example to be classified is assigned to the class of the closest prototype.  The learning of the neural network transforming input data to the prototype space is learned using 2 loss functions: the first one maximizes the margin between the distance to the prototype of the correct class and the other prototypes, the second one makes the clusters as compact as possible.","This paper proposes a nonparametric method in deep embedded space to address incremental few-shot learning problems. By compressing the learned tasks into a small number of reference vectors, the method could add more reference vectors to the model for each novel task, which could alleviate catastrophic forgetting and improve the performance of related tasks. Finally, this paper evaluates the proposed method on the classification and regression problem, respectively.",0.16964285714285715,0.2753623188405797,0.20994475138121546
1903,SP:ae14d964a70036123901e571f100da89e7f59ec6,"The paper aims at a better understanding of the positive impacts of Batch Normalisation (BN) on network generalisation (mainly) and  convergence of learning. First, the authors propose a novel interpretation of the BN re-parametrisation. They show that an affine transform of the variables with their local variance (scale) and mean (shift) can be interpreted as a decomposition of the gradient of the objective function into a regressor assuming that the gradient is parallel to the variables (up to a shift) and the residual part which is the gradient w.r.t. to the new variables. In the second part of the paper, authors review various normalisation proposals (differing mainly in the subset of variables over which the normalisation statistics is computed) as well as the known empirical findings about the dependence of BN on the batch size. The paper presents an experiment that combines two normalisation variants. A further experiment strives at regularising BN for small batch sizes.","The primary technical contribution comes from Section 2, where it is demonstrated that the normalized back-propagated gradients obtained from a BN layer can be viewed as the residuals of the gradients obtained without BN regressed via a simple two-parameter model of the activations.  In some sense though this result is to be expected, since centering data (i.e., removing the mean as in BN) can be generically viewed as computing the residuals after a least squares fit of a single constant, and similarly for de-trending with respect to a single independent variable, in this case the activations.  So I'm not sure that Theorem 1 is really that much of an insightful breakthrough, even if it may be nice to work through the precise details in the specific case of a BN layer and the relationship to gradients.",0.16981132075471697,0.19148936170212766,0.18
1904,SP:aeb3b57c2e2f7f7dfba24ee77e4aab2f445b947f,"In the paper, the authors proposed a novel privacy-preserving defense approach BAFFLE for federated learning which could simultaneously impede backdoor and inference attacks. To impede backdoor attacks, the Model Filtering layer (i.e., by dynamic clustering) and Poison Elimination layer (i.e., by noising and clipping) were presented respectively for the malicious updates and the weak manipulations of the model. To thwart inference attacks, private BAFFLE was built to evaluate the BAFFLE algorithm under encryption using secure computation techniques.",This paper provides an interesting research direction for the cross-domain of federating learning and backdoor attacks. This direction has very limited work until the recent 2 years. The work being proposed in this manuscript is simple and straightforward to implement. The pipeline has been clearly demonstrated. The experiments have multiple aspects presented and show promising results in various metrics.,0.1375,0.18333333333333332,0.15714285714285714
1905,SP:aeb3da5e74ad99557ef60627ab355b6402a88e77,"The paper studies density ratio estimation (DRE), addressing the 'train-loss hacking' problems which often arise and hamper estimation when models are too flexible. The authors propose a new risk estimator for DRE, providing a non-negative Bregman divergence estimator, with the non-negative correction. Theoretical analyses are shown with the estimation error and empirical analyses are examined in multiple machine learning problem settings.  ","The paper addresses learning the ratio between two densities from their samples, with applications to outlier detection and covariate shift adaption. An existing approach is to minimize the Bregman (BR) divergence's empirical approximation while modeling the density ratio function $r^*$ by a flexible hypothesis family, such as neural networks (NNs). A particular issue of such an approach (that the present work aims to resolve) is ""train-loss hacking,"" meaning that the empirical loss can become arbitrarily large and negative. A new loss/objective based on BR divergence has been proposed, appearing on page 4, and is referred to as $\widehat{\text{nnBR}}_f(r)$. The major theoretical result, Theorem 1, states that minimizing the proposed objective effectively minimizes the BR divergence for sufficiently large sample sizes. Following this theorem and its corollary, the paper presents empirical evaluations, showing the new algorithm outperforms prior ones on standard datasets.",0.265625,0.11486486486486487,0.16037735849056606
1906,SP:aebc7fd9042d95e9ee3d1baf909b5267e0a10775,"This paper tackles the problem of temporal action proposal generation (TAPG). The authors address the problem from two perspectives: features wise and score fusion wise. They use non-local blocks to integrate appearance features and motion features together. For score fusion, they propose transformer based module to incorporate long range temporal information. The proposed method is evaluated on two benchmark datasets and achieved state-of-the art performance.","In general, it is an interesting paper to utilize multiple techniques to enhance two-stream features and transformer to improve proposal scores, though all the techniques are not first proposed in this paper. But some technical details are not clearly presented, so the solidarity cannot be evaluated. Furturemore, more ablation study is needed to verify the contribution of the paper. If all the the concerns are properly addressed in the rebuttal, this paper can be accepted. ",0.16176470588235295,0.14473684210526316,0.15277777777777782
1907,SP:aebd056143c988e81577e5604b38712895fa21ea,"The authors propose an RL algorithm for learning risk-averse policies from offline data. Empirically, it is shown that it can outperform some existing risk-neutral approaches on a number of challenging robotic control tasks under risk-sensitive performance measures. Although the empirical results are encouraging, the theoretical properties of the proposed algorithm are unclear and therefore it is not clear how easy it can be implemented in other tasks.","The paper studies the problem of safe reinforcement learning, where we want to learn risk-averse policies in the offline setting. It proposes “Offline Risk Averse Actor Critic” (ORAAC) which performs competitively as risk-neural agent, and outperforms D4PG based baseline as a risk-averse agent on D4RL benchmark. The algorithm involves modifying the losses to learn risk-averse actor, distributional critic and a VAE-based imitative policy.",0.18571428571428572,0.19117647058823528,0.18840579710144928
1908,SP:aec7ce88f21b38c205522c88b3a3253e24754182,"This paper handles the challenge of generating generalizable programs from input-output specifications when the size of the specification can be quite limited and therefore ambiguous. When proposed candidate programs lead to divergent outputs on a new input, the paper proposes to use a learned neural oracle that can evaluate which of the outputs are most likely. The paper applies their technique to the task of synthesizing Android UI layout code from labels of components and their positions.","A method for a refinement loop for program synthesizers operating on input/ouput specifications is presented. The core idea is to generate several candidate solutions, execute them on several inputs, and then use a learned component to judge which of the resulting input/output pairs are most likely to be correct. This avoids having to judge the correctness of the generated programs and instead focuses on the easier task of judging the correctness of outputs. An implementation of the idea in a tool for synthesizing programs generating UIs is evaluated, showing impressive improvements over the baseline.",0.24358974358974358,0.19791666666666666,0.21839080459770113
1909,SP:aecbe1b77f8ad3df9f7377237cc47230b80ff50b,"This paper presents a new temporal adaptive module (TAM) to generate video-specific temporal kernels based on its own feature maps. TAM proposes a unique two-level adaptive modeling scheme by decoupling dynamic kernel into a location sensitive importance map and a location invariant aggregation weight. The importance map is learned in a local temporal window to capture short term information, while the aggregation weight is generated from a global view with a focus on long-term structure.","This paper proposes a temporal adaptive module for video recognition. Specifically, it decouples dynamic kernel into a location sensitive importance map and a location invariant aggregation weight, which can be plugged into existing 2D CNNs to yield a powerful video architecture with small extra computational cost. The experiments conducted on several datasets demonstrate the effectiveness of the proposed method.",0.32051282051282054,0.423728813559322,0.3649635036496351
1910,SP:aecd57c5b2337667d1619d0da05b1103c8ba07cf,"This paper proposes a method for training model that are robust to spurious correlations, building upon prior work that uses product-of-experts and a model explicitly trained on a dataset bias (e.g., a hypothesis-only model). Instead of using a model explicitly trained to learn the dataset bias, the authors use a “weak learner” with limited capacity. Then, this model is used in the PoE setting as in past work. The advantage of this method is that a model developer doesn’t need to know that a bias exists, since the hope is that the weak learner will implicitly learn the bias.","This paper focuses on the known problem that current NLP models tend to solve tasks by exploiting superficial properties of the training data that do not generalize. For example, in the NLI task, models learn that negation words are indicative of the label ""contradiction"" and high word overlap is indicative of the label ""entailment"". There have been many recent solutions proposed for mitigating such behavior, but existing methods have tended to assume knowledge of the specific dataset biases a priori. In this paper, the authors propose a method based on product of experts that doesn't assume particular knowledge of specific dataset biases. The method works by first training a weak model and then training a ""main"" model using a loss that upweights examples on which the weak model performs poorly (namely, predicts the wrong answer with high confidence). The assumption is that weak models will exploit heuristics, and so this method will deincentivize the main model to use those same heuristics. The authors evaluate on a range of tasks, including a simulated bias setting, and NLI setting, and a QA setting, and offer a fair amount of analysis of their results. In particular, the analysis showing that the weak learners do in fact adopt the biases which have been documented elsewhere in the literature is interesting, and the discussion of ""how weak does the weak learner need to be"" is appreciated (a few questions on this below).",0.2980769230769231,0.13025210084033614,0.18128654970760233
1911,SP:aedf78f4a2f4f452758e11eb3d928ae9a2520a0d,"This paper proposes a new graph neural network (GNN) architecture whose convolutional layer is capable of learning spectral graph filters of arbitrary characteristics via Bernstein approximation. Under the constraint of positive filter response, the authors show that the polynomial which approximates the solution to a generalised graph-based optimisation necessarily has the form of a non-negative linear combination of Bernstein basis, which justifies the proposed GNN convolutional layer. Experimental results demonstrate that the proposed scheme can learn complex filters and achieve competitive results on a number of benchmark datasets.","This paper proposes BernNet, a novel graph neural network with theoretical support that provides a simple but effective scheme for designing and learning arbitrary graph spectral filters. The key property of BernNet is that 1) any valid polynomial filers that maps [0,2] to [0,1] can always be expressed by a BernNet, and 2) the filters learned by our BernNet are always non-negative. The experiments demonstrate that BernNet can learn complex spectral filters, such as band-rejection and comb filters, and it achieves superior performance in real-world graph modeling tasks. Overall, the motivation is clear and the idea is interesting. Technical contributions are clearly shown with both theoretical and empirical evidence. ",0.3,0.23684210526315788,0.2647058823529412
1912,SP:af128acd773c40e3b0b92f647a2126704036a75d,"The paper addresses data-efficient GAN training.  It decomposes the task of the GAN training in low data regimes into two sub-problems: 1) finding the sparse subnetwork, so called lottery ticket, in the original GAN model, based on observations in [1,2], on a small set of training images; 2) then training the found sparse subnetwork, which is a more data-efficient solution in comparison to the dense one, on the same small training set.  In addition, the paper proposes a feature augmentation technique, which injects adversarial perturbations into intermediate features of both discriminator and generator. The paper shows that the sparse subnetwork can benefit from extra data- and feature-level augmentations.","This paper proposed to extend Lottery Ticket Hypothesis (LTH) for data-efficient GAN training. Specifically, the authors have found that sparse subnetworks lead to better sample qualities of Image GANs. In addition, they have proposed AdvAug that combines the ideas of feature augmentation and adversarial training.",0.13274336283185842,0.32608695652173914,0.18867924528301888
1913,SP:af25780cfdf89b04ccb29c2da58b6188adfa9c2e,"Overall the paper suffers from a lack of clarity in the presentation, especially in algorithm 1, and does not communicate well why the assumption of different dynamical processes should be important in practice. Experiments show some improvement compared to (Trivedi et al. 2017) but are limited to two datasets and it is unclear to what extend end the proposed method would help for a larger variety of datasets. ","Overall, the contribution of the paper is somewhat limited [but a little more than my initial assessment, thanks to the rebuttal]. It is essentially an extension of (Trivedi et al. 2017), adding attention to provide self-exciting rates, applied to two types of edges (communication edges and “friendship” edges). Conditioned on past edges, future edges are assumed independent, which makes the math trivial. The work would be better described as modeling a Marked Point Process with marks k \in {0,1}.",0.23529411764705882,0.19753086419753085,0.21476510067114093
1914,SP:af31abf3d1d705bca5b2d35e7689d502c1520e99,"The authors build on the work by Ghorbani et al. in concept-based interpretability methods by taking into account the ""completeness"" of the concepts. This basically tests whether the models accuracy holds if the input is projected onto the span of the discovered concepts. They propose ""ConceptSHAP"", based on Shapley values, to assign importance to the learned concepts. These could be shown to satisfy some reasonable properties such as efficiency (sum of importances equals total completeness value), symmetry, additivity, dummy (a concept that does not change the completeness universally should have zero importance) as stated in Prop. 4.1. The method is finally tested on a variety of datasets, including a synthetic one, which shows that optimizing ""completeness"" helps in discovering a richer variety of important  concepts than prior work). ","The paper proposes metrics for evaluating concept based explanations in terms of ‘completeness’ -- characterized by (1) whether the set of presented concepts if sufficient to retain the predictive performance of the original model and (2) how is performance affected when all information useful to a complete set of concepts (as per (1)) is removed from features at a specific layer. Assuming concept vectors lie in linear sub-spaces of the activations of the network at a specific layer, the underlying assumption is that if a given set of ‘concept’ vectors is complete, then using a projection of the intermediate features from input onto the sub-space spanned by concepts should not result in reduced / affected predictive performance. Based on these characterizations, the paper proposes an objective to discovering complete and interpretable set of concepts given a candidate cluster of concepts. Furthermore, the paper proposes metrics to quantify the importance of each concept (using Shapley values) and per-class importance of concepts. The authors conduct experiments on toy data, image and text classification datasets and show that their proposed approach can discover concepts that are complete and interpretable.",0.2153846153846154,0.1497326203208556,0.17665615141955834
1915,SP:af32b11ab09c21c2732a744bf8c694cd80acf309,"This paper introduces a number of data preprocessing options for numeric features provided by an open source library automunge. The most of the paper focuses on explaining the specific transformations offered under each option, including normalization, binning, and noise injection. For normalization, a new transformation 'retain' is offered in addition to traditional z-score, min-max etc. The paper uses one section between normalization and binning to explain a notion 'family tree primitives' which is used in the composition of multiple transformations. In experiments, the paper uses the higgs dataset. Three settings of the dataset are used: full data, 5% data and 0.25% data. 6 settings of transformations are used: raw data, z-score, retain, retain with bins, retain with noise injection, and retain with partial noise injection. When averaged over the three settings of the dataset, using raw data leads to suboptimal auc score compared with the other five. It is acknowledged that ""the metrics for normalized data were slightly better than raw on average, it is not clear if they were sufficiently statistically significant to draw firm conclusions. "" The paper concludes that ""any consideration around benefits of feature engineering should distinguish","The paper describes a library (Automunge) for pre-processing tabular data to prepare the data for downstream machine learning tasks. The paper also describes how to use the said library and the various options (including some new forms of normalization) available in the library. Experimental evaluation on Higgs Boson interaction dataset is provided, following the experimentation in Baldi, Sadowski and Whiteson 2014. Some improvements over the published results in Baldi 2014 are shown. ",0.10309278350515463,0.273972602739726,0.149812734082397
1916,SP:af5ebe07a96714c0bb85aef1f4b3e23120db142e,"In this paper, the problem of algorithmic recourse is studied where the goal is to find best recourse (counterfactual set) that is optimized for user cost. The author proposed new user-incurred cost evaluation method, Expected Minimum Cost (EMC), which approximate user satisfaction without assuming a fixed global user cost function, and instead consider user cost functions as hidden and user-specific. Specifically, the authors define cost function for each user as a set of feature-specific functions of user-incurred cost when transitioning between feature states, and define MinCost as the minimum transition cost across possible recourses. To cover diverse user cost functions, they propose to model user cost distribution with a hierarchical sampling procedure and estimated expected minimum cost by drawing samples from it. Next, they formulate a discrete optimization problem using EMC as objective, and propose a search algorithm (COLS) for best recourse generation. They introduce three new metrics for user satisfaction (all related to MinCost): FS@k, Coverage and PAC. Finally, they test with two real-world datasets and show that COLS achieves significant outperformance against baselines (that optimize for distance-based metrics) on the newly proposed metrics and show that their method is doing better in fairness as well. ",This work introduces a new method for identifying actionable recourses for users with user-specific cost functions. Users’ cost functions are hidden from the recourse method. The paper proposed a discrete optimization algorithm COLS to solve the objective EMC. It further used a popular real-world dataset to illustrate the performance.,0.09313725490196079,0.37254901960784315,0.14901960784313725
1917,SP:af5f654232fc76ba12e7a87e1575236446100d03,"This paper studies the problem of multiclass differentially private PAC learning. It provides a generic reduction from multiclass differentially private PAC learning to binary private PAC learning, that is intuitively based on the decomposition of an integer $k$ into $\log(k)$ bits. As a result, the contribution of the paper is a private multiclass learning algorithm (with sample complexity polynomial in the multiclass Littlestone dimension and poly-logarithmic in the number of labels-classes). This work is closely related to recent progress in the binary classification regime towards the connections between differentially private learnability and online learning.","This work studies the connection between the differential privacy of binary learning and multiclass learning. The authors first show a simple reduction from multiclass to binary to private learning, meaning that they show that for any $f$ if there is an algorithm that private learns each binary function of $f$ (meaning learns each bit of $f$) then there is a private algorithm for $f$. Furthermore, the authors show tight bounds on Littlestone of multiclass and binary learning. They prove that if a multiclass hypothesis class has Littlestone dimension $d$ then each binary restriction of the same class has Littlestone dimension bounded by $\sim 6d\log k$. The authors provide upper and lower bounds for this claim. Moreover, the authors provide an upper bound to the sample complexity or privately learning a multiclass hypothesis relatively to the Littlestone dimension of this class.",0.31958762886597936,0.2198581560283688,0.2605042016806723
1918,SP:af6173648147cb7a4b1270caea7e9bd6de005b1f,"The authors introduce LMAC, a meta-learning framework that learns to iteratively generate a strong population of agents for a game sampled from some distribution over games. To this end they propose to train a network that predicts a meta-distribution from a given payoff matrix between the agents in the population. This meta-distribution can then be used to train a new best-response agent to add to the population. In the paper they calculate this best response either using gradient descent or reinforcement learning. The choice of meta-solver is also flexible: the authors derive both meta-gradients as well as an evolutionary strategy. They report results on a range of games (from Games of Skill, to Lotto, non-transitive games to Poker). ","This paper presents an auto-curriculum method for solving zero-sum games. Previous methods rely on existing methods such as fictitious play, iterated best response, or double oracle to define the set of opponents (i.e., meta strategy) an agent needs to train with. The present work describes Learned Multi-Agent Auto-Curriculum (LMAC), a system that learns the meta-strategy in an end-to-end approach. Empirical results on a set of zero-sum games show that LMAC can be competitive with existing methods.",0.128,0.18823529411764706,0.1523809523809524
1919,SP:af6334109cf6487687fbba7daf38f59956f1134f,"In this work authors benchmark a biologically plausible network architecture for image classification. The employed architecture consists of one hidden layer, where input to hidden layer weights W1 are either trained with PCA or sparse coding, or are kept fixed after random initialization. The output layer units are modeled as leaky integrate-and-fire (LIF) neurons and hidden to output connections W2 are tuned using a rate model that mimics STDP learning dynamics in the LIF neurons. The authors compare classification results on MNIST and CIFAR10 datasets, where they also include results of an equivalent feed-forward network that is trained with standard error backpropagation.","This article compares different methods to train a two-layer spiking neural network (SNN) in a bio-plausible way on the MNIST dataset, showing that fixed localized random connections that form the hidden layer, in combination with a supervised local learning rule on the output layer can achieve close to state-of-the-art accuracy compared to other SNN architectures. The authors investigate three methods to train the first layer in an unsupervised way: principal component analysis (PCA) on the rates, sparse coding of activations, and fixed random local receptive fields.  Each of the methods is evaluated on the one hand in a time-stepped simulator, using LIF neurons and on the other hand using a rate-approximated model which allows for faster simulations. Results are compared between each other and as reference with  standard backpropagation and feedback alignment.  The main finding is that localized random projections outperform other unsupervised ways of computing first layer features, and with many hidden neurons approaches backpropagation results. These results are summarized in Table 8, which compares results of the paper and other state-of-the-art and bio-plausible SNNs. PCA and sparse coding work worse on MNIST than local random projections, regardless if the network is rate-based, spike-based or a regular ANN trained with the delta rule. Feedback Alignment, although only meant for comparison, performs best of the algorithms investigated in this paper.",0.29523809523809524,0.13304721030042918,0.18343195266272191
1920,SP:af656384c8eec0891912cc1893a5d827bc6efb78,"1. Summary: This paper proposes Capacitron, a conditional variational latent variable model for TTS which allow for controllable latent variable capacity. They optimize the Lagrangian dual of the ELBO and restrict the capacity of the rate-term through a learnable, non-negative multiplier. They demonstrate the effectiveness of their approach on a range of TTS tasks such as same-text prosody transfer and inter-text style transfer, and provide extensive analyses on their latent variable capacity (in addition to comparisons to non-variational approaches based on Tacotron).","In this work authors present a regularized, variational autoencoder method for speech synthesis. To endow the latent space with more capacity, the authors employ a modified variational autoencoder objective, which uses a learnable Lagrange multiplier to impose a capacity limit on KL divergence between latent posterior and prior. The authors furthermore propose to decompose the latent embedding space into a two-level hierarchical representation to give generative process more control over style transfer and sample-to-sample variance. They extend earlier theoretical results providing upper bounds on the mutual information between data and its latent embedding to their hierarchical latent representation. In numerical experiments the authors evaluate their approach on a number of speech synthesis tasks involving same-text prosody transfer, inter-text style transfer, inter-speaker prosody transfer. They also analyze speech samples generated from latent samples drawn from the prior.",0.3218390804597701,0.19718309859154928,0.2445414847161572
1921,SP:af913437115d717862f353ae238f3fb1fc9d72f4,"The paper proposes an algorithm for learning policies and internal models (""decision dynamics"") from demonstrations. The key idea is to fit a distribution over policies, observation models, and transition models using an EM-like method. Offline experiments on a healthcare dataset show that the method learns interpretable decision dynamics, recovers biased internal models, and accurately predicts actions relative to prior methods.","This work proposes an approach for understanding and explaining decision-making behavior. The authors aim to make the method 1) transparent, 2) able to handle partial observability, and 3) work with offline data. To do this, they develop INTERPOLE, which uses Bayesian techniques to estimate decision dynamics as well as decision boundaries. Results on simulated and real-world domains show that their method explains the decisions in behavior data while still maintaining accuracy and focuses on explaining decision dynamics rather than the “true” dynamics of the world.",0.2459016393442623,0.1724137931034483,0.20270270270270271
1922,SP:af9b6bd175b9484c0da182bcdc66a427f1725062,"The paper proposes a multi-domain music translation method. The model presents a Wavenet auto-encoder setting with a single (domain independent) encoder and multiple (domain specific) decoders.  From the model perspective, the paper builds up on several exciting ideas such as Wavenet and autoencoder based translation models that can perform the domain conversion without relying on parallel datasets. The two main modifications are the use of data augmentation, the use of multiple decoders (rather a single decoder conditioned on the output domain identity) and the use of a domain confusion loss to prevent the latent space to encode domain specific information. This last idea has been also used on prior work.","A method is presented to modify a music recording so that it sounds like it was performed by a different (set of) instrument(s). This task is referred to as ""music translation"". To this end, an autoencoder model is constructed, where the decoder is autoregressive (WaveNet-style) and domain-specific, and the encoder is shared across all domains and trained with an adversarial ""domain confusion loss"". The latter helps the encoder to produce a domain-agnostic intermediate representation of the audio.",0.15178571428571427,0.20987654320987653,0.17616580310880828
1923,SP:afb7cc467235d77ddcfc6b8745fa6096223d8fdd,"The goal of the paper is to design mechanisms to explain the unfairness in the outcomes of a ML model and propose methods to mitigate unfairness. The paper uses the Shapley value framework. The main idea is to alter the prediction function so that instead of providing the classification score, an ""unfairness"" score is returned. An out of the box application of the Shapley value framework on this unfairness score now returns the ""unfairness"" feature attribution. These feature attributions can be used to explain the unfairness of the model. The paper then proposes to learn a linear perturbation, which when combined with the additive property of Shapley framework results in updated ""unfairness"" attributions.",This paper presents a method for feature attribution for fairness of the classifier.  They also demonstrate a feature augmentation technique to mitigate unfairness.  They connect their attribution method to to the augmentation technique and demonstrate that their method can attribute the necessary changes to achieve fairness. They evaluate their approach on a few tabular data sets.,0.11504424778761062,0.23214285714285715,0.15384615384615383
1924,SP:afe4b486f834deea0faac7d7a55644df5c1388ed,"This paper focuses on the problem of causal discovery in additive linear models with non-Gaussian errors (LINGAM) and latent variables. It asks: are the underlying orientations statistically decidable (controlled error for every n) for any algorithm? Unlike previous work that answered in the affirmative when all variables are observed, the authors demonstrate that the answer is negative when there is latent confounding. While identifiability guarantees exist in this setting (i.e. causal orientations or equivalently partial orderings are identifiable from data), decidability does not hold, developing further insights about the performance of LINGAM. ","This paper is about statistical causal inference. More specifically, this paper is about the causal discovery that infers causal graphs. Many methods focus on investigating the identifiability of various models for causal discovery and proposing estimation methods for the identifiable models. This paper points out that the identifiability does not necessarily imply that desirably consistent estimations methods exist.   There are many types of consistency, including uniform consistency and point-wise consistency. This paper investigates which consistency can be achieved for linear non-Gaussian acyclic models with hidden common causes, confounded LiNGAM (Hoyer et al., 2008). This analysis is based on a consistency concept named statistical decidability proposed in Genin and Mayo-Wilson (2020).   Their main result is summarized in Table 1. Genin and Mayo-Wilson (2020) showed that LiNGAM with latent confounders (Shimizu et al., 2006) is (statistically) decidable with/without the faithfulness assumption. Faithfulness is a common assumption in causal discovery (Spirtes et al., 1993). The causal ordering of variables, ancestral relationships, of confounded LiNGAM has been shown in identifiable if faithfulness is assumed (Hoyer et al., 2008; Salehkaleybar et al., 2020). If faithfulness is not assumed, it is not decidable. The definitions of decidability are on pages 2 and 3. Theorem 1.1 and 1.2 say how one could check whether such consistency hold. Their very main result is Theorem 6.1 in the final section. All the other sections are written to prepare for giving the theorem.  ---- I updated the score and confidence.  ",0.24468085106382978,0.0931174089068826,0.13489736070381234
1925,SP:b01077ca319b19401044d1ec4a62f5dcaf0eeb21,"This submission proposes a general method (K-Adapter) for injecting knowledge (either factual or linguistic) into pre-trained language models.  The key architectural property of the approach is that K-Adapters are isolated from one another, allowing the use of multiple adapters without interference. These K-Adapter modules take hidden layer _inputs_ from the main pre-trained model (eg, BERT), and are pre-trained on their knowledge outputs before a fine-tuning phase where they feed into a joint downstream task-specific model along with the pre-trained model outputs.","The authors propose a plug-in based adapter approach to allow for task specific parameter settings without updating the original pre-trained model which prevents the potential for catastrophic forgetting while also removing the need for separate models for separate tasks.  The work seems to build off Houlsby 19  as briefly cited, but its in plug-in nature seems easier to adopt for multiple tasks.  There is however not direct comparison with it or Cooper et al 19 ( https://arxiv.org/pdf/1902.02671.pdf ) which makes it difficult to assess.  The way in which the adaptors were pretrained was a little unclear to me.  The experiments are extensive and well done.",0.13333333333333333,0.10714285714285714,0.11881188118811882
1926,SP:b0196d78c6627950362072092997688e6dd65e32,"This paper proposed a meta-learning approach to learn piecewise-Lipschitz functions in the multi-task setting. Simply applying a traditional single-task exponential forecasting method multiple times cannot make the regret bound diminishes as the number of tasks $T$ increases. To tackle this issue, they first attempt to obtain a bound that involves the task similarity term, and then the authors propose two meta-learning algorithms, based on the observation that the regret bound depends on two things: learning rate and initialization probability choosing. Hence, they proposed two meta-learning algorithms, to efficiently learn to choose better initialization and learning rate. The theoretical results show that this algorithm can provably improve the baseline of applying a single-task algorithm $T$ times. ","The paper study the initialization-based meta-learning focus on the piecewise-Lipschitz functions whose discontinuities are dispersed. The authors designed an initialization method that implicitly run on online convex optimization procedure over an adaptive discretization to improve the performance of the exponential forecaster across multi-task. To demonstrate the usefulness of their proposed method, the authors instantiate the method in two settings: online configuration of clustering algorithms and adversarial robustness in online learning.",0.1557377049180328,0.25675675675675674,0.19387755102040816
1927,SP:b030108c8ae5c6ad968b76072d0ab08af9de4cd9,"I really appreciated this paper. It discusses a very complex question (""Are we learning in a kernel regime, or in a rich regime where features are identified"") by looking at perhaps the simplest model the authors could think of, and then study in detail the model. And how simple it turns out to be: just a linear regression with a twist. All in all, the paper is indeed is a clear demonstration that the differences between""Kernel"" regime and one where some actual Learning is done can be demonstrated on simple examples. It is also the simplest model where one can observe  a non-trivial inductive bias and 'implicit regularisation'","This paper analyzes an inductive bias of the gradient flow for diagonal two-or higher-homogeneous models and characterizes a limit point depending on the initialization scale of parameters. Concretely, the paper shows that the gradient flow converges to an interpolator attaining minimum L1- (or L2-norm) when the scale is small (or large). In addition, these analyses are well verified empirically on MNIST and CIFAR-10 datasets.",0.11818181818181818,0.19117647058823528,0.14606741573033707
1928,SP:b031a23d6cba224ae0f2fc49721f5f02331204d4,"The paper extends the conformal prediction framework, hitherto limited to models trained under the IID assumption, to the context of multi-step time series forecasting. It shows that under this framework, one can obtain reasonably well calibrated predictive intervals of the future trajectory of a time series, an important problem in decision theory.  Experiments with synthetic data and several healthcare datasets confirm the validity of the approach against baselines.","This paper proposes a conformal prediction method (CoRNN) for uncertainty estimation in time series forecasting. CoRNN is a recurrent network-based multi-step forecaster, it can also achieve a valid finite sample coverage guarantee. Compared with other baselines, CoRNN is computationally efficient, does not require any modifications to the predictive model, and provides theoretical coverage guarantees. Empirical results on simulated and real-world datasets demonstrate the superiority of CoRNN in constructing confidence intervals for multi-step forecasts.",0.2028985507246377,0.18181818181818182,0.19178082191780824
1929,SP:b054b02760d839fe09152fbdc75e3090d147345b,"In this paper, the authors propose generalize the FM to consider both interaction between features and interaction between samples. For the interaction between features, the authors propose to use graph convolution to capture high-order feature interactions. Moreover, the authors construct a graph on the instances based on similarity. Then a GCN is applied to the sample graph where the feature embedding is shared between the two components. Experiments are carried out on four datasets with tasks of link prediction and regression. Comparison to several baselines demonstrate the superior performance of the proposed method.","This paper proposes to combine the graph neural networks and factorization machines. First, the authors propose a relational feature interaction component (RFO) tp deal with the categorical features. This component first uses the factorization machine to project the features to h^FI(x), then it uses an aggregation operation to get the prediction y^RFI. To explore high-order correlations, the authors further propose to calculate a concurrence graph, on which RFI propagates the embedding vectors to get relational high-order correlations. To further model high-order sample interactions, this work then presents a special graph convolutional operation that considers the element-wise products of the encoded features. ",0.26595744680851063,0.23148148148148148,0.2475247524752475
1930,SP:b05dc7c8eb4108fcf028d86de6dc4db5e70fed49,"In this paper, the authors claim to establish a Lipschitz bound on neural networks, initialized randomly, and trained until convergence.  They also claim to establish probabilistic concentration of the resolvent of the Gram matrix from a mixture of k distributions with varying means and covariances.  The authors also present the spectrum and leading eigenspace of the Gram matrix for representations by CNNs of images generated by a GAN.","The authors generalize Gaussian random vectors to a broader class of ""concentrated"" vectors which they use as their primary tool for analysis of the latent representations learned by GANs. They show that the spectral behavior (i.e. spectra and leading eigenspaces) of the Gram matrix computed over GAN representations is the same as those produced by a high dimensional Gaussian Mixture Models (GMMs). Furthermore, they show that the ""sufficient statistics"" (i.e. measures of information encoded in the latent representations) for GANs depend only on their first and second moments. Thus, for data that follows Gaussian mixture patterns, GANs and GMMs behave identically. The authors also show that common neural network operations (linear/convolutional layers, pooling, batch normalization, ReLU activations) are Lipschitz transformations, where the Lipschitz constants can be bounded using spectral normalization (this is borrowed from previous work). They also provide some empirical analysis to verify their theoretical findings.",0.27941176470588236,0.12666666666666668,0.17431192660550457
1931,SP:b06e9de47853c0a0a43bda7a7ed264fc6ececa1f,"In this paper, the authors proposed the duality gap as the criterion for evaluating the training of GAN. To justify the proposed criterion, the authors designed empirical experiments on both synthetic and real-world datasets to demonstrate the ability of the duality gap for detecting divergence, mode collapse, sample equality, as well as the generalization to other application domains besides image generation. Comparing with the existing criteria, e.g., FID and INC, the duality gap shows better ability and computational efficiency. ","This work proposes to use duality gap and minimax loss as measures for monitoring the progress of training GANs. The authors first showed a relationship between duality gap(DG) and Jensen-Shannon divergence and non-negativeness on DG. Then, a comprehensive discussion was presented on how to estimate and efficiently compute DG. A series of experiments were designed on synthetic data and real-world image data to show 1) how duality gap is sensitive to capture non-convergence during training and 2) how minimax loss efficiently reflects the sample quality from generator. ",0.25925925925925924,0.22826086956521738,0.24277456647398843
1932,SP:b078edeead27869c0535134641feacd064874de5,"This paper studies asymptotic convergence rates for a family of distributed Stochastic Approximation Schemes in a cooperative multi-agent learning setting (Nonlinear Gossip models). They provide convergence rates which applies almost surely on sample paths, improving over the existing analysis that analyse the expected behavior. In addition they have weaker assumptions on the Gossip matrix and the step sizes (removing square summability).  As a result, they analyze policy evaluation through TD(0) with linear function approximation for the infinite horizon reinforcement learning problem and the convergence rates follow for TD(0).  ","This paper presents a Law of Iterated Logarithm (LIL) for Distributed Stochastic Approximation (DSA) schemes, which characterizes the rate of convergence of the updates to their stable equilibrium. The conditions are more general than previous works (in particular the gossip matrix is not required to be doubly stochastic and step-sizes need not be square summable). An application to the case of TD(0) with linear function approximation is given. ",0.27472527472527475,0.35714285714285715,0.31055900621118016
1933,SP:b08abec20b2b0e98c5694595b38182894ea043bf,"Authors propose an approach to perform authentication based on users' behaviour (behavioral biometrics) on two different domains (web and mobile) by means of a siamese NN. The proposal is evaluated on three different dataset, collected ad-hoc for this work, showing a performance up to >0.9 acc. In the experimentation setup authors include different data splits, sequences lengths and training methods (pairs and triplets). The work shows the feasibility of using this type of approach for few-shot classification under real industry constraints.","This paper proposes the use of siamese neural networks for the task of user verification by learning to identify their behavioral patterns of interaction with mobile phones or web browsers. Notably, the behavioral characteristics of users when engaging with these devices, measured in the form of mouse movements or keyboard typing patterns on browsers or touch patterns on mobile phones, serve as a proxy for more direct biomarkers such as face recognition, eye scans, etc. The authors argue that the latter requires more specialised hardware and is thus not easily scalable. Instead, they architect the first NN based solution that serves both modalities, web and mobile phones, while trying to be more accurate and responsive.",0.13095238095238096,0.09565217391304348,0.11055276381909548
1934,SP:b0aebd87afa8415276e3551e84b4eb6f3152b877,"Given an additively decomposable function F(X, Q) = sum_over_x_in_X cost(x, Q), one can approximate it using either random sampling of x in X (unbiased, possibly high variance), or using importance sampling and replace the sum_over_x with a sum_over_coreset importance_of_a_point * cost(x, Q) which if properly defined can be both unbiased and have low variance [1]. In this work the authors consider the weighted sum of activations as F and suggest that for each neuron we can subsample the incoming edges. To construct the importance sampling strategy the authors adapt the classic notion of sensitivity from the coreset literature. Then, one has to carefully balance the approximation quality from one layer to the next and essentially union bound the results over all layers and all sampled points. The performed analysis is sound (up to my knowledge).","The authors propose to reduce the size of fully connected neural networks, defined as the total number of nonzeros in the weight matrices, by calculating sensitivity scores for each incoming connection to a neuron, and randomly keeping only some of the incoming connections with probability proportional to their share of the total sensitivity. They provide a specific definition for the sensitivity scores and establish that the sparsified neural network, with constant probability for any sample from the training population, provides an output that is a small multiplicative factor away from the output of the unsparisfied neural network. The cost of the sparsification is essentially the application of the trained neural network to a small number of data points in order to compute the sensitivity scores",0.14965986394557823,0.176,0.16176470588235292
1935,SP:b0c94a1ef77cbdab8af5402718ed06964148dd95,"This paper explores the problem of deep heteroskedastic multivariate regression where the goal is to regress over symmetric positive definite matrices; that is, the deep learning model should take as input data points, and produce a conditional covariance matrix as the output. The key challenge in this setting is how to ensure the predicted matrix is positive definite (and thus follows the non-linear geometry of these matrices), how the neural network can be trained for this task, and what loss function can be used for effective training. The paper proposes a neural network with bilinear layers in this regard, and uses the von Neumann divergence as the loss function to regress the predicted covariance against a ground truth SPD matrix. The gradients of the von Neumann divergence are provided for learning via backpropagation. Experiments on several synthetic datasets and small scale datasets are provided, showcasing some benefits. ","This manuscript proposes a novel formulation of the MLP to address predicting a symmetric positive definite (SPD) matrix from an input vector or matrix.  While the field has had methods for years to estimate SPD matrices (such as the covariance matrix estimate in the reparameterization trick), this manuscript proposes a markedly different approach based on a different layer structure and repeated normalization steps based on Mercer Kernels.  Additionally, the loss used can be modified to use more PSD-specific losses, such as the symmetrized von Neumann divergence, rather than the traditional quadratic loss.  This loss appears to give significantly better solutions on synthetic data.",0.1891891891891892,0.2692307692307692,0.22222222222222224
1936,SP:b0ddaded23d30a4f36ea93c27971167644ac43f1,"The paper uses koopman theory to design principled data augmentation method for offline reinforcement learning. They learn a VAE style encoder-decoder model such that $D(E(s))=s$ and a forward model such that $F(s_t, a_t) = D((K_0 + \sum_{i=1}^m K_i, a_{t,i})E(s_t)) = s_{t+1}$. The koopman operator $K$ is then used to generate symmetries which are applied to both $s_t$ and $s_{t+1}$ as data augmentation during bellman error minimization. The resulting algorithm KFC and KFC++ leads to overall better data augmentation and improves for S4RL and CQL.","This paper develops a new method (Koopman Forward (Conservative) Q-learning, KFC in short) for offline reinforcement learning by extending the static dataset to include new states that are computed by learning an action-invariant Koopman latent representation of the system. The Koopman transformation to obtain the transformed state transitions is build using a variational auto-encoder. Experimental results are provided on D4RL, RoboSuite and MetaWorld benchmarks. This is a well-written paper (there are some minor typos which the authors should rectify). The method developed here shows improved performance over current methods in a number of benchmark problems.",0.125,0.13131313131313133,0.12807881773399016
1937,SP:b0eb702a24df15b70d99f335b9fe26aca3ffcc43,"This paper proposes robust model adaptation, which first do a pretraining with adversarial weight perturbation. Then the final result is obtained by iteratively doing model adaptation on the learned model, with a local smoothness penalty objective. The proposed results shows improvements over existing methods.","RoMA is a framework that leverages the local smoothness prior to robustly approximate black-box objective functions. RoMA consists of two steps: 1, train the proxy models (neural networks) to approximate black-box objective functions by perturbing original inputs with Gaussian inputs and minimizing worst-case weight perturbations; 2, iteratively adapting the proxy model to enforce the local smoothness of loss landscape around the input x(t). This paper devises two separate loss functions for optimizing neural networks in these two steps. As a result, this method serves to avoid adversarial optimized inputs. In the experiment section, this method is compared to the state-of-the-art methods on the Design-bench dataset. Results show that this method achieves state-of-the-art performance across a variety of tasks. ",0.22727272727272727,0.07751937984496124,0.11560693641618497
1938,SP:b0f193db92cf2541bc252cb492ee3f9a6d50fc16,"The authors propose group equivariant neural posterior estimation (GNPE), a posterior estimation method which can self-consistently infer parameters and standardize the pose. For equivariant posterior distributions, the GNPE can achieve better performance than the traditional NPE. Moreover, GNPE can also be applied to cases where the equivariance of the posterior is approximately estimated.  The major advantage of GNPE over the other flow based models under equivariance constraints is that GNPE is architecture-indepenent, i.e., an arbitrary flow model can be utilized in GNPE and we don't need to design a special network structure for the equivariance.","In this paper the authors present a method for performing Bayesian inference in likehood-free settings where the data and parameters are jointly equivariant or approximately equivariant.  Examples include translational or rotational equivariance, where if the latent parameter are translate or rotated, then the distribution over the data is the same, except that the data are translated or rotated in the same way as the latent parameters.  The method presented here acts by mapping each simulation to a standard ""pose"" and then aims to learn both the original pose and any additional parameters from the data.  There are two main components to this method -- 1) the standard simulation-based inference method of estimating latent parameters from data, but applied to data that have had their pose standardized and 2) a Gibbs sampling framework to use the family of posteriors learned from the first component to jointly estimate the pose and ant other parameters from unposed data.",0.1919191919191919,0.12179487179487179,0.14901960784313725
1939,SP:b109c13a5d110eb9254eafc226881e44e393120d,"The paper describes how to use normalising flows for Semi Supervised Learning (SSL). Briefly, the method consists in finding a (bijective) map for transforming a mixture of Gaussians into a density approximating the empirical data-distribution -- as usual for flow methods, the parameters are found through likelihood maximisation. This is a elegant approach that naturally exploits the standard so-called cluster assumption in SSL. The papers also shows how to incorporate a consistency-based regularisation within the method.","The paper describes a normalising flow with the prior distribution represented by a Gaussian mixture model (GMM). The method, FlowGMM, maps each class of the dataset to a Gaussian distribution in the latent space by optimising the joint likelihood of both labelled and unlabelled data, thus making the method useful for semi-supervised problems. Predictions are made using the maximum a posteriori estimate of the class label. To make the method robust to small perturbations of the inputs, the authors introduce a novel consistency regularisation term to the total loss function, which maximises the likelihood of predicting the same class after a perturbation.",0.2692307692307692,0.20388349514563106,0.23204419889502764
1940,SP:b12a97dbba987675ed77e022393beffc77e982c3,"This paper investigated the consistency property of CEVAE, mainly under unknown parametric form of generative model (p(x|z),p(t|z),p(y|t,z)), the unknown distribution of latent variables, and correlated proxies. Theoretical analysis under some special cases is given. Most conclusions are based on empirical observations. ","The paper takes an in-depth look at using latent variable models in causal effect estimation from proxies. The idea behind such methods, specifically CEVAE, is that the proxies provide sufficient information about the confounder (one extreme case is when the proxies determine the confounder) to ensure that the causal effect is identified. As the authors suggest and show, both theoretically and empirically, this idea bears fruit in terms of estimability of causal effects only under potentially strong assumptions. The authors outline multiple failure modes of the CEVAE which I believe extend to other existing deep learning based methods for proxy-based effect estimation. Finally, experiments show in some more semi-synthetic datasets, the estimated effects are not consistent.",0.16,0.06722689075630252,0.09467455621301775
1941,SP:b16e4a52ca4ae6105ae7506b5446d31901b71d3f,"This paper tackles the problem of learning to label individual timesteps of sequential data, when given labels only for the sequence as a whole. The authors take an approach derived from the multiple-instance learning (MIL) literature that involves pooling the per-timestep predictions into a sequence-level prediction and to learn the per-timestep predictions without having explicit labels. They evaluate several pooling techniques and conclude that the log-sum-exp pooling approach is superior. The learned segmentations are used to train policies for multiple control skills, and these are used to solve hierarchical control tasks where the correct skill sequence is known.",The paper presents a weakly supervised method for segmentation of trajectories into sub-skills inspired by multi-instance learning (MIL) in image classification by Andrews et al. (2002). This is done via training a classifier to label each observation per time-step with the probability of skills corresponding to that observation. These predictions are then accumulated throughout the trajectory to compute the probability of the skill in that trajectory. There is only a trajectory level supervision provided which specifies which skills are present with no specification of the order in which they appear. They empirically show that their model can achieve decent skill level classification scores on multiple environments provided that there is a large variety of demonstrations provided.,0.16346153846153846,0.14285714285714285,0.15246636771300448
1942,SP:b1a146584c94ca088447b3885de73ca2e63478fb,"While most works consider embedding as the problem of mapping an input into a point in an embedding space, paper 1341 considers the problem of mapping an input into a distribution in an embedding space. Computing the matching score of two inputs (e.g. two images) involves the following steps: (i) assuming a Gaussian distribution in the embedding space, computing the mean and standard deviation for each input, (ii) drawing a set of samples from each distribution, (3) computing the normalized distances between the samples and (iv) averaging to obtain a global score.","pros: The  paper is well-written and well-motivated. It seems like uncertain-embeddings will be a valuable tool as we continue to extend deep learning to Bayesian applications, and the model proposed here seems to work well, qualitatively. Additionally the paper is well-written, in that every step used to construct the loss function and training seem well motivated and generally intuitive, and the simplistic CNN and evaluations give confidence that this is not a random result. ",0.11827956989247312,0.14102564102564102,0.12865497076023394
1943,SP:b1ed4e2f53695578c1601d754fa8120758efa2d5,"Gradient stochasticity is used to analyse the learning dynamics of SGD. It consists of two aspects: norm stochasticity and directional stochasticity. Although the norm stochasticity is easy to compute, it vanishes when the batch size increases. Therefore, it can be hard to measure the learning dynamics of SGD. The paper is motivated by measuring the learning dynamics by the directional stochasticity. Directly measuring the directional stochasticity with the ange distribution is hard, so the paper uses vMF distribution to approximate the uniformity measurement. The paper theoretically studies the proposed directional uniformity measurement. In addition, the experiments empirically show the directional uniformity measurement is more coherent with the gradient stochasticity.","This work provides an analysis of the directional distribution of of stochastic gradients in SGD. The basic claim is that the distribution, when modeled as a von Mises-Fisher distribution, becomes more uniform as training progresses. There is experimental verification of this claim, and some results suggesting that the SNR is more correlated with their measure of uniformity than with the norm of the gradients.",0.12844036697247707,0.2153846153846154,0.16091954022988506
1944,SP:b1f2e7dee0606c25926a81ac32462c8bd2cb4808,"This paper proposes an algorithm to learn coordination strategies for multi-agent reinforcement learning. It combines gradient-based optimization (Actor-critic) with Neuroevolution (genetic algorithms style). Specifically, Actor-critic is used to train an ensemble of agents (referred to as “team”) using a manually designed agent-specific reward. Coordination within a team is then learned with Neuroevolution. The overall design accommodates sharing of data between Actor-critic and Neuroevolution, and migration of policies. Evaluation is done using the multi-particle environments (Lowe et. al. 2017) and a Rover domain task.","This paper proposes to use a two-level optimization process to solve the challenge of optimizing the team reward and the agent's reward simultaneously, which are often not aligned. It applies the evolutionary algorithm to optimize the sparse team reward, while using RL (TD3) to optimize the agent's dense reward. In this way, there is no need to combine these two rewards into a scalar that often requires extensive manual tuning.",0.15555555555555556,0.1917808219178082,0.17177914110429449
1945,SP:b20efba59d6476db15db3f6c92aa4536f121119a,"This papers presents an unsupervised domain adaptation algorithm for semantic segmentation. A generative adversarial network is envisaged to carry out synthetic-to-real image translation. In doing so, depth information extracted from a simulator is used as privileged information (PI) to boost the transfer on the target domain, regularizing the model and ensuring a better generalization. ",The paper focuses on the problem of semantic segmentation across domains. The most standard setting for this task involves real world street images as target and synthetic domains as sources with images produced by simulators of photo-realistic hurban scenes.  This work proposes to leverage further depth information which is actually produced by the simulator together with the source images but which is in general not taken into consideration.,0.16071428571428573,0.13043478260869565,0.14400000000000002
1946,SP:b2243f53f080e0babbc6061de7e2c2059a8d0cf0,"This paper describes a deep learning approach for predicting Hamiltonian systems. The original paper enforces conservation in the loss function. Several of the follow-up papers embed a symplectic integrator instead, but these couldn't handle non-separable systems. This paper can both handle non-separable systems and use a symplectic integrator to enforce conservation. They demonstrate their system on quite a few examples and show lower error (both in prediction and the deviation in the Hamiltonian) than a NeuralODE or the original HNN paper. The final example, in Figure 5, shows a compelling visual improvement.","The paper extends the symplectic family of network architectures towards modeling nonseparable Hamiltonian dynamic systems. More specifically, the paper implements a  symplectic integration schema (from Tao (2016)) for solving arbitrary nonseparable (and separable) Hamiltonian systems within a symplectic neural network architecture. The results from several modeling tasks show that the proposed Nonseparable Symplectic NNs (NSSNNs) are more robust and accurate than vanilla HNNs and NeuralODEs when applied to nonseparable Hamiltonian systems. ",0.14583333333333334,0.19718309859154928,0.16766467065868262
1947,SP:b23ddc921ab2a7ebd5c33520f0007216335e1420,"The work is a clear introduction/overview of this area of research. The reviewer enjoyed the connections to Multiple-Gradient Descent and clear distinctions/contrasts with previous approaches to weighting the outputs of multiple discriminators. All in all, the paper is quite clear in what its contributions are and how it differs from previous approaches. The details and motivations of the Hypervolume Maximization  (HVM) method (especially as it relates to and interacts with the slack method of picking the nadir point) were a bit harder to follow intuitively given the standalone information in the paper.","The paper investigates the use of multi-objective optimization techniques in GAN-setups where there are multiple discriminators. Using multiple discriminators was proposed in Durugkar et al, Arora et al, Neyshabur et al and others. The twist here is to focus on the Pareto front and to import multiple gradient descent and hypervolume-maximization based methods into GANs. ",0.12631578947368421,0.20689655172413793,0.1568627450980392
1948,SP:b258e7150a73085f7bf32c927126a3601210bcec,"Learning with noise labels is a hot topic now due to the reason that deep learning algorithms often require large-scale supervised training samples and labelling a large amount of data is costly. However, almost all of the existing methods assume that the label noise is instance-independent. It either depends on the clean classes or is completely random. This paper studies the instance-dependent label noise, which is more realistic and applicable, but difficulty to address. The authors target to solve this problem. A feasible solution would contribute to the community a lot.","This paper focuses on instance-dependent label noise problem, which is a new and important area in learning with noisy labels. The authors propose confidence-scored instance-dependent noise (CSIDN) to overcome strong assumptions on noise models. They clearly define confidence scores and justify their availability. To solve CSIDN model, they propose instance-level forward correction with theoretical guarantees. Their experiments on both synthetic and real-world datasets show the advantage of this algorithm.",0.14893617021276595,0.1891891891891892,0.16666666666666666
1949,SP:b27b045c9e31aff4ba338989628658c5f472a2bb,"This paper introduces a model for continual learning based on example replay. Motivated by the Complementary Learning Systems theory in neuroscience, the authors propose to use, instead of a single backbone network, two different models: the slow and the fast learner. The slow learner is composed of a standard backbone architecture, such as ResNet, and it is optimized via self-supervised learning with examples from a memory buffer. The fast learner performs an adaptation of representations provided by the slow learner (based on masking) and embeds a classifier. The fast learner is supervised with class labels. Experiments and ablation studies are carried out on two datasets, namely miniImagenet and CORE-50, both in the presence and in the absence of task labels at inference time.","This work proposes an Architectural-based method for online continual learning, suitable both for the Task-aware and Task-free scenarios. Inspired by biologic suggestions, the author separate a continual learner in a slow network (which learns generic representations in a contrastive fashion) and a fast network (which utilises the feature generated by the former to produce a classification response). Experiments show state-of-the-art accuracy in the presented setting.",0.16,0.28169014084507044,0.20408163265306123
1950,SP:b27d0bb34999cb1d197f68cca7e4c01c433ed6e8,"This paper 1) proposes a simple transfer learning approach to enable train adversarially robust few-shot classifiers for few-shot image classification, and 2) present a method for novel classification task based on calibrating the centroid of the few-shot category towards the base classes. Results show good performance has been achieved on three benchmarks i.e., Mini-ImageNet, CIFAR-FS, and CUB datasets.  My main concern of this work is that the improved performance can be mainly resulted from the pretrained stage (base training) using the base dataset $X_b$. Normally, pretraining can improve the performance on small tasks.","This paper aims to address the problem of adversarial attack for low shot image classification. This work is motivated by the challenging scenario where there is a need of significant amount of data to train an adversarial robust classifier and there is not much data under few-shot setting. This work proposed and demonstrated a simple approach for robust few shot classifier. A model is first adversarially trained on the base classes and produce a robust base model. The feature extractor of the robust base model is then frozen. With the frozen feature extractor, 2  different manners are used for training a novel / few shot classifier, including (1) training a linear classifier and (2) computing category centroid for each novel class and perform nearest neighbor classification using the centroid. The experiment demonstrates that this simple baseline can outperform prior baselines on 3 datasets. The ablation study includes 1 vs 5 shot and different adversarial training methods. However, the core contribution of this paper is weakened due to the lack of theoretical analysis.",0.26,0.1511627906976744,0.19117647058823528
1951,SP:b27e82ceb1636e24042a76b3749d729029ebb38c,"The authors present miniF2F, a dataset of formalized mathematical problems drawn from diverse sources including IMO, AIME, AMC, undergraduate, and high school problems. The focus is on algebra, inequalities, and number theory as those problems are easier to formalize than for example, geometry or combinatorial problems. The formalization is done in Metamath, Lean, with efforts for Isabelle ongoing.  The authors run GPT-f on Metamath and Lean, and the tidy baseline (from the PACT paper) on the dataset and present results. They find that proving in Lean is vastly better for performance than Metamath which they conjecture is due to access to higher level tactics in Lean compared to Metamath.","This paper presents miniF2F, a test suite of Olympiad-level problems of theorem proving that is implemented in Metamath, Lean and Isabelle. MiniF2F contains 488 individual theorem statements that are formalized from Olympiad math contests. GPT-f models trained on Metamath and Lean are evaluated on this test suite.",0.14545454545454545,0.32653061224489793,0.2012578616352201
1952,SP:b2a151ab2ee385b50881be2865f6503902f2fcc9,"This paper introduces a model that learns a slot-based representation, along with a transition model to predict the evolution of these representations in a sparse fashion, all in a fully unsupervised way. This is done by leveraging a self-attention mechanism to decide which slots should be updated in a given transition, leaving the others untouched. The model learns to encode in a slot-wise and is trained on single step transitions.","This paper proposes to use a ‘slot-based’ (factored) representation of a ‘scene’ s.t. a forward model learned over some observed transitions only requires sparse updates to the current representation. The results show that jointly learning the forward model and the scene representation encourages meaningful ‘entities’ to emerge in each slot. Additionally, the paper argues that this representation allows for better generalization and can also guide exploration by rewarding actions that change multiple entities",0.2328767123287671,0.22666666666666666,0.22972972972972974
1953,SP:b2a573333b5b1b89b68f307c2b5de571fc84a481,"This paper proposes a new combination method for active learning and semi-supervised learning, where the objective is to make predictions that are robust to perturbations (for SSL) and select points for labeling with labels that differ under perturbations. This technique achieves 2x label efficiency over SSL with uniform-random sampling. Additionally, the authors assess (at least for CIFAR-10 with batch size 50) the best starting random seed set as 100 labels, known as K_0 in this work. This work yields pretty good empirical results and has a conceptually unified approach to SSL and active learning building off of recent works. ","This paper proposes a semi-supervised active learning method to reduce the labeling cost. In the proposed method, a selection criterion to better integrate AL selection mechanism in SSL training framework is designed. The simple metric that aims to measure the inconsistency across a certain number of meaningful perturbations. It considers N perturbed samples of the original input data x, which can be obtained by standard augmentation operations (e.g. random crops and horizontal flips for image data). Then the variance is adopted to quantify consistency.  In this way, the proposed method prefers data samples with high values, which may possess varying level of difficulty for the model to classify. To verify the effectiveness of the proposed method, several baseline methods are compared on several benchmark data sets, and the proposed method has achieved better performance. Meanwhile, to deal with the “cold start” problem, a measure that is found to be empirically correlated with the AL target loss is proposed, and this measure can be used to assist in determining the proper start size. However, there are some minor concerns:",0.22330097087378642,0.12777777777777777,0.1625441696113074
1954,SP:b2b102006ecbc904af657965e067999eea6e8774,"The authors introduce sparse-flows, which is trained by iteratitively pruning a continous normalizing flow network (in this case FFJORD).   Through their experiments the authors show that the sparsified FFJORD model often preforms better than FFJORD and other flow-based models like GLOW, real-NVP etc. They show (on a variety of datasets) that upto a limit, sparsifiying the model can reduce the NLL of the data. The authors also show that pruning flattens the loss surface for Neural-ODEs and show that classifiers trained through sparse-ODEs are more robust than ODEs.","**Summary**  The paper describes the effect of using pruning during neural ODEs training. Namely, the authors propose to train neural ODEs iteratively by alternating training (fine-tuning) and pruning steps. They demonstrate the benefits of applying the proposed training procedure to the density estimation tasks. Also, the paper considers a simple classification task to compare the robustness of decision boundaries of pruned ODE-based flows.",0.12903225806451613,0.18461538461538463,0.1518987341772152
1955,SP:b2c42a7bda0971e7fa51ecfd4cdf4cdb895295de,"The authors consider the effects of backfill dynamics--the correction of historical data--on time series prediction. They use COVID-19 forecasting as the motivating application. Both the features (ER visits, hospitalization rate, etc.) and the target (deaths) are subject to revision, and the authors collect a data set showing that the backfill error due to revisions can be extremely large. The authors make several other interesting observations regarding backfill error and sequences in their data. A key finding is that real-time forecasts tend to overestimate their accuracy when compared to the stable accuracy after errors are corrected. The authors then propose a Back2Future (B2F) pipeline that can be used to refine predictions from a model when backfill dynamics are present. They demonstrate consistent improvement on stable accuracy for multiple COVID-19 forecasts.","The authors deal with the problem of revising previous recorded data and its effect on timeseries predictions. They showcase how revisions in past data, quantified as the backfill error, can introduce a considerable error in predictions. Towards that, they propose a novel deep learning approach, the Back2Future, that refines the model predictions using backfill dynamics. They demonstrate its efficiency on a real COVID dataset.  ",0.19402985074626866,0.40625,0.2626262626262626
1956,SP:b2cb7590f48bb18dbe0f70b894ef981acea1874b,"This work addresses the problem of source-free domain adaptation. Instead of fine-tuning *the source model* on the target data, this work proposes to fine-tune *a representation learned on the target data alone* using e.g. self-supervised contrastive learning. This permits distinct target architectures that can improve performance and/or reduce memory and computational cost.","The paper proposes a multi-stage approach for source-free domain adaptation, namely when source data is not available and one can only use the model pre-trained on the source and adapt it based on unlabelled target domain data. The paper advocates for learning on target not via fine-tuning the source model, but rather distill from it initializing on source using contrastive learning (the authors use Moco V2). The source model is also adapted on target via InfoMax loss before being used as the teacher for the distillation. The authors propose to use the FixMatch strategy (with strong and weak aug taken from AutoAugment) for the distillation. The authors show some gains when combining with SOTA source-free adaptation methods: TENT and SHOT. The authors also show that improved accuracy can be obtained with much smaller models trained on target using their method (e.g. replacing Res50 or Res101 with Res18 on Visda-C. Extensive experiments, ablations, and results are provided.",0.3620689655172414,0.12883435582822086,0.1900452488687783
1957,SP:b2da79a6f231ac2b1aae65062f5eb22bdf97cb2d,"This paper introduces a hybrid model architecture that makes it possible to integrate a separable loss function across a region of input space. Such integrals can be used as regularizers for robustness near the observed data points (local consistency), and out-of-distribution (OOD) detection in neighborhoods away from the observations. The paper uses these regularizers to train models that are less vulnerable to adversarial attacks and out of distribution mishaps.","For input-output pair $(x,y)$, the paper undertakes the task of estimating (*) $E_{x \sim p(x)} \Omega(\hat y(x))$. When $x$ is high dimensional, integration is difficult. Standard ML/DL applies MC to estimate this integral based on an iid sample $(x_i,y_i), i=1,\ldots,n$. This paper suggests there is a better way.   The main idea is to recognize that if $f$ is a separable function and $h$ is a bijective function, then (**) $E_{x \sim p(x)} f(h(x))$ is easy to evaluate. ",0.1267605633802817,0.09782608695652174,0.11042944785276075
1958,SP:b2db29d0d04f1d24db38fab833ec657fbc3955e6,"This paper discusses the problem of controlling a dynamic system based on raw sensory inputs. Their method uses an encoder/decoder to map the sensor information (video frames in this paper) to a learned embedded space. Next, it proposes to build a linear function that evolves the dynamic system’s states in the embedded space. This paper evaluates the performance of the proposed pipeline on three classic control problems: cart-pole, single pendulum, and double pendulum.","This paper, inspired by (approximations of) Koopman operator theory, proposes an adaptive algorithm that learns a (controlled) dynamics model online. The learned model consists of an encoder and estimated (and continuously updated) A, B matrices. The method is shown to work well (with low RMSE and good control performance) on several low-level control tasks with images as the observations (hence the encoder).",0.14473684210526316,0.1746031746031746,0.15827338129496402
1959,SP:b2e35fe3a80f221b5a384f2a2ce66abd92275d63,"This paper investigated the effect of non-uniform sampling in an offline RL setting. Using TD3BC (Fujimoto and Gu, 2021) as a backbone offline RL algorithm, the authors applied prioritized experience replay (PER) to the sampling of TD3AC with variants of priority metric, including standard TD error, rank-based return, pseudo-count using a hash table, and the other three metrics. The authors insist that non-uniform sampling can be helpful in offline RL compared with usual uniform sampling. They also found that there is no one outperforming metric for prioritized sampling in offline RL settings.","This paper empirically studies six variants of prioritized experience replay, typically used in online RL, in a batch RL setting. The comparison is performed using TD3BC on three D4RL Mujoco benchmark environment times 5 data sets. The experiments study the performance and bootstrapping errors. Among other things, it is shown that non-uniform sampling strategies are also interesting in a batch RL setting. The paper also discusses some shortcomings of these approaches and future directions.",0.19791666666666666,0.25333333333333335,0.2222222222222222
1960,SP:b2e738e35c3c6739200f87341678897be89771f7,"The authors present a novel method dubbed AutoBayes that tries to find optimal Bayesian graph models for ""nuisance-robust"" deep learning. They employ the Bayes-Ball algorithm to construct reasonable inference graphs from a generative model given by iterative search. The corresponding DNN modules are then built/linked and trained using a form of variational inference with adversarial regularization where applicable. The authors also propose the use of an ensembling approach to further improve robustness of the ""best"" model.","The paper presents AutoBayes: a new approach for nuisance-robust deep learning which explores different Bayesian graph models to search for the best inference strategy. It automatically builds connections between classifier, encoder, decoder, nuisance estimator and adversary DNN blocks. The approach also enables disentangling the learned representations in terms of nuisance variation and task labels. Different benchmark datasets have been used for evaluation.",0.189873417721519,0.23809523809523808,0.2112676056338028
1961,SP:b2f83cd755f4da835e943237e2ba6faf69e8008a,This paper presents an analysis on the trained recurrent neural networks (RNN) especially for NLP classification problems. The analysis takes the dynamical systems point of view and investigates the dynamics by looking at the Jacobians around the fixed points. This work founds low dimensionalility and attractor dynamics in the RNNs which might lead to a better undertanding of RNNs.,"This paper sheds light on how trained RNNs solve text classification problems by analyzing them from a dynamical systems perspective. It extends recent work where a similar analysis was applied to the simpler setting of binary sentiment classification. When projecting the RNN hidden states to principal dimensions that explain most of the variance, the authors find (N-1) dimensional simplex attractors for N-dimensional classification, 2D attractors for ordered classification, and N-dimensional hypercubes for multi-label classification. ",0.22033898305084745,0.16666666666666666,0.1897810218978102
1962,SP:b31551ab379915f28477cb1f49699cb811a91d29,This paper relates GCN to PCA from the perspective of optimization. The authors propose Graph PCA that is a general form of GCN. They further introduce a regularization term that enforces nodes with same labels close to each other. ,"This manuscript looks at the classic graph-regularized PCA (GPCA) and try to build the connection with GPCA and the state-of-the-art GCN, and finally proposes a new deep graph network GPCANet.  The authors make a number of clear contributions as listed in the paper: 1) they build the connection between GPCA and GCN, 2) Based on this connection, they propose novel way of using such GPCA as a graph layer or as an initialization process for training GCN etc. and 3) thus present a new architecture of GPCANet that performs well on their tests. ",0.3076923076923077,0.12371134020618557,0.17647058823529413
1963,SP:b3180fc8a3ed68988595e881da81393fac04847c,"In this paper, the authors propose a graph-level representation, which extends the existing node-level representation learning mechanism. Besides, both unsupervised and semi-supervised learning are leveraged for InfoGraph and InfoGraph*, receptively. The authors naturally apply Deep Graph Infomax, a contrastive representation learning method, for the whole graph level instead of the previous node embedding learning. The experiments on graph classification and molecular property prediction indicate the effectiveness, even compared to the supervised methods.","The paper presents a new graph representation learning method for the whole graph under both unsupervised and semi-supervised setting. Different from existing ones using graph kernel, or graph2vec, the proposed InfoGraph is able to extract graph-level representation with fixed-length features that are generalized well. Basically, InfoGraph is parameterized by graph neural networks, but guided by mutual information loss. Experiments on both unsupervised and semi-supervised experiments on popular benchmarks demonstrate the effectiveness of InfoGraph and InfoGraph*",0.25333333333333335,0.24050632911392406,0.24675324675324678
1964,SP:b3210d565f51a3a5ea729ffa7e99e1727bd65cdd,"In this work, the authors propose an approach, MIINT, for identifying infected individuals using a network-based approach. They also suggest two key properties, potency and similarity among groups, which impact the efficacy of MIINT and similar approaches. A detailed simulation framework is used to compare MIINT to relatively weak baselines. The simulation results show that the MIINT modestly outperforms the baselines; the results also confirm that all approaches degrade as expected as potency decreases and the similarity among groups increases. Experimental results on a (private) real-world dataset are somewhat mixed, but show that MIINT achieves a better true positive rate at an acceptable false positive rate.","This paper formulates the contagious disease into a missing label problem with dependence between each data point. The paper targets an important problem, especially in this pandemic, and the effort is greatly appreciated. However, the writing of this paper is confusing and it makes it hard to catch the main contribution of this paper. There are some concerns: ",0.09259259259259259,0.1724137931034483,0.12048192771084339
1965,SP:b33082267afa3cdcb3a8e2a049b1a4bc8f3d9d5d,"This paper provides theoretical insight for approximation properties of RNN encoder-decoder architecture in linear setting. More specifically, they study supervised learning problem of temporal modelling where a first RNN encodes a given sequence into a coding vector and a second RNN is responsible to decode said vector to a target output sequence. Linear setting here refers to a linear and continuous-time idealization in eq 6.  Their analysis summarized as following: 1.  Universal approximation: any linear, continuous, and regular temporal relation can be approximated by RNN encoder-decoder up to arbitrary accuracy. 2.  Approximation rate for large size coding vector: beside width of encoder and decoder, this error bound depends on $\alpha$ smoothness of $\mathbf{H}$ and $\beta$ temporal decay rates of the output of constant signal under $\mathbf{H}$ where $\mathbf{H}$ is a sequence of linear, continuous, and regular functionals on inputs. Each $\mathbf{H}$ has a unique two-parameter representation $\rho(t,s)$. Target functionals that are smooth and have fast decaying memory are identified as good target of this approximation. 3.  Approximation rate for small size coding vector: the architecture and the following assumptions in the paper give rise to an intrinsic structure to this type of RNN encoder-decoders called temporal product structure which can be deconstructed into encoder and decoder parts. By relating this structure to rank of temporal relationships they show approximation rate (in small size coding vector) is additionally a function of rank structure of target relationship. This analysis enables us to see the coding vector size as a knob to control number of parameters vs approximation error. 4.  Experiments: they show that the theoretical analysis holds in their experiments.","This paper provides theoretical studies for why encoder-decoder can be seen as a generalization of RNNs in time-inhomogenous sequence modeling. The authors put an impressive amount of effort into mathematically defining approximation properties of RNN encoder-decoders beginning from a universal approximation result.   The authors first show the universal approximation property of RNN encoder-decoders, and subsequently, they show approximation rates of targets for RNN encoder-decoders. They introduce a notion of temporal products that can characterize the temporal relationships in the input/output pair. ",0.1111111111111111,0.3563218390804598,0.16939890710382513
1966,SP:b336aead05ceba504836cebfbf4f36516c94ca09,"In this paper, the authors focus on cross-domain few-shot learning in the case of large source-target domain shifts. In particular, a new Cross-domain Hebbian Ensemble Few-shot (CHEF) learning method is proposed that performs representation fusion using an ensemble of Hebbian learners on different layers of a DNN trained on the source domain. The proposed CHEF method is validated on classification benchmark datasets with smaller domain shifts (miniImagenet and tieredImagenet) and larger domain shifts (drug discovery, ChEMBL20), and it can outperform related SOTA methods, especially with larger shifts.   ","This paper primarily deals with cross-domain few-shot learning. Under this setting, there is a large shift in domain going from the meta-train dataset to the few-shot datasets. Inspired by previous work, the authors argue that high-level concepts might not be useful in this setting but low-level concepts like edges, textures and shapes can be utilized. They propose a Cross-domain Hebbian Ensemble Few-shot (CHEF) learner, that learns an ensemble of classifiers at multiple levels of a deep neural network, thus making use of both low and high level concepts. Experimental results show that CHEF does better, in most cases, than learning a separate classifier at a given level. They show results under the cross-domain and the standard few-shot setting.",0.29347826086956524,0.2109375,0.24545454545454548
1967,SP:b35f74a2fd21a865da1621b2c59ead20e912e3ad,This paper proposes an extension of GCSL where the goal-conditioned BC loss is weighted by a variable that correlates with the number of steps necessary to achieve the desired goal.  The advantage of this approach is that sub-optimal trajectories to a particular goal will get downweighted to the benefit of more direct trajectories.  This effectively adds a policy improvement step to GCSL with the underlying objective function being that of arriving at goal states as fast as possible.    Results on goal-conditioned tasks show that the proposed approach (WGCSL) performs consistently better than GCSL and in some cases significantly better (HandReach-expert).,"The proposed method proposes a method for goal-conditioned RL that can be interpreted as a weighted version of prior work.These weights resemble a combination of discounting and advantage weighting. The paper provides theory arguing that these weights cause the proposed method to optimize a tighter lower bound than prior work. Experiments show that it outperforms the prior work, which does not include weights on each training example.",0.125,0.18840579710144928,0.15028901734104047
1968,SP:b3803f35c83786a139be4422007de99c6e786cf3,"This paper deals with the problem of complementary label learning, that is, when we know the set of labels which a given observation does not belong to. In particular, the paper proposes a robust loss function and an algorithm for learning from complimentary labels. Results shown on MNIST and CIFAR datasets indicate the superior accuracy using the proposed loss function.","This paper studied a new problem, that is, learning from complementary labels.  The goal is to predict a correct label for a given sample when only given complementary labels. On the basis of the ordinary-label learning, the authors defined ""robust loss functions"" for complementary-label learning:  a a loss function is called robust  loss function if minimizer of risk with complementary labels would be the same as with ordinary  labels. Then, they provided  two sufficient conditions for the robust loss function and a exclusion algorithm is provided for prediction. Experimental results show that the proposed method outperforms other methods in several datasets.",0.3333333333333333,0.1941747572815534,0.24539877300613497
1969,SP:b386db96a13357984b61761342ae1cc876fe6d3a,"This paper proposes a new method to defend a neural network agains adversarial attacks (both white-box and black-box attacks). By jointly training a Generative Cleaning Network with quantized nonlinear transform, and a Detector Network, the proposed cleans the incoming attacked image and correctly classifies its true label. The authors use state-of-the-art attack methods on various models, and the proposed model consistently outperforms all baseline models, even dramatically outperforming them for some specific attack methods.","This paper developed a method for defending deep neural networks against adversarial attacks based on generative cleaning networks with quantized nonlinear transform. The network is claimed to recover the original image while cleaning up the residual attack noise. The authors developed a detector network, which serves as the dual network of the target classifier network to be defended, to detect if the image is clean or being attacked. This detector network and the generative cleaning network are jointly trained with adversarial learning so that the detector network cannot find any attack noise in the output image of generative cleaning network. The experimental results demonstrated that the proposed approach outperforms the state-of-art methods by large margins in both white-box and black-box attacks. ",0.34177215189873417,0.216,0.2647058823529412
1970,SP:b392cdc4ce546566457a48e95bfbaea6cad5b44b,"The paper studies batch normalization in deep neural networks. For a two-layer network with scalar output and batch normalization, a dual of the problem is derived. It is then shown that in the high-dimensional regime, the dual can be further simplified so that an optimal solution can be computed in closed form. In the general case, the concept of hyperplane arrangements can be used to formulate an equivalent finite-dimensional convex program which can be solved in polynomial time.   The analysis is then extended for vector output networks and different architectures including L-layer neural networks and CNNs. It is then shown that the convex problems tend to fit low singular value directions which will lead to poorer generalization. As a remedy, the authors propose a truncated variant of the problem by obtaining a low-rank approximation of the data.  In the experimental section, it is shown on the CIFAR-100 dataset that the closed form solution leads to superior results compared to the solution obtained by gradient descent. Moreover it is shown that the truncated variant of the approach is needed to achieve a good generalization performance.","The claim of this paper is casting training neural networks with batch normalization to a convex program solvable in polynomial time. The convex reduction sparks an implicit regularization of batch normalization. Taking inspiration from the convex program and the implicit regularization, the authors improve BN. ",0.1,0.4222222222222222,0.16170212765957445
1971,SP:b3951670f71d8af5e59144d68c7d50405a001227,"This paper investigates a crucial problem, i.e., how to generate good node representations under the InfoNCE contrastive loss in graphs. By studying the feature of loss function’s gradients, it finds that the dynamic temperature change is beneficial to learn uniform node representations. The proposed method GLATE is simple but effective. The analysis of the connection between GLATE and the information bottleneck principle helps us understand why GLATE is so effective. The presentation of this paper is clear and well-organized. For example, Figure 1 makes us easy to understand the problem generated by the static temperature and the significance of this work. The experiments are laid out in detail. The results on the tasks of transductive and inductive learning show GLATE’s advantage over the SOTA graph contrastive learning algorithms.","The authors explore the role of the temperature in the loss function for graph contrastive learning. They argue that global uniformity and local separation are both necessary to the learning quality and this can be controlled by the temperature. Thus, they develop a simple but effective algorithm GLATE to dynamically adjust the temperature value in the training phase. Experiments are also conducted to demonstrate the effectiveness of the method.",0.1590909090909091,0.30434782608695654,0.20895522388059704
1972,SP:b3a424fda4f96b24f753105c1c0ca8b04ebb15e2,"This paper presents a family of constrained universal approximation results for probabilistic transformers.  The authors provide significant theoretical contributions for both convex and non-convex constraint sets.  In my opinion, this represents a significant advance in our understanding of universality in ML.","The paper under review studies the universal approximation theory with constraints.  For any convex or non-convex compact set, a universal approximation is proved through a probabilistic transformer with constraints. Furthermore, a chart-free universal approximation is established on the Riemannian manifold with geodesically-convex constraints.",0.19047619047619047,0.17391304347826086,0.1818181818181818
1973,SP:b3c08f134af295f65238e3ce338e941733858d7e,"The paper studies the problem of document retrieval using embedding based models. It argues that performing near-neighbour search on a large number of dense embeddings hurts performance and accuracy. As an alternative, the paper proposes SOLAR (SPARSE ORTHOGONAL LEARNED AND RANDOM EMBEDDINGS), a model which uses high-dimensional, ultra sparse embeddings, on which near-neighbour search can be done using simple lookup operations. In SOLAR the document labels are divided into equal chunks of sparse vector, and independent models are learned for mapping the query to each chunk. Hence, SOLAR could be trained on multiple GPUs in an embarrassingly parallel way without requiring any communication between the GPUs. The paper demonstrates the effectiveness of SOLAR by comparing it against strong baselines on various recommendation and extreme classification datasets. It also provides theoretical justification for SOLAR by showing how “one-sided” learning (i.e. fixing label embedding but learning mapping from query to label) is mathematically equivalent to “two-sided” learning (i.e. jointly mapping the label and query to a common space).","This submission addresses the problem of learning document embeddings for document retrieval/recommendation tasks. Such tasks are characterized by a large number of documents and a large set of semantic class labels. In contrast to the now standard approach of representing documents and their labels as dense low dimensional embeddings, this work proposes to use sparse high dimensional embeddings for documents/labels and claims that the proposed approach has certain advantages over state of the art:",0.12138728323699421,0.27631578947368424,0.1686746987951807
1974,SP:b3d7af1a904d9b81f819ffd5652add205a7c89dc,"The paper argues that input optimization problems are pervasive in modern machine learning methods (adversarial example optimization, latent optimization in generative models, image completion/denoising). The authors then make a connection to deep equilibrium models (DEQ), which generate an output as a fixed-point of a single non-linear function. The connection is that both input optimization and DEQ process are fixed point iterations and can be solved jointly as an equality-constrained optimization problem. This results in 3-9x speeds on adversarial example generation and generative image modeling tasks.",The paper proposes an extension to the DEQ framework that allows to simultaneously perform input and output optimization of the implicit DEQ layer. The extension called JIIO can itself be cast as another DEQ and backpropagated through. This appears to be useful in a number of applications such as decoder-only autoencoders where the encoder is defined implicitly as optimization over the latent representation. ,0.15555555555555556,0.21875,0.18181818181818185
1975,SP:b403e36027a1f260c7daead40764de7984c943ef,"This paper works on empirically demonstrating the connection between model connectivity and the lottery ticket hypothesis, which are individually explored in the literature. Here the model connectivity refers to the fact that SGD produces different solutions (from the randomness, such as data ordering) that are connected through model parameter transition paths of approximately equal loss/accuracy. The lottery ticket hypothesis tells that there exist sparse subnetworks of the corresponding full dense network which can attain as strong loss / accuracy as the full dense network. ","This paper empirically presents a very interesting connection between two also very interesting phenomena (mode connectivity and lottery ticket hypothesis), while removing a previous limitation of the lottery ticket hypothesis on larger networks. through a good amount of experiments, the authors empirically showed these two phenomena co-occur together (i.e. matching networks are stable) and have positive correlation (i.e. the more “matching” the network the more “stable”), under different network architectures and datasets.",0.23809523809523808,0.26666666666666666,0.25157232704402516
1976,SP:b40d3377562ae081c8491d3f8a03eee5f7ddce41,"This paper proposes a safe reinforcement learning algorithm, CRABS, which can achieve zero training-time safety violations. The key idea is to iteratively learn the dynamic model, the policy and the barrier certificates. The barrier certificates are learned via adversarial training and can constrain the exploration of the policy in the safe set. The proposed algorithm is evaluated in four simple classical control problems (variants of inverted pendulum and cartpole). The evaluations demonstrate zero training-time violations and comparable learning performance compared to other safe learning baselines.","The paper proposes an RL algorithm that starts from an initial safe but low return policy that is iteratively improved while ensuring no safety violation occurs during the rollouts required by the training. The paper achieves this by learning barrier functions as safety certificates.  The two ""simpler"" barrier conditions are directly enforced in the structure of the learned function. In contrast, the ""closed under a policy+environment step"" condition R3 is checked heuristically on a probabilistic model of the environment with a Metropolis-adjusted Langevin algorithm.  Finally, the authors evaluate the achieved return and number of safety violations of their RL algorithm and other RL algorithms on variations of the Pendulum and CartPole gym environments.",0.27586206896551724,0.20869565217391303,0.2376237623762376
1977,SP:b43b18dff27627655d43c7d1c297256373c18cee,"The paper develops a deep probabilistic model for forecastic stochastic time series with application to epidemic forecasting. The proposed algorithm encodes data points (weekly flu records) comprising a time series of arbitary size into a fixed-sized embedding by passing it through a GRU and binding the hidden states via self attention. Another round of self attention is used to relate whole time series (seasons). Next, it calculates a probabilistic cross attention graph, the edges of which match the whole time series of full seasons of past years to snippets from the current season. The data generating process where all building blocks come together is inferred by a standard variant of amortized variational Bayes. The paper conducts a rigorous set of experiments on a public flu statistics database to analyze multiple aspects of the proposed method and the benchmarks, such as prediction accuracy, uncertainty calibration, and explainability. The proposed method improves the state of the art with respect to all these aspects with a clear margin.","This paper proposes a method for probabilistic time series forecasting for univariate real-valued data (they just consider Influenza-Like Illness) using a semi-parametric neural network. The basic idea is to embed the prefix of observations for the current season into a fixed-sized latent vector using a GRU, and to embed all past full-year sequences into latent vectors, and then to compute a weighted average of the most similar embeddings from the past and to use this feature inside an MLP to predict the future, k-weeks ahead. They evaluate on the CDC dataset and report improved point estimates and calibration scores. ",0.16265060240963855,0.2571428571428571,0.19926199261992616
1978,SP:b44bdec4ffc5f79048deedf805b2835067bca899,"In this paper, the authors propose a new mechanism to perform the attention operators. The similarity between a key and a query is performed as the dot product between a trainable weight and the addition of the key and query.  The proposed Siamese attention operator is much more efficient than prior attention methods in terms of speed. The evaluation on a few computer vision tasks shows the presented method performs as well as the typical attention methods, but it runs much faster. ",The authors introduce a novel self-attention operator for neural networks. Their self-attention operator computes similarity between elements a and b as (a+b)^Tw where w is a learned parameter and does not use the softmax operator. This leads to improvements in space and time complexity compared to regular self-attention which uses the dot product (a^Tb).,0.2073170731707317,0.2833333333333333,0.23943661971830987
1979,SP:b451949bef9c16fe4dea78ef337d7f7dcbae3f90,"This paper proposes to learn static and dynamic channel pruning policies for convolutional neural networks. Static pruning depends only on the training dataset and is computed once before the model is deployed. Dynamic pruning is input-dependent. The policies are obtained with deep reinforcement learning on the training dataset using a combination of the loss function and storage/computation resource budgets as a reward signal. The key novelty in this paper is to combine static and dynamic pruning which can obtain the benefits from both worlds. Experimentally, the learned pruning policies are competitive with recent dynamic pruning approaches on CIFAR-10 and ILSVRC2012, in terms of both final test accuracy and number of parameters/inference time.",This work introduces a Reinforcement Learning based framework that simultaneously learns both a static and dynamic pruning strategy. The combination allows the static pruner to decrease the required storage while the dynamic pruning can optimize the required compute using input-dependent pruned weights. The RL agent can dynamically learn the optimal sparsity distribution among the different layer of the networks while staying under a resource constraint as opposed to other methods which often enforce a layer level sparsity ratio. It demonstrates the efficacy of the algorithm on CIFAR10 and ILSVRC2012 and showed the effect of the tradeoff between static and dynamic pruning.,0.23275862068965517,0.2647058823529412,0.2477064220183486
1980,SP:b46afcbaf09319053c4ae21b7ee68a34c78dc28f,"The authors propose a new loss function as well as an adjoining visualization for improved performance of hard negative / easy positive mining for deep triplet metric learning. The authors note that under the NCA loss, if one selects an easy positive / hard negative and computes the gradient with respect to this example, this can lead to the negative example also being pulled closer to the anchor which is undesired. Similar phenomena can also be observed for easy positive / semi-hard negative mining as well. Motivated by this, the authors begin by designing a visualization to make this issue with NCA loss more apparent. Then they design what they refer to as an “entanglement factor” to quantify this issue more precisely. Using the desired dynamics of the gradients for the easy positive / hard negative mining and integrate to form what they refer to as the “second order loss.” Using this loss, they compare against the standard NCA loss on several datasets, showing modest performance gains. They also compare against a variety of other deep triplet embedding frameworks and show competitive results.","This paper uses the triplet scatter plot as a way to describe triplet selection strategies. The authors explain previously observed bad behavior for hard-negative triplet mining showing that it tends to make all points close to each other. The authors propose a simple modification to the desired gradients and derive a loss function that gives those gradients. With this modification, they show that easy positive hard negative (EPHN) gives results that exceed or are competitive with state of the art approaches. The paper is well-written and makes a convincing argument which will be of interest to a broad community.",0.1388888888888889,0.24752475247524752,0.17793594306049823
1981,SP:b478b1c0c0f94040c6272af647685b0185cf16ca,"This paper proposed a new adversarial attack method by using Markov chain Monte Carlo.  Based on this attack method, a new adversarial learning method called adversarial training by using Contrastive Divergence (ATCD) which approaches equilibrium distribution of adversarial examples with only a few iterations is performed. The experimental results demonstrated the effectiveness of ATCD.","Adversarial examples are time-consuming to generate. In this paper, the adversarial training is reformulated as a combination of stationary distribution exploring, sampling, and training. A Hamiltonian system is proposed to model data samples from their initial states, and is shown as the general form of FGSM. The sample generation method is proposed via contrastive divergence with few training iterations. Experiments have been validated on datasets. ",0.18518518518518517,0.15151515151515152,0.16666666666666666
1982,SP:b47a2f74c2155720bad53fdd1d07036a4cc754f5,"The authors of the paper are adding a  parametrized (by input data) layer to perform a renormalisation step from a small scale PDE to larger scale system. This requires a definition of a closure term that modifies the equation at the larger scale to match the behaviour at the a more accurate, smaller scale. This is shown to significantly reduce the required computing resources, while still retaining high accuracy.  More, the system is defined on graph convolutional network that is applicable to complex mesh structures that are required for proper description of many real world problems.  The authors introduce a simplified form of the attention mechanism that is missing the value vectors and softmax portions, but gives a possibility to introduce a degree of  non-linearity to the activation, besides the activation function. The expectations is that this will help the network to reach accuracy with fewer computations. This is  validated in the  CFD cases considered in the paper.","This paper proposes methods for neural simulation of physical systems on graphs. In particular it proposes the use of hyper-network style layers (CP-dense) where the weights of the layer are determined by regressing some context parameter. These layers are combined in the CP-GNet architecture, which shares a similar encoder / process / decode structure to MeshGraphNets. The proposed layers are shown to yield performance improvements on simulation tasks relative to dense layers.",0.07547169811320754,0.1643835616438356,0.10344827586206896
1983,SP:b4874a9e8d55c290a6fe83bb7d88be93e31d9842,"This paper proposes to optimize the state marginal distribution to match a target distribution for the purposes of exploration. This target distribution could be uniform or could encode prior knowledge about downstream tasks. This matching can be done by iteratively fitting a density model on the historical data from the replay buffer, and training a policy to maximize the log density ratio between the target distribution and the learned density model. Experiments are performed on two domains: a simulated manipulation task and a real robotic control task. Overall, the paper is well-written.","The paper proposes to frame exploration in reinforcement learning as a distribution matching problem. More specifically, the proposed method (SMM) aims to minimize the reverse KL between the state distribution induced by the policy and a desired state distribution. The desired state distribution can be used to guide exploration (e.g. by penalizing bad states) or can be chosen uniformly (resulting in a policy that maximizes state entropy).",0.17204301075268819,0.23529411764705882,0.19875776397515527
1984,SP:b49a36c9f58b31442d37feac1e564af804f5eed3,"In this submission, the authors propose a three-stage framework for large-scale graph embedding. The proposed method first constructs a small graph by graph coarsening, then applies any existing graph embedding method, and last refines the learned embeddings. It is useful, however, the experimental results are not convincing and cannot support the authors' claims about the proposed method.","This paper proposed a multi-Level framework for learning node embeddings for large-scale graphs. The author first coarsens the graphs into different levels of subgraphs. The low-level subgraphs are obtained with the node embeddings of the higher-level graphs with a graph convolutional neural network. By iteratively applying this procedure, the node embeddings of the original graphs can be obtained. Experimental results on several networks (including one network with ~10M node) prove the effective and efficiency of the proposed method over existing state-of-the-art approaches.   ",0.3389830508474576,0.2247191011235955,0.2702702702702703
1985,SP:b4ac58e24c0304c3976ef46e9ef7cee9ee6483bf,The authors introduce a new variant of GPFA for neural data that includes an ARD prior over the mixing matrix to automatically learn dimensionality. The authors also develop specific inference methods for this work as well as exploit structure in the covariance matrix for stability/speed. The authors test their model on synthetic data to demonstrate that the bGPFA model correctly identifies true latent dimensionality and performs well in situations with Poisson and Negative Binomial noise.  The authors also show model performance on multi-region reaching data in monkey cortex and explore the presence of time delays in the model.,"The authors introduce a Bayesian GPFA model, and extend this formulation to non-Gaussian noise models. A Gaussian prior over the loading matrix is proposed, and the paper employs a variational inference strategy for the inference of the model. The inference is shown to be efficient in the number of data points and helps in automatic relevance determination of the observations, as well as learning the appropriate number of latent variables to use. The method is used on a synthetic dataset to recover the dimensionality and the structure of the latent dimensions. Additionally, the method is applied to neural data from primates during a self-paced reaching task, with recordings from the primary somatosensory and motor cortices.",0.26,0.2222222222222222,0.23963133640552994
1986,SP:b4c82616d2410a07ecce89da0e5dc9428f9209ae,"A method to predict likely type of program variables in TypeScript is presented. It consists of a translation of a program's type constraints and defined objects into a (hyper)graph, and a specialised neural message passing architecture to learn from the generated graphs. Experiments show that the method substantially outperforms sound typing in the TypeScript compiler, as well as a recent method based on deep neural networks.","This paper proposed to use Graph Neural Networks (GNN) to do type inference for dynamically typed languages. The key technique is to construct a type dependency graph and infer the type on top of it. The type dependency graph contains edges specifying hard constraints derived from the static analysis, as well as soft relationships specified by humans. Experiments on type predictions for TypeScript have shown better performance than the previous methods, with or without user specified types. ",0.20588235294117646,0.18181818181818182,0.19310344827586207
1987,SP:b4e02a29e7fadf041f25c131fd2d2ff2ccd46dfb,"This paper proposes an approach to perform statistical inference for hierarchical models with intractable likelihoods. It extends an existing approach for simulation-based inference (SNPE-C) in order to use models that have global and local random variables.   The authors propose a scheme in which two conditional flows a trained: The first flow models a distribution over global parameters given an observation and $N$ permutation invariant auxiliary observations. Permutation invariance could e.g. be accounted for with a deepset architecture. The experiments do not make use of this flexibility, relying on an average operation instead. The second flow then models a distribution over local parameters given the observation and global parameters. They refer to the resulting inference scheme jointly as h-Flow, for hierarchical flow.  A motivating toy example is provided, along with a relevant, more realistic simulator from Neuroscience (a Neural Mass Model; NMM). h-Flow is compared against a naive approach on both of these examples. The comparison turns out about equal on the toy example and favorably for h-Flow on the NMM. On the toy example, h-Flow is additionally compared against a hierarchical ABC variant and LFVI, comparing favorably to both of them.","The authors propose a new likelihood-free inference method for Bayesian hierarchical models, called h-Flow, that exploits additional information provided by a set of auxiliary observations with shared, global parameters. h-Flow works by approximating two relevant posterior distributions, i.e. that of the global parameter beta and the local parameters alpha given beta, with separate normalizing flows, which are then multiplied to yield the joint posterior distribution. The normalizing flows are trained by minimising the KL-divergence between the true and approximated posterior distribution and the training data is refined over several rounds by means of SNPE-C (also known as APT).",0.1111111111111111,0.21153846153846154,0.14569536423841062
1988,SP:b4e3c2c496f9d52800ffc4d19c9a40eab410b464,"The idea is nice. It is well aligned with tools that are needed to understand neural networks. However, the experiments feel like they are missing motivation as to why this method is being used. The paper does not provide very significant evidence that this method is useful. The negation example is nice but this doesn't seem to display the potential power of the method to understand a neural network.",The authors propose a notion of conductance to attribute the deep neural network’s prediction to its hidden units. The conductance is the flow of attribution via the hidden unit(s) in consideration. The paper proposes using conductance to not only evaluate importance of hidden unit to the prediction for a specific input but also over a set of inputs. The strongest part of the analysis of conductance is that conductance naturally couples  the path at the base features with that of the hidden layer.,0.18571428571428572,0.15294117647058825,0.16774193548387098
1989,SP:b4e5b4a3546fdec14a958bbe0d387bce946396b0,"The authors of the paper propose a new method, the CORES (COnfidence REgularized Sample Sieve), to tackle the important problem of learning under instance dependent label noise. The proposed method, in essence, involves the use of a confidence regularization term that encourages more confident predictions and a sieving process to remove the samples with large losses. Theoretical justification and empirical experiments were conducted to demonstrate the effectiveness of the proposed method. ","The paper introduces a noise-robust loss function CORES2, motivated by peer loss. The novel loss adds a regularization term that promotes confident prediction and pushes the model prediction away from the prior of the label. Using this loss function, the authors propose a dynamic sample sieve to separate the clean data and corrupted data on-the-fly, by the magnitude of CORES2 loss. The author's approach is to rule out samples whose losses are larger than an adaptive threshold. Importantly, the process of sieving successfully sieves out corrupted samples, both in a theory of 'better than random guess classifier' and in practice. The authors, then show that the proposed CORES2 can be decoupled under the instance-dependent noise setting. Then CORES2 is proved to be noise-robust, which means CORES2 is equivalent to minimizing the original cross-entropy loss. They also show a principle approach for finding the hyperparameters $\beta$. Further, a consistency loss is adopted after sample sieve on the corrupted samples. The author conducts extensive experiments, including CIFAR10, CIFAR100, and Clothing1M under different settings of noise. CORES2 achieves the SOTA results in all the experiments.",0.30985915492957744,0.1164021164021164,0.16923076923076924
1990,SP:b5433e6f4dc436a4a15554124a790aa794d5dc0d,The paper proposes adding two mechanisms to the BERT architecture for NLU. The first is based on integrating information from all layers of the encoder via a method called Squeeze and Excitation. The second uses Gaussian blurring to encourage information sharing among neighboring words. The proposed method improves modestly on BERT on the GLUE suite of problems. It also substantially improves on BERT with respect to a class of examples that are designed to confound models that learn superficial heuristics based on word occurrence.,"This paper proposes a novel BERT based neural architecture, SESAME-BERT, which consists of “Squeeze and Excitation” method and Gaussian blurring. “Squeeze and Excitation” method extracts features from BERT by calculating a weighted sum of layers in BERT to feed the feature vectors to a downstream classifier. To capture the local context of a word, they apply Gaussian blurring on output layers of the self-attention layer in BERT. The authors show their model’s performance on GLUE and HANS dataset.",0.21428571428571427,0.2222222222222222,0.21818181818181817
1991,SP:b54979281d5d198dd7ec9514793945e14f77d320,"The paper proposes a formulation for taking care of neighborhood of different distances for graph embedding. It makes use of a notion called permutation invariant function which defined as a function where if we swap any features in the inputs, the function value remains the same. Given this, they make two contributions to make the consideration of neighborhood of different distances for graph embedding possible. First, they make the assumption that the contribution of neighbours of same steps should be the same and thus permutable in defining how the embedding function of a node is depending on this neighbours. Another one is the use of 1-d NN for estimating the contribution from 1-step, 2-step and up to infinite-step. Then, the overall problem formulation is defined and can be learned using SDG.","The paper explores the very interesting and relevant problem of universal node representation.  It points out that although powerful models for representation learning on graphs exists, most existing works require to pre-define a pairwise node similarity or to specify model parameters. Hence, the authors propose a novel model that doesn’t require to pre-define neighbors nor to specify the dependence form between each node and its neighbors.",0.08148148148148149,0.15942028985507245,0.10784313725490197
1992,SP:b54f917ab6d50c280b4c973a268e16bc08be0f83,"This is a strong paper that is well-motivated and well-written. I enjoy reading the paper, thinking about the questions and learning the new results.  Contribution on problem formulation: The paper provides a new offline RL framework that accommodates the entire data composition range, smoothly interpolating between two regimes: expert data and data with uniform coverage.   Contribution on algorithm design and the upper bounds: The paper provides a lower-confidence-bound algorithm that achieves almost optimal performance in multi-armed bandits and MDPs, and optimally solves the offline learning problem in contextual bandits. It is interesting to see that in all the three settings, LCB achieves a faster rate of 1/N for nearly-expert datasets compared to the usual rate of 1/\sqrt{N} in offline RL.  Contribution on the lower bounds: The paper provides information-theoretical lower bounds to capture the fundamental hardness for this new offline RL framework. The paper also has interesting discussion on whether the knowledge of C* is necessary to design optimal algorithm.","This work presents a simple algorithm for offline reinforcement learning based on optimizing the sum of lower confidence bounds of rewards for each transition (where the confidence bound is constricted using the offline dataset of transitions).  Theoretical bounds are given on the suboptimality of the resulting policy, based on the quantity $C^*$, which bounds the proportion of non-optimal transitions in the dataset.  Conditional on there being a finite ratio of non-optimal to optimal actions in each state, the presented algorithm has good performance in both the ""expert data"" case, in which the behavioral policy that generated the data is close to optimal, and the ""uniform coverage"" case, in which the behavioral policy covers all possible transitions. ",0.15294117647058825,0.22033898305084745,0.18055555555555555
1993,SP:b562599572cd55c95dd0f8e1449ba6c6cfdd14e1,"This paper considers the problem of policy learning in Markov Decision Process (MDP) from the combination of online and offline samples. The offline samples are generated by a behavior policy in the same MDP model, i.e., the behavior agent and the learning agent share the same state-action space. The learning procedure goes as follows. One first trains a MDP policy from the offline data; the online samples are then used to fine-tune the learned policy.","This paper proposes to deal with distribution shift problem between online and offline samples when the agent trained by offline data is fine-tuned with online interactions. Two mechanisms are introduced: (1) using two replay buffers for offline and online data respectively, and training the agent with data sampled from these two buffers with a certain ratio (the ratio changes in a way that more online data is used in later epochs); (2) learning an ensemble of independent agents in the offline phase, and distilling them into a mean policy to overcome bootstrapping error. Empirical results demonstrate that the proposed method perform well during fine-tuning when there is distribution shift.",0.24358974358974358,0.17117117117117117,0.20105820105820107
1994,SP:b57dd473377d8ec5ef38f2cebd1f83a847270b27,"This study focuses on the stability of multi-branch networks. It analyzes the forward and backward stability of multi-branch network, and builds the relations with some widely-adopted initialization and normalization schemes. A simple new aggregation method is proposed that enjoys better stability than the sum and average aggregations. The method is extended to the multi-head attention layer in Transformer. Experiments on image classification and machine translation tasks using ResNeXt and Transformer are conduced to show the efficacy. ","This paper studies the training of multi-branch networks, i.e. networks formed by linearly combining multiple disjoint branches of the same architecture. The core contribution in this paper is the “STAM” aggregation rule which is to set the combination coefficient to $1/\sqrt{C}$ for a network with $C$ branches. This aggregation rule is justified by (1) theoretical analysis on the function values and gradient norms at initialization, and (2) experiments on residual networks and transformers showing that this rule performs better than the baseline rules (such as sum or average).",0.2125,0.18478260869565216,0.19767441860465115
1995,SP:b593d6d2dcfb7781a993c9a1a85e4685f1c1990d,"This article is a position statement that aims to point out weaknesses in the  authors' conception of the ML field's agenda. As the authors state, the work is descriptive, not prescriptive: it does not provide specific directions, but rather points to trends that (in the extreme) are problematic. The key points in the article include: (1) natural environments provide rich support for learning beyond traditional supervised classification labels; (2) evolutionary and developmental processes provide strong inductive biases that can  inform model design; (3) the amount of data that natural learners have available is often underestimated (as is one-shot learning abilities); (4) there are many signals in natural environments which can constrain learning beyond traditional class labels.","With this opinion paper the authors aim at clarifying some terminology commonly used in the modern deep learning literature. The goal is to highlight the strong overlap between several approaches that have been proposed as ""alternatives"" to supervised learning: predictive, unsupervised, semi-supervised and self-supervised learning. According to the authors, such proliferation of terms has been promoted by the (wrong) conviction that supervised learning is too limited in scope and does not account for the great variety of learning mechanisms observed in biological agents. The authors argue that the deep learning community would benefit from a clarification in terminology, which could highlight that, overall, all learning approaches can be defined as “supervised”.",0.1694915254237288,0.17699115044247787,0.17316017316017315
1996,SP:b596fd3d45ea581a519346600064035c14f62877,"This paper proposes a novel algorithm NeuralMCS for maximum common subgraph (MCS) identification. The proposed algorithm consists of two components. One is a neural-network model based on Graph Matching Networks (GMN, Li et al, 2019) to learn a node-to-node matching matrix from examples of the ground-truth MCS results. Another is the algorithm called GSE (Guided Subgraph Extraction) to obtain an MCS by making an explicit assignment from the estimated matching matrix by the NN model. Experimental comparisons are made to other NN-based approaches combined with threshold-based assignments by the Hungarian algorithm (w.r.t the accuracy) and to a state-of-the-art exact algorithm MCSplit, and show the effectiveness of NeuralMCS.","This paper proposed a graph net based approach for subgraph matching. The general idea is based on the graph matching network (Li et.al, ICML 2019) that computes the node embeddings of two graphs with co-attentions. The training requires the supervision of ground truth matching. During inference an iterative method with heuristic stopping criteria is used. Experiments on tiny graphs show better results than learning based baselines, but worse results than MCS solver.",0.19491525423728814,0.3108108108108108,0.23958333333333334
1997,SP:b5ada6c8353b28ae7c30e8cf3a1346db9c04033d,"The authors study exact asymptotics of the dynamics of momentum-accelerated SGD for a least-squares regression model with a ""mean-field"" regression design matrix A, in the scaling limit where n,d -> infinity proportionally. The paper has the following contributions:  (1) The authors introduce a d-dimensional diffusion approximation, eq. (7), which they conjecture to describe the asymptotic behavior of a class of momentum-accelerated multi-pass SGD algorithms, under certain assumptions for the design. The conjecture is proven rigorously for (non-momentum-accelerated) SGD and orthogonally invariant designs A in Theorem 2, using a small adaptation of the argument by Paquette et al '11. A heuristic derivation of this approximation for the more general class of momentum-accelerated algorithms of interest is given in Appendix B.1, and the conjecture is supported strongly by numerical results on both Gaussian designs and regression designs derived from MNIST images.  (2) The authors prove that the expected loss value at any epoch t that is predicted by this diffusion equation admits a form given by a Volterra integral equation, Theorem 1, which depends on the eigenvalues of the Hessian A'A. Assuming the correctness of the approximation in (1), the convergence rates of various momentum acceleration schemes may then be analyzed and compared by analyzing the long-time behavior of this Volterra integral equation.  (3) The authors carry out this analysis of the Volterra integral equation for the heavy-ball and Nesterov acceleration schemes, and establish either exponential rates of convergence or polynomial rates of convergence to the limit loss, depending on whether d/n -> 1. (This limit loss is not zero in the studied regime, and is instead characterized by Theorem 3.) The results of this analysis are summarized in Table 3. This analysis is more straightforward for the heavy-ball method, where the kernel defining the Volterra equation is of convolution form. For the Nesterov-accelerated scheme, the authors show that the long-time dynamics may be approximated by a convolutional kernel (Appendix C.3) and hence analyzed via this approximation.  (4) A few practical insights from this analysis are a prescription of the scaling of the step size and momentum parameters in n that are needed to obtain a speed-up over non-accelerated SGD, and the dependence of this speed-up on the choice of acceleration scheme (heavy-ball vs. Nesterov) and on the ratio d/n.","This paper analyzes the behavior of stochastic gradient algorithms on a high dimensional least-squares problem. Under the proposed unified framework, it concludes that stochastic momentum methods with a fixed momentum parameter does not improve the convergence of SGD. The authors then propose a new algorithm with momentum parameters depending on sample size, which achieves an optimal complexity asymptotically.",0.0475,0.3220338983050847,0.08278867102396514
1998,SP:b5c515f4c6ba9dea26e5871b31528e1edc6597bd,"The paper presents techniques for training a non expansive network, which keeps the Lipchitz constant of all layers lower than 1. While being non-expansive, means are taken to preserve distance information better than standard networks. The architectural changes required w.r.t standard networks are minor, and the most interesting changes are made to the loss minimized. The main claim of the paper is that the method is robust against adversarial attacks of a certain kind. However, the results presented show that a) such robustness comes at a high cost of accuracy for standard examples, and b) even though the network is preferable to a previous alternative in combating adversarial examples, the accuracy obtained in the face of adversarial attacks is too low to be of practical value. Other properties of the networks, explored empirically, are that the confidence of the prediction is indicative of robustness (to adversarial attacks) and that the networks learn better in the presence of high label noise. ","This paper presents a combination of methods that, together, yield neural networks that are robust to small changes in L2 distance. The main idea is to ensure that changing the input by a bounded L2 distance never changes the output by more than the same L2 distance. Then, the difference between the highest-scoring class and the second-highest scoring class provides a bound on how much the input must change. The trivial way to do this is to rescale the final output layer so that all of the magnitudes are very small; however, this would give no additional robustness at all. To counteract this, the paper introduces several additional heuristics for increasing the gap between the highest-scoring class and the second-highest scoring one. Adversarial training can be used to make the models even more robust. ",0.18404907975460122,0.21739130434782608,0.19933554817275745
1999,SP:b5d287a76a010838b352f4ec537fd83ef1f064cc,This paper investigates the way decaying the learning rate helps the training of neural networks. First the paper discusses about other existing hypothesis such as the “Gradient Descent Hypothesis” by Lecun et al 1991 and SGD explanation by Kleinberg et al 2018. Then the paper tries to find contradicting examples against those two hypothesis with experiments. Then they propose their explanation which suggests that initially fitting noisy data and then decaying it helps it to learn more complex data. Then the paper tries to experimentally explain why the other explanations fail and theirs is better.,"The paper investigates the role of learning rate decay in neural network training. While there are prevalent ideas of how/why learning rate decay help both optimization and generalization of neural networks, this work proposes interpretation based on pattern complexity. The mechanism the paper proposes is that initial learning rate helps ignore noise in the beginning and decayed learning rate help to learn complex patterns. ",0.17894736842105263,0.26153846153846155,0.2125
2000,SP:b5f024a484f19add02eb52a485c2b4806ff5528e,This paper addresses the problem of learning segmentation models in the presence of weak and strong labels of different types. This is an important problem that arises while learning in data-scarce settings. The presented approach optimizes jointly over the various types of labels by treating each one as a task. They extend the U-net architecture to incorporate the different tasks.,"This paper proposes a method for semantic segmentation using ""lazy"" segmentation labels. Lazy labels are defined as coarse labels of the segmented objects. The proposed method is a UNET trained in a multitask fashion whit 3 tasks: object detection, object separation, and object segmentation. The method is trained on 2 datasets: air bubbles, and ice crystals. The proposed method performs better than the same method using only the weakly supervised labels and the one that only uses the sparse labels.",0.1935483870967742,0.15,0.16901408450704225
2001,SP:b5f7c5fcade8783b63c1067e0a14f5bafa88dfce,"This paper identifies a common problem in previous VAE related models: adding more stochastic layers to an already very deep model yields small predictive improvement while substantially increasing the inference and training time. Therefore, a new model that proposes to use attention mechanisms to build more expressive variational distributions in deep probabilistic models by explicitly modelling both local and global interactions in the latent space is proposed. The model is evaluated on standard dataset MNIST and OMNIGLOT, and showed superior performance against a wide range of baseline models.","This paper improves the architecture of deep VAEs using the attention mechanism.   The attention mechanism is used in two ways: 1. layer-wise attention (attending stochastic feature maps which are conditioned on other variables within the hierarchy, interpreted as a mixture of skip connections) 2. non-local attention (attention across the spatial dimensions, increases the size of receptive field)  The authors demonstrate the effectiveness of their architectural changes by challenging current sota deep VAEs on MNIST, OMNIGLOT and CIFAR-10. Notably, they outperform the state-of-the-art methods (in likelihood) on CIFAR-10 using fewer layers and fewer GPU hours.   The authors provide an extensive ablation study, showing the impact of each type of attention on the training performances (test likelihood on CIFAR-10).",0.1590909090909091,0.112,0.13145539906103287
2002,SP:b619dae0690930ba616bfeb3e32e89de6e798993,"This work makes an interesting observation that it is possible to use exponentially growing learning rate schedule when training with neural networks with batch normalization. This paper provides both theoretical insights and empirical demonstration of this remarkable property. In detail, the authors prove that for stochastic gradient descent (SGD) with momentum, this exponential learning rate schedule is equivalent to constant learning rate + weight decay, for any scale invariant networks, including networks with Batch Normalization and other normalization methods. This paper also contains an interesting toy example where  gd converges when normalization or weight decay is used alone while not when normalization and weight decay are used together.","This exciting and insightful paper presents theorems (and illustrating examples and experiments) describing an equivalence of commonly used learning rate schedules and weight decay settings with an exponentially increasing learning rate schedule and no weight decay, for neural networks with scale-invariant weights. Hence, the results apply to a large set of commonly employed settings. The paper contains an interesting example of a neural network for which gradient descent converges if with batch normalization as well as with L2 regularization, but not when both are used. ",0.2336448598130841,0.29069767441860467,0.2590673575129534
2003,SP:b61b07e85d8e940816c1a769cb4c695112f5c7ad,"This work focuses on weight pruning at initialization. In this paper, the authors point out an important problem that the pruned subnetwork at initialization is going to be trained and previous prune-at-init methods ignore this fact. As a result, these prune-at-init methods ignore the trainability of weights. This paper proposes to use meta-gradients through the first few steps of optimization to determine which weights to prune. Experimental results show that ProsPr (this paper) achieves state-of-the-art pruning performance.","This work studies the problem of pruning neural networks at initialization. It first identifies that the saliency score defined by the existing method SNIP has room for improvement. Specifically, the authors propose a method named prospect pruning to take into account the sequence of weight updates to determine the pruning mask. The experimental results on Tiny ImageNet and CIFAR show that the proposed method achieves better performance than existing methods of pruning at initialization.",0.23529411764705882,0.2702702702702703,0.2515723270440252
2004,SP:b63d45fa7937d0efe9d4d471ca75e52114393ea7,"This paper provides a novel off policy objective to solve imitation learning. It resolves the limitation of the famous GAIL algorithm that we need on-policy samples to interact with the environment. The new algorithm is simple but efficient, and can handle off-policy settings. The derivation of equation (12) is nice and intuitive, provide a potential on creating new imitation learning algorithm. Empirical results show that the new algorithm can perform as good as the state-of-the-art baseline, under on-policy setting.","This paper presents an algorithm for adversarial imitation that uses off-policy data in a principled manner, unlike prior work. The core idea is to express the KL-divergence between the policy's state-action marginal and the expert's state action marginal using the Donsker-Varadhan representation and then applying the change of variable similar to DualDICE to avoid computing the marginal of the current policy, thus getting rid of the on-policy sampling requirement. The paper then shows how the auxiliary variable (critic) added to the optimization is a value function that maximizes the corresponding induced reward in AIL methods, thus unifying the objectives for policy optimization and reward learning. The authors then present practical considerations needed in getting this formulation to work, including sampling from a replay buffer, biased sampling for the exponentiated term and avoid the double-sampling issue. Finally, the paper presents some results, which show that valueDICE is comparable to most of the other imitation learning methods. ",0.24705882352941178,0.12883435582822086,0.1693548387096774
2005,SP:b64e0883045830bbcf2438c94e653564762eeab0,This paper presents two fundamental questions about the assumption of existing PML research. The authors derive a novel PML method from a probabilistic formulation which meets the $\epsilon$-identifiable definition. They provide theoretical analysis and algorithms to verify the proposed two questions. Thorough comparative experiments validate the superiorities of the proposed method.,"The paper addresses the problem setting of partial multi-label learning (PML). The task is to select the ground-truth labels from a set of label candidates and disregard false-positive or noisy labels that may occur in the labelling process. The authors propose MILI-PML that exploits dependencies between labels and features for selection and relies on the assumption that ground-truth labels have a higher overall dependency between labels and features than false-positive ones. The paper provides theoretical analysis to show that the model can identify ground-truth labels from a candidate set correctly and propose a corresponding optimization procedure. Further, the authors conduct experiments to demonstrate the effectiveness of MILI-PML and claim that the method achieves superior performance compared to other SOTA methods.  ** Thanks for the response to this review. ",0.34615384615384615,0.13333333333333333,0.1925133689839572
2006,SP:b65c6ca0d33243de3419efafb5f102512960d994,"The paper presents an approach to isolate factors of variation using weak supervision in the form of group labels. The proposed method Affinity Cycle Consistency (ACC)  claims to work with these group labels, which are weaker than the more common, one factor per group type labeling.  An important aspect of this approach is that it does not attempt to disentangle the factors of variation, but only capture (or isolate) them in the latent space. ",This paper applies a weakly-supervised learning approach to identify factors of object postures in an image dataset. The core idea is to introduce two sets of images. The first set is the reference data set with grouped objects of different active/inactive posture constraints. This set is used to provide weak supervision information in posture identification. The second set is the probe set. It does not necessarily require posture grouping of objects. Affinity Cycle Consistency loss is set up to automatically map objects of similar active postures between the two image sets (objects of similar postures are supposed to be the nearest neighbors in the learned embedding space). The experimental study verifies the validity of the proposed factor isolation algorithm. ,0.2972972972972973,0.18181818181818182,0.22564102564102564
2007,SP:b65f2b9b46b4ae629b97125ea036154e6bccaed2,"The paper proposes a new approach to compute hyperbolic embeddings based on the squared Lorentzian distance. This choice of distance function is motivated by the observation that the ranking of these distances is equivalent to the ranking of the true hyperbolic distance (e.g., on the hyperboloid). For this reason, the paper proposes to use this distance function in combination with ranking losses as proposed by Nickel & Kiela (2017), as it might be easier to optimize. Moreover, the paper proposes to use Weierstrass coordinates as a representation for points on the hyperboloid.","Learning embeddings of graphs in hyperbolic space have become popular and yielded promising results. A core reason for that is learning hierarchical representations of the graphs is easier in hyperbolic space due to the curvature and the geometrical properties of the hyperbolic space. Similar to [1, 2], this paper uses Lorentzian model of the hyperbolic space in order to learn embeddings of the graph. The main difference of the proposed approach in this paper is that  they come up with a closed-form solution such that each node representation close to the centroid of their descendants. A curious property of the equation for the centroids proposed to learn the embeddings of each node also encodes information related to the specificity in the Euclidean norm of the centroid. Also this paper introduces two additional hyperparameters. Beta hyperparameter is selected to control the curvature of the space. Depending on the task the optimal curvature can be tuned to be a different value. This also ties closely with the de-Sitter spaces. Authors provide results on different graph embedding benchmark tasks. The paper claims that, an advantage of the proposed approach is that the embedding of the model can be tuned with regular SGD without needing to use Riemannian optimization techniques.",0.2717391304347826,0.1201923076923077,0.16666666666666669
2008,SP:b663cb80c4f664393b5820a27e9ae004ef4ec413,"This paper tackles ingredient recommender systems problem. This paper proposes the Interpretable Relational Representation Model (IRRM) to achieve both usefulness and interpretableness. There are two variants of the model, first is to model latent relation between two ingredients, the second is to leverage external knowledge base and results from TransE to learn relational representations.","The paper studies a promising task of interpretable food ingredients recommendation - there has been a growing interest in modeling recipes. The idea of leveraging KG to improve the interpretability/faithfulness of recipe-related ML tasks seems like a contribution to the community. In particular, the author proposes a method to learn pair specific relational representations for one-to-one (i.e. ingredient to ingredient) and many-to-one (ingredient-set to ingredient) food pairing tasks.",0.2037037037037037,0.14666666666666667,0.17054263565891473
2009,SP:b665f2dbd3a30e5a4d3942abc7b8f9d45db41cb8,"This paper “Linear algebra with transformers” studies the application of seq2seq transformers to matrix operations. It studies their performance across different encodings of floating point numbers, different sizes of matrices, different operations, and different (synthetic) data distributions. The main findings are that transformers work surprisingly well on various matrix operations (addition, multiplication, eigenvalues, inversion, SVD, …) for small matrices (e.g. 5x5), and that generalization to OOD problems is not symmetric (I.e. generalization from one distribution to another does not imply the other way round).","The authors train generic, dense transformers to perform several standard linear algebra computations, ranging from simple tasks like transposition to complex nonlinear tasks such as matrix inversion. They restrict themselves to relatively small matrices due to the practical limits of the dense, quadratic attention mechanism. The main result of the paper is that transformers can perform fairly well on all tasks, meaning that they can usually produce outputs that are correct upto relatively small tolerance. The paper also shows that some forms of out-of-distribution generalization are possible, and that this phenomenon is sensitive to the details of the training distribution.",0.2,0.16666666666666666,0.1818181818181818
2010,SP:b669fac24df0cab2ca31e638ea1b336e5af40866,The paper proposes a hybrid imitation learning/reinforcement learning method for learning hierarchical policies where the top layer provides sub-goals and desired cumulative rewards and the bottom layer learns to meet these goals. The advantage of such a decomposition is interpretability of the learned policy. The algorithm is evaluated on MountainCar and LunarLander from OpenAI’s gym. The authors show that their imitation learning/RL scheme is able to solve both tasks while producing reasonable sub-goals. ,This paper proposes a hierarchical RL method where the high level controller produces a series of sub-goals in an open-loop fashion which the low-level controller attempts to reach sequentially with the aim of maximising task rewards. The agent is trained using an extension of Hindsight Actor-Critic (HAC) algorithm. The algorithm also leverages a model-free flat policy trained on task rewards as an expert. The approach is evaluated on two tasks: Mountain Car and Lunar Lander. ,0.2692307692307692,0.2625,0.26582278481012656
2011,SP:b694d900930116938e266467c4703a80192ce2c0,"The paper proposes an approach to construct conformal prediction sets. The idea is to estimate p(x|y) and then construct a conformal set based on the p(x|y) instead of p(y|x). The paper claims that such a method produces cautious classifiers that can produce ""I don't know"" answers in the face of uncertainty.","The paper proposes deep learning extension of the classic paradigm of 'conformal prediction'. Conformal prediction is similar to multi-label classification, but with a statistical sound way of thresholding each (class-specific) classifier: if our confidence in the assignment of an x to a class y is smaller than \alpha, then we say 'do not know / cannot classify'). This is interesting when we expect out of distribution samples (e.g., adversarial ones).",0.2413793103448276,0.19444444444444445,0.21538461538461537
2012,SP:b6ca7f80548c640f173512386883ce7e305dd96c,"The paper describes a method that aims to learn task-agnostic priors for zero-shot generalization. The main idea is to employ the following modeling approach on top of the model-based RL framework: a local convolution network is used to compute a score for each local state action pair, and then another network is used to aggregate all the scores. While the problem being studied is important and the experimental results seem positive, there are a few concerns.","The paper proposes a framework (Scoring-Aggregating-Planning (SAP)) for learning task-agnostic priors that allow generalization to new tasks without finetuning. The motivation for this is very clear - humans can perform much better than machines in zero-shot conditions because humans have learned priors about objects, semantics, physics, etc. This is achieved by learning a scoring function based on the final reward and a self-supervised learned dynamics model.",0.17721518987341772,0.2,0.18791946308724833
2013,SP:b6fef1ef35ccf967c2df9d1704ba38df1af3e879,"The paper proposes the anisotropic version of randomized smoothing. Evaluation metrics based on the volume of the certified region are proposed, allowing comparisons with the certified regions provided from isotropic randomized smoothing. Experimental results show the usefulness of introducing anisotropic randomized smoothing as it certifies larger regions.","In this paper, the authors discuss the extension of $\ell_{p}$-randomized smoothing to anisotropic counterparts. In particular, they consider the extension of $\ell_{2}$-certificates from (hyper)spheres to (hyper)ellipsoids by sampling anisotropic rather than isotropic Gaussian noise, as well as the extension of $\ell_{1}$-certificates to cross-polytopes by sampling scaled Uniform noise rather than unscaled noise. Further, the authors discuss how these extended certificates can be compared to their base-counter parts to establish superiority (inclusion). The introduced certification algorithm, ANCER, utilizes the idea of data-dependent randomized smoothing to find the anisotropic shape with maximal certification volume. In experimental evaluation on Cifar-10 and Imagenet the authors show that the obtained certificates permit higher isotropic certificating radii than other methods in the per-sample optimization setting.",0.2978723404255319,0.10606060606060606,0.1564245810055866
2014,SP:b700b2e67fe44a82672de943640710d3b2141405,"The paper points out that the practical behavior of AII assumes the optimality of the attribute classifier, which is rarely held in practice. And claims that the paper analyzes the practical behavior of AII both theoretically and empirically, indicating that AII has theoretical difficulty as it maximizes variational upper bound of the actual conditional entropy. Then it argues an ugly modification based on a wrong property of conditional entropy. ","The paper studies the problem of representation learning under invariance constraints (i.e., the representation should be invariant wrt some attributes). The authors first review the adversarial invariance induction (AII) approach and they point out its limitations and then they propose a novel variant, which introduces an explicit regularization to minimize pairwise divergence (i.e., different attributes should lead to the same conditional distribution over the learned representation). The authors support the modified objective function both from a formal point of view and with an extensive empirical validation",0.18840579710144928,0.14772727272727273,0.16560509554140126
2015,SP:b71f0c38b5308ce902baeff4d457745c50034894,"This paper basically built upon [1]. The authors propose to do sampling in the high-frequency domain to increase the sample efficiency.  They first argue that the high-frequency part of the function is hard to approximate (i.e., needs more sample points) in section 3.1. They argue that the gradient and Hessian can be used to identify the high-frequency region. And then they propose to use g(x)=||gradient||+||Hessian || as the sampling metric as illustrated in Algorithm 1. To be noticed that, they actually hybrid the proposed metric (6) and the value-based metric (7, proposed in [1]) in their algorithm.","This paper proposes a new way to select states from which do do transitions in dyna algorithm (which trains policy from model experience as if it was a real experience). It proposes to look for states where frequency of value function as a function of a real valued state is large, because these are the states where the function is harder to approximate. The paper also shows that such frequency is large where the gradient of the function is large in magnitude which allows for finding such states in practice. In more detail, similar to previous algorithms, this algorithm keeps both an experience replay buffer as well as another buffer of states (search-control queue) and uses a hill climbing strategy to find states with both higher frequency and higher value. The paper tests the algorithm on toy domains - the mountain car and a maze with doors.",0.22857142857142856,0.16326530612244897,0.19047619047619044
2016,SP:b72cadebbbd59150361f32fe4cf32684d5fe22cb,"Authors propose a supervised method for predicting adjacency matrix for a set of points. Loss function consists of 4 terms: intersection over union loss with respect to target adjacency, cross entropy loss, symmetry penalty and L2 regularization of parameters. Learning process consists of alternating node feature updates parametrized by GCN-like layers and updates of the adjacency matrix (different across layers).","This papers presents a supervised method to learn from network data. The method alternates two steps: a node embedding step (using convolutions) and an adjacency matrix update (using local convolutions or fully connected layers). These steps are stacked forming a NN that is used to represent the learning steps. The objective function is composed of a linear combination of typical losses such as cross-entropy, intersection over union and other regularization terms. The linear coefficients are treated as hyper-parameters. The methods are evaluated on graph generation and edge prediction tasks, showing results comparable to the state-of-the-art.",0.2786885245901639,0.17,0.21118012422360247
2017,SP:b7632acf4753f9670c244597cc702fcab680982e,"The central concept of this paper is model information, a description length of a discriminative model. The authors advocate usage of model information for analyzing several aspects in deep learning. In particular, they show how model information can be used to judge about difficulty of supervised tasks, domain similarity, model capacity, roles of different network components, and knowledge distillation. All of these are important topics and are relevant to the ICLR community. While most of the definitions and interpretations seem intuitive and valid, there are a few concerns and questions, and in some cases, it is hard to decide whether the conclusions of the interpretations should be trusted.","The paper examines different use-cases of a quantity proposed in prior works which is said to capture the model information. It shows that this quantity behaves as expected overall. Quantifying the amount of information a deep neural network is a very interesting question for the community with both theoretical and practical appeal (from an analytical perspective but also from a model selection perspective, for example).",0.12962962962962962,0.21212121212121213,0.16091954022988506
2018,SP:b76fa33429ee938e18037ddb4df37d2da952d566,"The paper proposes an isocapacitory measure for analysing decision bound, in a way complementing the isoperimetric analysis proposed by Ford et al. 2019. The authors showed that the new measure captures different geometric properties of the decision boundary, potentially useful for adversarial training. The paper also proposed a new generalisation bound, although did not compare with other generalisation bounds.","The paper under review introduces a number of geometric measures (isoperimetric, isocapacitory ratios that relate to Brownian motion or heat diffusion probabilities) that are applied to study neural network decision boundaries locally.  Specifically, the studies applying the measures to study adversarially trained NN empirically, and there are generalization and network compression bounds analytically proven that are derived that relate to Brownian motion probabilities.    Empirical observations on LeNet and Wide ResNet trained on MNIST and CIFAR showed adversarially trained or noise trained networks did exhibit curvature of the decision boundary, showing finer structure than previously known.",0.1864406779661017,0.11578947368421053,0.14285714285714288
2019,SP:b7853999d2be6a4e637097094d8088e0229d651e,"The paper proposes a method to improve adversarial robustness of the current convolutional networks. The method is based on dropping outputs of a fraction of neurons. However, unlike in dropout the masks are kept fixed throughout training/inference and applied to the bottom layers of the network. This shifts the focus of the network away from texture and towards shape features resulting in the adversarial examples being fooling humans as well.","Studies suggest that CNNs that overly rely on texture features are more vulnerable to adversarial attacks. The authors of this paper propose a simple yet effective method ""defective convolution"" that randomly ""disables"" neurons on the convolution layer. The authors argue that by doing so, the CNN is encouraged to learn less from object texture and more on features such as shape. The authors support this statement by empirically evaluating the proposed model under multiple perturbation methods.",0.19718309859154928,0.18421052631578946,0.19047619047619044
2020,SP:b796596921ad17276bd65df6b8fc9195db76a574,"This paper addresses point cloud registration from a meta-learning perspective to quickly adapt with limited training data. The main idea is using a meta-learner is to initialise a 3D registration learner. The meta-learner predicts a prior registration that can rapidly adapt to new registration problems. Experimental results on several datasets (ModelNet, FlyingThings3D, and KITTI) showed superior performance over FlowNet3D. ","This paper presents a new architecture for point cloud registration. Different from existing methods, the proposed architecture consists of two stages. The first one is called meta learner, which is used to predict a task distribution and sample the key parameters for the second stage - 3D registration learner. By separating the network into two different parts, the learned model may be better at generalization.   Experiments were conducted on ModelNet40, FlyingThings3D, and KITTI datasets. The results show the proposed method outperforms some existing methods, including FlowNet3D, FlowNet3D++, and HPLFlowNet.",0.3548387096774194,0.25,0.29333333333333333
2021,SP:b7af23a88486ea212c5c3061202b5cc7c179bc68,"This paper proposes a pretraining technique for question-generation models. The pretraining involves generating the sentence which contains an answer candidate from the context around it. Through several well-executed experiments the paper shows that this type of pretraining can improve performance of several existing question generation models, and the resulting synthetic questions generated help in augmenting reading comprehension datasets.","This paper presents a model for unsupervised pre-training for the task of question generation. The model first predicts the number of answer present in a given paragraph and then selects the top-K answer spans from the paragraph. After selecting the answer spans, the model, then tries to generate the answer containing sentence by inputting the paragraphs less the answer-containing sentence and also the answer span. The key idea is that this unsupervised pre-training strategy is close to the actual task of generating question given the context and the answer. This is also the key differentiator between this work and other existing pre-training strategies for question generation (e.g. Alberti et al 2019). ",0.3,0.15384615384615385,0.2033898305084746
2022,SP:b7d48d865a7b6f111ef00a8b6ddb7c1d4a3eb1cf,"This paper studies the hybrid regret bounds for combinatorial semi-bandits (in stochastic, stochastic with corruption and adversarial settings simultaneously) and linear bandits (w.r.t. three different parameters). The paper improves the previous results by combining optimistic predictors with FTRL and the alg. of tracking the best linear predictor.","This paper provides an algorithm for the combinatorial semi-bandits that achieves regret bound with three well known notions of data dependence regret in adversary regime. Besides that the provided algorithms attains best of both worlds result (Zimmert et al., 2019) up to a logarithmic factor in adversary setting. Their algorithm in stochastic regime with adversarial corruption achieves $O(\log T + \sqrt{C\log T})$ regret with respect to $T$ as the time horizon and $C$ as the corruption budget. Furthermore, they improved existing regret bounds for adversarial linear bandits to achieve path-length regret bound which in worst case is tight up to a logarithmic factor.",0.3,0.14018691588785046,0.1910828025477707
2023,SP:b7d4e597b9f7988a74250e4d4c1644af720e804a,"This paper considers the problem of designing a curriculum of trajectories to teach an imitation learning agent. The authors propose to sequentially give trajectories that are both difficult (low probability) for the current learner and easy (high probability) for the demonstrator. Some theoretical justification is provided for why this approach works as well as some empirical results on simple domains. In general this paper seems novel, but there are many areas that deserve more clarification and it is unclear how far this idea can be taken given the strong assumptions.","This paper considers the problem of providing experts demonstrations to a learner, modeled as a Maximum Entropy IRL or a Cross Entropy Behavioral Cloning algorithm, in order for them to achieve a target performance on some task. The key contribution of the paper is to provide a demonstration ranking strategy which can be greedily utilized to define a curriculum. This strategy resulting in convergence for both types of learners. Importantly, and in contrast to prior work, this approach can be done in a manner that does not explicitly see the learner's internal dynamics.  Moreover, in the case of the maximum entropy IRL (with deterministic dynamics), the prove that the convergence is logarithmic. Finally, they show the efficacy of this approach in various domains.  ",0.2,0.14516129032258066,0.16822429906542055
2024,SP:b8563132155c0017eaf3643dcfa9ada463a5fb23,"The authors propose a method to apply the reparametrization trick when the random variables of interest are discrete. Their technique is based on a formulation of the objective function in terms of Gumbel-Max operators. They propose a derivation of the gradient in terms of an auxiliary variable \epsilon, such that the resulting gradient estimate is biased but the bias is reduced as \epsilon approaches zero, at the cost of increasing variance. Experiments are performed with VAE including discrete latent variable models. The authors show how their method converges faster than other baselines formed by estimators of the gradient given by the REBAR, RELAX and Gumbel-soft-max methods. In experiments with semi-supervised VAEs, their method outperforms the Gumbel softmax method in terms of accuracy and objective function.","This paper proposes combining the Gumbel-max trick and ""direct loss optimization"" for variance reduction in VAEs with discrete latent variables. This is a natural combination (in hindsight), since the Gumbel-max trick turns sampling into non-differentiable optimization, and direct loss optimization provides a way to optimize the expected value of a non-differentiable loss. The paper is well-written for the most part and is backed by good experimental results. However it like some of the mathematical details and some of the exposition could be greatly improved.",0.15503875968992248,0.2247191011235955,0.18348623853211007
2025,SP:b85a64f320fef1b864a9ee21dad6de343598d8be,"This work introduces a generalization bound for multimodal learning, which shows that, for a sufficiently large sample size, the model risk decreases with an increasing number of considered modalities. The authors also discuss a novel principle to dictate whether new modalities can be beneficial as a function of the dataset size and considered function classes. An empirical evaluation on both toy and real-world data validates the theory, underlining the benefits of learning from different modalities and laying the foundations for future research.",This paper aims to provide a theoretical explanation on whether multimodal learning can perform better than unimodal learning. They study a popular multimodal learning framework which firstly encodes features from different modalities into a common latent space before mapping the latent representations into a label. They prove that under certain conditions multimodal learning enables better estimation of the latent space which then enables better task performance. They also show some experiment results to back up their theory.,0.14457831325301204,0.15584415584415584,0.15000000000000002
2026,SP:b88b30ec0a8eeef4243a5f0181e2afc0294fcff4,This paper studies the problem of policy learning in a factored Markov decision process (MDP). The factorization of the transition probability distribution is graphically described through a set of influence diagrams. The objective function is a linear combination of weighted kernel functions. The authors propose an efficient policy gradient algorithm to learn the optimal policy. Simulation results support the authors’ results.,"This paper proposes a policy gradient algorithm for MOMDPs with large factored action spaces, where the background knowledge on the MOMDP structure is given as an influence network. A new baseline for policy gradients is given that makes use of the MOMDP background knowledge and a factorisation of the RL policy. The paper analyses the favourable variance properties of the resulting policy gradient estimator. Empirical results are provided on a pedagogical bandit example, and a traffic control problem. The latter demonstrates applicability of the method even when the graphical assumptions only hold approximately. ",0.29508196721311475,0.1935483870967742,0.23376623376623376
2027,SP:b89605095e431ae84ab91c9831a03ef9a5843e17,"This paper studies the attainability of Equalized Odds fairness criterion in both the classification and regression problems. When the prediction function is deterministic, it shows that Equalized Odds may not be attainable under certain conditions. In contrast, if the prediction function is randomized, then Equalized Odds classifiers can always be achieved under some conditions. Moreover, it shows that the performance attained using the in-processing approach after exploiting all available features is always better than attained using the post-processing approach. ","This paper studies under what conditions a classifier can satisfy the condition of equalized odds. The authors first prove an impossibility result which shows that (under linear non-gaussian case) any deterministic classifier	cannot achieve equalized odds across the protected groups. This leads to the question of randomized classifier. We can always satisfy equalized odds with randomized classifier  with a trivial classifier. However, the authors show two interesting results — (1) using the post-processing framework developed in Hard et. al. (2016) it is possible to obtain a non-trivial randomized classifier that satisfies EO, and (2) in-processing based classifiers are better than the post-processing based fair classifiers if we compare them in terms of accuracy.",0.32098765432098764,0.2222222222222222,0.2626262626262626
2028,SP:b8b826f478d505b38f97ea351b08290bbcd0029d,"The paper evaluates a geo-localization task based on ""lean"" images only, obtained by projection of 3d models without texture information. Multiple levels of granularity of the lean images (edges/edges+faces/edges+faces+depth) are compared for the learning, both in a ""memorization"" setting and in a ""generalization to unseen poses"" setting. Moreover, the behavior of the learning when labels are shuffled is evaluated.","This paper evaluates the performances of Deep Learning for geo-localization tasks in a world of images without textures (""lean images""). More exactly, the lean images are images rendered from a 3D model of a city. made of the depth and/or the buildings' edges and/or the buildings' faces. For the purpose of the evaluation, no real images are used,  only lean images both at training and test times. Many lean images are generated for training a network to predict the camera pose (2 translation parameters,  two angles), as a classification problem or a regression problem.",0.2923076923076923,0.1958762886597938,0.2345679012345679
2029,SP:b91c2d68ececc4827e5619ade1afdd2249b0d962,"This paper develops an algorithm that approximates the principal components corresponding to the top singular values. The algorithm requires the user specified tolerance instead of the number of top singular values, which is often the case in practice. It presents the detailed algorithm and evaluate its performance using numerical experiments. ","This paper presents a PCA algorithm that terminates after approximate singular values fall below a user provided threshold. The proposed method is based on the FFQR algorithm of Feng et al, but includes a tolerance based stopping criteria. It is stated that the algorithm runs $O(mnl)$ time. Experimental results are provided for comparison between TSVD and randQB_EI of Yue et al.",0.28,0.2222222222222222,0.24778761061946905
2030,SP:b91c4d5f9cde00d87fd76c1eb710322a767af87d,"This paper proposes a domain adaptation technique when source data is not available. The exponentially weighted average of BN statistics from source training along with the trained model is utilized to align source and target distributions. Source model is divided into feature encoder and classifier components based on the presence of the last BN layer. BN statistics matching loss minimizes the distribution discrepancy between source and target, whereas information maximization loss enforces the classifier to be sufficiently discriminative. Experiments on several benchmark datasets showed competitive performance with state-of-the-art domain adaptation methods.","In the work, the authors focus on tackling the problem of source free domain adaptation. The proposed method mainly has two parts, in which the second is nearly the same as the SHOT-IM as in Liang et al., 2020 [1], while the first part aims at coping with this problem from a new perspective to align the distribution of target features extracted by the fine-tuned encoder to that of source features extracted by the pre-trained encoder. To achieve this, they utilize batch normalization statistics stored in the pre-trained model to approximate the distribution of unobserved source data. ",0.1595744680851064,0.1485148514851485,0.15384615384615388
2031,SP:b92c785318f5e3774a4ef5c933c72015cbf80327,"This paper suggests Distributing Black-Box Optimization (DiBB) framework that enables the running of black-box optimization techniques in a distributed manner. Under the assumption that some optimization variables are correlated in a negligible manner to the optimization objective values, the authors partition the variables into the chunk of variables dubbed ""Box."" The core idea of DiBB is to perform black-box optimizations for each block and update the optimization results in an asynchronous manner. From the numerical experiments on the black box optimization benchmark (BBOB), the proposed DiBB shows marginally better performance when the underlying black box function matches the assumption that the optimization variables can form blocks. Additionally, the authors apply DiBB to perform a canonical example of RL tasks.","This paper proposes Distributed Black Box optimization (DiBB), which involves using disjoint distributed pipelines to perform CMA/Hessian-based updates, over functions with assumed separability in terms of parameters. The method is explained in detail, and experiments are performed on BBOB functions (with varying dimensions), along with Mujoco Walker2d with a relatively large policy architecture (10K+ parameters). Other ablations such as wall-clock time and varying block sizes are also experimentally presented.",0.13114754098360656,0.2222222222222222,0.16494845360824742
2032,SP:b93dae908d1cdefa8097c5c96e4829fe157b4073,"In this paper, the authors focus on the label shift problem in multi-source transfer learning and derive new generic principles to control the target generalization risk. They propose a framework that unifies the principles of conditional feature alignment, label distribution ratio estimation, and domain relation weights estimation. A WADN algorithm is proposed for 3 multi-source label shift transfer scenarios:  learning with limited target data, unsupervised DA, and label partial unsupervised DA. The proposed WADN algorithm is validated on different scenarios on common benchmark datasets (Digits, HomeOffice, Amazon Review), and results indicate that it can outperform related SOTA methods for these scenarios. ","This paper aims to provide a unified principle for multi-source transfer learning under label shifts. Based on this principle, this paper claims that a unified algorithm is proposed for various multi-source label shift transfer scenarios: learning with limited target data, unsupervised domain adaptation and label partial unsupervised domain adaptation. The proposed algorithm is validated on three benchmark datasets. The proof seems correct via combining existing single-domain DA theory and the theory regarding Wasserstein distance. The main theorem (Theorem 1) assumes that we can get the label information in the target domain, which is not realistic in many DA problem settings (e.g., UDA or multi-source UDA in this paper). In many DA problem settings, we have to use pseudo labels to replace with true labels in the target domain, which should be analysed in the proposed theorem. However, this paper does not make any efforts to theoretically analyse the effect of pseudo labels, which results in that this paper has very limited impacts on the DA field. Besides, there are some misleading conclusions in this paper. ",0.3786407766990291,0.21666666666666667,0.2756183745583039
2033,SP:b9477062862ad7bab901f295b471a254dcf78e1f,"This paper analyses an existing algorithm (LSVI-UCB) with generalized linear function approximation instead of conventional linear function approximation.  Under this generalized linear setting, they propose a so-called “optimistic closure” assumption which is shown to be strictly weaker than the expressivity assumption in the conventional linear setting. The paper then proves that LSVI-UCB still enjoys sub-linear regret in the generalized linear setting with strictly weaker assumptions. The paper also derives a general error propagation through steps that do not require a closed-form expression of the empirical dynamic and reward functions as in the linear case; this could be applicable to general function approximations.   ","The authors studies an episodic MDP learning problem, where they propose to study an Optimistic Closure assumption which allows the Q function to be expressed as a generalized linear function plus a positive semi-definite quadratic form. They motivate the assumption by showing that the assumption allows the tabular MDP case to be modeled, and that the Optimistic Closure is in fact a strictly weaker assumption than the linear MDP assumption made in previous related works. The authors then proceed to the design and analysis of the LSVI-UCB algorithm, which involves estimating the the parameter of the GLM model by a ridge estimator and adding an optimistic exploration bonus to the Q function. The authors propose a regret bound for the algorithm.",0.24299065420560748,0.21138211382113822,0.22608695652173913
2034,SP:b97073d441c824891124ad65fd95937fe9e53533,"This paper presents the traveling observer model (TOM), a general framework to learn multiple heterogenous supervized (input,output) tasks, which are indexed by a continuous ""variable embedding"" that is automatically learned by the system. The authors show on simple problems that the learned task embeddings can recover an intuitive organization of the problems' variables in space or time. They also show that the model simultaneously trained on 121 seemingly unrelated classification tasks can outperform state-of-the art supervized methods fine-tuned on single tasks.",".** Authors present a methodology for performing multi-task learning from data with disjoint and heterogeneous input domains. Particularly, they introduce an embedding of the inputs, in order to project each pair of input-output observations in a common continuous manifold where the exploration is significantly easier. Results show that the approach is valid with both synthetic and real-world data and they also demonstrate that the model is flexible when increasing/decreasing the dimensionality of the latent manifold.",0.2,0.21794871794871795,0.20858895705521474
2035,SP:b97bf410f00e2c9352e7d63e1b7cc1b684e99f45,"The authors provided a training scheme that ensures network retains old performance as new data sets are encountered (e.g. (a) same class no drift, (b) same class with drift, (c) new class added). They do this by incrementally adding FC layers to the network, memory component that stores previous precomputed features, and the objective is a coupling between classification loss on lower level features and a feature-loss on retaining properties of older distributions. The results aren't very compelling and the approach looks like a good engineering solution without strong theoretical support or grounding. "," a method is presented for on-going adaptation to changes in data, task or domain distribution. The method is based on adding, at each timed step, an additional network module transforming the features from the previous to the new representation. Training for the new task/data at time t relies on re-training with all previous data, stored as intermediate features. The method is shown to provide better accuracy than naïve fine tuning, and slightly inferior to plain re-training with all the data.",0.11458333333333333,0.12941176470588237,0.12154696132596685
2036,SP:b9919f153a64663a2bfaf12303c660d995694591,"The paper proposes an alternative to the uniform sampling scheme used for constructing mini-batches in stochastic gradient sampling algorithms. The proposed scheme, called Exponentially Weighted Stochastic Gradient (EWSG), is devised such its transition kernel matches that of the batch gradient descent. The proposed scheme is shown to achieve better results than the uniform sampling one.","This paper proposes a non-uniform sampling method for stochastic gradient minibatches for SG-MCMC. By sampling the indices of the stochastic gradients according to a parameter-specific (exponentially weighted) non-uniform distribution, the paper shows that it exactly matches the transition kernel of full batch gradient MCMC (for underdamped langevin dynamics) in Theorem 2. Although this exponentially weight distribution is intractable, the paper presents an approximate sampler in Algorithm 1 (that both uses a 1-step Metropolis Hastings approximation and a deterministic approximation for the $x$ term $r_{k+1} = r_k$). Finally the paper compares Algorithm 1 with other SGMCMC methods in a small synthetic Gaussian example, bayesian logistic regression on Covertype data, and a Bayesian neural network on MNIST.  ",0.32142857142857145,0.14754098360655737,0.20224719101123598
2037,SP:b9b8e3efa69342c90b91dcb29bda1e2f8127581e,"I am unimpressed with the quality of writing and presentation, to begin with. There are numerous grammatical errors and typos that make the paper a very difficult read. The presentation also follows an inequitable pattern where the backgrounds and related works are overemphasized and the actual contribution of the paper seems very limited. In its current form, this paper is not ready for publication in ICLR.","This paper proposes a neural topic model that aim to discover topics by minimizing a version of the PLSA loss. According to PLSA, a document is presented as a mixture of topics, while a topic is a probability distribution over words, with documents and words assumed independent given topics. Thanks to this assumption, each of these probability distributions (word|topic, topic|document, and word|document) can essentially be expressed as a matrix multiplication of the other two, and EM is usually adopted for the optimization. This paper proposes to embed these relationships in a neural network and then optimize the model using SGD.",0.18181818181818182,0.11650485436893204,0.14201183431952663
2038,SP:b9cbdab6989220afcdf7c836d52119d93997c3a1,"This paper proposes a framework that utilizes Random Walk Positional Embeddings (RWPE) as extra features to boost the performance of GNNs. In particular, positional embeddings are updated as a separate forward network in each layer. The framework has demonstrated improved quality by injecting its positional embeddings and feed-forward structures in several GNNs. ","This paper is concerning the Positional Encoding (PE) for GNNs.  PE augments the typical GNNs to distinguish isomorphic nodes. However, existing PE models such as Laplacian eigenvectors require huge computational resources. This manuscript proposes LSPE that augments the input to the nodes AND the embedding vectors with PE elements.  The LSPE models iteratively updates the embedding for PEs, in addition to the node feature embeddings.  The update formula of the PE embedding is similar to those of the node feature embedding, thus the computational requirements of the LSPE does not .  The manuscript tests two ways of PEs, one is based on the Laplacian, and the other is based on the random-walk. The manuscript also proposes the PE=only loss to foster the training.  Experimental results shows that the propose LSPE can improve the graph regression of the ZINC dataset greatly, and also can achieve some improvements in graph classification tasks on the MOLTOX21 and the MOLPCBA datasets.   ",0.22641509433962265,0.0759493670886076,0.1137440758293839
2039,SP:b9ce6d4e7451388efdd7cbacca24053f7fa73ab3,"This work proposes a technique for domain generalization by mixing style of images from different domains. This work adopts a mix up style approach [A] for domain generalization. Different from [A], the paper proposes to conduct mix-up in the intermediate layers, in particular, instance normalization layers. The proposed approach diversifies the data implicitly and the experimental results show that the mix-style can improve domain generalization.","This paper proposed a simple regularization technique for domain generalization tasks, termed MixStyle, based on the observation that domains are determined by image styles. By mixing styles of different instances, which generates synthesized domain samples while preserving the content features, the proposed method achieves the generalizability of the trained model. The MixStyle was applied to numerous applications, such as category classification, instance retrieval, and reinforcement learning, and attained the state-of-the arts. The MixStyle is relatively simple to implement, but effective. ",0.26865671641791045,0.21951219512195122,0.24161073825503357
2040,SP:b9d29e5258471d8fbd0b73e3bb05ed3cdfc68d6a,"This work is about a new architecture for normalizing flows inspired by implicit neural networks. In particular, the authors show that a specific implicit neural network build from residual blocks defines a bijective map. From this insight, they show how to efficiently train such architecture by estimating the log Jacobian and solving the inverse problem related to the implicit architecture. On top of this achievement, the authors thoroughly study the attractiveness of their architecture compared to i-res-flow. They demonstrate analytically and empirically that implicit normalizing flows are strictly more expressive than i-res-flow.","The authors concerns the question of how expressive invertible functions can be constructed. Their ansatz is the defining an invertible layer implicitly, using the root of an equation. While this approach is more general, they employ residual flows (ResFlows) to formulate a particular realisation of such an equation, calling the model ImpFlow. They show that the resulting function space is strictly richer than that of ResFlows. They further demonstrate how ImpFlows can be trained and evaluated. Empirically, ImpFlows outperform ResFlows on all considered tasks.",0.14583333333333334,0.16666666666666666,0.15555555555555556
2041,SP:b9eff5f0e2d89e5074e564fcbe7b0183c8c4818b,"The paper investigates why DDPG can sometimes fail in environments with sparse rewards. It presents a simple environment that helps the reader build intuition and supports the paper's empirical investigation. First, the paper shows that DDPG fails on the simple environment in ~6% of cases, despite the solution being trivial—go left from the start state. The paper then augments DDPG with epsilon-greedy-style exploration to see if the cause of these failures is simply inadequate exploration. Surprisingly, in 1% of cases DDPG still fails. The paper shows that even in these failure cases there were still rewarded transitions that could have been learned from, and investigates relationships between properties of individual runs and the likelihood of failure. The paper then explains how these failures occur: the policy drifts to always going right, and the critic converges to a piecewise constant function whose gradient goes to zero and prevents further updates to the policy. The paper then generalizes this deadlock mechanism to other continuous-action actor-critic algorithms like TD3 and discusses how function approximation helps mitigate this issue. Finally, the paper gives a brief overview of some existing potential solutions.","Overview: This paper describes a shortfall with the DDPG algorithm on a continuous state action space with sparse rewards. To first prove the existence of this shortfall, the authors demonstrate its theoretical possibility by reviewing the behavior of DDPG actor critic equations and the “two-regimes” proofs in the appendices. They then demonstrate the occurrence of the critic being updated faster than the actor, leading to a sub-optimal convergence from which the model can never recover. In this demonstration, they use a very simple environment they created, “1D-Toy”. The 1D-Toy environment is a one-dimensional, discrete-time, continuous state and action problem. Moving to the left at all in 1D-Toy results in a reward and episode end. Episode length was set at 50, as the agent could move to the right forever and never stop the episode. The authors demonstrate how the failure of the agent to obtain 100% success in this simple environment was, in fact, due to the phenomenon mentioned earlier. If the agent managed to obtain a reward very early on in training, it was highly likely the agent would converge on an optimal solution. If not, the actor would drift to a state were it no longer updates, and the critic would similarly no longer update either, resulting in a deadlock and suboptimal policy. The authors then generalize their findings using a helpful figure (Figure 7) which describes the cyclical nature of the phenomenon and how it can happen in any environment. Finally, the authors mention potential solutions to prevent the training failure from occurring, such as avoiding sparse rewards, replacing the critic update to avoid loss, etc.",0.22279792746113988,0.15579710144927536,0.1833688699360341
2042,SP:b9fb99a65e598d0e0b1a97bc04dfc80865216541,"This paper starts with an autoencoder trained on vision data. Autoencoders aren't generative models, strictly, so in order to make it so, they leverage a simple linear transformation on over RKHSs. The kernel they use is the NTK. In order to generate, the construct a reduced sample version of the Kernel using Nystrom's approximation, then use a geodesic interpolation algorithm to inverse map the transferred sample from the prior in the RKHS space back to the latent space for use in the decoder.","The authors build a generator that builds on top of the latent space of a “well-trained auto-encoder”. The generator consists of several steps: 1) sampling an latent element from the spherical latent space, 2) using a kernel Perron-Frobenius operator to embed the sampled latent element 3) selecting latent representations of real samples based on the indices of the highest values of the newly calculated embedding 4) calculating the geodesic interpolation of these latent representations 5) using the decoder of the autoencoder to generate new samples from the latent element resulting from geodesic interpolation. The authors describe the related work, the methods they propose and present experimental results on 4 datasets. ",0.18823529411764706,0.1415929203539823,0.16161616161616163
2043,SP:b9fccc3eefa7f0ca1b671d62da0fa4390169a496,"This paper concerns the convergence rate of SGD with heavy-tail noise. In particular, the considered gradient noise consists of a finite-variance part (corresponds to the multiplicative noise in SGD for least square) and an infinite-variance part (corresponds to the additive noise in SGD for least square). The main results can be viewed as a law of large number and a central limit theorem in the absence of finite-variance. First the authors show that when the loss is ""strongly convex"" and ""smooth"" in the $p$-PD sense and the heavy-tail part noise has finite $p$-moment, SGD (with decaying stepsize) iterates converges to the correct optimum, and the convergence rate is justified in the p-norm sense. Moreover, if the heavy-tail noise is the domain of normal attraction of some stable distribution, then the properly normalized SGD iterates also converges to the stable distribution. Finally, the heavy-tailed noise model is justified from two linear model examples.","The authors analyze SGD for a class of strongly-convex functions and under (possibly) infinite noise variance, i.e., the pth moment of the noise exists for $p \in [1,2)$, but noise variance is not assumed to be bounded. Such noise behavior is defined as heavy-tailed. Additionally, the noise is assumed to be state-dependent such that the noise vector has a component whose variance is bounded by a function of the query point (iterates). For standard analysis of SGD, noise vectors are assumed to be independent of query points and of each other. Specifically, for a class of strongly convex functions (denoted as p-positive definite (p-PD), p=2 being positive definite Hessian) and under heavy-tailed noise, the authors:  -	Quantify the convergence rate with respect to (w.r.t.) distance to unique optimum in $L^p$, which approaches the optimal rate in strongly convex setting as $p \rightarrow 2$. This result is achieved for SGD without any modifications and under state-dependent noise model. -	Prove that normalized Polyak-Ruppert average (uniform average) converges weakly to an $\alpha$-stable distribution, under additional assumptions on the noise and the Hessian. Central Limit Theorem (CLT) does not hold under heavy-tailed noise model.  In order to reinforce the setting they consider and verifiability of their assumptions in practice, authors discuss about the real-world examples that admit heavy-tailed noise and satisfy p-PD assumption. ",0.2716049382716049,0.18565400843881857,0.2205513784461153
2044,SP:ba08e61f269da3a11d13117daf31979353c18c74,"The paper proposes a new RNN unit: ON-LSTM. The idea is to explicitly integrates the latent tree structure into recurrent models. Experiments are conducted to evaluate performances on four different tasks: language modeling, unsupervised parsing, targeted syntactic evaluation, and logical inference. Good results on unsupervised parsing show that the model learns something close to human judgments of the sentence parses.","Language is hierarchically structured: smaller units (e.g., noun phrases) are nested within larger units (e.g., clauses). This is a strict hierarchy: when a larger constituent ends, all of the smaller constituents that are nested within it must also be closed. While the different units of an LSTM can learn to track information at different time scales, the standard architecture does not impose this sort of strict hierarchy. This paper proposes to add this constraint to the system by ordering the units; a vector of ""master"" input and forget gates ensures that when a given unit is reset all of the units that follow it in the ordering are also reset.",0.14754098360655737,0.08035714285714286,0.10404624277456649
2045,SP:ba46a3b9b5fe435a365a863ccc87cf07bf16cd93,"In this paper, the authors proposed a novel method of Meta-Surrogate Model (MSM) which can generate more transferable adversarial examples in the black-box adversarial attacks. The problem is formulated as a bi-level-like optimization problem which achieved via a differentiable attacker. Extensive experiments demonstrate its effectiveness in generating the transferable adversarial examples.","A complete black box adversarial attack thus far has not performed well as research shows. By complete black box, it means there is no information available about the target model, not even query based probing. Most SOTA uses a surrogate model to generate adversarial examples, where the surrogate model may, every likely, not in any way resemble the target model in practice. This paper claims that by adopting a meta training scheme, more effective black box attacks are achievable when compared to the SOTA.",0.23636363636363636,0.15476190476190477,0.18705035971223022
2046,SP:ba5cdfc4c1ad55f08c3e39934785e11e61b202ea,"This paper introduces capsule network for object detection. To solve the issue of capsule network when applied to large-scale detection problems, this paper develops deformable capsules, a new  prediction head SplitCaps, and a dynamic routing algorithm, SE-Routing. Experiments are conducted on COCO where it performs slightly worse than the baselines but arguably predicts less false positives.","The paper proposes to use the capsules to perform object detection on COCO. Capsules, while showing promises, are usually too expensive for tasks beyond MNIST and Cifar. The authors propose three key improvements in DeformCaps, SplitCaps and SE-Routing to improve the efficiency and therefore allow capsules to be applied on larger tasks such as object detection. The authors claim novelties in:",0.20689655172413793,0.1935483870967742,0.19999999999999998
2047,SP:ba7d83f40e335b7c670e0cdde6b75374d1ddfaf9,"The authors propose CMOW, an extension of the CBOW model that allows the model to capture word order. Instead of each word being represented as a vector, words are represented by matrices. They extend the CBOW objective to take into account word order by replacing the averaging of vectors to create the context with matrix multiplication (a non-commutative operation). This is the first time this model has been applied in a large scale unsupervised setting. They are able to do this using their objective and an initialization strategy where the matrix embeddings are set to the identity matrix with some Gaussian noise added.","The paper presents new training schemes and experiments for a matrix-multiplicative variant of CBOW. This variant is called a CMSM (Yessenalina and Cardie, 2011; Asaadi and Rudolph, 2017) which swaps the bag of vectors to a product of square matrices for encoding context to incorporate word ordering. It seems this model has not been trained successfully before (at least with a simple approach) due to the vanishing gradient problem.",0.15384615384615385,0.22857142857142856,0.18390804597701152
2048,SP:baa4df747449efe4264ed522194481e05c1e7096,"The authors introduce strategies for pre-training graph neural networks. Pre-training is done at the node level as well as at the graph level. They evaluate their approaches on two domains, biology and chemistry on a number of downstream tasks. They find that not all pre-training strategies work well and can in fact lead to negative transfer. However, they find that pre-training in general helps over non pre-training.","This paper proposes new pre-training strategies for GNN with both a node-level and a graph-level pretraining. For the node-level pretraining, the goal is to map nodes with similar surrounding structures to nearby context (similarly to word2vec). The main problem is that directly predicting the context is intractable because of combinatorial explosion. The main idea is then to use an additional GNN to encode the context and to learn simultaneously the main GNN and the context GNN via negative sampling. Another method used is attribute masking where some masked node and edge attributes need to be predicted by the GNN. For graph-level pretraining, some general graph properties need to be predicted by the graph.",0.16666666666666666,0.1016949152542373,0.1263157894736842
2049,SP:bacf7f05516ec99a3dafaedb8cba0f0b2831f99c,"The paper proses a new adversarial (poisoning) defense based on a known graph reweighting scheme known as the ricci curvature. The ricci curvature assigns a weight to each edge that captures the graph structure, i.e. the value reflects whether the edge is an inter-community connection or an intracommunity connection. Empirically, the ricci curvature is known to be more robust w.r.t. random edge insertions/deletions. The authors propose a new sampling method based on the ricci curvature and use it within their novel training scheme. Empirically, the effectiveness of their approach is shown via experiments on synthetic SBM graphs. Moreover, the authors use a random attack and Metattack on various datasets. They show superior performance to multiple baseline architectures/defenses.",In Ricci-GCN new graphs are resampled in each iteration of the training phase based on the Ricci flow metric. The Ricci flow incorporates curvature information and captures the intrinsic geometry of the graph. Compared to e.g. spectral embedding it is more robust to structural perturbations. This leads to improved robustness against adversarial attacks on the graph structure.,0.13821138211382114,0.288135593220339,0.18681318681318684
2050,SP:bae39837d7167b44abee412dd258c7640d315471,"This paper proposed a new pre-trained language model based on BERT, called StructBERT. The key contributions are the two new pre-train objectives, (1) word structural objective, where the goal is to reconstruct the right order of intentionally shuffled word tokens, and (2) sentence structural objective, a three-class sentence-pair prediction, either the 2nd sentence precedes the 1st, the 2nd succeeds the 1st, or the 2nd is randomly selected. Unlike the original NSP (next sentence prediction) task, which is simple but tends out to be not so helpful in many downstream tasks, both proposed pre-train objectives seem to be rather useful in benchmarks tested in the paper, including GLUE, SNLI, and SQuAD. ","This paper proposes to use additional structures within and between sentences for pre-training BERT. The basic idea is to shuffle either some n-grams within sentences or the sentences in texts, then train the model to predict the correct orders. Experiments in this work show that, with this additional training objective, the proposed pre-trained model, StructBERT, obtains good performance on the tasks including natural language understanding and question answering.",0.1565217391304348,0.2535211267605634,0.19354838709677424
2051,SP:bafcf085e146530fbae6b30f7966f413eb003df6,"In this paper, the authors proposed a non-parametric approach for video generation, i.e., video frame (un)conditional resampling. The proposed method is inspired by Video Textures (Sch¨odl et al., 2000), which synthesizes new videos by stitching together snippets of an existing video. Comparing to existing 'video textures' methods, the authors mainly made two improvements/contributions. (i) a new pipeline for modeling and calculating probabilities of transitioning between frames of the same videos. Specifically, giving a video clip, the authors first extract overlapping segments from it and fit a bi-gram model. The adjacent segments are regarded as positive pairs with high transitioning probability, yet other random sampled pairs are negative pairs. Similar to contrastive learning works, NCE loss is utilized to train the bi-gram model. (ii) Extending the model to a conditional situation and performing the task of audio conditioned video synthesis. The authors made a trade-off between the audio conditioning signal and the learned transition probabilities. Finally, experiments including multiple qualitative resampled videos and quantitative user studies were provided. And the proposed method demonstrated promising performance. ","of this paper: In this work, the authors propose a method to learn to generate long-range video sequences. The general idea is starting from a prior work (Video Textures) and extending this work with a learning framework. Specifically, during training a model is used to learn the transition probability between different video segments. During inference, long-range video synthesis is achieved through iterative sampling of new video segments. To guarantee the smoothness of the transition between different segments, an existing interpolation method is used to connect these video segments in a sequential order.",0.12637362637362637,0.24468085106382978,0.16666666666666669
2052,SP:bb1f6d7f3b71e1dd597c4a2e1b42db5aa560ed23,"The authors study the problem of contrastive learning, and in particular consider the NT-Xent loss function used in popular contrastive learning methods, such as the SimCLR algorithm. Such algorithms typically require long training times and very large batch sizes to be effective, and the authors explore this phenomenon in more detail.  Concretely, they identify a term in the gradient of this loss that has a potentially undesirable effect (the negative-positive coupling term), supported through empirical analysis. They adjust the contrastive loss function to prevent this term appearing in the resulting gradient, with the goal of improving learning speed and robustness to small batches.   In experiments on common SSL datasets including CIFAR10/100, STL10, and ImageNet, they find that by removing this coupling term, their method can improve significantly on competitive SimCLR and MoCo baselines, at much smaller batch sizes. Furthermore, they find that their method trains much faster with this adjustment to the loss.  Drawbacks: The authors do not appear to include a discussion of limitations in the paper or in the supplementary material. Furthermore, some of their baselines (in particular SimCLR) seems to be  weaker than other reported numbers in the literature, so this is worth examining in more detail. ","This paper observes that in contrastive leanring the gradient contribution from positive pairs and negative pairs is scaled by a common multiplier that tends to be small in the small negative batch size N regime, and close to 1 for large N. The authors propose a minor modification to the InfoNCE loss function - removing the term on the denominator pertaining to the positive pair - that suffices to remove the multiplier (i.e. set it equal to 1 always). Although the change is minor, the authors observe an improvement in robustness to batch size in SimCLR (and queue size in MoCo) and find that fewer epochs of training are required to attain a certain level of performance (though in the large epoch regime the performance saturates at a similar optimal performance level as the vanilla InfoNCE loss). ",0.1625615763546798,0.2426470588235294,0.19469026548672566
2053,SP:bb2885554d98533633a54e0a84ec5c08ba87db2d,"This work develops a differentiable spectral projection layer to enforce spatial PDE constraints using spectral methods, to achieve the introduction of the physical constraints in the end-to-end network without damaging the intrinsic property of the network. Analysis of computational cost shows the proposed layer is cheaper than the convolutional layer. The experimental comparison demonstrates the superiority of the proposed method. In my viewpoint, the novelty of this paper is somewhat novel. ","The paper describes a way to efficiently enforce physical constraints expressed by linear PDEs on the output of a neural network. The idea is to have, as a last layer of the network, a projection onto the constrained solution space, and to back-propagate through it. That projection layer is made efficient for high-dimensional outputs via the fast Fourier transform (FFT), exploiting a well-known numerical trick. Importantly, the proposed strategy is very general, and can indeed be used with any PDE constraint that is a linear combination of differential operators.",0.2465753424657534,0.1956521739130435,0.2181818181818182
2054,SP:bb2b782fedfbfd1f1f8e5f148ae76b0080882f14,"The authors propose to tackle the associative memory problem by recasting read/write operations to read/write by optimizing the parameters/input of an energy based model. Writing is reformulated as training a parametric energy model (EBMM) to have local minima of energy w.r.t. the parameters at memorized data points. Reading is performed by performing (projected) gradient descent on the corrupted/incomplete input to minimize the energy. To ensure the operations are fast (read and write with minimal gradient steps), the authors propose to take inspiration from modern meta-learning literature and learn initialization parameters of the energy model (and other hyperparameters for GD during read/write) from which writing is fast while ensuring reading is also fast, since the models are trained to maximize read/write performance within a constrained number of gradient steps.  Experimentally, the authors show that EBMM reading performs similar to baseline methods (but better across many memory sizes) on the standard Omniglot task. On CIFAR-10 and downsized ImageNet, they show much better L2 reconstruction error of corrupted images. They also show that the learnt energy ","This paper proposes a new type of energy-based models, a class of non-normalized generative models that relies on an energy function to retrieve patterns that correspond to its minima. The goal that is tackled by the authors is to implement an associative memory system, i.e. a mechanism that is able to retrieve any one of a set of patterns, given a distorted copy of these patterns. This task is traditionally carried out using attractor neural networks like the Hopfield model, a recurrent neural network model endowed with a learning rule that allows it to quickly embed a given set of patterns in its weight matrix such that the patterns become stable fix points of its dynamics. As the authors point out though, models like the Hopfield model are limited in their capacity to assimilate attractor patterns and in term of their expressiveness. On the other hand, more complex models based on deep architectures trained with gradient descent are slow at updating their weights to create new attractors.",0.14207650273224043,0.15294117647058825,0.14730878186968838
2055,SP:bb43cfb5f54986cf5d310aa141514739712c2fd4,"This paper studies the problem of privacy-protected multi-domain collaborative filtering, in which a ""win-win"" deal for source and target domains can be achieved. The proposed framework, MDFNet, contains multiple local clients and one global server. In each client, the encoder achieves feature separation, and the decoder constructs original data based on separated features. Experiments on benchmark datasets demonstrate the best performance of the proposed MDFNet compared with baselines. ","This paper proposes a Mask-Driven Federated Network (MDFNet) to reach a “win-win” deal for multiple domains with data protected to solve the Privacy Protected Multi-Domain Collaborative Learning (P2MDCL) problem. Specifically, each domain is armed with an individual local model via a mask disentangled mechanism to learn domain-invariant semantics. Second, the centralized server refines the global invariant model by integrating and exchanging local knowledge across all domains. Moreover, adaptive self-supervised optimization is deployed to learn discriminative features for unlabeled domains. ",0.19718309859154928,0.16666666666666666,0.18064516129032257
2056,SP:bb4ad6af4f43dab9af6411b2d72bacebbb9f29ab,"The paper presents regularization techniques for model based reinforcement learning which attempt to build counterfactual reasoning into the model. In particular, they present auxiliary loss terms which can be used in ""what if"" scenarios where the actual state is unknown. Given certain assumptions, they show that this added regularization can improve generalization to unseen problem settings. Specifically they propose two forms of regularization: (1) enforcing that for different actions the predicted next state should be different (action-control) and (2) enforcing that when certain parts of the low dimensional state are perturbed, over a model rollout the perturbation should only affect the perturbed parts of the state, essentially encouraging the latent space features to be independent (disentanglement). ","This paper proposes a method called ""counterfactual regularization"" whereby the dynamics/transition model is encourage to not have degeneracies where the actions don't influence the state transitions.  Concretely, this is done by, for every state, computing the maximum deviation of Transition model under a different action than the action taken in the history, and encourage that deviation to be as large as possible.  If that maximum deviation is 0, then all actions lead to the same next state. Empirical results show reasonable improvements in the StarIntruders task.",0.1452991452991453,0.19318181818181818,0.1658536585365854
2057,SP:bb4bb5c40ab4d33a1b44de02dde494c623b9e579,"This paper explores the connection between neural networks and Gaussian processes (GP). Specifically, this paper interprets the neural network activations as the inter-domain inducing variables for a GP. Specifically, this paper adopts the proposed approach in deep gaussian processes, proposing initialize a DGP by a pre-trained neural network based on the connection. They investigated the effectiveness of the approach by multiple experiments.","This paper proposes to establish an equivalence between the forward passes of neural networks and  deep Gaussian process (DGP). Authors further propose models that can either be seen as neural networks with improved uncertainty or deep Gaussian processes with increased prediction accuracy. This is achieved by developing a DGP that has an identical forward pass to a neural net. The training of DGPs can be improved by taking practices from NNs, e.g., a DGP can be initialised in the same way as neural  net without the specialized initialization in DGP literature. Experiments are performed on UCI benchmarks, MNIST, Fashion-MNIST and CIFAR-10. ",0.296875,0.18269230769230768,0.22619047619047616
2058,SP:bb6716468d3bd92b5e7de774aa89d5d52df461cb,"Training-free NAS is a promising direction. This work demonstrates that two theoretically inspired indicators: the spectrum of NTK and number of linear regions, strongly correlate with the network’s performance, and can be leveraged to reduce the search cost and decouple the analysis of the network’s trainability and expressivity. The authors thus proposed TE-NAS to rank architectures by analyzing the two indicators. Without involving any training, TE-NAS can achieve competitive NAS performance within minimum search time. ","This paper introduces a searching framework of neural architectures ranking the candidates with two different metrics: the spectrum of NTK and the number of linear regions in the input space. These two metrics do not require the training of neural networks lightening the computational burdensome. Authors support their method by providing results from CIFAR-10, ImageNet, and NAS-Bench-201 benchmark (Dong & Yang).",0.225,0.2857142857142857,0.2517482517482517
2059,SP:bb6daea45ba4fa232ab06647374900fdc27128bb,"The paper describes an approach to planning in imperfect information games called DSMCP. The algorithm is the basis for a system that won the 2020 reconnaissance blind chess competition. The algorithm views the game as a POMDP by assuming a fixed policy for the opponent. Infostates are represented compactly using a particle filter where each particle represents a set of world states with a maximum size. These are further compressed as ""synopses"", which are conjunctions or disjunctions of Boolean features over all the states in the set. The synposes are then input to a neural network that has been trained to imitate one of a set of possible policies including several other RBC programs. Policy action choices are mixed with UCB action choices to create a search tree. Saliency of different synopses is found to be somewhat correlated with decreased performance when removing that feature.","This paper presents Deep Synoptic Monte Carlo Planning, the technique behind the 2020 champion Reconnaissance Blind Chess (RBC) program Penumbra.  This method samples possible world states to approximate information sets, which it then abstracts uses synopses.  These abstracted information sets are then used monte-carlo planning to determine actions to take in the game.  The approach, with some RBC specific tweaks, is evaluated in the RBC domain and shown to be very successful. ",0.1310344827586207,0.2602739726027397,0.17431192660550462
2060,SP:bb73db8670fc2c0c3374934edcd34f8bfd0d038f,"This paper tackles the task of content transfer. For a given type of images (frontal face shots), the goal is to transfer a particular localized property (e.g. glasses or facial hair) extracted from one image to another image of the same type (difference face). This is also known as the problem of guided image-to-image translation. ","The paper proposes an unsupervised approach for mapping two sets of objects, A and B, such that set B contains all the information that is in set A and some additional information. The paper learns a latent space which encodes: (a) information which is shared in both sets, and (b) the additional content present in B. This is done by employing a two-pathway encoder and a decoder for both the sets. Experiments on problems such as adding glasses or facial hair to faces shows that the proposed method performs better than existing disentanglement approaches. ",0.20689655172413793,0.12631578947368421,0.1568627450980392
2061,SP:bb83b81f007ebd41f444ed55636f0c3b3ca6b2c0,This paper attempts to improve upon the greedy core-set for active learning (Sener and Savarese) by employing distances scaled by uncertainty. The proposed method then leverages a beam search algorithm to identify the best core-set configuration among candidates with the lowest log-confidence to yield further improvements. Empirically evaluated on CIFAR10/100 and SVHN.,"In this paper, the authors propose to improve the vanilla greedy Core-set active learning algorithm by (1) weighting the distance with uncertainty (measured by doubt, $1-\max_yP(y|x)$) and (2) use beam search instead of greedy search where the beams are selected by average uncertainty. They show with several toy examples that this way the samples are concentrated closer to low-confidence region. They further try to find theoretical groundings for the advantage of the proposed algorithm with several assumptions. Finally they show that the proposed algorithm outperform vanilla coreset on CIFAR and  SVHN, and provide some ablation studies to showcase the effect of beam search and uncertainty weighting.",0.39285714285714285,0.19642857142857142,0.26190476190476186
2062,SP:bb9e587a38647060cbd38e3aad4376b19b18bd4d,"This paper proposes a new type of attack: AdvTrojan. This new attack is activated only when the test examples contain two things: backdoor trigger pattern and adversarial perturbation. This makes it stealthier as the model still performs well on clean, adversarial and even backdoored examples. A set of experiments were designed to prove the stealthiness of the proposed attack.","Based on the framework proposed by Pang et al. (2020), this paper unifies adversarial examples and Trojan backdoors into a synergistic attack. The inference results are dominated by the Trojan trigger and the adversarial perturbations. Such a mechanism extends the ability of the Trojan trigger. Incorporated with adversarial perturbations, the desired results of the adversary could be multiple classes. ",0.23728813559322035,0.23728813559322035,0.23728813559322035
2063,SP:bba5c62e1900284fdf028d2ece640157f7cb4c92,"The paper proposes a method for solving few-shot image classification that generates all the weights of a very small CNN model. This has the advantage that the generated model can be very small+compact, compared against for example some embedding methods that might require large image classification networks to run as a pre-process. The method is also able to handle unlabeled samples in a fairly natural way.","This work presents the use of a hybrid CNN-Transformer model for few-shot image classification. Specifically, the paper applies encoding and encoding-decoding transformers between convolution layers to increase the learning capacity.  The paper also includes a Conv-based hybrid model and uses Omniglot, miniImageNet, and tieredImageNet for evaluations. ",0.17391304347826086,0.24,0.20168067226890754
2064,SP:bbaaeb718f346e866e91cf7e6f9278f0a2bfbab4,"This paper gives a method in the class of learning representations which have some information censored. In particular, the authors propose a setup where there are many “private” classes, and some classes are more similar than others – this maps (I think) onto the privacy setting, where each class is like one individual. They give a modification of an entropy loss, focal entropy, which is conducive to this type of learning, and show in experiments that this method can be successful.","########################################################################## Summary: The paper studies how to learn private representations that only captures the non-sensitive attributes of the dataset. They propose an adversarial representation learning method that employs VAEs. Specifically, the architecture in the VAE contains 6 players with 2 as adversarial classifiers. They introduce focal entropy as the objective function instead of entropy for adversarial classifiers to achieve deep sanitization. They empirically evaluate the method by reporting the target task accuracy and attribute inference accuracy on two datasets.",0.1375,0.13924050632911392,0.13836477987421383
2065,SP:bbb16b1e4d1f81767e48a424dd78ac73ff34d47c,"The authors consider RL with safety constraints, which is framed as a multi-reward problem. At a high-level, this involves finding the Pareto front, which optimally trades off objectives. The paper primarily introduces and discusses a discretization scheme and methods to model the Q-value function as a NIPWC (non-increasing piecewise constant function). NIPWC are stored as values over discrete partitions of state-action spaces. To do so, the authors introduce two data structures DecRect and ContDecRect to store Q function values over geometric combinations of subsets of state-action space.","I generally like the paper. The paper discussed a constrained value iteration setting where the safety contraints must be greater some threshold, and thresholds \delta are parameters. The paper attempts to develop an value iteration algorithm to compute a class of optimal polices with such a parameter. The algorithm is mainly based on a special design of representation/data structure of PWC function, which can be used to store value functions and allows to efficiently compute several relevant operations in bellman equation. A graph-based data structure is developed for continuous state domains and hence value iteration can be extended to such cases. ",0.15053763440860216,0.13592233009708737,0.14285714285714285
2066,SP:bbb70a2512ecbd1fbef0f9219b1d3423a4b6ed83,"The paper proposes a method to incorporate Successor Features (SFs)  in domains with continuous state and action spaces. It proposes an actor-critic architecture (a variation of the Soft Actor-Critic method) that learns disentangled representations for the environment dynamics and the tasks. The network architecture guarantees such disentanglement with two independent modules: one for the representation of the dynamics $\phi$ (fed by the current state, action, and next state) and one for the task representation $\boldsymbol{w}$ (fed by task-specific information, such as the goal). These modules are learned jointly in a single-stage training procedure, contrasting prior work [1]. The main contribution of this model is the enablement of the SFs for continuous domains without relying on the costly inference mechanism from the classic SFs framework implementation while enabling generalization among similar tasks.","This work looks at the use of successor features for solving simple continuous control tasks (in particular, reaching to different locations and door closing). The two contributions they enumerate are a ``practical implementation of SF framework for continuous state and action domains'' and jointly learning $\phi$ and $w$ (that is the successor features and the task weights $w$). They show their approach outperforms a goal-conditioned SAC baseline on these control tasks including generalizing to target locations that were not used during training. ",0.1323529411764706,0.21686746987951808,0.1643835616438356
2067,SP:bbcb77fc764f7e90ef6126d97d8195734fcdafe8,"This paper deals with 3 theoretical properties of ridge regression. First, it proves that the ridge regression estimator is equivalent to a specific representation which is useful as for instance it can be used to derive the training error of the ridge estimator. Second, it provides a bias correction mechanism for ridge regression and finally it provides proofs regarding the accuracy of several sketching algorithms for ridge regression.","This paper presents a theoretical study of ridge regression, focusing on the practical problems of correcting for the bias of the cross-validation based estimate of the optimal regularisation parameter, and quantification of the asymptotic risk of sketching algorithms for ridge regression, both in the p / n -> gamma in (0, 1) regime (n = # data points, p = # dimensions). The authors derive most of their results exploiting their (AFAICT) new asymptotic characterisation of the ridge regression estimator which may be of independent interest. The whole study is complemented by a series of numerical experiments.",0.27941176470588236,0.20652173913043478,0.2375
2068,SP:bbde4c0910f4ef9ef433f0349f7ff3edd569b63f,"This work presents an encoding approach for unordered set input to neural networks. The authors base their approach on weighted finite automata, where in order to absorb unordered sets, they enforce multiplicative commutativity on transition matrices by approximating them as complex diagonal matrices. The authors furthermore provide mathematical references and results to derive bounds for their approximation. They show that positional encoding in Transformer network can be seen as a special case of their multiset encoding scheme, which also generalizes DeepSets encoding from real to complex numbers.","This paper proposed a complex weights based multiset automata designed to represent unordered data. The main idea of multiset automata is that the transition matrices of the automata is pairwise commutative. To achieve this property, the authors proposed to restrict the transition matrices to be diagonal and shows that the latter is a close approximation of the former. The authors proceed to give two practical applications of the multiset automata: position encoding of the transformer and deepset networks. For the former, the authors showed that the position encodings from Vaswani et al. can be written as a weighted unary automaton and therefore it is a generalization of the original position encodings. For the latter, the authors extended the classical deepset networks into its complex domain, allowing more efficient representation of the data. ",0.22988505747126436,0.15151515151515152,0.182648401826484
2069,SP:bc06971951ef8e7c013b4ef134e1c8d3c3da0c85,"The authors frame continual learning as a meta-learning problem that balances catastrophic forgetting against the capacity to learn new tasks. They propose an algorithm (MER) that combines a meta-learner (Reptile) with experience replay for continual learning. MER is evaluated on variants of MNIST (Permutated, Rotations, Many) and Omniglot against GEM and EWC. It is further tested in two reinforcement learning environments, Catcher and FlappyBird. In all cases, MER exhibits significant gains in terms of average retained accuracy.","The transfer/ interference perspective of lifelong learning is well motivated, and combining the meta-learning literature with the continual learning literature (applying reptile twice), even if seems obvious, wasn't explored before. In addition, this paper shows that a lot of gain can be obtained if one uses more randomized and representative memory (reservoir sampling). However, I'm not entirely convinced with the technical contributions and the analysis provided to support the claims in the paper, good enough for me to accept it in its current form. Please find below my concerns and I'm more than happy to change my mind if the answers are convincing.",0.16455696202531644,0.12149532710280374,0.13978494623655913
2070,SP:bc08cb09ecac842d09fd6e03ecf45b2fce9857b6,"This work aimed to understand the prioritized experience replay, a widely used technique to improve learning efficiently for RL agents. The authors proposed three different value metrics to quantify the experience, and showed that they are upper bounded by the TD error (up to a constant). The extension to soft Q-learning was also presented. Finally, the authors showed in experiments that derived upper bounds hold in Maze and CartPole. They also demonstrated that a new variant based on the upper bound achieved better performance on a subset of Atari games.","the idea of prioritized experience replay is revisited, but from a new perspective with new theoretical results. Here, the authors propose the expected value of backup (EVB) as a metric to assess the quality of a sample and its potential improvement on the policy and on the value function. The authors decompose this metric into the benefit attributed to the policy and benefit to the value function. The authors have two theorems. The first theorem shows that the surprise (aka the temporal difference error) is an upper bound of the EVB in the Q-learning setting. The second theorem shows that the surprise, multiplied by a constant that depends on the policy, is an upper bound to EVB in the soft RL setting. The authors demonstrate that the proposed tighter bound on the EVB *could* yield improvements in the soft RL setting. ",0.2967032967032967,0.19014084507042253,0.2317596566523605
2071,SP:bc0d62459bcb00a581f2273b5f4aabe3ead1d0c1,"This paper proposes a meta-learning algorithm to solve the problem of exploration in a contextual bandit task using prior knowledge. This is analogous to how exploration strategies have been learned from past data in the meta-learning for RL (for example, [1]). Their algorithm simulates contextual bandit problems from fully labeled data and uses it to learn an exploration policy that works well on tasks with bandit feedback. The training step for the exploration policy builds upon the AggreVaTe algorithm, where policy optimization is performed on the history augmented data by using a separate roll-out policy to estimate the advantage of a particular action for a particular context, from the point of view of regret minimization.  In terms of theory, they show that by using specific algorithms (example, Banditron) as the inner policy optimization procedure, a no-regret algorithm can be obtained.   ","    This paper introduced a meta-learning algorithm for the contextual bandit problem, MELEE, which learns an exploration policy based on simulated and synthetic contextual bandit tasks. The training is mainly divided into two steps. In step one, they proposed to train a policy optimizer, which maps features and actions to rewards. This policy optimizer could be used to reveal the most valuable action to take according to the modeled reward. All possible actions and their corresponding values are revealed to the policy optimizer because of the existing ground-truth labels in the synthetic dataset. The policy optimizer would then suggest which action to take. The algorithm takes the action in an  greedy fashion, i.e. with probability  it will follow the suggestion and with probability  it will sample it uniformly at random. The policy optimizer, historical actions and the taken actions are appended to the training set for training the exploration policy  in the next step. The procedure in step one is proposed to be done in  rounds. In step two, the training set is used for training an exploration policy  . During testing, the contexts are drawn from the real world, the policy optimizer will first evaluate the whole history and the exploration policy will generate actions with the input from the policy optimizer and the context. The algorithm suggests the action to explore in an  greedy fashion. The proposed algorithm is evaluated on a dataset for learning to rank, and 300 synthetic datasets. It shows better performances in most cases.",0.2569444444444444,0.14741035856573706,0.18734177215189876
2072,SP:bc3dfb9f0153699929a0b2556b4eb170aa7d6e54,"The mTSP with the goal of minimizing the longest route is considered, which minimizes the maximum route. This objective results in a balanced-length set of routes, which compared to the sum of routes obtains a more practical result. A graph representation based on the worker and assigned tasks is defined, then a type-aware graph attention (TGA) embedding procedure is proposed in which it obtains an embedding for node and edge representation. The state for each entity involves the 2D coordinates of the entity and the boolean indicator of idleness and assigned task of the worker. The action is worker-to-task assignment, and the reward is the makespan of finishing the problem, which is a sparse function. In type-aware graph attention (TGA) embedding, the embedding of node and edge are obtained and using the attention mechanism, an important weight for the embedding of each edge is obtained. The embedding functions are type-dependent which means the embedding considers the source node-type. The final message value for each node is obtained by multiplying the weight and edge embedding value of its neighbors. Then, an MLP is used to obtain a value for each source and possible target node, which takes the final value of the source, target, and edge between those as input. Then, the output of the MLP is used to get the final probability of choosing the next node.","The paper proposes a reinforcement learning approach to solve the min-max multiple TSP, where there are multiple salesmen and the goal is to minimize the longest subtour while every city is visited by one salesman. The authors propose an architecture, ScheduleNet, that encodes a partial solution or state and outputs a policy, i.e. a probability distribution over the actions. They train the model using a variant of the REINFORCE algorithm. The approach is validated on randomly generated mTSP instances as well as the standard literature benchmark TSPlib.",0.08974358974358974,0.23595505617977527,0.13003095975232198
2073,SP:bc3ec338f786c1d1f5aed405ee7cd3699a0f91c8,"This paper considers the regression problem in scenarios in which the conditional distribution of the response variable y given the input x is multimodal. For artificially constructed datasets, in which the the conditional modes are known, performance is assessed by the RMS distance to the mode closest to each prediction.  For real-world datasets, performance is in terms of RMSE and MAE.","The paper proposes an implicit function approach to learning the modes of multimodal regression. The basic idea is interesting, and is clearly related to density estimation, which the paper should have discussed. On the other hand the tackled problem is a weaker variant of the learning multimodal output distributions in regression. What is the benefit of tackling this simpler problem, when in reality we are interested in the output distributions? In Bayesian literature (BNNs, deep GPs, Bayesian regression) multimodal outputs are routinely produced, but the paper ignores these methods. The paper should compare to these, and demonstrate the benefit of just learning the modes instead of learning the full output distributions (perhaps the mode learning gives more accurate mode assignment?).",0.27419354838709675,0.14166666666666666,0.18681318681318682
2074,SP:bc3f37d80dec716a01f93f7cd8bfb888dd8a509d,"The authors demonstrate the function expression properties for the Residual type convolutional neural networks to approximate the block sparse fully connected neural networks. Then it is shown that such Res-CNNs can approximate any function as long as it can be expressed by the block-sparse FNNs, including the Barron class and Holder class functions. The price to pay is that the number of parameters is larger than that of the FNNs by a constant factor. ","This manuscript shows the statistical error of the ERM for nonparametric regression using the family of a Resnet-type of CNNs. Specifically, two results are showed. First, the authors show that any block-sparse fully connected neural network can be embedded in CNNs. Second, they show the covering number of the family of CNNs. Combining with the existing results of the approximation error of neural nets (Klusowski&Barron 2016, Yarotsky 2017, Schmidt-Hieber 2017), they show the L2 statistical risk. ",0.25,0.2375,0.24358974358974358
2075,SP:bc4cb6a48758c5a9d81fa13e2b144f151dd6a85b,"This work addresses the task of causal discovery. The proposed contribution is to apply prior work which uses reinforcement learning for combinatorial optimization to structure learning. Specifically, the proposed optimization problem seeks to maximize a penalized score criterion subject to the acyclicity constraint proposed by Zheng, et al. Empirical results show the proposed method performing favorably in contrast to prior art. ","In this paper, the authors propose an RL-based structure searching method for causal discovery. The authors reformulate the score-based causal discovery problem into an RL-format, which includes the reward function re-design, hyper-parameter choose, and graph generation. To my knowledge, it’s the first time that the RL algorithm is applied to causal discovery area for structure searching.",0.18032786885245902,0.1774193548387097,0.17886178861788615
2076,SP:bc5907a21b9d31cda4e4c4c513792a8f99edd0b6,"The paper focuses on studying the importance of utilising manifold/topology information for machine learning tasks. To this end, the authors benchmark four different approaches, including VAE, GR-VAE (using graph distances to regularise  embedding distances (as shown in Eq. 1)).  The paper performs experiments on four tasks, including synthetic data, MNIST, text representation, and chemical reactions. As conclusion, the paper demonstrates that in some cases, adding relational information is beneficial, while in other cases, the effect is subtle. Thus, the paper aims to provide a metric for understanding when and how manifold/topology information is needed. ","This paper investigates different ways of incorporating topological information about the data in the machine learning models. The paper introduces a novel loss that aims to enforce the relational information between data points into the embedding space learned by a Vae on the node features. The experiments demonstrate that for data with a certain topology type, the introduced loss can provide performance when used together with existing methods. The paper opens up possibilities of further investigation into incorporating topological information (if available) into the learning procedure.",0.16494845360824742,0.18604651162790697,0.17486338797814208
2077,SP:bc6830f25785febd985a5563f62df972428eeeee,"The authors propose a new method for computing Knowledge Graph Embeddings on KGs where textual descriptions of entities are available. They evaluate the effectiveness of their method on a number of downstream tasks, including open-world KG completion, closed-world KG completion and entity classification. They show that their method (FOlK) outperforms baselines across all tasks in key metrics.",This paper presents an approach to learn representations of (open-world) entities in a KG with given textual descriptions of open-world entities. This paper describes a technique that jointly learns embeddings for KG entities from descriptions and KG structure for open-world knowledge graph completion. The technique is experimentally validated on the YAGO3-10-Open and WN18RR-Open datasets and it beats previous open world entity representation learning methods.,0.1864406779661017,0.15714285714285714,0.17054263565891473
2078,SP:bc69ea7519d15ff99678ebc5a228da631480c39d,"Much like progressive growing of GANs two years ago, this paper adopts a similar coarse-to-fine procedure for scaling EBMs to higher resolutions. In particular, the approach starts from learning EBMs on low-resolution images and then smoothly transitions to higher resolution by carefully designing an expand layer and a smooth sampling procedure. Authors were able to obtain competitive FID scores on CIFAR-10, and demonstrate the first set of 256x256 image samples from EBMs. In addition, authors demonstrate successful application of EBMs to unpaired image-to-image translation.",This paper presents a number of methods to scale up training and sampling of EBMs on image data. The main contribution consists of an approach for progressively growing the model by increasing the image resolution as training progresses. This approach echos similar approaches used for scaling up GAN training. The approach involves slowly annealing in new blocks to the model during training which processes the image at increasing resolutions. This allows training of image EBMs at notably larger resolutions than published in prior work.,0.15555555555555556,0.16666666666666666,0.16091954022988508
2079,SP:bc770f3d7472b4a89f0773960ac365193f5e0754,"The authors propose an approach to calibrate conditional distribution estimation models. The approach uses normalizing flows to transform an existing model's predictions into a prediction that better matches the empirical quantiles to the theoretical quantiles. After this remapping procedure, the authors introduce a new plot to visualize calibration. Empirical benchmarks are run on a suite of UCI datasets.","The paper proposes to use normalizing flows to improve estimates of aleatoric uncertainty in regression tasks. First, the paper suggests that since normalizing flows can improve the flexibility of output distribution, they can be used to mitigate issues of underfitting. Second, the paper proposes an approach that uses normalizing flows for recalibration, which allows people to still query the model’s statistical properties. The authors also introduce a plot that is useful for diagnosing calibration issues. ",0.288135593220339,0.2236842105263158,0.2518518518518519
2080,SP:bce4d9d2825454f2b345f4650abac10efee7c2fb,"The problem addressed by this paper is the estimation of trajectories of moving objects thrown / launched by a user, in particular in computer games like angry birds or basketball simulation games. A deep neural network is trained on a small dataset of ~ 300 trajectories and estimates the underlying physical properties of the trajectory (initial position, direction and strength of initial force etc.). A new variant of deep network is introduced, which is based on an encoder-decoder model, the decoder being a fully handcrafted module using known physics (projectile motion).","This paper proposes an architecture that encodes a known physics motion equation of a trajectory of a moving object. The modeled equation has 3 variables and the network works in a latent space- contrary to taking raw images. It uses an auxiliary network (named InferNet) to train the final one used at inference time (named RelateNet). The former aims to reconstruct the input sequence of positions representing trajectory, and has intermediate 3 latent variables that correspond to the 3 variables of the modeled equation, while as decoder it uses the modeled known equation itself. The latter is a mapping from the relative position of the object to 2 latent variables of the former InferNet, and is trained with MSE loss. At inference, RelateNet takes as input the relative position of the object, predicts 2 variables of the equation and finally uses the motion equation to calculate the trajectory.",0.2111111111111111,0.12837837837837837,0.15966386554621848
2081,SP:bcf9ed060b00d47720785afbdfd540a4c98715d4,"The authors prove lower bounds on the number of queries required for optimizing sums of convex functions.  They consider more powerful queries than the usual queries that provide function evaluation/gradient pairs for chosen summands.  As was done in [1] (which is cited in the submission), in this work algorithms can also get the answer to a","This paper proves a better complexity lower bound for stochastic PIFO optimizers on the problem of finite-sum minimization. The paper assumes that the objective function is the sum of n individual loss functions. It further assumes that (1) the optimizer initializes at a fixed point, and (2) at each iteration, it randomly and independently selects one loss function to update the parameter vector. ",0.19298245614035087,0.171875,0.18181818181818182
2082,SP:bd1924f07a404d154237ea6acde8cf79b3b338c5,"This paper proposes DyMON, an unsupervised object-centric representation learning model that can be applied to scenes with dynamic objects and multiple viewpoints. DyMON is trained to obtain object latents that are independent of the viewpoints. The model builds off of MulMON, extending it to work with scenes with dynamic objects. Two assumptions are made about the training scenes: 1) a high frame rate assumption and 2) the relative speed difference between the camera and the objects is large -- that is, either the camera moves much faster than the objects or the objects move much faster than the camera. With these assumptions, the problem can be reduced to either a multi-viewpoint, static objects problem or a single-viewpoint, dynamic objects problem. Through experiments, the authors demonstrate that DyMON can be used to query predictions of the scene at arbitrary times and viewpoints. ","The following work proposes a method for learning the factorized latent structure of a scene. Specifically, while the primary prior work MulMon [28] assume static objects while the viewpoint varies through time, this work allows for both camera and object motion within the training data. To achieve their goal of factorizing object motion from camera motion, they assume high framerate and use clustering to determine cases where the camera is moving quickly and the objects slowly, versus cases where the camera moves slowly but the objects move quickly. Notably, once trained, they are able to resynthesize the scene's dynamic objects from novel viewpoints. ",0.17482517482517482,0.2403846153846154,0.20242914979757085
2083,SP:bd4fee07f87a3b40b274d1cbbae3ac07f11cb48d,"This work introduces GQ-Net, a novel technique that trains quantization friendly networks that facilitate for 4 bit weights and activations. This is achieved by introducing a loss function that consists of a linear combination of two components: one that aims to minimize the error of the network on the training labels of the dataset and one that aims to minimize the discrepancy of the model output with respect to the output of the model when the weights and activations are quantized. The authors argue that this has the effect of “guiding” the optimization procedure in finding networks that can be quantized without loss of performance. For the discrepancy metric the authors use the KL divergence from the predictive distribution of the floating point model to the one of the quantized model. The authors then propose several extra techniques that boost the performance of their method: 1. scheduling the weighting coefficients of the two loss terms (something which reminisces iterative pruning methods), 2. stopping the gradient of the floating point model w.r.t. the second loss term, 3. learning the parameters of the uniform quantizer, 4. alternating optimization between the weights and the parameters of the quantizers and 5. using separate batch normalization statistics for the floating point and quantized models. The authors then evaluate their method on Imagenet classification using ResNet-18 and Mobilenet v1 / v2, while also performing an ablation study about the extra tricks that they propose.","In this paper, the authors propose a framework towards 4-bit auantization of CNNs. Specifically, during training, the proposed method contains a full precision branch supervised by classification loss for accurate prediction and representation learning, as well as a parameterized quantization branch to approximate the full precision branch. A quantization loss between the full precision branch and the quantization branch is defined to minimize the difference between activation distributions. The authors proposed a series of improvements, including alternative optimization, dynamic scheduling, detach and batch normalization to help boosting the performance to SOTA under 4-bit quantization.",0.0954356846473029,0.23958333333333334,0.13649851632047474
2084,SP:bd65ec9b7d991a0c23b882bb137653f2f2f94c71,"This paper proposes an intrinsic reward formulation to address the challenge of sparse reward in reinforcement learning. The key idea is to learn multiple models. The prediction error of each model is used as a component of the intrinsic reward. These components are fused using an alpha-mean function. The parameter alpha can be tuned automatically throughout the training process using meta-gradient methods. The method is evaluated on 6 OpenAI continuous control benchmarks (with delayed reward), and demonstrates better performance than several state-of-the-art prior works on intrinsic reward.","In this paper, the authors explore a model based intrinsic reward generation mechanism, in environment settings where the reward assignment is sparse. The authors used an ensemble of models,  and computed the alpha-mean value of their KL divergences with respect to the ""true transitions"". The alpha-mean serves as the intrinsic reward, with the parameter alpha being co-optimized during the training.  The authors demonstrated that their proposed approach yields top performance in six augmented MuJuCo continuous control tasks. ",0.2391304347826087,0.275,0.2558139534883721
2085,SP:bd79f443ec2da0a34a77be823acfc81ba45d8a18,"The paper focuses on using intrinsic motivation to improve the exploration process of reinforcement learning agents in tasks with sparse-reward and that require multi-agent to achieve. The authors proposed to encourage the agents toward the actions which changed the world in the ways that ""would not be achieved if the agents were acting alone"". The experiments are done with dual-arm manipulation.","The paper proposes a novel algorithm for encouraging synergistic behavior in multi-agent setups with an intrinsic reward that promotes the agents to work together to achieve states that they cannot achieve individually without cooperation. The paper focuses on a two-agent environment where an approximate forward dynamics model is learnt for each agent, and can be composed sequentially to predict the next environment state given each agent’s action. However, this prediction will be inaccurate if the agent’s affected the environment state in such a way that individual dynamics model cannot predict i.e. synergistic behavior was produced. This prediction error is used as extrinsic reward by the proposed approach, while also having a variant where the true next state is replaced by another approximation of a joint forward model which allows for differentiability of actions with respect to the intrinsic reward. Empirical analysis shows that this intrinsic reward promotes synergetic behavior on two-agent robotic manipulation tasks and achieves better performance that baselines and ablations.",0.296875,0.1130952380952381,0.16379310344827586
2086,SP:bd7f50f0b7150fbbf799760afdeeaeed76e93c8e,"This paper focuses on the topic of learning from noisy -- or as they call it ""corrupted"" -- labels. Specifically this focuses on an approach where data selection -- ideally of cleaner/less noisy examples --  can help the learn model overcome data noise, akin to the approaches this builds upon (i.e, the Co-Teaching and MentorNet approaches). The specific idea here is to take an AutoML style approach to the problem  in particular to determine how many examples are selected in each mini-batch. The proposed method is based upon natural gradient based updates to the hparams (which was really the only feasible way to tackle this problem given the complex dependence on the hparams and a good choice). The experimental results using synthetic noise corruption are indicative of improved performance compared to the baseline techniques.","This paper studies the problem of learning from corrupted labels via picking up clean instances from training dataset. The sample selection mainly based on function R(t), which controls how many instances are kept. This paper proposes a unique curvature of R(t) based on intuition and presents how R(t) can be learned via combination of some existing functions. Natural gradient is presented to optimize the parameters in the autoML framework. Experimental results on both synthetic data and real-world data demonstrate the effectiveness of the proposed method. ",0.17164179104477612,0.25842696629213485,0.2062780269058296
2087,SP:bdd033e98090e13a856caeb28892512bfc0d67e3,"Risk monotonicity has raised many research interest since the pioneer work of Belkin, Mikhail, et al., as this contradicts the classical understanding that the risk decreases as we see more samples. The non-monotonic behavior of the risk curve stress that we lack a clear understanding of generalization. As a result, this paper aims to addressing the problem of how to obtain an algorithm that returns an estimator with monotonic risk behavior.   In addressing the above mentioned question, the authors make the following contributions:  The authors first derive a new concentration inequality for Martingale Difference Sequences. The bound drops the traditional assumption of i.i.d data and is time-uniform. In addition, the bound improves over the standard concentration inequalities by a factor of $\log n$.  On top of the concentration inequality bound, the authors also propose a ""wrapper"" algorithm which returns a consistent estimator that is proved to demonstrate monotonic risk curve. In addition, the algorithm does not hurt the excess risk convergence rate.","The paper studies the problem of risk monotonicity, that is, the property that the population loss decreases monotonically with increasing data points. The paper proposes an algorithm that converts any consistent base algorithm into a risk-monotonic algorithm while maintaining consistency under two assumptions: (1) an assumption on the generation of samples which is weaker than i.i.d. (2) an assumption on the base algorithm requiring its posterior to not have KL divergence to a fixed prior growing super-linearly in the sample size.  The approach presented in the paper is pretty straightforward: the base algorithm is run for $k=1, \ldots, n$ times and iteratively the current hypothesis is updated to be the base learner's output only if the risk reduces from the previous step, else it remains unchanged. Finally the hypothesis at step $n$ is returned. The main challenge here is to be able to confidently account for this change using the samples. For this, the authors derive a new concentration inequality for this using an online algorithm's guarantees.  ",0.1746987951807229,0.16666666666666666,0.17058823529411765
2088,SP:bddd3d499426725b02d3d67ca0a7f8ef0c30e639,"In this paper, the author extends the standard music Transformer into a conditional version: two encoders are evolved, one for encoding the performance and the other is used for encoding the melody. The output representation has to be similar to the input. The authors conduct experiments on the MAESTRO dataset and an internal, 10,000+ hour dataset of piano performances to verify the proposed algorithm.","This paper presents a technique for encoding the high level “style” of pieces of symbolic music. The music is represented as a variant of the MIDI format. The main strategy is to condition a Music Transformer architecture on this global “style embedding”.  Additionally, the Music Transformer model is also conditioned on a combination of both “style” and “melody” embeddings to try and generate music “similar” to the conditioning melody but in the style of the performance embedding. ",0.27692307692307694,0.23376623376623376,0.2535211267605634
2089,SP:be0078e2f368cda6539705fb4f17645823674872,"This paper presents a “hammer”-style ATP for the HOL4 theorem prover. Theorem proving is characterized as a Markov decision process in which states are sequences of subgoals that arise during theorem proving and in which the action space is defined over tactics (which can take either theorem labels or terms as input). Within this setting, the paper introduces a reinforcement learning algorithm that uses a novel architecture specific to the ATP task. The proposed algorithm out-performs state of the art ATPs. A core claim of the paper is that the system is capable of backtracking during proof search.","TacticZero proposes a reinforcement learning approach to theorem proving in interactive theorem provers (HOL4 in this paper, but the approach could be applied to others). The RL agent selects both a node in the search tree to expand and a proof tactic to apply in this state. This means the RL agent learns to generate good proof steps, but also learns how to search effectively. The paper formalizes this process as an MDP and demonstrates experimentally, that we can learn good search strategies in this way (compared to various BFS and DFS algorithms). The paper also shows that their approach compares favorably to existing theorem provers (not relying on deep learning). The RL agent is trained with policy gradient.",0.18,0.15126050420168066,0.1643835616438356
2090,SP:be306853f891ecd112e8ec21ec332af48be9b3ec,"This paper considers the problem of estimating the change in the performance of commercial ML APIs (ML as a service) as the models are updated over time (experiments are for 2020 vs 2021). It formalizes the problem as estimating the change in the confusion matrix over time. The main theoretical contribution is an adaptive sampling method to more efficiently estimate this shift. Interesting empirical results on various ML APIs are provided in the paper, showing the relevance of the problem and the effectiveness of the proposed method.",Authors show that ML models behind publicly available APIs change and these changes cause result changes for input datasets. Authors track the changes through confusion matrix differences. They propose an efficient algorithm they call MASA to evaluate the changes in results with reduced number of queries. Their algorithm achieves better estimates given the same budget than uniform sampling.,0.12643678160919541,0.1896551724137931,0.15172413793103448
2091,SP:be4508cbb636877e0f76a3518559df72623f394d,"The paper investigates the bias (an the variance) of the Bayesian-mean decoder. The authors found that the bias is driven by two components: The variations of the priors and variations of the Fisher information, and the exact relation is driven by the encoding objective. Simulations are used to back the results.  Disclaimer: I am an experimental visual psychophysicist with experience in Deep Learning. Thus the paper falls a bit outside my area of expertise (as indicated to the AC). I am focusing on the general aspects of this paper.","The authors present a unifying account of how the bias and variance of the Bayesian mean estimator (in an encoder-decoder setup) are determined from the prior and the encoder’s Fischer information. They then use these approximations to the bias and variance to explore the behavior of Bayesian-optimal systems across a fairly wide range of objectives (estimation, MI maximization, discrimination). Their theoretical findings recapitulate known findings, and also offer an explanation for anti-Bayesian bias (when the bias is toward the stimulus with lower prior probability). Specifically, the bias is proportional to the sum of a Bayesian effect (toward the prior) and an anti-Bayesian effect, where the dominant direction depends on the specifics of the problem. The authors show that their approximations are fairly consistent with true values for a simple problem when the encoding noise is low. ",0.28888888888888886,0.18439716312056736,0.2251082251082251
2092,SP:be490ce3cc1184daa229cab9c9dbfede83f79469,"The paper explores a hybrid type of model architectures that combines the recently popular transformer based model architectures with already well established convolutional neural networks. Specifically, the proposed hybrid model follows a two-stage training strategy where first a CNN model is trained and the pre-trained weights are used to further improve the training by recasting the weights into a new transformed CNN model termed int he paper as T-CNN. The proposed T-CNN model architecture is able to outperform its CNN counterparts and other models compared in the paper. The representations learnt by the T-CNN are also analyzed in the experimental analysis section.","This work proposes an approach to bridge CNNs and vision transformers for image recognition. The idea is to replace the last convolutional stage of a ResNet by a self-attention layer which is initialized from the weights of the convolutional stage. The approach is shown to improve the performance of the CNN, especially in terms of robustness to adversarial examples, corruptions in the input images, and domain shift. ",0.1588785046728972,0.25,0.19428571428571426
2093,SP:be593818e1d32a8b3cdb66adcbf6daca5c56cf0c,"This paper proposes Trust Entropy Actor Critic (TEAC), a novel algorithm for reinforcement learning (RL) combining the idea of TRPO/PPO and max-entropy RL, together with the corresponding critic, actor and dual updates. The high level idea is that trust region methods ensure stability by constraining the KL divergence from the previous policy, while entropy regularization encourages exploration, and hence combining the two may achieve the best of both worlds and obtain a good trade-off between stability and exploration. To achieve this goal, the authors propose to augment the original trust-region subproblem in TRPO with an additional constraint on the lower bound of the policy entropy (together with two other trivial constraints corresponding to the validity of the policy in the MDP framework). Then by forming the Lagrangian function and setting the gradient to zero, the authors obtain both the critic (value) and actor (policy) updates with different choices of dual variables (corresponding to the two trivial constraints), together with the dual updates. Numerical experiments compared to some popular baseline RL algorithms are also reported to demonstrate the improvement of TEAC compared to the existing works. ","The paper addresses the problem of reinforcement learning in continuous spaces by formulating the problem as a constrained optimization problem. In this problem, the objective is maximizing the expected reward, and the constraints ensure that 1) the distance between the new and old policies is bounded, 2) the entropy is above a threshold, and 3) the assumptions of MDP hold. The paper then derives closed-form solutions for the Lagrangian, which are used for obtaining variable update rules. An empirical study examines the ideas against benchmark problems. ",0.1164021164021164,0.25287356321839083,0.15942028985507245
2094,SP:be61009b01b9f886142989abefd0896a299b05d5,The paper shows a new loss function that can be used for quantile regression. The key idea is to combine loss functions often used in quantile regression with a new penalty that enforces conditional coverage. Results show improvements according to several metrics.,The authors propose a novel method to construct prediction intervals with pre-specified conditional coverage probability. Starting point of the paper is the observation that the length $|\hat{C}(X)|$ and conditional coverage indicator $1\{Y \in \hat{C}(X)\}$ are independent whenever the prediction interval $\hat{C}(X)$ has exact coverage probability.  The authors therefore suggest to compute lower and upper bounds of the prediction interval by solving a quantile regression problem augmented by a penalty term that penalizes correlation between $|\hat{C}(X)|$ and $1\{Y \in \hat{C}(X)\}$. The authors compare the performance of their procedure and competing methods on simulated data and nine benchmark data sets.,0.23809523809523808,0.09009009009009009,0.130718954248366
2095,SP:be68300138280bab710e907dfc81395c16a270cf,"This paper introduces Neighbourhood Distillation (ND), a new training pipeline for knowledge distillation (KD), which splits the student network into smaller neighbourhoods and trains them independently. The authors breaks away from the end-to-end paradigm in previous KD methods and provides empirical evidence to reveal feasibility and effectiveness of ND. Specially, ND can: 1) speed up convergence, 2) reuse in neural architecture search and 3) adapt to the synthetic data.","This paper studies knowledge distillation in the context of parallelly training sub-networks (called neighbourhoods) instead of commonly used end-to-end training paradigm. The authors explore the applications of the proposed neighbourhoods distillation in improving sparse networks,  searching a good student structure given the teacher and knowledge distillation merely using synthetic data. Both CIFAR and ImageNet datasets are considered in the experiments.",0.2112676056338028,0.23809523809523808,0.22388059701492535
2096,SP:be6df295f535480586a951445b824142bb60b56e,"This paper proposes a variant of MAML, called body only in the inner loop (BOIL), in which the output layer is not trained (learning rate is set to 0, always) but gradients are still backpropagated to the remaining layers, which are trained as in MAML. In essence, this is the inverse of the ANIL method of Raghu et al., which showed that MAML mainly adapts only the output layer for few-shot image classification. This paper shows that never training the output layer of the network (simply leaving it at its randomly-initialized values) can provide much better performance across a number of few-shot image classification tasks, including those requiring domain transfer.","Previous work studied MAML and showed that representation reuse is the main contributing factor in performance and not representation change. This paper first asks the question of whether representation reuse is enough for meta-learning? The paper hypothesizes and empirically evaluates the need/benefit for representation change in meta-learning tasks especially for cross-domain transfer. For this, they propose BOIL, a variant of MAML where the head of the network is not updated during inner loop updates.",0.13274336283185842,0.19230769230769232,0.15706806282722513
2097,SP:be719de25d3d60635a9508fd610f2da3f4fd164d,"In this submission, a common modelling assumption for unsupervised disentanglement is challenged: that the disentangled representation follows the independence structure of the underlying (data generating) factors. Instead, the paper proposes to consider *action sequences* which describe how datapoints are interrelated. The paper provides evidence that the capacity of the latent representation (controlled by Lagrange parameter beta in beta-VAE related models) is related to the significance of particular action sequence for disentanglement. To leverage this insight, the fractional VAE (FVAE) is proposed, consisting of several sub-encoders and different training stages. The disentangling properties of the FVAE is demonstrated on the dSprites and 3D chairs datasets, with the FVAE performing favourably to the beta-VAE w.r.t. the Mutual Information Gap (MIG) disentanglement metric on dSprites.","This paper addresses the problem of disentangling representations using Variational Autoencoders. In particular, the authors introduce the concept of disentangling action sequences and propose the fractional variational autoencoder framework to disentangle them step-by-step. To this end, they analyze the inductive biases on the data and define latent information thresholds which are correlated with the significance of the actions.",0.14173228346456693,0.3,0.1925133689839572
2098,SP:be7c42be6523a9923bf4701c9854816d0d8d2494,"This paper presented a new pooling method for learning graph-level embeddings. The key idea is to use the initial node attributes to compute all-pair attention scores for each node pair and then use these attention scores to formulate a new graph adjacency matrix beyond the original raw graph adjacency matrix. As the result, each node can average these attention score edges to compute the overall importance. Based on these scores, the method chooses top-k nodes to perform graph coarsening operation. In addition, a graph connectivity term is proposed to address the problems of isolated nodes. Experiments are performed to validate the effectiveness of the proposed method. ","This paper proposes a topology-aware pooling method on graph data, which explicitly encodes the topology information when computing ranking scores. More specifically, the proposed method uses an attention operator to compute similarity scores between each node and its neighborhood nodes, and then uses the average similarity score of each node as the ranking score in the node selection process. This topology-aware pooling technique can be applied to graph neural networks on downstream tasks such as graph classification. Experimental results demonstrate the effectiveness of the proposed method, which outperform previous state-of-the-art models consistently.",0.26605504587155965,0.29896907216494845,0.2815533980582524
2099,SP:be873fc103ccbf8312a711d8798834c2d824438b,"The paper proposed a scheme to detect the presence of anomalous inputs, such as samples designed adversarially for deep learning tasks, that is based on a ""subset scanning"" approach to detect anomalous activations in the deep learning network. The paper is considering a very interesting problem and provides the suitable application of an approach previously developed for pattern detection. The approach is motivated by p-value statistics of the activation patterns in the deep learning network under the ""null hypothesis"" of a non-anomalous input.","The paper is the first paper, in my knowledge, that introduces the problem of identifying anomalous (or corrupted) subset of data input to a neural network. The corrupted inputs are identified vis-a-vis a set of “clean” background set (e.g., the training/ validation data set). Experimental evaluation is performed on the problem of identifying the subset of noisy CIFAR-10 images created by adding targeted adversarial perturbations.",0.18823529411764706,0.2318840579710145,0.20779220779220778
2100,SP:beaa3dfef4bdf3d8fea64d4cf86911f45edd2873,"This paper sets up a new problem based on a continuous stream of potentially partially labelled data, which the authors call the Unsupervised Progressive Learning problem. The paper also introduces a new model designed to approach this problem, called the STAM architecture, with many concepts applied in a novel way. The STAM architecture is tested on example problems from the UPL problem.","This paper proposes a method called Self-Taught Associative Memory (STAM) for Unsupervised Progressive Learning (UPL) , i.e., learning salient representation from streams of mostly unlabeled data with occasional class labels, where the number of class increases over time. The motivation of this paper is quite interesting in that the authors try to mimic how animals learn. The surrounding environments of animals are considered to be unlabeled, and animals gradually learn to distinguish between objects without explicit information. The model shed light on the problem of catastrophic forgetting by introducing dual-memory organization. To be specific, Short-Term Memory contains a set of centroids associated with the unlabeled data, whereas Long-Term Memory stores the prototypical centroids, which are frequently seen patterns. In addition, the model utilizes novelty detection technique to introduce new centroids to each layer of the model, and it prepares the newly created centroids to be associated with new classes. ",0.24193548387096775,0.09803921568627451,0.13953488372093023
2101,SP:beaf78b9053a49c23e984589327f48513f1d4277,"This submission proposes an approach to modulate activations of general convolutional neural networks by means of an auxiliary network trained on additional metadata to a dataset. The specific goal is to improve out-of-distribution (OOD) generalisation. This *conditional network* approach is illustrated for two standard convolutional neural network (CNN) architectures, U-Net and VGG, on two benchmark datasets suitable for OOD detection, the Inria Aerial Image Labeling Dataset and the Tumor Infiltrating Lymphocytes classification dataset. The conditional network approach yields favourable results compared to competing segmentation as well as classification networks and exhibits a reduction of the generalisation gap compared to the baseline methods. ",This paper aims to tackle the out-of-distribution generalization problem where a model needs to generalize to new distributions at test time. The authors propose to utilize some extra information like the additional annotations as the conditional input and output the affine transformation parameters for the batch normalization stage. This extra information helps the backbone network get a more general representation from the training set thus the model is robust to the distribution shift when testing. Experiments are conducted on the Aerial Image Labeling and the Tumor-Infiltrating Lymphocytes datasets which correspond to the image segmentation and classification task respectively.,0.20952380952380953,0.21782178217821782,0.21359223300970875
2102,SP:bec6749b6c08257273b9666e874b7faa8fa20b3d,"Previous works have shown that DNNs are able to memorize random training data, even ignoring the enforcing of data-dependent geometric regularization constraints. In this work, authors show convincing results indicating that this is due to a lack of consistency between the main classification loss (typically soft-max cross entropy) and the selected geometric constraint. Consequently, they propose a simple approach where the softmax loss is replaced by a validation loss that is consistent with the enforced geometry. Specifically, for each training batch, instead of considering a join loss (soft-max cross entropy + geometric constraint), they apply a sequential process, where each training batch is split into two sub-batches: a first batch used to apply the geometric constraint, and a second batch (based on the proposed feature geometry) where a validation loss is used to generate a predicted label distribution. Authors test the proposed idea using an implementation that enforces that samples from each class belong to an independent low-rank sub-space (enforced geometric constraint). Results verify the main hypothesis. Specifically, the resulting model is able to fit real data but not data with random labels. The strength of this evaluation is enhanced including results from relevant baselines. In terms of generalization of real data, the proposed approach offers a small increase in accuracy.","The paper proposes a data-dependent regularization method which is coupled with softmax loss to train deep neural networks for classification. The paper turns to Orthogonal Low-rank Embedding (OLE) loss for the geometric constraint that one class of data/feature are assumed to reside on a low-rank subspace that subspaces of different classes are orthogonal ideally. The probability in the softmax is then modeled as cosine similarity between data feature and the class-specific subspaces. In this way, geometric loss and softmax loss have the common goal for optimization. Moreover, during training, the geometry enforced on one batch of features is simultaneously validated on a separate batch using a validation loss. The experiments seem to suggest such a model helps avoid overfitting/memorizing noisy training data. The paper reads well and is easy to follow.",0.1527777777777778,0.24087591240875914,0.18696883852691218
2103,SP:beceaf69f88002af8930ddd841296b5a40feb8c8,"The paper proposes a method for imitation learning via inverse reinforcement learning based on a specific modeling of the reward. It is modeled as the log probability of a state action pair to belong to the expert policy. It models this distribution as a Bernoulli one and thus it reduces the IRL problem to a classification task. The global method also uses an off-policy algorithm to learn the value function of the current agent policy to improve sample efficiency. The method is tested on a set of continuous control tasks such as walker, hopper or humanoid. ","This paper proposes a new method to imitate expert efficiently. The paper first proposes a way to compute reward function from expert demonstration and uses the log probability to represent this reward function.  Then they find a form of bellman equation that can optimize the reward stably. After the 'Q learning without IRL', an off-policy RL off-pac is applied. So this paper achieves comparable results to GAIL but uses much less data amount. ",0.18556701030927836,0.24,0.20930232558139533
2104,SP:bf0b8ec1ea69eb1b54e6502182b66ab3a8321c42,"This manuscript proposes an approach to reduce memory access and computation in Recurrent Neural Networks.  Specifically, they train a second ""little"" neural network to approximate a pre-trained ""big"" network and use simple rules to switch between the little and the big network.  The approach can provide some speedups while reducing the total number of memory accesses and the computational cost in exchange for a mild decrease in predictive performance.","This paper attempts to compress the networks so as to accelerate the running procedure as well as save the storage. The authors propose a dual-module that is composed of a little module and big module. The big module use the full original data and parameters whereas the little module use small data and parameters by random projecting on the original ones. Through a statistical investigation, the authors provide a method to choose the little or big module dynamically. By applying this method on LSTM and GRU, the authors make them more efficient. Experimental results validate this point.",0.22857142857142856,0.16326530612244897,0.19047619047619044
2105,SP:bf0cf7080618b0578eab60961d20e7a99a50c080,"The authors present an approach to optimize determinantal point processes directly (by gradient descent, instead of . via approximations), so that diversity could be modeled in objective functions for deep learning systems. The approach taken is to express the DPP term as an L-ensemble in the spectral domain over the gram matrix. They also generate sub-gradients for cases where the gradient does not exist (when the gram matrix is not invertible).","Determinantal Point Processes (DPPs) are statistical models that allow efficient sampling of diverse solutions - a problem that is hard with most machine learning modeling frameworks.  However, learning diverse features via DPPs with deep learning frameworks is challenging due the instability in computing the gradient which involves a matrix inverse operation. Better marriage between deep learning and DPPs is an important problem as diversity is crucial in many machine learning problems (even beyond computer vision - the experimental domain of this paper - e.g. in machine translation and document summarization). ",0.19444444444444445,0.1590909090909091,0.17500000000000002
2106,SP:bf0dc1023654d3b515119e32a8bd9ab97a79398a,"The authors propose a scheme for simultaneous dictionary learning and classification based on sparse representation of the data within the learned dictionary. Their goal is achieved via optimization of a three-part training cost function that explicitly models the accuracy and sparsity of the sparse model, simultaneously with usual classification error minimization. An alternating optimization algorithm is used, alternating between sparse representations and other parameters.","This manuscript studies supervised learning with incomplete observation of the features, assuming a low-rank structure in the full set of features. The work tackles the problem with a global cost function that optimizes the classifier on observations reconstructed with a dictionary penalized jointly for sparse coding. Importantly, the dictionary is optimized both for the supervised-learning task (the classifier) and the sparse coding. The manuscript contributes a theoretical argument showing with sparse-recovery arguments that if the data can be decomposed sparsely, the incomplete feature prediction problem can perform as well as the complete one. Finally, it performs a empirical study on simulated data as well as computer-vision problems with random missing pixels as well as occlusions, and using for the classifier logistic regression as well as classic neural network architectures.",0.24615384615384617,0.12030075187969924,0.16161616161616163
2107,SP:bf144506fc556d0587b7c2a24e1284dcd69f7c26,"This paper proposes an anomaly detection approach that has two stages: a first stage for learning a feature representation and a second stage to train either a one-class classifier based on OC-SVM or KDE.  The main contribution of the paper is the feature representation learning that relies on contrastive learning to optimise a self-supervised loss function which minimises the distance of the samples from the same image augmented with different data augmentation functions and maximises the distance of samples from different images augmented with the same augmentation functions.  The data augmentation functions used were horizontal flip and rotation (0,90,180,270).  Results on the public datasets CIFAR-10, CIFAR-100, Fashion MNIST, and Cat-vs-Dog show that the proposed method has better anomaly detection (measured with AUC) than the state of the art.  The paper also displays qualitative anomaly detection results and an ablation study that shows: a) how close to uniform distribution (on hypersphere) the feature representations are as a function of batch size, and b) how AUC is affected with batch size and depth of MLP project heads.","This paper proposes a framework for deep one-class classification (an example application being anomaly detection).  The basic idea is to combine self-supervised representation learning (eg through a proxy task such as rotation prediction or contrastive learning), with a classical approach to one-class classification, such as one-class SVM or KDE.  This is in contrast to existing methods for deep one-class classification that use simulated outliers to form a surrogate classification loss and then train end-to-end.  The paper further improves on the first stage of representation learning, by introducing modifications to contrastive learning to make it more appropriate for one-class classification.  The main insight is to introduce distribution augmentation, where geometric transformations of images, such as rotation, are treated as separate instances, to be separated from the original view.  This is motivated from the perspective of reducing uniformity of the inliers across the unit hypersphere, to allow for better separation from outliers.",0.1837837837837838,0.21518987341772153,0.19825072886297374
2108,SP:bf5f51cf38c536816105c691b7f1eee6d004fc05,"This paper investigates the use of random perturbations applied to a robotic policy to learn a local gradient useful for policy optimization. The method aims to learn a policy directly on a real physical robotic system, bypassing both simulation models and model-free RL. Training pairs are gathered by perturbations of a starting policy, and the ""gradient"" is captured in a probabilistic model learned from the training data. The paper includes experiments on a custom 3-DOF robotic platform.","This paper presents a method for control by estimating the gradient of trajectories w.r.t. the policy parameters by fitting a GP to a set of noisy trajectories executing the same controller. This is opposed to the majority of current RL methods that either learn a forward model or learn a policy. They argue that learning this gradient is a middle step between model-based and model-free RL. The method is shown to estimate gradients on simple policies (linear and nonlinear open-loop controllers, and a linear PD controller) for a free-space reaching robot, and update a controller to add a trajectory constraint to pass an intermediate state.",0.26582278481012656,0.1891891891891892,0.22105263157894736
2109,SP:bf66a9d224ff5090ed67cfb1a6a73a9c929e5b50,"This paper proposes to address the limitation of current interpretable graph neural networks over out-of-distribution data. In this work, the intrinsically interpretable GNN is investigated by identifying the invariant rationales corresponding to environment-invariant causal patterns. The proposed model is evaluated on the graph classification task to demonstrate its effectiveness as compared to state-of-the-arts.","This paper proposes a novel algorithm DIR that allows the learned GNN model to make predictions based on causal patterns. The whole framework consists of four components where (1) the rationale generator splits the input into causal and spurious parts; (2) the distribution intervener replaces the spurious part; (3) the graph encoder embeds the graph based on the spurious and causal parts, respectively; (4) the shortcut and causal classifiers are applied to the spurious and causal embeddings, respectively. This algorithm is highlighted by its objective which encourages the predictions accurate while invariant to the spurious part. On both synthetic and real-world datasets, DIR outperforms the related baselines consistently. As a novel end2end rationalization method, As a novel end2end rationalization method, the underlying DIR principle is proved to be sufficient and necessary for satisfying the oracle function.",0.3220338983050847,0.1386861313868613,0.19387755102040816
2110,SP:bf9538a602859eaf9e0c3138c5e46c782863a054,"This paper proposed the combination of two techniques for improved learning with unlabelled data: 1)  Positive-Unlabelled (PU) classifier, and 2) class-conditional GAN (cGAN). The idea is that the PU classifier can help produce more accurate pseudo labels for training of a cGAN, and with the improved cGAN, the generated images can be used in turn to further improve the PU classifier. The idea looks interesting and the empirical results verified its effectiveness. ","This paper targets at relieving the massive labeled data consumption of deep learning through the framework of semi-supervised learning. In particular, it finds out that two training approaches, Positive-Unlabeled classification and the conditional generation, can benefit each other. Jointly conducting these two approaches can push better performance on both tasks, thus eventually achieving better performance with a limited amount of labeled data. The authors combined the two tasks with a new type of GAN network. They further gave the corresponding theoretical proof for this new GAN model and verified its performance on the benchmark datasets.",0.22972972972972974,0.17525773195876287,0.19883040935672514
2111,SP:bfc029f8ae6271d156f507cf3886bd4079a91d55,"The paper introduces a new neural network architecture called a ""Graph Tree Neural Network"". This architecture is inspired by several properties of the human brain: 1. it's multi-modal; 2. it allows for cross-input reasoning; 3. it can adapt its internal structure to the current input; 4. it can adapt the amount of computation per input; and 5. the human brain is larger than most neural networks.  The architecture itself relies on mode-specific representation components: later, in the experiments, they introduce targeted architectures for images, speech and text. These representations are then consumes by a convolutional logic that allows full communication within the different components of the network. Finally, these components can be recursively combined to yield a full graph tree neural network.  This architecture is then evaluated on several domains covering speech, vision and nlp datasets, showing consistent improvement over the selected baselines.","In this paper, the authors propose Graph Tree Neural Network (GTNN) a new learning model that is structured as a graph tree (i.e., a tree with links between siblings) where each node has to process the data coming from its children. GTNN can take as input data of various types where each node will be processing the data differently according to the data type. The authors describe how (de)convolution and recurrent neural networks can be achieved within GTNN. Experiments were conducted on some classic deep learning datasets of three different data types: images (MNIST), language (IMDB), and sound (Speech Command). The goals of those experiments were two see whether GTNN can process various datasets of different types and if GTNN can produce an output vector that retains all the information coming from the different data types.",0.14965986394557823,0.15942028985507245,0.1543859649122807
2112,SP:bfdade05a90180a4b30d9593598b9d7c2a9e0533,"This paper presents a simple methodological study on the effect of the distribution of  convolutional filters on the accuracy of deep convolutional networks on the CIFAR 10 and CIFAR 100 data sets. There are five different kind of distributions studied: constant number of filters, monotonically increasing and decreasing number of filters and convex/concave with a local extremum at the layer in the middle.  For these distributions, the total number of filters is varied to study the trade-off between running-time vs. accuracy, memory vs. accuracy and parameter count vs. accuracy.","The search/design space of neural network architectures is vast, so researchers tend to use simple heuristics to guide their designs; alternatively neural architecture search methods may minimise heuristics in order to remove bias within the search. The authors propose applying a few simple heuristics in the form of ""templates"" for the number of convolutional filters across the different layers within an architecture. Apart from reversing the filter distribution, which starts a network with a large amount of filters and then reduces them (given how the filter number is generally increased with depth and reduction in spatial resolution), the authors also propose using the same number of filters per layer (""uniform""), as well as ""quadratic"" and ""negative quadratic"" distributions. There does not seem to be any particular motivation for these patterns, but this is at least better than poor justifications.",0.2391304347826087,0.15714285714285714,0.1896551724137931
2113,SP:bffc59409af0acecdcb344728b3f18d404e9d6ea,The paper works on improving the runtime for estimating Shapley values. The work introduces FastSHAP that estimates Shapley values with a learned explainer model. The method is validated on tabular and image datasets (CIFAR10 and Imagenette).,"This paper proposes FastSHAP to efficiently estimate the Shapley value in a single forward pass using a learned explainer model. Since there is no label to train the Shapley value estimator, stochastic gradient optimization using a weighted least squares-like objective function is applied to train FastSHAP. The experimental results and the deployment efficiency shows the superiority of the presented method.  ",0.2777777777777778,0.16393442622950818,0.20618556701030927
2114,SP:c00be5119de90c410bab1b23fc36e559aca76041,"This paper applies several algorithmic and code optimization techniques to reduce the training time for word2vec and fastText. The final implementation runs 3-20x times faster than the baselines on manycore CPUs, with almost no quality loss. The improved implementation is a result of the combination of many techniques, including namely no_subword, Minibatching, Negative sharing etc. ","This paper proposes the approaches that reduce the training times of word2vec and fastText. To improve the efficiency, it uses several techniques such as negative sample sharing, batched updates, and a byte-pair encoding-based alternative for subword units. By using English, German, and Russian languages data, it shows that the proposed approach is much faster than the existing approaches. ",0.21052631578947367,0.2,0.20512820512820512
2115,SP:c05a2a8f891a43b8c4ccb920d595fd3ac330bfc3,The authors propose the generative classifier for meta continual learning. This approach is an extension of a well-known method for few-shot learning called prototypical networks. The proposed method is evaluated on two challenging continual learning datasets (Omniglot and MiniImagenet) and compared to other methodsin this field as well as adequate baselines.  The main contributions of the paper can be summarized as: - The introduction of the new method for continual learning using the generative classifier.  - Clearly explained and visualized with toy example the difference between catastrophic forgetting in case of generative and discriminative classifiers. - Precisely formulated and justified statements about immunity to catastrophic forgetting. - Insightful empirical analysis of the proposed method (mostly covered in the appendix).  ,"This paper proposes a probabilistic generative approach using meta-learning for continual learning. It is inspired by cognitive and neuroscience about meta-continual learning to address catastrophic forgetting. It presents the problems occurring in the discriminative approaches and suggests how to handle them by using generative classifiers. Using new update scheme for discriminative classifiers, it shows that the catastrophic forgetting problem is reduced. It also improves the existing prototypical learning by Bayesian approach.    ",0.15384615384615385,0.2465753424657534,0.18947368421052632
2116,SP:c06210186b5a8a289540141b1cf72b2500f1668d,"This paper presents a new synthetic dataset to evaluate the mathematical reasoning ability of sequence-to-sequence models. It consists of math problems in various categories such as algebra, arithmetic, calculus, etc. The dataset is designed carefully so that it is very unlikely there will be any duplicate between train/test split and the difficulty can be controlled. Several models including LSTM, LSTM + Attention, Transformer are evaluated on the proposed dataset. The result showed some interesting insights about the evaluated models. The evaluation of mathematical reasoning ability is an interesting perspective. However, the un-standard design of the LSTM models makes it unclear whether the comparisons are solid enough. ","This paper is about models for solving basic math problems. The main contribution is a synthetically generated dataset that includes a variety of types and difficulties of math problems; it is both larger and more varied than previous datasets of this type. The dataset is then used to evaluate a number of recurrent models (LSTM, LSTM+attention, transformer); these are very powerful models for general sequence-sequence tasks, but they are not explicitly tailored to math problems. The results are then analyzed and insights are derived explaining where neural models seemingly cope well with math tasks, and where they fall down. ",0.1926605504587156,0.2079207920792079,0.19999999999999998
2117,SP:c06abfb514f76fecbab62bd5730df2012b3e896a,"This paper studies the problem of multi-task offline RL and propose 2 methods, BAIL+ and MBAIL, each is an algorithmic variant based on the BAIL algorithm. The overall goal is to improve performance on multiple tasks. This setting concerns with a number of tasks coming from a MDP distribution where transition function is the same and reward function is different.  The authors propose a 2-stage method: first use the BAIL+ algorithm to boost the performance of a particular task with data from other tasks. Then, distillation is used to distill policies from these tasks into one policy. ","(Note that the rest of the review will use Offline RL and Batch RL interchangeably)   Building on top of BAIL (Chen et al. 2019), this paper provides two algorithms for the multi-task offline RL setting. The BAIL+ algorithm assumes that we know the identity of the target task and that all tasks share the same transition function. It uses sample transfer from non-target task data to boost its performance on the target task. The MBAIL algorithm builds on top of BAIL+ and MBML (Li et al 2019), where it distills the BAIL+ policies for each individual task into one master policy that performs decently on all tasks. The authors evaluated the proposed methods on the Ant-Dir, Ant-Goal, and HalfCheetahVel environments from Mujoco. The authors compared MBAIL, BAIL+, BAIL, and contextual BCQ. MBAIL consistently performed the best out of the first three, while contextual BCQ performed better on the Ant-Goal env.  ",0.24242424242424243,0.15483870967741936,0.1889763779527559
2118,SP:c076b203ffada1be4399351d17008ce6fa54f441,This paper proposes an information-theoretic framework for learning a world model that encodes task-relevant information of the world. It shows that the learned encoder and dynamics model can be used to train the policy and fitting the value function to agent to perform comparibly well to Dreamer on standard tasks and outperform them when there are distractions in the scene. The paper also provides a theoretical anylisis of the task-relevant information in the encoding.,"The paper proposes a method for visual model-based reinforcement learning that relies on contrastive learning to learn the predictive model. Building on Hafner’20, the paper replaces the image reconstruction objective with a noise contrastive estimation (NCE) objective for the latent dynamics model, an NCE objective between the images and representations, and an additional maximum likelihood objective for the latent dynamics. It is shown that the method is competitive to Hafner’20 on the DM Control benchmark, and outperforms Hafner’20 on DM Control tasks with natural images used as background. The paper also theoretically analyzes one of the used objectives, arguing that it may lead to discarding irrelevant information.",0.2727272727272727,0.1891891891891892,0.22340425531914893
2119,SP:c08b370b56eba4fb58a1ea1cba0f45c9cd3143e7,"This paper considers the rate at which the SGD iterations will escape the valley around a local minimum. Under some approximation assumptions, this paper shows that the SGD noise covariance is highly structured as it aligns with the Hessian at the local minimum in the immediate vicinity. By considering the Ito SDE with the approximate SGD noise covariance and through a random change of time scale, the the Langevin equation on the loss landscape is transformed to that on the logarithmic loss landscape, but with a simpler additive noise. Such a logarithmized loss landscape is then exploited to derive the escape rate of SGD from a local minimum.","This paper studies the behavior of SGD around the minimum. Unlike many other works that simply treat SGD noise as a fixed noise, the authors characterizes the location-dependence of SGD noise, which gives drastically different escaping behavior. By some simplification of the noise covariance matrix, the authors are able to formulate an SGD with isotropic noise with a time change. The new SDE is a dynamics on the log-loss landscape with a simple additive noise. With this result, the escape rate and stationary distributions are derived, depending polynomially on the loss, instead of exponentially. Numerical experiments are conducted to justify the assumptions made in the analysis, and verify the theoretical conclusions in the case of linear regression.",0.3055555555555556,0.2773109243697479,0.2907488986784141
2120,SP:c0924c1c4d4132e6d80e24103c243780438f8a89,"The paper introduces an approach for learning policies across multiple MDPs and using those policies to improve learning performance on the task that the agent designer cares about. The approach assumes that a set of MDPs are provided to the learning agent, and that all of the MDPs have the same underlying task but with different reward densities (i.e., some of these MDPs have shaped rewards, and thus are faster to learn from). The approach operates by training the main agent to imitate the actions chosen by the other agents that are trained on the MDPs with shaped reward functions.","This paper introduces an approach called action guidance, made to address issues in more standard applications of reward shaping. The main idea of their approach is that there are two different kinds of agents, one (auxiliary agents) that learn from shaped reward functions alone and the other (main agent(s)) that learn only from the actual sparse rewards. The authors made use of a simplified RTS domain and demonstrated that their approach outperformed a more naive shaped reward approach. In addition they demonstrated an ablation study on positive learning optimization. ",0.2079207920792079,0.23333333333333334,0.21989528795811517
2121,SP:c0a87b8792e2ec4144737c3b48439aebe4f9f915,"Motivated by the emergence and fast development of the area of neural optimisation solvers having been proposed for a vast number of combinatorial problems, this paper is devoted to studying the adversarial robustness of such solvers. In particular, given the intractability of the target combinatorial problems, the paper proposes to evaluate neural solvers based on adversarial robustness. As an example, the authors aim at perturbing SAT and TSP problems and evaluating the robustness of the corresponding state-of-the-art neural solvers on the perturbed problem instances. The paper shows that the existing solvers are susceptible to adversarial attacks. Moreover, the paper claims that the issue may be alleviated if additional training of the solvers is performed on the perturbed instances.","In this paper, the authors propose to evaluate and improve the robustness and generalization of neural combinatorial solvers with adversarial examples, that is, perturbed inputs that fool the neural network to generate outputs with high loss. The authors claim that their proposal reconciles the tension between the hardness results from Yehuda et. al. (2020) and the overly-optimistic evaluation results from previous work. Furthermore, they instantiate their proposal with two classic combinatorial problems -- SAT and TSP, where adversarial examples are generated without the need to run potentially exponential-time solvers. They show that adversarial examples not only expose the fragility of common neural solvers, but can also help improve their generalization and robustness via adversarial training.",0.19008264462809918,0.19827586206896552,0.1940928270042194
2122,SP:c0c3373f6d4e54dc4ce24da2bd90ac9644593e30,"This paper proposes a method to train a neural network by selecting a weight from a set of $K$ randomly generated weights for each edge in the network. Each edge has a different set of random weights. Quality score is assinged to each of $K$ random weights, which determines the weight used in the forward calculation. Instead of optimizing weights directly, the proposed method optimizes the quality scores with the straight-through gradient estimator. Experimental results show that the neural network trained by the proposed method achieves high accuracy compared to random initialization even when $K=2$.","The paper investigates a type of neural network in which one of K possible fixed weights is chosen in each neuronal connection. The weights themselves are fixed and random, but the scores that determine which of the weights is chosen are updated through back-propagation using a straight-through estimator. The accuracy and behavior of such networks is studied for small networks on small datasets (MNIST, CIFAR).",0.1958762886597938,0.2835820895522388,0.2317073170731707
2123,SP:c0d72e20146d4608068bd607c0d1fe306e821779,"The paper presents a novel approach for determining the causal direction between two random variables $A$ and $B$. The approach is based on the assumption that the conditional distribution $P_{A \rightarrow B}(B \mid B)$ does not change between the train and transfer distribution. As a result, a model that predicts the correct causal direction $A \rightarrow B$ should generalize better from the train to the transfer distribution compared to a model predicting the wrong causal direction $B \rightarrow A$. While previous work has proposed to use this insight to determine the causal direction by comparing the adaptation speed, this paper proposes to directly measure and compare the generalization performance. The results indicate that the proposed approach leads to the same performance in terms of causal relation prediction, but that it is more sample efficient and faster.","This paper describes an approach for learning a representation U(X,Y), V(X,Y) of data (X,Y) such that U and V are causally meaningful, and U causes V. The approach relies on observing data from two domains, P and Q, where P(V| U) = Q(V |U) (reflecting the causal structure). The approach is a modification of Bengio et al. The main new idea is that the objective function can be tweaked by replacing a KL divergence term with a term involving domain-shift induced generalization errors.",0.13043478260869565,0.2,0.15789473684210528
2124,SP:c0e79bbc34b390168a3bc07c2c1b410736100783,"The authors demonstrate that using a modification of the LiRPA method during the branch-and-bound process for solving the neural network verification problem can lead to significant speed-ups. The experimental results are strong. The authors convincingly show that the their method outperforms the existing state-of-the-art method by Lu & Kumar (2020) on an experimental setup similar to that work. The application of LiRPA to branch-and-bound is straightforward (since any incomplete verifier can be used), as is the use of gradient descent to improve the bound given by LiRPA (a standard technique applied to improve the bounds of certain verifiers). ","This paper describes a branch-and-bound (BaB) process for neural network verification that uses linear relaxation based perturbation analysis (LiRPA). It gives a way to tighten the bounds obtained via LiRPA. Overall, this results is a complete verification procedure, which is an order of magnitude faster than existing linear programming (LP) procedures.",0.1523809523809524,0.3018867924528302,0.20253164556962025
2125,SP:c0f61016a2c05e72b86843012e7bca7b678907b3,"In this paper, authors propose a conditional generative model which predicts the missing expression given the surrounding code snippet. Authors represent programs as graphs and use some off-the-shelf encoder to obtain representations for all nodes. Inspired from the attribute grammar, authors augment every node in AST with two new nodes which contain inherited and synthesized information. Based on GGNN, a grammar-driven decoder is further proposed to sequentially generate the AST and the corresponding program. Authors also propose a large dataset which is built from open sourced projects. Experimental results on this dataset show that the proposed method achieves better predictive performance compared to several recent work. ","The paper introduces a 'code generation as hole completion' task and associated dataset, ExprGen. The authors proposed a novel extension of AST code generation which uses what they call Neural Attribute Grammars. They show the proposed method does well on this task, compared to ablations of their model (which are similar to previous AST approaches).",0.14678899082568808,0.2909090909090909,0.1951219512195122
2126,SP:c126dc4e6625a18fdeecbd54f61abeff7e38f796,"This submission proposes a new federated learning framework based on knowledge transfer. Local dataset at each party are partitioned and each partition is used to train a teacher model. All teacher models at each party are used to train a student model using pseudo labels based on voting on public dataset. Student model from each party is then uploaded to server and used to train the final model based on voting on unlabeled data. Differential privacy analysis is conducted and experimental evaluations comparing to other mainstream federated learning methods are presented. The advantages of the proposed method include privacy preservation, lower communication traffic, as well as applicability to non-differentiable models. While the proposed framework is technically sound, the reviewer is not convinced by its technical contributions. The design of the framework is integration of existing technics such as PATE, and the mechanism of protecting privacy as well as reduction of communication traffic is also not new (see FedMD: Heterogenous Federated Learning via Model Distillation,  Neurips 2019 Workshop and Ensemble Distillation for Robust Model Fusion in Federated Learning, Neurips 2020). There is no clear advantage in the proposed method over these existing methods from the reviewer’s point of view. Plus the overall performance on benchmark dataset seems to be degraded compared to other mainstream methods like FedAvg. The reviewer would like the authors to explain and discuss the technical contributions of the submission and compare the proposed framework to these similar existing methods based on knowledge transfer. ","The paper considers classification tasks in the federated learning scenario when each device/worker is powerful in terms of computational power and storage space, but, the communication between devices is constrained. The paper proposes a novel algorithm for federated learning that reduces the number of communication rounds to one. The algorithm constructs an ensembled model with the majority voting out of the locally trained models and then on the server side learns a final model by mimicking the performance of the ensembled model on a public dataset. ",0.10080645161290322,0.28735632183908044,0.14925373134328354
2127,SP:c1297729b15bbaece175e784cd5f7db7f395fede,"This paper presents a meta-active learning approach to obtain an LSTM-based embedding of a dynamic system and use a chance-constrained (probabilistic safe) optimization to find optimal control configuration via applying mixed-inter linear programming (MILP) on the learned embeddings of the dynamic system. The main idea is to learn a Q-function as an acquisition function to describe the future information gain, which is the percent decrease in the error of the objective (e.g. model error) via a meta-learning strategy in which the agent interacts with the environment via distribution of altered dynamics. ","In this work, a meta active learning approach is proposed to learn the hidden dynamics of control systems, where safety is also a major concern. The main idea lies in doing meta-learning with Q-learning, meanwhile selecting safe actions by solving a mixed-integer linear programming problem. The performance of the proposed approach is verified from real datasets of deep brain stimulation by outperforming existing baselines for a significant gap in both accuracy and computational complexity.",0.20408163265306123,0.2597402597402597,0.22857142857142856
2128,SP:c137c12d6f9dfed77ea6b51e05ef79aa8ac2a987,"This paper develops a general morphology evolution algorithm, and demonstrates its utility in a setting where morphologies are encoded as graphs. The methodology is grounded in a theoretical notion of empowerment, and theory is introduced that extends empowerment to the case of morphology. The morphology evolution itself requires no task-specific signals, but yields morphologies that generalize well to several tasks of interest.","The paper introduces an algorithm for optimizing the robot morphology in a simulated environment. The key idea is that instead of finding a morphology and a controller for a specific task, they propose to search for a morphology that can reach a large variety of states in a predictable way. Specifically, they developed an objective function that maximizes the mutual information between the actions and the final states of the robot. The proposed algorithm is demonstrated on a few simulated locomotion and manipulation tasks.",0.20634920634920634,0.15476190476190477,0.17687074829931973
2129,SP:c157b650393ac987f2816812d1b720e41a8eb39c,"The paper meticulously builds a theoretical framework for Lie-algebra convolutional layers and then goes on to show how CNNs, GCNs and FC layers are a special case of L-convs. The paper also demonstrates how the underlying generators can be learnt from data and provide convincing supporting experimental results. The proposed L-conv layers also use much fewer parameters compared to previous works. ","The paper presents a new approach for building group-equivariant neural networks. The authors propose *L-conv*, a layer which is equivariant to transformations from a group $G$ in the neighborhood of identity. They show that a network with a sufficient number of such layers is $G$-equivariant as a whole. Additionally, the authors propose to learn the structure of the group directly from the training data instead of incorporating it in the network *a priori*.",0.203125,0.17105263157894737,0.18571428571428575
2130,SP:c163bfc3f289c0c63ec25bbd21a63a921518ed22,"This paper presents a method for symbolic superoptimization — the task of simplifying equations into equivalent expressions. The main goal is to design a method that does not rely on human input in defining equivalence classes, which should improve scalability of the simplification method to a larger set of expressions. The solution uses a reinforcement learning method for training a neural model that transforms an equation tree into a simpler but equivalent one. The model consists of (i) a tree encoder, a recursive LSTM that operates over the input equation tree, (ii) a sub-tree selector, a probability distribution over the nodes in the input equation tree, and (iii) a tree decoder, a two layer LSTM that includes a tree layer and a symbol generation layer. The RL reward uses an existing method for determining soft equivalence between the output tree and the input tree along with a positive score for compressing. ","This paper provides a novel approach to the problem of simplifying symbolic expressions without relying on human input and information. To achieve this, they apply a REINFORCE framework with a reward function involving the number of symbols in the final output together with a probabilistic testing scheme to determine equivalence. The model itself consists of a tree-LSTM-based encoder-decoder module with attention, together with a sub tree selector. Their main contribution is that this framework works entirely independent of human-labelled data. In their experiments, they show that this deep learning approach outperforms their provided human-independent baselines, while sharing similar performance with human-dependent ones.",0.19205298013245034,0.26851851851851855,0.22393822393822393
2131,SP:c171fccf8cd846266842b5fc4896477903b9bdb5,"In this paper, the authors present a interesting, novel idea of promoting the diversity and cooperation among multiple RPNs for the problem of few-shot detection. They first identify a critical problem in few-shot detection, which is that existing RPNs can miss objects of novel classes and that their proposed boxes make very similar errors. In order to resolve this issue, the authors propose to utilize multiple RPNs in the same detection pipeline and include a diversity loss when training the RPNs, such that they provide diverse scores to the anchor boxes. In this way, the chance of all the RPNs missing an object becomes small. The authors further include a cooperation score to enforce the RPNs to provide more meaningful scores (rather than sparse scores just to promote diversity). The proposed approach is evaluated on COCO and Pascal, and the results demonstrate that the proposed approach does improve the detection performance, as compared to the state of the art, especially in very low-shot cases.","The authors propose a few-show object detection architecture, which improves the 1st stage of two-stage detectors (R-CNN in particular). In a few shot setting, the existing approaches the region proposal generator may ignore some novel out-of-distribution classes as they have not been included at training time. The proposed method attempts to correct this by using many RPN's, and training them such that the gradient is only passed to one of them at a time; thus forcing them to learn mutually different kinds of regions.",0.1377245508982036,0.25555555555555554,0.17898832684824906
2132,SP:c175800a7bed98ed75736f032d6a5a9a2f3832c0,"The paper introduces a framework for computationally efficient and exactly rotation-equivariant spherical CNNs. The work most closely resembles the Fourier space method of Kondor et al., but improves on it in a number of ways: firstly, a channel-wise structure is introduced for the tensor product nonlinearities, which avoids the degree blowup of this operation while still allowing mixing between different harmonic degrees. Secondly, computational complexity of linear layers is reduced by factorizing it into three operators, two of which operate similar to depthwise-separable convolutions and one of which acts uniformly across channels. Thirdly, an optimized sparse degree mixing set is proposed, based on a minimum spanning tree. Finally, a more efficient sampling theorem is used that reduces the Nyquist rate by a factor of two compared to the ones used in previous works on spherical CNNs.","This paper introduces a generalized spherical convolution operation that is strictly equivariant to rotation. The authors show that the spherical convolution operations introduced in prior works can be encompassed by the proposed approach. Because spherical convolutions introduce significant computational overhead, the authors also introduce an array of methods that reduce the computational cost while maintaining the model accuracy. Experiment results on multiple benchmark datasets show that the proposed approach outperforms the alternative approaches while having less number of parameters.",0.1079136690647482,0.189873417721519,0.13761467889908258
2133,SP:c17c3726ce894bd1c31874a79a06b196ea54e06d,"The paper proposes a discriminative training formulation for learning sentence representations, where a classifier is required to distinguish between real and fake sentences. The sentences are encoded with a Bi-LSTM and the resulting sentence representations are then used in a number of sentence-level tasks (classification, entailment, and retrieval). The experiments show benefits on most tasks compared to Skip-Thought and FastSent baselines, and the information captured by the representations is analyzed with probing tasks, showing that they are better at capturing certain kinds of information like the presence or order of words. ",Derive sentence representations from a bidirectional LSTM encoder trained to distinguish real sentences from fake ones. Fake sentences are derived from real ones by swapping two words or dropping a single word (yielding two different models). The resulting representations are applied to various sentence classification tasks by using them as input to a logistic regression classifier trained for the task. Results are generally better than similar experiments performed with SkipThought vectors trained on the same Toronto BookCorpus.,0.23404255319148937,0.2857142857142857,0.2573099415204678
2134,SP:c1c2fefa8ee3a807922ccc6072f5ef410795c0d2,"This paper proposes a generalized formulation of a probabilistic model for graph-structured data that incorporates graph networks (GN) (or rather, provides a probabilistic extension thereof). The authors show that the proposed framework is general enough to subsume existing approaches such as Neural Relational Inference (NRI) and Neural Processes (NP). The method is empirically validated on simulated and real-world data, with emphasis placed on the modelling of wind farm data.","This paper proposes a framework for a general probabilistic generative model for attributed graphs. The proposed model assumes that the nodes, edges, or global attributes of a graph have many different properties, which can be deterministic or stochastic, and observable or unobservable, and so on. The proposed model formulates a stochastic dependency between the conditioning graph variable G_h and the state graph variable G_s similar to beta-VAE, assuming the existence of several latent variables in addition.  The paper shows that the proposed model encompasses many existing Bayesian graph models and evaluate its performance using wind farm dataset and artificial simulation dataset with ELBO or test data log-likelihood.",0.29577464788732394,0.1891891891891892,0.23076923076923078
2135,SP:c1d77b1cc1c26d9d596eea8d19b4b3607eb218b9,"In this paper, the authors propose a new kernel named Path Kernel to understand deep neural network training. The key idea is to reparameterize the network with respect to the active path in the network. In this way, they can decompose the Tangent Kernel into data-dependent and architecture-dependent pieces. They authors rewrite the formulations of the existing pruning at initialization methods with respect to their Path Kernel and provide some new understandings. ","The paper studies the problem of neural network pruning at initialization through the lens of neural tangent kernels (NTK). As a result, the paper delivers a unified perspective on SNIP, GRASP, and SynFlow. Based on the framework, the paper provides a method to approximate the convergence dynamics of pruned models. The paper also motivates a SynFlow-variant from the theoretical framework.",0.14864864864864866,0.18032786885245902,0.16296296296296295
2136,SP:c212c6ec99a02f68a721f9673b6873ea2bc1b282,"Motivated by the many applications of min-max optimization problems in Machine Learning, the authors examine the effect of using different learning rates for each player in Gradient Descent Ascent (GDA) for non-convex non-concave optimization problems. Prior work has already established that making the learning rate of one player infinitely larger than other player's learning rate alleviates the cycling problems of GDA and makes game-theoretically meaningful equilibria the only asymptotically stable fixed points. The main contribution of this work is that it proves that we can get the same stability guarantees while keeping the learning rates of both players finite. This is crucial for practical applications where using unbounded learning rates in not an option. The authors employ this result to prove a variety of local convergence results in both deterministic ans stochastic settings.","The paper studies  the local asymptotic stability of a specific class of solutions points, referred to as strict local minmax equilibria (or differential Stackelberg equilibria), in the case of Gradient Descent-Ascent Dynamics with a finite time-scale separation. The time-scale separation (\tau) is being captured by the ratio of the step-sizes between the min and max agents respectively. Recently, Jin et al. showed the set of asymptotically stable critical points of gradient descent-ascent coincide with the set of differential Stackelberg equilibrium as the time separation goes to infinity. The paper shows that an infinitely large separation is not needed and some finite but large enough separation suffices.  The paper provides a close analogue of another previous result by Mescheder about local stability of gradient descent dynamics in GANs under strong technical assumptions. The paper ends with GAN experiments where \tau=1, 2, 4, 8 are tested and the performance seems to peak at 4. ",0.1956521739130435,0.17088607594936708,0.18243243243243243
2137,SP:c224948235ce93086c52e9cbb6fea4c5ef629f1d,"The authors propose extensions to LISTA with the goal of addressing underestimation (by introducing “gain gates”) and including momentum (by introducing “overshoot gates”). The authors provide theoretical analysis for each step of their LISTA augmentations, showing that it improves convergence rate. Their theoretical statements are empirically validated and then a numerical comparison is performed between the most interesting LISTA variants. Their proposed GLISTA performs favorably, especially for networks of depth greater than 10.","This paper proposed two novel gates to improve the convergence speed of the learned ISTA (LISTA) algorithm for sparse coding. The first gate is designed to address the problem that the output of the LISTA algorithm usually has a lower magnitude compared against the ground-truth. To address this, the paper proposed a gain gate to increase the magnitude of a layer in the LISTA algorithm. The second gate is designed to further improve the convergence with a technique similar to the momentum but with a time-varying coefficient. ",0.1506849315068493,0.12359550561797752,0.13580246913580246
2138,SP:c2354cd786dad3513c97dafbb39d03f5fdcc03b6,"To exploit the near neighbor/manifold features, this paper proposes to combine k-nearest neighbors of each training data point into the neural network models.  Specifically, the authors propose two families of models built on the popular sequence to sequence neural network models and memory network models, which mimic the k-nearest neighbors model in model learning. Besides, the final label of the classification task will be learned, a sequence of nearest neighbor labels and a sequence of out-of-sample feature vectors (for oversampling) will be also learned in the same time, similar with the multi-task approaches. Since the proposed models are based k-nearest neighbor calculations, which is time-consuming, they also design an algorithm for the ‘out-of-core’ situation, say load a small portion of data each time to approximately calculate the neighbors. Experiments show that some proposed models work better than baselines in classification and oversampling.","I had a hard time understanding this paper. The approach is clearly about combining kNN with neural networks, but it wasn’t clear how it is done. After reading the whole paper, my guess is that kNN is done on raw data first, and then its results are used for training a neural network. In particular, a network is trained to predict the labels of neighboring samples, which are obtained by kNN beforehand. A simple figure explaining it in the introduction would be very helpful since the idea is not that complex. ",0.11842105263157894,0.1956521739130435,0.14754098360655735
2139,SP:c23a091ab0ede0ec6e6f4fe4d9b3ddb02e04d109,When no task specific heads are available sample labels cannot be predicted and the dependency between two tasks and thus task transferability cannot me measured. The paper uses a Gaussian process to model the task space and comes up with a closed solution for the mutual information gain. Proposes a greedy selection algorithm for selecting checkpoints to maximize the information gain. Experiments with text and image datasets are performed to show that selecting checkpoint based on this criterion outperforms random selection.," The paper considers the question of how to select an ensemble of existing pretrained models to be used as feature extractors, when the task for which they are to be used is not known a priori. It seems to aim less to generalize to a given fixed target task distribution, but rather at generalizing over an expectation over target task distributions.  To achieve this, the authors propose essentially two steps:  Firstly, considering the feature representation of each model from the zoo, and computing a within-model similarity matrix between the features extracted for one fixed model over a set of samples. Then to use the cosine angle between similarity matrices of different models as a similarity between models.  Secondly, to select a fixed number of models (corresponding to a fixed budget) based on mutual information estimates between the set of models and the remaining models. This is intuitively appealing.",0.2345679012345679,0.12751677852348994,0.16521739130434784
2140,SP:c23df634e580ad4ecbdfb6980e836d912b96a64c,"The paper proposes a measure of datasets’ values using the volume of the feature matrix (defined to be the determinant of its left Gram), which captures the diversity in features. They show the effectiveness of this measure both theoretically and empirically. The paper proves that for regression problems,  a larger volume usually leads to a smaller bias and a lower mean squared error. They also verify this claim using randomly generated datasets. They also proposed a replication robust measure by compressing similar data. Finally, they use experiments on both real-world datasets and synthetic data to verify their claims and demonstrate that their measures without validation give results consistent with other methods which may require validation.","This paper intends to design a method to evaluate the value of a dataset. Such methods have been previously developed by calculating the Shapley value of the dataset based on its effect on model accuracy. The authors argued that since the model accuracy depends on a validation data set, selection of the validation dataset highly affects the Shapley value of each party's dataset, and hence will be a source of disagreement. To overcome this issue the authors set the value of a dataset based on the determinant (volume) of the left Gram matrix of its input features. The value of duplicated data is removed by constructing a compressed version of the dataset that preserves its diversity. The authors refer to this as robustness, since the values are robust to duplications. The authors provide some propositions connecting volume with bias and MSE. This has been validated experimentally as well.  ",0.1896551724137931,0.1476510067114094,0.1660377358490566
2141,SP:c26255b9b2de0df893e12a6cf5e61ffc46640418,"This paper proposes a novel approach to erase backdoor triggers from neural networks through distillation. The defense method, called neural attention distillation (NAD), first finetunes the backdoored model on a set of clean data to get a teacher model. The second part of NAD then finetunes another copy of the original backdoored model (student) on the same clean data while minimizing the difference between the activation maps of the student model and teacher model. The teacher model’s weights are frozen in this distillation phase. The authors show that NAD outperforms or matches previous backdoor defenses over a range of attacks on the CIFAR-10 and GTSRB datasets. Further experiments are also conducted to show NAD’s performance under different conditions such as the percentage of clean data and configuration of teacher-student models.","The paper proposes a simple yet effective approach for purifying a neural network poisoned with backdoor attacks, AKA backdoor erasing. In short, the authors propose a two-step process: 1) fine-tuning the poisoned model on a small portion of clean data, which is a commonly used defense, and 2) treating the poisoned model as the student and the fine-tuned model as the teacher and performing attention distillation. The authors show the proposed approach's effectiveness by comparing to three commonly used techniques leveraging six state-of-the-art backdoor attacks on two datasets, namely GTSRB and CIFAR10.  ",0.23134328358208955,0.31313131313131315,0.26609442060085836
2142,SP:c264d3f6941ec6718023d469f338c7100f9f6460,"The authors propose a multi-objective neural architecture search based on an evolutionary algorithm. The contradicting objective functions are optimized by ranking the candidates by Pareto-dominance, replace the bottom 50% with new candidates generated by the top 50% candidates through random mutations. The multi-objective function considers classification accuracy and an approximation of the inference speed. The method is compared to MobileNet and Mobile NASNet on ImageNet indicating an improvement with respect to search time.",The paper proposes a multi-objective search algorithm that designs resource-efficient convolutional architectures. The key idea is to maintain a population of networks and to iteratively approach the Pareto front through evolution. The normal & reduction cells are searched on CIFAR-10 and then transferred to ImageNet. The resulting architectures empirically lead to better trade-offs than other baselines.,0.19736842105263158,0.2542372881355932,0.2222222222222222
2143,SP:c28b8fa3bb2124845a81b3a8e30c6790b2c10df9,"This work proposes a curvature model VIVIT based on generalized Gauss-Newton (GGN) approximation for the training of neural networks with a convex loss function. The low-rank structure of VIVIT allows for efficient eigen-value decomposition, which also gives per-sample directional derivatives and curvatures. To further improve the efficiency, sampling within the mini-batch and among the coordinates of the prediction can be applied to trade off computational cost with accuracy. As an application example, VIVIT is used to provide noise-aware directional damping which improves the stability of second-order methods.","This paper highlights how the low-rank structure of the generalized Gauss-Newton (GGN) approximation of the Hessian can be used as a computationally efficient tool to study the loss landscape of deep neural networks. In particular, authors discuss methods to compute the full spectrum of the GGN and thus providing access to per-sample directional gradients and curvature approximation. Through the lens of the GGN spectrum, authors make observations on the geometry of the loss landscape and its evolution during training, and propose an adaptive damping technique for second-order optimizers that utilizes the GGN curvature information.",0.26595744680851063,0.25510204081632654,0.2604166666666667
2144,SP:c2dfaba3df490671f8ce20bf69df96d0887aa19d,"The authors propose a prediction model for directed acyclic graphs (DAGs) over a fixed set of vertices based on a neural network. The present work follows the previous work on undirected acyclic graphs, where the key constraint is (3), ensuring the acyclic property. The proposed method performed favorably on artificial/real data compared to previous baselines. ","This work addresses the problem of learning the structure of directed acyclic graphs in the presence of nonlinearities. The proposed approach is an extension of the NOTEARS algorithm which uses a neural network for each node in the graph during structure learning. This adaptation allows for non-linear relationships to be easily modeled. In addition to the proposed adaptation, the authors employ a number of heuristics from the causal discovery literature to improve the efficacy of the search. Empirical results are provided which compare the proposed algorithm to prior art. ",0.26785714285714285,0.16666666666666666,0.20547945205479448
2145,SP:c3236039988295311cdf505107bffa85b883e680,"The paper proposed a GNN model based on a weighted line graph, which adds weights to the line graph for the original input graph in a node/graph property prediction task. The line graph is a graph built on the original graph but with edges as nodes. A new convolution called weighted line graph convolution layer (WLGCL) is proposed to overcome the issue of ""biased topological information"" of the line graph. The weights for the line graph in WLGCL are computed based on the node degree of the original graph, which implies the node degree in the line graph is always 2. The WLGCL can be implemented for different kinds of graph convolution, which rule incorporates graph connectivity, node features and edge features.  ","This paper introduces a weighted line graph formulation (WLGCL) which corrects the over-counting (""bias"") of high-degree node features in a line-graph based convolutional network. Further, the paper uses Incidence Matrix to implement WLGCL updates which reduces the space complexity ($O(N^4) \to O(N^3)$) and time complexity ($O(N^4 C) \to O(N^4)$) compared to the naive implementation. The paper shows empirical evaluation on downstream task of graph classification and shows gain in accuracy. ",0.17073170731707318,0.25925925925925924,0.2058823529411765
2146,SP:c3276f7bbc7faa158569f67c2cd806e4154e0048,"The paper constructs a synthetic classification task with a known manifold structure by training the classifier with data from a variational autoencoder with a low-dimensional latent space. The paper argues that the components of image gradients that lie in the tangent space of the data manifold are semantically meaningful, whereas the part orthogonal to the image manifold is nonsensical. The experiments in the paper support this hypothesis to an extent. This is an interesting, although not unexpected, conclusion.","The paper argues that the main reason (or a good reason) for the ""meaningfulness"" of a gradient with data manifold. The authors perform a set of controlled experiments with different feature attribution methods. Finally, they theoretically show that alignment of the gradient with data manifold has nothing to do with generalizability. ",0.17721518987341772,0.27450980392156865,0.2153846153846154
2147,SP:c33d55dadd5fe4399b85968375ddffdeaf64ad61,"This is an interesting idea where the authors propose ""SurfaceFusion"", where they use the source embeddings learned by the encoder to modulate the output of the decoder at the final layer. The authors claim this is because the embeddings contain valuable information that is lost during encoder processing because the encoder lacks the capacity to represent both semantic and surface features. The authors then show through a series of experiments that attending over the encoder embeddings is useful, and propose a way to integrate the information from the embeddings directly into the last layer of the decoder, showing that this improves experimental results.","The authors perform a thorough analysis of encoder fusion for Transformers: which encoder layer should the N-th decoder layer attend to? It turns out that the final decoder layers often attend to the encoder embeddings, leading the authors to provide them to the last decoder layer which leads to small improvements of performance on machine translation, summarization and grammar correction tasks. These are nice results, but the gains are small and the models are tested in the very basic configurations. These tasks and techniques, as well as some numbers used to claim state-of-the-art, are from a few years ago (e.g., SOTA on en-de translation is higher currently than the authors claim and higher than their number). It would be interesting to see if the presented conclusions hold for larger models - esp. for a T5 Transformer on masked language modeling, as this would be a more commonly used model in 2020. Unluckily, it is quite possible that increased activation size may negate the benefits of the authors' technique. It may well though make it even more important -- it would be really good to know! Lacking these experiments, we cannot recommend acceptance at this point.",0.23300970873786409,0.12060301507537688,0.15894039735099338
2148,SP:c343c46cd2f33ae06be87cf9b44fbdbd59f335cd,**Overview**: The paper presents a simple regularizer term that aims to force a GAN to generate samples following a uniform distribution over different classes. The regularizer depends on a classifier that works well on an imbalanced or long-tailed dataset. The paper presents experiments on CIFAR-10 and LSUN that were synthetically long-tailed or imbalanced. The results show that the proposed term generates samples that follow a more uniform distribution over classes.,"The paper proposes a regularizer to force an unconditional GAN generator to produce samples that follow a uniform class distribution. To provide feedback to the generator about the class distribution over the generated images, the proposed method utilizes a pretrained classifier on the same (imbalanced) training dataset. Motivated by the exponential forgetting of earlier tasks in neural networks [1], the regularization term encourages the generator to increase the proportion of samples of an infrequent class after a certain number of iterations and vice versa. Empirical studies are performed to show the effectiveness of the regularization: 1) the paper shows that the proposed method enables generating samples with a uniform class distribution with a GAN trained on a dataset with a long-tailed class distribution and (2) that the method benefits in generating universal adversarial perturbations (UAPs) in the data-free scenario. ",0.3972602739726027,0.20567375886524822,0.27102803738317754
2149,SP:c36ebda129cbecfd9279410d276bb365cd5676eb,"This paper studies the inductive bias of gradient descent (GD) on smooth non-linear models when optimizing a weighted ERM. The authors provide several novel results for the linear and non-linear model cases. For linear models and linearly separable data, they show that GD converges to the hard-margin SVM solution and the convergence rate upper bound is lower for weighted ERMs that have higher weight on low margin points. They further characterize the inductive bias for non-linearly separable data, on a unique non-linearly separable subspace defined by Ji and Telgarsky (2018). For nonlinear models they consider a weak regularization setup. They show that asymptotically GD converges to a max margin predictor, which is similar to the non-weighted ERM case. They prove a generalization bound for weighted ERM and together with experiments provide insights on the generalization performance of GD in this case.","It is now well-understood that when the data are linearly separable,  gradient descent over the linear class of functions converges toward the hard margin solution. It highlights the implicit bias of gradient descent. Among all solutions interpolating the dataset, gradient descent selects the one with larger margin, partly explaining why over-parametrized models may generalize.  The picture for non-linear class is a little bit more complicated. ",0.11564625850340136,0.25,0.15813953488372093
2150,SP:c395c4430a7169941643a29482096a5d69b7ae50,"This submission proposes extensions of PDE-net that relax some constraints that could help extend the range of applications of this approach. First, rather than fixing a spatial discretization in the form of a grid, the authors use a Delaunay triangulation to represent the domain. The updates to the nodes of this triangulation are performed using a message-passing GNN framework which couples neighboring nodes. Secondly, the authors use a classical adjoint method to allow for arbitrary time-discretizations (though this may be much more expensive in practice).","The paper proposes to use graph-based networks for evaluations of PDEs with continuous time formulations. In contrast to existing works on continuous time ODE formulations with graph structures, the proposed networks incorporate relative spatial information in order for the network to evaluate spatial derivatives in addition to the temporal dynamics. A key argument for this setup is the flexibility in spcae (via the graph nets) in addition to a variable time step. ",0.14772727272727273,0.1780821917808219,0.16149068322981366
2151,SP:c3a4b596e4a86f0032646a166f9506f73a34d60d,"This work proposes an AutoML framework for multivariate irregularly sampled time series. To achieve this, the proposed framework integrates different modules: data-augmentation self-supervised loss (Equation 7), an anomaly detection loss (Equation 5), and a reconstruction loss. Besides, hyperparameters and model’s configuration is optimized by using AutoML (including Bayesian optimization). The model is evaluated on the well-known time-series datasets UCR and UAE. ","This paper proposes an autonomous representation learning framework for multivariate time series with irregular sampling rates. Specifically, there are three major components proposed in the framework. 1) An AutoML solution for hyperparameters optimization under Bayesian framework is proposed to automatically seek optimal network structures and parameters. 2) Variational autoencoders based on generative approach and attention mechanism is employed to learn the semantic representation of time series with limitation of irregular sampling. 3) A sample energy function derived from Gaussian mixture model attempts to depict the level of anomaly of sliced time series.",0.2878787878787879,0.20652173913043478,0.24050632911392408
2152,SP:c3a5a5600463b8f590e9a2b10f7984973410b043,"The paper proposes an imitation learning algorithm that combines support estimation with adversarial training. The key idea is simple: multiply the reward from Random Expert Distillation (RED) with the reward from Generative Adversarial Imitation Learning (GAIL). The new reward combines the best of both methods. Like the GAIL reward, the new reward encourages exploration and can be estimated from a small number of demonstrations. Like the RED reward, the new reward avoids survival bias and is more stable than the adversarial reward.","This paper proposes an approach for improving adversarial imitation learning, by combining it with support-estimation-based imitation learning. In particular, the paper explores a combination of GAIL (Ho and Ermon, 2016) and RED (Wang et. al., 2019), where the reward for the policy-gradient is a product of the rewards obtained from them separately. The motivation is that, while AIL methods are sample-efficient (in terms of expert data) and implicitly promote useful exploration, they could be unreliable outside the support of the expert policy. Therefore, augmenting them by constraining the imitator to the support of the expert policy (with a method such as RED) could result in an overall better imitation learning algorithm. ",0.2682926829268293,0.19130434782608696,0.22335025380710663
2153,SP:c3b9fafd3676ec970b5d2a7dbb9d92b1ffda5959,"This paper studies the fine-tuning problem from offline to online RL. While the naive approach to fine-tune offline policy suffers from a sudden distributional shift by online samples and too much behavior constraint in offline algorithms. The proposed method leverage (1) the adaptive coefficient tuning in TD3+BC loss, (2) randomized ensembles of Q-functions (proposed by Chen et al. 2021), and (3) down-sampling of offline data. The experiments seem to show better or competitive results to other approaches.","This paper proposes a new offline RL with online fine-tuning method. The authors first pretrain the policy using recent offline RL method TD3+BC with offline data and then collect on-policy data to further improve the pretrained policy. To prevent the policy from either degrading performance or failing to improve at the fine-tuning stage, the authors propose an automatic scheme to adjust the $\alpha$ term that controls the BC loss in TD3+BC to ensure that the policy does not continue to contain itself to the behavior policy if there's room for improvement and also is able to stick to the previous policy if the performance is already near optimal. The authors conduct evalutions in D4RL mujoco environments and show that the approach is able to outperform prior methods in halfcheetah.",0.23170731707317074,0.14074074074074075,0.17511520737327188
2154,SP:c3bdf7ffa026668d98d241b72ee14e2a3510a7d9,"The authors propose to balance multi-task training using IMTL-G on the shared backbone and IMTL-L on the task-specific branches. IMTL-G enforces equal gradient projections between tasks with a close-form formulation to calculate the desired gradient weightings $\alpha$. IMTL-L learns the loss weightings $e^s$ with a regularization term $-s$. Additional constraint by making all loss weightings sum to one is used. The paper compares the effectiveness of the proposed IMTLs with their counterparts on Cityscapes, NYUv2, and CelebA and claims state-of-the-art performance.","This paper presents a satisfying solution to the open problem of how to train all tasks at approximately the same rate in multi-task learning. There has been a bunch of work on this problem in the last few years. This paper characterizes existing work w.r.t. the fairness of training across tasks in order to motivate two new methods, one applied to shared parameters and the other to task-specific parameters, which overcome the shortcomings of previous methods. The two new methods can be naturally combined to yield a complete method for fair training. Experiments on common MTL benchmarks show the new method compares quite favorably to previous approaches.",0.17391304347826086,0.14414414414414414,0.15763546798029557
2155,SP:c3c6c4cdd054808bf7110053a06c528524555ae5,"This manuscript proposes a robust version of conditional GAN (named RoC-GAN) that leverage the intrinsic structure in the output space. To achieve robustness, the authors replace the single pathway in the generator with two different pathways that partially share weights. The authors study the theoretical properties of RoC-GAN and prove that it shares the same properties as the vanilla GAN. For quantitative evaluations, the authors use two datasets of natural scenes and faces and evaluate denoising and sparse inpainting using the SSIM metric.","In general, this is a well-written paper. This work focuses on the robustness of conditional GAN(RoC-GAN) when facing the noise. The authors claim the generator of RoC-Gan will span the target manifold, even in the presence of large amounts of noise. The main contribution of the paper is to introduce a two-pathway model, where one of them is used to perform regression as ordinary GAN while the other one helps the whole model span the target domain.",0.24705882352941178,0.25609756097560976,0.251497005988024
2156,SP:c3d608213089ac61f4887e18c5c1e58363c78a09,"This paper considers the notion of ""no-harm"" group fairness, i.e. trying to reduce the risk gap between minority and majority groups without excessive reduction in performance on the majority groups. Authors formalize the problem by defining a Pareto fair classifier, i.e. one that minimizes the risk gaps between groups and belongs to the family of Pareto classifiers containing the classifier minimizing the empirical risk. Authors suggest an optimization procedure for finding the Pareto fair classifier and demonstrate its performance on multiple datasets.","This paper introduces a new kind of algorithmic fairness framework where the focus is on first finding a fair classifier that does ""no harm"" and then in a subsequent step potentially allow doing harm in order to achieve even fairer outcomes. Fairness is here understood as risk disparity: how different are the risks achieved by our model in the various subgroups. The risk is task-dependent and can be something like a cross-entropy loss for classification problems. The goal is to have similar risks in the subgroups that correspond to sensitive attributes.",0.21176470588235294,0.1935483870967742,0.20224719101123598
2157,SP:c42bf54b98bda516112c7b604dd2a84002c4ecfa,The paper proposes a method for representing a computation of a neural network over a finite set of inputs by a projection onto a set of linear transformations (from the input space) called tropical rational map (TRM).  TRM is essentially a snapshot representing the internal representation of however deep network based on its response to a finite set of inputs.  Authors use this linearised approximation of the network internal to gather information about the complexity and generalisability of its function mapping.  ,"This paper studies the role of linear terms in the network performance using nontrivial tropical algebra inspired algorithms. In particular, the paper extracts linear terms associated with the linear regions of only the training points, and uses this to generate an extracted network function. The paper proposes an algorithm TropEx to systematically extract linear terms from piecewise linear network functions built using activation functions such as ReLUs. It is shown that this extracted network can be used for classification on the test data as well. In fully connected networks, such a modeling seems to work well on the test data. In the case of CNNs, the gap between the extracted network and original one is large. The paper argues that the number of linear regions may not be the right metric for expressiveness and generalization. ",0.18518518518518517,0.1111111111111111,0.13888888888888887
2158,SP:c44e42aed2bb38106bdc33fd5e7b3dfb4e9c5584,"This paper proposes a model-agnostic meta-attack and achieves promising adversarial attack performance compared with state-of-the-art adversarial attack algorithms. The proposed algorithm overcomes many issues, such as the vanishing gradient problem, training instability problem, generalization to other defense models. The detailed experiments support the proposed method.","This paper proposes an automatic approach for attacking classifiers, by approximating a possible adaptive attack that can take place on a newly-published defense. The methodology (MAMA) applies meta machine learning techniques, by training it on different defenses to let it grasp what might be a good signal to follow when attacking an unknown classifier. The authors then test this strategy and a naive version of it (that is, the one that is only trained on the attacks, and not fine tuned on a test set) against other attacks proposed in literature. Results suggest a modest improvement against defenses hardened with adversarial training.",0.22,0.10679611650485436,0.14379084967320263
2159,SP:c4549595bfdf81732bd6dbec7265f6bfed58d61b,"This paper studies the problem of active feature acquisition (AFA). The authors formulate AFA as a Markov decision process (MDF) and use reinforcement learning to resolve it. In order to overcome the sparse reward and complicated action space in this situation, the authors combine a generative surrogate model into their framework (GSMRL) to provide more feedback to the agent. Additionally, the authors adapt GSMRL into the supervised, unsupervised task (AIR) domain and introduce the corresponding dealing process in detail. Finally, the authors conduct lots of experiments to validate the superiority of GSMRL and the necessity of each component in GSMRL.","In this work, a reinforcement learning (RL) approach is proposed to solve the active feature acquisition (AFA) problem (as well as the active instance recognition problem). Comparing to existing RL approaches for AFA, the main difference of the proposed approach is to introduce a generative model (utilizing the existing ACFlow model) to learn the transition function, in order to provide additional rewards and auxiliary information. The proposed approach is evaluated on MNIST and UCI datasets, which can outperform two existing baselines.",0.19,0.2345679012345679,0.20994475138121546
2160,SP:c457a63633d74f3637f83a95fc2f29bdd01b6411,"The paper proposes Dreamer, a model-based RL method for high-dimensional inputs such as images. The main novelty in Dreamer is to learn a policy function from latent representation-and-transition models in an end-to-end manner. Specifically, Dreamer is an actor-critic method that learns an optimal policy by backpropagating re-parameterized gradients through a value function, a latent transition model, and a latent representation model. This is unlike existing methods which use model-free or planning methods on simulated trajectories to learn the optimal policy. Meanwhile, Dreamer learns the remaining components, namely a value function, a latent transition model, and a latent representation model, based on existing methods (the world models and PlaNet). Experiments on a large set of continuous control tasks show that Dreamer outperforms existing model-based and model-free methods. ","This paper introduced a latent space model for reinforcement learning in vision-based control tasks. It first learns a latent dynamics model, in which the transition model and the reward model can be learned on the latent state representations. Using the learned latent state representations, it used an actor-critic model to learn a reactive policy to optimize the agent's behaviors in long-horizon continuous control tasks. The method is applied to vision-based continuous control in 20 tasks in the Deepmind control suite. ",0.1678832116788321,0.27058823529411763,0.2072072072072072
2161,SP:c4662d0c24d1744837443315de5f92042cada40b,"The paper proposes a new method combining evolutionary methods and RL. In particular, the authors combine CEM and TD3 in PGPS. PGPS maintains a population of policies, which interact with the environment to collect data filling the replay buffer. The data in replay buffer is then used to train TD3. PGPS enables information flow in both directions: when the TD3 policy performs poorly, the elite policy from the population is used to guide TD3 by an imitation learning loss; The TD3 critic helps select top policies in the population and the TD3 actor is also included in the population. The experiments on simple Mujoco domains demonstrate the utility of PGPS and the ablation study analyzes the utility of each part of PGPS.","Recently, several researchers have been trying to combine the goodnesses of direct policy search approaches (mostly based on evolutionary computation approaches)  and those of policy gradient approaches in control tasks. This paper proposes a novel combination of an evolutionary direct policy search and an actor-critic approach. The authors combines a cross-entropy method, which directly samples parameters of actor network (policy) from a Gaussian distribution that is trained during the search process, and the twin delayed deep deterministic policy gradient (TD3), which is an off-policy actor-critic approach. ",0.14754098360655737,0.2,0.16981132075471697
2162,SP:c468214b11371b7f34a10070e1245573d856dd9e,"The paper addresses the problem of computational inefficiency in video surveillance understanding approaches. It suggests an approach called Dynamic Convolution consists of Frame differencing, Prediction, and Dyn-Convolution steps. The idea is to reuse some of the convolutional feature maps, and frame features particularly when there is a significant similarity among the frames. The paper evaluates the results on 4 public datasets. However, it just compares the approach to a baseline, which is indeed applying convnet on all frames. ","This paper proposes a technique to reduce the compute cost when applying recognition models in surveillance models. The core idea is to analytically compute the pixels that changed across frames and only apply the convolution operation to those pixels. The authors term this as dynamic convolution and evaluate this method on the SSD architecture across datasets like PETS, AVSS, VIRAT.",0.17721518987341772,0.23333333333333334,0.20143884892086333
2163,SP:c473e0c822290d2dad31acd42b52002d9c213fa2,"This paper describes a method for adapting lottery tickets (LT) found in one network architecture to a related architecture of different size. The motivation for this work is to study the connection between LTs of different architectures, and to reduce the cost of performing iterative magnitude pruning (IMP). If LTs can transfer between architectures, then it may be possible to find lottery ticket only once and adapting the size of the model as needed, without having to perform IMP for each model architecture. They restrict to adaptation to models of the same family (only differing in depth), and show that the adapted lottery tickets outperform pruning-at-initialization and RigL.  Networks are viewed at the level of ""units"", which are layers (+normalization), or residual blocks for ResNets. The adaptation method is to replicate nearby units of a smaller source model for each additional layer, or drop nearby units of a larger source model for each extra layer. They perform ablation studies on various choices for the replication/dropping of units.","This paper focused on exploring the transferability of a subnetwork obtained from the given dense network. Following the Lottery Ticket Hypothesis (LTH), a new hypothesis called Elastic Lottery Ticket Hypothesis (E-LTH) was proposed along with a corresponding validation method––Elastic Ticket Transformations (ETT). Extensive experiments on different benchmarks are provided to prove the effectiveness of ETT.",0.07058823529411765,0.21052631578947367,0.10572687224669604
2164,SP:c496aecb8ebf5e0d803342e8582f8a2515fe344d,"The paper proposes to solve two variants of adversarial poisoning attacks: 1) General Poisoning Attacks - where either the input is distorted or the label is flipped. 2) Label Flipping Poisoning Attacks - where the input images are intact but only the labels are flipped. The crux of the algorithm is the standard ensemble model idea, where we train multiple models each with a partition of the data and take the most prevalent prediction among all models during inference. This naturally adds robustness to the Additionally, the paper also provides theoretical lower bounds on the 'amount' of distortion below which precision is preserved.","This paper studies how to enhance the robustness of classifiers in face of data poisoning attacks. The key insight of the paper is that adding or deleting one training point can at most change one of the k partitions of the training set. Based on this idea, the authors propose Deep Partition Aggregation (DPA), a robust classification algorithm that first partitions the training data into k subsets, and then separately train a model on each subset. The final prediction is an aggregation of the predictions of those k classifiers using the majority vote. Apart from DPA, the authors also consider a setting where a large amount of data points do not have labels. In that scenario, semi-supervised learning algorithms are used as based algorithm when training separate models on each subset. The proposed method SS-DPA enjoys the property of being fast to train, since learning is performed on a subset that has smaller number of data points. The paper derives theoretical guarantees in terms of when the prediction of a particular data point can be certifiably correct. Finally, experiments on MNIST and CIFAR demonstrate the effectiveness of the proposed defense as compared to prior works.",0.26732673267326734,0.13705583756345177,0.18120805369127518
2165,SP:c49cea9b8b1ad72568948d3d184b2d95d4cc00e3,"This paper proposes an approach called conservative policy gradients to stabilize the training of deep policy gradient methods. At fixed intervals, the current policy and a separate target policy are evaluated with a number of rollouts. The target policy is then updated to match the current policy only if the current policy is better than the target policy. Experiments show that the proposed method, when applied to TD3, reduces the variance in performance through the training.","This paper proposes a simple method for stabilizing the off-policy deep reinforcement learning algorithm, which updates the target network only when the online network performs better than the target network in order to ensure the stability guarantees. More specifically, at every T time steps, they execute both the online network and the target network so as to evaluate the performance of each policy. Then, they update the target network only when the online network outperforms the target network with high probability. The experimental results show that the proposed Conservative-TD3 (C-TD3) is less prone to performance degradation during training.",0.32894736842105265,0.24752475247524752,0.2824858757062147
2166,SP:c4d8b135b7625ac0b52bdc4b9753c0db61b4d777,"This paper studies a theoretical aspect of IRM and how will it fail. Main contribution is pointing out that IRM is ineffective when the number of environments $E$ is smaller than the dimension of environmental feature $d_e$. A simple but universal model assumption is built, where environmental feature $z_e$ and causal feature $z_c$ is sampled from Gaussian conditional on label $y$. The analysis is two-fold: linear regime and non-linear regime. In the former part, given the feature extractor $\Phi$ is linear, a constructed solution to IRM is built to demonstrate the result. For the latter part, the other show the failure of IRM via several results in Thm 6.1 / D.3. The whole analysis is clear and easy to follow, thus the reviewer believe this submission deserves to be accepted. ","* The work gives extended theoretical analysis on the effect of invariant risk minimization scheme, which is an increasingly popular framework for robust prediction. The work considerably extends the results in the original IRM paper. The results seem reasonable, and clarify implausible beliefs on the framework. The intuitions and proving techniques could also inspire new methods to improve the current framework.",0.11029411764705882,0.25,0.15306122448979592
2167,SP:c4eef128786551f4e0ec9f43853df8b59a04f205,"This work proposes a probabilistic model which disentangles view, class and shape attributes explicitly (it does not rely on an emergent phenomena of disentangled factors in the latent space). In comparison to a similar approach, GVAE, CIGMO additionally disentangles the content factor into category and shape factors. Obtained results are reasonable and show advantage of the proposed method over related approaches.","This paper proposes a categorical invariant generative model (CIGMO) from a set of 2D images that tries to disentangle the factors of data category, intra-category geometry, and rendering viewpoint. CIGMO trains a VAE with a hierarchical graphical model that explicitly factors out the three components by design. Experiments on two datasets (ShapeNet rendered images, MultiPie face images) show that the proposed method can discover the concept of data category without using explicit supervision. It also supports feature manipulation over the geometry and viewpoint factors.",0.2459016393442623,0.17647058823529413,0.20547945205479454
2168,SP:c4f85e58f75ccd367c8907900be68c1ed4b05d4c,"This paper investigates using virtual nodes in graph neural networks for link prediction. Specifically, the authors use a graph clustering algorithm to determine groups of nodes in the graph and adopt multiple virtual nodes in the graph for the link prediction senario. They also theoretically investigate the effect of using virtual nodes for link prediction. Experiments conducted on six datasets  provide insights and guidelines about using virtual nodes for link prediction.    ","The authors revisited the commonly used trick of virtual nodes in graph learning. The authors proposed the multiple virtual nodes usage under the link prediction scenario and provided both theoretical and empirical supports for it. For theoretical analysis, the authors consider the influence score for m-regular graph and expressiveness of link representation (by concatenating representation of two nodes) in a special case and non-attributed graphs. For empirical analysis, the authors compare the performance of multiple virtual nodes setting to only one node setting with different GNN strategies and different datasets. They finally conclude that the virtual nodes can stably improve base GNN performance on some challenging link prediction tasks.",0.3380281690140845,0.21621621621621623,0.26373626373626374
2169,SP:c4fca42dd90955a07a8787b10669c84831e53720,"The paper presents an approach for optimizing molecular properties, based on the application of CycleGANs to variational autoencoders for molecules. A recently proposed domain-specific VAE called Junction Tree VAE (JT-VAE) is employed. The optimization of molecules is an important problem for example in drug discovery or materials design, and the development of machine learning approaches for it is therefore an important application.","This paper proposes to use CycleGAN to generate a molecule with a desired property given an initial molecule without that property.  This is a task appearing in drug design. Specifically, the training set consists of two sets of molecules with and without a desired property. For each molecule, a representation/embedding is obtained, which is the latent code of the JT-VAE. Two generators/transformers are introduced to perform transformation from the representation of one domain to that of another domain. The training involves a weighted sum of several losses: the LSGAN loss, the cyclic consistency loss and the reconstruction loss, which are exactly the same losses used in the CycleGAN paper.  Experiments are conducted on ZINC-250K dataset and evaluated in terms of structural modifications and molecule optimization.",0.203125,0.10077519379844961,0.13471502590673573
2170,SP:c531962563138a4254b397840c31aab244a2f0d7,"The authors propose an approach for speech enhancement based on optimizing the empirical OT loss between the joint distribution of noisy/clean training data and noisy/cleaned target data (c.f. (1), line 139). The cleaned speech outputs are additionally optimized under a standard WGAN formulation (c.f. line 129). Their approach consistently outperforms DAT[19] and MDAN[44] on VoiceBank-DEMAND and Helicopter-TIMIT mixtures, and performs roughly on-par or slightly worse on TIMIT-(Crowd-party, Cafeteria, Baby-cry) mixtures which contain speech, according to the standard PESQ and STOI metrics.","This paper proposes using a discriminator-constrained optimal transport method for unsupervised speech enhancement (SE). The method is specifically designed for a regression task. It involves 2 parts. The first parts estimates a generator function as an OT problem to align the source and target labels. The source-target alignments ($\gamma$) and the generator function parameters (${\theta}_f$) are estimated in an interleaving fashion. The second part incorporates a discriminative training component on the label distributions using WGAN. Two discriminative loss functions were used, one for the generator (${\cal L}_f$) and another for the discriminator (${\cal L}_h$). The discriminator losses are applied periodically at a pre-defined interval ($n_f$ and $n_h$).   The proposed method is referred to as the discriminative-constrained optimal transport network (DOTN). It does not require any additional knowledge about the noise types during training. This paper compares DOTN with two other adversarial domain adaptation methods, namely DAT and MDAN, using two datasets (VoiceBank and TIMIT). Different types of noise are artificially added to these datasets using the DEMAND dataset at different SNR levels to create different noise domains. The quality of the speech enhancement methods are evaluated using the PESQ and STOI metrics.  The overall results show that the proposed DOTN outperforms DAT and MDAN on both datasets. However, the model sizes and computational complexities of the models are not reported, making it difficult to compare different methods. Besides, there is lack of detailed discussions/analyses about the design of the training algorithm (see main review).    ",0.26881720430107525,0.0984251968503937,0.1440922190201729
2171,SP:c55a51a4154e8f02f8b43cfed0a4216ba197c3a0,"The authors seek to use a small RNN to generate extended, time-varying outputs given a cue indicating which output to generate. They focus on the problem of generating a sequence of outputs, cued in series, without the end state of one interfering with the subsequently cued trajectory. They show that small vanilla RNNs do not readily perform this task: RNNs at a random state can generate a sequence when cued, but they fail to do so when their state is at the end point of another sequence. The authors then show that by biasing the activity of the network towards the origin in the absence of an input (which they suggest is inspired by neuroscience), RNNs more readily learn sequences and more consistently generate accurate sequences in series. My enthusiasm for the work is relatively low for a variety of reasons. Primarily, the authors fail to test obvious alternative hypotheses of ways that the problem domain they design could be solved by a learned system, without the need to add the inductive bias they add. Moreover, and more fundamentally, the relevance of such a small toy system (300 units, trained to generate just 10 trajectories) for machine learning is unclear. ","This paper considers the problem of RNNs learning arbitrary sequences of “motifs” (continuous time functions, discretized) after having learned the individual motifs separately. Inspired by some previous work, it proposes an architectural approach to deal with interference by introducing a motif-dependent low-rank perturbation to the recurrent weights of the RNN, following Schuessler et al. (2020). To this end, the paper introduces a new evaluation task (motif generation), which is used to compare that architecture and sensible baselines. It then moves to propose a new model inspired in thalamocortical interactions in the brain: an RNN equipped with a preparatory module that imposes a beneficial bias when following a specific training protocol.",0.10945273631840796,0.19642857142857142,0.14057507987220444
2172,SP:c57202d97644413a7a1586156e0ea2d88950cc80,"This paper presents a self-training approach for improving sequence-to-sequence tasks. As a preliminary experiment, this study randomly sampled 100k sentences from WMT 2014 English-German dataset (WMT100K, hereafter), trained a baseline (Transformer) model on WMT100K, and applied self-training methods on the remaining English sentences as the unlabeled monolingual data. After exploring different procedures for self-training, this study uses the fine-tuning strategy: train a model on the supervision data; build pseudo parallel data by predicting translations for all unlabeled data using the trained model; train a new model on the pseudo parallel data; and fine-tune the new model on the supervision data. This strategy alone gave a 3 points improvement of BLEU.",The paper introduces an interesting study that tries to explain why conditional text generation models with autoregressive decoders benefit from self-training on pseudo labels created from the same model. The paper introduces and verifies two hypotheses: 1) Decoding strategy: Since beam search is a biased estimator sampling using it doesn't reflect the learned distribution from the model and hence variations happen that benefit learning. (this partially help).,0.1271186440677966,0.21739130434782608,0.16042780748663102
2173,SP:c5727500bc787fd26fe060b0a06892ee4430175e,"This paper uses singularity analysis developed in the context of analytic combinatorics to study the relationship between the reproducing kernel Hilbert spaces of the NTK in a deep fully connected ReLU network, the Laplace kernel, and exponential power kernels. The main results are when these kernels are restricted to the unit sphere. In particular, the authors show that, as vector spaces, the RKHS on the unit sphere of the NTK for a ReLU network of any fixed depth are the same and in fact coincides with that of the Laplace kernel. The authors also compare the RKHS for exponential power kernels, demonstrating that larger powers lead to smaller Hilbert spaces. ","This paper proves that the reproducing kernel Hilbert spaces of a deep neural tangent kernel and the Laplace kernel have the same set of functions when they restricted to the sphere $S^{d-1}$, which improves the results established in Geifman et al., 2020. Moreover, the paper proves that more non-smooth of the exponential power kernel leads to a larger RKHS with restriction on the sphere $S^{d-1}$ and the entire $R^d$. Furthermore, the authors conduct numerical experiments to verify the asymptotics of the Maclaurin coefficients of the Laplace kernel and NTKs kernel. In summary, the paper is well-written and organized logically. The proof of theoretical results of this paper seems to be correct and reasonable, resulting from the full details of the proof provided in the appendices. ",0.33636363636363636,0.2803030303030303,0.30578512396694213
2174,SP:c578bd6652d1dcd0e280d587ffc973dddf3146c6,"This paper applies the Go-Explore algorithm to the domain of text-based games and shows significant performance gains on Textworld's Coin Collector and Cooking sets of games. Additionally, the authors evaluate 3 different paradigms for training agents on (1) single games, (2) jointly on multiple games, and (3) training on a train set of games and testing on a held-out set of games. Results show that Go-Explore's policies outperform prior methods including DRRN and LSTM-DQN. In addition to better asymptotic performance Go-Explore is also more efficient in terms of the number of environment interactions needed to reach a good policy.","This paper considers the task of training an agent to play text-based computer games. One of the key challenges is the high-dimensional action space in these games, which poses a problem for many current methods. The authors propose to learn an LSTM-based decoder to output the action $a_t$ by greedily prediction one word at a time. They achieve this by training a sequence to sequence model on trajectories collected by running the game using a previously proposed exploration method (Go-Explore). While the results are promising, there might be limited novelty beyond training a sequence to sequence model on pre-collected trajectories. Further, the experiments are missing key elements in terms of proper comparison to baselines. ",0.205607476635514,0.18333333333333332,0.19383259911894274
2175,SP:c57d966aea7e3a714f81845afed92f4ffa730626,"In this article, the authors characterized the second-order fluctuation of the prediction risk of the (min-norm) least square estimator, by assuming an underlying noisy teacher model $y_i = \beta^T x_i + \epsilon_i$, in the regime where the data dimension $p$ and the number of training samples $n$ grow large at the same pace. Results in both the under-parameterized (Theorem 4.1 and 4.2) and over-parameterized regimes (Theorem 4.3-4.5) were provided, under the statistical model where the data $x_i$ are zero-mean random vectors with **generic** i.i.d. entries and then ""rotated"" to have some possible covariance structures. Numerical experiments for relatively small values of $n,p$ were conducted to support the theoretical assessment.","This paper investigates the phenomenon of double descent, also referred to as ""more data hurts"", in high dimensional linear regression using the least square estimator.  In the same setup, previous sharp results were already established in the asymptotic regime. Non-asymptotic results are also known but are less precise. The authors of this paper try to provide a new type of results that fill the gap between the two regimes (asymptotic vs non-asymptotic). To do so they have managed to derive second order (CLT type) asymptotic results for different risks based on more refined random matrix theory results.",0.144,0.18181818181818182,0.16071428571428573
2176,SP:c5b4b64dfec46e1119de74375b5fe26a277b52fe,"The authors propose an extension of cycle-consistent adversarial adaptation methods in order to tackle domain adaptation in settings where a limited amount of supervised target data is available (though they also validate their model in the standard unsupervised setting as well). The method appears to be a natural generalization/extension of CycleGAN/CyCADA. It uses the ideas of the semantic consistency loss and training on adapted data from CyCADA, but ""fills out"" the model by applying these techniques in both directions (whereas CyCADA only applied them in the source-to-target direction).","This paper introduces a domain adaptation approach based on the idea of Cyclic GAN. Two different algorithms are proposed. The first one incorporates a semantic consistency loss based on domain-specific classifiers acting on full cycles of the of the generators. The second one also makes use of domain-specific classifiers, but acting either directly on the training samples or on the data mapped from one domain to the other.",0.15053763440860216,0.2,0.17177914110429446
2177,SP:c5bc1d50c01d86f3f5ccb52508cc4112a1937bd4,The paper proposes a question answering model that is augmented with a common-sense knowledge graph (KG). The paper builds on the following two observations — (a) KGs are incomplete often lacking facts that would be needed for reasoning to answer a question. (b) Current methods over-retrieves facts (edges) from the KG leading to a lot of unrelated facts that potentially makes reasoning noisier and harder.,"In this paper, the authors propose a new approach towards incorporating knowledge graphs (KG) into commonsense QA frameworks. KGs are helpful for adding structured ""world"" information, which neural-symbolic architectures can leverage to do commonsense reasoning, e.g., ""what is the expensive resource in printing on paper?"" (paper). In such architectures, however, the authors argue that KG quality is a large impediment (e.g., missing or incorrect edges, distracting nodes, etc). Therefore, they propose a ""hybrid"" KG-based model (accordingly named ""Hybrid Graph Network"") that jointly learns to refine/augment the graph structure while also optimizing it for inference performance.",0.18181818181818182,0.12,0.14457831325301204
2178,SP:c5d1720922dfde389abbce3110a7f049e972192a,"This work proposed a stepsize for the extragradient/mirror-prox method that works both in smooth and non-smooth settings. The stepsize is based on the empirical values of gradient/operator differences, and mirror maps are used to allow for non-euclidian geometry such as KL divergence. The paper offers us three convergence results: 1 bound for the extragradient update (no mirror map) and 2 bounds for the mirror-prox update (convergence of iterates without a rate and convergence of the restricted gap with rates). The theory is followed by simple randomly-generated problems, which is ok for justifying the theory but can't serve a significant contribution on its own. ","This paper propose a novel algorithm that solves the min-max problems and games based on the extra gradient (EG) framework. One of the main goal of this paper is to achieve the optimal convergence rate for both smooth/nonsmooth setttings without assuming the Lipchitz continuity/boundedness conditions. A ""Bregman-Proximal"" step was introduced to take place of the traditional Euclidean norm projection norm to depict the geometry or the smoothness properties of the problem. Furthermore, the authors adopt an adaptive step size scheme into the ""Mirror-Prox"" step to achieve the optimal convergence rate under both settings. ",0.16216216216216217,0.1836734693877551,0.1722488038277512
2179,SP:c5f7b60e4be5b38d3b29fc4e0395aca077e23eae,This paper proposed a new method for black-box adversarial attacks which tries to learn a  low-dimensional embedding using a pretrained model and then performs efficient search within the embedding space to attack the target network. The proposed method can produce perturbation with semantic patterns are easily transferable. It can be used to improve the query efficiency in black-box attacks. ,"Review: The paper proposes a new framework (TREMBA) for black-box adversarial attack. The method utilizes a pretrained source network to learn a low dimensional embedding, it then searches efficiently within the embedding space (using NES) and produces an adversarial perturbation that can attack an unknown target network. A generator model first encodes an input to a latent vector and then decodes it to give an adversarial perturbation as an output. This generator is trained so that it can fool the source network and is then used to find the adversarial pattern when searching in the latent space. TREMBA produces perturbations with high level semantic patterns, and is easily transferable to different target architectures. The paper demonstrates its performance in terms of number of queries vs success rate on different datasets, Google cloud vision API and adversarially defended networks.",0.4838709677419355,0.2158273381294964,0.29850746268656714
2180,SP:c5fa77eef56d8878f58c99c5c50902a3f739e2fb,"The paper builds upon the recent advances in transformer based image classification methods (ViT variants) and detection methods (DETR variants). It argues that naively replacing the conv feature backbone in DETR with a ViT based one, is problematic due to (i) the quadratic complexity of the self attention module in ViT, and (ii) then again the attention module in the transformer encoder decoder part (which they call ""neck""). To remedy, it proposes to build on top of Swin Transformer backbone, by proposing a novel reconfigured attention module (RAM), and further removing the encoder-decoder in the neck, replacing it with only a lightweight decoder.","This paper proposes ViDT, a high-performance Detection Transformer with an impressive accuracy-speed trade-off. A lot of experiments as well as ablation studies are conducted to prove the effectiveness of the proposed detector. The design principle of ViDT can also generalize and inspire future detector design. Moreover, this paper also includes an in-depth analysis of several current Detection Transformer architectures. ",0.11538461538461539,0.19047619047619047,0.1437125748502994
2181,SP:c610bfdc080b0c939039a6083d71d5f03d3a3f32,"The authors propose an approach to reduce the sensitivity of neural networks to visual distortions. To do so, they modify the representation of a data point within a network, using its relative position (to other points) in representation space rather than its absolute position  (which is measured as distance of a point to the decision boundary of each class). They then evaluate their approach on common corruptions from the CIFAR-C dataset.","This paper presents a method to represent input points by their relative positions to decisions boundaries using an adversarial attack instead of the more usual output of a deep model (before the last linear classification layer). The motivation of the method is to obtain representations that are more robust to input distortions such as blur, noise, over-exposure, etc. More specifically, the representation obtained by a deep model before the last linear classification layer (f_L) is replaced by a concatenation of the perturbation needed for that representation to be misclassified by f_L. Using this new representation, they are able to obtain more robust classifiers against input perturbations. ",0.16666666666666666,0.11009174311926606,0.13259668508287295
2182,SP:c61e55589c5e98e1ee016f7f96c7b3c2c7b972ea,"In the setting of online learning, this paper investigates difference-of-squares models with the aim of devising conceptually simple and efficient passive-aggressive algorithms. Starting from the background on online passive-aggressive linear classification, the authors present the difference-of-squares model, by highlighting its symmetries. For this model, the update step and the averaging step are justified in detail. Experimental results on the InfiMinst dataset corroborate the interest of this quadratic passive-aggressive approach, especially in comparison with the standard, linear approach. ","The authors proposed a low rank model for quadratic classification formulated as a neural network, which they called Difference-of-Squares (DoS). Albeit not a universal approximator, such as neural networks, the proposed model can compete with any fully quadratic classifier. The ablation study involved using the INFIMNIST dataset and the DoS model was compared against a linear classifier. There has also been a bizarre outcome presented, i.e. linear model outperforming the DoS with dimensionality=1. Many thanks to the authors for mentioning this and being honest that they do not know why this is happening.",0.17857142857142858,0.15463917525773196,0.16574585635359115
2183,SP:c64ba67ebf7b6abedb24f26cbd45e221cfd6b1d6,"The paper studies how to solve a class of group sparsity regularized minimization problems. In particular, a half-space stochastic projected gradient (HSPG) method is proposed, which is based on the Prox-SG and a new half-space step that promotes group sparsity. This step is to decompose the feasible space and then perform group projection. Convergence analysis is provided, together with the theoretical discussion that HSPG has looser requirements to identify the sparsity patter than Prox-SG. Numerical experiments on the DCNNs based image classification shows the proposed method achieves the state-of-the-art performance in terms of accuracy. The work looks interesting with wide applications, especially in deep neural networks. However, the novelty is incremental and limited. ","This paper proposed a new algorithm for the group sparsity regularization problem. They claim most existing algorithms, though return solutions with low objective function value, only give dense solutions and cannot effectively ensure the desired structured sparsity. The new technique requires an initialization that is closed to some truly sparse local minimum, which is achieved by running proximal gradient descent first. Then, they proposed a new half-space iterative step to force elements in specific groups exactly to zero. The authors also provide convergence analysis and numerical evidence for the newly proposed algorithm.",0.15833333333333333,0.20430107526881722,0.17840375586854457
2184,SP:c64e935f86a415a464632de66ffe1d610df585e4,"The paper addresses adversarial attacks against visual perception pipelines in autonomous driving. Both subprocesses in the visual perception pipeline, object detection and multiple object tracking (MOT), are considered. The paper proposes a novel approach in adversarial attacks, the tracking hijacking, which can fool the MOT process using Adversarial Examples (AEs) in object detection. The key idea is to exploit the tracking error to place specific attacks on single frames in MOT, which can lead to a displacement of the detected objects. It is shown that the proposed method can effectively attack the perception pipeline by just fooling 2 to 3 consecutive frames on average.","This paper is about conducting evasion attacks against Multiple Object Tracking (MOT) techniques. Compared to existing work on adversarial examples against object detection, to attack MOT techniques, the adversary needs to successfully fool multiple frames, and the authors show that by naively using existing attack approaches, the adversary needs to achieve 98% single-frame attack success rate to fool the tracking system, which is too hard for existing attack algorithms.  Therefore, this paper proposes a smart way of attacking MOT techniques by leveraging the properties of the tracking algorithm. In particular, they generate adversarial perturbations to remove the original bounding box while adding a fake bounding box that has some overlap with the original bounding box, so that the system will compute the movement of the object in a wrong way. They evaluate on videos in Berkeley Deep Drive dataset, and show that by attacking 2~3 frames, they can achieve nearly 100% attack success rate, while the attack success rate is only 25% if the tracking algorithm is not considered when crafting the attacks.",0.25961538461538464,0.15428571428571428,0.1935483870967742
2185,SP:c6613fdb5a29233f4fb6b2eb86542ae07fc1d366,"This paper aims to tackle few-shot classification with many different domains. The idea is to build a pool of embedding models, which are based on the same base network. The models are diversed by their own modulators. The high-level intuition is to let the model pool capture good domain-invariant features by the shared parameters and domain-specific features by the selection network, which is desirable to represent the complex cross-domain task distribution, without a significant increase in the number of parameters. ","In this paper, the authors proposed to address the few-shot learning problem, especially for the cross-domain setting where a newly coming task originates from a different distribution (or in this work implemented by sampling from an unseen dataset). Basically, the authors constructed a model zoo based on source datasets at hand, and learned an “argmax” meta-selector which takes embedding of a task as input and outputs the model selection index. The idea is very intuitive, and the implementation is kind of an incremental combination of (Rebuffi et al., 2018) building models for multi-tasks and (Oreshkin et al., 2018) tailoring based on task embeddings.",0.2,0.1588785046728972,0.17708333333333334
2186,SP:c686503ec773532c596fdf2b90a6bcc4db9044d3," The work presented in this paper aims to analyze the relationships between the probability distribution of the data, perceptual distances, and unsupervised machine learning. Perceptual sensitivity is correlated with the probability of an image  in its close neighborhood. The paper also explores the relation between distances induced by autoencoders and the probability distribution of the training data, as well as how these induced distances are correlated with human perception. At the end, the paper specifies that perceptual distances do not always lead to noticeable gains in performance over Euclidean distance in common image processing tasks.","This paper presents a mainly theoretical explication of the relationship between natural image statistics and perceptual distances for small image distortions. The paper presents a number of observations linking distances in natural images, autoencoders, and perceptual similarity for humans. The paper finally explores some implications of these observations, including impressive-seeming results on training with no data using perceptual distances as regularizers. ",0.18947368421052632,0.2903225806451613,0.22929936305732487
2187,SP:c6f58fd967bd81a9b46c030dc5b2d1d16670e057,"The authors propose using a recent method for adversarial inverse reinforcement learning (AIRL) for the task for generating high-quality image captions. Leveraging the GAN framework, a discriminator is trained to distinguish real captions from those produced by the generator, while the generator is optimized with policy-gradients (REINFORCE) to maximize the pseudo-reward from the discriminator. The main difference from prior work seems to be that the discriminator acts on a word-level, rather than sentence-level (as done, for instance in Dai et. al. 2017). Correspondingly, the generator policy is updated with the objective of 1-step reward maximization (more like contextual bandits), rather than with a long-term sequential decision-making objective (as done in Dai et. al. 2017). The evaluation is done using 2 data splits – standard and robust, with various metrics such as SPICE, CIDEr, BLEU, CHAIR. Diversity analysis and ablations are also performed to dissect the performance of the proposed approach. ","This paper proposes a refined Adversarial Inverse Reinforcement Learning (rAIRL) to remedy the reward ambiguity by decoupling the reward for each word in a sentence, while the existing methods that utilize reinforcement learning to optimize evaluation score handle only sentence-level rewards. Furthermore, a conditional term is introduced in the loss function to avoid mode collapse and to increase the diversity of the generated captions. Throughout experiments on MS COCO show that the proposed method achieves state-of-the-art performance with several evaluation scores.",0.1464968152866242,0.27058823529411763,0.19008264462809918
2188,SP:c70cde6949c99a2fb3547bac830f12495176e271,"This paper studies efficient methods for finding near-stationary points ($||\nabla f(x)|| \le \epsilon$) of a convex (finite-sum) function. The authors nicely introduce main reasons for the need of such research, and their three main contributions are as follows.  First, this paper provides variants of OGM-G that is an optimal method for finding a near-stationary point for a smooth convex function under the initial bounded-function condition (IFC). In specific, Proposition 3.1 complements the complexity of OGM-G (with and without a change of coefficient at the last iteration). In addition, a memory-saving variant of OGM-G was studied, which does not require computing coefficients in advance.   Second, based on OGM and the loopless SVRG, the authors propose Acc-SVRG-G. With the two-stage parameter choice under the initial bounded-distance condition (IDC), it has fast rates for minimizing both the gradient norm and the function value for the first time.   Third, with adaptive regularization, the Acc-SVRG-G achieves the best existing rates (by the regularized Katyusha) up to a logarithmic factor, in terms of minimizing the gradient norm, under both IDC and IFC. The proposed R-Acc-SVRG-G has advantage over the regularized Katyusha, since it does not require the knowledge of $R_0$ and $\Delta_0$. ","This paper proposes several optimization algorithms: 1. a memory-saving variant of OGM-G (by the way, could the authors provide the full name of OGM-G?); 2, a new accelerated SVRG (full name?); 3, Near-Optimal Accelerated SVRG with Adaptive Regularization. Analysis of convergence rate is provided.",0.08294930875576037,0.375,0.13584905660377358
2189,SP:c71c1b8b8e1a7fe2225d8e232288de3c08f0356c,"This paper presents a method to provide some level of interpretation on the influence of input features on the response of a machine level model all the way down to the instance level. The proposed method is model agnostic. Quoting the authors, they advocate for methods that look at interpretability “as understanding the population distribution through the lens of the model” without restriction on the models fit. The problem is posed as a hypothesis testing problem. The paper proposes “proper test statistics” for model agnostic feature selection. It is argued that f-divergence tests are proper statistic tests, with the KL being particularly interesting as it provides computational advantages. ","This paper addresses supervised feature selection: given a D-dimensional input variable x = (x_1, ..., x_D), and a response variable y, the goal is to find a subset of ""useful"" features in x. Here, a feature x_j is useful if it is dependent on y even when conditioning on all other input variables (denoted by x_{-j}, which is a set). A generic procedure that can produce a p-value for each feature (allowing on to test each feature whether it is useful) is the conditional randomization test (CRT) proposed in Candes et al., 2018.  For the CRT to produce a valid p-value for each feature (input dimension) x_j, one needs to specify a test statistic that measures conditional dependence between x_j and y given the rest of the features.",0.1651376146788991,0.13333333333333333,0.1475409836065574
2190,SP:c73fc3212d75833f5f54e4d76326b759fa9442c4,"This work introduce rigorous information-theoretic measures for structured prediction tasks. It proposed metrics for both `""total uncertainty"" (entropy) and ""knowledge uncertainty"" (MI, EPKL and RMI) on the sequence level, introduced efficient Monte-Carlo approaches to estimate them in practice. Finally, author conducted thorough experiment to evaluate the effect of ensemble strategy and choice of metric for error detection and OOD detection in ASR and NMT.",This paper proposes two different measures of knowledge (epistemic) uncertainty in structured prediction with an autoregressive model and discusses how to compute their approximations. The main contribution is the proposed reverse mutual information (RMI) as a measure of epistemic uncertainty in structured prediction. Experiments on benchmark datasets demonstrate the effectiveness of the proposed method in error detection and OOD detection.,0.21212121212121213,0.23333333333333334,0.22222222222222224
2191,SP:c760569687ca96532cd81273870cb61082b447ff,"In this paper, the authors propose a new policy gradient algorithm called TSIVR-PG for the policy optimization for a general utility function. They adopt a gradient truncation mechanism in TSIVR-PG to get rid of the uncheckable importance weights assumption which is frequently used in previous literatures. They establish convergence rate to stationary points, and global convergence results with additional assumptions. Moreover, they conduct experiments and compare with other previous methods.","There is a lot of interest in studying policy gradient type of algorithms for solving the RL problem recently.  This paper develops a variance reduced policy gradient method, where the objective function can be some general utility function instead of just being the cumulative reward. A sample complexity of $\mathcal{O}(\epsilon^{-3})$ was established under some mild conditions, and it was further improved to $\mathcal{O}(\epsilon^{-2})$ under a convexity assumption and a so-called over-parametrization assumption. ",0.19444444444444445,0.175,0.18421052631578944
2192,SP:c78209f866eb37bb3786570a64486915386b8488,"ML models are trained on a predefined dataset formed by a set of classes. Those classes use to be the same ones for training and testing. However, what happen when during testing time images with classes unseen during training are shown to the model? This article focus in this problem which is not currently taking much attention by the mainstream research community and is of great importance for the real world applications.","This paper addresses the problem of out-of-distribution detection for helping the segmentation process. Therefore, the detection is performed on a pixel basis. The application of the approach is to datasets used for autonomous driving, where semantic segmentation of the view of the road is a typical application. Since in a road view there will be pixels that are projections of objects that are likely not in the set of classes known by the semantic segmentation algorithm, it makes sense to flag them as being out of distribution (OOD), or not known, or to assign to them a low confidence level. The proposed approach is trivial: train a binary classifier that distinguishes image patches from a known set of classes from image patches coming from an unknown (background class). The classifier output applied at every pixel will give the confidence value. While there are different dataset options to represent the known classes, the background class is represented by images from ILSVRC. The results show that for the segmentation application the approach works better than using an adaptation of more elaborate out-of-distribution methods.",0.2361111111111111,0.0918918918918919,0.13229571984435798
2193,SP:c7be5b2c2dbf1bd54ace77553ebab21b9a219ef5,"This paper revisits ObjectNet dataset closely and found applying classifiers on object bounding box significantly reduces the gap between ImageNet and ObjectNet. The authors further investigates the robustness of CNNs against image perturbations and adversarial attacks, and found limiting the object area to their segmentation mask significantly improves model accuracy (and robustness). Qualitative evaluation is also performed over confident and less-confident / incorrect model predictions and find it correlates with human perception.","The authors present a follow-up to the prior work of Barbu et al on the task of Object Recognition* (name confusion addressed in cons below). Barbu et al demonstrated that on a more realistic dataset like ObjectNet, models trained on a clean dataset like ImageNet suffer significant degradation. This work reduces the performance gap by cropping out the object using bounding box or mask information and running the recognition model on top of it. They do this for a variety of models (AlexNet, VGG-19, ResNet-152, Inception-v4, NASNet-A, PNASNet-5L) and transformations (image distortions, adversarial perturbations, context, geometric transformations). ",0.1527777777777778,0.10679611650485436,0.12571428571428572
2194,SP:c7c30d05c86b1bb69f9098afe8bc2514e8eb22c0,"The authors propose a hardware-agnostic metric called effective signal norm (ESN) to measure the computational cost of convolutional neural networks. This metric aims to fairly measure the effects of pruning and quantization. What’s more, based on the metric, the authors demonstrate that models with fewer parameters achieve far better accuracy after quantization. A large number of experiments are carried out to prove the effects of the metric and related conclusions, however, several experiments and arguments are confusing. ","The paper proposes a new metric to evaluate both the amount of pruning and quantization. This metric is agnostic to the hardware architecture and is simply obtained by computing the Frobenius norm of some point-wise transformation of the quantized weights. They first show empirically that this Evaluation metric is correlated with the validation accuracy. Then use this metric to provide some general rules for pruning/quantizing to preserve the highest validation accuracy. Finally, they derive a strategy to perform pruning by monitory the signal to noise ratio during training and show experimentally that such method performs better than competing ones.",0.25316455696202533,0.19801980198019803,0.22222222222222224
2195,SP:c7c4415e10a9426b0cffb18491d42922700dce85,"In this paper, the authors proposed a new method to model the source code for the bug repairing task. Traditional methods use either a global sequence based model or a local graph based model. The authors proposed a new sandwich model like [RNN GNN RNN]. The experiments show that such simple combination of models significantly improve the localization and repair accuracy. ","The paper proposes improvements on existing probabilistic models for code that predicts and repairs variable misuses. This is a variant of the task, proposed by Vasic et al. The task takes a dataset of python functions, introduces errors in these functions and makes a classifier that would identify what errors were introduced and effectively reconstruct the original code.",0.14754098360655737,0.15517241379310345,0.15126050420168066
2196,SP:c7e7a9e3047b95af8862d79681b3c47ada2642b2,"This article is concerned with the problem of training models under noisy data. The authors first adopt the loss and output consistency for data selection. EMA method is used for smoothing to obtain more accurate clean label detection. Meanwhile, through the introduction of temperature hyperparameters, the model gradually completes the transition from supervised learning using clean labels to self-supervised learning using noisy labels. ","This paper proposes a curriculum learning method to handle noisily labeled data. The idea is to introduce a consistency measure instead of directly apply a loss function for the typical supervised learning, where the specific consistency is measure for both temporal dimension along neighboring steps and spatial dimension over different data augmentation samples for a given real sample. The consistency measure is applied for self-supervision while the loss function is applied for supervised learning. The final optimization is managed between the two components through weighting parameters, such that the training is made through a migration from a supervised learning to self-supervision by gradually adapting the weighting parameters. Evaluations are reported on Cifar10/100, WebVision, and ILSVRC2012.",0.28125,0.15254237288135594,0.1978021978021978
2197,SP:c7f896d15bb66637e8ad0b80f7baa713d9da6c30,"The authors address methods to encourage the emergence of the layout expression structures on the frameworks of neural module networks (NMN) for the visual QA problems. The methods are motivated from the works on language emergence for communication between multi-agents and the language acquisition of new-born babies from parents, which achieved with limited data. The methods, ‘iterative learning’ (IL) are designed as forming two agents (program generators and execution engines) to play VQA games. Basic architectures and learning methods seem to be very similar to the approach of semi-supervised learning introduced in [ICCV17]. ","The authors apply iterated learning - a procedure originating in CogSci analyses of how human languages might develop - to the training of neural module networks. The goal is for iterated learning to encourage these networks to develop compositional structures that support systematic generalization without requiring explicit pressures for compositional structures (in past work, such explicit pressures have generally been necessary). The proposed approach brings substantial improvements in systematic generalization across two datasets, SHAPES and CLEVR.",0.16666666666666666,0.21621621621621623,0.18823529411764706
2198,SP:c824a0fe491742bf809b2d3a90e47810f0ef6a5e,"This paper introduces Neural Jump Ordinary Differential Equations as a method for learning models of continuous-time stochastic processes sampled at random time epochs. Specifically, the paper studies the problem of estimating the marginal conditional expectation (i.e., the L2 optimal approximation conditional on the available information) by estimating an auxiliary stochastic differential equation, parameterized by  neural networks, that approximates the conditional expectation of the process of interest at each point in time. The neural networks are trained by using a “randomized” mean squared-loss objective. The main theoretical results in the paper include asymptotic consistency of the optimal objective value in the limit of a large neural network, as well as consistency of a Monte Carlo sample average estimator of the value. The paper also establishes the L2 convergence of the estimated auxiliary solution to the marginal conditional expectation.","The authors propose a method for learning the conditional expectation of stochastic process in an online fashion. The paper bears a considerable theoretical treatment, derived from the stochastic filtering literature, which is present both in the main body of the paper and the appendix. Besides the model, the paper also aims to provide a theoretical justification of the convergence of their method. ",0.17857142857142858,0.4032258064516129,0.2475247524752475
2199,SP:c82bd8defbc84e7fe5cddb5ce2262bcb96366c18,This paper introduces a genetic algorithm that maintains an archive of representations that are iteratively evolved and selected by comparing validation error. Each representation is constructed as a syntax tree consists of elements that are common in neural network architectures. The experimental results showed that their algorithm is competitive to the state-of-the-art while achieving much smaller model size.,The paper presents a method for learning network architectures for regression tasks. The focus is on learning interpretable representations of networks by enforcing a concise structure made from simple functions and logical operators. The method is evaluated on a very large number of regression tasks (99 problems) and is found to yield very competitive performance.,0.14754098360655737,0.16363636363636364,0.15517241379310345
2200,SP:c8330db4743ced525c85be1261a538cfc9ad4e35,"The paper presents a proof of exponential convergence to global optimality in the over-parametrization settings for an implicit model with scaled weights parameters. Although existing work has established similar proofs for feedforward explicit neural networks, such methods don't work with non-linearly activated implicit models where the well-posedness issue poses challenges to the training process. The authors shows that by scaling the weights, well-posedness can be ensured. The convergence result is obtained first on continuous settings and is then extended to discrete settings. Numerical experiments on real datasets confirms the finding."," In this paper, the authors theoretically analyze the convergence of gradient descent for an implicit neural network with infinite layers with ReLU activation.  The authors show the unique fixed point of the infinite-layered mapping when the weight matrix $\boldsymbol{A}$ has a properly bounded spectral norm.  Using implicit differentiation, the authors show the partial gradient at the fixed point.  Furthermore, the authors show the linear convergence rate by proving the strictly positive-definite of the Gram matrix $\boldsymbol{G}(t)$  (and $\boldsymbol{H}(t)$). ",0.16842105263157894,0.18823529411764706,0.17777777777777778
2201,SP:c86b5fd03baefacd2e70d21e5b41faf8b97bb29b,"This paper aims to bridge GNNs with life-long learning so that the catastrophic forgetting problem in graph-structured tasks is alleviated. Specifically, the major contribution seems to be transforming the original graph into a feature graph so that the node classification problem is transferred into a graph classification problem with isolated samples. Meanwhile, feature interactions are modeled in constructing edges of the feature graph. Experiments on three citation graphs demonstrate the effectiveness of the proposed method. ","This paper aims to solve the problem of lifelong graph learning. Thus far, the topic about graph learning and lifelong learning is still underexplored. This paper proposes a new graph topology based on feature interaction, which takes the features as nodes and turns the nodes into graphs, and thus formulates a regular lifelong learning problem by defining the feature graph continuum. The authors conduct experiments on three popular citation graph datasets including Cora, Citeseer, and Pubmed.",0.2857142857142857,0.2894736842105263,0.2875816993464052
2202,SP:c8776bd6d8dba1ccaabefcdab75900df8e709aa5,"This paper uses the pre-trained large model (CLIP) to transfer the language knowledge to the unseen labels for zero-shot semantic segmentation. The idea is reasonable and coherent with previous works that distill knowledge from pre-trained models. The experiments also show good results on several benchmarks in a zero-shot setting. However, the method is not novel and leads to many problems.","The paper proposes Language driven Semantic segmentation (LSeg) for semantic segmentation. Essentially, LSeg embeds text labels and image pixels into a common space, and assigns the closest label to each pixel. LSeg is flexible and can dynamically handle arbitrary label sets on the fly with varying length, content, and order. The paper demonstrates that LSeg achieves comparable performance as state of the art few-shot semantic segmentation networks on FSD-1000 even though it is used in zero-shot setting. When a fixed label set is used based on the data set (all labels in the training set), it also matches the accuracy of traditional segmentation algorithms on ADE-20k. LSeg uses text encoder from CLIP-ViT-B/32 which is frozen during training while the weights of the image decoder (DPT with a ViT-L/16) is updated to maximize the correlation between the text embedding and the image pixel embedding of the ground truth class of the pixel. Spatial regularization is applied at the end that also up samples the predictions to the original input resolution. ",0.3125,0.11235955056179775,0.1652892561983471
2203,SP:c895519de92206da36297207d000246430963b08,"This paper presents two advances in conformal prediction, a field with information retrieval applications in which a set of candidate responses to a query is presented and the objective is to return a small set of responses with at least one of the responses being the correct response.  The first contribution is a method in which the possibility of several admissible responses is modeled (rather than there being just one response) with the system being calibrated against the odds that a particular response is the ""most admissible"", i.e. most conforming to the joint query/response distribution being learned from data. The second contribution is a cascaded prediction system in which simpler and less computationally expensive models are used for initial filtering and then more sophisticated and more expensive models are used downstream to further refine the response set. Rigorous statistical adjustments are used to account for multiple-hypothesis-test issues arising from using the cascading system.","Conformal prediction (CP) allows for the selection of a set of candidate answers guaranteed to contain the correct answer with some probability. The authors propose two extensions to CP, 1. To extend validity for all admissible answers, 2. Using prediction cascades to improve computational efficiency. The authors show that their approaches provide similar guarantees on accuracy like CP but with lowered predictive efficiency and computational cost.",0.10191082802547771,0.24242424242424243,0.14349775784753366
2204,SP:c89a7dc5dcd23d4677a4d59edb187196e93f7df7,"This work proposes a new path planning method PlaLaM, which is an extension of the LaMCTS algorithm. The authors provide a novel regret analysis of adaptive region partitioning schemes.   The authors demonstrate that the PlaLam method improves performance in toy 2D navigation tasks. The approach is also be applied to compiler phase ordering and molecular design achieving comparable performance to a solution based on proximal policy optimization at 4000 episodes.  The authors show comparisons to a number of baseline methods, but do not include a comparison the the LaMCTS method, which there approach is an extension of. I look forward to their explanation in the rebuttal.  Model-free RL and planning are my domains of expertise. Evolutionary algorithms are not, so please consider my review according.","The paper presents a black-box optimization method that efficiently searches the parameter by partitioning the parameter space using a latent space. The proposed method is built upon LaMCTS proposed by Wang et al. [2020]. This paper provides theoretical analysis of LaMCTS and proposed the modifications. The proposed algorithm, PlaLaM, was tested in synthetic tasks and real-world tasks, including compiler optimization and molecular design tasks. The proposed algorithm outperformed baseline algorithms in those experiments. ",0.15079365079365079,0.25333333333333335,0.1890547263681592
2205,SP:c8a8e6b90a56186572e90e21755e73effbeaea14,"The paper raises an alarm that state-of-the art change-point detection methods in the ML literature do not handle important practical aspects arising in time-series modeling, namely seasonality. Indeed, methods designed to detect changing distribution under an i.i.d. setting can fail dramatically when the assumption is violated, when the change happens in the seasonal component.  The paper proposes to use an auto-encoder to find the ""main pattern"" within each seasonal window, and to use total variation penalty (l1-norm on the change) of the hidden state in the auto-encoder to encourage a smooth state-sequence which allow breaks.  They use k-means clustering to partition data-points, and detect a change-point if two consequent hidden states don't end up in the same cluster. ","This paper proposed a new model for change point detection, using autoencoders with temporal regularization, in order to impose temporal smoothness in the latent codes. To motivate this new model, the authors also provided a toy example to show how the abnormality in a time series is removed in the reconstructed signal using this additional regularization term. Experimental results were provided to support the proposed new model.",0.12121212121212122,0.23880597014925373,0.16080402010050251
2206,SP:c8c5809f731c2f0c6bf01e24bc4d9eb7cf924ccd,"This is an interesting paper, as it tries to understand the role of hierarchical methods (such as Options, higher level controllers etc) in RL. The core contribution of the paper is understand and evaluate the claimed benefits often proposed by hierarchical methods, and finds that the core benefit in fact comes from exploration. The paper studies hierarchical methods to eventually draw the conclusion that HRL in fact leads to better exploration based behaviour in complex tasks. ","This paper evaluates the benefits of using hierarchical RL (HRL) methods compared to regular shallow RL methods for fully observed MDPs. The goal of the work is to isolate and evaluate the benefits of using HRL on different control tasks (AntMaze, AntPush, AntBlock, AntBlockMaze). They find that the major benefit of HRL comes in the form of better exploration, compared to the ease of learning policies. They claim that the use of multi-step rewards alone is sufficient to provide the benefits associated with HRL. They also provide two exploration methods that are not hierarchical in nature but achieve similar performance:  a) Explore and Exploit and b) Switching Ensemble.",0.34210526315789475,0.23853211009174313,0.2810810810810811
2207,SP:c8cb37b4a9a89fd31a6e86c84e0575845a580dfa,This paper studies convex minimization problems lacking Lipschitz continuity of the objective and compactness of the feasible set. They assume access to a standard stochastic subgradient oracle with mean-zero noise and bounded variance. The main contribution of the paper is to propose an adaptive method based on Mirror descent and a clever step-size rule that attains optimal convergence rates under several regularity assumptions beyond standard Lipschitz continuity.,"- In the paper, the authors propose an adaptive parameter agnostic algorithm AdaMir for online and stochastic convex optimization problems. - AdaMir is essentially like the popular Adagrad algorithm with Bregman distances involved in controlling the step-size. - Their setting involves non-Lipschitz gradients, contrary to the traditional Lipschitz smooth setting. ",0.13043478260869565,0.1836734693877551,0.15254237288135594
2208,SP:c8da6ab10ee30c9a5da7b8110b9f34079f33f366,"The paper proposes a meta-learning method that utilizes unlabeled examples along with labeled examples. The technique proposed is very similar to the one by (Ren et al. 2018), only differing in the choice of a different clustering algorithm (Kulis and Jordan, 2012) instead of soft k-means as used by Ren et al. ","This work proposes a learning method based on deep subspace clustering. The method is formulated by identifying a deep data embedding, where clustering is performed in the latent space by a revised version of k-means, inspired by the work [1]. In this way, the proposed method can adapt to account for uni-modal distributions. The authors propose some variations of the framework based on soft cluster assignments, and on cumulative learning of the cluster means.",0.25925925925925924,0.18421052631578946,0.2153846153846154
2209,SP:c8dbd8a29e123eb0c0d4e01fa5f4c2575563aacf,"The paper proposed to use gradient-based presentation in deep neural networks to capture missing information unavailable in the activation-based network representation. It is claimed that the missing information that could not be encoded during learning from training set can be revealed by taking the gradient of an example with respect to the model parameters. Based on this idea, a new learning algorithm is proposed to combine both the conventional loss for activation-based presentation and gradient-based regularization. As an illustration, the method is evaluated on anomaly detection benchmarks with gradient-based representation as part of the anomaly inference. ","The authors consider gradients of some loss as a feature representation. The intro starts describing a form of classification loss, but this is switched to a GAE unsupervised loss in Eq. 1. In that section the authors somewhat show that a naive gradient representation does not work well, but at the same time show that it /may/ work with their method, introduced right after, and which consists in an ""orthogonality"" regularizer, introduced with any arbitrary loss later in Eq.3, and back to GAE in Eq.4. The authors evaluate whether this regularizer hurst reconstruction error ",0.13861386138613863,0.14583333333333334,0.14213197969543145
2210,SP:c8fd8414a0779eab64b10e2951e36aad4f256168,"This paper presents a novel approach for doing hierarchical deep RL. Each level of the hierarchy is rewarded for reaching a goal state. The top level's goal state is the environment goal, lower level goals states are the actions of the higher levels. The lowest level's actions are primitive actions. Each level can act until it reaches it goal or a maximum of T steps. Then HER is used to still learn from missed subgoals. For example, if the lowest level is given a subgoal and fails to achieve it, it is trained with a new experience where the goal was the achieved state. In addition, the level above is trained with an experience where the action it chose (the subgoal that was not achieved) is replaced with the subgoal that was achieved. So HER is replacing goals on one level and replacing actions on the higher level. The paper shows nice empirical results across 6 domains.","This paper proposed a framework that can improve the performances of reinforcement learning algorithms in tasks that involve long time horizons and sparse rewards. The proposed method is a hierarchical reinforcement learning framework that can use policy hierarchies with an arbitrary number of levels. To improve the sample efficiency in the learning process, the authors proposed to apply the hindsight experience replay mechanism at each level. Also, in order to avoid the actor function to output an unrealistic subgoal, the authors proposed the subgoal testing technique. ",0.12578616352201258,0.23255813953488372,0.16326530612244897
2211,SP:c91868cfd7dc498d7571e570e3a6e3434dba174b,"This paper is built on the top of DNC model. Authors observe a list of issues with the DNC model: issues with deallocation scheme, issues with the blurring of forward and backward addressing, and issues in content-based addressing. Authors propose changes in the network architecture to solve all these three issues. With toy experiments, authors demonstrate the usefulness of the proposed modifications to DNC. The improvements are also seen in more realistic bAbI tasks.","This paper proposes modifications to the original Differentiable Neural Computer architecture in three ways. First by introducing a masked content-based addressing which dynamically induces a key-value separation. Second, by modifying the de-allocation system by also multiplying the memory contents by a retention vector before an update. Finally, the authors propose a modification in the link distribution, through renormalization. They provide some theoretical motivation and empirical evidence that it helps avoiding memory aliasing. ",0.14666666666666667,0.14666666666666667,0.14666666666666667
2212,SP:c9261d925dd0828ecea13a5a53a6ca9e3f60a628,"The authors develop a new method for solving the N-k SCOPF problem, an optimal power flow problem robust to any $k$ outages. Specifically, they relax the problem to allow for any convex combination of outages that has total 1-norm less than $k$. They then leverage recently popularized implicit differentiation techniques to solve the resulting minimax problem. Their formulation works for generic minimax problems, although one can exploit problem-specific structure when solving the N-k SCOPF problem. Finally, they test their method on a reasonably large test case for $k = 1, 2, 3$, and show that it finds a solution in a reasonable amount of time that improves upon standard OPF (in terms of the number of violations).","In this paper, N-k SCOPF is formulated and solved through the lens of adversarial learning and the implicit function theory. Thus, problem formulation and the development of a multi-level optimization algorithm are two key contributions. Meanwhile, the paper is mostly well written and easy to follow. ",0.09166666666666666,0.22916666666666666,0.13095238095238096
2213,SP:c9481aa3660d329ae9727810687f68930d1f2d5e,"Motivated by few-shot learning challenges such as Omniglot, the authors propose a human-like model for learning how to draw visual concepts that consists of three components: (1) a location model for picking the starting point of the next stroke given the current ""canvas"", (2) a stroke model that continues an existing stroke, (3) a termination model that decides when to stop drawing.  The three components of this model are trained on example glyphs that are heuristically parsed into strokes.  The authors evaluate performance of this method, called GNS (Generative Neuro-Symbolic) versus more classical program learning approaches based on pre-existing libraries of subroutines and more generic deep neural network architectures.  This approach (1) represents an advance over methods based on pre-defined subroutines in the sense that primitives such as ""draw a stroke intersecting an existing stroke"" are learned rather than supplied by the programmer and (2) performs much better at few-shot learning of glyphs than generic approaches.","In this paper, the authors seek to combine the advantages of symbolic, compositional models and neural approaches, in particular by using ""probabilistic programs with neural network subroutines"" which should reflect a causal generative process. This is certainly an interesting area to explore. But I'm not convinced that the approach they propose (GNS) lives up to their stated goals.",0.08024691358024691,0.22033898305084745,0.11764705882352941
2214,SP:c95b7015438d26176ef74968cca54ea98fddab98,"This paper studies the correlation between the attention mechanism and many prior arts. Heuristically, this paper links the currently hot topic, attention mechanism, with many milestones works in the past decades before the deep learning era, including subspace learning, sparse coding, kernel regression, non-local means, etc. Among these classic methods, many can be formulated as optimization problems. The minimizer to the optimization problem can be treated as the output of attention modules, and the optimization algorithm can be understood as the ``architecture'' of attention. Specifically, this work highlights the potential of sparse coding in designing the sparse attention mechanism when considering the self-expressiveness in subspace learning is essentially profoundly connected to the formulation of self-attention.","This paper surveys several lines of prior work which has connection to the self-attention module in transformers. Specifically, the authors show that self-attention has the similar form with the kernel regression and non-local mean algorithm. They also demonstrate that locally linear embedding and self-expression algorithm for subspace clustering have the form of representing one data point by weighted sum of other data points, and thus are connected to the weighted sum of values in self-attention. Based on these observations, the authors argue that the innovation of self-attention is not modeling the long-range relation, which is also proposed in prior work, but the learnable parameters and the multi-head design. The authors also suggest several directions for future work, such as using self-attention for manifold clustering.",0.23728813559322035,0.21052631578947367,0.22310756972111553
2215,SP:c966fd016af0edb014beaaee492f136ea57c77aa,"In the paper, the author addresses a calibration-based conditional coverage error in order to avoid the difficulty of conditional coverage, which provides a middle ground between marginal (no conditional information) and conditional coverage (high computational cost). The author generates the idea building on prior work and designs a new loss function combining the high-quality criterion and a coverage assessment loss. The theoretical framework about the loss function is laid out clearly, and the performances on benchmark datasets provide accurate results which outperform the other baseline algorithms on high-quality prediction intervals generation.","In the submitted paper, the authors study high-quality prediction intervals (PIs). The paper proposes a novel design of loss functions to generate PIs and conditional coverage estimates. The theoretical justification for using the conditional coverage error (in Ca-module) is presented and the numerical experiments with promising results are provided on multiple benchmark datasets.",0.20212765957446807,0.34545454545454546,0.2550335570469799
2216,SP:c98108a3d1120eb4c9c34ba2e07545e9a3f93bdf,"This paper considers the problem of capacitated vehicle routing which is a famous combinatorial optimization problem that is known to be NP-hard. This paper takes the approach of solving instances of this problem using RL. The goal is this problem is to minimize the maximum time (or makespan objective) for multiple vehicles to complete various tasks subject to fuel constraint. The paper trains a graph embedding from random instances and then show that it solves new instances of this problem with reasonable accuracy. Moreover, they also show that the embedding can be transferred to other related objectives.","The paper presents a reinforcement learning approach to learn a routing policy for a family of Vehicle Routing Problems (VRPs). More precisely, the authors train a model for the min-max capacitated multi vehicle routing problem (mCVRP), then use it to solve variants of the problem that correspond to various VRP problems (with a single vehicle, no capacity constraints, no fueling stations, etc). They use a GNN to represent the states and the PPO algorithm to learn the policy. They validate their approach on both random instances and literature benchmarks.",0.17346938775510204,0.18888888888888888,0.18085106382978725
2217,SP:c993d028cb6c4168ee0a40f62cb9020008ba8bf2,"This paper introduces a brand new graphical modeling framework from the perspective of neural ODEs. Traditionally structure learning involves using sampled data to learn the structure of graphs. This paper, however, looks at the graph structure learning problem from a different viewpoint, using continuous-time dynamics inspired from neural ODEs. Theoretical guarantees on parameter estimation are provided. Some experiments on benchmark time-series datasets are also conducted. ","The paper proposes to learn Jacobian-sparse neural network ODEs from irregular trajectories of a dynamical system. The main contribution is the sparsity of the ODE Jacobian, which results in learning of differential covariate causalities. Learning the differential structure is an important real-world problem. The proposed method is elegant, simple and effective, although incremental. ",0.13432835820895522,0.16363636363636364,0.14754098360655737
2218,SP:c9affd2ef30c7b4e0873aeb5783105b8ea6c056b,"The authors propose a new pooling layer, LaPool, for hierarchical graph representation learning (Ying et al., 2019) by clustering nodes around centroids that are selected based on ""signal intensity variation"". The signal intensity variation of node x is defined as sum_{y in HOP(x, h)} ||x - y||  where HOP(x, h) is the set of nodes reachable from x within h hops. Once top k maximizers are selected as centroids (k can be predetermined or dynamically chosen), a sparse cluster assignment distribution is computed for each node using sparsemax (Laha et al., 2018), and the affinity matrix and the node embeddings are coarsened as in Ying et al. (2019). The authors show that LaPool can improve performance in various graph-related tasks over baselines and generate interpretable clusters. ","The paper introduces a new pooling approach ""Laplacian pooling"" for graph neural networks, which the authors claim is able to better preserve information about the local structure, and to provide interpretability.  Namely, the pooling approach is based on finding centroids (nodes having high signal variation compared to their neighbors, via graph-Laplacian) and assigning other nodes to be ""followers"" based on a soft-attention mechanism. The authors add these new pooling layers to existing GNN architectures and show improved performance on problems of classification and generative modeling of molecular graphs. The paper also extends CNN interpretability techniques (integrated gradients) to GNNs.",0.13953488372093023,0.1782178217821782,0.1565217391304348
2219,SP:c9bc6f77b7493e1cadb84f89759d5a89e61320de,"This submission studies the meta-learning problem in RL under offline settings. A new algorithm is proposed to address this problem by extending the recent VariBAD algorithm designed for online meta-RL. The key modifications to adapt the original VariBAD to offline settings are the state re-labelling and reward re-labelling tricks, which aim at addressing the MDP ambiguity specifically showing up in offline meta-RL. Experiments are conducted on four sparse reward tasks under both offline and online settings, comparing with PEARL (a recent online approach) and the original VariBAD respectively.","The paper studies the problem of offline Meta-Reinforcement Learning (RL). In this problem, N separate RL environments are considered which are drawn from a specific underlying distribution. For each such environment, M trajectories each of horizon H are provided beforehand. The task is to train an RL agent that performs well in expectation on a new RL environment drawn from the same distribution.  The authors adapt the online VariBAD algorithm (Zintgraf et al., 2020) by the use of a techniques called state relabeling and reward relabeling. ",0.1935483870967742,0.20689655172413793,0.19999999999999998
2220,SP:c9c45def5238b7a9b753c8169bb940aaaaa0c150,"- This paper tackles an important problem: Suppose we have trained a model on a dataset, but we wish to adapt it quickly. For example, we might add new training points, delete training points, or wish to change the model and regularization. We could re-train a model, but that's slow - can we get a similar result but quicker and using less memory? - This paper proposes K-prior: regularizing the model towards the original model in both weight space and predictions. - They show that training on the K-prior objective on the entire dataset recovers the original model - which would not be true if we only have weight space regularization, or only have prediction regularization. - In practice, to save memory, they only form the prior on a few points, and they describe heuristics to choose these points, with some mathematical justification - They show that this methods work well in practice, compared to just replaying the points  ","This paper proposes a new regularizer to adapt the prior knowledge through weight prior and the memory that is smaller than the entire dataset but identical to be learned correctly. Previous methods to do this have focused on the ""Add/Remove Data"" task, but the authors extended the adaptation tasks to adapt regularizer change or architecture change through the proposed regularizer, K-priors. It also could be applied to a variety of models from a linear model to deep learning. They described the connections between K-priors and previous works for adding/removing data for SVMs, knowledge distillation and continual learning for deep learning, and Bayesian learning. They mainly validated that K-priors outperform the model without K-priors but using the same memory selected through K-priors for logistic regression and classification tasks. ",0.14743589743589744,0.17164179104477612,0.15862068965517243
2221,SP:c9fc1bcc4e132fc239fb64b18b12b9f137f5ed3c,"The paper proposed to study the problem of extracting correspondences for 3D point cloud registration. The paper presented CoFiNet (Coarse-to-Fine Network) to extract hierarchical correspondences from coarse to fine without detecting keypoints.  The model firstly learns to match down-sampled nodes and proposes node correspondences. On a finer scale, node proposals are consecutively expanded to patches that consist of groups of points together with associated descriptors. Patch correspondences are then refined to point level by a density-adaptive matching module. The proposed method has been evaluated on both indoor and outdoor standard benchmarks.",The paper presents a novel learning method for point cloud registration by extracting hierarchical correspondences in a coarse to fine manner. There are two modules:  Coarse scale:  a network is first utilized to downsample and extract feature from input  point cloud. The features are then strengthened and used to compute a score matrix for coarse correspondence proposals.  Fine scale: coarse correspondence proposals are expanded to patch correspondences via grouping and refined with a density-adaptive matching module.,0.30526315789473685,0.37662337662337664,0.3372093023255814
2222,SP:ca085e8e2675fe579df4187290b7b7dc37b8a729,"This paper describes a method that builds upon the work of Wang et al. It meta-learns to hallucinate additional samples for few-shot learning for classification tasks. Their two main insights of this paper are to propose a soft-precision term which compares the classifiers' predictions for all classes other than the ground truth class for both a few-shot training set and the hallucinated set and b) to introduce the idea of applying direct early supervision in the feature space in which the hallucination is conducted in addition to in the classifier embedding space. This allows for stronger supervision and prevents the hallucinated samples from not being representative of the classes. The authors show small, but consistent improvement in performance on two benchmarks: ImageNet and miniImageNet with two different network architectures versus various state-of-the-art meta-learning algorithms with and without hallucination. The authors have adequately cited and reviewed the existing literature. They have also conducted many experiments (both in the main paper and in the supplementary material) to show the superior performance of their approach versus the existing ones. Furthermore their ablation studies both for the type of soft precision loss and for their various individual losses are quite nice and thorough. ","In this paper, the authors address few-shot learning via a precise collaborative hallucinator. In particular, they follow the framework of (Wang et al., 2018), and introduce two kinds of training regularization. The soft precision-inducing loss follows the spirit of adversarial learning, by using knowledge distillation. Additionally, a collaborative objective is introduced as middle supervision to enhance the learning capacity of hallucinator. ",0.09178743961352658,0.30158730158730157,0.14074074074074075
2223,SP:ca0c4bdb02f7d939fb6de38b6b446ced4b5984a0,"This paper proposes a neural-symbolic deep generative model to generate music and poems. Compared to other natural language sentence generation tasks, songs and poems usually require some structural constraints, e.g., rhythm and rhymes. Therefore, their approach first generates a program represented as a set of relational constraints, then generates sequences that satisfy the constraints. During the training time, given a training example, i.e., a sequence, they formulate the program synthesis task as a combinatorial optimization problem, and thus they can find the required constraints using the Z3 solver. They use the SOTA generative models for both of the two sequence generation domains. They propose several variants of the generation approach, to ensure that the generated sequences satisfy the constraints. They evaluate their approach in terms of both the low-level and high-level structures. To measure the low-level structure, they compute the negative log likelihood of the SOTA generative models. To measure the high-level structure, they apply the Z3 solver to solve the relational constraints of each generated sequence, and train some discriminators to distinguish the generated sequences from the human-written ones in the dataset. For the poetry domain, they also evaluate the diversity of the generated sequences. Generally, the neural-symbolic approach generates sequences with better high-level structures, and the generated samples are more diverse.","This paper proposes an approach for generating sequences that possess high-level structure, and in particular structure that can be expressed using hand-crafted symbolic relations. Given a domain and a set of possible relations to consider, this approach first extracts a sequence representation of the relational constraints for each example, then trains a two-stage generative model that first generates relational constraints and then generates the final output conditioned on the constraints. The authors apply their approach to the generation of music and poetry, and show that, compared to simple baselines, the generated outputs are more consistent with human-generated examples (according to other learned models of high- and low-level structure).",0.14798206278026907,0.2920353982300885,0.19642857142857145
2224,SP:ca12fed22111b64e2e41cea1d3f0601b8e6be9c2,"This paper proposed a new way of learning point-wise alignment of two images, and based on this idea, one-shot classification and open-set recognition can be further improved. The idea is interesting. As a human, when we say two images are similar, we may compare them locally and globally in our mind. However, traditional CNN models do not make direct comparisons. And this work give a good direction to further improve this motivation.","Authors argue that using average (independent) greedy matching of pixel embedding (based on 4-6 layer cnn hypercolumns) is a better metric for one-shot learning than just using final layer embedding of a 4-6 layer cnn for the whole image.  Their argument is backed by outperforming their baseline and getting competitive results on few shot learning tasks. Their method is much more computationally heavy than the baseline matching networks. In order to make training feasible, in practice they train with 90% dropout of test pixels embedding & 80% dropout of reference pixels embedding. ",0.13333333333333333,0.10638297872340426,0.11834319526627218
2225,SP:ca1c5b8304d703df56c13e9bd2ab11ad8771bb6d,"Authors propose to regularize the Jacobian of the generator in a VAE setting so as to encourage local alignment of the latent axes, i.e. `local disantanglement'. They do so by finite differences, and empirically show on the MPI3D dataset the effectiveness of their approach.","In this paper, the authors try to solve the identifiability issue of representation learning for generative processes with similar eigenvalues. Inspired by ICA, sparse coding, the authors propose to add an L1 regularizer of the Jacobian of decoder mean-mapping to the ELBO. To compare with other methods, the authors also adapt the common evaluation metrics (including MIG and Modularity) to the problem of local disentanglement. Both qualitative and quantitative results show the efficiency of the proposed method compared with baseline models.",0.3111111111111111,0.17073170731707318,0.2204724409448819
2226,SP:ca1df198beeed3714ec47725153839ebbffb3bea,"The paper focuses on the so-called bang-bang policies. These are ones, which are allowed only for discrete values, typically two extremal ones. Even though they are usually disadvantageous in real-world scenarios, they tend to arise in simulation, and they seem to deliver at least decent performance.","The work investigates emergence of bang-bang control policies in continuous RL problems, by making the connection to optimal control. Exmpirically, it shows how continuous control problems are solved with bang-bang policies, using 4 different algorithms, and that for most of the domains in these experiments, a continuous action space is not needed. The experiments also explore modified reward functions designed to increase smootheness of the learnt policies and their effect on the (original) return obtained during exploitation. ",0.1836734693877551,0.11392405063291139,0.14062499999999997
2227,SP:ca2a33f605f245e0c4051c77e746dab6846d1c7a,"This paper proposes a modification to momentum. Extra terms are added to account for the drift in parameters through the gradient updates that contribute to the momentum. The effect of this modification is studied on supervised learning and TD learning and on different representations. The conclusion is that while the original momentum is good enough for supervised learning, this modification matters when there is bootstrapping, especially on representations with high interference.","This paper extends the idea of momentum, commonly used in optimization literature, to Temporal Difference (TD) learning which is a widely used algorithm for policy evaluation in Reinforcement learning literature. The main challenge in this work is to account for the 'optimization bias' introduced by using momentum based updates. The authors propose to do this via a Taylor approximation to the TD update and empirically show the merits of this idea on some toy data sets as well as on an Atari game. ",0.23943661971830985,0.20481927710843373,0.22077922077922077
2228,SP:ca3e6cdc26b1617414ecefb5f81319011a1874b3,"This paper investigates sophistical exploration approaches for reinforcement learning. Motivated by the fact that most of bandit algorithms do not handle heteroscedasticity of noise, the authors built on Information Direct Sampling and on Distributional Reinforcement Learning to propose a new exploration algorithm family. Two versions of the exploration strategy are evaluated against the state-of-the-art on Atari games: DQN-IDS for homoscedatic noise and C51-IDS for heteroscedastic noise. ","The authors propose a way of extending Information-Directed Sampling (IDS) to reinforcement learning. The proposed approach uses Bootstrapped DQN to estimate parametric uncertainty in Q-values, and distributional RL to estimate intrinsic uncertainty in the return. The two types of uncertainty are combined to obtain a simple exploration strategy based on IDS. The approach outperforms a number of strong baselines on a subset of 12 Atari 2600 games.",0.22535211267605634,0.2318840579710145,0.2285714285714286
2229,SP:ca6acbc11e7d3f693e4710fe6adb8d71cde3fe6b,"Authors introduced approaches aimed at learning invariant predictors across data sources. Rather than using distribution/risk matching schemes as often done by previous work, they propose to train models against mixtures of data points as a means to avoid that models rely on spurious correlations between domain and class labels, since such correlations observed during training might not hold at testing time. The proposed setting uses the idea of mixup to combine data instances in two different schemes: I-combine data points from the same class but different domains, and II-combine data points from the same domain but from different classes.","This paper propose a mixup-style data augmentation method under the data distribution shift context. In particular, data distributions are formulated as mixture of distributions (i.e., domains), and two distribution shift scenarios are considered: (1) domain shift, where the test domain and train domain are disjoint. (2) subpopulation shift, where test distribution has different mixture proportion than train distribution. It's  assumed that domain identification spuriously correlates with labels. To tackle this problem, this paper proposes two mixup strategies: (I) mixup two examples with same label but different domains; (II) mixup two examples with same domain but different labels. It's claimed that such mixup could cancel out the spurious correlations. Extensive experiments on a variety of datasets show its superiority compared to empirical risk minimization (ERM) and alternative data augmentation methods. The paper further provide theoretical analysis that under certain conditions, the proposed method has asymptotically smaller worst case classification errors than ERM and vanilla mixup. ",0.18627450980392157,0.12025316455696203,0.14615384615384616
2230,SP:ca8044d2b9b890b64e7c650d6e6e402cb175b3e7,"Quality: sufficient though there are issues. Work done in automatic speech recognition on numerous variants of recurrent models, such as interleaved TDNN and LSTM (Peddinti 2017), is completely ignored [addressed in the revision]. The description of derivatives needs to mention the linear relationship between input features and derivatives (see trajectory HMMs by Zen and Tokuda) [addressed in the revision]. TIMIT is a very simple task [addressed by adding WSJ experiments]. Derivations in the appendices could be connected better [addressed in the revision]. ","The paper takes a good step toward developing more structured representations by exploring the use of quaternions in recurrent neural networks.  The idea is motivated by the observation that in many cases there are local relationships among elements of a vector that should be explicitly represented.  This is also the idea behind capsules - to have each ""unit"" output a vector of parameters to be operated upon rather than a single number.   Here the authors show that by incorporating quaternions into the representations used by RNNs or LSTMs, one achieves better performance at speech recognition tasks using fewer parameters.",0.14634146341463414,0.12244897959183673,0.13333333333333333
2231,SP:ca83623b552cb6bd000d5a67fd81e41a6d7b1e7a,"The paper studies the behaviour of disentanglement methods and metrics on data where a couple of factors of variation (FoV) are correlated, a more realistic setup compared to the usual independent FoV setting in the literature. The paper shows how the correlation in the FoV is reflected in the representations learned by the models, and claims that the widely used disentanglement scores fail to capture these correlations. A couple of solutions that use weak supervision are suggested.","This paper systematically presents a large-scale empirical study on the disentangled representation learning when the underlying factors are possibly entangled. From the results of purely unsupervised settings, the authors have discovered the shortcomings of the existing metrics of disentanglement as well as the poor learned representations (in terms of disentanglement). However, with the help of small amount of factor labels or other weak supervision signals, recent approaches could learn fairly perfect representation.",0.18181818181818182,0.1917808219178082,0.18666666666666668
2232,SP:caa56814ef257c2f061420c46199dc29d24d9484,"This paper targets training generative adversarial networks with a formulation that is motivated by mass transport of fluid flows. While generalized transport formulations are popular for GANs by now, especially the Earth Mover's distance and the Wasserstein GAN version that this paper is based on, this submission instead frames the problem with a divergence-free flow model inspired by Navier-Stokes. The problem of matching output distributions then becomes one of inferring a suitable flow field that aligns the distributions. ","The paper addresses the task of constructing a generative model for data using a novel optimal transport-based method. The paper proposes an alternative view of obtaining generative models by viewing the generation process as a transport problem (specifically, fluid flow mass transport) between two point clouds living in high-dimensional space. To solve the transport problem, a discretization scheme is proposed, which gives rise to a variant of point cloud registration problem, which is solved using numerical optimization. The results are provided on synthetic data and a real MNIST data. ",0.16049382716049382,0.14285714285714285,0.1511627906976744
2233,SP:caa7fcf551f4ee75b6c06f05581bc5ef298fedbe,This paper introduces a formulation for the contextual inverse reinforcement learning (COIRL) problem and proposed three algorithms for solving the proposed problem. Theoretical analysis of scalability and sample complexity are conducted for cases where both the feature function and the context-to-reward mapping function are linear. Experiments were conducted in both a simulated driving domain and a medical treatment domain to compare the three proposed algorithms empirically. Empirical results for using a deep network as the contextual mapping function is also provided.,"This work focuses on the problem of 'contextual' inverse reinforcement learning, where the reward is a function of the current state of the MDP, and a set of context features, which remain constant within each episode.  The primary contribution of this work is the formulation of inverse reinforcement learning (for restricted spaces of context-dependent reward functions) as a convex optimization problem.  Based on this formulation, the paper describes several IRL algorithms based on approaches to solving convex and non-convex optimization problems, including variations of mirror descent, and evolution strategies (in principle allowing for the optimization of reward functions with arbitrary parametric representations).  The algorithms presented in this work all assume that computing an optimal policy for a specific reward function is a relatively inexpensive subroutine, which limits their applicability to domains where such planning is straightforward.  Experimental results are presented for a simple highway driving domain, as well as a simulated patient treatment domain constructed from real-world clinical data.",0.27710843373493976,0.1419753086419753,0.18775510204081633
2234,SP:caca11294236433df3e4a14e0ae263ef332372c9,"This paper studied the effectiveness of Conditional Entropy Bottleneck (CEB) on improving model robustness. Three tasks are considered to demonstrate its effectiveness; generalization performance over clean test images, adversarially perturbed images, and images corrupted by various synthetic noises. The experiment results demonstrated that CEB improves the model robustness on all considered tasks over the deterministic baseline and adversarially-trained classifiers. ","The paper modifies existing classifier architectures and training objective, in order to minimize ""conditional entropy bottleneck"" (CEB) objective, in attempts to force the representation to maximize the information bottleneck objective. Consequently, the paper claims that this CEB model improves general test accuracy and robustness against adversarial attacks and common corruptions, compared to the softmax + cross entropy counterpart. This claim is supported by experimental results on CIFAR-10 and ImageNet-C datasets.",0.21666666666666667,0.18309859154929578,0.19847328244274812
2235,SP:cae612186f97a548f9d34ff2c5d87dc5a970afdd,"The paper introduces an algorithm (BAIT) for batch active learning, designed for and tested on neural networks. It centres around an objective in eq 4, argmin_select trace(I_select^-1, I_all), with I as the Fisher information matrix of the final layer parameters of a neural network, an objective that has been previously derived/analysed in simpler settings. The contribution here is applying it to deep neural networks. It draws links with a current SOTA method, BADGE, and shows slight performance benefits over it.","The paper introduces a new principled active learning algorithm called BAIT, which uses the Fisher information matrix to select informative samples. The approach uses a greedy approximation to solve the global batch acquisition problem. Compared to other approaches, it also works for regression.  The paper provides ablation and gives a new perspective on BADGE, another active learning algorithm.  Multiple experiments both for classification and regression are provided.",0.19767441860465115,0.2537313432835821,0.22222222222222224
2236,SP:cae76295c4e38ce51c6bf1ed147ee4ea0569faed,"The submission tackles unsupervised anomaly detection, specifically in a scenario where supervision labels are not available, only information about the ratio of anomalous examples in the data set. They suggest an architecture consisting of two auto-encoders collaboratively determining anomalous samples and updating their weights based on data that is deemed normal. The authors provide a theoretical analysis of the selection process, and validate anomaly detection performance on a range of experiments.","This paper presents a Robust Collaborative Autoencoder (RCA) for unsupervised anomaly detection. The authors focused on the overparameterization of existing NN-based unsupervised anomaly detection methods, and the proposed method aims to overcome the overparameterization problem. The main contibutinos of the proposed method are that (1) it uses two autoencoders, each of which is trained using only selected data points and (2) monte carlo (MC) dropout was used for inference.",0.1527777777777778,0.15714285714285714,0.15492957746478875
2237,SP:caea798fb6dcc5623f6516a64c2ea94deac2ae02,"This paper proposes a new loss function for unsupervised facial attribute editing and transfer. Specifically, a latent mapping network is trained by optimizing the similarity/distance between the generated and desired image in the CLIP latent space. Experiments show some comparisons and ablations for the ""smile"" attribute.","The authors proposed a directional latent mapping network for facial attribute editing via text inputs. The directional latent mapping network could correctly edit relevant attributes while preserving irrelevant attributes via training with the semantic direction consistency (SDC) loss. This paved the way to a novel semantic directional decomposition network (SDD-Net) for text-driven facial attribute transfer: SDD-Net transfers semantic-aware attributes from reference images to a target, with the multi-modal approach guiding the process via text input descriptions. CelebA-HQ dataset was used to compare results with recent SOA methods.",0.2553191489361702,0.12903225806451613,0.1714285714285714
2238,SP:cb123d2c425d00ef5dd94db8c8faa0210f72b57c,"The paper proposes a new adversarial training scheme, LEAP, to obtain models robust against $\ell_\infty$-bounded adversarial examples. The loss used as the objective minimized during training involves both local and global (wrt the input space) properties of the network. Experiments suggest improved performance compared to single and multi-step standard adversarial training and TRADES.","The authors developed a novel robust training algorithm LEAP to focus on the effective use of adversaries. The proposed method improves the model robustness at each local patch and combines these patches through a global term, achieves overall robustness. The authors showed by maximizing the use of adversaries, they achieved high robust accuracy with weak adversaries. Furthermore, when trained with strong adversaries, the proposed method matches with the current state of the art on MNIST and outperforms them on CIFAR-10 and CIFAR-100.",0.26785714285714285,0.17857142857142858,0.2142857142857143
2239,SP:cb32c18a6a766894aa23e1f84ea9c38ef21fe023,"This paper studies a new category of adversarial attacks, i.e., attackers that try to slow-down multi-exit DNNs using adversarial examples. The paper extended adversarial attacks to perform the slow-down attack and showed that the attacks could slow-down multi-exit DNNs by 1.5x - 5.0x. Additionally, the paper experimentally answers many questions such as (1) the effectiveness of adversarial training against the attack, (2) input-agnostic attack, and (3) cross-architecture/domain transferability.","This paper studies adversarial attack and defense for adaptive multi-exit network. Adaptive multi-exit network is, by itself, a pretty new and under-studied topic, let alone the adversarial study on top of it. This paper proposes a simple-yet-effective DeepSloth attack based on layerwise loss function. It also proposed an efficacy metric for better evaluation. The experiments are conducted on four multi-exit networks and two datasets: cifar10 and tiny imagenet. In the appendix, there is also evaluation on different norms of attacks. The results on white-box and black-box attack demonstrate the effectiveness: DeepSloth not only hurts the accuracy (also achieved by baselines), but also hurts the efficacy (only achieved by DeepSloth). To reduce the computation burden of performing the attack, the authors did two things: 1) model partitioning in scenario of IOT, and 2) universal attack across a dataset. At the end, the authors adapt AT to multi-exit networks and demonstrate that AT is effective in general and DeepSloth is further helping AT for better robustness.",0.28205128205128205,0.12716763005780346,0.17529880478087648
2240,SP:cb35385634bc2ba2381921b491176a5309e754dd,"The paper proposed a theoretically grounded O(N) approximation of the softmax attention. The key idea is to interpret attention as a kernel function and construct the random feature projection that can reproduce this kernel. It is highly non-trivial to derive a feature mapping that can accurately approximate the softmax kernel. To better approximate the softmax kernel, the author proposed some important design choices, all of which are supported by theoretical and empirical evidences. The author showed that 1) adopting non-negative random features is very essential to the approximation and the proposed Positive Random Features (PRF) can effectively reduce the variance when the attention values are small, 2) drawing orthogonal random matrices can further reduce the variance of the approximation, 3) the final proposed Performer model runs faster, takes less memory, and has better performance than other O(N) and O(N logN) attention methods.",The authors propose to use the kernel feature map self-attention formulation introduced in [1] to efficiently approximate the softmax attention. The main contribution of the paper lies in the proposed _positive random features_ that can approximate softmax with a strictly positive feature map without which the training is unstable. The authors also show that an approximation of softmax is not necessary for good performance and actually use ReLU random features to achieve their best results when training from scratch.,0.1564625850340136,0.2875,0.2026431718061674
2241,SP:cb52e5738da392c9e3c38a51d0dfc01d17c508d5,"In this paper a method for pose estimation is proposed, which is based on the well known neural model “stacked hourglass networks”. The novelty in the proposed paper is a multi-scale formulation, which creates multiple scales from the input image and feeds them into different hourglass modules. The different scales are weighted differently, where the weights for a given scale depend on the error obtained on previous scales.","Authors extends stacked hourglass network with inception-resnet-A mudules and a multi-scale approach for human pose estimation in still RGB images. Given a RGB image, a pre-processing module generates feature maps in different scales which are fed into a set of serial stack hourglass modules each responsible for a different scale. Authors propose an incremental adaptive weighting formulation for each stack-scale-joint. They evaluate proposed architecture on LSP and MPII datasets.",0.2028985507246377,0.18666666666666668,0.19444444444444448
2242,SP:cb6397f78128e20abf726c63700dd49370335418,"This paper proposes a measure for a model’s spatial frequency sensitivity (SFS) based on the input-Jacobian in the Fourier basis. With this measure, the authors observe standard CNN training biases towards certain particular spatial frequencies consistently across samples. Based on this measure, the authors propose a family of spatial frequency regularization techniques to suppress the model’s sensitivities to certain spatial frequencies.  ","This paper proposes a novel spatial frequency regularization technique that improves the robustness of training neural networks against superficial fourier statistics in a dataset.  In the loss function, It adds a regularization term that is based on the Fourier-transformed input-Jacobian.  This term could be customized such that the trained model could ignore (be insensitive to) features with specific frequency in the dataset.   The authors define spatial frequency sensitivity using input-Jacobian in Fourier space.  Although this paper focuses on datasets with images, the method is extendable to any n-dimensional data.  Empirically, the method is evaluated for its robustness against fourier filtering, corruptions, and image patches shuffling in CIFAR10 & CIFAR100 datasets.  It shows better results than other baselines in maintaining the classification accuracy of a model against fourier filtering and image patches shuffling.  There do seem to be slight performance gaps from the SOTA AugMix method in image corruptions.  However, the method is considered to be simpler than AugMix and still outperforms other baselines in many cases.   Experiments demonstrate that the proposed method could learn global features present in a dataset.",0.34375,0.12021857923497267,0.17813765182186234
2243,SP:cb85203d43368ce095c1f37015bf7af061914a5c,"This paper studies influences of data structures on neural network learning. The data structures discussed in this paper are structured inputs (concentrating on a low-dimensional manifold) versus unstructured ones, as well as the teacher task (labels are obtained as a function of high-dimensional inputs) versus the latent task (labels are obtained as a function of the lower-dimensional latent representation of inputs). The introduced model, the hidden manifold model, which is a latent task with structured inputs, is claimed to reproduce two features found in learning of the MNIST data set, whereas the teacher task with unstructured inputs does not.","The authors consider the general problem of ""structure"" in datasets--particularly, what are the features of datasets that govern the learning dynamics of neural networks trained to classify that data.  They approach this problem by looking at combinations of [iid gaussian, structure] inputs and [teacher, latent] tasks (for particular choices of ""teacher"", ""latent"", and ""structure).  Finally, they identify that ""structure"" in the input space, and a notion of ""latent""-ness in the task seem crucial for a synthetic dataset to recapitulate the learning dynamics of a real-world dataset.",0.1568627450980392,0.1797752808988764,0.1675392670157068
2244,SP:cb8f98d674ac5fdafd3ff738a7d0027f6c4a19ad,"This paper introduces an unsupervised learning algorithm Dynamics-Aware Discovery of Skills (DADS) for learning low-level “skills” that can be leveraged for model-predictive control. The skills are learned by maximizing the mutual information between the next state s’ and the current skill z conditioned on the current state s. Maximizing this objective corresponds to maximizing the diversity of transitions produced in the environment, while making the skill z be informative about the next state s’. The idea is that using this objective leads to learning a diverse set of skills that are predictive of the environment. The skills z correspond to a set of action sequences, which are represented by a distribution \pi(a|s,z). Because the above objective is intractable to compute (because it relies on the true dynamics p(s’|s,a)), it is variationally lower bounded using the approximate dynamics q_{\phi}(s’|s,z), which represents the transition dynamics when using a certain skill and this variational lower bound is optimized to produce the optimal q_{\phi}(s’|s,z) and \pi(a|s,z).","This paper proposes a novel approach to learn a continuous set of skills (where a skill is associated with a latent vector and the skill policy network takes that vector as an extra input) by pure unsupervised exploration using as intrinsic reward a proxy for the mutual information  between next states and the skill (given the previous state). These skills can be used in a model-based planning (model-predictive control) with zero 'supervised' training data (for which the rewards are given), but using calls to the reward function to evaluate candidate sequences of skills and actions. The proposed approach is convincingly compared in several ways to both previous model-based approaches and model-free approaches.",0.14835164835164835,0.23275862068965517,0.18120805369127516
2245,SP:cbb28b39e7a2f17e1b229130ba484e49b69ab695,"This paper proposes an estimator to quantify the difference in distributions between real and generated text based on a classifier that discriminates between real vs generated text.  The methodology is however not particularly well motivated and the experiments do not convince me that this proposed measure is superior to other reasonable choices.  Overall, the writing also contains many grammatical errors and confusing at places.","This paper proposes two metrics to measure the discrepancy between generated text and real text, based on the discriminator score in GANs. Empirically, it shows that text generated by current text generation methods is still far from human-generated text, as measured by the proposed metric. The writing is a bit rough so sometimes it's hard to figure out what has been done. It's also unclear how the proposed metrics compare to simply using the discriminator for evaluation. Therefore, I'm inclined to reject the current submission.",0.296875,0.21348314606741572,0.2483660130718954
2246,SP:cbc68a631ec8a6098096224d15cf84b13f9c6c71,"This paper introduces a high-level semantic description for 3D shapes. The description is given by the so-called ShapeProgram,  Each shape program consists of several program statements. A program statement can be either Draw, which describes a shape primitive as well as its geometric and semantic attributes, or For, which contains a sub-program and parameters specifying how the sub-program should be repeatedly executed. The ShapeProgram is connected with an input through two networks, the program generator (encoder) and a neural program executor (decoder). Both encoder/decoder are implemented using LSTM. The key ML contribution is on the decoder, which leverages a parametrization to make the decoder differentiable. The major advantage of the proposed technique is that it does not need to specify the ShapeProgram in advance. In the same spriit of training an auto-encoder. It can be learned in a semi-supervised manner. However, in practice, one has to start with a reasonably good initial program. In the paper, this initial program was learned from synthetic data. ","This paper presents a methodology to infer shape programs that can describe 3D objects. The key intuition of the shape programs is to integrate bottom-up low-level feature recognition with symbolic high-level program structure, which allows the shape programs to capture both high-level structure and the low-level geometry of the shapes. The paper proposes a domain-specific language for 3D shapes that consists of “For” loops for capturing high-level regularity, and associates objects with both their geometric and semantic attributes. It then proposes an end-to-end differentiable architecture to learn such 3D programs from shapes using an interesting self-supervised mechanism. The neural program generator proposes a program in the DSL that is executed by a neural program execution module to render the corresponding output shape, which is then compared with the original shape and the difference loss is back-propagated to improve the program distribution. The technique is evaluated on both synthetic and ShapeNet tasks, and leads to significant improvements compared to Tulsiani et al. that embed a prior structure on learning shape representations as a composition of primitive abstractions. In addition, the technique is also paired with MarrNet to allow for a better 3D reconstruction from 2D images.",0.21052631578947367,0.17475728155339806,0.1909814323607427
2247,SP:cbfb4439fcbf27dc2c05675123b7b0555acdbf33,"The paper presents a graph neural network (GNN) architecture with learnable low-rank filters that unifies various recently-proposed GNN-based methods. The local filters substitute the graph shift operator (GSO) by a learnable set of parameters that capture the local connectivity of each node in the graph. Moreover, a regularization penalty is proposed to increase the robustness of the model and prevent these local structures to overfit. The paper provides proofs to justify the generality of the approach and how different methods can be seen as a particularization of the proposed scheme. Two theorems are also proved to claim the stability of the GNN architecture against dilation perturbations in the input signal. Several numerical experiments are conducted to empirically test the usefulness of the model.","This paper proposed L3Net which is a new graph convolution with decomposing the learnable local filters into low-rank. It can contain both spatial and spectral graph convolution (including ChebNet, GAT, EdgeNet and so on) as subsets. It is also robust to graph noise. Experiments are conducted on mesh data, facial recognition and action recognition, indicating out-performed performance over baselines. Its robustness to graph noise is also tested.",0.12698412698412698,0.2318840579710145,0.1641025641025641
2248,SP:cbff5688c7be72a90c6e2ff6e3629c6feac3717c,"This paper focuses on lossless source compression with bits back coding for hierarchical fully convolutional VAEs. The focus/contribution is three-fold: 1. Improve the compression rate performance by adapting the discretization of latent space required for the entropy coder ANS. The newly proposed discretization scheme allows for a dependency structure that is not restricted to a Markov chain structure in the encoder model q(z|x) and in the generative part of the model p(x,z). This is in contrast with bit-swap[1], which requires a markov chain structure. The dependency structure that is allowed in the proposed method is widely known to perform better than a markov chain structure, which can explain why it improves significantly over Bit-swap [1] (another hierarchical VAE compression algorithm that uses bits back coding.) 2. Increasing compression speed by implementing a vectorized version of ANS, and heaving an ANS head in the shape of a pair of arrays matching that of the latent variable and the observed variable. The latter allows for simultaneous encoding of the latent with the prior distribution and the image with the decoder distribution. 3. Showing that a model trained on a low-resolution imagenet 32 dataset can generalize its compression capabilities to higher resolution datasets with convincing results. ","This paper proposes a method for lossless image compression consisting of a VAE and using a bits-back version of ANS. The results are very impressive on a ImageNet (but maybe not so impressive on the other benchmarks). The authors also discuss how to speed up inference and present some frightening runtime numbers for the serial method, and some better numbers for the vectorized version, though they're nowhere close to being practical.",0.10328638497652583,0.3013698630136986,0.15384615384615385
2249,SP:cc0fa305b4443aa39690c404edc80ecf9c5757ae,"The paper analyzes the property of local and global data manifold for adversarial training. In particular, they used a discriminator-classifier model, where the discriminator tries to differentiate between the natural and adversarial space, and the classifier aims to classify between them while maintaining the constraints between local and global distributions. The authors implemented the proposed method on several datasets and achieved good performance. They also compared with several whitebox and blackbox methods and proved superiority. ","This paper presents a framework for adversarial robustness via incorporating local and global structure of the data manifold. Specifically, the key motivation is that standard adversarial methods typically use only sample specific perturbations for generating the adversarial examples, and thus using them for robustness of the learning model is limited. Instead the paper proposes to capture the global data manifold as well in the robustifying framework. To this end, an objective is presented (4,5) that uses latent data distributions, with the goal that the adversarial perturbations should maximize the f-divergence against the latent distribution of the clean samples. Experiments are provided on several datasets and demonstrate significant performance improvements.",0.2894736842105263,0.1981981981981982,0.23529411764705885
2250,SP:cc400541c428521afdffeede69807daf3180cb17,"The author(s) propose a computationally efficient mean estimator for generative distribution that are ""heavy-tailed"" in nature. The phenomenon of heavy tailed distributions for gradients in the training stage of generative models are common in nature and the proposed method aims to alleviate this problem by constructing a robust gradient estimator in such situation. The proposed methodology is well backed up by synthetic and real data examples. The topic is interesting and the proposed methodology is novel.","The paper studies the problem of high-probability mean estimation for heavy-tailed distributions, i.e., constructing a high-probability confidence intervals for the mean, when the underlying distribution has only finite low-degree moments.  The paper motivates this problem from the view-point of machine learning algorithms, where the gradients are heavy-tailed. 	Especially in deep generative networks, the paper  highlights the heavy-tailed nature of gradients via experiments. On a theoretical side, the paper derives bounds for mean estimation when the distribution has bounded fourth-moments.",0.19230769230769232,0.17045454545454544,0.18072289156626506
2251,SP:cc6c0eb769a3da3f0e311fe6a4b96286f1f98d01,"This paper considers the exploration efficiency issues in off-policy deep reinforcement learning (DRL). The authors identify a sample efficiency limitation in the classical entropy regularization, which does not take into account the existing samples in the replay buffer. To avoid repeated sampling of previously seen scenarios/actions, the authors propose to replace the current policy in the entropy term with a mixture of the empirical policy estimation from the replay buffer and the current policy, and term this approach as sample-aware entropy regularization. The authors then propose a theoretical algorithm called sample-aware entropy regularized policy iteration, which is a generalization of the soft policy iteration (SPI) algorithm, and show that it converges assuming that the empirical policy estimation is fixed. A practical algorithm based on the sample-aware entropy regularized policy iteration, called Diversity Actor-Critic (DAC), is then proposed. This algorithm is a generalization of the well-known soft actor-critic (SAC) algorithm. Finally, numerical experiments show that DAC outperforms SAC and other SOTA RL algorithms, and some ablation studies are also provided to demonstrate the effect of hyper-parameter choices in DAC.","The paper proposes DAC, an actor-critic method exploiting the replay buffer to do policy entropy regularisation. The main idea of DAC is to use the data from the replay buffer to induce a distribution  $q(\cdot, s_t)$ and replace the entropy part of the Soft Actor-Critic objective with a convex combination of $q$ and $\pi$. This results positively on exploration properties and leads to sample-efficiency gains on some of the considered MuJoCo benchmarks.",0.1443850267379679,0.35064935064935066,0.20454545454545453
2252,SP:cc73a630ce68477bde408cc08a92a4f98eb2c597,"The manuscript illustrates how a noisy neural network can reduce the learning capacity. To mitigate this loss, the authors propose a method that combines the method of ""noise injection and ""knowledge distillation"". However, from a conceptual point of view,  their contribution (i.e. (10) in Section 5,) is unclear to me. Specifically,  the authors are not precise about how do they merge the aforementioned previous ideas and come up with the new loss function (10). ","The article on ""Noisy Machines"" addresses the issue of implementing deep neural network inference on a noisy hardware computing substrate, e.g. analog accelerators. This is an important topic because analog devices allow fast and energy efficient inference, which is crucial for inference at the edge. Because of their analog nature such devices suffer from noisy computations, and in this article the case of noisy weights is studied. ",0.13333333333333333,0.14705882352941177,0.13986013986013987
2253,SP:cc84a9b9b02da8079787f6e5de7e1b83d95e8d5f,The paper proposed a transfer learning setting where the target domain varies/evolves over time and the source domain is considered static. The paper uses C-divergence to measure label-dependent domain discrepancy between source/previous target domain and the current target domain and provided a theoretical bound. The paper also used supervised VAE for CONTE algorithm and included C-divergence as a part of the objective function.,"This paper studies how to transfer the information in the static source domain to the time-evolving target domain. This paper proposes a domain discrepancy measure and an algorithm for continuous transfer learning. The results seem to be interesting and the problem this paper studies is important. However, the domain rate in the main results and algorithm could be easily generalized which can make the results more broadly applicable. Moreover, it needs more clarification about the motivation of using the C-divergence measure in the time-evolving target domain.",0.27941176470588236,0.21348314606741572,0.24203821656050958
2254,SP:ccba49bdbf7b0abceacc9b2807c74078f231a3f1,The paper shows that semantic relations associated with mentions can be used to improve fine-grained entity typing. The whole model contains three parts: 1) Base FET Model 2) Hypernym Relation Model 3) Verb-argument Relation Model. Experimental results show that the integrated semantic relation information improves the final performance. The comparisons are extensive. The submission is well suited to the akbc conference.,"This work addresses fine-grained entity typing by leveraging semantic relations of the mention with other words in the same sentence. Specifically, the authors showed how to use hypernym relations and verb-argument relations. For the first, they used Wikidata to train a string match based candidate extraction and BERT-based verification model. For the second, they used an existing SRL system to extract relations between the verb and the mention. Then the two system each produce a prediction that is then combined with the base model through a gating network. The proposed method significantly improves over baselines. And they performed ablations studies to show the help from hypernym and verb-argument.",0.25396825396825395,0.14285714285714285,0.18285714285714283
2255,SP:ccd16b5f5c55b6d5dce275233542c1dade0699c8,"This paper proposes an evolutionary-based method for the multi-objective neural architecture search, where the proposed method aims at minimizing two objectives: an error metric and the number of FLOPS. The proposed method consists of an exploration step and an exploitation step. In the exploration step, architectures are sampled by using genetic operators such as the crossover and the mutation. In the exploitation step, architectures are generated by a Bayesian Network. The proposed method is evaluated on object classification and object alignment tasks.","This paper proposes a search method for neural network architectures such that two (potentially) conflicting objectives: maximization of final performance and minimization of computational complexity can be pursued simultaneously. The motivation for the approach is that a principled multiobjective search procedure (NSGA-II) makes it unnecessary to manually find the right trade-off between two objectives, and simultaneously finds several solutions spanning the tradeoff. It is also capable of finding solutions from the concave regions of the Pareto-front. Multiobjective search for architectures has been explored in recent work, so the primary contribution of this paper is to show its utility in a more general and perhaps more powerful setting.",0.25,0.19090909090909092,0.21649484536082475
2256,SP:ccdb108ba692c4227be899e453faf3c36102ff71,"This paper analyzed the averaged SGD for overparameterized two-layer NNs for regression problems. Particularly, they show that the averaged SGD can achieve the minimax optimal convergence rate, with the global convergence guarantee. To achieve, they propose a new parameter which captures the ``complexities’’ of the target function and the RKHS associated with the NTK.","This paper considers the optimization of a wide two layers neural network (for a regression task) using averaged SGD. The authors consider the Neural Tangent Kernel (NTK) regime. The NTK is a kernel defined using the activation function and the initial distribution of the parameters of the input layer. The RKHS H associated to this NTK is assumed to contain the Bayes predictor. Based on this, the authors derive a convergence rate for the predictor constructed from the T-th iterate of averaged SGD and the Bayes predictor in terms of the L2 distance wrt the distribution of the features. By specifying this bound in terms of the decay of the eigenvalues of the integral operator in H, they obtain an explicit generalization error bound, which is optimal for the class of problems considered in the paper.",0.32727272727272727,0.13138686131386862,0.1875
2257,SP:ccef448cb87c0cac9153d0e5b3b266a6b794c277,"The paper describes a way of representing online handwriting data, typically seen as a discrete sequence, in a continuous space, using neural ODEs. The learned representation allows sampling from and interpolation in the latent space. The results in the paper are compared (mostly qualitatively) to autoencoder-learned representations based on representing data as discrete sequences, Bezier curves, and implicit surface representation from differentable geometrty.","This paper proposes a new model, called SketchODE, for learning representations of sketches using neural ODEs. Specifically, the authors parameterize hand drawn strokes as solutions of ODEs and build an auto encoder like framework for learning the vector fields of these ODEs from data.   The decoder is modelled with a second order neural ODE acting on an augmented state (which allows for self overlapping trajectories which is necessary for handwritten data) that includes the stroke itself as well as an underlying hidden state. The decoder is made conditional by passing a latent vector to the model, which is mapped both to the initial state of the ODE as well as the dynamics function of the ODE. Varying this latent vector and solving the ODE then gives rise to different handwritten patterns.  The encoder is parameterized by a neural CDE which takes as input some ground truth trajectory and returns a new state which is mapped to the latent vector. The model is then trained end to end using a reconstruction loss between the ground truth and reconstructed trajectories.  In addition, the authors show that two additional tricks can further improve performance: using sine activation functions in the MLPs parameterizing the vector fields as well as using perlin noise to create (continuous) augmentations of the data.  The authors then discuss and demonstrate various compelling properties of their model. This includes the existence of a latent space (which allows for interpolation of handwritten data) as well as one shot learning capabilities for new classes of data.  The main contributions of the paper in my eyes are then: - Introducing an interesting continuous neural model of handwritten data - Demonstrating compelling properties of this continuous model over traditional discrete models - Introducing the VectorMNIST dataset, which I believe could be useful for other researchers - Interesting experiments on various handwritten datasets   ",0.3125,0.06578947368421052,0.10869565217391304
2258,SP:cd0d3d64c3bfae598cd59fc7597531d30251dd54,"The paper treats the problem of unsupervised RL, which it defines as the problem of pretraining a system, without having access to a reward function, to learn a collection of policies, that are labeled skills. The idea is that when the reward function is presented, the target policy can be assembled as a combination or composition of these skills. Such policies had been previously proposed to be learned using mutual information maximization approaches.   The primary contribution of this paper that it analyzes the space of policies/skills that are learnable using mutual information based approaches. The authors present this analysis through a geometric lens on the probability simplex of the possible states of the system. A given policy or skill can be associated to a point in this space by associating with a skill or policy its discounted state probability distribution.   Using these analytical tools, the authors prove several interesting results. For instance, they show that by maximizing mutual information alone, one cannot learn sufficient skills to cover all the set of optimal policies - the number of unique skills learned through this approach is bounded by the dimensionality of the state space. ","This paper is trying to analyze whether unsupervised skill discovery is useful for more easily solving any possible downstream tasks in an MDP. It does so by adapting the idea of the value function polytope to a state visitation distribution polytope. It also specifies possible reward functions in this geometric setting and analyzes the connection between points on this polytope and returns with respect to the reward function.  Next, it casts the mutual information based skill discovery problem in this geometric space and tries to analyze the skills learned. From their analysis, the paper suggests ways to infer how many skills can be learned, and whether those skills are optimal with respect to some downstream tasks.  It seems that these skills can be guaranteed to be the vertex of the above polytope, but not to be optimal with respect to all downstream reward functions. They then suggest that the skills learned might be useful for an adaptation procedure that ignores the dynamics of the environment.",0.1875,0.21818181818181817,0.20168067226890757
2259,SP:cd167a1412b5c09594275811b7efebc358e2d121,"An RL based method, called Rewriting-by Generating (RBG), is proposed to solve large-scale VRPs. It borrows the idea of the hierarchical RL agent, which consists of two parts: ""Generator"" and ""Rewriter"". In the generation process, the graph is divided into several sections and in each section, an RL algorithm runs to get the best route. Then, the rewriter gets the solution of all generators and tries to connect them together with the goal of globalizing them with a smaller route. To this end, the rewriter merges each of two sub-problems together and then divides it into another two sub-problem and solves each again. Doing this helps decrease the route length. This diving and merging is learned by an RL agent (think of the outer agent in the hierarchical RL) so that the rewriter learns when and how to do this. The rewriter uses the attention mechanism to choose two parts of the merged routes, and then get a new solution for each part using the inner-agent. To get the initial sub-problems, K-mean clustering is used to get sub-problems of about 100 nodes. In the evaluations, CVRP of size 500, 1000, and 2000 are considered. The results are compared to LKH3 and google OR-Tools, along with RL algorithms. LKH3 slightly outperforms RGB in terms of the tour length in problems of 500 and 1000 nodes, though it takes a longer time to get the solution.","The paper presents a hierarchical reinforcement learning approach to solve large-scale vehicle routing problems (VRPs). A “rewriting agent” is responsible for dividing the customers into regions while a “generating agent” is responsible for computing the vehicle routes in each region, independently. The rewriting agent learns to score pairs of regions to be merged, using as a reward the reduction of VRP cost gained by the merge. The VRP costs are computed by the generating agent, which is based on the attention model of (Kool et al 2019), that is known to perform well for smaller scale VRPs. ",0.10699588477366255,0.2653061224489796,0.15249266862170086
2260,SP:cd3d672f555b7a88704ad3142aca702ec7154258,"This paper proposes to learn the dynamics of an incompressible fluid via a physics informed loss formulation using an unsupervised training framework. It employs a custom solver that is executed at training time to learn a Navier-Stokes residual with a incompressible (curl of a stream function) formulation. This setup is demonstrated for two dimensional karman vortex streets, and a control example for the magnus effect. ","This paper presents a ""physics-informed"" deep learning model of fluid dynamics. The underlying deep learning architecture employed is a somewhat standard u-net, but one of the proposed method's distinguishing features is that it enforces its adherence to physical behavior at its loss terms, by penalizing predictions that are not incompressible or do not conserve momentum. Notably, this approach allows it to be trained unsupervisedly, without requiring the generation of ground-truth simulations.",0.16666666666666666,0.14666666666666667,0.15602836879432622
2261,SP:cd488af7b4ffc290fcd06ca9577156fa67ec3286,"The paper proposes a self-supervised graph representation learning algorithm named BGRL. BGRL employs similar architecture & training mechanism with BYOL and necessary adjustments (e.g., the augmentation methods, dropping the prejector module) to adapt to the characteristics of graph datasets. Given the nature of BYOL-based methods that negative samples are not used during training, BGRL scales only to O(n) when computing the objective function, which essentially breaks the computation limit incurred by the quadratically complex objective function adopted by SimCLR-based models (e.g., GRACE), hence makes the proposed model applicable to large graphs.  The major contributions of the paper are summarized as follows:  (1) The paper highlights and empirically verifies BYOL's advantages in not only boosting task performance but also enhancing model scalability, the second aspect is important but ignored by previous / concurrent BYOL-based methods.  (2) The paper tests the effect of introducing label supervision to the BYOL-based scheme on learning node representations for large graphs, which is not studied in previous / concurrent BYOL-based methods.  (3) The paper evaluated BGRL against other base models on various benchmarks, which not only provides multiple aspects of BGRL's advantages, but also enriches the baselines of unsupervised graph representation learning, especially on large graphs.","This paper proposes BRGL, a method for graph representation learning based on ‘bootstrapping’ (in the same sense BYOL is). Different from the prior art, which mainly relies on contrastive learning, BRGL naturally scales linearly with graph size.  An extensive suite of experiments shows that BRGL scales better than previous works while yielding state-of-the-art (SOTA) performance in node classification. ",0.07692307692307693,0.26229508196721313,0.11895910780669146
2262,SP:cd63a80ffd1039df8b4b470f26353da3ce0022ec,"This paper proposes an autocurricula scheme to train a goal-conditional agent in a dynamic and sparse-rewarding environment. The main idea is to train a setter model to sample goals for next-step training, where the setter can make the decision either based on the training history or the environmental observation (conditional case). The paper proposes three criteria which leads to three types of loss to train the setter model, i.e., goal validity (the goal should be achievable by some existing policy), goal feasibility (how probable the current policy can achieve the goal), and goal coverage (the sampled goals by the setter need to cover all possible goals). A judge model is needed to output the feasibility of a given goal. So the autocurricula scheme contains the solver (agent), the setter, and the judge, each having its own combination of loss and they are trained together. Given a desired goal distribution, the paper proposes to additionally train a discriminator whose optimization objective is Wasserstein loss. In experiments, they evaluate the proposed method on three types of tasks in two environments, i.e., 3D color finding and grid world alchemy. The goals in the two environments are similar in that they all aim to achieve some color or color pairs. The difference lies in that the first one finds colors while the second pick up colors. Each environment can be changed between episodes by changing the colors of objects in the scenes. Experimental results show that different combinations of the three types of losses can bring improvements in some scenarios. Making setter and judge conditioned on environment observation can further improve the success rate. Given a desired distribution of goals, the learning becomes more efficient. The paper compares this method with Goal GAN as a baseline and outperforms it on the three tasks.","This paper tackles the task of automatically inducing a curriculum for agents learning through reinforcement. Specifically, they use two agents — a setter agent that sets goals, and a solver agent that solves the goals provided by the setter.  While this has been explored before, the difficulty lies in training both agents simultaneously in a robust fashion. If the goals are too difficult, the solver will be unable to solve them and if they are too easy, the solver will be unable to improve. The authors propose a combination of different losses to help the setter balance its goal predictions — validity, feasibility and coverage. In addition, they train a judge model predict the reward that the solver agent would achieve on a goal proposed by the setter. Empirical results on two setups demonstrate the effectiveness of this approach in learning a good curriculum. ",0.13486842105263158,0.2887323943661972,0.1838565022421525
2263,SP:cd75cf49f7e773f69c08c6489ec9f63f9a2de4ad,"Neural architecture search usually aims to find a single fixed architecture for the task of interest. The paper proposes to condition the architecture on the input instances by introducing a ""selection network"" that learns to retain a subset of branches in the architecture during each inference pass. The intuition is that easier instances require less compute (hence a shallower/sparser architecture) as compared to the more difficult ones. The authors show improved results on CIFAR-10 and ImageNet in terms of accuracy-latency trade-off over some handcrafted architectures and NAS baselines. The method resembles sparsely gated mixture of experts [1] at a high-level, but has been implemented in a way that better fits the context of architecture search (which is still technically interesting).","This paper proposes an instance-aware dynamic network, ISBNet, for efficient image classification. The network consists of layers of cell structures with multiple branches within. During the inference, the network uses SelectionNet to compute a ""calibration weight matrix"", which essentially controls which branches within the cell should be used to compute the output. Similar to previous works in NAS, this paper uses Gumbel Softmax to compute the branch selection probability. The network is trained to minimize a loss function that considers both the accuracy and the inference cost. Training of the network is divided into two stages: First, a high temperature is used to ensure all the branches are sufficiently optimized, and at the second stage, the authors aneal the temperature. During the inference, branches are selected if their probability computed by Gumbel Softmax is larger than a certain threshold.",0.184,0.16428571428571428,0.17358490566037735
2264,SP:cd78fd328ffefb039b4f7629174f06f582a63920,"This paper is about representing functions $\psi : (\mathbb{R}^d)^n \rightarrow \mathbb{R}$ that are symmetric or asymmetric with respect to the permutation group $S_n$.  The aim is to consider neural networks giving only functions that symmetric or asymmetric, and to establish universality results.  The motivation comes from applications such quantum physics or computer vision with permutation symmetries. ","In this paper the authors study the representability of symmetric or antisymmetric functions using neural networks. In particular, we say f: R^n -> R is symmetric/ antisymmetric if f(x)= f(pi(x)) for all pi in S_n or is of the form f(x)= sign(pi) *f(pi(x)) where sign(pi) is the sign of the permutation. Such functions with such symmetries are ubiquitous in quantum physics since if one looks at the wave function of a  system of identical bosons, then they are symmetric and if you look at fermions they are antisymmetric. In this paper they authors try to understand if there exists succinct architectures that can learn/represent functions with such a symmetry property.  In this direction the author makes a few observations For every ""nice"" antisymmetric function f, there exists a symmetric function Phi and a matrix associated to Phi such that determinant of Phi can be used to represent f.  Then the authors show that the standard Ferminet (the first demonstration of deep learning) can be used to represent determinants of slater determinant and hence an arbitrary continous antisymmetric function.",0.2833333333333333,0.09042553191489362,0.1370967741935484
2265,SP:cd8eaee441e33312233c6d6d41142be9e6b59b9d,"The paper handles the issue of missing values in supervised deep learning settings. The fig.1 describes their method aptly. Their method (supMIWAE) is a combination of a VAE with a neural network classifier. Given the task to predict p(Y|x_{obs}, x_{miss}), the authors view it as a joint model of covariates and outcomes. Their model takes in x_{obs} and first fits a distribution to get x_{miss} and then models them as a joint distribution to predict outcome Y|(x_{obs}, x_{miss}). They use importance sampling technique to get multiple samples from the generative model. ","This paper approaches the problem of supervised learning with missing data. The authors propose a probabilistic approach by jointly modeling the observed data, missing data and outcomes. The main contribution of this model is that they rely on deep generative models which seems to be an improvement from previous methods based on simpler generative models like mixture of Gaussians, for example. With the proposed model, the authors derive an optimization problem that consists in optimizing the discriminative model (classifier) and the generative model simultaneously. For the training and testing phases, the proposed algorithm considers multiple imputations of missing data, which is demonstrated to be superior to single imputation methods. Experimental results on small and simple datasets (2D datasets, MNIST digits-Fashion and regression) are nicely presented and analyzed.",0.1782178217821782,0.140625,0.15720524017467247
2266,SP:cd9024c0331b487fcb0cc13872f3ddb01f57ce15,"This paper proposed a learning algorithm to recover the events of using an appliance and as well as the location of the appliance in a home by using smart electricity meter and a motion sensor installed a home. In the model, the input is a window of electricity energy consumption and context and the output of the model is the location collected by the motion sensor. The appliance activation as the latent variables is learned using a autoencoder architecture. ","Authors proposed a multi-modal unsupervised algorithm to uncover the electricity usage of different appliances in a home. The detection of appliance was done by using both combined electricity consumption data and user location data from sensors. The unit of detection was set to be a 25-second window centered around any electricity usage spike. Authors used a encoder/decode set up to model two different factors of usage: type of appliance and variety within the same appliance. This part of the model was trained by predicting actual consumption. Then only the type of appliance was used to predict the location of people in the house, which was also factored into appliance related and unrelated factors. Locations are represented as images to avoid complicated modeling of multiple people.",0.34177215189873417,0.2109375,0.26086956521739124
2267,SP:cda2c05c55cce270fdb88ee63ad828dc7f91bc7a,"This paper proposes a posterior approximation for BNN that models correlations between the layers weights. The paper begins by pointing out that, for any posterior distribution approximation, the optimal conditional posterior distribution over the top-layer weights given the weights of the previous layers has a closed-form in the case of Gaussian likelihood, which, due to Bayes rule, turns out to be product of the likelihood and the top-layer prior. Based on this insight the paper proposes to model each conditional posterior distribution over intermediate layers weights given previous layers weights following the same structure, that is, as a product of a 'pseudo-likelihood' over unobserved noisy activations and the prior for that layer. In order to make inference tractable, the paper proposes the use of global inducing points as well as noisy pseudo-observations of the activations of intermediate layers which are treated as variational parameters.  The paper also describes how such procedure applies to convolutional neural networks and how it can be applied for DGPs as well.","The paper proposed a new way of doing Bayesian deep learning in which the optimal conditional posterior for the last layer weights could be reached if the inducing input $Z_0$ is chosen to be the input data $X$ and the pseudo-observation for the last layer $V^L$ is the observation $Y$. Instead of factorizing the inducing points The global inducing input $Z_0$ is propagated through the network to ensure posterior dependencies across layers. The authors also extend this idea to deep Gaussian processes so that the latent functions across layers are correlated. Experiments show better performance than previous methods on both synthetic and real datasets, without the need to anneal the weights for the KL term in ELBO.",0.1695906432748538,0.2396694214876033,0.19863013698630136
2268,SP:cddf3d13882b412a10ed5981101b1088f184c647,"The authors propose a uniform sampling technique for deep generative networks (DGNs) inspired by the probabilistic change of variables formula. The technique works with any already trained DGN and does not involve any further training. (Though it does require back propagation w.r.t. the input $x$.) In essence, the algorithm works by drawing many samples N >> K from the DGN, then sampling from these $N$ samples with probability inversely related to their pushforward density (as computed by the change-of-variables formula). ","This paper concerns with uniform sampling from deep generative networks such as GANs and VAEs. The training samples of DGNs are often biased as they are obatined based on preferences, costs, or convenience that leads to DGNs producing biased examples. This paper gives a gemoetry based sampler MaGNET, that given any trained DGN, produces samples that are uniformly distributed on the learned manifold. It theoretically proves, and empirically shows that the MaGNET produces a uniform distrbution on the manifold regardless of the training set distribution. The theoretical proofs require that the DGNs only comprise continuous piecewise affine (CPA) non-linearities, such as ReLu, absolute value, max-pooling. The three main contributions of the paper are as following: (a) It characterizes the transformation incurred by a density distribution when composed with a CPA mapping. (b) It derives an analytical sampling strategy that allows to obtain a uniform distribution on a manifold that is continuous and piecewise affine. (c) It provides multiple numerical experiments validating the gains of their proposed method MaGNET. ",0.24096385542168675,0.11764705882352941,0.15810276679841895
2269,SP:ce02279c05b6c1d89e80f8d2ce16403aa2586ad6,"The paper describes a new method for detecting outliers with deep autoencoders by suppressing the reconstruction of out-of-distribution data. The article first investigates the reasons why standard autoencoders (AEs) reconstruct outlier datapoints fairly well, and are therefore problematic when used to detect anomalies via the reconstruction loss. The main novel contribution is the Energy-based Autoencoder (EBAE), a variant of an autoencoder in which the reconstruction loss is directly used as an energy function, and therefore outliers should have high energy. This is done with a new gradient formulation that enforces normalization of the probability distribution by sampling from the learned model via a variant of Langevin Monte-Carlo sampling. This second term is supposed to punish the reconstruction of outliers. Results are shown on a MNIST holdout task (leave one class out), and for OOD detection in CIFAR-10 and a downsampled version of ImageNet, showing that EBAE learns to reconstruct samples from different datasets, as well as constant and noise inputs, with significantly higher reconstruction error than competing methods.",The authors address an important problem of autoencoders having low reconstruction error for OOD instances. They use the regular inlier reconstruction loss minimization with an additional term to maximize reconstruction loss for fake sampled OOD instances. A two stage Langevin Monte Carlo sampling technique is used for sampling in the proposed EBAE framework to generate diverse samples. Empirical analysis reveals that the proposed method outperforms existing autoencoder baselines. Some of my concerns with this paper are the following,0.12138728323699421,0.2692307692307692,0.16733067729083664
2270,SP:ce086370afe643339b3f7d7a366d9f4dcce9a5aa,"The paper proposes a new loss function which can be used in the reconstruction term of various auto-encoder architectures. The pixel-wise cost function \ell(X, X') = f(X - X'; a) is defined for pairs of two input images X and X' and has one positive real-valued hyperparameter a. For small values of t the function f(t; a) behaves like a quadratic function, while for large t it behaves like |t|. As a consequence, it is smooth, everywhere differentiable (like L2) while not penalizing outliers too hard (like L1). The authors present several experiments conducted on MNIST and Celeba datasets, demonstrating that a simple change of a conventional pixel-wise squared L2 distance with the proposed log-cosh cost function improves the FID scores of generated samples as well as the visual quality of reconstructions (including ""the sharpness""). ","This paper proposes to change the L2 norm of loss function of VAE into hyperbolic cosh function. The idea  and presentation are clear and straightforward. However, the used cosh function does not convince me since when t=a, f(t,a) will still be very large! Also, they will grow fast with exp|at|. The authors are encouraged to provide more detailed proofs for the advantages of cosh function.",0.1347517730496454,0.2753623188405797,0.18095238095238098
2271,SP:ce147e13a4126d022aa6c22dca433ca81062f924,This paper presents a new deep CCA method to learn non-linear relationships between two modalities. It trains two neural networks each for a modality to maximize the total correlations of their output representations. Gating is applied to input variables by associating each with a latent Bernoulli variables which is then relaxed with the clipped Gaussian random variable. Experiments on one synthetic and two real datasets demonstrate the superiority of the proposed method.,"This paper proposes a DL method for learning sparse non-linear transformations that maximize correlations between two views. In particular, each view is passed through a separate network. Stochastic Gating is applied to the input layer of each network. The two networks are jointly trained by maximising the correlation between their outputs. Sparsity is obtained by imposing L0 regularization terms on the Stochastic Gating variables.",0.273972602739726,0.3076923076923077,0.2898550724637681
2272,SP:ce211e46a1eac8bd3e35ccc30621bfdd53ba9a82,"This paper addresses the issue of noisy gradient estimation in a type of evolution strategies popularized by the open AI's reinforcement learning paper. It is a follow-up paper of reference [14], and try to analyze the optimality of the gradient estimation. The goal of the paper is well stated and well motivated. The paper itself is well-organized. However, the novelty of this work is not sufficiently high and its usefulness is questionable. ","This paper provides a new type of gradient estimator that combines an Evolutionary Strategies (ES) style estimate (using function evaluations at perturbed parameters) along with surrogate gradient estimates (gradient estimates that may be biased and/or high variance). The estimator involves computing antithetic ES estimates in two subspaces: along the set of (normalized) surrogate gradients, and along a set of randomly chosen vectors in the orthogonal complement of the span of the surrogate gradients. The paper provides a proof of the optimality of the estimate, that is, the proposed gradient estimate maximizes the cosine of the angle with the true gradient over the vectors in the subspace defined by the set of surrogate gradients and sampled directions. The paper proposes an additional mechanism for generating surrogate gradients by simply using previous gradient estimates as surrogate gradients, and derives a convergence rate for when this iterative estimator will approximate a fixed, true gradient (e.g. for linear functions). Finally, the paper applies the estimate to two tasks: MNIST classification and robotic control via reinforcement learning, demonstrating improvements on both compared to standard ES.",0.3333333333333333,0.13736263736263737,0.1945525291828794
2273,SP:ce4275ab9437fd5c73c61a5ff17ed24881fdd717,"The paper claims that smooth activations are more reproducible than ReLU. The accuracy gain claims seem marginal and not carefully carried out, further ablation studies are needed to strengthen the conclusion on accuracy. However, the main point of the paper is reproducibility where the feature is measured by the ‘Prediction Difference’. PD (introduced in section 2) is a measure over a set of models where the PD score is low if the models output consistent estimates for the same validation samples. ","This paper addresses the problem that deep neural networks (DNNs) can lead to different predictions (even when they are initialized the same way) due to the stochasticity of samples selected in mini-batch SGD and update procedures from different optimizers, which leads to convergence to different regions along the loss surface.  They attribute this problem to the complicated loss surface that arises from the discontinuity in relu activations. They show that smooth activations can help remedy this issue, by tuning the activation to become more relu-like, which leads to a better tradeoff between prediction differences (i.e. consistency) and model accuracy.  ",0.14814814814814814,0.11764705882352941,0.13114754098360654
2274,SP:ce4b30f5da82d5d28aabe201cf6180b230ff4e26,"In the paper ""Adaptive Discretization for Continuous Control using Particle Filtering Policy Network"", the authors introduce a new way to discretise the action space of agent in RL settings by using a Particule Filtering approach. The main idea is that the learned policy will output the weight of each particle to define which one should be used, while the position of the particle changes during the learning process. Particles that are not moved (because they have a weight that is systematically too low) are removed and resampled from other particles. ","This paper presents an approach to multimodal policies based on Gaussian mixtures. The policy is parameterized as a set of Gaussian distributions (with state-invariant mean and variance) weighted by state-dependent mixture weights, which are the output of a (softmaxed) network. The weighting network and the means and covariances of the Gaussians are updated with standard RL losses. The authors propose a resampling scheme for mixture elements that consistently have low weight, in the style of resampling in particle filters. The authors evaluate the method with several RL algorithms including PPO and SAC, and on a variety of environments. ",0.17777777777777778,0.16,0.16842105263157894
2275,SP:ce4cfc10fe405005267e62712d939275d2847128,"In this paper, an unbiased estimator for expectations over discrete random variables is developed based on a sampling-without-replacement strategy. The proposed estimator is shown to be a Rao-Blackwellization of three existing unbiased estimators with guaranteed reduction in estimation variance. The connections of the method to other gradient estimators are discussed. Experimental results on several toy and real-data DL/RL problems are reported to demonstrate the applicability of the proposed estimators in the practice of machine learning. ",This paper introduces an gradient estimator for loss functions that are expectations over discrete random variables. The basic idea is that an estimator over a discrete distribution can be Rao-Blackwellized by conditioning on the event that the discrete realization was produced by being the first sample drawn from an unordered set of samples drawn with replacement. Much of the paper is spent showing how this Rao-Blackwellized estimator can be computed in practice and how it compares to other known estimators.,0.2625,0.25609756097560976,0.2592592592592593
2276,SP:ce6ab36fc3d97a419858fb6f5dd6a0425a389b8b," The paper provides benchmarking of some of the popular active learning methods on CIFAR10, SVHN and FashionMNIST datasets. Effects of factors such as choice of backbone, data augmentation, optimizers, learning rate, cold vs warm starting are studied and the conclusions are provided as best practices. Analysis is also performed w.r.t using unlabeled data, choosing the initial labeled pool (random vs K-Means++/K-Center), and unsupervised pre-training of the backbone. ","This paper conducts an extensive analysis of state-of-the-art Active Learning (AL) methods (Coreset, BADGE, LL4AL, JLS, and WAAL) and studies the effect of different training settings (Backbone architecture, Initializing backbone weights, Optimizer, and learning rates, with and without data augmentation) and their effect on AL evaluation for image classification. It also highlights the main factors that can influence the performance of AL methods: the construction of an initial training set following a certain strategy instead of random sampling, and pretraining the backbone of the network in an unsupervised manner. In addition, it provides solid benchmarks to compare new with existing methods in sections 5 and 6.",0.273972602739726,0.1834862385321101,0.21978021978021978
2277,SP:ce7160f4223a048b2adadbd5d6e766551bed300e,"This paper discusses why inaccurate one-hot label in contrastive learning cannot reveal well semantic similarities between samples, and how these inaccurate label assignment would impair its generalization for semantic instance discrimination.   To address this issue, a novel self-labeling refinement method is proposed to obtain more accurate labels for contrastive learning. This is done via two complementary modules that respectively generates accurate soft-labels and enhances semantic similarity between queries and their positives during training.  Both theoretical analysis and empirical results are provided to support the claims made in this paper.","The paper argues that the one-hot label for instance discriminative contrastive loss will impair the performance in downstream tasks. By assuming ground-truth soft labels, the authors prove that the generalization of the network depends on the discrepancy between ground-truth soft labels and refined labels. Therefore, two approaches, SLR and MM are proposed to address the issue. Empirically, the proposed approach outperforms the baselines by non-trivial margins.",0.16304347826086957,0.21428571428571427,0.18518518518518517
2278,SP:ce7d5818ec4598134e27b2f5bc346686d95f8f70,"This paper proposes a method, called Triangular Dropout, to allow a fully connected layer in a network to have variable width at deployment, which is achieved by applying a lower-triangular mask to the output of the fully-connected layer. Experiments were conducted in three different scenarios, autoencoder, image classification, and reinforcement learning. Results show that models trained with Triangular Dropout retain most of their performance when being ablated.","This paper proposes Triangular Dropout, a mechanism for training fully-connected layers whose width can be decreased at test time, by using dropout masks with a particular structure at train time. The proposed approach compares favorably to previous methods when training autoencoders of varying bottleneck size on MNIST. Authors show that Triangular Dropout can also be used to tune the parameter count - accuracy trade-off at test time on VGG-19. Finally, the proposed method is used to measure task complexity in RL by using the minimum layer width required to solve the task as a proxy.",0.2608695652173913,0.18556701030927836,0.21686746987951808
2279,SP:ceb502f2595c97afdce83fd3a98bcacbdb98e5c5,"This paper shows a linear speedup in FedAvg w.r.t. number of devices, mainly theoretically, while most prior works ignore it. The main convergence results are given for three cases: a) Strongly Convex+Smooth, b) Convex+Smoth, and c) Strongly/x convex+Smooth+0 training loss can be achieved. The paper is well-written and motivated with good discussions of the algorithm and the related works. ",This paper gives convergence analysis for FedAvg and its accelerated version under data heterogeneity and system heterogeneity. The main improvement comes from a more careful analysis for one-step descent where the authors make use of the term $\alpha_{t} \sum_{k=1}^{N} p_{k}\left[F_{k}\left(\mathbf{w}^{*}\right)-F_{k}\left(\overline{\mathbf{w}}_{t}\right)\right]$ that is ignored by previous work Li (2020b). The paper focuses on how FedAvg’s convergence scales with the number of participating devices. It improves previous analysis for FedAvg under more federated settings and shows that FedAvg has linear speedup for any number of participating devices. ,0.1791044776119403,0.1111111111111111,0.13714285714285712
2280,SP:ced0bf1b82967fcf2184a2b6acafb486cbaafad8,"This paper studies the generalization properties of the stochastic weighted majority vote (MV) classifiers, where the weight of the MV follows another distribution over MVs. The proposal allows a direct analysis of the risk of the stochastic MV instead of analyzing through other empirical quantities, which leads to tighter bounds. By taking the distribution over MVs to be Dirichlet distributions, the authors also provide an exact and an approximation method to optimize the parameters of the distribution.","The authors propose an algorithm for learning a *stochastic* weighted majority vote classifier, by optimizing a (PAC-Bayesian) generalization bound. They consider Dirichlet distributions over classifiers as well as general measures, and derive analytical and numerical schemes, respectively, for optimizing both. They empirically evaluate the algorithm for several datasets and model classes (decision stumps and random forest). They also compare against deterministic weighted majority vote classifiers learned by optimizing Gibbs classifiers via existing PAC-Bayes bounds (first order, secord order, C-bounds, etc). The resulting stochastic predictor achieves competitive performance and bound tightness compared to ones obtained by minimizing alternative bounds.",0.15584415584415584,0.1188118811881188,0.1348314606741573
2281,SP:cefb35a0bba2e8d3b11b1c81bde283b4e0699da6,"This work examines the recently proposed randomized smoothing method for certifying the robustness of neural networks. The authors explain a theoretical framework for analyzing randomized smoothing as a certification method, propose two alternative definitions of robustness (D_MR and D_inf), and prove that using Gaussian noise for smoothing is near “optimal” for L2 robustness, while using exponential noise for smoothing is optimal for L_inf robustness (the authors do this by establishing a lower bound on the noise necessary for smoothing to work). This also leads the authors to the interesting conclusion that randomized smoothing may not be scalable to high dimensional data for L_inf robustness.","The authors propose a new definition for robustness of random functions. This definition is ideal for analyzing the certified robustness under randomized smoothing techniques. They analyze and show that the Gaussian smoothing is near optimal for \ell_2 smoothing as the mean maximum error is only off by a factor of log d where d is the dimension from the optimal mean maximum energy. This is the case even under a more strict definition of robustness defined as D_\infty. Moreover, the authors show that indeed smoothing with an exponential family  is optimal under D_\infty robustness metric with radius measured in \ell_\infty.",0.25,0.25961538461538464,0.2547169811320755
2282,SP:cf0aed09560d12961f718e915b72a2c5403c4e4a,"This work proposes a simple pruning method that dynamically sparsifies the network during training. This is achieved by performing at fixed intervals magnitude based pruning for either individual weights or entire neurons. While similar methods have been explored before, this work proposes a slight twist; instead of updating the weights of the model by following the gradient of the parameters of the dense model, they update the parameters of the dense model according to the gradients of the sparse model. Essentially, this corresponds to a variant of the straight-through estimator [1], where in the forward pass we evaluate the compressed model, but in the backward pass we update the model as if the compression didn’t take place. The authors argue that this process allows for ``feedback” in the pruning mechanism, as the pruned weights still receive gradient updates hence they can be ``re-activated” at later stages of training. They then provide a convergence analysis about the optimization procedure with such a gradient, and show that for strongly convex functions the method converges in the vicinity of the global optimum, whereas for non-convex functions it converges to the neighbourhood of a stationary point. Finally, the authors perform extensive experimental evaluation and show that their method is better than the baselines that they considered.","In this paper, the authors proposed a novel model compression method that uses error feedbacks to dynamically allocates sparsity patterns during training. The authors provided a systematic overview of a good number of existing model compression algorithms depending on the relative order of pruning and training processes. The effectiveness of the proposed algorithm is illustrated by comparing its generalization performance with 6 existing algorithms (and their variants) with two standard datasets and various networks of standard structures. The authors also showed the convergence rate and the fundamental limit of the proposed algorithm with two theorems. ",0.11574074074074074,0.2631578947368421,0.1607717041800643
2283,SP:cf0db5624fc03cd71e331202c16808174b4a9ae7,"This paper proposes a new LSTM architecture called LH-STM (and Double LH-STM). The main idea deals with having a history selection mechanism to directly extract what information from the past. The authors also propose to decompose the history and update in LH-STM into two networks called Double LH-STM. In experiments, the authors evaluate and compare their two architectures with previously proposed models. They show that their architecture outperforms previous in the PSNR, SSIM and VIF metrics.","The paper proposes a type of recurrent neural network module called Long History Short-Term Memory (LH-STM) for longer-term video generation. This module can be used to replace ConvLSTMs in previously published video prediction models. It expands ConvLSTMs by adding a ""previous history"" term to the ConvLSTM equations that compute the IFO gates and the candidate new state. This history term corresponds to a linear combination of previous hidden states selected through a soft-attention mechanism. As such, it is not clear if there are significant differences between LH-STMs and previously proposed LSTMs with attention on previous hidden states. The authors propose recurrent units that include one or two History Selection (soft-attention) steps, called single LH-STM and double LH-STM respectively. The exact formulation of the double LH-STM is not clear from the paper.  The authors then propose to use models with LH-STM units for longer term video generation. They claim that LH-STM can better reduce error propagation and better model the complex dynamics of videos. To support the claims, they conduct empirical experiments where they show that the proposed model outperforms previous video prediction models on KTH (up to 80 frames) and the BAIR Push dataset (up to 25 frames).",0.3625,0.13875598086124402,0.20069204152249134
2284,SP:cf11852f87d71e71dc4e5327eef4236db46fe1d5,"In this paper, the authors present a natural image model based on the manifold of image patches.  It is similar to the Deep Image Prior in that it is untrained and has a convolutional-like structure.  It leads to an optimization problem with a reconstruction loss term and an auto encoding term.  The authors show empirical results in time series recovery, non-semantic inpainting, and super resolution.  In the image processing tasks, the performance of the proposed algorithm is on par (sometimes slightly worse, sometimes slightly better) than that of DIP.","This paper introduces a transformation from the deep image prior (DIP) to an embedding with an autoencoder (MMES). The authors aim to use this transformation to explain (""in words"") why the DIP works so well and explain why convolutions are needed in the DIP. The contributions are summarised as a) providing an interpretable analogue to the convnet, b) demonstration of the proposed method's effectiveness, and c) characterisation of the DIP as a ""low-dimensional patch-manifold prior"".",0.25274725274725274,0.2948717948717949,0.272189349112426
2285,SP:cf1ec0a8c98ae674d784d1ec3275bc1cbacf404f,"The paper describes a video summarization model that is trained to use either user provided query or automatically generated dense  captioning to select key-frames as summaries.  At the core of the approach is an attention mechanism that computes similarity between frame embeddings and text embeddings. Subsequently, each frame representation is replaced by a weighted-average (softmaxed) of the language embeddings; key and value embeddings are from the text model while query embeddings are from the image model. Finally, a score is assigned to each frame via a standard transformer based model. A post-processing step converts the key frame scores to key-shot level summaries such that only 15% of the videos are selected. The overall model is trained with a weighted Binary cross-entropy loss. ","This paper unified the generic video summarization method and the query-based video summarization method. Specifically, the paper proposed a language guided video summarzation approach that takes both video frames and text as input and summarizes the video frames under the influence of the text. For generic video summarization, the model relies on a video captioning method to provide the text guidance. The proposed approach achieves superior performance on both generic video summarization datasets and the query-based video summarization datasets.",0.14960629921259844,0.2345679012345679,0.1826923076923077
2286,SP:cf2a87c633ea31f81e59e310d79f3fa0b4c4b031,"This paper proposes a methodology for reverse engineering adversarial perturbations. This allows a defender to recover the original image used to produce an adversarial example and may be an effective tool to mitigating adversarial example attacks.  The paper introduces the concept of reverse engineering adversarial perturbations, defines metrics that quantify reverse engineering performance, creates a framework for training a denoising model to find the adversarial perturbations, and compares the resulting model against adversarial denoising techniques.","The paper considers the problem of automatically reconstructing adversarial perturbations from examples in a post-hoc manner. The authors argue that for an effective reconstruction, it is not sufficient to only minimize the reconstruction error but also it is essential to align the predictions of the original and their reconstructed versions. To achieve these goals, the authors combine a denoising network, with a prediction alignment network via a standard combination of their respective losses. The authors incorporate data augmentation to further improve the performance of their approach. The empirical result indicates that the new architecture is able to better balance the prediction alignment and the reconstruction error than the baselines.",0.22666666666666666,0.15454545454545454,0.18378378378378377
2287,SP:cf446212c3be85660aea33c9604c240473a42105,"This paper presents Neural Markov Logic Networks  (NMLN), which is a generalization of Markov Logic Networks (MLN). Unlike MLN which relies on pre-specified first-order logic (FOL) rules, NMLN learns potential functions parameterized by neural networks on fragments of the graph. The potential function can possibly take into account the constants present using embeddings to better solve transductive problems（otherwise the potential can only use relational structure). To make computation tractable, the size of local potential functions is constrained. Training of this MRF is performed by solving a min-max entropy problem: conditioned on an informative potential, the uncertainties shall be decreased. Experiments on a knowledge base completion task and a graph generation task show superior performance compared to baselines like neural theorem provers.","The following paper provides an extension to Markov Logic Networks(MLNs), by removing their dependency on pre-defined first-order logic rules.  This is handled via neural networks which are able to capture the statistical relations, so-called Neural Markov Logic Networks(NMLNs). As this is an implicit representation from the neural network, the rules act as potential functions on the MLN structure. As general MLN techniques are reliant on domain experts or exhaustive structure learning approaches, NMLNs are able to model more domains as provided in the work with knowledge-base completion tasks and generative modelling of molecules. ",0.192,0.24242424242424243,0.2142857142857143
2288,SP:cf50b8861f21b6e45ce531f9ad879d62f378eaf2,"The authors propose a new method of securely evaluating neural networks. The approach builds upon existing Trusted Execution Environments (TEE), a combination of hardware and software that isolates sensitive computations from the untrusted software stack. The downside of TEE is that it is expensive and slow to run. This paper proposes outsourcing the linear evaluation portions of the DNN to an untrusted stack that's co-located with the TEE. To achieve privacy (i.e., the input isn't revealed to the untrusted evaluator), the approach adds a random number r to the input vector x, evaluates f(x+r) on the untrusted stack, then subtracts off f(r) from the output. This limits the approach to be applicable to only linear functions. To achieve integrity (verify the correctness of the output), the paper proposes testing with random input vectors (an application of Freivalds theorem, which bounds the error probability). The techniques for integrity and privacy works only on integer evaluations, hence the network weights and inputs need to be quantized. The paper tries to minimize degradation in accuracy by quantizing as finely as numerically allowable, achieving <0.5% drop in accuracy on two example DNNs. Overall, compared to full evaluation in a TEE, this approach is 10x faster on one DNN, and 40x to 64x faster on another network (depending on how the network is formulated).","Given the growing interest in building trust worthy and privacy protecting AI systems, this paper demonstrates a novel approach to achieve these important goals by allowing a trusted, but slow, computation engine to leverage a fast but untrusted computation engine. For the sake of protecting privacy, this is done by establishing an additive secret share such that evaluation on one part of the share is performed offline and the computation on the other part of the share is performed on the untrusted engine. To verify the correctness of the computation on the untrusted server, a randomized algorithm is used to sample the correctness of the results. Using these techniques, the authors demonstrate an order of magnitude speedup compared to running only on the trusted engine and 3-4 orders of magnitude speedup compared to software-based solutions.",0.15859030837004406,0.26277372262773724,0.19780219780219782
2289,SP:cf54053f38d5ac81a33d41beb16dfb7f33d1e7b0,The paper presents a method for deriving multi sense word embeddings. The key idea behind this method is to learn a sense embedding tensor using a skip-gram style training objective. The objective defines the probability of contexts marginalised over latent sense embeddings. The paper uses Gumbel-softmax reparametrization trick to approximate sampling from the discrete sense distributions. The method also uses a separate hyperparameter to help scale the dot product appropriately. ,"  This paper extends the skipgram model using one vector per sense of a word. Based on this, the paper proposes two models for training sense embeddings: One where the word senses are marginalized out with attention over the senses, and the second where only the sense with highest value of attention contributes to the loss. For the latter case, the paper uses a variant of Gumbel softmax for training. The paper shows evaluations on benchmark datasets that shows that the Gumbel softmax based method is competitive or better than other methods. Via a crowdsourced evaluation, the paper shows that the method also produces human interpretable clusters.",0.2638888888888889,0.1792452830188679,0.21348314606741572
2290,SP:cf57db4d77bafc3f7741422fe54e9eb2d1ab7051,"This paper analyzes the invariance properties of the K-FAC algorithm by reconstructing the algorithm in a coordinate-free way where the neural network is viewed as a series of affine mappings alternating with nonlinear activation functions. It converts the original metric into an approximate metric, whose coordinate representation matches the K-FAC approximation. So K-FAC can be viewed as the exact natural gradient under the new metric rather than an approximation under the Fisher metric.","Natural gradient (NG) has been proven efficient in statistical learning, and one of its attractive properties is being invariant under smooth transformations of the parameter space. Computing NG is often difficult as one has to derive the Fisher matrix and its inverse. K-FAC offers an approximate method for approximating the NG with the risk of losing the invariant property.",0.14285714285714285,0.18333333333333332,0.16058394160583941
2291,SP:cf5a5f9660d0aab430057bbe11ed925e0b9419d6,"In this paper, the authors propose a layer-wise model aggregation scheme in federated learning cases to reduce the communication cost. Specifically, they quantified the model discrepancy between local models and global models and adaptively adjusted the aggregation interval in a layer-wise manner. By increasing the aggregation intervals and relaxing the aggregation frequency, the method can reduce the communication cost in federated learning cases. The experimental results show it can reduce the communication cost for IID data and non-IID data compared to FedAvg.",This paper developed an adaptive aggregation method for federated learning. The theoretical analysis shows how the interval affects the convergence rate. The experiments show that it can reduce the communication cost. ,0.2,0.5483870967741935,0.2931034482758621
2292,SP:cf90c83667e2974b91b0d93c12c5987491314005,Neural Architecture Search (NAS) aims to find a model with the best possible accuracy (or best possible accuracy/size tradeoff) from within a human-defined search space. One popular strategy for speeding up NAS is to train a one-shot model -- a single set of shared weights -- that can then be used to evaluate any candidate architecture within the search space without retraining or fine-tuning. The submission investigates how various decisions made when training a one-shot model can affect its ability to rank different candidate architectures within a search space.,"This work analyzes commonly used heuristics for training the supernet in weight sharing NAS. The authors first proposes a new metric, sparse Kendall-Tau, to measure the quality of the supernet. Then extensive experiments are conducted on three NAS benchmarks to empirically evaluate the heuristics, and pick the best settings. To highlight the significance of the training quality of supernet, the author showed that random search, when combined with the best settings, can performs competitive to SOTA results. ",0.14130434782608695,0.16666666666666666,0.15294117647058822
2293,SP:cfbe7ae1f40e2c23a6161d04e3229bc860c79042,"of the paper:  Learning from label proportions (LLP) is an area in machine learning that tries to learn a classifier that predicts labels of instances, with only bag-level aggregated labels given at the training stage.  Instead of proposing a loss specialized for this problem, this paper proposes a regularization term for the LLP problem. The core contribution of this paper is to use the idea of consistency regularization, which has become very popular in semi-supervised learning in the recent years.  The regularization term takes a perturbation of an input sample, and then force the output of the original and perturbed sample to be similar by minimizing  a KL divergence of the two output distributions.  Experiments show the performance of the proposed method under two bag generation settings.  The paper also finds empirically that the hard L_1 has high correlation with the test error rate, which makes it an ideal candidate when the user splits the validation data from training data (meaning there are no ground truth labels for each instances).",This paper proposes using Consistency Regularization and a new bag generation technique to better learn classification decision boundaries in a Label Proportion setting.  The consistency regularization works to make sure that examples in the local neighbourhood have similar outputs. The authors further use K-means clustering to create a new bagging scenario they use to mimic real-world LLP settings. ,0.08092485549132948,0.23333333333333334,0.12017167381974247
2294,SP:cfcc0751394443ee8179098ee4fec54128f668a3,This work proposes that most relevant datasets to the machine learning community today have support on a mixture of disconnected components. They argue that popular GAN models cannot fit distributions of this kind and provide a number of proofs to convince the reader of this claim. The authors discuss a number of simple modifications on top of standard GANs which can alleviate this issue. These include replacing the standard unimodal latent distribution of the generator with a mixture model and replacing the standard generator with an ensemble of generators. The authors demonstrate that by replacing the standard GAN with an ensemble (or a pseudo-ensemble) they can achieve improved performance over a standard GAN given a fixed parameter budget with respect to a number of different evaluation metrics. ,"This paper addresses the problem that models like GANS which learn continuous mappings from a connected latent space, are incapable of producing a mapping that contains disconnected components. The authors argue that real-world classes like ""badger"" and ""zebra"" are indeed disconnected and thus the inability of GANs to learn a disconnected mapping poses a problem. The authors formalize the statement and argue instead that one should learn an ensemble of GANs. These aren't really ensembles as in classification but components of a mixture model. They are using each GAN to represent one component of a mixture distribution. They also argue that conditional GANs and GANs with mixture distributions over the latents are similar. The paper closes with interesting but insufficient experiments showing the benfits of ensembles of GANs on one dataset (CIFAR10).",0.203125,0.19402985074626866,0.1984732824427481
2295,SP:d02cf08c6b78934d9bceb1fced353db460da192b,"This paper proposes a new framework for unsupervised domain adaptation by applying the disentangled representations learning (DiCyR). The core idea of DiCyR is to split the raw feature into the task-related one and its complimentary context where the task-related representations are projected into a shared space for alignment. From my point of view, disentangled representations learning is the most interesting part of this work.","This paper studies the domain adaptation problem by addressing the challenge of splitting task-specific and task-orthogonal information in the target domain using the proposed disentangled cyclic reconstruction method. The authors further develop a variant for the unsupervised domain adaption (UDA) task. The authors argue that the existing adversarial classifier based UDA solutions do not guarantee that the domain specific information does not contain any information that overlaps with the shared information in the target domain. Another shortcoming of these baselines is the learned representation in their domain-invariant feature space might not allow for accurate labeling in the target domain. To solves these limitations, the authors directly minimize the information sharing between representation, instead of using domain adversarial classifier and adversarial label predictor.",0.24242424242424243,0.128,0.16753926701570682
2296,SP:d038f28f90bdf4625c61eefe75dd062ebf583fc8,"This paper analysis and studies translation invariance in convolution neural networks. It argues that typically it is claimed that CNNs are translation invariant due to the convolution function, and that actually convolution are equivariant. While pooling is the actual function that gives local invariance (or global when the pooling is across all locations), this is not included in the description of invariance. One neural network, VGG-16, is used for the analysis in different scenarios: 1) pre-trained on Imagenet and fine-tuned to the new dataset on one location 2) trained from scratch using the new dataset in one location 3) trained from scratch using the new datasets in all locations of the canvas and test on the other datasets. The main conclusion in the paper is that CNNs are not invariant to translation by design of the architecture, but that when pre-trained on naturalistic images, they can be. ","This paper addresses the problem of how convolutional neural networks (CNNs) achieve translation invariance, and the authors argue that this invariance es mostly learned from suitable datasets, rather than a result of the architecture. In particular, ImageNet-pretrained networks have learned to be invariant to translation, and fine tuned. The experiments are performed in MNIST-like datasets evaluating classification performance at different locations. The authors conclude that invariance is achieved when the CNN is trained with the different objects being presented at different locations across the canvas, and that the invariance can be forgotten after subsequent training.",0.19205298013245034,0.29896907216494845,0.2338709677419355
2297,SP:d0393690be2cffce0618681c819a41cee75f1434,"The author proposes an algorithm that improves DPSGD by using public data to identify a lower-dimensional space where the gradients lie in. They show that the algorithm can provide a better convergence guarantee, specifically, p reduced to log(p). They also conducted experiments to show the proposed algorithm outperforms the generic DPSGD especially at small epsilon with a small amount of public data.","The paper considers the problem of solving differentially private empirical risk minimization. To reduce the dependence on dimensionality $p$, they propose Projected DP-SGD (PDP-SGD) that projects the noisy gradients to a low-dimensional subspace computed from a free public dataset at each iteration. They prove that PDP-SGD is differentially private and has only a logarithmic dependence on $p$.",0.140625,0.14754098360655737,0.144
2298,SP:d082c56e6a6ece9511c88e7b99b49271922a11e0,"This paper addresses long-text generation, with a specific task of being given a prefix of a review and needing to add the next five sentences coherently.  The paper proposes adding two discriminators, one trained to maximize a cosine similarity between source sentences and target sentences (D_{coherence}) and one trained to maximize a cosine similarity between two consecutive sentences.  On some automatic metrics like BLEU and perplexity, an MLE model with these discriminators performs a little bit better than without.","The paper proposes a method for improving the quality of text generation by optimizing for coherence and cohesion. The authors develop two discriminators--a ""coherence discriminator"" which takes as input all of the sentence embeddings (i.e. averaged word embeddings) of the document and assigns a score, and a ""cohesion discriminator"" which takes as input the word embeddings of two consecutive sentences and assigns a score. In the former, the score is the cosine similarity between the encodings of the first and second half of the document. In the latter, the score is the cosine similarity between the encodings of the two sentences. Both discriminators use CNNs to encode the inputs. The discriminators are trained to rank true text over randomly drawn negative samples, which consist of randomly permuted sentence orderings and/or random combinations of first/second half of documents. This discriminators are then used to train a text generation model. The output of the text generation model is scored by various automatic metrics, including NLL, PPL, BLEU, and number of unique ngrams in the outputs. The improvements over a generically-trained generation model are very small.",0.30864197530864196,0.13297872340425532,0.18587360594795538
2299,SP:d0a64bf0e31cd45a6682309dd26e5ae8a51c2e8a,This paper proposes a simple regularizer for RL which encourages the state representations learned by neural networks to be more discriminative across different observations. The main idea is to (implicitly) measure the rank of the matrix which is constructed from a sequence of observations and state feature vectors and encourage the rank to be high. This paper introduces three different objectives to implement the same idea (increasing the rank of the matrix). The experimental results on Atari games show that this regularizer improves A3C on most of the games and show that the learned representations with the proposed regularizer has a high rank compared to the baseline. ,"The authors propose the notion of ""expressiveness"" of state representation by simply checking the effective rank of the state vectors formed by a sampled trajectory. The authors then propose a regularizer that promotes this expressiveness. Experiments on a large set of Atari games show that this regularizer can improve the performance of reinforcement learning algorithms.",0.17757009345794392,0.34545454545454546,0.2345679012345679
2300,SP:d0d4a8c48f25248a697b59b83a6fa79026f837ac,"This paper tackles the problem of hand and object segmentation. At inference, the model takes a single image and the 2D location of the hand and outputs a hand-object segment. The key idea is to extract supervision from optical flow by contrastive learning. ","This paper addresses a novel problem of segmenting the object which is contacted by hand from a singe image. Since there are no annotations for this task, the authors present an approach to mine pseudo labels from videos based on optical flow. In particular, the authors assume that the contacted object has similar motion fields as the hand. The method works well for many cases except when objects are not moving or not moving in planar planes as also discussed in the paper. The experimental results demonstrate the effectiveness of the approach.",0.2727272727272727,0.13043478260869565,0.1764705882352941
2301,SP:d0fa6a5ae7db3a14eed64b94f79c2677689c396d,"The paper proposes a new algorithm for propagating gradients through neural ODEs, which minimizes peak memory requirements by checkpointing not only the individual solver steps but also the internal stages. The considered, specific, partitioned Runge--Kutta method has symplectic properties and provides exact gradients. The experiments demonstrate the reduced peak memory cost together with competitive runtimes. ","In this paper, the authors propose a new adjoint method for training neural ODEs, named the symplectic adjoint method, which is an adjoint method solved by a symplectic integrator. The proposed symplectic adjoint method obtains the exact gradient with memory proportional to the number of uses plus the network size. Numerically, the authors show that the symplectic adjoint method consumes much less memory than the naive backpropagation algorithm and checkpointing schemes, and performs faster than the adjoint method, and is robust to round off errors.",0.25,0.16470588235294117,0.19858156028368795
2302,SP:d10de5e45dc6a79787c2167e2ab7fd1dc9c9a4e1,"This paper seeks to solve program translation problem through code retrieval. It proposes an interactive code retrieval system, called iPTR to perform cross-language retrieval with minimum code pairs. The method extracts textual features and structural features from code and transform the features into target-language features through an autoencoder, which is trained through a uni-language manner. It further leverages users' correction to update feature representation and for new round of retrieval.","This work proposes a retrieval-based approach for program translation. Existing ML/DL models for program translation typically design a decoder to directly generate the code in the target language. On the contrary, this work designs iPTR, which first computes a feature representation of the target code, then retrieves the most similar code in a large code corpus. Specifically, iPTR includes a query transformation model (QTM), which generates the feature representation of the target code, given the feature representation of the source code as the input. The feature representation includes the information of tokens in the code, and the paths in the syntax trees. The idea of using the paths is similar to the code2vec paper. QTM could be trained without parallel data between source and target codes. Specifically, encoders and decoders of different programming languages could be trained in a similar way to the training of autoencoders. This idea is similar to TransCoder. Meanwhile, they show that iPTR could be trained with active learning and user feedback, where they use active learning to acquire limited parallel training data, and user feedbacks are corrections of the wrong output code. They compare their approach to existing ML/DL program translation models, as well as code retrieval systems. They show that iPTR performs better than other baselines, even without active learning and feedbacks. Not surprisingly, active learning and incorporating user feedbacks further improve the performance.",0.2465753424657534,0.07725321888412018,0.11764705882352941
2303,SP:d11f0eb42f1ea12686290a2936b5aee262c8d84d,"The article ""PairNorm: Tackling Oversmoothing in GNNs"" considers the interesting phenomenon of performance degradation of graph neural network when the depth of the network increases beyond the values of 2-4. The authors argue that one of the reasons for such behavior is so-called ""oversmoothing"", when intermediate representations become similar for all the nodes in the graph. The authors propose the special NN layer ""PairNorm"", which aims to battle with this issue.","It is known that GNNs are vulnerable to the oversmoothing problem, in which feature vectors on nodes get closer as we increase the number of (message passing type graph convolution layers). This paper proposed PairNorm, which is a normalization layer for GNNs to tackle this problem. The idea is to pull apart feature vectors on a pair of non-adjacent nodes (based on the interpretation of Laplace-type smoothing by NT and Maehara (2019)). To achieve this approximately with low computational complexity, PairNorm keeps the sum of distances of feature vectors on all node pairs approximately the same throughout layers. The paper conducted empirical studies to evaluate the effectiveness of the method. PairNorm improved the prediction performance and enabled make GNNs deep, especially when feature vectors are missing in the large portion of nodes (the SSNC-MV problem).",0.2465753424657534,0.13043478260869565,0.17061611374407581
2304,SP:d154782d1a48802582244b6aa037e8483f58ef19,"This paper proposes a sliced version of the Bures distance, which is a lower bound on the 2-Wasserstein distance. The purpose behind this is to identify instances that are have the highest contribution towards the discrepancy between two distributions. But compared to other sliced OT distances, this one operates on a the Bures lower bound, which yields a more tractable solution. The paper presents experimental results on image classification datasets, which are claimed to show an advantage of the proposed variant over the full sliced Wasserstein distance .","This paper studies a family of integral probability metric (IPM) divergence on Hilbert spaces. This family can be characterized by the choice of the witness function, and specific witness function may give rise to the Bures distance, the MMD, Wasserstein, as well as many sliced variants. While this family has been well understood for distributions on finite dimensional space, this paper extends this insight to distributions on (possibly infinite dimensional) Hilbert space. By leveraging the representer theorem, the paper provides the finite dimensional optimization problems that can be solved to estimate the divergence from samples. The power of the method is demonstrated on the covariate shift experiments.",0.22727272727272727,0.18691588785046728,0.20512820512820512
2305,SP:d17896673440629f058db587e1c34eeed7a0ce5f,"This paper looks at adversarial examples from the context of RKHS norms for neural networks.  The work builds conceptually on the work of Bietti and Mairal (2018), who investigate approximate RKHS norms for neural networks (including computation via a specialized convolutional kernel), and Xu et al., (2009) which looks at robustness properties of kernel classifiers.  The authors discuss how the RKHS norm of neural network functions provide robustness guarantees for the resulting classifier, both in terms of a straightforward robustness property for a given example, as well as in terms of generalization guarantees about robustness.","In this paper, the authors consider CNN models from the lens of kernel methods. They build upon past work that showed that such models can be seen to lie in appropriate RKHS, and derive upper and lower bounds for the kernel norm. These bounds can be used as regularizers that help train more robust neural networks, especially in the context of euclidean perturbations of the inputs, and training GANs. They show that the bounds can also be used to recover existing special cases such as spectral norm penalizations and gradient regularization. They derive generalization bounds from the point of view of adversarial learning, and report experiments to buttress their claims.",0.18947368421052632,0.16363636363636364,0.175609756097561
2306,SP:d18240d9eca55834f96c0223924e425a38685368,"This paper proposes a framework to select the neural networks for downstream tasks. To identify the better generalization model, the authors propose a new metric (Neural Capacitance, NCP) to predict precise learning curves. And the authors provide the theoretical explanations for NCP.  Then the authors have verified the advantages of the proposed method when being applied to different datasets (CIFAR10, CIFAR100, SVHN, Fashion MNIST, Birds) with 17 CNN models.",Accurately predicting the performance at early stage is important for efficient model selection without incurring too much computation. The paper proposes a neural capacitance metric as a predictive measure to capture the performance of a model on the downstream task using only a handful of early training results. The metric is derived from a line graph mapped from a neural network by modeling the dynamical system of the network.,0.2028985507246377,0.2028985507246377,0.2028985507246377
2307,SP:d197f9ea345b135b417400d791002f18baad39e7,"The paper considers learning hyperbolic representations for unsupervised 3D segmentation. Since the general task of producing annotations for 3D data can be expensive (e.g. for segmentation in dense voxel grids), this is an important problem. The paper proposes to learn hierarchical data structures (e.g. 3D biomedical images) with a hyperbolic variational autoencoder. The paper adapts different metric learning approaches, such as triplet loss and computing a Frechet mean on Riemannian manifolds for clustering. ","The authors of this manuscript propose an unsupervised learning framework for 3D segmentation of biomedical images. Specifically, the proposed method learns effective representations for 3D patches using variational autoencoder (VAE) with a hyperbolic latent space. Its main contribution lies at that it introduces a new unsupervised learning framework including hyperbolic convolutional VAE and hierarchical triplet loss. This work conducts experiments on toy dataset, the Brain Tumor Segmentation dataset, and cryo-EM data. The experiment demonstrates competitive performance of the proposed method.",0.2,0.18518518518518517,0.1923076923076923
2308,SP:d1bf5f544aab913ab3803635f8fda80e05af6bfb,This paper proposes a way of extending Hindsight Experience Replay (HER) to dynamic or moving goals. The proposed method (DHER) constructs new successful trajectories from pairs of failed trajectories where the goal accomplished at some point in the first trajectory happens to match the desired goal in the second trajectory. The method is demonstrated to work well in several simulated environments and some qualitative sim2real transfer results to a real robot are also provided.,The authors propose an extension of hindsight replay to settings where the goal is moving. This consists in taking a failed episode and constructing a valid moving goal by searching prior experiences for a compatible goal trajectory. Results are shown on simulated robotic grasping tasks and a toy task introduced by the authors. Authors show improved results compared to other baselines. The authors also show a demonstration of transfering their policies to the real world.,0.21621621621621623,0.21333333333333335,0.21476510067114093
2309,SP:d1ed10fc70ad59ec4b69fa48a20155835e655b2d,"The paper applies the techniques from reward-free RL literature to the constrained RL setting. They propose a meta-algorithm that takes a reward-free RL solver and uses it to solve the approachability and constrained-RL problems with convex constraints. The proposed approach comes with an overhead factor that is logarithmic in the number of samples.   They apply this approach to provide sharp analysis on three different settings: tabular VMDPs, linear VMDPs and two-player VMGs. ","The paper introduces a connection between reward-free and constrained MDPs. The interesting result in the paper is the fact that it is possible to use any reward-free method to solve constrained and approachability problems. In particular, they show that starting from an RFE method with sample guarantees, it is possible to obtain guarantees in these settings paying only a small cost. This meta-framework can be used to solve many different problems (e.g., tabular and linear problems). ",0.2597402597402597,0.25,0.25477707006369427
2310,SP:d1f2bfa043d6ce88a18bbef8a0e694e92ab43d2e,"This paper introduces a method on semi-supervised graph classification. For each graph, the method first constructs another view based on the cosine similarity between nodes' features, and from the two views (topology and feature similarity), GCN and GAT are applied to extract representations. All node representations are further combined via two layers of attentions. A diversity loss that encourages dissimilarity between the learned representations of GCN and GAT is introduced to the cross-entropy loss for joint optimization. The whole framework makes sense in terms of learning meaningful node representations for classification. However, the method lacks novelty, it is an incremental development on the existing graph neural networks. The choice of GCN and GAT as the building blocks are not well justified. It is also possible to try other kinds of GNNs. The statement on GAT ""ignores the inherent structure of the graph space"" on page 4 is confusing since it learns weights based on the graph structures. The experimental results show the better performance of the proposed method, but are not well analyzed. It may be better to compare with other multi-graph methods such as","The paper presents a GNN model to jointly encode both topology and feature graphs to enhance node representations' quality. In particular, the model DGCN uses two GCNs to learn and propagate two different types of node representations on the topology graph, respectively. The model also utilizes two GATs to learn and propagate two different types of node representations on the feature graph, respectively. Finally, the model leverages attention mechanisms on these four types of node representations to produce the final node embeddings.",0.13829787234042554,0.3170731707317073,0.1925925925925926
2311,SP:d203a332170f0f196a66a40e4b23ac99e07aeb7f,"This manuscript empirically show that adversarial training in large-batch training scenario has better performance than traditional data augmentation. And furthermore, the authors proposed a simple method to conduct adversarial example generation and gradient computation w.r.t. to weights concurrently to accelerate the adversarial training in distributed setting. The key strategy is to use staled weights to generate adversarial examples, and then decoupled the bi-level optimization. ","This paper presents a simple algorithm named ConAdv to incorporate adversarial training into the large-batch training setting such that one can further increase the batch size without harming too much accuracy while maintaining the high utilization of the hardware. The core idea is to use adversarial training to improve the accuracy for large batch training and at the same time use stale weights to allow parallel computation of the adversarial example and the normal gradient updates. With his simple yet novel approach, the paper has demonstrated good performance on ImageNet with batch size as large as 96k while maintaining the accuracy above MLPerf's 75.9.",0.27941176470588236,0.17757009345794392,0.2171428571428571
2312,SP:d20be056d12806215020db73c46174288e688706,"The method proposes an algorithm for Offline Reinforcement Learning. The work starts from the idea that behavioral cloning struggles at learning from data coming from several policies but, on the contrary, easily learns a behavior policy if initialized with a “close” policy. A curriculum is thus built for behavioral cloning to efficiently learn the “best policy shown in the dataset”. For this, a behavioral cloning is trained on a sequence of trajectories defined the following way: the next trajectory selected for training is the most probable according to current policy. The trajectories-dataset is then filtered by saying that the return should be above a threshold given by a running average of the trajectories seen so far. ","This paper applied Online Imitation Learning to offline RL. The central idea is, at each iteration of training, the proposed approach will sample the data points from the neighboring policies based on the experience picking. The intuition is built based on the observation/analysis of the discrepancy between demo policy and initialized imitating policy.  I like how authors scrutinized their observations with theoretical analysis. The neighboring policy picking targets at solving the ""dilemma"" of quantity-quality. However, the main technical contribution is not super very in-depth, authors tackle the KL-divergence constraints through the assumption that each trajectory is sampled by a single policy, which I am not sure whether it is very practical as claimed by authors (yield good bound and performance as illustrated in experimental studies).",0.20512820512820512,0.18604651162790697,0.1951219512195122
2313,SP:d26682cab15475af1eedf1431fb8596e311b965d,"This paper proposes a robust Bayesian deep metric learning framework against noise label inspired the BLMNN (Wang & Tan, 2018), deep metric learning (Hoffer & Ailon, 2015; Hu et al., 2015; Wang et al., 2017; Lu et al., 2017; Do et al., 2019), and Bayes by Backprop (Blundell et al., 2015). Directly applying the variational Bayes learning (Wang & Tan, 2018) in deep learning is challenging since it requires sampling from a distribution of the neural network parameters. Instead, this paper adapts the variational inference by Blundell et al. (Blundell et al., 2015), which allows to efficiently sample the parameters of a Bayes neural networks by using a backpropagation-compatible algorithm. The experimental results on several noisy data sets show that our novel proposed method can generalize better compared to the linear BLMNN (Wang & Tan, 2018) and the point estimation-based deep metric learning (Hoffer & Ailon,","This paper introduces a Bayesian deep metric learning framework that is robust against noise labels. The proposed method is inspired by the BLMNN (Wang & Tan, 2018), deep metric learning (Hoffer & Ailon, 2015; Hu et al., 2015; Wang et al., 2017; Lu et al., 2017; Do et al., 2019), and Bayes by Backprop (Blundell et al., 2015).  Different from BLMNN that only considers a linear metric learning, the authors’ framework can handle non-linear deep metric learning, which is useful for many real-life applications. Moreover, directly applying the variational Bayes learning (Wang & Tan, 2018) in deep learning is challenging since it requires sampling from a distribution of the neural network parameters. Instead, The author adapt the variational inference by Blundell et al. (Blundell et al., 2015), which allows to efficiently sample the parameters of a Bayes neural networks by using a backpropagation-compatible algorithm. They also theoretically show the robustness of the proposed method when working with label noise. The experimental results on several noisy data sets show that their novel proposed method can generalize better compared to the linear BLMNN (Wang & Tan, 2018) and the point estimation-based deep metric learning (Hoffer & Ailon, 2015; Lu et al., 2017), especially when the noise level increases. In my opinion, the main novelty of this",0.951048951048951,0.6384976525821596,0.7640449438202247
2314,SP:d26829f8a3a08c2935f10ab5871b847fd11c9887,This paper focus on providing both differential privacy and adversarial robustness to machine learning models. The authors propose an algorithm called differentially private adversarial learning (DPAL) to achieve such goal. DPAL consists two sub-models: (1) An auto-encoder to extract feature representation; and (2) A classifier takes the embedding of encoder and return the predict logits. The auto encoder uses the reconstruction loss and the classifier uses the similar loss as in adversarial learning. ,"This paper propose an algorithm with DP preservation to train adversarially robust neural networks. To preserve DP, a single-layer linear autoencoder with shared weights is learned to extract features from training data, whose encoder is used to extract private features for the training and inference of a deeper network. To enhance robustness against various attacks, adversarial examples crafted with such attacks are injected into the training set in this algorithm. Guarantees of privacy preservation for training on both clean data and adversarial examples for the autoencoder and the inference network are given. Certified robustness of the smoothed classifier is also given, which depends on the privacy budget of each compositing mechanism. Experimental evaluations of two small (2 and 3 conv layers) networks are given on the MNIST and CIFAR10 dataset, showing improved conventional accuracy on clean samples and adversarial attacks, and certified accuracy than 4 baseline privacy-preserving algorithms.",0.26666666666666666,0.13333333333333333,0.17777777777777776
2315,SP:d2a7acc9e746f3db643d59d854b2bc91b6a6a35e,I appreciate the work the authors did by collecting a large dataset that can be used as a benchmark of ethical assessment across different moral concepts. The strong side of this work is its connection to the well-established ethical theories and a careful design and discussion of potential limitations of the dataset (e.g. cultural differences and ambiguous judgements). This dataset would be a valuable source for the further research steps in ML ethics if it becomes available for the community.,"The authors present a large and thoroughly constructed dataset, containing various types of data points, spanning major aspect of ethics. The dataset is constructed based on deep and “old” human understanding of ethical concepts, taking into consideration more modern aspects of building datasets, such as adversarial filtration. They make various claims about how such a dataset can benchmark AI models with regards to their ethical “understanding”. Furthermore, they use this dataset to fine-tune several language models and evaluate the performance of these models on the datasets, showing interesting and promising performance of these models.",0.1951219512195122,0.16842105263157894,0.1807909604519774
2316,SP:d2a8d90ecc5c406db6ffcd61e45dba647295a898,"This paper proposes a new variant of local SGD algorithm to make it be more realistic. In particular, (1) it allows workers to perform different number of local steps, depending on their computational resources; (2) workers are organized in a multi-level structure. Workers connected to one central hub can synchronize frequently and hubs are communicated in an infrequent and decentralized manor.","This paper extends (Wang & Joshi, 2018) and proposes MLL-SGD for training models in hierarchic networks, where the network consists multiple sub-networks, and each sub-network contains multiple workers. In the level of sub-networks, models can be averaged. In the level of workers, the local copies of models can be averaged within a sub-network; however, workers cannot communicate directly with those from a different sub-networks. In such setting, MLL-SGD is proved to enjoy certain convergence property.",0.1935483870967742,0.14814814814814814,0.1678321678321678
2317,SP:d2b9bdcb5035b77770f20f5c1f3608e398886842,"This paper empirically investigates the effect of different reward-prediction models for model-based reinforcement learning (MBRL) in the particular context of decision-time planning with the cross-entropy method and visual tasks. To that end, five models are evaluated: four models that predict rewards and observations jointly, while one model only learns to predict rewards but without observation prediction. The authors claim that predicting observations in addition to rewards improves performance of MBRL in their setting (in terms of cumulative reward maximization). This hypothesis is tested on a bunch of tasks from the DeepMind Control Suite, both in an online and offline setting. The authors conclude, based on their experiments, that their hypothesis can be confirmed.","The paper proposes a simple taxonomy of objectives for training predictive models for planning in visual model-based RL, and evaluates them in a set of consistent experimental tasks and using a largely consistent set of models. It claims that in the context of the models investigated, backpropagating losses based on future observations yields better performance than using only the reward as training signal, and that prediction accuracy of future observations is also more predictive of task performance than reward prediction errors. It additionally empirically demonstrates the magnitude of effect exploration policies can have in this setting, showing how a lot of the models that perform worse online simply explore less well. ",0.21367521367521367,0.22321428571428573,0.21834061135371177
2318,SP:d2d5800a67dc1972370362f55665a8fe2f25f961,"The paper deals with a relevant issue. The simplified supervised learning setting is a good way of looking at the issue of non-stationarity in isolation and it makes a compelling case that neural networks optimized by SGD can have generalization issues in settings where the data distribution changes over time, even after the data distribution converges. The solution proposed by the paper is simple and can be applied to most off-the-shelf RL algorithms. My main criticism would be that the hybrid objective feels rather ad-hoc and that the proposed method could use a bit more theoretical justification. Also, since the issue being tackled here is quite general to RL, a wider set of benchmarks and base-algorithms (in addition to PPO) would be necessary to get a better picture.","This paper investigates an interesting problem that transient non-stationarity can affect the generalization of the neural network. This paper first conducts experiments on a supervised learning task to illustrate that transient non-stationarity can lead to degenerated performance on testing set. Then, the paper proposes an RL algorithm called ITER to avoid the negative impact of such non-stationarity.",0.09774436090225563,0.21666666666666667,0.13471502590673576
2319,SP:d2fa25043c067418b73ec48dca54c1105a611856,"This paper studies the problem of learning the parameters of a two-layer (or one-hidden layer) ReLU network $y=A\sigma(Wx)$, under the assumption that the distribution of $x$ is symmetric. The main technique here is the ""pure neuron detector"", which is a high-order moment function of a vector. It can be proved that the pure neuron detector is zero if and only if the vector is equal to the row vector of A^{-1}. Hence, we can ""purify"" the two layer neural network into independent one layer neural networks, and solve the problem easily.","This paper pushes forward our understanding of learning neural networks. The authors show that they can learn a two-layer (one hidden layer) NN, under the assumption that the input distribution is symmetric. The authors convincingly argue that this is not an excessive limitation, particularly in view of the fact that this is intended to be a theoretical contribution. Specifically, the main result of the paper relies on the concept of smoothed analysis. It states that give data generated from a network, the input distribution can be perturbed so that their algorithm then returns an epsilon solution. ",0.3163265306122449,0.31958762886597936,0.317948717948718
2320,SP:d30f90a1fcfc6cb120ed92d1f36b3e4312948201,"This paper studies the permutation symmetry of deep neural networks. It was known that by reordering neurons and their connections in each layer, the input -> output map the neural network represents can be preserved. This corresponded to a set of unconnected equivalent points in the weight space. The authors study the weight-space connectivity of these points through midpoints they call “permutation points”. They demonstrate that such points are members of high-dimensional manifolds of equivalent points. After that, they look at empirical experiments and explicitly construct a path between two equivalent weight-space points on a toy task and MNIST.","The paper presented a method for studying the landscape of the loss function w.r.t. parameters in a neural network from the perspective of weight-space symmetry. The detailed method includes constructing/optimising a low-loss path in between two parameter vectors (incoming connections from the previous layer) of two neurons respectively, and then set the output weight vectors (outgoing connections to the next layer) to be the same without changing the output of the current layer. ",0.1485148514851485,0.19230769230769232,0.16759776536312848
2321,SP:d3299ff1a9838da59e00b18add7185466d239bcc,"In this paper, the author proposed a transformer-based encoder-decoder framework for label-free text style transfer. The described task under the unsupervised setup is important and instructive for the text style transfer domain. The model architecture is well demonstrated and the writing is easy to follow up. The experiment results show satisfying performance even comparing with state-of-the-art supervised methods. ","This paper proposes a novel approach to the label-free style transfer task where an input is corrupted via different strategies and fed into an auto-encoder which is additionally conditioned on its prior adjacent context sentence via a ""style encoder"" which adds its mean pooled hidden state to the former before decoding.  Both encoders are initialized to and leverage the strength of pre-trained T5 model.  Additionally the amount of addition/deletion of tokens is tunable at both training and inference time.  ",0.25,0.1927710843373494,0.217687074829932
2322,SP:d32cc190926af44697a23cc7022707c4df75ed2e,"This paper has a simple message. When predicting families (weight vectors) of labels, it makes sense to use an ensemble of predictors and average them using a Wasserstein barycenter, where the ground metric is defined using some a priori knowledge on the labels, here usually distances between word embeddings or more elaborate metrics (or kernels K, as described in p.8). Such barycenters can be easily computed using an algorithm proposed by Benamou et al. 18. When these histograms are not normalized (e.g. their count vectors do not sum to the same quantity) then, as shown by Frogner, Zhang et al, an alternative penalized formulation of OT can be studied, solved numerically with a modified Sinkhorn algorithm, which also leads to a simple W barycenter algorithm as shown by Chizat et al.","The paper proposes a framework based on Wasserstein barycenter to ensemble learning models for a multiclass or a multilabel learning problem. The paper has theoretically shown that the model ensembling using Wasserstein barycenters preserves accuracy, and has a higher entropy than the individual models. Experimental results in the context of attribute-based classification, multilabel learning, and image captioning generation have shown the effectiveness of Wasserstein-based ensembling in comparison to geometric or arithmetic mean ensembling.",0.10526315789473684,0.18666666666666668,0.13461538461538464
2323,SP:d3804a2538416b73935cbece4344fa8ad9d4bbe9,"This paper proposes a universal and unsupervised GNN-based representation learning (node embedding pretraining) model named PanRep for heterogeneous graphs, which benefits a variety of downstream tasks such as node classification and link prediction. More specifically, employing an encoder similar to R-GCN, PanRep utilizes four different types of universal supervision signals for heterogeneous graphs, i.e. cluster and recover, motif, metapath random walk and heterogeneous info maximization, to better characterize the graph structures. PanRep can be further fine-tuned in a semi-supervised manner with limited labeled data, known as PanRep-FT, for specific applications. Experiments on benchmark datasets have shown the effectiveness and performance gain over other unsupervised and some supervised baseline approaches. One example use case is applied to COVID-19 drug repurposing to identify potential treatment candidates. ","This paper proposed introduces a problem formulation of universal unsupervised learning. They develop an unsupervised node representation learning method by combining four signals: (1) cluster and recover supervision, (2) motif supervision, (3) metapath random walk supervision, and (4) heterogeneous information maximization. Aside from conducting experiments on node classification and link prediction, they apply their method on drop-repurposing knowledge graph to discover drugs for Covid-19.",0.19083969465648856,0.3787878787878788,0.2538071065989848
2324,SP:d39fbf20324d392c4b0cbbf7fc40451d38285e6f,"The paper demonstrates that incorporating equivariance (i.e. symmetries) into model for predicting fluid dynamics improves its performance, especially when the test distribution is transformed by those symmetry groups. Leveraging the recent literature on equivariant CNNs, the paper proposes a CNN model that is equivariant with respect to known symmetries of the Navier-Stokes equations (time/space translation, rotation, uniform motion, and scaling). This approached is validated on 2 datasets on fluid dynamics: a synthetic dataset on Rayleigh-Benard convection and a real-world ocean dynamics dataset. On the synthetic dataset, the proposed models demonstrate better performance under distribution shift. On the real-world dataset, the models yields predictions that are more accurate and physically consistent.","This paper studies improving the modeling of physical dynamics with equivariant neural networks. In particular, this paper focuses on a new type of data governed by physical models. Several special symmetry groups are considered to better characterize the system, including uniform motion equivariance, resolution-independent scaling, and resolution-dependent scaling, etc. Simulation results show that the proposed equivariant model yields better accuracy and physical consistency than the non-equivariant models even with data augmentation, given the type of distributional shift is known. Results on the real-world data show some of the equivariant models can generalize better than the non-equivariant models.",0.1810344827586207,0.20588235294117646,0.19266055045871558
2325,SP:d3aa27250b7c2d199bcddffcb491f7e2a647fc45,"This paper presents PDLP, a practical first-order method for linear programming (LP) that can solve to the high levels of accuracy that are expected in traditional LP applications. The proposed algorithm is matrix-free and can scale to very large problems. The core idea is based on the saddle-point reformulation of LP and the celebrated primal-dual hybrid gradient (PDHG) method (cf. Chambolle and Pock, 2011). Combined with several new techniques, e.g., diagonal preconditioning, presolving, adaptive stepsizes and adaptive restarting, PDLP improves the state-of-the-art approaches, including SCS, by a significant margin. Experimental results on PageRank applications are encouraging.  ","The paper applies the primal-dual hybrid-gradient (PDHG) method (also sometimes referred to as Chambolle-Pock algorithm) to solve very large linear programs. The motivation is to solve problems which are out of reach for commerical LP solvers that are based on simplex or interior-point approaches. Moreover, the algorithm is admissible to highly parallel computation due to the simple update rules of PDHG.   The main contribution is a careful combination of existing heuristic which are known to speed up PDHG in practice: restarts, ""line search"" and preconditioning.  In experiments, this combination of heuristics is shown to substantially improve a basic PDHG baseline. Contrary to existing wisdom, it is shown that FOMs, when enhanced with good heuristics, can indeed find highly accurate solutions to large-scale problems.  ",0.18269230769230768,0.1484375,0.16379310344827583
2326,SP:d3d5b63a44519237d64cc3087c26a5c910a6e17e,"This paper proposes to use Consistency Regularization for training GANs, a technique known to work well in unsupervised learning. The technique consists in applying a transformation to real images and enforcing that the features of the discriminator between the transformed inputs and the original inputs are similar. The author show that using this technique enables them to improve the performance of a standard GAN significantly on CIFAR10. They also carry an ablation study studying the influence of the different part of the proposed technique.","The paper presents a new regularization technique termed consistency regularization for training GANs. The idea is the following: the authors propose to penalize the sensitivity of the last layer of the discriminator to augmented images. This idea is simple yet efficient: it is easy to implement, a regularization term is gradient-free, and its computation is up to 1.8 times faster than standard gradient-based regularization techniques. The authors tested different augmentation techniques and concluded that simple ones behave better (e.g., shifting and flipping). The experimental results show an impressive gain in FID measure, renewing the current state-of-the-art score for class conditional image generation on CIFAR-10 dataset. ",0.23809523809523808,0.17699115044247787,0.20304568527918782
2327,SP:d3e5ddd5bff36693dda6d3fb3fc19ab47706ec74,"It is an interesting idea about how to enforce the Lipsthitz constrain in WGAN by using virtual adversarial training. The connection between virtual adversarial and this paper method - ALR is quite simple and clear. In the experiments, the FID score in the table is not complete which can not clearly compare the ability of the Lipschitz regularization to other regularization methods. The paper addresses that the approximation of r_{adv} will affect the performance of ALR. How to balance the quality and computation complexity is quite important. This paper did not provide the reason about why this method can not work better than GP method in high-dimensional setting.","Virtual Adversarial Training (Miyato et al., 2017) can be viewed as a form of Lipschitz regularization. Inspired by this, the paper proposes a Lipschitz regularization technique that tries to ensure that the function being regularized doesn’t change a lot in virtual adversarial directions. This method is shown to be effective in training Wasserstein GANs. ",0.13761467889908258,0.2727272727272727,0.18292682926829268
2328,SP:d442ae98d8f485119b8fdd7070d16a7cabc0f9ea,"This submission numerically shows that during exploring the neural network landscape,  GD flow keeps increasing the sharpness.  As a result, GD with a fixed learning rate will exhibit two phases during the dynamics.  Denote by $\eta$ the fixed learning rate.  In the first phase, GD follows closely to the GD flow, and it finally converges to a region where the sharpness is roughly $2/\eta$.  Then, it transits into the second phase during which the sharpness hovers right at or above $2/\eta$. In the second phase, GD cannot increase the sharpness anymore due to the dynamical stability constraint. Thus, the authors name it the Edge of Stability phase.  What is interesting is that in the edge of stability phase, the loss is still decreasing steadily although not monotonically. ","This paper presents an interesting observation for GD. That is, the sharpness of the learnt model in the final phase of the training (measured by the largest eigenvalue of the training loss Hessian) hovers right at the value 2/\eta while the training loss. At the same time, the loss goes to unstable and non-monotonically decreasing. This pattern is consistent across architecture, activation functions, tasks, loss functions and BN. Comprehensive experiments are conducted to show this common observation. The paper is easy to follow.",0.17054263565891473,0.25882352941176473,0.205607476635514
2329,SP:d453f2c264d38a6ad28961e224c7a42d0c1e0939,"This paper proposes A*MCTS, which combines A* and MCTS with policy and value networks to prioritize the next state to be explored. It further establishes the sample complexity to determine optimal actions. Experimental results validate the theoretical analysis and demonstrate the effectiveness of A*MCTS over benchmark MCTS algorithms with value and policy networks.","This paper presents the search algorithm A*MCTS to find the optimal policies for problems in Reinforcement Learning. In particular, A*MCTS combines the A* and MCTS algorithms to use the pre-trained value networks for facilitating the exploration and making optimal decisions. A*MCTS refers the value network as a black box and builds a statistical model for the prediction accuracies, which provides theoretical guarantees for the sample complexity. The experiments verify the effectiveness of the proposed A*MCTS. ",0.36363636363636365,0.25,0.2962962962962963
2330,SP:d45b7399209937f6c1af318573d6106beff29dcf,This work targets better ranking performance after supernet training in NAS. The authors leverage meta-learning to make the shared supernet weights adaptive to randomly sampled subnetworks. Experiments are conducted on NAS-Bench-201 and MobileNet space.,"The paper proposed an improved training strategy for oneshot NAS supernetworks. The key idea is to view the training of each subnetwork as a ""task"", and then to apply an MAML/Reptile-style meta-learning scheme to ensure efficient cross-task adaptivity. Experiments on NAS-Bench-201 and ImageNet show improved calibration between the supernet’s predictions and the architectures' true rankings.",0.32432432432432434,0.1935483870967742,0.24242424242424238
2331,SP:d489a94958b9f496aa7713249451c5ffe0c6892c,"This paper is about generating adversarial examples for some target model and protecting from such attacks.  Authors consider a setting when an adversary has access to some ""similar to target "" domain data, and can use this data to generate a surrogate model. Using this surrogate model an adversary can generate adversarial examples, that apparently also fool the target model. Then authors also propose a defense mechanism from this type of attack, Learn2Weight. This is a learnt network that, for a given example, returns perturbation of weights to the target model which will be applied to the target before inference. This model is trained by a defender on synthetic domains generated as perturbations to the target data","The paper considers the adversarial attacks via a surrogate model constructed using data from a different domain. The authors propose a defense from such attacks by a special kind of adversarial training inspired by the idea of domain adaptation. The idea can be useful but raises a lot of questions, especially when looking at the evaluation of the proposed approach.",0.16379310344827586,0.31666666666666665,0.21590909090909088
2332,SP:d4a56729d5384ebab0169c5416ae7e5348522f23,"This paper introduces a functional extension of the Bregman Lagrangian framework of Wibisono et al. 2016. The basic idea is to define accelerated gradient flows on the space of probability distribution. Because the defined flows include a term depending on the current distribution of the system, which is difficult to compute in general, the authors introduce an interacting particle approximation as a practical numerical approximation. The experiments are a proof-of-concept on simple illustrative toy examples.","This paper derives accelerated gradient flow formula in the space of probability measures from the view of optimal control formalism. The generalization of variational formulation from finite space to the space of probability measures seems new, but the resulting PDE seems to be a known result, which is the Fokker-Planck equation (with some minor modifications) for the 2nd order Langevin dynamic. From this point of view, the resulting algorithm from the derived PDE seems not having much practical advantage over SGHMC (a stochastic version of 2nd order Langevin dynamics).",0.2597402597402597,0.2222222222222222,0.23952095808383234
2333,SP:d4bbe950c85fca32385520bf998941552e7543c1,"The paper connects the optimization method, mirror descent, to the study of the policy optimization method. Based on the mirror descent principle, the paper proposes the MDPO algorithm, which updates the policy via approximately solving a trust-region problem. The paper proposes the on-policy and off-policy variants of MDPO. Furthermore, the paper connects the on-policy MDPO to PPO and TRPO and connects the off-policy MDPO to SAC. The contribution of the paper is to provide a unified viewpoint of several RL algorithms and shows that   MDPO performs equally or better than TRPO, PPO, and SAC in different tasks. ","Summary: Inspired by recent theoretical analysis of TRPO and PPO that use mirror descent, this paper proposes two new algorithms that directly minimize a mirror descent objective by taking multiple gradient steps. While similar to TRPO and PPO, MDPO is different in important ways, and happens to perform better in practice. The authors also propose a similar off-policy version of MDPO that happens to be closely related to SAC while also outperforming SAC experimentally.    ",0.1568627450980392,0.21333333333333335,0.1807909604519774
2334,SP:d4f153b454e26d9a63adbe656cee46437fe8f252,"In this paper, the authors propose a policy learning strategy that is patient-driven and interpretable. They focus on the case of organ transplant, not predicting matching but rather whether an organ will be accepted by a clinician for their patient. The authors show that their method perform on par with other approaches, with the added benefit that the decision space is interpretable and can be investigated.","This paper proposes a ML procedure (or framework) for understanding donor organ acceptance decisions for patients on an organ waiting list. Their framework uses NNs for both learning a latent space (encoder/decoder), and for identifying policy criteria for the patient decision function. They include a variety of constraints (consistency, partial monotonicity, model complexity) that are salient to a real organ allocation setting. They lightly discuss their results on real data from UNOS.",0.1791044776119403,0.1643835616438356,0.17142857142857143
2335,SP:d4fd62a9542f068cffd3aabe30ae8dd7991284e2,"This paper proposes a new machine learning setting called “Continual Few-Shot Learning” which fuses the up until now disparate paradigms of continual learning and few-shot learning. To evaluate methods in this new setting, a new benchmark and dataset called SlimageNet64 are defined. Various methods are evaluated on the new benchmark establishing a set of baseline results for the new setting.","This paper proposes a benchmark for a new task called continual few-shot learning. The benchmark is based on the ImageNet dataset. Basically, the model looks at a part of the support set one after another sequentially, and it is then evaluated on the query set that contains balanced samples from each part of the support set. Under the benchmark, there are four types of challenges, which differs in how they sub-partition the support set. A suite of models have been run and evaluated, including MAML, ProtoNet and SCA. SCA is found to have the best performance, whereas ProtoNet is found to be the most resource efficient.",0.3225806451612903,0.18518518518518517,0.2352941176470588
2336,SP:d50fb34a105a8212a0766593cc4f7edaea560f9f,"This paper proposes a novel analysis for optimal separable convolution considering the number of parameters and FLOPs. The idea is to constraint the input information consumed stationery throughout the optimization of the parameters for separable convolutions. More specifically, this paper proposes the notion of volumetric receptive field and by holding it constant throughout optimization, one can arrive at a constrained optimization problem for solving the parameters for the optimal separable convolution. Empirical results of replacing common convolution with optimal convolution in various modern CNNs have demonstrated the effectiveness of the proposed optimal separable convolution.","This paper proposes a novel type of convolution called optimal separable convolution. Compared with existing separable convolutions like depth separable and spatial separable convolutions, the authors design a scheme to achieve an optimal separation. To prevent the proposed convolution from being degenerated, the authors define the volumetric receptive field to be the volume in the input space that affects CNN’s output. The volumetric RF condition requires that a properly decomposed separable convolution maintains the same volumetric RF as the original convolution before decomposition.",0.2553191489361702,0.2857142857142857,0.2696629213483146
2337,SP:d510a4587befa21d3f6b151d437e9d5272ce03a2,"This paper proposed BOGCN-NAS that encodes current architecture with Graph convolutional network (GCN) and uses the feature extracted from GCN as the input to perform a Bayesian regression (predicting bias and variance, See Eqn. 5-6). They use Bayesian Optimization to pick the most promising next model with Expected Improvement, train it and take its resulting accuracy/latency as an additional training sample, and repeat. ",This paper provide a NAS algorithm using Bayesian Optimization with Graph Convolutional Network predictor. The method apply GCN as a surrogate model to adaptively discover and incorporate nodes structure to approximate the performance of the architecture. The method further considers an efficient multi-objective search which can be flexibly injected into any sample-based NAS pipelines to efficiently find the best speed/accuracy trade-off.,0.24242424242424243,0.24615384615384617,0.24427480916030536
2338,SP:d5262e875cc88b3a33653ebdc21d1b418c81d26b,"This work provides a compressive analysis across multiple (18) different hardware performance predictors by  - (1) collecting their performance under different amounts of training data and different input network structures and showing each prediction method’s advantageous/disadvantageous scenarios - (2) analyzing the  prediction accuracy's influence on selecting subsequent hardware architecture and giving the insights on how to pick/design hardware performance predictors for the NAS.  Based on the observation drawn, MLP ones are found to be the most promising predictors in terms of the accuracy with limited training samples, while the Lookup Table model serves as a very cheap and straightforward guidance. In terms of the architecture selection guided by the model-based predictor, the work conjectures by verifying some of the selected network  structures’  hardware performance and increase the number of explored network structures can lead to better pareto front of the selected network architecture","In neural architecture search (NAS), performance predictors are an important tool, because predicting attributes such as accuracy can save costly measurements. Hardware metric predictors predict metrics such as latency in addition to accuracy. This paper gives an empirical study of 18 different performance predictors on NAS-Bench-201 and TransNAS-Bench-101, evaluating the rank correlation of the predictors on different datasets and predicted metrics. Then they evaluate how the inaccuracy of the predictors affect the predicted Pareto-front of architectures, compared to the true Pareto front. The authors run this experiment by simulating the errors in predictors. The authors find that MLP models perform the best on average across all settings they tried, and leads to an acceptable predicted Pareto-front.",0.1643835616438356,0.19672131147540983,0.1791044776119403
2339,SP:d56d16dbf3be1381b4deb4fe29892f894dff3ff4,"This paper simply combines mixup and self-distillation to achieve more adaptive soft label, which effectively regularize the training. In the manuscript, authors argue that the existed mixup-based approaches has two mainly efforts, may create misleading training samples or meet computation cost issue on creating samples. Motivated by this, they propose ""LaMix"", which can leverage the information of self-distillation, to solve those two efforts and achieve competitive performance with SOTA ""Puzzle-mixup"".   ","The previous advanced Mixup methods, such as CutMix and PuzzleMix, involve input mixing. This paper suggests a new Mixup approach, called LaMix, that does not require input mixing. The solution is combining the original target label (interpolation of two one-hot targets) and generated target labels from an additional network to use it for training. The authors argue that LaMix achieves superior performance without input mixing.",0.16216216216216217,0.18181818181818182,0.17142857142857143
2340,SP:d58f24e421f2022d85f95291fcf910262a76f590,"The authors develop an unsupervised method for solving SAT problems. The method consists of an energy-based loss function which is optimized by a three-stage architecture that performs propagation, decimation, and prediction (PDP). The authors show that on uniform random 4-SAT problems, their PDP system outperforms two classical methods, a prior neural method, and performs favorably in comparison to a heavily developed industrial solver. Further, they show that a PDP system trained on modular 4-SAT problems performs better on modular 4-SAT problems that one trained on uniform random 4-SAT problems.","This paper investigates the well-studied problem of solving satisfiability problems using deep learning approaches. In this setting, the authors propose a neural architecture inspired by message passing operations in deep probabilistic graphical models. Namely, the architecture takes as input a CNF formula represented as a factor graph, and returns as output a set of soft assignments for the variable nodes in the graph. The internal layers of the architecture consist of propagation, decimation and prediction steps. Notably, decimation operations take an important role in learning non-greedy search strategies. Besides PDP operations, the architecture incorporates parallelization and batch replication techniques. The learning model is trained in a non-supervised way, using a cumulative (discounted) log-likelihood loss that penalizes the non-satisfying assignments returned by the algorithm.  ",0.18947368421052632,0.140625,0.16143497757847533
2341,SP:d5c0c600df22dfa86497d3a82d8ce580fd9c2032,"This paper conducts a systematic and thorough analysis of a long-criticized problem of current knowledge base completion (KBC) research -- its evaluation setup. It discovers several major issues of the popular ranking metric with negative sampling and several popular benchmarks, such as unrealistic assumptions, existence of semi-inverse relationships in the KBs, suspicious model calibration behavior, and all together leading to inconclusive evaluation of true model performance. Based on the analysis, the paper further proposes that triple classification is a better metric for KBC because it's less prone to the problems from the open-world nature of KBs and their incompleteness. However, triple classification doesn't work well with randomly sampled negative examples (as shown in the paper). Therefore, this paper also collects a new benchmark from crowdsourcing based on YAGO3-10 where the positive and negative triples are examined and judged by multiple workers, hence forming a more solid ground for evaluation than random sampling. Several simple heuristic baselines are also proposed and shown to perform comparatively with state-of-the-art embedding models on the new benchmark, which shows that there's still a large room for model development.","This paper first analyzes several popular KB-completion datasets and their evaluation methods.  Several issues have been highlighted and discussed, such as the assumptions made in the ranking metrics, skewed distributions on semi-inverse relations (in WN18RR & YAGO3-10), confidence scores by popular methods are not calibrated.  In addition, the authors also suggest that some simple baselines are actually quite robust.  Based on their finding, the author creates a binary triple classification dataset.  Effectively, every triples in their dataset are examined by multiple Turkers to ensure the label quality and also to avoid the potential error due to the ""close-world"" assumption behind some existing datasets.",0.15104166666666666,0.27358490566037735,0.19463087248322145
2342,SP:d5ccf8fdd029c2a99dac0441385f280ed3fc03fb,"The authors extended the regular convolution and proposed spatially shuffled convolution to use the information outside of its RF, which is inspired by the idea that horizontal connections are believed to be important for visual processing in the visual cortex in biological brain. The authors proposed ss convolution for regular convolution and group convolution. The authors tested the proposed ss convolution on multiple CNN models and show improvement of results. Finally, detailed analysis of spatial shuffling and ablation study was conducted.","In this paper, the authors proposed a shuffle strategy for convolution layers in convolutional neural networks (CNNs). Specifically, the authors argued that the receptive field (RF) of each convolutional filter should be not constrained in the small patch. Instead, it should also cover other locations beyond the local patch and also the single channel. Based on this motivation, the authors proposed a spatial shuffling layer which is aimed at shuffling the original feature responses. In the experimental results, the authors evaluated the proposed ss convolutional layer on CIFAR-10 and ImageNet-1k and compared with various baseline architectures. Besides, the authors further did some ablated analysis and visualizations for the proposed ss convolutional layer.",0.25925925925925924,0.18421052631578946,0.2153846153846154
2343,SP:d5d2c965b30b18749ef11e08271d76ff9c556329,"The authors propose a new semi-supervised boosting approach. The approach takes a set of supervised learning algorithms to simulate ""crowd-source"" labels of the unlabeled data, which are then used to generate a noisy label per unlabeled instance. The noise level is then estimated with an agreement-based scheme, and fed to a modified AdaBoost algorithm that is more noise-tolerant given the noise level. Some theoretical guarantee of the modified AdaBoost algorithm is derived and promising experiment results are demonstrated.","In this paper, the authors present an approach for semi-supervised learning which combines noisy labels with boosting. In a first step, the labeled instances are used to train a set of classifiers, and these are used to create noisy labels for the unlabeled instances. Then, an EM procedure is used to estimate the noise level of each instance. Finally, a version of AdaBoost which accounts for instance noise levels is proposed to create a final classifier. A limited set of experiments suggests the proposed approach is competitive with existing approaches.",0.3048780487804878,0.27472527472527475,0.28901734104046245
2344,SP:d5fc92a93b6eb506bfe8cd218f09cb28fdc29b75,"The paper presents an approach that supports better performance when out of distribution cases occur. It does so by letting neurons be of only compact support and thus if the input is out of distribution (OOD) it is expected to be outside that support and therefore the output will be zero. This is used to detect OOD examples. A parameter alpha is used in the algorithm that determines the size of the support. When it is small then the network acts very similarly to a regular network and when it increases the support is limited. Therefore, to make training stable, they start with a small alpha and then increase it throughout the training. ","The authors propose a new neural network unit and training algorithm in order to improve OOD detection. Units can smoothly be changed between standard (dot-product) and RBF type through a shape hyperparameter. During training, this hyperparameter is slowly moved in the direction of the RBF shape. Empirical comparisons on three OOD problems are presented, showing that the proposed approach is competitive.",0.11504424778761062,0.20967741935483872,0.14857142857142858
2345,SP:d616f1a6c241f03f2ddf2d171ecfb7689d61857d,"In this paper, a unified view of embedding methods for visualization is presented. The main message is that, Laplacian eigenmaps and t-SNE are governed by a single formula, and the difference of them can be seen as a difference of a hyperparameter value. We can also approximately recover two different embedding methods --- UMAP and ForceAtlas2. Using a few benchmark data sets, the relationships of these methods are visualized.","the authors study a number of neighbor embedding methods in terms of attraction-repulsion forces. The authors show that t-SNE, UMAP, FA2, and LE can be (approximately) unified as a common approach that use different levels of tradeoff between these two terms. They also discuss the increased attraction in UMAP as a result of negative sampling.",0.2608695652173913,0.3157894736842105,0.28571428571428575
2346,SP:d6218fdd95b48f3e69bf12e96f938cecde8ff7ab,"This is a great paper using optimal transport theory for generative and implicit models. Instead of using general vector fields, the authors apply the potential vector fields in optimal transport theory to design neural networks. The mathematics is correct with convincing examples. This brings an important mathematical connection between fluid dynamics and GANs or implicit models. ","The paper proposes a ‘potential flow generator’ that can be seen as a regularizer for traditional GAN losses. It is based on the idea that samples flowing from one distribution to another should follow a minimum travel cost path. This regularization is expressed as an optimal transport problem with a squared Euclidean cost. Authors rely on the dynamic formulation of OT proposed by Benamou and Brenier, 2000. They propose to learn a time-dependent potential field which gradient defines the velocity fields used to drive samples from a source distribution toward a target one. Experiments on a simple 1D case (where the optimal transport map is known), and on images with an MNIST / CelebA qualitative example.",0.23214285714285715,0.11206896551724138,0.15116279069767444
2347,SP:d629a2e1996688c91a5294e702eb12b11370eed4,"The paper proposes a robust multi-objective RL approach and a non-linear utility metric to enforce an accurate and evenly distributed representation of the Pareto frontier. Robustness is obtained by formulating the problem as a two-player zero-sum game. The goal of the main agent is thus to learn the policies on the Pareto frontier under attacks from the adversary. This is achieved by training a single network to generate approximate Pareto optimal policies for any provided preference. To train this network, they introduce a new metric for Pareto frontier evaluation based on hypervolume and entropy (to force evenly distributed solutions). The resulting algorithm has the classical structure of an actor-critic algorithm where the critic provides an estimate of the Q-function and the actor updates the policies of the protagonist and adversary through alternate optimization.","This paper seeks to train multi-objective RL policies that are robust to environmental uncertainties. There are two main contributions: a novel approach to solve this problem, and a novel metric to evaluate Pareto fronts. The metric combines the typical hypervolume metric (that captures the quality/performance of a Pareto front) with a novel ""evenness"" metric, that captures how well solutions are spread out across the space of preferences. The proposed approach, called BRMORL, consists of training a protagonist policy that maximizes utility alongside an adversarial policy that seeks to minimize utility (motivated by zero-sum game theory), while using Bayesian optimization to select preferences to train on, in order to optimize the hypervolume-and-evennesss metric. Both the protagonist and adversarial policy are conditioned on preferences.",0.19424460431654678,0.2125984251968504,0.2030075187969925
2348,SP:d643be475992d1e14394cb6200b8db3d2b07c34f,"The paper presents a sampling-based approach to speeding-up training of GCNs in distributed systems. The key step in this task involves exchanging and aggregating messages sent along the edges of the graph. If the nodes of the graph are partitioned between several machines, then exchanging those messages involve costly communication between the nodes. To reduce this communication, the paper introduces a variant of the node sampling approach of Chen et al. (2018b) and Zou et al. (2019), where the probabilities of nodes in other machines are scaled down by some factor s. The approach is evaluated experimentally, showing that it reduces the amount of communication while (essentially) preserving the accuracy.","This paper proposed a new distributed training method for GNNs. Specifically, unlike traditional distributed training methods for CNNs where data points are independent, nodes in a graph are dependent on each other. Thus, this dependence incurs communication between different workers in the distributed training of GNNs. This paper aims to reduce the communication cost in this procedure. Here, this paper proposed to sample more neighbor nodes within the same worker while reducing the sampling probability for the neighbor nodes on other workers. It also provides some theoretical analysis and conducts the experiments to verify the proposed method. ",0.19642857142857142,0.2268041237113402,0.2105263157894737
2349,SP:d68fbbd734099992d67e10a0b15483ae7359ec52,"In this paper, the authors propose a constant-time approximation for graph convolution operation via theoretical analysis on the number of sampling from each neighbor. The authors prove that both node embedding and gradient can be approximated via constant number of samples among the neighbors. Extensive experiments are carried out to verify the correctness of the proposed bounds.","In this paper, the authors provide a theoretical framework for characterizing the approximation guarantees provided by node sampling to estimate embeddings in various GNN architectures. In particular, they prove several PAC learning-style bounds on the embedding and gradient estimation when using node sampling approaches. They also observe that since the number of nodes selected for sampling is not dependent on the size of the graph, this amounts to a constant time operation for determining embedding and gradient estimates.",0.3103448275862069,0.22784810126582278,0.2627737226277372
2350,SP:d6970df559439a15ce1d3573e9c9eabe0a6b10d7,"This paper describes training a sequence of conditional EBMs (inspired by  Ho et al. (2020)) instead of training unconditional EBMs.  Each conditional energy describes the probability of recovering x, given its noisy version \hat{x}. The noisy version of x can be described as a normal distribution centered at x, so the condition EBM has an additional term ||x - \hat{x}||^2, which constrains the Langevin dynamics to remain in the vicinity of \hat{x}, so it converges faster!","The paper proposed a novel method to train EBMs based on diffusion recovery likelihood. It constructs a sequence of noisy version of data and learn a conditional between consecutive noisy pairs. Compare to working with the likelihood directly, doing so makes the training much easier. Besides, even using a potentially non-convergent MCMC for gradient estimation, it still leads to a well-behaved energy potential, unlike EBMs trained via maximising the likelihood directly.",0.1518987341772152,0.1643835616438356,0.15789473684210525
2351,SP:d6adc0ff083e18cb7a7c5be3189017dea4f8beb6,"This work adds to a growing literature on biologically plausible (BP) learning algorithms. Building off a study by Bartunov et al. that shows the deficiencies of some BP algorithms when scaled to difficult datasets, the authors evaluate a different algorithm, sign-symmetry, and conclude that there are indeed situations in which BP algorithms can scale. This seemingly runs counter to the conclusions of Bartunov et al.; while the authors state that their results are ""complementary"", they also state that the findings “directly conflict” with the results of Bartunov, concluding that BP algorithms remain viable options for both learning in artificial networks and the brain.","The authors are interested in whether particular biologically plausible learning algorithms scale to large problems (object recognition and detection using ImageNet and MS COCO, respectively). In particular, they examine two methods for breaking the weight symmetry required in backpropagation: feedback alignment and sign-symmetry. They extend results of Bartunov et al 2018 (which found that feedback alignment fails on particular architectures on ImageNet), demonstrating that sign-symmetry performs much better, and that preserving error signal in the final layer (but using FA or SS for the rest) also improves performance.",0.16346153846153846,0.18888888888888888,0.1752577319587629
2352,SP:d6b0ad3bacba7ba1a532470056cd180ec9bf9688,"This work proposes the Graph Substructure Network (GSN) to encode structural roles for different nodes so that the expressivity of Graph Neural Networks is improved. The core idea is to count the number of certain substructures, such as cycles, cliques, and triangles. Then the proposed MPNN encodes such substructure counting information into the message passing. Experimental results show that the proposed method can obtain better performance than the comparing methods. ","This paper presents a natural extension of Message Passing Neural Net (MPNN)  by incorporating structural features. These structural features are computed as the counts from different substructures (like small lines, stars or complete graphs) induced in the original graph. These counts are combined to obtain a new feature per node or per edge. Then these features are used in a standard MPNN. The authors then show that the resulting GNN is more expressive and they validate this claim experimentally.",0.17142857142857143,0.1518987341772152,0.16107382550335572
2353,SP:d6c1148b4f3044ea3ff8a2dc07981a539fd9ee34,"This work proposed a general manifold clustering algorithm called Neural Manifold Clustering and Embedding (NMCE), which utilize Maximum Coding Rate Reduction (MCR2 ) as the objective function and data augmentation to enforce constrains.    In the implementation stage, given that even the toy experiment is difficult to optimize with the full NMCE objective, a multistage training procedure is applied with the first stage actually trying to optimize the Total Coding Rate (TCR), which is another kind of self-supervised learning objective claimed in this paper.   On synthetic and real-world datasets COIL20, COIL100, CIFAR-10, CIFAR-20 and STL-10, NMCE achieved comparable and sometimes better results, compared to baseline methods or some alternative manifold clustering methods listed in the paper.  ",Authors developed a method and training procedure for manifold clustering problems. The proposed solution inspired from information theoretic methods namely maximum rate reduction. Authors also support their claims with empirical results.,0.06722689075630252,0.25806451612903225,0.10666666666666666
2354,SP:d6ceacb118a56f9aabb563c7833e13b5af712acc,"The authors extends randomized smoothing, originally developed for classifiers, to functions which map inputs to a general metric space. The extension seems intuitive but is technically challenging. The authors develop tractable, statistical methods both for finding the smooth prediction as well as computing the certificates. Various experiments are conducted to highlight its flexibility in different metrics and scenarios, such as Jaccard distance w.r.t. face detection, total variation distance w.r.t. dimension reduction, and angular distance for image reconstruction. ","This paper proposed a smoothing technique to perform adversarial training, such that the trained model is robust to small $l_2$ perturbations in the input. The major contribution is that the proposed method is applicable to a wide range of distance metrics. The idea of computing the minimum enclosing ball is also a very interesting idea, and I believe similar idea can be used to smoothing based optimization. ",0.12345679012345678,0.14705882352941177,0.1342281879194631
2355,SP:d6ecb075f238cc67a6cc4f6b924e1b7b3eb69dfa,"This paper presents a novel method called Embed-SAD (as well as Input-SAD) to learn graph/node representations to disentangle structure and attribute information. Input-SAD is a simple baseline that tries to get structure-attribute disentanglements by individually processing graph structures and node attributes. For structure, the original node attibutes are replaced by out-degrees only, and passed to GNNs, while for attibutes, the node attibutes are passed to fully-connected networks. Embed-SAD is a more elaborate method to disentangle the GNN embeddings by posing two types of additional losses, i.e., the edge-reconstruction loss for structures, and the Noise-Contrastive Estimation (NCE) loss to maximize the mutual information against the structure-encoding vectors, in addition to the original loss for supervision. The paper also develops an interesting evaluation metric called SAD-Metric where node attibutes or graph structures are exclusively perturbed for each graph, and prediction for whether that perturbation is for structure or for attibutes made by the element-wise absolute differences between embedded vectors before and after the perturbation. This SAD-Metric can quantify the extent to which the obtained representation can detect which perturbation, that for structures or that for attibutes, is made for each sample graph. The experimental results also demonstrated that the structure-attibute disentanglement by Embed-SAD learning strategy actually improved the prediction performance of many off-the-shelf GNNs over many different graph- or node-level tasks.","This paper focuses on disentangling embeddings of the structure and the attribute of graph. The authors' key idea is that the structure and attribute information should be split in GNN. Based on this, the authors try to disentangle the structure embedding and the attribute embedding. With two different components, two different kinds of embeddings can be captured at the input stage.   In addition, these two different kinds of embeddings can be obtained by reconstructing the edge and minimizing the mutual information. At last, the authors propose a metric to evaluate the disentanglement. The models in this paper outperform baselines in node classification and graph classification task. ",0.12552301255230125,0.2830188679245283,0.17391304347826086
2356,SP:d6f338e6a069d00ba77aca07c2ba69e15b845a16,"The authors developed two algorithms MRBO and VRBO for  bilevel stochastic optimization problem, and showed that their computational complexities ($\mathcal{O}(\epsilon^{-1.5})$) outperform all existing algorithms ($\mathcal{O}(\epsilon^{-2})$) orderwisely. The authors claim two main contributions. First, MRBO is the first momentum algorithm that exhibits the orderwise improvement over SGD-type algorithms for bilevel optimization. Second, VRBO is the first that adopts the recursive variance reduction technique to accelerate bilevel optimization. Their experiments demonstrate that these algorithms  outperform existing algorithms, and suggest that the double-loop design may be more suitable for bilevel optimization than the single loop structure.","This paper presents two algorithms (one single-loop and one double-loop) which exploit variance reduction techniques to improve the best known sample complexity for stochastic bilevel optimization problems with strongly convex lower-level from $O(\epsilon^{-2})$ to  $O(\epsilon^{-1.5})$.    Bilevel optimization consists in two nested optimization problems: the upper-level aims at minimizing an objective function where some of the variables are a solution of the lower-level problem. In the stochastic setting, upper and lower-level objectives are not accessible and are instead replaced by unbiased estimators. In addition to several smoothness assumptions, this work and several recent others consider the case when the lower-level problem is strongly-convex, which guarantees that the lower-level solution is unique, the existence of the upper-level gradient, and allows to provide convergence guarantees to stationary points even when the lower-level solution is not computed exactly.   This work studies two algorithms (MRBO and VRBO) which both achieve a sample complexity of $O(\epsilon^{-1.5})$, which improves upon the previous optimal complexity of $O(\epsilon^{-2})$. Both algorithms exploit variance reduction  to achieve the desired complexity. MRBO is single loop and combines variance reduction and momentum while VRBO is double loop and uses large-batch gradients to reduce the variance. Recent works have already applied momentum and variance reduction to solve stochastic bilevel problems but this one is the first (together with two concurrent works) to achieve a sample complexity this low. The authors present experiments on the data hyperclearner setting which show that VRBO performs the best and double-loop algorithms seem to outperform single-loop ones. ",0.3333333333333333,0.125,0.18181818181818182
2357,SP:d713225fa41061a2ad23a072786c21f066b2a777,The paper proposes a generative models for learning over the space of geometric graphs -- those graphs whose nodes are associated with geometric coordinates (point clouds). The point cloud serves as basis for decoding graph structure. This makes the entire system efficient. An extensive suite of experiments on chemical benchmarks (QM9 and ChEBML) show that the proposed method is competitive against state-of-the-art rivals on a variety of measures and tasks. ,"This paper studies the problem of geometric graph generation (mainly focusing on molecule graph generation). Specifically, the authors propose a new method,  namely Geometric Graph Generator (G3), which generates three-dimensional geometric graphs. Different from others, G3 can capture both the combinatorial and the geometric information of graphs. The proposed algorithm can successfully generate molecule graphs and runs faster than other baseline methods. The key parts of G3 are the point encoder and graph encoder, and the three-step decoding process, that is the coordinate decode, feature decoder, and finally graph decoder.  The experimental results show that G3 has better performance than other generators in terms of validity, uniqueness, and novelty. ",0.2222222222222222,0.14414414414414414,0.1748633879781421
2358,SP:d74f95781e1b0f164644b7e30247791eae6afc79,"This paper proposes a novel data augmentation method, untied MixUp (UMixUp), which is a general case of both MixUp and Directional Adversarial Traning (DAT). DAT is referred to in this paper as a scheme that only input feature vectors are mixed, while MixUp also incorporates their corresponding labels. The authors provide a theoretical discussion that both DAT and UMixUp converges to be equivalent to each other when the number of training samples becomes infinity. Experimental results on Cifar 10, Cifar 100, MNIST, and Fashion MNIST show quantitative comparisons among the baseline, MixUp, and UMixUp.","This paper introduces directional adversarial training (DAT) and UMixUP, which are extension methods of MixUp. DAT and UMixUp use the same method of MixUp for generating samples but use different label mixing ratios where DAT retains the sample's original label. In contrast, UMixUp uses a function of the input mixing ratio. This paper shows that UMixUp and DAT are equivalent when the number of samples tends to infinity. In the experiments, UMixUp provides an improvement over MixUp.",0.23404255319148937,0.28205128205128205,0.2558139534883721
2359,SP:d76bc6a749e9576dade07060b012715c7b96f534,"The paper is a detailed account of how large of a learning rate a given mode can take when it is trained by constant step size SGD. Many papers investigated the effect of learning rate (and batch size and width etc…) to the final accuracy. In general, the findings indicate increased accuracy up to a certain threshold (where the algorithm doesn’t converge any more). Such findings are abundant in the literature. However, the present paper investigates the path that SGD takes to get to find those ‘good’ performing points in the weight space. Two phases emerge: monotonic decay in loss vs catapult regime and the latter appears to perform the best. ","This paper analyzes the effect of choosing a large step-size on the generalization of deep networks. They suggest that starting with a large learning rate, the loss initially increases before converging to a flatter minimum with improved generalization (catapult effect). When the learning rate is above a certain threshold, the authors observed this catapult effect along with a decrease in the curvature of the landscape. These observations were empirically demonstrated through various experiments and analytically studied for a two-layer linear network.",0.17857142857142858,0.24096385542168675,0.2051282051282051
2360,SP:d77c4c7084efd617021048e3f324fcfdb113b0c0,"This paper follow recent trend of adversarial examples which is on generating images with small differences in the input space, but that are misclassified by a large margin by a neural net. The key idea of the paper is that any negative component before a ReLU activation share the same zero feature after the ReLU. Thus, any neural network that has ReLU activations have a polytope in the input space that will have identical activations in the later layers. Based on this observation, the paper assert that such polytope always exist and describe how to find its corners with a gradient descent based method. Two simple experiments on MNIST and ImageNet datasets are carried to show the feasibility of the method in practice and the existence of images with feature collision, together with their average L2 distance from real images. Since the images are clearly not ""natural"" images, a further method based on selecting patches of real images is reported and tested on ImageNet. This shows that the approach can be further applied on macro-level differences.","This paper studies a non-local form of adversarial perturbation, which, to my limited knowledge is new. The form of the perturbation is specific to ReLU activations, but it may be a large set. The authors also devise an algorithm to generate natural-looking perturbations in this set. Instead of updating a seed example through gradient descent, they propose to generate perturbations by combinations of image patches from multiple seed images. The weights of the combination are optimized by a gradient descent like algorithm in a similar manner as standard gradient-based approaches to generating adversarial examples. This produces perturbations that look like ```in-paintings'' or transplants of one seed image onto another. Here are a few comments:",0.1638418079096045,0.2457627118644068,0.1966101694915254
2361,SP:d783d5b819a35bec590394a1d3f87aa5dd3fa253,"The paper proposes an unsupervised approach to identify image features that are not meaningful for image classification tasks. The goal is to address the domain adaptation (DA)/domain generalization (DG) issue. The paper introduces a new learning task where the domain identity is unavailable during training, called unguided domain generalization (UDG). The proposed approach is based on an old method of using gray level co-occurence matrix, updated to allow for differentiable training. This new approach is used in two different ways to reduce the effect of background texture in a classification task. The paper introduces a new dataset, and shows extensive and carefully designed experiments using the new data as well as existing domain generalization datasets.",The paper proposed a novel differentiable neural GLCM network which captures the high reference textural information and discard the lower-frequency semantic information so as to solve the domain generalisation challenge. The author also proposed an approach “HEX” to discard the superficial representations. Two synthetic datasets are created for demonstrating the methods advantages on scenarios where the domain-specific information is correlated with the semantic information. The proposal is well structured and written. The quality of the paper is excellent in terms of novelty and originality. The proposed methods are evaluated thoroughly through experiments with different types of dataset and has shown to achieve good performance. ,0.1794871794871795,0.19811320754716982,0.1883408071748879
2362,SP:d78dcd46d90c1bac526f8b1135bb69d4ba5a3bb7,"The paper addresses the problem of adversarial attack for an optical-flow-based action recognition in both the white-box setting (i.e., gradients are available) and the black-box settings (i.e., the gradients cannot be computed by the optical flow algorithm). A video is partitioned into fixed-size temporal intervals, a state-of-the-art deep optical flow estimator is applied on each pair of two consecutive frames within the interval, and perturbations are applied to each frame (or selected frames using saliency cues) within the interval to attack the recognition system using Fast Gradient Sign Method (FGSM). Experiments are carried out on the UCF-101 dataset, in the white-box and black-box settings, and show that the method is able to effectively attack the system.","This paper presents a framework for generating adversarial perturbations for videos. Specifically, the paper proceeds by using a standard image-based adversarial noise generation setup (such as the FGSM scheme), and applies it to the motion stream of a two-stream action recognition pipeline; this motion stream typically using optical flow images. As such flow generation is usually done offline and thus is not differentiable, the paper resorts to the recent FlowNet 2.0 scheme that uses an end-to-end learnable deep flow generation model. Three variants of the scheme are provided, (i) that perturbs all frames in a flow stack, (ii) that perturbs only a sparse set of frames as decided by the importance of a frame to action classification, and (iii) a variant of (ii) that recalculates the gradients for all frames if the ones selected in (ii) were not adversarial. Experiments are provided on UCF101 dataset and show promise. Analysis is presented on the transferability of  the learned noise to flow images generated via external means.",0.21705426356589147,0.16470588235294117,0.18729096989966554
2363,SP:d7b4a400a8376f863b898e6ab363485bb95f0cde,This paper proposes two ideas for improving the performance of certified training. The first idea is to use assign weight for each input based on the margin to the decision boundary. The second idea is to use automatic scheduling of perturbation radius during training. They show that using these two ideas leads to improved certified robustness on MNIST and CIFAR-10 datasets. ,This paper proposes bound-based weighted loss and epsilon auto-tuning to improve the performance of certifiable training. The insights of the improvements are mainly borrowed from well-developed adversarial training while they are customized for certifiable training considering bound margins provided bound propagation methods. The experimental results clearly show the improvements from individuals and the combination of the two methods.,0.22580645161290322,0.22950819672131148,0.22764227642276422
2364,SP:d7bfb6a33941b5691275b77917b1d100764b91af,"Recent studies have proposed automated slice discovery methods (SDMs), which leverage learned model representations to mine input data for slices, or important subgroups of data, on which a model performs poorly.  An ideal SDM should automatically identify:  1. Slices that contain examples on which the model underperforms, or has a high error rate. 2. Slices that contain examples that are coherent, or align closely with a human-understandable concept.  This is difficult because: 1: No quantitative evaluation framework exists for measuring performance of SDMs; Existing SDM evaluations are either qualitative, performed on synthetic data, or consider only a small subset. 2. Prior qualitative evaluations have demonstrated that existing SDMs often identify slices that are incoherent, even though they may satisfy the first ideal case.  Domino: The authors preset Domino, an SDM that leverages cross-modal embeddings and a novel error-aware mixture model to discover and describe coherent slices using natural language descriptions. The proposed method could also quantitatively compare SDMs, which has not been done before.  Step 1. Embed: Encode inputs in a cross-modal embedding space with a function.  Step 2. Slice:  identify underperforming regions in the cross-modal embedding space using an error-aware mixture model fit on the input embeddings, model predictions, true class labels using expectation maximization. I.e. input embeddings, class labels, and model predictions as independent based on slice.   Step 3. Describe: Use the text embedding function ψtext learned in step (1) to generate a set of k natural language descriptions of the discovered slice.  Evaluation Approach of 3 popular slide types: Rare slice: To generate settings with rare slices, Construct a skewed dataset such that for a given class label Y, elements in subclass C occur with proportion α, where 0.01 < α < 0.1. Correlation slice: Construct a dataset such that a linear correlation α exists between the target variable and other class labels, where 0.2 < α < 0.8. Noisy label slice. Construct dataset such that for each given class label Y, the elements in subclass C exhibit label noise with probability α, where 0.01 < α < 0.3.  Experiments show that when cross-modal embeddings are provided as input, the error-aware mixture model often outperforms previously-designed SDMs.","The paper propose a framework for identifying on which subsets of data machine learning models make systematic errors. The problem is cast in two parts: (1) identify a model that can be identify a subset of data and predict degraded performance of the machine learning model for this subset and (2) ensure that the identified subset is ""coherent"". The framework is evaluated on a number of classification tasks in computer vision and medicine.",0.054945054945054944,0.273972602739726,0.09153318077803203
2365,SP:d7c00cd82b5d4cd035635e74b8525cf5603d305b,"The authors propose to improve a safe RL algorithm, constrained policy optimizaiton, that can learn the optimal safe policy while exploring unsafe states less often during the training process. In particular, they dampen the estimated advantage associated with unsafe states, which encourages the RL algorithm to explore safe states more often during the learning process. In addition, the authors aim to find a policy that satisfies the constraints with high probability, rather than only in expectation, by considering the worst-case constraints. The empirical results show that a safe RL algo that dampens the advantage and respects worst-case constraints are able to learn policies with large returns and avoid unsafe states.","In this paper, the authors proposed a new constrained policy optimization algorithm and a worst-case version of the constrained MDP framework. Tho proposed constrained policy optimization algorithm is based on CPO, and a novel advantage function (CSAE) based on the concept of a ""safe"" state. Experiments in control simulation tasks are provided.",0.11607142857142858,0.24528301886792453,0.1575757575757576
2366,SP:d81493884c06f29a4e9ee2ed51a5502df7dd277f,"This paper is an empirical study which attempts to test some of the claims regarding the information bottleneck principle applied to deep learning. To estimate the mutual information (I(x; h) and I(y; h)) in neural networks, the authors define a lower bound on the MI. Then a PixelCNN++ model (for I(x; h)) and a partially frozen classifier (for I(y; h)) are used to compute the MI during classifier and autoencoder training. For both tasks, the authors report the mutual information between hidden layers and input training data first increase for a while and then decrease. The generated images conditioned on hidden layers by the PixelCNN++ were shown to demonstrate the fitting and compression of data in a visual and intuitive fashion.","The authors propose to extend the analysis of Shwartz-Ziv & Tishby on the information bottleneck principle in artificial neural network training to realistic large-scale settings. They do so by replacing otherwise intractable quantities with tractable bounds in forms of classifiers for I(y;h) and Pixel CNNs for I(x;h). In conclusion, they observe two phases during training, one that maximizes mutual information between input and hidden representation and a second one that compresses the representation at the end of training, in line with the predictions from toy tasks of Shwartz-Ziv & Tishby.",0.216,0.28421052631578947,0.24545454545454545
2367,SP:d856b17ff19142ea30fcb687ee8a911b135fc3f5,"The paper focuses on quantifying uncertainty for classification problems using Dirichlet based uncertainty (DBU) estimation techniques. The authors study these techniques for their robustness properties under adversarial attacks, proposes a novel attack type targeting uncertainty estimates through differential entropy, and investigates robust training for detecting in and out of distribution data points. Experiments using image datasets showed that uncertainty from DBU models 1) do not provide robust identification of correct predictions under adversarial attacks, 2) are only able to detect weak attacks and do not perform well under strong attacks, 3) robust training does not guarantee generalization to both in and out of distribution datasets.","This manuscript addresses an important question of how Drichlet-based uncertainty (DBU) measures can be used to quantify robustness to adversarial label attacks. Robustness to OOD samples of these models were already shown in the papers they were proposed but this work differs from them in using adversarial samples as OOD samples. Via extensive experimental results on various datasets, the authors conclude that the uncertainty estimates are not good indicators for identifying correctly classified samples for adversarially perturbed data.",0.12380952380952381,0.16455696202531644,0.14130434782608695
2368,SP:d872c4d4c7d2495156ce9a1c30dd2696ce1173df,"This paper proposes FLAG (Free Large-scale Adversarial Augmentation on Graphs), an adversarial data augmentation technique that can be applied to different GNN models in order to improve their generalization. The proposed technique consists on adding adversarial perturbations to the nodes’ features solving the standard min-max problem for adversarial training. In this setup, a noise vector is added to the input features which tries to maximize the loss by performing gradient ascent, while the classifier is trained to minimize the loss despite the added adversarial noise.","This paper investigates adversarial feature augmentation for improving the generalizability of graph neural networks. The authors adopt an existing augmentation algorithm and apply on the nodes of each training graph, and use the perturbed graphs for training. The focus of the paper is extensive experimentation in various tasks and settings to illustrate the effectiveness of adversarial augmentation in graph-based tasks. The experiments provide new, non-trivial insights, such as the effect of the number of network layers on the effectiveness of augmentation. The paper is well-written and easy to read.",0.21839080459770116,0.20652173913043478,0.21229050279329612
2369,SP:d8cd0216bc99e82a957d527a342bcefc5b69ec3c,"		a. This article contributes a framework and tool for visualising data collected from a policy during RL training. It also contributes a set of views for visualising RL training data that could be used in general. Finally, the paper contributes a high-level workflow and a set of example use cases for how this tool might impact debugging a training session.","The paper deals with debugging of black-box deep reinforcement learning (RL) agents to better understand and fix their policies. The authors propose diverse tools for, among others, visualizing the state space in terms of calculated statistics, analyzing the taken actions across learning episodes or exploring the replay buffer. The authors also propose a workflow for using the proposed tools. The resulting Vizarel tool is evaluated in terms of an exemplary walkthrough.",0.13114754098360656,0.1111111111111111,0.12030075187969924
2370,SP:d8e30dcadff63f56df4894cb5ba871cb2f8ee0ea,"The paper describes a pipeline for image compression which allows to reliably detect specific manipulation patterns in compressed images.  The results show that it is possible to learn image compression that performs similarly to a modern image compression algorithm while in the same time is optimized to reveal specific kinds of manipulations. The authors build upon (Korus & Memon, 2019), but use a learnable codec instead of differentiable JPEG. ","This paper presents a learned image compression method that is able to be robust under a variety of tasks. The results aren't state of the art in terms of rate-distortion performance, but this paper has a very good analysis of the results, and has produced a very fast codec. In that sense, this is a very interesting paper that may lead to other fast methods (the other fast method they compared the runtime against - WaveOne never published a complete description).",0.22058823529411764,0.18292682926829268,0.2
2371,SP:d8fb4eefbb282d80e357ec143ea0697334b55ab2,"The authors identify that contemporary methods for finding very sparse subnetworks in deep neural networks (DNNs), including both methods for finding either ""weak tickets"" (after training) or ""strong tickets"" (before training), do not find very sparse (and good) solutions. They question if this is a fundamental limitation (i.e. these very sparse solutions don't exist), or if this is a limitation of current methods in finding such solutions. To answer this question, the authors propose to either ""plant"" known good very sparse subnetworks in DNNs, or to try and find solutions for toy problems for which the authors could identify good hand-made very sparse subnetworks - including a classification problem (Circle), function regression (ReLU), and manifold-learning problem (Helix) . The experimental results analyze the performance of strong and weak sparse subnetwork search methods, including GraSP, SNIP, SYNFLOW, alongside magnitude and random pruning in finding these planted tickets. None of the strong ticket methods are able to find the ""planted"" tickets for any sparsity level, while the weak methods are able to find tickets, but not at extreme sparsity. Further analysis reveals layer collapse in particular to be a problem. The authors conclude that rather than a fundamental limitation, current methods (in particular for strong tickets) are limited in finding very sparse tickets even if they are known to exist at that sparsity level.","The authors note a distinction between kinds of sparse networks in the literature. ""Weak tickets"" require training to perform comparably to the original network, while ""strong tickets"" do not.  The authors prove a lower bound for the probability that a strong ticket exists, and note that instead of training, this ""strong ticket"" need only be scaled by some constant to achieve similar performance to the larger network.  Using the insights of this proof, the authors propose three benchmark tasks to find a ground truth sparse network.  They evaluate common pruning methods to find both weak and strong tickets using these tasks, and find that most methods perform well on 2 out of the three weak ticket finding tasks.  They also note that the only method designed specifically for strong ticket finding performs well on these tasks.  For further evaluation, they additionally share weak and strong ticket finding results for VGG-16.   ",0.15625,0.23178807947019867,0.18666666666666668
2372,SP:d8fe4568447b255f04befefa320abc6d2f32ccdc," ### Contributions * This paper proposes a safe model-based deep RL approach where     * No simulator is needed. The dynamic model is learned from data.     * No constraint is specified. * This work is an extension of reward query synthesis via trajectory optimization (ReQueST).  * ReQueSt (previous work)     * Algorithm         * Dynamics learned from (potentially unsafe) random exploration.         * Reward learned from binary human feedback that is generated by a procedural reward function.         * Demonstrated in State-based 2D navigation (non-pixel-based), Image-based Car Racing (pixel-based, 64x64×3).     * Regarding safety         * ReQueST avoids the problem of safe exploration by allowing agents to explore these states in a simulated model without having to visit them in the real environment. * This work     * Algorithm         * Dynamics learned from safe demonstration provided by humans (160 person-hours).           * Similar to ReQueSt, `except that we use a larger encoder network, a deconvolutional decoder network, and train using a simple mean-squared error loss between ground-truth pixel observations and predicted pixel observations.`         * Reward learned from             * Type of feedback from humans: reward sketch (previous work) (10 person-hours).             * The proxies for value of information: maximization and minimization of reward as predicted by the current reward model.             * The algorithm for reward learning: MPC.         * Demonstrated in 3D env           * Task goal = eat all the 3 apples           * Env 1 = Cliff edge environment             * Safety = not fall off the end of the world           * Env 2 = Dangerous blocks environment             * Safety = bumping into blocks           * Each env has 3 Sized subvariants.           * Each env is pixel-based, 96×72×3.     * Regarding safety         * Safety is achieved by focusing the learned dynamic model in the safe scenarios, with only the safe data. `Given models of sufficient fidelity, this should allow us to train an agent with close to zero instances of unsafe behaviour in the real environment.`  ### Results * Env 1 = Cliff edge environment (Fig5)     * Safety violations during training: proposed method << model-free RL     * Safety violations during testing: proposed method = model-free RL << random policy     * Apples eaten: random policy <= proposed method < model-free RL     * => Proposed method vs model-free RL => tradeoff between safety violations during training and apples eaten * Env 2 = Dangerous blocks environment (Fig6)     * Safety violations during training: Proposed method << model-free RL     * Safety violations during testing: Proposed method << model-free RL = random policy     * Apples eaten: random policy = model-free RL < proposed method     * => Proposed method is better than model-free RL and random ","The paper proposes an extension to ReQueST, which learn learns a neural simulator of the environment from safe human trajectories and then learns a reward model from human feedback. This work extends ReQueST by dense reward sketches on imagines trajectories and evaluates the idea on a visually-complex 3D environment. The paper also discusses the amount of training data that is needed for ReQueST to work in such a setting. The authors collect 160 person-hours of ""safe"" human exploratory trajectories and 10 person-hours of reward sketches. Their results show that the application of ReQuest results in ""3 to 20"" times less constraint violations compared to a non-safe baseline.",0.08290155440414508,0.2882882882882883,0.12877263581488932
2373,SP:d905f831fd48700ebbaf8286fa71f77b45aa685f,"This paper posits that similar input examples will have similar gradients, leading to a gradient ""coherence"" phenomenon. A simple argument then suggests that the loss should decrease much more rapidly when gradients cohere than when they do not. This hypothesis and analysis is supported with clever experiments that confirm some of the predictions of this theory. Furthermore, since, as the authors emphasize, their hypothesis is prescriptive, they are able to suggest a novel regularization technique and show that it is effective in a simple setting.","The surprising generalization properties of neural networks trained with stochastic gradient descent are still poorly understood. The present work suggests that they can be explained at least partly by the fact that patterns shared across many data points will lead to gradients pointing in similar directions, thus reinforcing each other. Artefacts specific to small numbers of data points however will not have this property and thus have a substantially smaller impact on the learning. Numerical experiments on MNIST with label-noise indeed show that even though the neural network is able to perfectly fit even the flipped labels, the ""pristine"" labels are fittet much earlier during training. The authors also experiment with explicitly clipping ""outlier gradients"" and show that the resulting algorithm drastically reduces overfitting, thus further supporting the coherent gradient hypothesis.",0.2,0.12878787878787878,0.15668202764976957
2374,SP:d909573bd57a8f14009fd399d88cd2eeddd0aab5,"This paper presents a model for effectively hierarchically ‘searching’ through the space of (continuously relaxed) FOL formulas that explain the underlying dataset. The model presented employs a three-level architecture to produce logic entailment formulas, skolemized with a set of skolem functions, i.e. ‘operators’. The three-level search, which is implemented via a stack of transformers, first searches through a space of variable and predicate embeddings to select operators, after which it searches through the space of predicates to form primitive statements of predicates and operators, and finally it generates a number of formulas from the previously ‘selected’ primitive statements. The model is applied on a toy task to showcase its speed, a knowledge base completion task, and modeling the visual genome dataset, where the model shows the ability to induce meaningful rules that operate on visual inputs. The presented benefit of the model is scalability, ability to induce explainable rules, and the ability to induce full FOL rules.","This paper proposes a novel architecture of integrating neural models with logic inference capabilities to achieve the goal of scalable predictions with explanatory decisions, which are of significant importance in the real deployment. In general, the article is well-written and nicely-structured with clear motivations, i.e., make the model predictions interpretable, make the logic rules differentiable, and make the algorithm scalable with longer rules and faster inference time. Both the methodology and experimental results make the idea promising and interesting. The contributions could be summarized in the following which make this piece of work worth of publication to my point of view:",0.1375,0.21153846153846154,0.16666666666666669
2375,SP:d90994dacbd0fd015426f033a721793d90051f0c,"This paper studies two popular algorithms: local SGD and minibatch SGD using the data shuffling technique, which means sampling without replacement. Authors provide analysis under PL condition and show that in some cases these methods with shuffling outperform classical local SGD and minibatch SGD. Additionally, this paper provides lower bounds for minibatch RR and local RR in homogeneous and heterogeneous settings. At the end of the paper, a new technique of using synchronized permutations is proposed. In an almost homogeneous setting, this approach can improve rates.","This paper proposes two variants of stochastic gradient algorithms without replacement. For smooth functions satisfying the PŁ condition, the authors showed that the proposed shuffling-based variants converge faster than their with-replacement counterparts (for the case with large number of epochs). Moreover, the authors showed that their provided convergence analysis is tight for the case with not large number of epochs. ",0.16279069767441862,0.22580645161290322,0.1891891891891892
2376,SP:d90cddf2bb62b5b5461e48860c69b6f779950206,"The authors study stability in two-sided markets with transferable utilities where each agent has no a-priori knowledge of her own preference. They introduce the measure of 'Subsidy Instability' that is defined as the minimum total subsidy (extra payment to all the agents) that can stabilize a (matching, transfer) pair. They propose a UCB based primal-dual algorithm that tries to minimize the Subsidy Instability with bandit feedback for the above system. The proposed algorithm is proved to have a O(|A|^3/2\sqrt{T}) regret in a time horizon of T, where A is the set of all agents. They provide an orderwise matching  lower bound for this setting. ","The paper considers two-sided platforms who seek to match users on   both sides under uncertainty about user preferences. The focus is on   the transferable utility setting, where the platform, in addition to   orchestrating a matching, imposes transfers between each pair (as   well as from the platform to the pair). After each matching, the   platform receives noisy (bandit) feedback regarding the utilities   received by each member in a matched pair. The goal of the platform   is to learn a stable market outcome efficiently. To capture the   (in)efficiency of learning, the authors introduce a measure of   instability of any matching, namely subsidy instability, which is   equal to the smallest total (non-negative) transfer the platform   needs to make to the users so that matching is stable. The regret of   any learning algorithm is then defined as the total subsidy   instability accumulated over a time horizon.    The authors first show that the subsidy instability is indeed an   appropriate notion to capture learning efficiency, by providing   natural economic interpretations as well as exhibiting a number of   smoothness properties and bounds. The authors then propose a natural   UCB-type algorithm, where each agent reports upper confidence bounds   on their preferences and the platform computes the optimal stable   matching and transfers under these reported preferences. The authors   show that this algorithm achieves an expected regret that is of   order $O(\sqrt{T\log T})$, and furthermore provide a matching lower   bound. (The bounds also establish regret dependence on other model   parameters.) ",0.35714285714285715,0.16194331983805668,0.22284122562674094
2377,SP:d90cf59a526832aad0436f9b6e168cb9c08568f8,"The paper at hand discusses a compressed network inference scheme, where two networks are trained to solve a give classification task. One network aims at achieving a high accuracy, whereas the other network is a highly compressed network which is able to highly speed-up inference. The compression of the network is performed by quantizing the parameters of the network to two or to three different values. The approach of the authors consists of estimating the uncertainty of the highly-compressed network by thresholding the scores. In the case that one score does not exceed the other scores by the pre-defined threshold, the sample will additionally be feed into the high-accuracy network. Experiments are performed on the CIFAR-10 and the ImageNet dataset using a convolutional neural network, a ResNet and a MobileNetV2 network. The speed-up is evaluated with respect to specialized hardware (FPGAs).",This paper proposes a framework to accelerate DNN inference on small embedding systems using an extremely low bit network and a moderately quantized network jointly. The mechanism of the proposed work is to first compute the difference using top2 prediction scores from the compressed network to determine if the inference is further needed for the original network. The proposed framework is evaluated on both CIFAR10 and ImageNet with different network structures and the empirical results indicate better accuracy and latency over baselines. ,0.16326530612244897,0.2926829268292683,0.2096069868995633
2378,SP:d92978dc1a820c8d0a8eb39a3129b4e3132cafa1,"This paper proposes a future frame prediction framework where the video generation can transition between different actions using a Gaussian process trigger. The framework consists of three components: an encoder which encodes the frame to a latent code, an LSTM which predicts the next latent code given the current one, and a Gaussian process which samples a new latent code. The framework can decide whether to switch to the next action by adopting the new latent code, depending on the number of frames passed or the variance of Gaussian.","The authors propose to use a Gaussian Process (GP) to model the uncertainty of future frames in a video prediction setup. In particular, they employ a GP to model the uncertainty of the next step latent in a latent variable model. This allows them to use the GP variance to decide when to change an ""action sequence"", corresponding to a deterministic dynamics function implemented using an LSTM. ",0.1797752808988764,0.23880597014925373,0.2051282051282051
2379,SP:d9337a6584f85065622b88caf23629b10c563ebd,The paper proposed a new method to handle feature/context interactions within the eCTR prediction neural networks. Details are provided in different scenarios. Experiments are conducted for offline and real-world experiments with promising results.,"This submission is on modeling feature interactions for CTR prediction. It proposes a framework that follows meta-learning. Specifically, to model the interaction between feature F1 and feature F2, it uses a meta neural-network g(F1) that takes F1 and produces the parameter for another neural network f(F2) that takes F2, i.e., the outcome of feature crossing is f(F2) where f's parameter is g(F1). It outperforms the baselines and is deployed online.",0.17142857142857143,0.07692307692307693,0.10619469026548672
2380,SP:d94b0a398257e68c8888f0fdb9e6765881f798af,"The paper proposes a recurrent and autorgressive architecture to model temporal knowledge graphs and perform multi-time-step inference in the form of future link prediction. Specifically, given a historical sequence of graphs at discrete time points, the authors build sequential probabilistic approach to infer the next graph using joint over all previous graphs factorized into conditional distributions of subject, relation and the objects. The model is parameterized by a recurrent architecture that employs a multi-step aggregation to capture information within the graph at particular time step. The authors also propose a sequential approach to perform multi-step inference. The proposed method is evaluated on the task of future link prediction across several baselines, both static and dynamic, and ablation analysis is provided to measure the effect of each component in the architecture.","This paper properly applied several technique from RNN and graph neural networks to model dynamically-evolving, multi-relational graph data. There are two key component: a RNN to encode temporal information from the past event sequences, and a neighborhood aggregator collects the information from the neighbor nodes. The contribution on RNN part is design the loss and parameterizes the tuple of the graph. The contribution of the second part was adapting Multi-Relational Aggregator to this network. The paper is well-written. Although I'm familiar with the dataset, the analysis and comparison seems thorough. ",0.14925373134328357,0.21052631578947367,0.17467248908296942
2381,SP:d9608f07e3a5f6d8775080df89a261e054c1a2f8,"The paper uses a deep neural network architecture (CNN + Transformer) to model logical translations of questions in the form of programs. The experimental setup uses the ""battleship"" game scenario, which is an interesting domain for questions because of the inherent partial observability present in the game. The paper is clearly written and well-presented.","The authors explore different ways to generate questions about the current state of a “Battleship” game. To do this, they introduce a neural network architecture with a convolutional encoder and a Transformer-based decoder and consider both supervised and reinforcement-learned training approaches. They evaluate the introduced methods in three different ways that demonstrate basic classification and generation abilities of the model.",0.18518518518518517,0.16129032258064516,0.17241379310344826
2382,SP:d99e737b62f3b4e4d9ad6f109cb145e88d55ce86,"The paper presents a synthetic naive approach to analyzing distorted, especially noisy, images through deep neural networks. It uses an existing gating network to discriminate between clean and noisy images, averaging and denoising the latter, so as to somewhat improve the results obtained if no such separation was used. It deals with a well known problem using the deep neural network formulation. Results should be compared to other image analysis methodologies, avoiding smoothing when not required, that can be used for the same purpose.  This should also be reflected in related work in section 2; the reason of including Table 1 in it seems unclear. ","This paper introduced a parameterized image processing technique to improve a robustness of visual recognition systems against noisy input data. The proposed method is composed of two components; a denoising network that suppresses the noise signals in an image, and gating network that predicts whether to use the original input image or the one produced by the denoising network. The proposed idea is evaluated on three tasks of object detection, tracking and action recognition. ",0.13333333333333333,0.1891891891891892,0.1564245810055866
2383,SP:d9a70ada6ed2324c5b430e0a7a6785b1eb49d3ef,"The paper studies the problem of Post-Training Quantization of NNs, where no fine-tuning is performed to quantize the model. In particular, the authors focus on sub-8 bit quantization and propose a novel integer linear programming formulation to find the optimal bit width for a given model size. Additional approaches are proposed to minimize accuracy degradation after quantization. These include","This paper proposed a set of methods for post-training quantization of dnns. The methods include AdaQuant (which jointly optimizes quantization steps for weight and activation per output activation of each layer), Integer Programming (which determines bit-precision for all the layers), and the batchnorm tuning. The authors presented promising experimental results on various neural networks to support the proposed methods. ",0.22580645161290322,0.22950819672131148,0.22764227642276422
2384,SP:d9b458c1ddd8165e4cef7861b7995d80fcf3c434,"This paper provides a set of empirical studies of the spectral and spatial properties of adversarial examples of deep neural nets (DNNs) classifiers. The studies illustrate that standard DNNs are much more sensitive to high frequency components of adversarial examples compared to adversarially-trained DNNs, and also that the adversarial examples corresponding to the latter exhibit more local consistency in the spatial domain. The paper then connects the effectiveness of an adversarial example to the concept of inducing larger differences in the local response of DNN layers compared to the corresponding natural example, denoted local response differences, and justifies this connection by empirically showing that: adversarially-trained DNNs have smaller local response differences on adversarial examples compared to standard DNNs; the smoother the DNN the better its robustness; successful attacks (adversarial examples) induce larger local response differences; and finally that adversarial examples transferred from other models, hence weaker examples, also induce smaller local response differences.","This paper studies the properties of adversarial examples from a spatial and frequency perspective and shows that naturally trained models are more vulnerable to high-frequency components in adversarial examples. Perturbations for naturally trained models are disordered, but perturbations for adv-trained models are image shape related. Based on these observations, the authors find that smoother adversarially-trained can achieve better robustness. ",0.15483870967741936,0.3870967741935484,0.22119815668202764
2385,SP:d9c6ad0938f6c842b3b2764daff1ad9f1631d891,"Additional to the maximally-fair consideration, this paper concerns the transparency in assembly selection problem. Specifically, the paper introduces the notion of transparency in panel selection as people can easy understand the probabilities with which each individual will be chosen for the panel and verify that individuals are actually selected with these probabilities. To achieve this, the paper studies the $m$-uniform lottery where the selection probability of each feasible panel must be multiples of $1/m$. The paper shows that there exists a uniform lottery over $m$ panels that can nearly preserve the fairness of the maximally-fair unconstrained distribution over panels.    Furthermore, the paper uses the fairness loss and marginal discrepancy to quantify the closeness of such lottery and the lottery obtained in an unconstrained (no transparency requirement) setting. The paper characterizes several upper bounds for these measures and further strengthen these bounds in more structured settings.   Lastly, the paper conducts experiments on real-world panel selection instances to demonstrate the viability of the uniform lottery approach as a method of selecting assemblies both fairly and transparently.  ","The paper discusses transparency in the context of sortition - selecting citizens to participate in a “Citizens’ Assembly” for the purpose of making policy recommendations. They seek to design algorithms which are approximately fair (with respect to three metrics - Maximin, Leximin, and NW) while being more interpretable/verifiable than disclosing selection probabilities. Their proposed solution is to design a uniform lottery, which selects a panel uniformly at random from a precomputed set of panels. They bound the fairness loss and deviation in marginals due to restricting to uniform lotteries, discuss LP rounding algorithms to find such lotteries, and run experiments on 11 real-world instances comparing the algorithms.",0.1787709497206704,0.29906542056074764,0.22377622377622378
2386,SP:d9f17344cd266b16a70c37d891b2c64a6d454908,"This paper introduces a unified model which combines label propagation algorithm (LPA) and graph convolutional networks (GCNs) for node classification. The motivation of this combination is supported by two analysis on the feature/label smoothing and feature/label influence. The proposed GCN-LPA framework utilizeds LPA to adjust the edge weight A* through the label information. Then, this edge weight A* is used to transfer the knowledge from label information to feature information for enhancing the representation learning in GCN. An end-to-end  solution is proposed by treating the LPA process as regularization. Overall, the idea of unifying GCNs and LAP in an end-to-end fashion is interesting. ","The paper proposed an unified model for Label Propagation (LPA) and Graph Convolutional Neural Networks (GCN). It is shown how it is possible to infer the relationship between LPA and GCN in terms of label or feature smoothing (how label/feature does propagate over the neighbors) and label or feature influence over the other nodes. The results are given in terms of two theorems (whose proofs are in an appendix) which essentially state that the total label influence of nodes with a particular label “l” on a specific node is proportional to the probability that node is labelled as “l” by LPA. In practice, LPA acts as a regularizer to learn transformation matrices and edge weights simultaneously in GCN. By means of a simple joint loss (eq.8), the regularized training show that transductive learning with the joint model surpasses GCN/GNN baselines. ",0.2818181818181818,0.21678321678321677,0.24505928853754938
2387,SP:da04daf3c2ef194dd3e9460acf3c967bb0222062,"This paper delves deeper into understanding shape-based representation of CNNs in an empirical way. Based on the stylized images, it proposes to use edge maps to more explicitly feed shape information to learning models. Besides, the common way to let models learn the shape-based representation is to train on the dataset contained the shape information while the texture information is severely distorted. The paper takes the point of changing the statistics of feature maps would result in style changes and proposed style-randomization to help CNNs better focus on shape information. Also, it connects the biasing degree on shape information of models with the defensive performance against common corruptions, like Gaussian additive noise, blur, and etc. An intuitive conclusion was drawn that there is no clear correlation between shape bias and robustness against common corruptions, and justified by extensive experiments. ","The paper disproves the hypothesis that addressing shape bias improves robustness to corruptions of neural networks, which has been stated by the previous studies [1, 2]. The paper demonstrates that the degree of shape bias of a model is not correlated with classification accuracy on corrupted images via experiments. For the experiments, this paper presents two novel methods to encourage CNNs to be shape-biased: 1) edge dataset and 2) style randomization (SR). In the experiments, the authors train CNNs to be shape-biased to various degrees based on the proposed methods. Additionally, they compare test accuracies of the models to evaluate shape bias and robustness to corruption. In addition, this paper shows that through fine-tuning the affine parameters of the normalization layers, a CNN trained on original images can achieve comparable, if not better, performance than a CNN trained with data augmentation.",0.1619718309859155,0.1597222222222222,0.16083916083916083
2388,SP:da1e92e9459d9f305f206e309faa8e9bbf8e6afa,"This paper proposes a multichannel generative language model (MGLM), which models the joint distribution p(channel_1, ..., channel_k) over k channels. MGLM can be used for both conditional generation (e.g., machine translation) and unconditional sampling. In the experiments, MGLM uses the Multi30k dataset where multiple high quality channels are available, in the form of multilingual translations.","This work is an extension of KERMIT (Chan et al., 2019) to multiple languages and the proposed model is called “multichannel generative language models”. KERMIT is an extension of “Insertion Transformer” (Stern et. al, 2019), a non-autoregressive model that can jointly determine which word and which place the translated words should be inserted. KERMIT shares the encoder and decoder of insertion Transformer, and the source sentence and target sentence are concatenated to train a generative model (also, various loss functions are included). In this work, parallel sentences from more than two languages are concatenated together and fed into KERMIT. Each language is associated with a language embedding. This work demonstrates that a joint distribution p(x1, . . . , xk) over k channels/languages can be properly modeled through a single model. The authors carry out experiments on multi30k dataset.",0.3275862068965517,0.13768115942028986,0.19387755102040818
2389,SP:da220d9a6a27b77e6aa2826d55d3ca20e0b3bc59,"This paper introduces an adaptive sample size quasi-Newton (AdaQN) method that exploits the superlinear convergence of quasi-Newton methods globally and throughout the entire learning process. The authors also provide convergence analysis to verify the AdaQN method, showing less gradient computation, as well as computational cost compared with previous SOTA methods. The numerical experiments on various datasets also confirm their theoretical findings. ",This paper  - introduces a new quasi-Newton (QN) algorithm called AdaQN to solve the ERM problem. This method is adaptive since it increases the sample size after few (3) runs of BFGS on a small ERM subproblem.  - gives its corresponding convergence analysis using a Matrix Bernstein bound - explains that AdaQN perfoms well because of the superlinear convergence on each subproblem which is possible when $m_0$ is large enough (greater than $\mathcal{O} (\kappa^2 log (d))$ if we leave out $s$) - provides clear comparison in term of theoretical computational cost is made against AdaNewton in Table 1  - performs numerical experiments showing the efficiency of the methods on small and medium size problems for l2 regularized logistic regression,0.2857142857142857,0.15254237288135594,0.1988950276243094
2390,SP:da2bdc7b32660092811416826572a6982cfc6e2c,"Paper proposes a contrastive learning-based approach to combine different data augmentation techniques for NLP tasks. While the widely used consistency loss focuses on a single example, the proposed contrastive objective allows capturing the relationships among all data samples which helps in producing diverse and informative examples. For experiments, the paper explores 5 data augmentation approaches with Roberta-large as the classification model. Empirical results on the standard GLUE benchmark leads to an impressive 2.2% average improvement. Authors also found that back-translation and adversarial training combination leads to better performance than other DA combinations.  ","The augmentation of NLP samples is an important task with no clear ""applicable to all"" mechanism. This is in sharp contrast to computer vision where techniques like rotation, modification of hue, saturation as well as umpteen other techniques exist. This work tries to address the issue by proposing a technique that carefully amalgamates multiple previously known approaches to generate diverse label preserving examples. The experimental results on RoBERTa highlight the applicability and importance of this data augmentation approach on the downstream task of text classification (GLUE).",0.125,0.13953488372093023,0.13186813186813184
2391,SP:da2ce3fdc90fc70d3f51e3e26fb844b4b1759af5,"The paper builds a privacy-preserving training framework within a Trusted Execution Environment (TEE) such as Intel SGX. The work is heavily inspired from Slalom, which does privacy-preserving inference in TEEs. The main drawbacks of Slalom when extending to training are (1) weight quantization needs to be dynamics as they change during training, and (2) pre-processing step of Slalom to compare u = f(r) isn't effective as the weights change, and running this within TEE is no better than running the full DNN within TEE. In addition, Goten also makes the weights private as opposed to Slalom. Overall, this is a very important contribution towards privacy preserving training and the paper takes a strong practical and implementation-focused approach by considering issues arising due to memory limitations in TEE and the performance implications of default Linux paging.","The paper proposes a method for privacy-preserving training and evaluation of DNNs. The method is based on a combination of hardware support from a trusted execution enclave (Intel SGX) and an algorithm for offloading intensive computation to unsecure GPU devices and communicating with the trusted environment without losing security guarantees during communication.  Compared to related work on a similar system (Slalom), the proposed system enables secure training in addition to inference.  The approach is based on the use of additive secret sharing to relegate chunks of computation to independent GPU servers.",0.16428571428571428,0.25,0.19827586206896552
2392,SP:da33f43dc72578ff039a1843c3bbbfc70ed4a685,"The paper proposes a regression approach that, given a few training (support) samples of a regression task (input and desired output pairs), should be able to output the values of the target function on additional (query) inputs. The proposed method is to learn a set of basis functions (MLPs) and a weight generator that for a given support set predicts weights using which the basis functions are linearly combined to form the predicted regression function, which is later tested (using the MSE metric) w.r.t. the ground truth. The method is trained on a large collection of randomly sampled task from the target family and is tested on a separate set of random tasks. The experiments include: ","The authors propose using sparse adaptive basis function models for few shot regression. The basis functions and the corresponding weights are generated via respective networks whose parameters are shared across all tasks. Elastic net regularization is used to encourage task specific sparsity in the weights,  the idea being  that with only a small number of available training examples, learning a sparse basis is  easier than learning a dense basis with many more parameters. The method is validated on both synthetic data and on image completion tasks. ",0.16101694915254236,0.22093023255813954,0.18627450980392157
2393,SP:da6583f39844661fbbbb50e2fbe6582ff3c3aa2a,"The derivative function of an ODE defines a vector field over the input space (augmented with time). Neural ODEs learn such vector fields when solving initial value problems. The authors propose a method that directly learns the flow of such a vector field, by learning a function that respects the constraints of a proper flow. This method avoids the need to perform a costly integration operation like in NODEs while also performing similarly or better.  ","This work proposes directly modelling the solution trajectories of an ODE, circumventing the need for costly numerical ODE solvers. Specifically, they model the function which returns a solution to the initial value problem, and derive conditions this function must satisfy in order to implicitly induce a valid ODE.  Crucially, the authors explain that Neural ODE models are not very interpretable, unlike more traditional applications of ODEs. Since we aren’t able to use the dynamics for interpretability, it makes sense to not modely them explicitly, and instead model its integral (via IVP) directly. (This is more my interpretation than what the authors stated explicitly.)  The authors propose several architectures, including ResNet flow and GRU flow. The issue with these models is that these models can only be inverted approximately and require expensive iterative schemes. A third approach is to design architectures inspired by normalizing flows, which trades off some expressivity for greater efficiency. The authors also consider the approximation capabilities of these models.  Section 3 introduces specific models for time-series and density estimation, and Section 4 compares these models to baselines on the relevant tasks. ",0.25333333333333335,0.10215053763440861,0.14559386973180077
2394,SP:da67860e703f8b08a84c6ba79fe3a32b33a187ad,"This paper proposed a method for **semi-supervised multi-view regression** based on **data augmentation** and an **undirected graphical model**. The author derived a ""**consistency**"" term for unlabeled data and a ""**diversity**"" term for labeled data based on their log-likelihood and combined them linearly with two hyperparameters. The proposed method was evaluated on tabular and image data and analyzed via ablation study.","This paper concerns the semi-supervised problem. Different from SOTA deep semi-supervised methods, the proposed DiCom employs a diversity measure on the labeled multi-view data, and combines diversity with consistency based on underlying probabilistic graphical assumptions. Experiments verify the effectiveness.",0.19047619047619047,0.2857142857142857,0.22857142857142854
2395,SP:da7dee28613a006abf6dc5717d4d711bcad210f6,"This paper proposes a novel meta-learning framework that utilizes auxiliary learning tasks of link predictions and label generations to improve the performance of GCNs on node classifications tasks. The meta-learning algorithm adopts the idea from [Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks](https://arxiv.org/abs/1703.03400) so that the models for auxiliary tasks are updated in a way that has higher impacts on the primary task.  The authors use two self-supervised learning tasks, edge predictions and label generation, as the auxiliary tasks.  The method performs favorably in the three standard public graph data sets with higher prediction accuracy.","The paper proposes a new auxiliary learning method to improve the existing GCNs. Considering that the edges in many graphs are unweighted and nodes labels are often one-hot, the authors added two auxiliary tasks to enrich the topology information in the graph node classification task. One is link prediction which generates probabilistic edges; and the other is to generate soft labels. The probabilistic edges and soft labels are iteratively updated by a meta auxiliary learning strategy in a smart way, and the results on three standard benchmark datasets outperform some baselines. ",0.2169811320754717,0.25,0.23232323232323232
2396,SP:da88bd545609da190d45106b615b2b1bbc132279,"In this work the authors propose a novel memory architecture wherein memories are stored in multiple ways across a series of memory blocks. By ""distributing"" the memories in such a manner, the model can flexibly retrieve one version of a memory or another, which enables more flexible computations when conditioning on that memory. The authors demonstrate that such a memory network does well in tasks involving relational reasoning. ","The authors propose a distributed memory architecture which shares some interface with the Differentiable Neural Computer however crucially segments memory into a collection of K units. The authors show that by increasing K the model learns to use its memory for algorithmic tasks such as copying and associative recall and learn faster. The authors also propose an auxiliary loss to improve memory representations, which involves reconstructing inputs from the representations in memory. ",0.23529411764705882,0.2222222222222222,0.22857142857142856
2397,SP:daa7f595becc6effe95530db02786d6de6b51e3f,"This paper present a study on efficient acoustic modeling using neural networks-based model. Four approaches are presented and evaluated: diag LSTM, QRNN, Gated ConvNet and adding a 1D convolution layer. The evaluation is done on ASR task using WSJ and in phoneme classification task using the TIMIT corpus. The study show that the inference speed is improved with comparable of better performance than the standard LSTM model.","This paper discusses applications of variants of RNNs and Gated CNN to acoustic modeling in embedded speech recognition systems, and the main focus of the paper is computational (memory) efficiency when we deploy the system. The paper well describes the problem of the current LSTM, especially focusing on the recurrent connection matrix operations, which is a bottle neck in this scenario, and introduces variants of RNNs (e.g., QRNN). Also these variants may not yield enough performance compared with LSTM, but 1-D convolution and/or deep structure helps to avoid the degradation. One of the biggest issues of this paper is that they use CTC as an acoustic model, while still many real speech recognition applications and major open source (Kaldi) use hybrid HMM/DNN(TDNN, LSTM, CNN, etc.) systems. Therefore, the paper's claim on CTC is not along with the current application trends. (It may be changed near future, but still hybrid systems are dominant). For example, the WSJ WER performance listed in Table 3 is easily obtained by a simple feed-forward DNN in the hybrid system. The latest Lattice free MMI with TDNN can achieve better performance (~2.X% WER), and this decoding is quite fast compared with LSTM. The authors should consider this current situation of state-of-the-art speech recognition. Also, the techniques described in the paper are all based on existing techniques, and the paper lacks the technical novelty.",0.27941176470588236,0.07983193277310924,0.1241830065359477
2398,SP:dab57601f3910855870d72fb2729f4ce011f11a7,"The paper prposes to learn an inverse network to predict x given a target y for optimisation, instead of the traditional way of optimisation (e.g. using Bayesian optimisation for the complex cases considered in the paper). However, unfortunately, this paper is too close in concept, and in my understanding lower in the solution quality to this recent paper:","This paper tackles the problem of solving a black-box optimization problem where only some samples have been observed. This task requires a good model that can be both expressive and generalizable. Instead of learning only a single forward model of x -> y, this paper proposes to additionally use a mapping from y -> x. Optimizing in the space of z instead of x can be much simpler, and this should also act as a strong regularizer during training. Specifically, the paper uses a GAN that transforms [y,z] -> x, where z is stochastically sampled. This paper further proposes a reweighting scheme that interpolates between a uniform weighting and weighting the best sample so far, as well as a sampling procedure that iteratively samples points and refits a second model, which was inspired by Thompson sampling.",0.22033898305084745,0.0962962962962963,0.13402061855670103
2399,SP:dac2e985d39e3466dafbf20124fdafe0f5b9bd24,"The authors propose a functional approximation to the error of pruned convolutional neural networks as a function of network hyperparameters. This functional approximation depends on a number of hyperparameters that are fit on the error of already trained and pruned networks on a certain task (in this case, image classification on CIFAR-10 and ImageNet are the tasks under consideration). The authors demonstrate that this fit is very accurate over many orders of magnitude, which demonstrates their hypothesis on the power law nature of the error distribution as a function of the hyperparameters under consideration.","This paper studies how to estimate the performance of pruned networks using regression models. The authors first empirically observe that there exist three distinct regions of sparsity: (1) In the low-sparsity regime, pruning does not decrease the accuracy (2) In the mid-sparsity regime, a linear relationship between the sparsity and the accuracy is observed (3) In the high-sparsity regime, pruning does not decrease the accuracy again. Under this observation, the authors proposed a regression model called the rational family and empirically verified its performance. The authors further extended this model to incorporate the network width and depth under some empirical observation called the error-preserving invariant. The authors performed experiments to verify different perspectives of the proposed functional form.",0.21052631578947367,0.16393442622950818,0.18433179723502302
2400,SP:daf8080733b61b118faad8dca6f09691ecaa3005,"This paper presents a new deep reinforcement learning method that can efficiently trade-off exploration and exploitation. An optimal policy for this trade-off can be solved under the Bayesian-adaptive MDP framework, but in practice, the computation is often intractable. To solve the challenge and approximate a Bayesian-optimal policy, the proposed method VariBAD combines meta-learning, variational inference, and bayesian RL. Specifically, the algorithm learns latent representations of task embeddings and performs tractable approximate inference by optimizing a tractable lower bound of the objective.","This paper considers a version of reinforcement learning problem where an unknown prior distribution over Markov decision processes are assumed and the learner can sample from it. After sampling a MDP, a standard reinforcement learning is done. Then the paper investigates the Bayes-optimal strategy for such meta-learning setting. The experiments are done for an artificial maze solving tasks. ",0.16279069767441862,0.23333333333333334,0.19178082191780824
2401,SP:db45d6d64491b9bf610e493af2247d9f4d578d68,"==+== A. Paper summary  This paper proposes a new model architecture to encode assembly code. By using a new reconstruction loss with the new architecture, the paper achieves better fine-tuning results on downstream binary code similarity detection tasks. ","This paper proposes an enhanced transformer for dealing with the generation of assembly code. This is achieved by feeding the model with one instruction at the time (as BERT did), and hence each of these is divided into sub-words in a position-preserving way. The authors shows the efficacy of GenTAL against many other work proposed in literature, showing that their solution is able to better grasp all the possible different level of optimization applied by the compiler (O1 to O3).",0.2631578947368421,0.12195121951219512,0.16666666666666666
2402,SP:db8ceeba535e0a4d0102ce512d9db4e53fc8971f,"This paper shows that a backdoored pre-trained model can behave maliciously in various downstream tasks without foreknowing task information. Instead of building up connections between triggers and target labels, this paper explores to assign predefined output representations to triggers. Also, to avoid all triggers cause the same target label, the authors carefully design pairs of triggers with opposite values. Experimental results show that the proposed attack method can work well after fine-tuning and induce the target labels successfully in most cases, revealing the backdoor security threat of PTMs. Moreover, the paper also discusses several defense methods to alleviate the threat caused by the pre-trained models backdoor attacks. ",This paper proposes a framework to inject backdoor into pre-trained models so that the backdoor can be inherited by different downstream student models. The key part of the attack is to restrict the output representations of backdoor samples via a proposed loss function. Experiment results show that the proposed method successfully injects backdoors to NLP and CV tasks.,0.18181818181818182,0.3389830508474576,0.23668639053254437
2403,SP:dbabb260baf9daed8066d80ef49ec0cfa9f70ae6,"The paper is based on the works of Lee et al and Cohen et al. Building upon these works, the paper comes up with an interior point method that matches the state-of-the-art in LPs. The paper's contribution is in a new type of sketching used inside the interior point method, that demonstrates some advantages over those of Lee et al and Cohen et al. Notable among these advantages are (1) the ability to preserve sparsity of an LP, and (2) exact solutions to the system of linear equations obtained from optimality conditions. ","The paper studies the problem of solving LP and more generally convex programming via sketching based approaches. In particular, the running time of proposed algorithm in this paper matches the running time of the best known algorithms [Cohen et al(19b) and Lee et al(19)]. However, this paper provides some further useful properties: 1) oblivious sketching, 2) sparse sketching which can be of interest in many applications. The paper has provided theoretical guarantees of their proposed algorithm. The problem that is studied in this paper is very important and the sketching based approach is also very practical. The paper would benefit from an empirical comparison of the proposed algorithm with the existing methods for solving LPs.  ",0.22916666666666666,0.18803418803418803,0.20657276995305163
2404,SP:dbb0ed3b53fc0905982b51853e83f5cdbaf3b535,"The paper describes an MLP architectures for problems in which the features do not have a known structure (eg, tabular data). A ""differentiable routing matrix"" partitions the data into K blocks. Then, standard MLPs are applied to each block and the results are recursively aggregated by moving forward in the model.","This paper studies supervised classification problems where features are unstructured. For these problems, the authors propose a new neural network architecture that first reorganize the features into groups, then builds feed-forward networks on top each group, and finally aggregate the hidden nodes of each group to produce the final output. Empirical and ablation studies are conducted to show the performance of this approach. ",0.2549019607843137,0.203125,0.22608695652173913
2405,SP:dbb2e549f21492129fac9e6944485440cfe093e0,"So this paper is interesting. It's sort of pursuing a similar path as recent works that use neural networks to evaluate (e.g., inception score, FID), notably those that optimize some lower bound of an information measure (e.g., MINE). In this case, the setting is ""datasets"", and the thing they are trying to quantify is the difficulty of the dataset as expressed by a lower bound to the lowest possible probability of the 0-1 error, which they should is related to the conditional entropy of the underlying input / label random variables (which makes sense). This direction seems very useful, and using neural network optimization to attempt to crack defining ""dataset complexity"" or ""difficulty"" seems a worthwhile venture.","The paper proposes a measure of difficulty for datasets. Prior work in this space has often utilized certain indicators like the overlap of samples across different classes etc. [A] While this work defines a model-agnostic error as the measure of difficulty, which should encompass all possible indicators of error. Then, the paper provides a lower bound on this error which can be estimated using neural network [B]",0.15,0.2647058823529412,0.19148936170212766
2406,SP:dbc876d7c158f89a0f22a4688ff05abca2ad5ddc,"The authors propose Glancing Transformer for single step parallel text generation. The approach is inspired from curriculum learning i.e. the training task is adaptively controlled based on the model's current performance. Specifically, the paper proposes a glancing strategy which compares the model's generation and reference sentence, and forms a sequence which is partially masked. The number of masked tokens in this sequence depends on the similarity between model's generation and reference sentence. The model is then trained to complete the partially masked sequence. ","This submission improves non-autoregressive translation (NAT) by proposing a non-iterative parallel text generation model called Glancing Transformer (GLAT), which includes the explicit word dependency modeling in NAT via a proposed Glancing Language Model (GLM). Compared to previous work, biggest contribution of the proposed method is that it improves the training of NAT model with a similar idea of curriculum learning, while keeping the inference time unchanged, setting a significant improvement for non-iterative NAT without reranking. It would be a good baseline for future research on non-iterative NAT models. ",0.14942528735632185,0.14130434782608695,0.14525139664804468
2407,SP:dbd3d412c69a5406bed19f1a0be0d9f01116307c,"The paper studies the scaling law relation between $t$ (time) and the population loss in the NTK regime. The authors show that the scaling law is determined by two indices, (1) the index of the power law decay of the spectrum of the NTK (2) the index of the power decay of the residual of the loss on the eigenfunctions of the NTK.  The main technical contribution is the computation of the two indices.   ","The paper identifies a polynomial decay rate in the loss function during gradient descent under the condition that both the eigenvalues of the semigroup operator, and the coefficients in the eigenfunction expansion of an initial loss (g), exhibit power law decay. These assumptions are verified for the semigroup operator in the infinitely wide (NTK) regime, a mean field regime, and also, interestingly, under a homogeneity assumption in the transition kernel. Two scenarios for g are also considered. Throughout, the authors have taken care to be precise with coefficients and compute quantities exactly. ",0.25675675675675674,0.20652173913043478,0.2289156626506024
2408,SP:dbf3b29b09d25f698ec0a252e63c4060a9c5cb70,"This paper proposes Permutation Phase Defense (PPD), a novel image hiding method to resist adversarial attacks. PPD relies on safekeeping of the key, specifically the seed used for permuting the image pixels. The paper demonstrated the method on MNIST and CIFAR10, and evaluates it against a number of adversarial attacks. The method appears to be robust across attacks and distortion levels.","This paper explores the idea of utilizing a secret random permutation in the Fourier phase domain to defense against adversarial examples. The idea is drawn from cryptography, where the random permutation is treated as a secret key that the adversarial does not have access to. This setting has practical limitations, but is plausible in theory.",0.18032786885245902,0.2,0.1896551724137931
2409,SP:dbf67fa98a71f8c3b7b62e9b5695ced62bcb730d,"This paper uses results from distributional robustness to provide bounds of p-norm-constrained adversarial risk which depend on the Lipschitz constant of the underlying classifier. The bulk of the paper focuses on sample-efficient mechanisms to approximate the Lipschitz constants of kernel methods so that a constraint on this Lip constant can be enforced during training. Empirically, the kernel methods are compared to existing deep learning approaches and are shown to be competitive at this scale.","Through the lens of Distributional Robust Risk (DRR), this work draws a link between adversarial robustness and Lipschitz constant regularisation. The authors first provide an upper bound of the DRR (with a Wasserstein ball as the ambiguity set) in terms of the true risk and the Lipschitz constant of the loss function under the current model. They show that the standard adversarial risk can be upper bounded by the DRR, emphasizing that the Lipschitz constant regularised loss can be used as a proxy for adversarially robust training.",0.23376623376623376,0.20689655172413793,0.21951219512195122
2410,SP:dc098f0332d6cda0884d293608bf992133b9aa20,"The paper proposes a continuous CNN model to accommodate the nonuniform time series data. The model learns the interpolation and the convolution kernel functions in an end-to-end manner, so that it can capture the signal patterns and be flexible. A layer has three networks, which learn a kernel function to represent the combination of interpolation and convolution, a bias function to represent the error correction with convolution, and then produce the output based on them. The authors introduce two assumptions and a two-hot encoding scheme for the input to control the model complexity. The paper also introduces an application of the proposed CCNN by combing with temporal point process. Experiments on simulated data compares the proposed method with some degenerative baselines show the advantage of learning the interpolation and the two-hot encoding configuration. The authors compare the performance on time interval prediction task based on real world dataset to show the model produces a better history embedding for the task.","A method that was proposed by authors deals with a problem of non-uniform data in time series. One of ways to deal with this problem is interpolate input signal between data points. In signal processing a standard way to interpolate is to apply a convolution with a kernel. This operation, by itself, is a non-trivial, since we lack any information about signal's spectrum (and do not know optimal kernel). Thus, the authors propose to search for a kernel in a form neural network. To this term they also add bias term which is also a neural network. ",0.10365853658536585,0.17,0.12878787878787878
2411,SP:dc1876416671e10eece54246ccc102eefafe46b7,"The author considers the setting of the MDP is sampled from a known prior $\phi$ rather than a fixed unknown one, which belongs to Bayesian reinforcement learning. Under this setting, the author firstly introduces an expected upper bound on the optimal Q-value $Q^{\star}_l(s, a)$, then introduces a new operator called optimistic Bellman operator. This operator combines the principle of using upper confidence bound to encourage exploration and the randomness influence of the transition kernel and rewards, providing a sequence of optimistic estimation of the optimal Q-value. Furthermore, it also uses a soft-max exploration policy to sample from the environment.  Based on these components, K-learning is proposed and has been proved to enjoy a tight Bayes regret bound $O(\sqrt{L^3SAT})$. More numerical experiments are conducted to show the performance with comparisons to existing methods. ","The paper proposes K-learning, a reinforcement learning exploration heuristic with Bayesian regret bounds. The authors adopt a Bayesian perspective under which long-term (Q-)values have epistemic uncertainty associated with them. They argue that exploration behaviour can be induced by maximising a particular (exponential) utility function of the resulting distributions. It is shown, that these utility scores obey a Bellman-like operator and can be computed using dynamic programming and an algorithm for episodic settings is proposed.  The authors link the optimal policy maximising the new objective to entropy regularised approaches, discuss the optimal selection of a temperature parameter governing risk-sensitivity and provide formal regret bounds under certain assumptions regarding the structure of the agents prior. Finally, K-learning is compared empirically to a number of exploration baselines where it performs competitively. ",0.1619718309859155,0.17164179104477612,0.16666666666666669
2412,SP:dc4dbc42defdc5f34bdfb2288fb33986ba348f8c,"The authors propose to include the mutual information between agents' simultaneous actions in the objective to encourage coordinated behaviour. To induce positive mutual information, the authors relax the assumption that the joint policy can be decomposed as the product of each agent's policy, independent of each other given the state, and they achieve so by introducing a latent variable that correlates agents behaviours. Since the mutual information is difficult to compute, the authors proposed to maximise a parametric lower bound. The algorithm is theoretically motivated as a policy iteration variation in its exact tabular form. But experiments are performed with neural network approximations on some environments. Numerical results show improvements over previous similar techniques.","- This paper proposes a Maximum Mutual Information framework for cooperative MARL. Following the insight that mutual information of agents’ policies is the indicator of coordination, this paper proposes VM3-AC, an MA-AC algorithm that optimizes long-term reward as well as a variational lower bound of mutual information in the paradigm of CTDE. Experimental results show superiority of proposed algorithm in comparison with a few benchmark approaches.",0.1391304347826087,0.23529411764705882,0.17486338797814205
2413,SP:dc605d174368de20c31edca06ef90fc18fb79faa,"This paper focuses on domain generalization, targeting the challenging scenario where the training set might not include different sources; even under the presence of different sources, the problem formulation does not takes into account domain labels. The proposed solution is based on meta-learning, following the path drawn by Li et al. AAAI 2018; the Authors propose to adversarially split the training set in meta-train and meta-validation sets, and then update the current model in a direction that fosters good generalization performance on the meta-test. Results on standard benchmarks are encouraging.","This paper proposes to unify adversarial training and meta-learning in domain-free generalization where labels of source domains are unavailable. To maximize the domain shift between the subsets of meta-train and meta-val, adversarial training is leveraged to find the worst-case train/val splits. Extensive experiments on benchmark datasets under different settings demonstrate the effectiveness of the proposed method. ",0.1702127659574468,0.25806451612903225,0.20512820512820512
2414,SP:dc61f3b946fd4ff24d64e8a34483dd2bd0b1b333,"The paper deals with the problem of simultaneously learning node embeddings and detecting communities on graphs. Although both tasks are particularly important while analyzing networks, most of the proposed approaches address them independently. The paper proposes a generative model, called VECODER, that aims to jointly learn overlapping communities and node representations. The proposed model follows a variational formulation which assumes that the node embeddings are generated from a prior distribution; this can be used to control how community embeddings are sampled. This leads to an encoder-decoder architecture, where the decoder ensures that similar (i.e., connected) nodes will obtain similar embeddings. The proposed model has been empirically evaluated on three tasks (overlapping and non-overlapping community detection, and node classification), and the performance has been compared against various baseline models.","This paper aims to learn node representations of graph to jointly satisfy node embedding properties and community detection property. Node embedding must preserve proximities guaranteeing that adjacent nodes are closer than others. Community detection must promote more similar clustering assignments to adjacent nodes than others. These two problems have been tackled separately or simultaneously but with maintaining two different node representations. The authors claim that the proposed VECoDeR is capable of learning a single community-aware node representation per node, which is jointly effective in both scenarios.",0.1297709923664122,0.19540229885057472,0.1559633027522936
2415,SP:dc665b731d4611b6164b2f84a031fa8b8d3701da,"This paper leverages similar code-summary pairs from existing data to assist code summary generation. The model first retrieves a similar code snippet from the existing database. Then, the author applied GNN over the code property graphs (CPGs).  A challenge is that CPGs are typically deep therefore it is difficult to capture long dependencies. The author proposed an attention mechanism to capture global information between nodes, and then a hybrid GNN layer encodes the retrieve-augmented graph.  Finally, a generator takes both GNN's output and the retrieved text summary and predict outputs. Experimental results over a new C code indicates that the proposed method outperforms both IR and neural generation methods.",This paper proposes a retrieval-augmented method for generating code summarization. The model encodes the input code based on its graph structure (Code Property Graph) with a hybrid GNN architecture. The model augments the initial graph representation of the input code based on the representation of the top-1 retrieval result. It also augments the final graph encoding with the BiLSTM encoding of the retrieved summary.,0.14285714285714285,0.24242424242424243,0.1797752808988764
2416,SP:dc768f825220140d0fa00fe2f63673803973c19c,"The paper studies reward-free reinforcement learning (RL) methods based on empowerment. The authors propose a technique for empowerment estimation under the assumption that a state after H timesteps can be factorized as a product of the current action and a matrix G(s) that depends on the current state. In contrast to the existing methods that rely on the optimization of variational lower bounds on mutual information for empowerment estimation, the technique allows having an almost closed-form expression for empowerment. The authors qualitatively demonstrate the convergence of their method to the true empowerment function on simple environments such as 2D ball-in-box as well on image-based Pendulum environment.","The paper proposes an new algorithm to simultaneously estimate and maximise empowerment for achieving unsupervised stabilization. The method relies on the formulation of a dynamic system as a linear Gaussian channel. In this formulation, empowerment can be efficiently estimated by solving a line search problem. The authors propose to learn the channel matrix G(s) from samples and exploit then linear formulation to learn a corresponding policy maximising empowerment. These two steps are done in an alternating fashion until convergence. In the experiments the method is compared to previous approaches for unsupervised control via empowerment. The authors show convergence close to the true empowerment landscape and prove the sample efficiency and low variance of their method. Additionally, their method is capable of unsupervised control based on image observations.",0.24107142857142858,0.2109375,0.22499999999999998
2417,SP:dc8557f06ebb81345d2edeb98716e8327dcb30d8,"This work is focused on topological characterization of target surfaces of optimization objectives (i.e. loss functions) by computing so called barcodes, which are lists of pairs of local minima and their connected saddle points. The authors claim that the barcodes constitute a representation of target objectives that is invariant under homeomorphisms of input to the objectives. The authors present an algorithm for computing the barcodes from graph-based representation of a surface, and present barcodes computed on toy examples in numerical analysis. ","This paper introduces the notion of barcodes as a topological invariant of loss surfaces that encodes the ""depth"" of local minima by associating to each minimum the lowest index-one saddle. An algorithm is presented for the computation of barcodes, and some small-scale experiments are conducted. For very small neural networks, the barcodes are found to live at small loss values, and the authors argue that this suggests it may be hard to get stuck in a suboptimal local minimum.",0.20481927710843373,0.20987654320987653,0.20731707317073172
2418,SP:dcb93f2170b1cc1c2e6bfba98328299243b1d483,"This paper studies variance neural networks, which approximate the posterior of Bayesian neural networks with zero-mean Gaussian distributions. The inference results are surprisingly well though there is no information in the mean of the posterior. It further shows that the several variational dropout methods are closed related to the proposed method. The experiment indicates that the ELBO can actually better optimized with this restricted form of variational distribution. ","This paper introduced a new stochastic layer termed variance layer for Bayesian deep learning, where the posterior on weight is a zero-mean symmetric distribution (e.g., Gaussian, Bernoulli, Uniform). The paper showed that under 3 different prior distributions, the Gaussian Dropout layer can converge to variance layer. Experiments verified that it can achieve similar accuracies as conventional binary dropout in image classification and reinforcement learning tasks, is more robust to adversarial attacks, and can be used to sparsify deep models.",0.21739130434782608,0.18518518518518517,0.19999999999999998
2419,SP:dccdd07d4daa907b04b330248f9a796cf2e2f361,"This paper proposes using homoglyphs to attack commercial NLP models for sentiment classification. Homoglyphs look like the characters in English language but they are encoded differently and, therefore, treated differently by the model. They experiment on various MLaaS models and show that their attack can effectively cause both targeted and untargeted misclassifications.",The paper proposes an attack method that generates homoglyph adversarial examples for NLP APIs. The method replaces English characters with other international characters that look similar. The paper shows empirically that the method achieves good performance for several real-world APIs. ,0.15384615384615385,0.1951219512195122,0.17204301075268819
2420,SP:dce8715440bee1c1dbf8fabc4f0c85bd5d7ddf1f,"This paper studies meta-learning problem with few-shot learning settings. The author proposes a learn each task predictive function via the form of random Fourier features, where the kernel is jointly learned from all tasks. The novel part is the parametrization of inference network using LSTM such that the random feature samples of t-th task conditional depending on all previous task 1,...,t-1, which is an interesting way of modeling kernel spectral distribution. The experiment results show improvement of the proposed methods compared to SoTA meta learning algorithms.","This paper proposes a meta-learning framework for learning adaptive kernels using a meta-learner. For representing kernels, the paper learns a variational posterior for the kernel features, by maximizing the Evidence lower Bound. Furthermore, to plug the kernel learning into the meta-learning framework, they let the variational feature posterior to condition on the current support set for adapting and to use a modified LSTM network for accumulating information. Empirically, they compare the proposed MetaVRF with multiple baselines in the standard fewshot classification benchmarks and demonstrate superior performance. They also illustrate that their adaptively-learnt Fourier feature outperforms the standard variational Fourier features.",0.1978021978021978,0.17307692307692307,0.1846153846153846
2421,SP:dd15ed83a39c92452558a7b4eb97cdc4a74e4542,"The paper considers the problem of recovering the span of the latent variables of a neural network with various activation functions. More precisely, if we write a neural network as M(x) = f(Ax), for some neural network f, and a matrix A: R^{k x d} -> R^{k}, k << d, we wish to recover the row span of A. The authors consider ReLU activations -- in which case they can recover at least ""half"" of the row span with ~kd queries to M(x), and smooth activations -- in which case they can approximately recover the row span in poly(k,d) queries. The authors also consider (empirically) applications of these algorithms to ""input obfuscation"": namely generating samples which are effectively noise, but the network classifies them as ""structure"" (e.g. digits on MNIST). ","The paper studies how to recover the span of a NN from a limited number of queries. The problem belongs to the general question of how to reconstruct functions from black-box interaction and it may find application in obfuscation attacks where very large perturbations of the input do not affect the output. The main contribution of the paper is on the theoretical analysis of a simple non-adaptive and a more sophisticated adaptive algorithm. The main finding is that under mild conditions on the structure of the NN partial recovery is possible. The empirical validation show that in practice, it is often the case the full span recover is actually possible, as the structure and weights of common NN are ""friendly"" enough.",0.17293233082706766,0.18699186991869918,0.17968750000000003
2422,SP:dd6a80c29d23d8ee356c637fff15c8d28956fba3,"The authors focus on the class imbalance problem and propose an algorithm named ROGA to generated samples of minority classes to balance the quantitative difference between classes. Specifically, the proposed ROGA generates samples of minority classes by using a Genetic Algorithm (GA) to explore the sample space. Moreover, to reduce the noise samples generated by ROGA, the authors propose to calculate the fitness as the Gaussian similarity with the surrounding samples and eliminate the samples with low fitness. My detailed comments are as follows.","In this work, the authors propose an oversampling technique which creates a population of synthetic samples for an imbalanced dataset using genetic algorithms. Each individual in the GA population corresponds to a synthetic sample, and the fitness function is based on the similarity (in feature space) of the synthetic sample compared to nearby samples of the same and different classes; standard crossover and mutation operators are used. In a limited set of experiments, the proposed approach sometimes outperforms competing approaches.",0.2261904761904762,0.2375,0.23170731707317072
2423,SP:dda4b48c036e1f4b90c93aa919d9df3e7ceabd3e,"This work considers the problem of learning a non-linear dynamical system in which the output equals the state.  Under several assumptions (input is Gaussian, non-linear activation is strictly increasing, stable system) it is shown that SGD converges linearly to the ground truth system with near-optimal sample complexity. The proof idea is to reduce this problem to the problem of learning a single non-linear neuron in the case that the covariance matrix of the data is well-conditioned. The main challenge is to show the covariance is well-conditioned under the reduction. In a nutshell, this is done by splitting the trajectory to sub-trajectories with independent states and using results from random matrix theory on matrices with independent rows.","The paper studies discrete time dynamical systems with a non-linear state equation.  They assume the non-linear function is assumed to be \beta-increasing like leaky ReLU. Under this setting, the authors prove that for the given state equation for stable systems with random gaussian input at each time step, running SGD on a fixed length trajectory gives logarithmic convergence.",0.13008130081300814,0.26229508196721313,0.1739130434782609
2424,SP:ddc70109c59cf0db7fe020300ab762a5ac57bd93,"This paper studies the internal representations of recurrent neural networks trained on navigation tasks. By varying the weight of different terms in an objective used for supervised pre-training, RNNs are created that either use path integration or landmark memory for navigation. The paper shows that the pretraining method leads to differential performance when the readout layer of these networks networks is trained using Q-learning on different variants of a navigation task. The main result of the paper is obtained by finding the slow points of the dynamics of the trained RNNs. The paper finds that the RNNs pre-trained to use path integration contain 2D continuous attractors, allowing position memory. On the other hand, the RNNs pre-trained for landmark memory contain discrete attractors corresponding to the different landmarks.","This paper explores how pre-training a recurrent network on different navigational objectives confers different benefits when it comes to solving downstream tasks. First, networks are pretrained on an objective that either emphasizes position (path integration) or landmark memory (identity of the last wall encountered). This pretraining generates recurrent networks of two classes, called PosNets and MemNets (in addition to no pre-training, called RandNets). Surprisingly, the authors found that pre-training confers different benefits that manifests as differential performance of PosNets and MemNets across the suite. Some evidence is provided that this difference has to do with the requirements of the task. Moreover, the authors show how the different pretraining manifests as different dynamical structures (measured using fixed point analyses) present in the networks after pre-training. In particular, the PosNets contained a 2D plane attractor (used to readout position), whereas the MemNets contained clusters of fixed points (corresponding to the previously encountered landmark).",0.26717557251908397,0.22580645161290322,0.24475524475524474
2425,SP:ddc8dc071cf5bcb28d68a58a9a4553ad4f628844,"Stating the observation that the RL agents with neural network policies are likely to be fooled by adversarial attacks the paper investigates a way to decrease this susceptibility.   Main assumption is that the environment is aware of the fact that the agent is using neural network policies and also has an access to those weights. The paper introduces a poisoning attack and a method to incorporate defense into an agent trained by DQN.  Main idea is to decouple the DQN Network into what they call a (Student) policy network and a Q network and use the policy network for exploration. This is the only novelty in the paper. The rest of the paper builds upon earlier ideas and incorporates different training techniques in order to include defense strategies to the DQN algorithm. This is summarized in Algorithm 1 called DadQN. Both proposed training methods; adversarial training and Provable robust training are well known techniques. The benefits of the proposed decoupling is evidenced by the experimental results. However, only three games from the Atari benchmark set is chosen, which impairs the quality of the evidence. In my opinion the work is very limited in originality with limited scope that it only applies to one type of RL algorithm combined with the very few set of experiments for supporting the claim fails to make the cut for publication.","The goal of this paper is to train deep RL agents that perform well both in the presence and absence of adversarial attacks at training and test time. To achieve this, this paper proposes using policy distillation. The approach, Distilled Agent DQN (DaDQN), consists of: (1) a ""teacher"" neural network trained in the same way as DQN, and (2) a ""student"" network trained with supervised learning to match the teacher’s outputs. Adversarial defenses are only applied to the student network, so as to not impact the learning of Q-values by the teacher network. At test time, the student network is deployed.",0.12389380530973451,0.27184466019417475,0.17021276595744683
2426,SP:ddd7d3c20a2aed0e4408e88e37806824c5d52b4d,"This paper proposes to adapt the RTRL technique when training RNNs to make it usable in practice. That is, instead of computing the full gradient of the loss $L$ according to all parameters, the proposed method ""DODGE"" consists in computing the gradient of $L$ in *one* or a small number of directions in the parameter space. These ""directional gradients"" of $L$ are much easier to compute than the full gradient when using RTRL. More precisely, the user can choose a subspace $\mathcal{P}'$ (of dim. $p'$) of the space of parameters $\mathcal{P}$ (of dim. $p$), and compute the projection of the true gradient $g^*$ of $L$ on the space $\mathcal{P}'$, *with a computational cost proportional to $p'$*. This is advantageous when $p' \ll p$.  Notably, this method can be used in two ways:  * estimating the true gradient by computing its projection on a random low-dimensional subspace of the parameters;  * improve an existing estimation $\hat{g}$ of the true gradient $g^*$ by computing the projection of $g^*$ on $\hat{g}$: this projection has better properties than $\hat{g}$.","The paper proposes a new gradient-based learning algorithm for recurrent neural networks, making use of the directional derivative along a candidate direction. The directional derivative serves the purpose of improving the usefulness of a given candidate direction for gradient-based parameter updates by computing the projection of the gradient along the given direction. The candidate direction can come from various sources such as randomly sampled directions, truncated backpropagation through time (BPTT), the “Reptile” meta-learning approach by Nichol et al. (2018), or synthetic gradients. The authors call this technique “deep online directional gradient estimate” (DODGE) and demonstrate it in several experiments including a copy task (Graves et al. 2014) and a NeRF task (Mildenhall et al. 2020).",0.12777777777777777,0.19491525423728814,0.15436241610738252
2427,SP:dde554a1db9bb15202e77adaf6edd9868865605b,"The paper proposes an approach to interpret a black-box control policy of a reinforcement learning (RL) problem such that its interpretations can be understood by a human user. For a given expert policy (i.e., a fitted deep neural network), the proposed approach uses transition probabilities induced by the expert policy to define regions of the state space that are “similar.” These policy-dependent regions are referred to as meta-states and are computed using an algorithm similar to spectral clustering. The proposed method then computes so-called strategic states for each meta-state, where strategic states of a meta-state are those states that belong to the meta-state and bridge the meta-state to other ones. In other words, the expert policy should pass through the strategic states frequently when it goes from one meta-state to another. The paper performs numerical experiments using standard RL applications, i.e., four rooms, door-key, and mini-Pacman, to show the effectiveness of the proposed approach.","This work proposes to explain an RL policy by clustering states into meta-states and presenting strategic state(s) for each meta-state. This clustering is performed based on policy rollouts, balancing likelihood of paths within a meta-state and number of paths from states within the meta-state. The authors present example explanations for three domains. A user study is performed to compare VIPER-D to the proposed method (SSX).",0.15568862275449102,0.36619718309859156,0.2184873949579832
2428,SP:ddea48ce0c858d47e27f5ab2d31db225b2396479,"This paper draws connection between performance of GNN and training set coverage in the graph. Specifically, it proposes theoretical study towards structural relation between them in terms of graph distance and empirical classification loss. A set of experiments are designed to validate the theory and assumption on three graph dataset. Further, the proposed idea is used in active learning as guidance.","This paper considers the problem of training set selection for graph neural network training. It shows that the generalization from the training to the test set in a well-trained graph neural network is closely tied to the shortest path distance in the graph, which motivates training strategies that ""cover"" the graph in this sense. The authors apply these ideas in a subset selection program, and verify their results with numerical experiments.",0.22950819672131148,0.19444444444444445,0.21052631578947367
2429,SP:de05c7b7b8830e38da4254af1e0ca2ddadb50134,"Some neural network runs involve layers with a large number of neurons. These require large matrix-vector or matrix-multiplication which can slow their training/inference. However, if the output of mat-vec/mul is dominated by a few neurons with which the activation has large inner product (a matmul can be thought of as a weighted sum of inner products), then the computation can be sped up by approximating mat-vec/mul by a limited weighted sum with the dominant terms. This requires maintaining an ANNS data structure that is up to data with the back prop. These updates to ANNS have to be done carefully -- too frequent and the training will slow down, or too infrequent and the results of the mat-mul are way off.  This paper studies how to do this in a principled way using data-dependent LSH updates and backs it up with experimental data.","The authors make a good insight into the slowly changing of Locality-Sensitive Hashing (LSH) hash codes for the weights (or model parameters) during the Neural Network (NN) training. With this new insight, they introduce a framework Mongoose with a newly designed schedule mechanism to reduce the LSH update overhead. The authors also analyse their model and show some bounds for batch speedup and LSH maintenance. Experimental results validate the efficiency and effectiveness of Mongoose over original LSH methods in NN training.",0.09271523178807947,0.17073170731707318,0.12017167381974249
2430,SP:de1248456feddd9a8f2617e49f913e6585a9951f,"This paper proposes an approach for time series forecasting that learns the graph structure among multiple (multivariate) time series simultaneously with the parameters of a Graph Neural Network (GNN). The problem is formulated as learning a probabilistic graphical model by optimizing the expectation over the graph distribution, which is parameterized by a neural network and encapsulated in a single differentiable objective. Empirical evidence suggests that the proposed GTS obtains superior forecasting performance to both deep and non-deep learning based, as well as graph and non-graph based, competitor forecasting models. In addition, GTS appears to be more computationally efficient compared to LDS, a recently proposed meta-learning graph-based approach.","The paper considers learning both graph structures and NNs for time series data, similar to the idea of LDS (Franceschi et al., 2019). Observing the computation and scalability issues with LDS, authors propose a unilevel optimization form wrt. the mean performance over the graph distribution. This is done via NNs, with input being the observed sequence, to output a real matrix whose elements are then treated as weights for the Gumbel trick. NN structures, training procedure, etc. mostly follow existing works.",0.15315315315315314,0.20987654320987653,0.17708333333333331
2431,SP:de2ca9e0d296137c5ddf68db89b5d0e6b1342031,"The authors propose a method for rapid adaptation from a single training task to an unseen test-task in reinforcement learning. The method optimizes to find a convex subspace, specifically a line, of parameters that minimize the objective in expectation over a uniform distribution. For adaptation, the authors propose to find a convex combination that performs well on the test task.","The paper studies how to discover a subset of policies that will become useful for fast adaptation of future tasks. The subspace is defined as the convex hull of some anchor policies which are discovered, and are encouraged to perform well with respect to the extrinsic reward while being as different as possible from each other in the parameter space. The quality of the set is then evaluated by its ability to quickly adapt to new tasks. ",0.18032786885245902,0.14285714285714285,0.15942028985507245
2432,SP:de4fc764e79cc8210a409c4bf7144ad7bb4baaf4,"The paper introduces RCPO, a model-free deep RL algorithm for learning optimal policies that satisfy some per-state constraint on expectation. The derivation of the algorithm is quite straightforward, starts from the definition of constrained optimization problem, and proceed by forming and optimizing the Lagrangian. Additionally, a value function for the constraint is learned. The algorithm is only compared to a baseline optimizing the Lagrangian directly using Monte-Carlo sampling.","This work tackles the difficult problem of solving Constrained Markov Decision Processes. It proposes the RCPO algorithm as a way to solving CMDP. The benefits of RCPO is that it can handle general constraints, it is reward agnostic and doesn't require prior knowledge. The key is that RCPO trains the actor and critic using an alternative penalty guiding signal.",0.15492957746478872,0.18333333333333332,0.1679389312977099
2433,SP:de54df40429714a5d975e1b0ef2c4b529ba5f6e3,"In the paper, the authors propose a general form that covers most stochastic gradient methods so far, e.g. stochastic gradient descent, Adam,  or adaptive probabilities methods. Then, they also provide a convergence analysis of convex problems.  In the experiments, they compared the proposed DASGRAD method with Adam, AMSGrad or SGD. Experimental results show that the proposed method converges faster than compared methods.  Following are my concerns:","In this paper, the doubly adaptive stochastic gradient method (DASGrad) is introduced via augmenting adaptive moment methods with adaptive (as opposed to uniform) probabilities for data sampling. The convergence of the proposed method is analyzed in terms of regret bound and is compared to similar results for ADAM. The method is validated with experiments on both convex and non-convex objectives as well as in applications to transfer learning.",0.23880597014925373,0.2318840579710145,0.23529411764705882
2434,SP:de7e056a3ebbbb4fce17331392af4840953ea064,"This paper formally summarizes common robustness notions in the literature as: standard robustness (SR), classification robustness (CR), Lipschitz robustness (LR), and strong classification robustness (SCR). The paper proves LR implies SR, SCR implies CR. Then some empirical studies are conducted.","The authors are proposing an approach to systematization of the types of robustness of neural network. In particular, they are discussing four types of robustness: through augmentation, through adversarial training, through Lipschitz constraint training and through logical constraints training. The authors discuss the interconnections between the four classes of robustness, hypothesize which one is more general than others, propose possible measures for how easily the robustness can be violated - randomly or intentionally. In the experimental evaluation the authors are checking the attacks vulnerability for the networks with different types of robustness, confirming discussions about them.",0.2,0.08421052631578947,0.11851851851851852
2435,SP:de83ec082fee45976ef980f33e068a32da3fdcd9,"This paper proposes Causal Anonymous Walks (CAWs) that are extracted by temporal random walks and work as automatic retrieval of temporal network motifs to represent network dynamics while avoiding the time-consuming selection and counting of those motifs. CAWs adopt an anonymization strategy that replaces node identities with the hitting counts of the nodes based on a set of sampled walks to keep the method inductive, and simultaneously establish the correlation between motifs. CAW-N to encode CAWs with a neural network model. CAW-N was evaluated to predict links over 6 real temporal showed better AUC gain compared to baselines. ","The authors provide in-depth analysis on the critical topic of capturing dynamic laws for the inductive representation learning of temporal graphs. The authors leverage the causal anonymous walk to capture the topological laws of the dynamic graph, while not requiring to memorize node identities such that inductive learning is still feasible. Compared with the previous work, the paper emphasizes on scenarios where node/edge attributes are less informative of the inductive reasoning. Some workaround methods are also proposed to deal with the edge features and to enable the efficient computation and sampling procedure. ",0.16831683168316833,0.18085106382978725,0.17435897435897438
2436,SP:de8f3058fe99455cc090f25a1dcd02b8cd0ea8e0,"The paper studies the problem of training deep neural networks in the distributes setting while ensuring privacy. Each data sample is held by one individual (e.g., on a cell phone), and a central algorithm trains a learning model on top of this data. In order to protect the privacy of the individuals, the paper proposes the use of multi-layer encoders (E) over the raw data, and then send them across the server. The privacy is ensured by exemplifying the inability to reconstruct the original data from the encoded features, via running a reverse deep model (X). The notion of privacy is quantified by the Euclidian distance between the reconstructed vector via the best X and the original feature vector, maximized over E. The overall framework resembles a GAN, and the paper calls it RAN (Reconstructive Adversarial Network).","Privacy concerns arise when data is shared with third parties, a common occurrence. This paper proposes a privacy-preserving classification framework that consists of an encoder that extracts features from data, a classifier that performs the actual classification, and a decoder that tries to reconstruct the original data. In a mobile computing setting, the encoder is deployed at the client side and the classification is performed on the server side which accesses only the output features of the encoder. The adversarial training process guarantees good accuracy of the classifier while there is no decoder being able to reconstruct the original input sample accurately. Experimental results are provided to confirm the usefulness of the algorithm.",0.17985611510791366,0.21929824561403508,0.19762845849802368
2437,SP:dea62d40d829155b4a45b0c13adcdbe1bb080cf6,"In this paper, the authors propose to better explicitly utilize the sequential information in the video to improve the performance of unsupervised scene decomposition in video. Concretely, 2D LSTM is used to combine the advantages of iterative inference and temporal information. By appropriately using the inferred results in the previous time step, the number of interactive inference steps is decreasing, which finally results in the O(R^2+T) complexity. ","The authors extend previous work of Greff et al. on unsupervised, multi-object scene decomposition to incorporate temporal information.  In particular, they apply the LSTM defined for each candidate object not only over inference steps, but also over time. This allows the model to capture temporal cues, such as object motion, to better decompose the scene into objects. In addition, this allows to speed up the inference, since they perform fewer inference steps at each consecutive frame, capitalizing on temporal consistency in videos (LSTM state can be largely refused between consecutive frames, since the appearance doesn't change a lot). Experimentally demonstrate that their approach indeed outperforms prior work on two toy datasets (bouncing balls and CLEVERER), while being more computationally efficient.",0.2571428571428571,0.14754098360655737,0.18749999999999997
2438,SP:deaee5e7a87bf430a6831dde8c2a2c84f62201ef,"This paper presents a new model for grammar induction for text, with help from the coupled images. The model was built on top of an existing unsupervised grammar induction model used for text without image information. The experimental results show the approach was effective. The work essentially demonstrates some effective ways of leveraging the additional image information for improving the grammar induction task. The paper also discussed some weaknesses of the approach and future work.","The paper proposed a new method CLIORA to do unsupervised parsing and vision-language grounding.  CLIORA is based on DIORA model.  But different from previous unsupervised parsing methods, CLIORA also induces alignment between constituents and image regions.  In order to train the model, the author introduces a contrastive loss. Experiment results show that the proposed method outperforms baseline unsupervised parsing methods and it also induces meaningful alignment between image regions and constituents.",0.17333333333333334,0.18055555555555555,0.1768707482993197
2439,SP:deb1448308aa429b8a2f2cf2d27f98f87e367c83,"This paper considers communication games when agents use experience replay. The agents' communication protocol may change over time, leaving outdated symbols in the replay buffer which are then trained on. This paper proposes replacing the old communication actions with up-to-date actions as the transitions are sampled, and shows that this leads to greatly improved convergence speed and higher performance plateaus.","The paper considers a multi-agent reinforcement learning (MARL) scenario where agents take actions based on the current observation alone. The paper proposes a communication correction mechanism where, during the centralized training, messages there were received in the past from other agents are reevaluated according to the updated policy. This way old messages can be updated instead of discarded, which is more efficient overall. ",0.1774193548387097,0.171875,0.1746031746031746
2440,SP:dec287e2fe3b34942440388a7e79031e833dc718,"This paper proposes to use an evolutionary search algorithm to search for better loss functions for the classification and regression branch of an object detector. The algorithm starts with 20 primitive mathematical operations. Due to the highly sparse action space, the vanilla evolutionary algorithm would take a long time to converge. Then the authors propose two ways to reduce the search space. First, they filter out loss functions which generates gradients of large magnitude to well-classified samples and do not converge to zero. Second, they construct a very small dataset by sampling only one image randomly from each category and evaluate the loss function on it to quickly filter out bad loss candidates.","This paper proposes to automatically discover proper loss functions for object detection. It first designs some unit mathematical operations as search space, and then performs evolutionary algorithm to discover well-performed loss functions for the object detection tasks. Different from image classification, one needs to search both classification and localization losses in object detection. To accelerate the search, the paper proposes convergence property verification and model optimization simulation to effectively evaluate the searched loss and reduce the search space.",0.20175438596491227,0.2911392405063291,0.23834196891191708
2441,SP:dec7cdf8b9b7c1b22d3a8c1a1acc15815232edfa,"This paper proposes that slightly robust neural networks contain universal features that are transferable across different classifiers trained on the same dataset. The authors demonstrate empirically that adversarial examples of slightly robust networks can transfer across network architectures relative to other levels of robustness. Moreover, the authors empirically show the universality of features in slightly robust neural networks.","This work studies how adversarial robustness of a source network can affect the transfer of adversarial examples to a different target network. The main finding is that slightly robust networks are ideal source networks; training the source networks with no adversarial perturbations, or with large perturbations, is less effective. The authors analyze why this might be the case, and propose that slightly robust networks have increased universality of representations.",0.25862068965517243,0.21739130434782608,0.23622047244094485
2442,SP:ded5591ef4dffd70134e3cc04d89083f17c85f0b,"In this paper, the authors claimed to address a new domain adaptation setting under double blind constraint, to meet the privacy requirement. Though the problem itself seems real and interesting, the solution in this work makes the problem quite trivial. In fact, any other domain adaptation method can be applied to address the problem, while the authors even did not compare with existing UDA methods which can be intuitively adapted.","This paper tackles the transfer learning problem with the double-blind unsupervised domain adaptation, where either the source or the target domain cannot observe the data in the other domain, but data from both domains are used for training. The high-level intuition of this paper is based on the observation that in some practical settings, the transferring source data to the target domain is restricted due to the privacy policy. The goal is to learn a classifier which performs well in target classification task under double-blind constraint. ",0.24285714285714285,0.19101123595505617,0.21383647798742136
2443,SP:dedb4bdd3e5253cda6aeff7dd18823967662c59c,This paper proposes that properly optimized MLPs can perform just as well if not better on tabular data. This is an important topic as it's well know that MLPs have not achieved similar performance as GBDT on data with categorical variables. The paper is well written and reasonably comprehensive in the experiments. ,"The paper supplies an empirical existence proof that an ""appropriately regularized"" multi-layer perceptron (MLP)-like model can outperform gradient-boosted decision trees (GBDT) on tabular data. The paper's proposed approach defines a set of parameterized techniques which includes ensembling, architectural changes, and data augmentation, and performs search over combinations from this set. The extensive experimental comparison across 40 tabular datasets shows that MLP-like models can outperform GBDTs and other neural network architectures.",0.18867924528301888,0.13333333333333333,0.15625
2444,SP:dee5207ad69f2330fc0990728f00711848dc0067,"This paper proposes Graph Joint Attention Networks (JAT), which augment Graph Attention Networks (GAT) by introducing structural attention coefficients, which are combined with the feature based attention coefficients computed by GAT. The authors present two ways of incorporating the structural coefficients, namely Implicit direction and Explicit direction. The authors evaluate their proposed technique in the Cora, Citeseer and Pubmed datasets, where they improve the performance of other GNN approaches.","Creating aggregation weight over neighbor nodes lies at the key part of graph neural networks. Generally the weights can be generated by the node structure or feature similarity. The node structure similarity provides a way to measure the correlation of a pair of nodes with a complete graph. While attention weight usually focuses on the local neighborhood, which can be easily biased by the node popularity [1, 2]. If a neighbor node with large degree, it potentially tends to have a large embedding norm. However, from complete view of graph structure, this neighbor might be a noisy node. With a given complete graph structure, we can downgrade the influence of structure bias. From this point of view, it's interesting to study whether the attention and structure weights can be complementary to each other. The key idea of this work is very easy to follow. The proposed strategy is to unify the weights generated by graph structure and node feature. Theoretical analysis shows the expressive power of  the proposed strategy. The experimental results for node classification also demonstrates its superiority comparing with state-of-the-art baselines.",0.2463768115942029,0.09090909090909091,0.1328125
2445,SP:df15480cfd6c0cdb9eff78de8c1b380bb5d1376f,"Context: Counterfactual explanations are a way to locally interpret model decisions for a given input by finding a ""nearby"" input with a different model decision. As in this paper, we can interpret some distance measure between the original input and its ""counterfactual explanation"" point as a kind of cost of achieving a different decision, usually for/to an individual who gets a negative decision to understand what they would need to change to receive a positive decision. In a fairness context we can consider differences in such costs between different groups as evidence of unfairness, for example if there are higher costs (on average, say) for individuals from a protected non-discrimination group.  The current paper shows that for a certain class of algorithms producing counterfactual explanations, it is possible for a small, adversarial perturbation of the input to produce a dramatically different explanation. The paper points out that this non-robustness of the algorithms in consideration is important from a fairness or regulatory standpoint by simulating a scenario where a model builder can jointly train a classifier and adversarial perturbation so that an auditor relying on counterfactual explanations (using any of the algorithms in consideration here) can be deceived. The paper shows how to train such models that can hide unfairness by providing a low-cost explanation for a nearby point relative to the higher cost explanation of the original input, and demonstrates the concept with experiments using two datasets and four different counterfactual explanation algorithms in the literature. Experiments also show how to achieve robustness by changing the initialization point for the counterfactual explanation algorithm, by reducing the dimension of the input space, or by otherwise constraining the complexity of the classification model.","This paper presents a new research problem regarding the vulnerabilities of counterfactual explanations, and introduces an adversarial model/framework to demonstrate the vulnerabilities of existing algorithms which employ hill-climbing to find counterfactual explanations (and initialize the search at the original data point). Some mitigation strategies for improving the robustness of this type of counterfactual explanation algorithms are also presented.  The work shows that the proposed adversarial model can pass the (recourse) fairness assessments which rely on counterfactual explanations produced by the counterfactual explanation methods using hill-climbing, but in fact is not a fair model as if the other features of an input instance from the non-protected group is perturbed slightly, the counterfactual explanation generated for the instance can be biased (i.e. having a much more desirable recourse). This result demonstrates the potential problem with the counterfactual explanation methods and the fairness assessment scheme based on counterfactual explanations.",0.12982456140350876,0.24503311258278146,0.16972477064220182
2446,SP:df29919afa3506422185fadbb95ed900cfb6b1ae,"The paper investigates on the regret bounds for the expert advice problem and the multi-armed bandit in a quite general intermediate regime so called adversarial regime with a self-bounding constraint provided by Zimmert and Seldin (2021) (henceforth ZS21). For the expert advice problem in this general regime, the authors provide two regret bounds and a matching lower bound for an instance of Decreasing Hedge algorithm and algorithms with the second-order bounds. For the multi-armed bandit problem they achieve a lower bound in the mentioned intermediate regime that matches with the state-of-the-art result by ZS21 up to a logarithmic factor.       ","The paper considered expert problem and multi-armed bandits in stochastic environment with adversarial corruption. In this setting, an adversary modifies stochastic feedback up to total corruption level $C$. The authors analyzed Hedge algorithm with decreasing learning rate and algorithms with second-order regret bounds, and showed that the regret has a $\sqrt{C}$ dependency to the corruption level. Matching lower bound in the expert problem and near-tight lower bound up to logarithmic factor in the multi-armed bandit problem, suggesting the analyzed algorithms achieve optimal robustness. ",0.29245283018867924,0.3522727272727273,0.31958762886597936
2447,SP:df423ffa99360482fdfa31ad2c7e2ecedfa8bf5a,"The authors proposed an interesting low-precision training method using a dynamic precision schedule. Their proposed Cyclic Precision Training (CPT) cyclically varies the precision during the training and the boundary of precision values is determined by a precision range test (PRT). As shown in their empirical results, CPT largely reduces time/energy costs during training while maintaining comparable accuracy. While CPT does show a promising empirical performance, the motivation and reason behind the proposed method require further explanations. ","The authors propose cyclic precision training (CPT), a method to train integer-quantized neural networks with high precision while saving bit operations. CPT alternates the numerical precision of the network during training between low (2-3 bits) and high (the final desired precision, e.g. 8 bits). A total of 32 cycles of low to high are used, and this is only applied to the weights and activations, the backward pass is always in high precision. CPT is able to achieve improved accuracy across a variety of models on CIFAR-10/100 as well as transformers on PTB and WikiText. On ImageNet, CPT achieves accuracy on part with regular quantized training but saves bit ops.",0.2564102564102564,0.17391304347826086,0.20725388601036268
2448,SP:df4916f0673c2e43eb0e2d5cda8f3d5c4863ffc2,"The paper introduces an approach to function-level clustering. Function-level clustering means that a conditional computation model is optimized (in this case, parallel copies of a neural network), and that the optimization step is grouped by the respective computation path. This is achieved by using a  ""self organizing map"" that can compose  to select minimal loss computation paths. In more detail, it: 1. computes the function through all of its existing computation paths 2. selects the lowest-loss path 2. optimizes that path and its neighbors only","This paper develops a 2D mapping method by extending the self-organizing map (SOM) to a multi-layer version. While the simple version of SOM can be regarded as a single-layer network, the proposed functional SOM (fSOM) adopts the multilayered encoder-decoder architecture. The training technique, called weight coherence update, is introduced to obtain consistent neighborhood structures. The proposed fSOM is applied to the 2D embedding problem using the MNIST dataset.",0.14772727272727273,0.18055555555555555,0.1625
2449,SP:df4c28b42c8505f42804ad298a1b51ebb060ea32,"This paper proposes a theoretical formulation for meta-learning that uses task similarity based on task gradients, which helps learning in the presence of outlier tasks. The inner loop parameter update is given by linear kernel regression, where the kernel function computes similarity between gradients of different tasks. While the paper includes experiments that outperform MAML and Meta-SGD on estimating randomized linear predictors, and randomized sinusoids with outlier data-points, these are not sufficient to establish the efficacy of the approach. ",The paper introduced a meta-learning framework in which a kernel describing similarity between the tasks is used to construct an RKHS which is used to perform kernel regression. The framework is instantiated in a form of an algorithm: TANML which can be viewed as an extension to a popular Meta-SGD algorithm. The experiments on two regression tasks are presented to analyse the efficacy of the proposed method.,0.25609756097560976,0.30434782608695654,0.27814569536423844
2450,SP:df86cedbf3a09f5d07380bcc99ee1674758a309b,"The paper analyzes joint scalings of the parameter initialization and the learning rate, with respect to the limit of infinite width, in the context of two-layer neural networks with stochastic gradient descent and binary logistic loss. It proposes some “dynamically stable” conditions and identifies a range of scalings that satisfy these conditions. This covers the neural tangent kernel (NTK) and mean field (MF) scalings, as well as others. The paper then proposes to add an extra correction function to the initialization of the MF limit and argues experimentally that this correction can give a proxy for standard neural networks.","This paper proposed a general framework to derive different stable limiting behaviors of the dynamics of two-layers neural networks, under different parameterization of the hyper-parameters. For certain choices of hyper-parameters, this recovers the mean-field limit and the NTK limit. This paper also proposed certain properties of the limiting dynamics and showed that using these properties as the classification criteria, there are only a finite number of distinct models in the limit. This paper also proposed a novel initialization-corrected mean-field limit that satisfies all properties.",0.21,0.23333333333333334,0.22105263157894736
2451,SP:df8bb4b9541a4d791778e89d47c8646b7f3d6d67,"This paper attempts to learn general and reusable features for transfer learning tasks. The authors propose a training paradigm called Racecar Training. The core idea of it is to operate a reverse pass for the network. The authors use mutual information to analyze the network for its improved generalizing capabilities. They also conduct experiments on classification, regression and stylization to validate their method’s effectiveness.","This paper proposes a scheme for training layered feedforward neural networks with backwards accumulation of gradients. In the proposed scheme, the intermediate activations during a forward pass are constrained, using an L2 norm penalty, to be close to the activations of a model that inverts the operations of each layer and transforms the data in reverese order (from output to input). The second, inverse, network shares all parameters with the feedforward network.",0.2,0.18055555555555555,0.18978102189781024
2452,SP:df975cc1c367d216509f31196a7eff5ad95e570a,This paper attempts to understand how a RNN goes about solving the Variable Copy Delay Memory task in fine detail. Their model has been trained perfectly on this task and so they are able to focus on how it goes about changing its cell values in the case. The authors present different metrics to track resetting and memorization behavior by the GRU's neurons.,"The paper analyzes GRU's underlying mechanisms that store and retrieve information in the delay copy task of a sequence of K symbols. It proposes a perturbation-based method to determine which neurons are responsible for encoding a step-element pair. The paper then shows that at each step of the decoding phase, certain neurons are reset by GRU, generally mapping to those tuned to hold information of step-element pair.  Finally, the paper provides a synthetic solution to the delay copy task for the case K=2.",0.140625,0.10227272727272728,0.11842105263157894
2453,SP:dfc80fb0b42de4903663641d305a8aa64abdd6e8,"The given paper describes a novel approach of learning binary trees using a differentiable relaxation of MIP. For that matter, authors describe their approach of tree traversal for the given input x and a complete binary tree of depth D. This problem is formulated as MIP which is relaxed to make it differentiable. This MIP is then reformulated to learn a tree structure (i.e. tree pruning). Finally, a decision node parameters are optimized using backpropagation. The algorithm alternates between tree structure learning using relaxed MIP and tree parameters learning using SGD. ","This paper presents a new approach to learn decision trees via sparse relaxation. The approach starts from a mixed-integer program that can simultaneously induce and prune optimal decision trees from data. The proposed technique aims to solve a continuous relaxation of this problem by combining (1) a tree induction routine, which uses isotonic optimization with (2) an efficient implementation that avoids the need for automatic differentiation. The paper includes experiments on publically available datasets, showing how the decision trees produced via sparse relaxation to decision trees produced using other tree induction approaches.",0.17391304347826086,0.17204301075268819,0.17297297297297298
2454,SP:e00ee9485f054034892f307e0ab2f8df1e2d8701,"The submission extends the MARL◦MAIR to the extensive Markov game case, where the decisions are made asynchronously. As a result, a stronger equilibrium SPE is becomes the target of the proposed method. To  this end, the submission takes advantage of the previous game theory results, to formulate the problem, and transform the model to a MAGAIL form. The empirical performance of the proposed method is demonstrated using experiments.","In this work, a multi-agent imitation learning algorithm for extensive Markov Games is proposed. Compared to Markov Games (MGs), extensive Markov Games (eMGs) introduces indicator variables, which means whether agents will participate in the game at the specific time step or not, and player function, which is a probability distribution of indicator variables given histories and assumed to be governed by the environment, not by the agents. Such a model allows us to consider asynchronous participation of agents, whereas MGs only consider synchronous participation, which is assumed in the existing multi-agent imitation learning algorithms such as MA-GAIL and MA-AIRL.",0.2028985507246377,0.13592233009708737,0.16279069767441862
2455,SP:e01809728bbe427d7b505f3f36d51b55a8e49d49,"This paper studies semi-supervised node classification in graph data. One powerful approach to the task is graph convolutional networks, which use discrete layers to perform information propagation. The paper generalizes GCNs into a continuous model via heat kernel, where the proposed model uses continuous layers for information propagation. The authors conduct both theoretical and empirical analysis of the proposed model. Experiments on several standard datasets show promising results. Overall, the paper studies an important problem in graph machine learning, and proposes a principled approach, which combines graph neural networks with heat kernels, and gives a new way of analyzing existing graph neural networks.","This submission introduced a new graph convolutional operator based on heat diffusion, named heat kernel GCN (HKGCN). First, continuous-time heat diffusion on graphs is reviewed, where the solution is given by the heat equation (6). Then, the authors showed that classical GCN can be approximated in the same formulation through discretization.",0.09615384615384616,0.19230769230769232,0.1282051282051282
2456,SP:e01cbc55e8f7bc90ed66b50387234c154f547e5e,"This paper extends the neural barrier certificate method from reinforcement learning to  the decentralized multi-agent reinforcement learning setting. In particular,  it borrows the idea of the control barrier function, which enforces the states of the dynamic system to stay in the safe set. It is known that in the single agent system if the control barrier function h satisfies the equation (1), the agent will never enter the dangerous set under policy pi. A straightforward way to extend the control barrier function in the MARL setting is to replace the state-action pair by  the joint state-action pair  in equation (1). However it may suffer from the exponentially large state and action space. Therefore, the author proposes a decentralized setting, where each agent just maintains its own control barrier function. To learn the policy and function h simultaneously, the author penalizes the violation of equation (2). At last, they test the proposed method in Navigation, Predator-Prey, ground robots and Drones compare it with several baselines.",This paper brings the recently introduced idea of control barrier functions (CBF) as safety certificate to the multi-agent land. To this end it introduces the idea of decentralized CBFs. This is followed with a framework for jointy learning the CBFs and policies with a PointNet inspired network architecture. The paper provides some generalization guarantees for the approach as well. Finally the approach is compared against various learning and planning based baselines where it significantly outperforms.,0.13690476190476192,0.3026315789473684,0.18852459016393444
2457,SP:e020226557ee78b133893665ef4f30c9cb81ff9f,"This manuscript studies mutual-information estimation, in particular variational lower bounds, and focuses on reducing their sample complexity. The first contribution is based on adapting the MINE energy-based MI estimator family to out-of-sample testing. MINE involves fitting a very flexible parametric form of the distribution, such as a neural network, to the data to derive a mutual information lower bound. The present work separates the data fitting from the mutual information evaluation to decrease sample complexity, the argument being that the function class is no longer a limiting factor to sample complexity of the mutual information estimation. The second contribution uses meta learning to decrease the sample complexity required to fit the neural network, creating a family of tasks derived from the data with data transformation that do not modify the mutual information. The approaches are demonstrated on synthetic data as well as fMRI data, to detect significant inter-subject dependencies in time-series of neural responses.","The paper proposes a neural-network-based estimation of mutual information, following the earlier line of work in [A]. The main focus has been to develop an estimator that can reliably work with small dataset sizes. They first reduce the sample complexity of estimating mutual information by decoupling the network learning problem and the estimation problem by creating a training and validation set and then using the validation set for estimating mutual information. Of course, there is still the problem of learning the network with smaller sized data. For this, they propose the strategy of creating multiple tasks from the same dataset, where the dataset is run through transformations that do not affect mutual information.",0.19375,0.26956521739130435,0.22545454545454546
2458,SP:e02b51aa077852aeddc65bb2217968aca35e9105,"This work (EVFM) aims to to improve predictions of n-body system dynamics by combining continuous lie symmetries with permutation symmetry. The authors propose to do this by encoding SO(3) invariant representations of each node, followed by the use of a graph transformer and a vectorization block to estimate the vector field. An evolving block is subsequently used to predict dynamics. ","The authors introduce a model to predict the time evolution of Newton mechanical systems and small molecules.  The model takes a graphical representation as input and converts it to an SE(3) and permutation equivariant representation using physical principles (i.e., white-box model). This representation is passed through a learned graph transformer module to produce a vector field which is used to predict the time evolution of the system/molecule. ",0.24193548387096775,0.2112676056338028,0.22556390977443608
2459,SP:e041de5583ca63b05986f5485730467021cd8ee1,"The paper shows how to infer the organisational structure of an institution. That is, it presents a model for predicting the is-ancestor relationships of institutions based on their string names. To this end, it makes use of Set-Transformers to model the token overlap between the institution names. This use is nice but also not highly original. The experimental evaluation is on a single dataset only. While the authors do present some examples, and overall hierarchy or something that provides some more insights into the learned model should be provided in order to show potential issues with transitivity and connected components. The evaluation only considers known pairs. But an organisational structure should also be consistent.  That is, the interesting motivation provided in the intro is not met in the experimental evaluation. Furthermore, the experimental protocol is  unclear. It seems to be a single training/test split, although one should consider several random splits or even some form of cross-validation, i.e., over the connected components given.",Paper is on modeling the prediction of ancestor relation between names of science institutions.  This is on the GRID dataset which already has some hierarchical information.  The proposed approach is set-based models (with neural encodings) where the overlap between two names is measured by set overlap at the unigram level.  In extended experiments additional metadata like address and type of institution are also incorporated into the model (which contribute a lot to the improvements).  A set of simple to intermediate baseline along with different thresholds of token overlap has been tested and the proposed model shows strong improvement in the MAP metric.,0.14285714285714285,0.23300970873786409,0.17712177121771217
2460,SP:e0600fd9c60fc02e37e332e608673682687f0190,"This paper tackles the problem of facilitating RL agents' learning in sparse reward, hard-exploration problems. The authors approached this challenge by generating a curriculum of tasks needed to finish the originally assigned task. Though using other auxiliary tasks to assist RL training has been heatedly discussed, their method has its own highlights and novelty. Pros and Cons are listed as follows:",This paper presents a procedurally content generation approach (APT-Gen) that generates a sequence of tasks for an agent to solve. These tasks are automatically generated in a way that helps an RL agent to learn hard-exploration problems. A main innovation of the approach is a task generator system that is both rewarded for generating tasks the agents can solve but also a sequence of tasks that are getting increasingly more similar to the target task.,0.24193548387096775,0.19480519480519481,0.21582733812949642
2461,SP:e0748a938f66f678cbe7827a9f336bdf4c1ec891,"Authors show how the nervous system of C. elegans can be modelled and simulated with data-driven models using different neural network architectures. Specifically, they target the use of state of the art recurrent neural networks architectures such as LSTMs and GRUs and compare these architectures in terms of their properties and their RMSE, as well as the complexity of the resulting models. Authors show that GRU models with a hidden layer size of 4 units are able to accurately reproduce the system’s response to very different stimuli.","This paper investigates the use of recurrent neural networks as a model reduction tool in computational neuroscience. More specifically, the authors consider the problem of predicting the activity of a set of four neurons in the C Elegans nematode worm, resulting from the (simulated) electrical stimulation of other neurons in the animal's connectome. Three experiments are carried out, testing different network architectures, network sizes, and the effect of increasing the temporal resolution of the data. The results show that a small GRU-based network is sufficient for achieving excellent agreement with the starting data, which was generated using computationally demanding simulations of a network of multi-compartimental neurons. The paper also includes an introduction on popular RNN architectures, and on the problem of model reduction in computational neuroscience. ",0.24719101123595505,0.17054263565891473,0.20183486238532108
2462,SP:e0a53b0c2398f49df1c8c053acb1dc4bc64a0729,"The authors tackle the problem of zero-shot learning, that is, the recognition of classes and categories for which no visual data are available, but only semantic embedding, providing a description of the classes in terms of auxiliary textual descriptions. To this aim, authors propose a method dubbed  Image-Guided Semantic Classification in which a two-stream network (fed by either visual and semantic embedding) learns a compatibility function whose recognition performance is enhanced by means of calibrated stacking (Chao et al. 2016).  ","This paper proposes a simple yet effective method for zero-shot learning. In the method, a network is learned to predict the compatibility function weight given the input of the image. The predicted weight is then applied to semantic attributes and the final class label is predicted by the maximum compatibility score. The method is evaluated on benchmark datasets and illustrates competitive performance.",0.14457831325301204,0.19047619047619047,0.1643835616438356
2463,SP:e0bef945605bdba26787c47c6c8ecaa896610b54,This paper introduces a regularization approach for stable continual learning of sequential tasks. The proposed method computes neuron importance based on the activation values of nodes with their respective standard deviation. It further suggests a weight re-initialization scheme to achieve better performance. Experimental results on several continual learning scenarios show that the presented approach is comparable to other existing competitors.,"This paper proposes a method that tackles the problem of catastrophic forgetting in continual neural networks by assigning importance to neuron activations while tasks are executed in sequence. Similar to previous research (Jung et al., 2020), the proposed method measures neuron importance using average activation values divided by corresponding standard deviation. This strategy is accompanied by weight re-initialization to guarantee that new tasks are fully learned. The method is tested in benchmark datasets for continual learning. ",0.3442622950819672,0.2727272727272727,0.30434782608695654
2464,SP:e0c0e58daacc7d78b1441c87dc5388f6b53adfa9,"The authors propose a momentum based approach for batch normalization and provide an asymptotic convergence analysis of the objective in terms of the first order criterion. To my understanding, the main effort in the analysis is to show that the sequences of interest are Cauchy. Some numerical results are reported to demonstrate that the proposed variant of BN slightly outperforms BN with careful adjustment of some hyper parameter. The proposed approach is incremental, and the theoretical results are somewhat weak.","In this work, the authors propose a generalization of the batch normalization (BN) technique often used in training neural networks, and analyzed this convergence. In particular, a one hidden layer and one BN hidden layer fully connected network is considered, and a deterministic gradient descent algorithm with certain kind of BN has been considered in this work. The proposed “generalized” BN strategy is devised on the deterministic setting, but it is a slight generalization of the original BN by introducing a moving average operation. Classical results of Bertsekas is leveraged to show the asymptotic convergence of the algorithm. ",0.25,0.20408163265306123,0.2247191011235955
2465,SP:e0cd21da9c8cdb3bc34ae8ab2e7d2974a3d3e921,"This paper considers the problem of releasing sensible structured data, where there are two inlined challenges: 1. The global network structure should be effectively preserved; 2. The link privacy should be rigorously protected. This paper looks at the secure release of network data with deep generative models. Specifically, the paper develops two models, DPGVAE and DPGGan, which can be viewed as a combination of DP-SGD and graph generation techniques. Extensive experiments are carried out on real-world network datasets, and the positive results have shown the effectiveness of the new models.",This work consider the problem of link privacy when releasing models that are trained on graph data. It achieves this by making a generative graph model based on a VAE differentially private. Differential privacy is obtained by adding noise to gradients during training (DPSGD approach). The paper uses graph metrics and a classification downstream task to evaluate the utility of generated graphs. Comparison of algorithms with related work and details of the mechanism could be expanded to articulate novelty and significance of the work.,0.18478260869565216,0.20238095238095238,0.19318181818181818
2466,SP:e0dd4a62106a2c2fc6a248c601ddb8422e148864,This paper proposes to learn a kernel for training MMD-GAN by optimizing over the probability distribution that defines the kernel by means of random features. This is unlike the usual setting of MMD-GAN where the kernel is parametrized by composing a fixed top-kernel with a discriminator network that is optimized during training. The main motivation for this approach is to avoid having to 'manually' fix some parameters of the top-level kernel like the bandwidth of the RBF kernel. They provide an algorithm to achieve such optimization in probability space along with some consistency results and perform experiments on MNIST and Cifar10 to demonstrate empirically the advantage of such an approach over those that fix the top-level kernel.,"This paper aims to improve the kernel selection issue of the MMD-based generative models. The author formulates the kernels via inverse Fourier transform and the goal is to learn the optimal N finite random Fourier features (RFF). The RFF samples are optimized by the proposed kernel alignment loss where the positive and negative labels are defined as samples coming from real and negative data distributions, respectively. Some theoretical analysis regarding the consistency of the learned kernel is provided. Experiment results on the IS score and FID on CIFAR-10 show improvement of the proposed methods over MMD-GAN baselines, while the results are not comparable to the original MMD-GAN due to unknown results.",0.19672131147540983,0.20869565217391303,0.20253164556962025
2467,SP:e0e0ce3b4f295b709ad615ca7ff4f345e333e823,"This paper considers robustness of MAB algorithm to model misspecification when knowledge on the distribution (e.g., tails) is not directly accessible. They study a generic Dirichlet Sampling algorithm and provide a generic theorem for regret decomposition. They applied the algorithm in three examples: 1) bounded distributions where optimal regret can be achieved, 2) light-tailed unbounded distributions where we can achieve slightly-worse-than-log regret through simple tuning strategies, and 3) unbounded distributions with some quantile condition where log regret is achievable.","The goal of this paper is to construct a sequential decision-making algorithm under non-standard distributional assumptions. The authors propose a Dirichlet Sampling algorithm, employing pairwise comparisons of indices computed with the arms’ observations and a data-dependent exploration bonus.  They suggest three specific variants of this strategy under different distributional assumptions having distinct tail behaviors.  When it is applied to the bounded distributions, the algorithm is shown to be optimal. Numerical studies display some advantages of the proposed algorithms.",0.20238095238095238,0.20987654320987653,0.20606060606060606
2468,SP:e0e860e28dac58b373db0b14d5c84f7258d2713a,"This work introduces a novel scene representation for agent navigation in 2D and 3D environments. At the core of the method is an implicit neural representation of environment - implicit environment field (IEF) - which is a neural net that maps location coordinates to its reaching distance. Several conditional variants of IEFs are proposed to allow for generalization to novel environments and goal locations. Navigation can the be achieved by gradient descent on the reaching function or a discretized greedy algorithm.  Experimental evaluation is conducted on 2D maze navigation and 3D human motion prediction, and indicate that the proposed representation performs favorably to the baselines. ","The paper proposes modeling reaching distance between any start position and any goal (subject to obstacle avoidance) with a neural network. This is equivalent to parameterizing a traditional path-planning (goal-reaching) continuous value function with the network, which the authors also mention in the introduction section. Different variants of the network are considered, with conditioning on goal (aiming to generalize to different goals) and conditioning on a 2D scene layout (aiming to generalize across different scenes). The network is trained in a supervised manner on data obtained from a traditional search method (fast marching method [1]) that assumes discrete states. The usefulness of the trained value network for navigation and its generalization properties are then experimentally validated in 2D and 3D environments, including an interesting navigation example with two dynamically moving agents in the same scene.",0.18446601941747573,0.1386861313868613,0.15833333333333335
2469,SP:e0f8626408b0f7931b4778c5696f8df856a49f3a,"The paper proposes a theoretically founded method to generate subsets of a dataset, together with corresponding sample weights in a way that the average gradient of the subset is at most epsilon far from the average gradient of the full dataset. Given such a subset, the authors provide theoretical guarantees for convergence to an epsilon neighborhood of the optimum for strongly convex functions. The proposed algorithm to create such a subset is a greedy algorithm that relies on parameter independent similarities between samples, namely similarity scores that are true regardless of the current value of the function parameters.","This paper proposes a novel extension to SGD/incremental gradient methods called CRAIG. The algorithm selects a subset of datapoints to approximate the training loss at the beginning of each epoch in order to reduce the total amount of time necessary to solve the empirical risk minimization problem. In particular, the algorithm formulates a submodular optimization problem based on the intuition that the gradient of the problem on the selected subset approximates the gradient of the true training loss up to some tolerance. Each datapoint in the subset is a medoid and assigned a weight corresponding to the number of datapoints in the full set that are assigned to that particular datapoint. A greedy algorithm is employed to approximately solve the subproblem. Theory is proven based on based on an incremental subgradient method with errors. Experiments demonstrate significant savings in time for training both logistic regression and small neural networks.",0.2653061224489796,0.17333333333333334,0.20967741935483872
2470,SP:e108dc35910955986e9f58d77965d34863c5374b,"This paper theoretically explores reinforcement/imitation learning via representation learning. The key theoretical question being investigated is the relationship between representation learning in a multi-task/meta learning setup and its dependence to the sample/task complexity. The paper sets up the problem in bilevel optimization framework, where the inner optimization learns/optimizes task specific losses, while the outer optimization learns the representation used in the inner level tasks. The main takeaway from the two theorems (which are the core contributions of this paper) are that when the number of tasks is higher than the number of samples, representation learning can reduce the sample complexity. The paper explores two scenarios in imitation learning, namely behavioral cloning and when only the states of the experts are available (and not their actions). Some experiments are provided to empirically validate the theory.","The paper tackles the representation learning problem where the aim is to learn a generic representation that is useful for a variety of downstream tasks. A two-level optimization framework is proposed: an inner optimization over the specific problem-at-hand, and an outer optimization over other similar problems. The problem is studied in two settings of the imitation learning framework with the additional aim of providing mathematical guarantees in terms of sample efficiency on new tasks. An extensive theoretical analysis is performed, and some preliminary empirical results are presented. ",0.18705035971223022,0.28888888888888886,0.22707423580786026
2471,SP:e11a3ee0dce61bc8647a345d8947b9d36e2323f8,"This paper studies the privacy guarantee of Bayesian learning using Stochastic Gradient Langevin Dynamics (SGLD). Since the SGLD updates are stochastic, it is often thought the solution can be suitable for privacy-preserving of the data that is used to train the algorithm. Using a counter-example, this paper shows that it is not necessarily correct to assume so.","This paper shows that even when the posterior is as private as targeted in the beginning, sampling from posterior with SGLS might not be as private as targeted. The authors prove the theorem on Bayesian linear regression problem. They prove that for n big enough sampling from the posterior is (\epsilon, \delta) differentially private (DP), but there is a step in which releasing a sample will not be (\epsilon^\prime, \delta)-DP for \epsilon^\prime=\omega(n \epsilon).",0.1864406779661017,0.14102564102564102,0.16058394160583941
2472,SP:e1317ed002e3e0f08ba90506cb2c38d65265a102,"This paper aims to improve the efficiency of the actor-critic method. The authors first analyzed the cause of instability in the prior work, from the perspective of bias and variance. Two remedies were then presented: (i) mixing the experience replay with online learning; (ii) proposing a trust region scheme to select the behavior policies. The authors finally tested the proposed method on Atari games, and showed the better results, compared with the state-of-the-art methods.","This paper investigates off-policy actor critic (AC) learning with experience replay using V-trace. It shows that V-trace policy gradient is not guaranteed to converge to a local optimal solution. To mitigate the bias and variance problem of V-trace and importance sampling, a trust region approach is proposed to adaptively selects only suitable behavior distributions when estimating the state-value of a policy. To this end, a behavior relevance function (KL divergence) is introduced to classify behavior as relevant. The proposed learning method LASER demonstrates the state-of-the-art data efficiency in Atari among agents trained up until 200M frames. In all, this paper is well motivated and technically sound. The draft can be improved by making it more self-contained by providing a sketch of the proof rather than refer everything to the appendix. Also it might be helpful to provide a pseudocode of LASER to help readers better understand the technical details. ",0.2948717948717949,0.14556962025316456,0.19491525423728814
2473,SP:e13275073d8298a924331305623d86a4b41c670e,"This paper is trying to answer the question why ensembles of deep neural networks trained with random initialization work so well in practice in improving accuracy. Their proposed hypothesis is that networks trained from different initializations, although all converge to a low-loss/high accuracy optimum, explore different modes in function space and therefore provide more diversity. To experimentally support their hypothesis, first they show that functions along a single training trajectory are similar, however trajectories starting from different initializations may significantly differ. The difference in function space is based on the fraction of points on which the two functions disagree in terms of their prediction. Second, they use different subspace sampling methods around a single optimum and demonstrate that they are significantly less diverse (low disagreement between predictions) than sampling from independent optima through diversity vs accuracy plots. Moreover, they comment on the recent observation that local optima are connected by low-loss tunnels. They experimentally show that even though low-loss/high accuracy path exists between local optima, these tunnels do not correspond to similar solutions in function space, further supporting the multi-mode hypothesis. The authors compare the relative benefit of subspace sampling, weight averaging and ensembling on accuracy and interpret their findings in terms of the hypothesis. ","This paper analyzes ensembling methods in deep learning from the perspective of the loss landscapes. The authors empirically show that popular methods for learning Bayesian neural networks produce samples with limited diversity in the function space compared to modes of the loss found using different random initializations. The paper also considers the low-loss paths connecting independent local optima in the weight-space. The analysis shows that while the values of the loss and accuracy are nearly constant along the paths, the models corresponding to different points on a path define different functions with diverse predictions. The paper also demonstrates the complementary benefits of using subspace sampling/weight averaging in combination with deep ensembles and shows that relative benefits of deep ensembles are higher. ",0.15165876777251186,0.25806451612903225,0.191044776119403
2474,SP:e15ece78207bbf0918e70dbe4fe9527b543e371f,"The authors propose an iterative method for discarding outlying training data: first, learn a model on the entire training dataset; second, identify the training examples that have high loss under the learned model; and then alternate between re-learning the model on the training examples that do not have high loss, and re-identifying the training examples with high loss under the new model. This method works for both supervised and unsupervised learning, and the authors show that in theory, their method has some convergence properties in the mixed linear regression and Gaussian mixture model settings. The authors also run some experiments on neural networks and datasets with synthetic noise to show the benefits of their proposed method.",This paper introduces a framework for situation when the training samples are not pure. The idea is a simple approach by training a model and removing a portion of examples from the training set based on the loss of the model. The authors provide some theoretical study on two models: linear regression and Gaussian mixture model and utilize deep neural network to show their framework performs well experimentally. ,0.22033898305084745,0.38235294117647056,0.27956989247311825
2475,SP:e16c21331906c3dad479600864c3491d89ab67a5,This paper proposes a personalized neural architecture search algorithm (FEDPNAS) for FL. FEDPNAS searches for an architecture with a base component (shared across clients) and a personalized component. It also uses a context-aware operator sampler to learn a sampling distribution for feature maps. It provides a theoretical analysis of the FL objective and empirically demonstrates that FEDPNAS outperforms FedAvg and FedDSNAS over image recognition tasks on CIFAR-10 and MNIST datasets.,The paper proposes a personalized neural architecture search technique for federated learning. The paper incorporates both task-personalization and context-personalization. Experimental results on both CIFAR-10 and MNIST datasets demonstrate the promise of the proposed method.,0.2222222222222222,0.43243243243243246,0.29357798165137616
2476,SP:e16dc7a0c8ab7f163f6b8f06926aeec03161280d,"This paper describes a sensor placement strategy based on information gain on an unknown quantity of interest, which already exists in the active learning literature. As is well-known in the literature, this is equivalent to minimizing the expected remaining entropy. What the authors have done differently is to consider the use of neural nets (as opposed to the widely-used Gaussian process) as the learning models in this sensor placement problem, specifically to (a) approximate the expectation using a set of samples generated from a generator neural net and to (b) estimate the probability term in the entropy by a deterministic/inspector neural net. The authors have performed some simple synthetic experiments to elucidate the behavior and performance of their proposed strategy. ","This paper addresses the issue of how to optimize sensor placement. The authors propose a framework for sensor placement called Two-step Uncertainty Network (TUN) based on the idea of information gain maximization. More concretely, the proposed method encodes an arbitrary number of measurements, models the conditional distribution of high dimensional data, and estimates the task-specific information gain at unobserved locations. Experimental results on the synthetic data clearly show that TUN outperforms current state-of-the-art methods, such as random sampling strategy and Gaussian Process-based strategy.",0.17073170731707318,0.23595505617977527,0.19811320754716982
2477,SP:e170d43e3733bc0cd7e38f380b63281056dce095,"The paper proposes neural thompson sampling (TS) - a method to run TS without assuming that the reward is a linear function of the context, as is generally assumed in literature. This is not the first paper to use neural networks for TS, however existing papers either a) used TS only in the last layer, or b) maintained uncertainty over the weights and sampled the entire neural network. This paper instead maintains a single network that computes the mean of the reward distribution of an arm. ","The paper proposes a novel Thompson sampling algorithm for neural networks which can be applied to any arbitrary, bounded reward function. While existing works apply Thompson sampling (TS) to neural networks in a heuristic way (e.g., sampling parameters in the last layer only), this algorithm considers the posterior distribution of all the parameters and is the first to provide a theoretical, tight regret upper bound. The work builds on the neural tangent kernel theory, which enables the use of techniques developed for linear reward functions (Agrawal and Goyal, 2013). Actually, the paper is analogous to the work of Zhou et al. (2020) which proposed the NeuralUCB algorithm by combining the neural tangent kernel theory and the Linear UCB methodology (Abbasi-Yadkori et al., 2011).",0.2823529411764706,0.192,0.2285714285714286
2478,SP:e1726e0e4f65ec99676002eca4ad9cdf27f60b56,"This paper presents a clear approach to improve the exploration strategy in reinforcement learning, which is named clustered reinforcement learning. The approach tries to push the agent to explore more states with high novelty and quality.  It is done by adding a bonus reward shown in Eq. (3) to the reward function. The author first cluster states into clusters using the k-means algorithm. The bonus reward will return a high value for a state if the corresponding cluster has a high average reward. When the total reward in a cluster is smaller than a certain threshold, the bonus reward will consider the number of states explored. In the experiments, the authors test different models on two MuJoCo tasks and five Atari games. TRPO, TRPO-Hash, VIME are selected as baselines to compare with. Results show that the proposed bonus reward reaches faster convergence and the highest return in both MuJoCo tasks. In those five Atari games, the proposed method achieves the highest or second-highest average returns.","This paper proposed a clustering based algorithm to improve the exploration performance in reinforcement learning. Similar to the count based approaches, the novelty of a new state was computed based on the statistics of the corresponding clusters. This exploration bonus was then combined with the TRPO algorithm to obtain the policy. The experimental results showed some improvement, compare with its competitors.",0.13690476190476192,0.3770491803278688,0.20087336244541487
2479,SP:e17d769dcdc8ebb5c5e2a7bcda45fb250cda4e49,"The paper presents a neural network model (SYNONYMNET) for automatically discovering synonymous entities from a large free-text corpus with minimal human annotation. The solution is fairly natural in the form of a siamese network, a class of neural network architectures that contain two or more identical subnetworks, which are an obvious approach for such a task, even though this task's SotA does not cover such architectures. even though the abstract consists the word novel, the chosen architecture is not a novel one but attached to this task, it can be considered as if.","This paper studies the problem of identifying (discovering) synonymous entities. The paper proposes using the ""contexts"" of the entities as they occur in associated text corpora (e.g. Wiki) in the proposed neural-network based embedding approach for this task. The key novelties of the approach lie in the ""matching"" system used, where contexts of one entity are matched with that for the other entity to see how well they align with each other (which effectively determines the similarity of the two entities). Experiments are conducted on three different datasets to show the efficacy of the proposed approach.",0.18947368421052632,0.1836734693877551,0.18652849740932642
2480,SP:e1844adc4921e5ff485d07de51ca078b21321390,"This work addresses the problem of causal inference in time-dependent treatment regimes. To address the problem, the authors propose an extension of the balancing representation for causal inference framework that seeks render the current treatment independent from a representation of the history of treatment and confounders. This is sensibly actualized within an RNN. The authors provide empirical results that demonstrate the proposed method performing very well in comparison to prior art. ","The paper introduces Counterfactual Recurrent Network (CRN) that is able to estimate the effects of various treatments from longitudinal data. The claim is that the model can decide (i) treatment plan; (ii) optimal time of treatment; and (iii) when to stop treatment. The proposed method attempts to learn time-invariant representations that are not predictive of the next treatment by borrowing ideas from Ganin, et al. (2016)’s work on for domain adversarial training. In fact, this paper is an extension of (Atan et al., 2018) to be applicable for longitudinal data. ",0.2222222222222222,0.17391304347826086,0.1951219512195122
2481,SP:e1b66646c8acdfa00bdfc0ec8740458d7e8b2d83,"This paper proposes a novel approach named OverLORD to learn disentangled representations for image class and attributes. To tackle the problem of previous methods that the learned content and class are often entangled, the authors propose to disentangle image representations to class and attributes, and further disentangle attributes to common attributes among all classes (content), and class-specific attributes (style). It uses the idea from LORD to disentangle the image representations, and extends LORD to not only common attributes (content), but also class-specific attributes (style). In this way, it is able to transfer the common attributes while preserving the class and class-specific attributes. Experiments are conducted on animal faces and human faces datasets, and the proposed approach is able to preserve the class-specific attributes (e.g., shape or identity of the face) better than previous image-to-image translation methods that only disentangle style and content.","The paper presents a principled approach to style transfer by disentangling class-specific attributes from common (eq. class-independent) attributes. In order to do so, the paper leverages the formulation of a recently proposed disentangling approach called ""LORD"". The proposed approach is called OverLORD, and includes two main augmentations to LORD. The first is the introduction of a style encoder to learn a latent code for class-specific attributes, and the second is to introduce an adversarial learning in the second stage for high-quality style-transferred generation of images. The results are shown on three datasets: AFHQ (dog, cat, wildlife), CelebA (human faces), and CelebA-HQ (hi-res human faces), and are compelling in both qualitative and quantitative comparisons. ",0.20134228187919462,0.25,0.22304832713754646
2482,SP:e1b814eef558840aef2fba9092482c1b09b1ef30,"This paper works on the problem of collaborative learning while preserving both confidentiality and privacy of the data points. It combines techniques from secure multi-party computation and differential privacy for the same, and improves on confidential inference and PATE in the process. The new technique is called CaPC. Finally, it states empirical results as evidence for the improved accuracy.","The authors combine several cryptographic techniques to create a federated systems that allows several entities to run classification against all the model held be the participants without revealing information in the process. In particular, the sample to be classified is not revealed to any other party, and differential privacy is used to protect the training data that was used to train the models. A central semi-honest coordinator is used to aggregate the results and add the differential privacy without learning any private information.",0.18333333333333332,0.13095238095238096,0.15277777777777776
2483,SP:e1ced25c8b1fc9745e6f43c1be529e418d9325f9,"This paper dives into why small pruned networks don’t train as well as large networks. They come up with a measure of weight utilization and claim that networks of all sizes only use a portion of their weights during training, and the imbalance increases during optimization. Additionally, they visualize the accuracy surface on the plane defined by the pretrained, pruned, and retrained networks and find that the retrained networks end up in the same basin as the pretrained networks.","The paper proposes to answer the question why ""a network with the same number of weights as that of the pruned network cannot achieve similar performance when trained from scratch"". Then it proposes an hypothesis that the small model ""does not utilize all of its weights either"". To prove this hypothesis, it goes on to define and study the ""utility imbalance"" of the weights and its changing with the pretraining, pruning, etc. Some visualization analysis was provided too.",0.1875,0.19230769230769232,0.18987341772151903
2484,SP:e2179d114157200f5a22928ba5ae5b41ff1342f4,"The paper aims to develop an information-theoretic framework for learning the underlying model from data with instance-independent label noises. It first formalizes the problem and relevant definitions with information measures, such as conditional entropy and conditional KL divergence, then argues that if the underlying model is well-separated, the proposed algorithm will be consistent in learning the noise-labeling matrix. At the heart of the algorithm is a discriminator being able to measure the labelings' noise level. A class of discriminators based on 'local intrinsic dimension (LID)' is then provided and evaluated empirically. The resulting algorithm performs well on the tested instances compared to existing ones. ","The paper considers the problem of estimating instance-independent label noise. More formally, it is assumed that the true labels for any data point are modified based on a noise transition matrix, and the goal is to estimate this noise transition matrix. The paper proposed an information-theoretic approach for this task, the key idea behind which is to estimate if a particular dataset has maximum entropy with respect to the labels. This estimation problem is solved using a recent discovery that the training dynamics of a neural network can be used to infer the presence of label noise.",0.2037037037037037,0.2222222222222222,0.21256038647342992
2485,SP:e2212b3da261410c7b2714361d85d1b6876d4a3d,"Adversarial examples are test time attacks in which the input is modified by up to distance \eps (under some metric) and the goal of adversarially robust learning is to have high (generalized) accuracy even under such attacks. One way to make predictions is to always output a label. Another way is to “abstain/detect” when the learner thinks the input is not clean and is perturbed with. The way we evaluate the performance in the detection model is to count detected perturbed inputs as “correctly classified”.  The paper asks a very natural question: is it easier to learn when detection/abstain is allowed or not? The main result of the paper is very clean: For any metric d, and any eps, the existence of a learner that achieves accuracy c under detection model under 2\eps perturbations is (information theoretically) equivalent to the existence of a classifier in the no-detection model with accuracy c and eps perturbation.  The proof is “constructive” but it is not “efficiently constructive”. Namely, given a classifier in either of the two settings above, the paper shows a rather simple (but smart) way of constructing another classifier (with the parameters stated above) in the other model.  The paper then takes this connection to revisit the results of quite a few papers from the literature in which they have claimed defenses that use detection as their key idea. The paper observes that the bounds that (many) of those papers claim would imply classifiers with no detection/abstain that beat the state of the art adversarially robust classifiers. The paper cautiously claims that this indicates that the defenses of those papers are not actually secure, but rather “not broken” under simple attacks tried by the authors.","This paper considers one important question: how to fairly compare the adversarial robustness between detection-based defenses and classification-based defenses. From the theoretical perspective, the authors show that: one can always (ideally) construct a robust classifier from a robust detector which has equivalent robustness, and vice versa. Based on this construction method, they are able to transfer the robustness between robust detectors and robust classifiers. Finally, they find that most existing detection defenses achieve suspiciously high robust performance compared with state-of-art robust classifiers, if they apply the proposed “transferring” criteria.",0.07958477508650519,0.24731182795698925,0.12041884816753927
2486,SP:e2317a75f2c19efd73e3360b51afa3202de59e95,The paper extends previous works of the study of the adversarial risk. The authors interest in the well definition of the adversarial risk. They then show a minimax theorem on the game between the classifier and the adversary.,"This paper formalizes different definitions of adversarial risk for binary classification and studies the equivalence between those definitions. Moreover, the authors analyze optimal adversarial risk through the lens of optimal transport, which leads to the existence of a Nash equilibrium of the adversarial robustness game. The contribution of this paper is theoretical.",0.34210526315789475,0.25,0.2888888888888889
2487,SP:e23a409a3fc7b9ac30367891a19f33934915f9a6,"The authors propose a novel method for learning prototype representation for relations which abstracts the essential semantics of relations between entities in sentences. The learned prototypes are learned based on an objective with clear geometric interpretation and have been shown to be interpretable and robust to noisy from distantly-supervised data. The method has been shown to be effective for supervised, few-shot, and distantly supervised relation extraction. The prototype embeddings are are unit vectors uniformly dispersed in a unit ball and statement embeddings are centered at the end of their corresponding prototypes. The training is done such that intra-class compactness and inter-class separability is increased. The results show that the proposed approach gives state-of-the-art results for few-shot, supervised relation extraction. The authors demonstrate the interpretability and robustness of the method. ","This paper presents a pre-training method for encoders (i.e., BERT) of relation extraction, leveraging distant supervision data. The main idea is to introduce a prototype embedding for each relation in the distantly generated data. The loss function to pre-train the encoders involve several terms, aiming to exploit the intra-class compactness (e.g., the contrastive loss for statement pairs) and the inter-class separability (i.e., constraining the distances between the prototype for one relation and the embeddings of the statements for the same and different relations). The paper incorporates a prototype-level classification loss. Compared to few-shot learning models (e.g., prototypical networks), the paper claims that prototype-based losses can help the model to better address the noisy label issue of distantly generated data due to the exploitation of prototype and instance interactions. The pre-trained encoder is then applied on datasets for few-shot, supervised, and fuzzy relation extraction. The proposed method achieves competitive performance with other methods. Some analysis are also conducted to demonstrate the effectiveness of the proposed model.",0.26277372262773724,0.20224719101123595,0.22857142857142856
2488,SP:e2541b2195db1d6b0025113818f7d7a653473370,"This manuscript proposes a new pooling layer in Graph Neural Networks (GNN). By computing certain scores on edges which indicate the importance of edges in the process of information propagation, top r% edges are selected and a pooled graph is constructed by considering the connected components to be super nodes. The authors tried to explain some connection between their pooled graph and the normalized cut problem, which is not clearly stated in the manuscript. Even though the manuscript explores an interesting and timely topic, their approach is not technically appealing and the explanations are not enough to thoroughly understand the authors' ideas. My main concerns and major questions are as follows:","The paper proposes a novel pooling layer for graph neural networks. Pooling in GNNs amounts to merging nodes that are very similar through the layers. Specifically, the paper proposes to merge nodes whose edges have a high score according to the edge cuts. The edge score in practice is computed in each layer using an attention mechanism on the concatenated representations of the edge’s nodes from that layer. The authors then choose a fixed ratio r of the top edges to keep, in an effort to remove edges of nodes from distant communities. The edge score matrix which is n x n stores all the scores and is truncated based on the aforementioned threshold, renormalized, and used to extract the connected components simply from disconnected areas of the matrix. In the following layer, the clusters form super-nodes and their representations are a weighted combination of each individual node’s representation.",0.25225225225225223,0.18421052631578946,0.21292775665399236
2489,SP:e2751f28a08aec48bf570637674406729cc97e36,"The paper proposes a new way of defining CNNs for omnidirectional images. The method is based on graph convolutional networks, and in contrast to previous work, is applicable to other geometries than spherical ones (e.g. fisheye cameras). Since standard graph CNNs are unable to tell left from right (and up from down, etc.), a key question is how to define anisotropic filters. This is achieved by introducing several directed graphs that have orientation built into the graph structure.","The paper introduces geometry-aware filters based on constructed graphs into the standard CNN for omnidirectional image classification. Overall, the idea is interesting and the authors propose an extrinsic way to respect the underlying geometry by using tangent space projection. Understanding the graph construction and filter definition is not easy from the text description. It would be better to use a figure to illustrate them. ",0.16455696202531644,0.2,0.18055555555555555
2490,SP:e27fedc58e99952aaa61b87bb613b7e2c3e23126,"This paper deals with a fair regression problem in which the accuracy disparity is employed as a fairness measure. The authors derived the upper and lower bounds on the difference of accuracy between groups to demonstrate that imbalance in the groups' sizes leads to accuracy disparity. Furthermore, they propose learning algorithms enabling us to mitigate the accuracy disparity, which is accomplished by minimizing the upper bound they derived. The empirical evaluations show that the present methods achieve a better trade-off between accuracy and fairness than some existing fair regression methods.",This paper theoretically and empirically studies accuracy disparity in regression problems. It proves an information-theoretic lower bound on the joint error and a complementary upper bound on the error gap across groups to depict the feasible region of group-wise errors. It further proposes to achieve accuracy parity theoretically and empirically by learning conditional group-invariant representations using statistical distances. ,0.16483516483516483,0.2459016393442623,0.19736842105263155
2491,SP:e29058161116a098ecdd4e2efc9ef0a608f48f8e,"This paper considers a variant of k-means which takes the k-nearest neighbor graph as input. The proposed algorithm, called local k-means (LKM in short), then works by locally optimizing the assignment vector of a point using an objective function that is roughly the incremental cost for the k-means objective. The paper provided a lot of empirical data to show the advantages of LKM.","This submission introduces a computationally efficient clustering algorithm called LKM, which focuses on the scenarios where data is presented in the form of graph. In brief, only the k-nearest neighbour distances of each point are considered in the objective and a simple truncation of large distances is introduced to mitigate the effect of outliers.  The method is shown to produce promising practical performance in comparison with existing techniques both computationally and in terms of clustering performance.  ",0.23880597014925373,0.2077922077922078,0.22222222222222224
2492,SP:e290ab27d2ef262375e49897784ecb70927a264c,"This paper proposes a differentiable architecture search approach for splitting a deep network into locally-trained blocks to achieve training speedup. The approach achieves better performance than using backprop on small datasets (CIFAR10 and TinyImageNet), and comparable or slightly improved performance on ImageNet with 2x claimed training speedup. Learned network architecture choices seem to transfer between datasets.","The paper proposes a method for decoupled training of neural networks called SEDONA. In the spirit of recent trends in greedy layer-wise and indirect training, SEDONA allows gradient information to flow either from the next layer as in backpropagation or from an auxiliary head, trying to make a prediction using the current layer's output. Since a direct search for the best decoupled configuration results into probing a combinatorial number of splits, authors propose a continuously relaxed formulation which they later discretize. Transferring the found decoupled configurations to datasets different from the ""pretraining"" ones shows improvements in terms of validation accuracy and training time.",0.17543859649122806,0.09523809523809523,0.12345679012345678
2493,SP:e298712480d42a70bfd7a3052fda16480d6b8f95,"The paper intends to utilize natural gradient induced by Wasserstein-2 distance to train the generator in GAN. Starting from the dynamical formulation of optimal transport, the authors propose the Wasserstein proximal operator as a regularization, which is simple in form and fast to compute. The proximal operator is added to training the generator, unlike most other regularizations that focus on the discriminator. This is an interesting direction. ","This paper considers natural gradient learning in GAN learning, where the Riemannian structure induced by the Wasserstein-2 distance is employed. More concretely, the constrained Wasserstein-2 metric $d_W$, the geodesic distance on the parameter space induced by the Wasserstein-2 distance in the ambient space, is introduced (Theorem 1). The natural gradient on the parameter space with respect to the constrained Wasserstein-2 metric is then derived (Theorem 2). Since direct evaluation of $G^{-1}$ poses difficulty, the authors go on to considering a backward scheme using the proximal operator (3), yielding:",0.29411764705882354,0.2127659574468085,0.24691358024691357
2494,SP:e2bc61c78d53d0b72fcc5cde34368e88290371b6,"This paper presents an attractor network (AN) approach for pattern interpretation and completion. The authors propose a convolutional bipartite architecture consisting of visible (input and output) and hidden layers with weight constraints and squared and energy-based losses. To prevent vanishing/exploding gradients, temporal-difference method and leaky sigmoid activation function are exploited. Training is done by stochastic gradient descent. In experimental validation, the proposed model is able to reconstruct missing pixels in the images for bar task and supervised MNIST. And, in OMNIGLOT and CIFAR-10 experiments, the proposed approach outperforms its variants, and in super-resolution results, it outperforms the baselines. ","The paper argues for the use of attractive networks (AN) for the tasks that involve learning from noisy data. Attractor networks are recurrent in nature and use energy minimization dynamics. As motivation, the authors point to studies that give evidence for the usefulness of recurrence for visual tasks. The experiments presented show that the proposed model produces better quality images than a VAE based baseline.",0.1262135922330097,0.2,0.15476190476190477
2495,SP:e2de45a266957eb22a06444dba4e4d58be9292be,"In this paper, the authors propose a zero-shot NAS to search backbone for detection task. Specifically, this method uses the differential entropy of output features as a metric to measure the performance of architecture on detection task. With the differential entropy , this method does not need training network parameters, reducing the search cost largely. Also, the backbones searched by this method have the state-of-the-art performance on detection task.",This paper proposes a zero-shot neural architecture search approach for backbone design in object detection. The idea is to compute an entropy-based multi-scale Zen-score and use the score as an objective for evolutionary architecture search. The paper achieves better results comparing with previous zero-shot NAS approaches on object detection and greatly reduces the search time of conventional NAS approaches while maintaining similar accuracy.,0.2361111111111111,0.25,0.24285714285714285
2496,SP:e2f5cc48d84e800d9557d2a0f0e90b636ea22a15,"The manuscript focuses on a trending topic of applying a Bidirectional Encoder Representations from Transformers (BERT)-based prediction model to a new domain. More precisely, it addresses classifying Electronic Recruitment Records (ERRs) with respect to job skills. Its contributions include, but are not limited to, (i) releasing a related de-identified ERR dataset to the public domain, (ii) introducing a BERT-based embedding model, called SkillBERT, to group skills present in this ERR dataset into as competency clusters, and (iii) giving experimental evidence of the obtained modelling gains. ","This paper proposes a model for job application screening. Since there is no job-related dataset available, the authors manually assigned labels to a large job application dataset. A skill set (e.g., Apache Hadoop, Apache Pig, HTML, Javascript) is firstly extracted from the job dataset.  Then a competency group is constructed (e.g., big data, front-end) as the labels. The problem is then formulated as a multi-label classification problem. That is, given a skill (which may belong to multiple competency groups), the model has to predict its competency groups. The authors proposed to use BERT as the main model. Moreover, the authors use additional features like similarity-based and cluster-based features. The experimental results are good. We think it can help recruiters find a suitable applicant.",0.1590909090909091,0.1076923076923077,0.12844036697247704
2497,SP:e2fc6b6f79035a170007f3abae3a86c93dc1b65c,"This paper considers how to effectively perform exploration in the setting where a difficult, high-dimensional MDP can be mapped to a simpler, lower-dimensional MDP. They propose a hierarchical approach where a model of the abstract MDP is incrementally learned, and then used to train sub-policies to transition between abstract states. These sub-policies are trained using intrinsic rewards for transitioning to the correct state, and the transition probabilities in the abstract MDP reflect how well a sub-policy can perform the transition. ","This paper considers reinforcement learning tasks that have high-dimensional space, long-horizon time, sparse-rewards. In this setting, current reinforcement learning algorithms struggle to train agents so that they can achieve high rewards. To address this problem, the authors propose an abstract MDP algorithm. The algorithm consists of three parts: manager, worker, and discoverer. The manager controls the exploration scheduling, the worker updates the policy, and the discoverer purely explores the abstract states. Since there are too many state, the abstract MDP utilize the RAM state as the corresponding abstract state for each situation. ",0.2235294117647059,0.2,0.21111111111111108
2498,SP:e317f90d7b2beaa2c0ab6a9e0959e1acc8435ab5,"This paper proposes a new approach for Bilingual Lexicon Induction (BLI). To do this, the paper proposes the use of a FIPP objective, which consists of the linear combination of reconstruction and transfer loss terms. It derives the Gram matrix that minimizes this loss, followed by a rank-constrained semi-definite approximation to obtain an aligned embedding whose Gram matrix is close to the one minimizing the FIPP. The proposed approach is deterministic and has been shown to be efficient. Experiments also demonstrate the method works well, both on BLI and on downstream tasks.","This paper proposes an approach to align word vector spaces based on a dictionary of pairs (e.g. translations) that retains ""common geometric structure"" (inner products within each vector space for a subset of word pairs). In essence the approach applies preprocessing to each vector space, finds a projection of one vector spaces to the (lower-dimensional) vector space minimising a combination of a reconstruction and transfer loss, and then aligns the two using weighted procrustes to resolve rotational symmetries.",0.18085106382978725,0.2125,0.19540229885057472
2499,SP:e325877291d52a9f935df5d135756455f45a2c67,The paper discusses a method for learning neural networks with hard-threshold activation. The classic perceptron network is a one-layer special case of this. This paper discusses a method called guided random local search for optimizing such hard-threshold networks. The work is based on a prior work by Friesen&Domingos (2018) on a discrete target propagation approach by separating the network into a series of Perceptron problem (not Perception problems as quoted by this paper). ,"This paper addresses the problem of training neural networks with the sign activation function. A recent method for training such non-differentiable networks is target propagation: starting at the last layer, a target (-1 or +1) is assigned to each neuron in the layer; then, for each neuron in the layer, a separate optimization problem is solved, where the weights into that neuron are updated to achieve the target value. This procedure is iterated until convergence, as is typical for regular networks. Within the target propagation algorithm, the target assignment problem asks: how do we assign the targets at layer i, given fixed targets and weights at layer i+1? The FTPROP algorithm solves this problem by simply using sign of the corresponding gradient. Alternatively, this paper attempts to assign targets by solving a combinatorial problem. The authors propose a stochastic local search method which leverages gradient information for initialization and improvement steps, but is essentially combinatorial. Experimentally, the proposed algorithm, GRLS, is sometimes competitive with the original FTPROP, and is substantially better than the pure gradient approximation method that uses the straight-through estimator.",0.2597402597402597,0.10810810810810811,0.15267175572519084
2500,SP:e34072bff0b40655ed566bd88f75b458d381edc4,This paper proposes a NAS method for both multiplication-based and adder-based networks. The contributions mainly lie on hybrid search space and new weight sharing strategy. The experimental results shows the method can obtain energy-efficient networks with high performance.,"This paper designs a hybrid search space that includes multiplication-based operators and multiplication-free operations to find good trading points between accuracy-efficiency. Further, this work defines the problem when training weight-sharing supernet on the hybrid search space and proposes the heterogenous weight sharing algorithm to address the problem. The proposed method is validated on both NLP and CV tasks, outperforming several competitive baseline methods in terms of accuracy and saving efficiency on latency or energy. ",0.43902439024390244,0.23076923076923078,0.3025210084033614
2501,SP:e3455519fcc3ce8644fa55c52771b5414a571026,"The paper presents new techniques to enable secure neural training in the TEE+GPU paradigm. This is a natural extension of previous work like Slalom which only handles the inference case. The authors propose a two-step approach. First, they clip the gradients during training to force the attacker to insert multiple deviations to influence the model. They then randomly verify the integrity a subset of the gradient updates to check for tampering. Combining these two ideas the authors demonstrate a 2-20x improvement over a TEE only benchmark.","The paper targets security challenges of deep neural networks. While solutions can hardly scale up to support realistic DNN model training workloads, the authors propose GINN to support integrity-preserving DL training by random verification of stochastic gradient steps inside trusted execution environments (TEE). GINN combines random verification and gradient clipping to achieve good performance. The experimental results show that GINN achieves 2x-20x performance improvement compared with the pure TEE based solution while guaranteeing the integrity with high probability.",0.1797752808988764,0.2,0.18934911242603553
2502,SP:e360ee23213bc07ce3e02914696e51ea4517ae9f,"In this paper, the authors propose a scalable certified defense framework to detect patch attacks. The authors empirically show that patch attacks rely on localized Superficial Important Neurons (SINs) to cause misclassification. By occluding image patches corresponding to these localized neurons, the predictions on patched images become unstable, while those of benign images rarely change. The proposed approach ScaleCert uses these SINs to check if a patch attack is present by occluding certain candidate regions and observing if the prediction changes. The proposed method leads to significant improvements in certified detection accuracy on ImageNet, while having lower computational cost, thus promoting its usage in the real world.","The proposed approach presents scalable certified defense against adversarial patch attack.  The method relies on pruning unimportant neurons and identifying regions in the input image which contain the adversarial patch. Once the patch location is identified, the label is predicted is using prediction consistency. A certification algorithm is provided which shows significant improvements over previous methods on ImageNet. ",0.17757009345794392,0.3275862068965517,0.2303030303030303
2503,SP:e36c7de37059ea0fe7ed64fb32926adfd76b30c1,"This work presents a novel learned activation function called Attention-based Rectified Linear Unit (AReLU). Element-wise attention module is developed that learns a sign-based attention (ELSA) which is the novel component of AReLU towards mitigating the gradient vanishing issue. Extensive experiments and analyses have been provided on MNIST and CIFAR100 datasets. Compared with other relevant activation functions, AReLU achieves faster convergence under small learning rate because of the amplification of positive elements and suppression of negative ones with two learnable data-adaptive parameters.   ","In this paper, the authors proposed a new activation function called AReLU which introduces an attention mechanism to the original ReLU function. Based on this new activation function, the output will be adaptively adjusted by the two learnable parameters \alpha and \beta. This kind of adaptive adjustment can be thought of as an attention mechanism undertaken over each element in the input feature map. It will in general amplify the positive elements while suppressing the negative ones, and the parameters \alpha and \beta will be adjusted adaptively based on the activation values. The experimental results showed that AReLU can achieve much better performance with small learning rates while comparable performance with fairly large learning rates. This inspires another set of transfer learning experiments that demonstrate the effectiveness of AReLU.",0.23529411764705882,0.15503875968992248,0.18691588785046728
2504,SP:e37e9f38fd9760a82039505a59b7eab209bbacd5,"This paper proposes a new few-shot learning method with class dependencies. To consider the structure in the label space, the authors propose to use conditional batch normalization to help change the embedding based on class-wise statistics. Based on which the final classifier can be learned by the gradient-based meta-learning method, i.e., MAML. Experiments on MiniImageNet show the proposed method can achieve high-performance, and the proposed part can be proved to be effective based on the ablation study.","The paper presents an enhancement to the Model-Agnostic Meta-Learning (MAML) framework to integrate class dependency into the gradient-based meta-learning procedure. Specifically, the class dependency is encoded by embedding the training examples via a clustering network into a metric space where semantic similarity is preserved via affinity under Euclidean distance. Embedding of an example in this space is further employed to modulate (scale and shift) features of the example extracted by the base-learner via a transformation network, and the final prediction is made on top of the modulated features. Experiments on min-ImageNet shows that the proposed approach improves the baseline of MAML.    ",0.1927710843373494,0.14953271028037382,0.16842105263157894
2505,SP:e384abbadce76420670e40b9597cc5511369d422,"This paper proposed a new analysis for AdaGrad method in smooth and non-convex optimization, to get high probability convergence toward stationary points.  Based on some assumptions (Eqs. (2), (6) and (7)), i.e., Lipschitz, bounded variance of gradient estimates, and bounded stochastic gradient, the authors analyzed Algorithm 1 (AdaGrad), which does not use any information of the quantities in the assumptions. They show that (in Theorem 4.2), with high probability, the averaged cumulative gradient norm square is converging to $0$ at order of $\tilde{O}(\log{(1/\delta)}/\sqrt{T})$. The main difficulty is to derive high probability bounds for the two quantities in Eq. (10), i.e., Propositions 4.1 and 4.2.  The authors then generalized their analysis to the generic AGD template (Algorithm 2), which recovers AdaGrad, AdaGrad with averaging, adaptive RSAG, and AcceleGrad as special cases by choosing different $\alpha_t$, $\eta_t$ and $\gamma_t$ parameters. Similar high probability convergence results can be obtained for AdaGrad with averaging, and adaptive RSAG, but not for AcceleGrad.  ","This paper provides an analysis of adaptive learning rate scheme in stochastic non-convex settings. Under assumptions of smoothness and bounded stochastic gradients (a light tailed condition), it is shown that the sum of the gradient norms of the iterates of the non-convex algorithm is small. In order to accomplish this, the analysis must deal with the standard difficulty for adaptive learning rates, which is that the learning rate depends on the current iterate and so makes it harder to apply standard martingale inequalities. The final results include a dependence on the smoothness constant $L$ and variance $\sigma$ which are not explicitly used in the algorithm.",0.16279069767441862,0.2616822429906542,0.2007168458781362
2506,SP:e38d77c5f280583a9c740fc8f4eccf8abceab5ce,"This paper proposes to train a generative model for entire populations of maximally diverse agents, from which one specific individual policy can quickly be selected at deployment time through a fast search process.  Policies are represented as networks augmented with a low-dimensional latent variable z, randomly sampled at agent initialization. Thus each trained network is actually a generative model, from which an infinity of policies can be generated by sampling over z.   Crucially, the training procedure encourages the fixed weights of the network to not only obtain good performance for any given random z, but also to produce maximally different policies for any two different z. Thus the method is a quality diversity (QD) method (though the authors seem ambiguous on the subject).  This method is compared with a previously published method (DIAYN), and with itself but without the diversity objective, and is found superior to both on various gridworld tasks, both in terms of expected performance and diversity of generated agents. ","The authors proposed a generative model of policies, which maps a low-dimensional latent space to an agent policy space to learn a space of diverse and high-reward policies on any given environment (without requiring the use of separate policy parameters). The proposed method is able to adapt to changes in our environment solely by selecting policies in latent space. The experiments evaluated our generative model’s capabilities in a variety of environments, including an open-ended grid-world and a two-player soccer environment.  The strength of this paper is as follows: 1) The proposed method integrates the goals of quality diversity into deep RL by simulating an entire population of agents via a generative model of policies. 2) The authors evaluated this method using three different experiments and showed that this method was able to learn a more multi-modal and effective policy space than any of the other baselines.  ",0.19631901840490798,0.20915032679738563,0.20253164556962025
2507,SP:e3aa12a5f1d70e4d877ae9ff02a92981c92f1f32,"The submission details a novel technique to learn the routing in capsule networks for image classification tasks. Connecting capsules in such architectures typically requires iterative approaches which are computationally expensive. The main idea in this submission is to leverage a non-iterative attention mechanism to learn this routing and thus decreases computational cost. Furthermore, the experiments indicate that the proposed architecture leads to higher accuracy on a number of image classification tasks and datasets.","The paper proposes to swap the typical routing mechanisms in capsules for a more standard attention mechanism. The attention mechanism is based on computing similarity scores using gaussians instead of dot-products . The authors show that this leads to better downstream performance of more natural tasks while preserving robustness to viewpoint changes, one of the main strengths of capsules.",0.20270270270270271,0.2542372881355932,0.22556390977443608
2508,SP:e3ce73327452f27aa256253ba6b402635697820c,"This paper proposes a method for unsupervised meta-learning based on using a variational autoencoder (VAE). The variational autoencoder model they use differs from the typical one in that it considers episode-specific datasets, where the approximate posterior can be computed as a function of the set (using transformer architecture) rather than using an individual example. Additionally, they use a mixture of Gaussian distribution as a prior, whose parameters are learned per-episode using the EM algorithm. For the supervised evaluation phase, in order to adapt the learned prior to the few-shot dataset setting, semi-supervised EM is run using both support and query sets to adapt the mixture of Gaussian distribution to the evaluation dataset. Then, the query set predictions are obtained using the learned prior and posterior from the VAE model. Experimental evaluation is conducted on the Omniglot and Mini-ImageNet benchmarks and the proposed method is compared against other unsupervised meta-learning methods, mainly CACTUs and UMTRA. An interesting aspect about the Mini-ImageNet experiments are that because learning the VAE directly for this high-dimensional data may be difficult, the authors use features from a SimCLR-trained model as input for their VAE model. The proposed method seems to perform favorably across both of the benchmarks when varying the number of ""shots"". ","The submission proposes an algorithm for the semi-supervised meta-learning (unsupervised meta-training + supervised meta-testing) setting of [1], which adapts the few-shot learning + evaluation setting of [2, 3] by omitting classification labels at meta-training time. The algorithm makes use of a variational auto-encoder (VAE) formulation defined over a hierarchical model that describes the decomposition of a dataset into tasks of datapoint-target pairs (i.e., the meta-learning setup). The prior distribution of the hierarchical VAE is taken to be a mixture of Gaussians to facilitate the construction of pseudo-labels at meta-training time. The algorithm is evaluated on the Omniglot and miniImageNet few-shot classification tasks (with labels unused at meta-training time).",0.14285714285714285,0.25833333333333336,0.18397626112759644
2509,SP:e3e6dc2285271426a37bc08e8989e03fe1891ea9,"This paper presents a model-based RL algorithm that provides decomposed dynamics models when the state and action spaces are defined as a multi-dimensional Cartesian space.  We can divide the method into two parts: * The one for partitioning the action coordinates, and * The NN architecture, one for each partition and then combining the outcomes ($h^i_t$) of partitions into the final one ($h_t$). This paper also shows a clustering based on the correlation, human-provided partition, and full/random partitioning algorithms.   The experiment shows the results on Mujoco-based environments that have orthogonal coordinates per position and velocity, so the action coordinate partitioning can be readily applicable.","The authors propose an environment dynamics decomposition (ED2) framework to decompose the environmental dynamics into multiple sub-dynamics. Empirical results show that ED2 improves the performance of several model-based reinforcement learning (MBRL) algorithms. The paper is well-written and easy to read, and the motivation is clear.",0.09090909090909091,0.20833333333333334,0.12658227848101267
2510,SP:e3e9a73988c8a2fb968f9ac2739ccac95f5a01bf,"To alleviate the issues of reward sparsity and mode collapse in most text-generation GANs with a binary discriminator, this paper proposes a self-adversarial learning (SAL) framework with a novel comparative discriminator that takes pairs of text examples from real and generated examples and outputs better, worse, or indistinguishable. Inspired by self-play in reinforcement learning, SAL employs self-play to reward the generator to generate better samples than previous samples with self-improvement signals from the comparative discriminator. It is argued that, because the comparative discriminator always produces self-improvement signals during the training and the self-improvement signal will not be very strong when generated samples are already good enough, the issues of reward sparsity and mode collapses in conventional text GANs are reduced. Experimental results on synthetic data and benchmark datasets demonstrate that SAL outperforms SeqGAN, MaliGAN, and RankGAN both quantitatively and qualitatively.","This paper introduces a Self-Adversarial Learning (SAL) mechanism in GAN based text generation, aiming at tackling the problem of mode collapse and sparse rewards problem. Specifically, motivated by “self-play” mechanism in RL community, instead of using a binary classifier as discriminator in original GAN, SAL employs a comparative discriminator which is a pairwise classifier with three classes: “better”, “worse” and “indistinguishable”. The authors provide lots of experimental results and ablation study showing the efficiency of the proposed mechanism in comparison with previous GAN models.",0.16326530612244897,0.27906976744186046,0.2060085836909871
2511,SP:e3ec7c4484ffce62c71a364bd6fadcad84dd5a3a,This paper studies the combination between model uncertainty and data uncertainty based on spectral-normalized Gaussian process. Theoretical results show that heteroscedastic SNGP allows for joint modeling of model and data uncertainties. The paper then proposes an approximate inference scheme for efficient model training. Experiment results support these claims on synthetic datasets and typical classification benchmarks. ,This paper presents a new method for model and data uncertainty estimation in deep neural networks combining the heteroscedastic method (Collier et al. 2020) and the Spectral-Normalised Gaussian Process (SNGP) method (Liu et al. 2020). It is shown that the two methods are complementary and their combination outperforms state-of-the-art methods on Out-Of-Distribution (OOD) detection on common image classification benchmarks.  ,0.26785714285714285,0.23076923076923078,0.24793388429752067
2512,SP:e43bf2bece7193a5b7dda847f81f3e730dffae9b,"This paper studies the problem of mean estimation of n vectors in R^d in a distributed setting. There are n machines. Each has one data point, a vector x_v. The goal is to compute the mean of x_v’s for v = 1, …, n with as few bits of communication as possible. ","The paper considers a particular setting of distributed mean estimation problem, where each party has a vector of potentially large $l_2$ norm, yet this vectors are fairly close to each other. The goal is to communicate as few bits as possible and estimate the mean of the vectors. Previous approaches had the dependence on the size of the ball containing all the vectors, which gives bad bounds if vectors are long (but close to each other).",0.3148148148148148,0.22077922077922077,0.2595419847328244
2513,SP:e4482ea19c071040799a23293a00fef8305126d5,"The authors introduce a variational autoencoder for conditional generation of molecules. The model is borrowed from text-based style transfer, applied here on sequence (SMILES) representation of molecules rather than viewing molecules as graphs (as more recent approaches). From a modeling point of view, the main new part is an additional regularizer whose role is to 1) ensure that the property used as input during generation matches the property derived from the generated molecule, and 2) to dissociate the latent molecule representation in the autoencoder (loosely speaking, its overall structure) from the property being controlled. This regularizer is just a squared difference between predicted and actual properties, averaged over independent samples from latent states and properties which are parametrically mapped to predicted properties via the decoder state (so as to be able to backprop).","This paper proposes a VAE-based conditional molecular graph generation model. For that purpose, the disentanglement approach is adopted in this paper: learn to separate property information from the structure representation of a molecular graph. The authors use the supervised VAE objective since the KL regularizer in the objective has reportedly disentanglement-promoting effect. The final objective function is a standard VAE ELBO plus a penalty term of the property value prediction error. Non-differentiable property estimation is conducted via stochastic sampling expectation with the help of an external program (RDKit).  ",0.1417910447761194,0.2087912087912088,0.1688888888888889
2514,SP:e449d491c8fd678c25baf537a4ea440c8a7e5245,"This submission proposes a theoretical and experimental framework for learning causal representations using continuous-time neural networks. The proposed method is evaluated on a visual drone navigation tasks of chasing static and dynamic objects in the AirSim simulation. Experiments show that the proposed method outperforms LSTMs, recurrent neural network version of Neural ODEs and continuous-time GRUs. ","This paper explores the capabilities of continuous-time networks to form casualty structures, as well as their applications to visual drone navigation. The authors find that models based on the liquid time-constant networks (LTCs) uniquely provide causal structures. The theoretical discoveries are then verified in closed-loop visual navigation experiments. LTC-based policies significantly outperform regular continuous time models and discrete RNNs, all trained using imitation learning. ",0.21052631578947367,0.17647058823529413,0.19199999999999998
2515,SP:e45e360db642276339cbe3890bd16df3ab748bc2,"The paper proposes the idea of a new knowledge graph embedding technique that builds on top of TransH and incorporate implication ordering. Results show that it outperforms the previous state-of-the-art method on link prediction and triple classification tasks on FB122. The idea and the new angle of looking at TransH are interesting, but the paper needs lots of revision in terms of clarity and formatting. More experiments could also be included to better show strength.","This work describes a new approach to learn KG embeddings by preserving the ""implication ordering"" among relations in the embedding space. The paper provides a cute new interpretation of TransH and then uses it to extend TransH to learn entity and relation representations. The crucial novelty of the approach is to map relations into linear subspaces whose parameters are tied using the implication ordering of relations.",0.1794871794871795,0.21212121212121213,0.19444444444444445
2516,SP:e472738b53eec7967504021365ac5b4808028ec1,"This paper introduces a corpus-based approach to build sentiment lexicon for Amharic. In order to save time and costs for the resource-limited language, the lexicon is generated from an Amharic news corpus by the following steps: manually preparing polarized seed words lists (strongly positive and strongly negative), calculating the co-occurrence of target word in its context via Positive Point-wise Mutual Information (PPMI) method, measuring the similarity between target words and seed words by cosine distance, iterating with the threshold 100 and 200. The PPMI lexicon is stemmed and evaluated from aspects of subjectivity detection, coverage, agreement and sentiment classification. Three other lexicons: Manual developed by manual, SOCAL and SWN developed by bilingual dictionary, are used as benchmark to compare with the PPMI lexicon. In sentiment classification experiment the PPMI lexicon did not show a superior performance. All the four lexicons have similar accuracy, between 42.16% ~ 48.87%.  Only when the four are combined together the result is improved to 83.51%. ","This paper proposes a domain-specific corpus-based approach for generating semantic lexicons for the low-resource Amharic language. Manual construction of lexicons is especially hard and expensive for low-resource languages. More importantly, the paper points out that existing dictionaries and lexicons do not capture cultural connotations and language specific features, which is rather important for tasks like sentiment classification. Instead, this work proposes to automatically generate a semantic lexicon using distributional semantics from a corpus.",0.13253012048192772,0.2857142857142857,0.18106995884773663
2517,SP:e4db134ad2f3217ae370cb58399efc86047166f7,"This paper studies learning in stochastic games, which are extensions of Markov decision processes (MDPs) from the single-agent setup to the multi-agent one. Here the objective of each learner is to optimize her own reward function. Similarly to the case of MDPs, here one can devise learning algorithms with controlled sample complexity or regret (or both simultaneously) even when reward and transition functions are unknown. ","The authors introduce new algorithms to solve two-players zero-sum Markov games, as well as two-players Markov game in the reward-free setting. The approach is model-based, based on successive episods of planning and counting for updating the model estimate. It involves solving a matrix game at each iteration, looking for a notion of equilibria that is computable in polynomial time (unlike Nash equilibria) An extension to multi-player games is proposed for both reward and reward free setting (in the appendix).",0.16417910447761194,0.12941176470588237,0.14473684210526316
2518,SP:e4e55a9fb7e1f55fd0a6d13c315f524774b74b5f,"The paper describes poisoning and backdooring attacks on CLIP, a recent method to (pre)-train multimodal networks with a contrastive objective. The setting here is different from a classical supervised BadNet-like setup in that learned embeddings are not necessarily going to be directly mapped to a class of choice. Authors evaluate both zero-shop learning setup and the linear probes to find that both of them can be successfully backdoored and poisoned with much fewer requirements. Authors extensively evaluate their attack and pinpoint what hyperparameters make it more effective. ","This paper explores data security in multimodal contrastive learning. In particular, it designs an image-text pair generation to poison the dataset, driving the model to misclassify a particular test input or a group of images with a small patch. While the generation method is quite simple, the attack success rate is impressive (only 3 out of 3 million images to conduct target poisoning attacks). This paper reminds us that it is potentially dangerous to train models on noisy and uncurated Internet scrapes, which is applied in some SOTA algorithms.",0.13333333333333333,0.13333333333333333,0.13333333333333333
2519,SP:e4eac7e23932f7b1c1ac0c281cbeb076a4525a86,"This paper proposes to combine model-based and multi-agent reinforcement learning. The authors follow the typical recurrent neural world models setting to generate imagined rollouts for decision-time planning. To tackle the non-stationarity of a multi-agent environment, they build end-to-end differentiable communication channels between agents within a pre-defined neighborhood. The communication message is defined as abstract information encoded from the imagined rollout. Agents then make decisions based on the message they received and the output of recurrent neural world models. Empirical studies are performed to show the superiority of proposed methods over SOTA model-free MARL approaches. Results are shown in two simple environments, which are designed to require communication between agents to solve the task.",The paper talks about developing a model-based method for cooperative multi-agent reinforcement learning. The proposed approach utilizes communication as a tool for mitigating the partial observability induced by the non-stationary task while also helping agents reason about other agents' behaviors. The authors present their motivation for using language as a medium in model-based RL stemming from early literature in psychology and linguistics.,0.13114754098360656,0.24242424242424243,0.17021276595744678
2520,SP:e4f04edbe1885c93875d82d78d3e0cf2d0359393,"This paper enables a feature-based parametrization and amortized inference of Pairwise Choice Markov Chains (PCMCs), a model for decisions in the face of a set of alternative choices (e.g. the rock-paper-scissors game).  Previous approaches to fitting PCMCs have leveraged sequential least squares programming, making optimization unstable, the model prone to overfitting, and test-time inference difficult.  The authors propose parametrizing PCMCs with neural networks to fix these issues.  Relying on universal function approximation results, the authors show that their PCMC-Net can represent arbitrary transition matrices.  The experiments report results on a dataset of airline booking behavior, comparing PCMC-Net with four other baselines from the literature.","This paper introduces a novel approximate inference method, called PCMC-Net, for models from the family of Pairwise Choice Markov Chains (PCMC). The method relies on training a neural network. Consequently, the authors claim that inference is amortized, but its computational complexity is still quadratic in the number of choice alternatives due to separate processing of all pairs of alternatives. PCMC-Net bakes the definition of PCMC into the neural net structure and therefore satisfies the theoretical properties of contractability and uniform expansion, which are desired properties of choice models",0.1981981981981982,0.24444444444444444,0.21890547263681592
2521,SP:e4f5ca770474ba98dc7643522ea6435f0586c292,"The paper studies (the more conventional) deterministic auto-encoders, as they are easier to train than VAE. To then try to maintain the model's capability of approximating the data distribution and to draw/synthesize new unseen samples, the paper both looks at imposing additional regularization terms towards a smooth decoder and proposes to sample from a latent distribution that's induced from empirical embeddings (similar to an aggregate posterior in VAE). Experiments are mostly around contrasting VAEs with the proposed RAEs in terms of comparing the quality of the generated samples.","This paper propose an extension to deterministic autoencoders. Motivated from VAEs, the authors propose RAEs, which replace the noise injection in the encoders of VAEs with an explicit regularization term on the latent representations. As a result, the model becomes a deterministic autoencoder with a L_2 regularization on the latent representation z. To make the model generalize well, the authors also add a decoder regularization term L_REG. In addition, due to the encoder in RAE is deterministic, the authors propose several ex-post density estimation techniques for generating samples.",0.17391304347826086,0.17582417582417584,0.17486338797814208
2522,SP:e4f6ad5fdfa9a438b8b3be4cbe856ea2ab5d68e6,"This paper studies the training of over-parameterized two layer neural networks with smooth activation functions. In particular, this paper establishes convergence guarantee as well as generalization error bounds under an assumption that the data can be separated by a neural tangent model. The authors also show that the network width requirement in this paper is milder than the existing results for ReLU networks.","The authors study the problem of binary logistic regression in a two-layer network with a smooth activation function.  They introduce a separability assumption on the dataset using the neural tangent model.  This separability assumption is weaker than the more Neural Tangent Kernel assumption that has been extensively studied in the regression literature.  In that case, a certain Gram-matrix must be nonnegative.  In the current work, the authors observe that the structure of the logistic loss in the binary classification problem restricts the functional gradients to lie in a particular space, meaning that nonnegative of the Gram-matrix is only needed on a subspace.  This is the underlying theoretical reason for why they can get improvement over those methods in the setting they study.  Under the separability assumption, the authors prove convergent gradient descent and generalization of the ensuring net, while assuming the two-layer networks are less overparameterized than what would have been possible under the Gram-matrix perspective.  ",0.34375,0.13664596273291926,0.19555555555555557
2523,SP:e522f566b99caa1192abcb06ec74ec8c3d6c6cdb,"This paper proposes to provide a novel noise-aware knowledge graph embedding (NoiGAN) by combining KG completion and noise detection through the GANs framework. More specifically, NoiGAN repeatedly utilizes a GAN model to 1) approximate the confidence score for facts identifying reliable data (discriminator) and 2) generate more challenging negative samples (generator). Then, it uses this confidence score and negative samples to train a more accurate link prediction model. The authors validate the proposed model through several experiments.","This paper presented a jointly learning framework based on GAN for tackling both knowledge graph completion and noise detection simultaneously. Existing works only deal with each of task independently and did not investigate the benefits of coping with both tasks together. The paper is well motivated. In order to achieve them, the paper presented a GAN framework in order to train a noising KG embedding as well the generator and discriminator. The key connections between two parts are through the confidence of a noise triple and generation of the negative sample triples. The whole framework looks quite interesting and promising. The experimental results are provided to validate the effectiveness of the proposed model. ",0.2948717948717949,0.20353982300884957,0.2408376963350785
2524,SP:e53c2b7df4186288a6d5c57057ef099761e91191,"In this paper, an invertible encoding method is proposed for learning latent representations and deep generators via inverting the encoder. The proposed method can be seen as an autoencoder without the need to learn the decoder. This can be computed by inverting the encoder. To the best of my knowledge the proposed method is novel and its building blocks are described adequately. ","PIE extend NICE and Real NVP into situations which require having a smaller dimensionality of the latent variable (d) compared to the dimensionality of the observed variable (D), i.e. d < D. This is done by learning an extension function g(z) from R^d to R^{D-d} and then using the change of variables formula on x and [z, g(z)]. To model probabilistically the deterministic function g(z) is replaced by Normal distribution with mean g(z) and a small variance.",0.1935483870967742,0.14285714285714285,0.1643835616438356
2525,SP:e5435a2d586d6f2bebf436aae8a7fb3602064ab8,"This paper develops a method to train agents to bid competitively in the game of Bridge. The authors focus on the bidding phase of the game and develop a model to predict the best bid to make at each turn of the phase. The difficulty in the bidding lies in understanding the signals provided by your own teammate as well as the opponent team in order to estimate the state of the game, which is partially observable since each player cannot see the hands of the three other players. The authors show that explicitly modeling the belief of other agents is not necessary and that competitive performance can be achieved with self-play. ","The authors propose a deep learning agent for automatic bidding in the bridge game. The agent is trained with a standard A3C reinforcement learning model with self-play, and the internal neural network only takes a rather succinct representation of the bidding history as the input. Experiment results demonstrate state-of-the-art performance with a simpler model. The authors discuss some findings with the proposed agent, such as the lack of need to explicitly model the belief and the possibility to self-train with different variants of opponents. Some visualization is also provided to understand how the trained agent behaves.",0.21238938053097345,0.2376237623762376,0.22429906542056074
2526,SP:e547064b6600f601b2ea5bfe9c3f67d119d2c8c9,"This manuscript presents a nice empirical comparison between the classic KNN imputation with two state-of-the-art GAN-based imputations for tabular data imputation. The experiments are performed on both simulated and publicly available real data. The results, overall, show that the KNN, despite its simplicity, provides very competitive results when compared to its more complex and computationally expensive alternatives. In summary, this paper has a few important messages for both method developers and reviewers in the missing data community: i) first try the simplest; ii) more complex does not mean better; iii) understand your data before data imputation;  ","This paper considers the problem of tabular data imputation to handle missing numeric data. It compares the RMSE of recently proposed GAN-based methods (GAIN and mis-GAN) with the classical KNN method (either through uniform or distance-weighted imputation). It considers 9 datasets, two are simulated by a mixture of Gaussians and 7 are real datasets, 5 of them used in the GAIN paper. The datasets have 500-30000 samples and 5-57 features (most are below 20). It also considers three different mechanisms of missing data (MCAR - completely random, MAR - random based on the observed data, MNAR - based on unobserved data), each with one or two rates of missing data (more rates are tested for MCAR with the simulated data). The hyperparameters of all the models are tuned once on the simulated data (1000 samples), and scaled based on the number of samples for each dataset (scaling the number of neighbors for KNN, or epochs for the GANs). The models are applied to each imputation case 20 times, presenting the mean and standard deviation for each dataset in each scenario. The paper shows that mis-GAN, originally developed for filling missing image pixels, usually performs much worse than KNN. Furthermore, KNN generally performs roughly on-par compared to GAIN, depending on the dataset and exact scenario (in many cases KNN is better). Based on the presented figures, the RMSE differences are usually within 0.02, but may reach 0.05. The compute required by KNN is much lower, and the paper calls for using the cheaper option, avoiding waste of resources.",0.27,0.10266159695817491,0.1487603305785124
2527,SP:e547b90d039328d391756b0657f9653e1a5c2d2b,"The paper proposes a novel representation learning technique to disentangle the latent space of pre-trained generative models, by discovering semantically meaningful directions in them.  The method trains a navigator and a delta-contrastor network, which consists of 2 encoders sharing weights. First, random samples are perturbed along the directions obtained from the navigator. The perturbed vectors are then decoded with the pre-trained generator, then encoded and the difference between 2 samples are taken. The output is in the variation space, where a contrastive learning technique clusters together the samples that were perturbed with the same direction. ","This paper presents a framework to model disentangled directions for pretrained models. Such an approach mitigates the problems with poor generation quality arising while training models with additional regularization terms to force disentanglement. The underlying idea is contrastive-based: similar image variations are caused by changing the same factors in contrast to the remaining image variations. The proposed framework is model-agnostic: it can be applied to GANs, VAEs and flow models.",0.12244897959183673,0.16666666666666666,0.1411764705882353
2528,SP:e58dc2d21175a62499405b7f4c3a03b135530838,"This paper investigates the performance of invertible generative models for solving inverse problems. They argue that their most significant benefit over GAN priors is the lack of representation error that (1) enables invertible models to perform well on out-of-distribution data and (2) results in a model that does not saturate with increased number of measurements (as observed with GANs). They use a pre-trained Glow invertible network for the generator and solve a proxy for the maximum likelihood formulation of the problem, where the likelihood of an image is replaced by the likelihood of its latent representation. They demonstrate results on problems such as denoising, inpainting and compressed sensing. In all these applications, the invertible network consistently outperforms DCGAN across all noise levels/number of measurements. Furthermore, they demonstrate visually reasonable results on natural images significantly different from those in the training dataset.","This paper proposes to employ the likelihood of the latent representation of images as the optimization target in the Glow (Kingma and Dhariwal, 2018) framework. The authors argue that to optimize the ''proxy for image likelihood'' has two advantages: First, the landscapes of the surface are more smooth; Second, a latent sample point in the regions that have a low likelihood is able to generate desired outcomes. In the experimental analysis, the authors compare their proposed method with several baselines and show prior performance.",0.14482758620689656,0.25,0.18340611353711792
2529,SP:e59dce35ddf8c0356e92c60959da89c7f4ce20de,"In this paper, the authors present a novel approach to evade the transferability of adversarial examples between two models. Specifically, they design a luring loss to train model T, an augmented version of M, where the adversarial examples cannot transfer from T to M. The luring loss is designed to reach a twofold objective: (1) for a clean example, T and M yield the same prediction (2) for an adversarial example, T and M yield different predictions, and in the best case, M can provide correct prediction. The proposed approach can serve as a defense for both detect adversarial examples and defend adversarial examples. Experimental results show that the proposed defense can detect and defend adversarial examples better that the three baselines. In general, the paper is clearly written and easy to follow.","The paper proposes a new framework for addressing the problem of adversaries in black box settings in order to improve model robustness. Leveraging classical deception frameworks used in network security, the authors propose to fool the attacker by training what they call a `luring component’ that is augmented to an already trained model such that the new model does not later good samples and targets the adversaries to achieve the desired result. Additionally, the proposed framework does not need access to labeled data and can be applied to any pre-trained model. Promising results are demonstrated on multiple datasets like MNIST and CIFAR 10, etc.",0.15037593984962405,0.19047619047619047,0.1680672268907563
2530,SP:e5b6ac071882028ba6191098c718861340728918,"The authors introduce DreamerV2, a modification of the influential Dreamer RL agent (hereafter refered to as DreamerV1). The primary changes from DreamerV1 are a discrete latent space and a modified loss function (and with it, a modified optimization scheme). As in DreamerV1, the agent trains a world model with environment experience, and the policy is learned by ""imagining"" within the learned latent space using the world model to simulate transitions and rewards. They demonstrate superior performance over a variety of successful benchmarks that use similar compute (1 GPU, 1 environment -- e.g. MuZero, which requires vastly more, is not considered) on Atari. Further, they analyze several ways of aggregating Atari scores, and (while their algorithm performs best of those tried in each aggregation), they recommend one aggregation method (along with several other choices made for benchmarking) going forward.","The authors build on the Dreamer architecture, that is able to learn models of an environment, to build DreamerV2, which learns a model of an environment in latent space. The authors then train their agent in this latent space. DreamerV2 was evaluated on the Atari learning environment and results showed that it was comparable to Rainbow and better, under certain metrics.",0.11594202898550725,0.26229508196721313,0.16080402010050251
2531,SP:e5bb31f2b7a8d8c2c605b71fc625890bb4f5a388,"This paper proposes Kokoyi, which can automatically translate mathematics into Python implementations. The proposed tool consists of kokoyi-lang, a programming language with the syntax of LATEX and the semantics of deep learning mathematics, and kokoyi-lang, a compiler and runtime supporting advanced optimizations. Kokoyi is integrated with Jupyter Notebook. To measure the flexibility of Kokoyi, the authors have implemented a variety of popular DL models and performed evaluation.","The paper presents a LaTeX-based language and compiler called kokoyi to write math-based models and compile them to actual code (such as PyTorch). The authors present an approach to support optimizations such as auto-batching during this compilation process which significantly reduces user burden. The authors presented kokoyi implementations of several popular models such MLP, CNNs, LSTMs and transformers and showed that the kokoyi compiler does not introduce much performance drop. ",0.2028985507246377,0.1917808219178082,0.19718309859154928
2532,SP:e5bd789648c97f1c8836ec1e574f644e04a1c7da,"This paper proposes a method for producing representations for clustering that take into account global trends in the dataset, rather than considering each pair of instances in isolation. They claim to achieve competitive clustering performance on omniglot, which they attribute to the use of these contextualised embeddings. They also present a theoretical justification for using transformers in metric learning","The hypothesis of this paper is that learning a contextual metric (allowing pairwise distances to depend on the data) can improves clustering, and is motivated by two examples (Omniglot, intersecting circles).  The paper proposes a new method - Attention based clustering (ABC) that incorporates context to learn a metric in the form of an embedding and kernel similarity layer (predefined). The embedding layer uses repeated self attention blocks (SABs) from the transformer architecture and is theoretically shown to make the clusters more condensed. An off-the-shelf clustering algorithm (e.g. spectral clustering) is used to cluster the similarity matrix (number of clusters pre-specified or inferred). The experiments show favorable results on the toy dataset and are competitive with methods that use a prespecified clustering.",0.2711864406779661,0.128,0.17391304347826086
2533,SP:e5d135c37cac9b64e242a56ff8e9d9a6db4eba06,The paper considers minimax optimality for some realizable interactive learning settings. A general separation is given between agnostic and realizable learners for the label complexity of active classification. Furthermore efficient algorithms are provided for minimizing the sample complexity of best arm identification and for minimizing the loss incurred while identifying the best arm (which is subsumed by usual regret minimization). Gaps between agnostic and realizable learners in the realizable setting are also shown for these settings. Experiments show that the new algorithms are competitive and can incorporate prior knowledge to obtain gains in sample complexity.,"Consider the problem of best arm identification: there are $n$ arms, each with a reward, and the goal is to select the best arm  with the best reward with as few pulls as possible. The query complexity of this specific problem in the realizable setting (where rewards correspond to an unknown function from a known family) is well understood (up to log factors), but there is no matching efficient algorithm. This paper provides nearly optimal algorithms for classes of functions that are convex (up to a discretization). Algorithms for related interactive learning problems are also considered. Finally, the authors present lower bounds for such problems that show that agnostic algorithms (not assuming realizability) can be much worse. ",0.22105263157894736,0.1794871794871795,0.19811320754716982
2534,SP:e5f3f418dfcf0d45c37cfc237aee269a3b9bfad3,"Saliency problem for black-box classification is the main focus in this paper, which means to find out  the part of the image that is most relevant for the current model decision. Authors propose to find an optimal ablation path between two images to get such saliency maps. The finding in this paper suggest a new view based on ablation path optimization. Several examples are presented to show the behavior of the proposed method for one image classification model.  ","The paper describes the black box approach to saliency prediction using ablation paths gradually replacing the parts of the image of one class with the image of another one. The idea has certain novelty, but the reviewer cannot see that it is backed by the evidence. The following comments are describing the reasons for the current paper rating and must be addressed for the rating to be improved:",0.189873417721519,0.22058823529411764,0.20408163265306123
2535,SP:e617ea828dc7662fa494799aac7136580ca492f0,"The paper proposes an edge-independent graph generative model. Besides the model, the paper also proposes the training process of the model and some theoretical contributions. Unfortunately, the evaluation of the model is based on another problem, clustering. This makes the paper complicate to evaluate. While the main contributions could be important, its evaluation does not guarantee that is able to replicate real networks. Most importantly, given its current results, it must suffer from the degeneracy problem.","This article deals with the task of community detection in the case of mixed membership networks, where a node can have multiple comunity assignments at once. It has been notice that in real-world networks, community overlaps tend to be much denser than the rest of the graph, which is a challenge to usual models (such as the stochastic block model).  The authors introduce a new mixed-membership graph model, where the expected adjacency matrix has the form  $$ \bar A = \sigma( V W V^\top), $$  with $\sigma$ the logistic function. In this model, the matrix $V$ represents the soft community assignments, and $W$ the inter-community similarities. The negative entries of $W$ allow this model to represent the heterophily of the network, wherein vertices are less likely to be connected when they belong to the same community.  They provide a learning algorithm to approximate $V$ and $W$ given the adjacency matrix $A$ of a graph, and show some existence results about such approximations.  In a second part, the authors provide several numerical experiments on real-world datasets, studying both the reconstruction of the matrix $\bar A$ and of the community membership matrix $V$.  They show that, in the chosen datasets, their algorithm outperforms or equals several others in the litterature.  ",0.2597402597402597,0.09523809523809523,0.13937282229965156
2536,SP:e62b3d784092d90177912d72a507837c113535f2,"This paper considers the theoretically interesting and practically important problem of concurrent deep reinforcement learning (DRL), i.e., DRL in which the agent has to decide the next action while performing the previous one. This introduces several significant challenges, including delays/latency and interruption of an on-going action. To address this issue, this paper proposes to consider the continuous time formulation of the concurrent control problem, derive a continuous-time Bellman equation for the concurrent control scenarios, and then derive its discrete-time counterpart. Contraction properties are shown for both the continuous-time and discrete-time concurrent Bellman equations, and a value-based DRL algorithm based on the concurrent Bellman equations is proposed and tested on a few tasks. ","The paper tackles the problem of making decisions for the next action while still engaged in doing the previous actions. Such a delay could either be part of the design (like a robot deciding the next action before its actors and motors have come to full rest after the current action) or an artefact of the delays inherent in the system (i.e. latency induced by calculations or latency of sensors). The paper shows how to model such delays within the Q-learning framework, show that their modelling preserves desirable contraction property of the Bellman update operator, and put their model into practice by an extensive set of experiments: learning policies for several simulated and a real-world setting.",0.19166666666666668,0.19327731092436976,0.19246861924686195
2537,SP:e637b7d5125d8534f65cab0a9df61398f7a334bb,"This paper shows that Transformer Attention approximates Sparse Distributed Memory (SDM) model under given conditions.  It further confirms that those conditions are satisfied on pre-trained GPT2 Transformer models.  In addition to theoretical analysis, some results are provided using various datasets including MNIST.  Furthermore, there is a section on biological interpretation of Attention and SDM.  ","This paper shows that Transformer's Attention closely approximates Sparse Distributed Memory (SDM), a biologically plausible associative memory model, under certain conditions on the data normalization. The authors first provide a review of Kanerva’s SDM. Then, they show that Attention approximates SDM theoretically and empirically via the pretrained GPT2 architecture. Here, the intersection between 2 Hamming circles in SDM is approximated by an exponential function of key and query, which forms the softmax function in Attention.  This close relationship between Attention and SDM leads to a hypothesis that Attention is performing the same associative memory operations as the cerebellum. Moreover, there are discussions on related works including Hopfield Network, Memory-augmented Neural Networks and Kanerva Machine. ",0.4,0.18803418803418803,0.2558139534883721
2538,SP:e65255cf3bf0f0931b173745cc587476f9c2e867,"This paper proposes a new RL algorithm whereby the policy selects a new state rather than action, with constraints to ensure the next state selected is a valid one. The contribution is the new algorithm ""SPP-RL"" which can be applied to off policy algorithms such as TD3/SAC. There is experimental evidence this may be an effective approach in some settings.","The paper describes an approach where a state-state mapping is learned (called state-planning policy or SPP) coupled with an off-policy RL system (the authors included experiments with DDPG, TD3,  and SAC).  Learning a state-state mapping, Q(s,s'), needs also to learn an inverse dynamic model to estimate which action (a) will take the current state (s) to the next state (s').  The authors framed the problem as a constrained optimization approach, where the objective is to maximize the sum of discounted rewards such that the differences between the target states (produced by the policy) and the actual states (produced by the environment with the action from the control model) are within a certain threshold distance. In particular, the authors solved the optimization problem via the Lagrange multiplier method.  Experiments were performed in different domains and with different state-of-the-art DRL systems. ",0.27419354838709675,0.11486486486486487,0.1619047619047619
2539,SP:e653f89bc504607362dfa2ba413b0481674f08df,"The paper proposes a variant of a Hamiltonian neural network for learning dynamics models for model-based RL. The proposed network architecture uses encoders/decoders to map the system state x = [q, p] from the observations s and vice versa. In the latent state, a standard HNN is used to compute dx/dt to increment the time step.   In the experiments, the paper applies this dynamics model to model-based rl and wants to show that this specific dynamics model increases the sample efficiency and leads to greater performance. It is especially noteworthy that the domains include locomotion tasks that include many contacts.","This paper proposes a model of neural ODE auto-encoder, NODA, which incorporates Hamiltonian mechanics to learn a world model. The paper shows theoretical results of transition errors and value errors. NODA is tested on a range of RL tasks. ",0.11650485436893204,0.3,0.16783216783216784
2540,SP:e65bda143869e9a4d75b7e7ee893a2ed7b8e822a,"This paper aims to combine a traditional CBMT system with an NMT system. The core idea of the paper is to use the output of the CBMT system as a second source to a multi-source NMT system. The first source of the system is CBMT, the second source is the original source and the output is the translation in the target language. All the experiments are conducted for English-Amharic with a small amount of parallel data from the Bible. A lot of details are provided about the generation of the CBMT system using Google Translate and details are provided about the approach to create such a system.","This paper presents a machine translation system based on a combination of a neural machine translation system (NMT) and a context-based machine translation (CBMT). The method is evaluated on a small parallel corpus application of English-Amharic translation. The idea is that in the small corpus setting, the CBMT can leverage a manually built bilingual dictionary",0.1651376146788991,0.3157894736842105,0.21686746987951808
2541,SP:e666899b4e1cfe12cb58b2dc76e6ec923c0e5059,"In this paper, the authors study an important problem, i.e., time-aware link prediction in a knowledge base. Specifically, the authors focus on predicting the missing link in a quadruple, i.e., (subject, predicate, ?, timestamp). In particular, the authors design a new tensor (order 4) factorization based method with proper regularization terms shown in Eqs.(4-6).","This paper extends the ComplEx model (Trouillon et al., 2016) for completing temporal knowledge bases by augmenting it with timestamp embeddings. Besides, based on the assumption that these timestamp representations evolve slowly over time, the paper introduces this prior as a regularizer. Also, the paper adds a non-temporal component to the model to deal with static facts in knowledge bases. The proposed model has been evaluated using the current benchmark temporal event datasets, showing state-of-the-art performance.",0.1896551724137931,0.1375,0.15942028985507245
2542,SP:e677ee557b7b802ce2588bfc05b16054913f9662,"The authors developed a novel quantization technique that yields layer-wise different mixed-precision quantization. To do so, they alternatively update the pre-trained weights and the quantizer, which they call cursor. The following two features distinguish this paper: using two precision values around the cursor's value (instead of the closest one) and regularizing the parameter size using a new loss function. Because the whole process is differentiable, the appropriate precision to each layer can be found fast. Thanks to these efforts, this method balances the compression rate and accuracy well on CIFAR-10 and ImageNet.","This paper is about using quantization to compress the DNN models. The main idea is to use NAS to obtain the mixed precision model. More specifically, it adaptively chooses the number of quantization bit for each layer using NAS by minimizing the cross-entropy loss and the total number of bits (or model size) used to compress the model. The experiment is on CIFAR and ImageNet, and compared with other quantization methods showing better accuracy.",0.18556701030927836,0.24,0.20930232558139533
2543,SP:e6b2bd6e602c95d5f0e17ea55e966da9955bd718,"This paper aims to directly optimize the metrics of semantic segmentation tasks, such as mIoU, which is different from the most existing methods which minimize the cross-entropy as a proxy. The metrics typically contain one-hot labels and logical operations. In order to directly optimize them, the authors first relax the one-hot label/prediction by Softmax. Then the logical operations applied on the one-hot label are extended by a continuous parameter function which is Monotonical and has the same output as the logical operation with 0/1 input. Finally, the authors describe a reinforcement learning framework to optimize the metrics parameterization (i.e., the outer objective), while the inner objective (i.e., the segmentation network) is trained by standard SGD. The experiments have been performed on Pascal VOC 2012 and Cityscapes datasets, showing the searched loss outperformed the traditional ones such as cross-entropy.","1.) In comparison with traditional loss function such as Cross-Entropy, WCE, DPCE, and SSIM, the proposed method achieves competitive performance. In addition, the authors also compare with the searched loss functions such as searched mIoU, searched FWIoU, etc. By combining the searched mIoU with the BIoU/BFI surrogate losses, the overall method achieves reasonable global performance, while refines the boundaries. ",0.10884353741496598,0.26229508196721313,0.15384615384615383
2544,SP:e6b4af51625d77c92368e3635d79f14e204c75ab,"This paper stuides the complexity of optimizing highly smooth convex functions. For a positive integer p, one wants to find an $\epsilon$-approximate minimum of a convex function f, given oracle aceess to the function and its first p derivatives, assuming that the p-th derivative of f is Lipschitz. The near-optimal algorithms exist in deterministic setting while it remains a gap between the upper bounds and lower bounds for randomized algorithms. The contribution of this paper is to provide a new lower bound that matches the best existing upper bound (up to log factors), and shows that it holds not only for randomized algorithms, but also quantum algorithms.   To prove the desired lower bound, the paper started with a classical nonsmooth lower bound instance in Eq. (8) and employed a new random smoothing technique. By this construction, the proof strategy for nonsmooth convex optimization can be executed on the smoothed instance considered in this paper, thereby giving us a lower bound for p-th order smooth convex optimization. Using this idea, the authors prove the lower bound for the desired class of optimization problems.","This paper studies the complexity of optimizing convex functions with Lipschitz $p$-th derivative. The authors prove a new lower bound $\tilde{O} (1 / \epsilon^{ \frac{2}{3p+1} } )$ that holds for deterministic, randomized and quantum algorithms. This lower bound matches the upper bound up to log factors.",0.15053763440860216,0.5833333333333334,0.23931623931623933
2545,SP:e6d26523e1b8f59840142193dcdd740ded86e9fa,"The paper argues that a better objective to train neural MCMC kernels is to maximize the proposal entropy (Titsias & Dellaportas, 2019) and demonstrate a method on doing so. The method shows improved sampling efficiency compared to previous method, especially one that optimize the alternative L2 expected jump. The novelty is not of the training objective but a neural instantiation with improved sampling efficiency.","This paper proposes a new MCMC transition kernel. This kernel is parameterized by neural networks and is optimized through an objective maximizing the proposal entropy. Specifically, the authors use a combination of a flow model and non-volume preserving flow in [Dinh et al., 2016] as the neural network parameterized kernel. Then they use the objective in [Titsias & Dellaportas, 2019] which maximizes the proposal entropy to optimize the kernel. The proposed method is tested on synthetic datasets, Bayesian logistic regression and a deep energy-based model.",0.2698412698412698,0.19767441860465115,0.22818791946308725
2546,SP:e6e0533858e89d3cdf4265cb5a89ba6f4f9837bb,"The paper tackles the problem of bias in target Q-values when performing Q-learning.  The paper proposes a technique for computing target Q-values, by first taking the min over an ensemble of learned Q-values and then taking the max over actions.  The paper provides some theoretical properties of this technique: (1) the bias of the estimator can be somewhat controlled by the size of the ensemble; (2) performing Q-learning with these target values is convergent. Experimental results show that the proposed technique can provide performance improvement on a number of tasks.","This paper proposes a new Q learning algorithm framework: maxmin Q-learning, to address the overestimation bias issue of Q learning. The main contributions of this paper are three folds: 1) It provides an inspiring example on overestimation/underestimation of Q learning. 2) Generalize Q learning by a new maxmin Q-learning by maintaining independent Q estimator and interact them in a max-min way for the update. 3) Provide both theoretical and empirical analyses of their algorithm.",0.18947368421052632,0.23076923076923078,0.20809248554913298
2547,SP:e6fdf0645148e28af1a54c7f05e2594b2cf535cd,"In summary, this paper studies if interpretation robustness (i.e., similar examples should have similar interpretation) can help enhance the robustness of the model, especially in terms of adversarial attacks. The study direction itself is interesting and very useful for the interpretation and adversarial attack community. Moreover, some promising results can be observed in part of the empirical study. However, this paper can be improved a lot as follows.","The present work considers adversarial attacks that also yield similar outputs for ""interpretability methods"", which are methods that output some vector corresponding to a given classification (usually the vector is e.g. an image or a similar object). It also shows that by regularizing nearby inputs to have similar interpetations (instead of similar classifications), robustness can be achieved similar to adversarial training. ",0.11594202898550725,0.12903225806451613,0.12213740458015265
2548,SP:e70a869dc8d81a0338d382ea6a761145ed8e59bd,"This paper first provides explanations to the inherent tradeoff between rotation adversarial attack and sensitivity attacks/spatial transform attacks, through their differences in saliency maps. Further, the authors proposed to utilize pareto training to find the best tradeoff among the four dimensions: natural accuracy, robustness against sensitivity/rotation/spatial transformation attacks. Experimental results show the proposed pareto adversarial training achieves better tradeoff between clean accuracy and adversarial robustness averaged across three types of attacks.","This paper first studies the tradeoffs between two forms of spatial robustness, including robustness against Flow-based spatial attack and Rotation-Translation (RT) attack. In particular, it proposes an approach to account for both local and global spatial transformations in an integrated framework. In addition, the paper investigates the relationship between the sensitivity-based (lp-norm based) and spatial robustness, and proposes a training method called ‘Pareto Adversarial Training’ to find optimal combination between natural accuracy, sensitivity-based and spatial robustness.",0.2972972972972973,0.2716049382716049,0.2838709677419355
2549,SP:e70a8e14cf2b179e5d9ea39c2885396828566ca3,"This paper focuses on the problem of word representations in multilingual NMT system. The idea of multilingual NMT is to share data among multiple language pairs. Crucially this requires some way to tie the parameters of words from different languages, and one popular method is to share subword units among languages. The problem is that subword units in different languages may not be semantically equivalent, and many semantically-equivalent concepts are not represented by the same subwords. This paper proposes an alternative way to share word representation, in particular by proposing a common set of ""semantic"" concept vectors across languages which are then folded into the word representations via attention. ","This paper presents an approach to creating word representations that operate at both the sub-word level and generalise across languages. The paper presents soft decoupled encoding as a method to learn word representations from weighted bags of character-n grams, a language specific transformation layer, and a ""latent semantic embedding"" layer. The experiments are conducted over low-resource languages from the multilingual TED corpus. The experiments show consistent improvements compared to existing approaches to training translation models with sub-word representations. The ablation studies in Section 4.4 are informative about the relative importance of different parts of the proposed model.",0.15454545454545454,0.16666666666666666,0.16037735849056606
2550,SP:e73541ff1e010add393fde5023555c06b4b4d443,"This paper proposes a change to the recently popular diffusion models, motivated by increasing the speed of sampling. This is accomplished by changing the “forward” process which adds noise to the data. In the original diffusion models, this forward process is a Markov process whose marginals and conditionals can be computed efficiently in closed form. This paper proposes to replace this Markov forward process with a non-markovian process that is designed to have the same marginals. The generative model, in this case, changes such that to predict the next step in the process, the model must first predict the “clean” sample at the end of the chain which is then used to give an estimate for the next step in the chain. ","This paper develops a variant (DDIM) of an existing method (DDPM) with the goal of accelerating it greatly while still maintaining performance. The authors are working in the context of a denoising process that runs in the reverse direction to a sequence of steps that each add a small amount of Gaussian noise to the original data. The proposal is to introduce an auxiliary function that breaks the Markov assumption by leaking some information in a controlled way about the training points x0, and then use this auxiliary function as scaffolding to train the actual Markov chain of denoising functions.",0.2032520325203252,0.25,0.2242152466367713
2551,SP:e74876791607559e3e6647ea6f45fecbbbe24bad,"This paper presents a strategy for object instance segmentation from images using training data that has no manual annotations. Instead of manual annotations, as is required for many state-of-the-art methods, this paper proposes to use high-level priors represented as rules that can be evaluated in the produced segmentation. These rules define what an acceptable segmentation is, and are used to create a reward signal for a reinforcement learning agent. The framework formulates an environment, an agent, an action space and a reward system in a stateless system to guide segmentation. All the components of the system are well designed and well thought, and this approach may have wide applications in bioimage segmentation problems.","The paper proposes the use of RL for instance segmentation. In particular, the paper uses super pixels together with graph partitioning and RL to learn the labels of instances. The model is validated on two datasets, one synthetic and one biomedical imaging dataset and is numerically compared to two approaches ([28] and [47]).",0.1111111111111111,0.24528301886792453,0.15294117647058825
2552,SP:e7c0d655d20b3a6de09dd2ea2d150b149ed60845,"This paper addresses potential biases introduced by attention models by re-weighing the attention weights. First, the paper provides a few examples that demonstrate attention weights correlated with social stereotype (e.g., doctor attending to he and nurse attending to she). Then, it proposes to reduce this type of bias by ""calibrating"" the attention weights. To do so, each sample is augmented with pairs of words corresponding to the groups for which the model is intended to mitigate bias. The augmented samples are used in training, and, thus, each token in the input will attend to tokens in the augmented portion of the sample. The weights are changed such that the weights attending on the augmented, group-relevant tokens are similar. This type of re-weighing can lead to some of the semantic meaning encoded in the network to change. To prevent this change, the attention weights corresponding to the tokens from the original sample are forced to follow the weights in an unaltered model that is trained in parallel. Last, the paper suggested also utilizing negative sampling: using random words for augmentation and forcing all attention weights to follow the ones of the teacher.  For evaluation, the paper shows the performance of several transformer-based models.  The evaluation of the method includes three different benchmarks: two benchmarks that measure bias intrinsically (Crows-Pairs and StereoSet) and an NLI task designed for measuring bias. To make sure that the semantic strengths of the model are not lost, the models are also evaluated using the GLUE tasks. The model obtains competitive performance for the GLUE tasks, while reducing bias compared to original models and a couple of related works.","This paper proposes a new debiasing method for contextualized word embeddings, specifically for attention-based text encoders. At a very high level, the proposed method tries to calibrate the attention scores of words from different groups, e.g. to reduce gender bias, the method forces the model (text encoder) to allocate same attentions to word ""man"" and ""woman"". Experimentally, the paper also demonstrates relatively good results on both likelihood-based evaluation (StereoSet and Crows-Pairs) and inference-based evaluation (NLI).",0.08992805755395683,0.3125,0.13966480446927373
2553,SP:e7c555dbd995aa8446a7a8ac705aa9bfced8ac9a,"Hyperbolic Neural Networks++ extends the existing work of applying hyperbolic manifolds to neural networks. It proposes new ways to reparametrize hyperbolic multinomial logistic regression (MLR) layers to reduce the number of parameters, to generalise fully connected layers  as well as split and concat operations to be more flexible and less computationally expensive. Further they expand hyperbolic neural networks to convolutional layer and attention mechanisms. The evaluation include direct comparison to HNN, and clustering with Transformers and seq-2-seq modeling.","The paper provides a reformulation of the fundamental operations in Euclidean space that are used in neural networks for the Poincaré ball model of hyperbolic space (and thus hyperbolic space generally). The paper’s reformulation differs from previous reformulations (Ganea et al. 2018) in several ways. For multinomial logistic regression, the excess n-1 degrees of freedom available in previous formulations when defining a Poincaré hyperplane via a point on the hyperplane and a normal vector are eliminated by using a canonical choice of normal vector along with a scalar quantity corresponding to the distance to the hyperplane from the origin. Fully connected (FC) neural network layers are also reformulated in a way that keeps with the interpretation of an affine transformation as returning a point whose individual coordinates are distances to a set of different hyperplanes. On the other hand, the previous reformulation directly used Möbius matrix-vector multiplication, which does not this same interpretation. The paper then gives hyperbolic reformulations of further types of neural network operations in Euclidean space, namely split/concatenation (less computationally intensive than that in previous work), convolution (not present in previous work). Turning its focus to attention models, the paper proves a theorem regarding the equivalence of various hyperbolic midpoints proposed in previous work. Finally, the paper carries out experiments testing each part of its reformulation on appropriate datasets.",0.275,0.09691629955947137,0.14332247557003258
2554,SP:e7caebe84a63ae1f2e8eda175eec514684a7a2ee,"This paper introduces a new method to accelerate training by saliency-based pruning. The method predicts future saliency for neurons based on observed saliency with a multi-output Gaussian process (MOGP), then greedily prunes neurons with least saliency at fixed intervals during training. The authors provide extensive mathematical analysis to show that the algorithm produces pruning mask solutions that are close to the optimum of the formulated optimization (the reviewer is unable to verify). The experimental results showed improvements in task accuracies of trained models but with longer training times. ","This paper introduces a method for pruning during the training process in order to filter out unimportant/redundant components of the network continuously to speed up training and perform gradual pruning over the training process. The proposed approach is novel in the sense that the vast amount of prior work on pruning has focused on either (i) pruning on network initialization (e.g., SNIP, etc.) or (ii) pruning after the network has been fully trained (e.g., Magnitude Pruning, among many others). The introduced method uses the Taylor-series based saliency criterion (of Molchanov et al., 2017) and uses a multi-output Gaussian process to predict future saliencies and to determine whether a parameter can be safely removed early on during training.",0.2222222222222222,0.16393442622950818,0.18867924528301888
2555,SP:e7d072333891bebe16584ee8276b874cb28fffda,"This paper proposes an algorithm for imitation of expert demonstrations, in situations where the imitator is acting under a different environment (different dynamics, for instance) than the one used to collect expert demonstrations. The algorithm builds on GAIL with the following modifications – the discriminator is made dynamics-invariant by adding a domain-adversarial loss, and the policy is made to condition on a dynamics context. A separate dynamics posterior network is trained (either supervised or unsupervised) to predict this context at test-time. ",The submission considers the problem of imitation learning when the dynamics of the expert are not known to the agent and the dynamics of the agent may change frequently. It is however assumed that the agent has access to a parameterized simulator that can simulate the expert dynamics. The parameters for the simulator are not known but are assumed to be drawn from a known distribution.,0.1686746987951807,0.21212121212121213,0.1879194630872483
2556,SP:e7f8866d8056c6e4bf3b4cf2b712a91751116bb4,"The authors proposed a new algorithm to implement a popular neuroscience theory, i.e. predictive coding, in deep neural networks (DNN). The feedforward connection weights are pretrained for object recognition and the feedback connection weights are trained for image reconstruction, and then predictive coding introduces recurrent computations with the trained DNNs. The authors use two image recognition DNNs (VGG16 and EfficientNetB0) in experiments. They found that the recurrent computation brings improvement in object recognition and image/feature reconstruction over time given noisy inputs. This property of predictive coding improves DNN robustness to noisy examples and adversarial attacks. The authors also provide a python package to allow community to explore the predictive coding algorithm.",The authors draw inspiration from neuroscience and propose augmenting feedforward neural networks with recurrent dynamics to improve their adversarial and corruption robustness. They provide a PyTorch package that can augment any convolutional neural network with recurrence. Their empirical tests show that recurrence mostly helps with robustness.,0.10619469026548672,0.2608695652173913,0.1509433962264151
2557,SP:e8329108f4d0fb74d9347dcb06c7fe6aff604ba9,"Recent works toward the understanding of word embeddings can explain how semantic word relationships, such as similarity, analogy and paraphrasing are encoded as low-rank projections of high dimensional vectors of co-occurrence statistics (Allen et al., 2019). Thus, the semantic relationships correspond to linear relationships of word embeddings. This paper builds on this understanding of (PMI-based) word embeddings aiming at the task of understanding the latent structure of low-rank knowledge graph representations. The authors draw a parallel between the embeddings of knowledge graphs and words under the premise that fundamentally the same structure of relations is captured in different ways. Strong evidence to this premise is provided by starting at encoded semantic relations of word embeddings generalizing them to three types (R,S,C) of knowledge graph relations. The authors analyse the performance of different state-of-the-art knowledge graph models and identify the best performing model per relation type. While a multiplicative model performs best for R-relations (highly related), an additive-multiplicative model should be used for S- (specialisation) or C-type (context-shift) relations. These results correspond to the predictions made beforehand and the theoretically derived loss functions based on the respective conditions of each relation type.","Based on PMI word embedding, the authors categorize the knowledge graph relations into three types, which serve as the foundation of knowledge analysis. This paper is not well-motived but presents the methodology, well. However, nothing in this paper surprised me, because this seems like a ````''regular'' research in this field.",0.07352941176470588,0.29411764705882354,0.11764705882352941
2558,SP:e8386ff9f69f7ffae3bf7fe122d61ef7b81fd425,"This paper addresses the well-known long-tail classification problem. The argument made here is that most of the existing methods attempt to transfer knowledge in the feature space, which is true. Based on this motivation, the paper proposes a method to do the knowledge transfer in the model space instead. The idea is to apply K-NN method in the model space to pick up a group of strong classifiers trained on the head classes with sufficient training samples available that are closest to a weak classifier in the model space and then a linear combination of the group of strong classifiers and the weak classifier to form a stronger classifier to the tail classes where only few samples are available for training; the linear combination weights are learned from a simple neural network, called Alpha Net. Two datasets artificially truncated from ImageNet and Places, respectively, that were also used in the peer work in the literature, were used to report the evaluations.",This paper focuses on how to transfer knowledge between classes. The authors proposed to transfer classifiers instead of features. The proposed to linearly combine the classifiers from rich classes to construct more robust classifiers or rare classes. The combination weights are predicted from a learned neural network for each rare class. The experimental results on two benchmark datasets outperform some existing methods. ,0.16463414634146342,0.43548387096774194,0.23893805309734514
2559,SP:e83f03fdb969034842d3046f69fc72df07750e54,"This work provides theoretical insights on recent learning rate proposals such as Cyclical Learning Rates (Smith et al.). The authors focus on stochastic approximation i.e. how large is the SGD loss as a function of condition number and horizon. The critical contribution is the theoretical benefit of oscillating learning rates over more traditional learning rate schemes. Authors provide novel upper/lower bounds to establish benefit of oscillating LR, support their theory with experiments and provide insights on finite horizon learning rate selection. An important drawback is that results only apply to linear regression which is a fairly simple setup.","The paper studies the effect of learning-rate choices for stochastic optimization, focusing on least-mean-squares with decaying stepsizes. The main result is showing that exponentially decaying stepsizes can yield improved rates of convergence of the final iterate in terms of dependence on the condition number. The proposed learning rate schedule depends on the condition number and the number of iterations. This positive result is complemented by showing that without prior knowledge of the time horizon, any stepsize sequence will frequently yield suboptimal solutions.",0.14,0.16470588235294117,0.1513513513513514
2560,SP:e84523133b0c393a7d673a3faef8cd2d6368830a,This paper presents a method of learning of energy based models using denoising score matching. This technique has been used before but only with limited success. The authors hypothesize that this is due to the fact that the matching was only performed over a single noise scale. The main idea of this work is to employ a range of scales to learn a single energy function. This trick helps to alleviate the problem of noisy samples concentrating in a low-volume region of the ambient space.,The paper proposes to learn an energy based generative model using an ‘annealed’ denoising score matching objective. The main contribution of the paper is to show that denoising score matching can be trained on a range of noise scales concurrently using a small modification to the loss. Compared to approximate likelihood learning of Energy based models the key benefit is to sidestep the need for sampling from the model distribution which has proven to be very challenging in practice. Using a slightly modified Langevin Sampler the paper further demonstrated encouraging sample qualities on CIFAR10 as measured by FID and IS scores. ,0.26744186046511625,0.22772277227722773,0.2459893048128342
2561,SP:e85499f1a98415c4392e71b1b5702cd89a35bd12,"This paper identifies how adversarial training (AT) algorithms for robustness may negatively affect the notion of robust fairness and proposes two methods ME-AT and ME-TRADES, which combine existing AT methods with a maximum entropy (ME) term, to improve the accuracy-robustness tradeoff and robustness fairness. Although AT algorithms improve model robustness, they also increase inter-class similarities, which make certain classes more difficult to classify, leading to unfair accuracies. The paper then shows that label smoothing (LS) mitigates this effect and in particular investigates the ME technique. The authors show that a method called TRADES outperforms another method called PGD-AT because it is a special version of ME. Experiments show that combining ME with these AT methods outperforms PGD-AT.","This paper investigates inter-class similarity and intra-class variance, and corroborates that AT will cause an increase in inter-class similarity, which could be the root of both the robustness-accuracy tradeoff and robust fairness phenomena. The authors first considers Label Smoothing (LS) as the regularizer, and concludes that LS will cause a loss of information in the logits, and hence weaken the discriminative power of the trained models. The authors then confirms that ME can help reduce the excessive inter-class similarity in robust models, and also provides a lower intra-class variance, which is the remedy of previous AT methods. Experiments partially support the conclusions of the paper.",0.2032520325203252,0.22522522522522523,0.21367521367521367
2562,SP:e86910b99dbc07691e2882c85c87d150de40a0ff,"This paper focuses on learning a representation that facilitates efficient content-based retrieval. Although the representations that are learned from deep neural networks can contain rich information, it is computationally expensive to use those representations to perform a search for the best match. In particular, computing the Euclidean distance between a query and an instance scales linearly with the size of the representation. Prior approaches to this problem have focused either on: (1) compactifying the learned representations into another form, such as a Hamming code, in a way that preserves the identifiability of an instance; (2) resorting to approximate methods that sacrifice accurate search for efficiency.","This paper proposes to learn sparse representation in neural networks for retrieval in large database of vectors. Such sparse representation, when the fraction of non-zeros is high, can be computed using sparse matrix multiplication, or variants of inverted index scoring and lead to potentially lower FLOPs needed. This paper proposes to induce sparsity by adding a regularization term, which counts the expected number of FLOPs needed for sparse scoring.",0.14150943396226415,0.21428571428571427,0.17045454545454544
2563,SP:e898ffa6bfdc1597ced0f9bd66c60ff9c6b4c383,"This paper investigates conditions under which communities of cooperative agents are stable. Communities in multi-round bargaining games with evolutionary dynamics are evaluated in three main setups. The first imposes no restrictions on the agents' behavior and is shown to be easily invaded by deceitful agents. The second enables agents to refuse to bargain with deceitful agents. Nevertheless, such communities are shown to be invadable. Finally, in the third setup, a global punishment system is shown to be able to drive out deceitful invaders. The main take-home message is that, when lying is an option, agents(' communities) need to be prepared for it.  ","This paper attempts to address a question in the emergent communication literature: what preserves / maintains the stability of emerged communication protocols.  The authors manipulate the prevalence of lying behavior in a community of agents playing a variant of a Nash bargaining game.  The main take-away is that explicit punishment, from the environment and from truth-tellers not wanting to communicate with liars, can prevent the spread of exploitative lying behavior in the community.",0.1346153846153846,0.1891891891891892,0.15730337078651685
2564,SP:e8a08f3ad14ae96021ec69070a156d57811c88be,"This paper introduces Monotonic Robust Policy Optimization (MRPO), an RL algorithm that aims to jointly optimize policy and domain sampling distribution, with the goal of improving policy performance for both average and worst-case scenarios and addressing the model discrepancy between the training and target environments. They derive a lower bound for the worst-case performance, which comprises the average performance, policy change, and the statistical distance between the worst and average case environments. A TRPO-like monotonic performance improvement guarantee is provided for the worst-case expected return. Finally, a practical approximation to MRPO is proposed, which imposes the assumption on Lipschitz continuity with respect to the environment parameters and circumvents the estimation of total variation distance between the worst-case environment and the sampled environment. Experiments are conducted on three control tasks with diverse transition dynamics parameters, where MRPO could improve both average and worst-case performance in the training environments, and it shows better generalization to the unseen test environments than baseline algorithms.","This paper focuses on the generalization issue in reinforcemetn leanring, specifically aims to address the problems of domain randomization(DR) technique. Different from standard DR which treats all the sample environment as equal, this paper proposed to improve the performance over all possible environments and the worst-case environment concurrently. This paper theoretically derives a lower bound for the worst-case performance of a given policy over all environment, and in practical, the proposed method, monotonic robust policy optimization(MRPO) carries out a two-step optimization to imporve the lower bound such as to maximize the averaged and worst-case policy perfomance. ",0.18072289156626506,0.29411764705882354,0.2238805970149254
2565,SP:e8af90f522657cb1cc069da98c22ae60d04b8879,"This paper proposes a two-stage GNN-based architecture to establish correspondences between two graphs. The first step is to learn node embeddings using a GNN to obtain soft node correspondences between two graphs. The second step is to iteratively refine them using the constraints of matching consensus in local neighborhoods between graphs. The overall refining process resembles the classic graph matching algorithm of graduated assignment (Gold & Rangarajan, 1996), but generalizes it using deep neural representation. Experiments show that the proposed algorithm performs well on real-world tasks of image matching and knowledge graph entity alignment.","The authors proposed a message passing neural network-based graph matching methods. The overall framework can be viewed as a graph siamese network, where two set of points are passing through the same graph neural network, and then two new embeddings are generated. Using the two embedding the similarity between points can be computed and then the final matching can be generated. ",0.11458333333333333,0.1774193548387097,0.13924050632911392
2566,SP:e8c5589f22688422495fbc1dd7418139443102b9,"This work proposes a new auto-regressive density estimator built using self-attention module from the popular Transformer network. TraDE can be seen as an extension of decoder-only Transformer network where an input embeddings are given by a simple RNN-based encoder. Like Transformer, TraDE leverages multiple layers of self-attention module to implicitly model long-range dependencies. This effectively eliminates the need for explicit vertex ordering and hence useful on data with no known canonical ordering. The proposed model is general and can be applied to both continuous as well as discrete data. Along with the MLE objective, TraDE is additionally regularised using MMD penalty which can be easily back-propagated using reparametrization / Gumbel softmax trick.","This paper proposes TraDE, a transformer-based density estimator that is capable of learning a density of real-valued tabular data. Compared to previously proposed transformers, there are three main differences in TraDE model: 1) the output is modeled as a mixture of Gaussians, 2) maximum mean discrepancy (MMD) is added to the loss, and 3) Gated Recurrent Unit (GRU) is used to provide positional encoding. Tested on a suite of benchmark tasks, the proposed method shows promising results over baselines.",0.1271186440677966,0.18518518518518517,0.15075376884422112
2567,SP:e8f3260b1545636a55ee5cbb1ec7df46e115b1c1,"The paper proposes a method to build equivariant neural networks by defining the layers in terms of the generators of the Lie group to which the NN is to be equivariant to. At the core lies the idea that any function (or conv kernel) with local support can be expanded in the Lie algebra basis via a Taylor approximation-like approach. Then, by observing that any function can be approximated with a basis of (shifted) local functions, it can be concluded that the presented approach in theory can approximate any group convolution. In addition, the authors the investigate the option to let go of the user-imposed constraint of being equivariant to a specific group, and instead let the neural network learn the generators (of the unknown group) in addition to the learnable weights that parametrize the layers. This is an open problem and the authors make promising steps in this direction.  Finally, the authors draw connections to physics, but I must admit, this part was too much for me and I did not get it, but possibly could have by investing more time in the paper. ","They propose a model for approximating invariant functions for Lie groups, the Lie algebra convolutional network (L-conv). While convolutional networks for ordinary groups require some kind of discretization, their model does not require it. Also, Lie algebra generators in our L-conv can be learned to automatically discover symmetries.",0.053475935828877004,0.2,0.08438818565400845
2568,SP:e958fbb0b004f454b79944ca72958254087147d4,"This paper proposes stable GradientLess Descent (GLD) algorithms that do not rely on gradient estimate. Based on the low-rank assumption on P_A, the iteration complexity is poly-logarithmically dependent on dimensionality. The theoretical analysis of the main results is based on a geometric perspective, which is interesting. The experimental results on synthetic and MuJoCo datasets validate the effectiveness of the proposed algorithms.","The paper proposes a novel zeroth-order algorithm for high-dimensional optimization. In particular, the algorithm as an instance of direct search algorithms where no attempt is made to estimate the gradient of the function during the optimization process. The authors study the optimization of monotone transformations of strongly-convex and smooth functions and they prove complexity bounds as a function of the condition number, the dimensionality and the desired accuracy. These results are also extended to the case where the function actually depends on a lower-dimensional input. Without any knowledge of the actual subspace of interest, the algorithm is able to adapt to the (lower) dimensionality of the problem. The proposed algorithms are tested on synthetic optimization problems and in a few Mujoco environments for policy optimization.",0.28125,0.13953488372093023,0.18652849740932642
2569,SP:e95b1fa1f8d1b66ef0fdfb6c7aa56983f83e2277,"This paper presents a mainly theoretical argument comparing the expressivity of model-free and model-based RL methods contrary to analysis in the past which usually relies on sample complexity. They construct a family of MDPs, where the true dynamics belong to a simple function class (in terms of the number of linear pieces needed to define the function), but the corresponding optimal Q-function belongs to a function class not necessarily expressible by a simple function. The paper then builds a similar case for randomly/semi-randomly generated MDPs. Finally, they propose to bootstrap the Q-function with n-step returns to boost the expressivity exponentially. ","The paper highlights an interesting issue regarding approximability of function approximators (neural networks). The paper provides cases where the action value function is difficult to approximate and is much more difficult than the dynamics of a model. The author conducts some experiments to claim that even with a large NN, DQN still finds a suboptimal policy. Theorems regarding the appoximability of the action value function are presented. Then the paper proposes that rollout-based search should be preferred for planning and conducts some experiments to verify this. Although the paper points out interesting issues of approximating action-value function, both the motivation and the suggestion regarding MBRL are not convincing.",0.18691588785046728,0.18181818181818182,0.18433179723502305
2570,SP:e963ad4e47263da9f64c76505e1853cbf8b012c4,"This paper studies the theoretical property of neural network's loss surface. The main contribution is to prove that the loss surface of every neural network (with arbitrary depth) with piecewise linear activations has infinite spurious local minima. Moreover, the paper further characterizes the partition of the local minima. More precisely, the loss surface is partitioned into multiple smooth and multilinear open cells and within each cell, the local minima are equally good. This result can also explain the linear neural network case where there is only one cell, implying that all local minima are global. ","This paper studies the landscape of deep neural networks with piecewise-linear activation functions. The paper showed that under very mild assumptions, the loss surface admits infinite spurious local minima. Further, it is shown that the loss surface is partitioned into many multilinear cells. If the network is two-layer with two-piece linear activations, it is proved that within each cell every local minimum is global. ",0.3125,0.44776119402985076,0.3680981595092025
2571,SP:e96daa10364c5538524ef78b83d5881c75aa9712,The paper proposes to use the technique in VAT to generate adversarial complementary examples in the (K+1)-class semi-supervised learning framework described by the Bad GAN paper. This leads to a formulation that combines the VAT loss and the (K+1)-class classification loss. The paper also provides analysis regarding why VAT is useful for semi-supervised learning.,The authors propose to combine BadGAN framework and VAT to accelerate learning in the semi-supervised setting. The paper shows that the VAT approach is actively pushing the decision boundary away from the high-density regions. While the BadGAN approach pulls the decision boundary to low-density regions. This simultaneous push and pull lead to after convergence in testing accuracy. The authors also report competitive results on standard datasets used for SSL such as SVHN and CIFAR10.,0.2833333333333333,0.22077922077922077,0.24817518248175185
2572,SP:e99ba3bc2e7d00a6d419b179cb76b5290b878f24,"The paper proposes a method to predict the future trajectory of a ball (or a set of balls) given the first few frames of the trajectory and a set of experience runs in the same environment. The model first learns to convert the set of images to a set of corresponding heatmaps that encode the location of the ball. Then, a recurrent network generates the future states given the first few locations and the output of a network that learns abstract information from the experience runs. The network is trained using reconstruction and perceptual similarity loss.","The paper proposes an architecture for few-shot video prediction in which a number of videos are summarized through global pooling operations and passed into a video predictor that learns to leverage them for adaptation, similar in spirit to the RNN-based meta-learning approaches such as Santoro’16, Duan’16. Due to global image and feature pooling operations, the proposed approach is computationally efficient. Proof-of-concept experiments are presented in a simple simulated physical prediction setting. It is claimed that the proposed model achieves generalization to longer sequences and larger board sizes, as well as a larger number of objects.",0.1875,0.17647058823529413,0.1818181818181818
2573,SP:e99bcd9b28e45fa14864042ee45998307eb13831,"This work proposes adversarial attacks on few-shot learning systems. Evasion attacks are developed which can be viewed a simple applications of PGD/FGSM. The authors then apply evasion attacks to a support dataset, such that the n-shot classifier's loss is maximised on a query set. Additionally, poisoning attacks that cause the classifier to learn a shifted label set are introduced. Experiments on miniImageNet are performed with two meta-learning algorithms (MAML and ProtoNets) showing that these attacks lead to a large decrease in accuracy in comparison to baselines such as random noise attacks or universal adversarial perturbations (UAP) [1]. The authors then perform additional experiments such as measuring drops in accuracy for different numbers of n in n-shot learning and different query set sizes. ","This paper introduces Adversarial Support Set Attack, an attack that perturbs the support set samples under the few-shot paradigm. It makes use of a seed query set to find adversarial samples that maximize the loss on this set, with the hope that it will generalize to any query sample. Empirical results show that this attack is effective against a variety of few-shot algorithms and datasets. Additionally, adversarial samples constructed on traditional few-shot algorithms are empirically shown to transfer to the fine-tuning few-shot algorithm (when using similar feature extractors).",0.15625,0.21505376344086022,0.18099547511312214
2574,SP:e9a1a59099fde52ef71566b2d9bab33b7a4c2178,"Overview:  This paper shows that the forward pass of a fully-connected layer (generalized to convolutions) followed by a nonlinearity in a neural network is equivalent to an iteration of a prox algorithm, where different regularizers in the objective of the related prox problem correspond to different nonlinearities such as ReLu. This connection is quite interesting. They further relate different stochastic prox algorithms to different dropout  layers and show results of improved performance on CIFAR-10 and CIFAR-100 on several architectures. The paper is well-written.",This paper theoretically verifies an equivalence between stochastic solvers on a particular class of convex optimization problems and a forward pass through a dropout layer followed by a linear layer and a non-linear activation. Experiments show that replacing a block of layers with multiple iterations of the corresponding solver improves classification accuracy. My detailed comments are as follows. ,0.1724137931034483,0.2542372881355932,0.20547945205479454
2575,SP:e9ac6b48ea0d07d528dea9a78266a2474789e139,"This paper explores matrix exponentiation as an alternative non-linearity in a neural network. The key idea is to compute an affine transform of the inputs, there by generating an nxn feature map, followed by applying a matrix exponential to this feature map, that is subsequently used for classification. The paper provides several scenarios where matrix exponential could be an interesting non-linearity to use. Experiments are provided on synthetic examples, and standard image recognition benchmarks in a limited setting and show some promise. ","This work proposes a novel machine learning architecture (or M-layer) that is in the form matrix exponential. This architecture can effectively model the interaction of feature components and learn multivariate polynomial functions and periodic functions. The architecture of the M-layer is well described. Its universal approximation capability is explained and proved in the Appendix. Other properties related to periodicity, connection to Lie groups, the interpretation from the perspective of dynamical systems, and the robustness bounds are discussed. Experimental study is conducted on toy datasets and three image classification datasets to demonstrate the properties of the proposed M-layer. ",0.17857142857142858,0.15,0.16304347826086957
2576,SP:e9b0313cd3e1e1dcd143cef09f572f418c7a0c27,"Neural network quantization is can enable many practical applications for deep learning, therefore it is an important research problem. The paper claims two contributions: 1. Injecting noise during training to make it more robust to quantization errors. 2. Clamping the parameter values in a layer as well as the activation output, where the clamping interval is some multiple of the standard deviation about the mean, and the clamping interval is updated using the Straight through estimator. The main strength of the paper lies in the empirical results where the combination of techniques employed by the authors outperforms the SOTA methods in a compute of scenarios.","The article presents a method for quantization of deep neural networks for classification and regression, using three key parts: (i) noise injection to model the effect of quantization during forward inference, (ii) clamping with learned maximum activations to reduce the quantization bin size, and (iii) gradual quantization of blocks of the network, while previously quantized blocks remain unchanged. The method is evaluated on ImageNet, CIFAR-10, and a regression task, showing performance on-par or better than state-of-the-art methods for particular quantization bit size. Finally, the method is used for porting network onto a FPGA.",0.14285714285714285,0.15306122448979592,0.14778325123152708
2577,SP:e9b9000c519a95f3161513184b751ab3e3f651fa,"The submission aims to provide rigorous theoretical results for the Wasserstein Autoencoder (WAE) - A model that has achieved great empirical success yet remains severely understudied. In particular, their main contribution in showing learning theoretic bounds such as complexity and convergence guarantees. As a feature of the Autoencoder set-up, they introduce the notion of statistical regeneration and go out to prove this statement for their learning setting.","This paper analyzes the statistical properties of WAE, providing theoretical guarantees for both sample reconstruction and latent distribution tasks. To do so, the authors use the family of so-called f-Wasserstein autoencoders due to the specific choice of discrepancy selected for measuring the target and latent distribution. Here total variation distance is chosen. After setting up necessary preliminaries, and assumptions the authors prove the first of two main theorems, consistency in estimating the latent space distribution. Under suitable conditions, the second theorem provides a guarantee regarding the regeneration. Since they analysis was conducted using TV, which upper bounds the Jenson-Shannon divergence, the final corollary transfers the regeneration guarantees to WAEs. Fairly gentle assumptions and interesting theoretical results are discussed in detail. ",0.19402985074626866,0.10569105691056911,0.1368421052631579
2578,SP:e9dcb99e720c5ddd920ccbeda176536132323a3d,"This paper studies reinforcement learning algorithms in a specific subset of multi-agent environments that are 'dominance solvable'. This means that, given an initial set of strategies in the game, if we iteratively remove 'dominated strategies' (those whose utility is strictly less than another strategy independent of the strategies used by other agents), then only one strategy remains for each player. The remaining strategy is called the iterated dominance solution. The paper proves the convergence of certain RL algorithms (REINFORCE in the 2-action case, and importance weighted monte-carlo policy iteration in the multi-action case) for normal-form games. The paper demonstrates the utility of this via mechanism design: in a principal-agent problem where one can design the rewarding scheme given by a 'principal agent' to various (RL) sub-agents, rewarding schemes motivated by iterated dominance guarantees the best solution for the principal agent, whereas schemes motivated by Nash equilibria do not. ","This paper studies independent multi-agent reinforcement learning (MARL) in dominance solvable games. The main contribution of this paper is that the authors have proved the convergence to the iterated dominance solution for two RL algorithms: REINFORCE (Section 3.1, binary action case only) and Importance Weighted Monte-Carlo Policy Improvement (IW-MCPI, Section 3.2). Empirical analysis for principal-agent games is demonstrated in Section 4.",0.1935483870967742,0.44776119402985076,0.2702702702702703
2579,SP:ea04662e871c7eef151c4c7b61464453f391ed9f,"This paper proposes to use matrix decomposition to construct low-rank representations to find the long-distance correlations in context, which is demonstrated more effective than popular self-attention mechanism. Combining linear transformation and matrix decomposition (core part), authors design Hamburger block to model global dependencies from input as residual output. The authors propose differentiable modified Vector Quantization and Non-negative Matrix Factorization to perform matrix decomposition. They propose one-step gradient, an approximation of Back-Propagation Through Time (BPTT) algorithm, to back-propagate gradient of matrix decomposition. They conduct experiments on semantic segmentation and image generation to demonstrate the superiority of their methods regarding modelling global dependencies and computational cost.","The paper presents a method based on matrix decomposition (MD) for encoding global context in computer vision tasks. In particular, a ""Hamburger"" block is proposed encompassing matrix decomposition as its central part, between two linear projection layers. Direct comparison and relations are drawn between the proposed method and the widely adopted self-attention paradigm. The proposed method leads to improved results when Hamburger blocks are used instead of self-attention blocks, leading at the same time to reduced number of parameters, memory footprint and inference time.",0.14414414414414414,0.18604651162790697,0.16243654822335027
2580,SP:ea31c76a7f4c38f29544f50159cca36fa17d15f3,"In this paper, the authors apply an interesting twist on 1-ply search to the problem of playing no-press Diplomacy. Diplomacy is an especially interesting application, because it is neither zero-sum nor two-player, in contrast to many recent AI success stories.  Before each action, they compute an equilibrium of the next step of the game, assuming that each player will thereafter play according to a ""blueprint"" strategy learned via imitation learning.  The equilibrium is computed using regret matching.  The resulting agent has very strong performance against both the previous state of the art bots, and against expert human players.","This paper proposes a combination of imitation learning and search applied to the multiplayer, simultaneous-move game of no-press Diplomacy. While both techniques have been used before, even in concert, there are some domain-specific challenges: more than two players, simultaneous moves, and a very large branching factor per player. The authors use imitation of human play for value estimates and selection of candidate actions, and External Regret Matching to generate a one-step policy. Experimental validation showed the agent to have strong human-level performance, and was hard to exploit using other machine-learning techniques.",0.20588235294117646,0.21649484536082475,0.21105527638190955
2581,SP:ea3b33a6e4cb41f8a77e08f7e72bcf9ea56bec71,"The paper discusses that it is common in Computer Vision debugging and explainability techniques to remove image regions to attribute different regions of the image to the decision of a classification model. Although such removal (of words) can be beneficial for Natural Language model debugging, it adds an additional bias in Computer Vision. This is because removing regions implies replacing the corresponding pixels with some baseline values e.g., black color, random intensities, average pixel values etc. The paper shows that irrespective of which part of the region is being masked (i.e., removing original image pixel values and replacing with baseline values), masking small portions of image can lead to CNNs predicting incorrectly and unreliably. The authors show that the CNN based classifiers seem to rely on the “masking pattern” to make the prediction, rather than the remaining (unmasked) portions of the image. In fact, even after removing some image regions randomly, the output distribution gets highly skewed towards a few classes e.g., crossword, jigsaw puzzle etc. Using LIME as a case study, it shows that missingness bias can lead to inconsistent and indistinguishable explanations. Moreover, this bias can be overcome if the model is trained with suitable augmentations that remove regions while training. The paper illustrates how using Visual Image Transformers is a better natural choice as these models allow actual removal of image regions rather than replacement with baseline values. Hence, these issues seen in CNNs due to missingness bias is not prevalent in ViTs.","The authors focus on the problem of model debugging (for image recognition). They identify that the proposed tools (that rely on CNNs and ResNets) might suffer from the ‘missingness’ issue, i.e., the absence of features due to masking objects of interest. The authors exhibit how the method of masking pixels/patches can lead to the missingness bias and this can happen even if the masked values are replaced with some other 'dummy' values. To mitigate that, they propose to use a recent transformer since it does not use convolutions, but linearized patches as inputs. Then, they demonstrate that the proposed method can simply 'skip' those patches that are masked and it does not result in a skewed result.  ",0.12449799196787148,0.2605042016806723,0.16847826086956522
2582,SP:ea4d4d3798119498a6df81a19dcab2ae4978996c,A method for computing sample learning weights based on variance is proposed. The method is model independent and a simple k-NN based estimator for the weights is derived. The authors justify their work by appealing to a novel generalisation bound. Overall the idea is interesting but the exposition needs to be significantly improved as proofs are difficult to follow as it currently stands.,"The authors introduce an algorithm called VBSW to re-weight a training data set in order to improve generalization. In summary, VBSW sets the weight of each example to be the sample variance of the labels of its k nearest neighbors. The nearest neighbors are chosen in the embedding space from the second-to-last layer of a pre-trained neural network. The last layer of the pre-trained model is then trained with these new weights.",0.171875,0.14285714285714285,0.15602836879432624
2583,SP:ea57214b79bbaaa7538597610944256e6ac1fbe4,"The paper studies the information-theoretic lower bounds in the minimax setting of meta-learning. The paper also discusses upper and lower bounds in the hierarchical Bayesian framework of meta linear regression. The novelty of the paper is two-fold: a) it proves a novel meta-learning local packing result to compute the conditional information between training task samples and the novel task data distribution and b) it compares the lower bound of the risk to the risk of posterior estimate in meta linear regression. In addition, the authors verify the dependence of risk on various parameters in 2 different experiments.","This paper provides a minimax novel-task risk lower bound for meta learning via information-theoretical techniques, showing the fundamental limits of meta learning. The novel-task minimax risk depends on the number of samples from the meta-training set and novel task, as well as the task similarity. The authors further investigate the meta learning problem on a hierarchical Bayesian model, discuss the lower bound and upper bound with maximum-a-posterior estimator.",0.19801980198019803,0.2702702702702703,0.2285714285714286
2584,SP:ea63d76d9c20125dba72138cd644536bea909177,"The paper aims to bridge the gap between model interpretation using probing and model's use of spurious features. They show that the findings of MDL with respect to a feature correlate with the extractability of the feature, given the evidence of representing the feature is available in the training data. The results are presented using both synthetic and natural language data.","This paper studies the relationship between extractability of features from pre-trained representations and how much a fine-tuned model uses that feature. The extractability of features is measured by the minimum description length of a probing classifier trained to detect the feature from the pre-trained representations (using the online code version of Voita and Titov). The degree to which a fine-tuned model uses the feature is measured by the amount of evidence required for a model to tease apart spurious from non-spurious features (called ""target"" features). Evidence here means examples where a spurious feature occurs but a non-spurious feature does not occur. When there are many such examples (high spurious-only rate), it is easier for a model to reject the spurious feature and learn to rely on the target feature. The ""degree to which a fine-tuned model uses a feature"" is defined as the minimal spurious-only rate at which the model can accomplish the task. ",0.3548387096774194,0.13496932515337423,0.19555555555555557
2585,SP:ea79f8424daf79a41fbbcfbb35f483b7dd66613c,Summary: This paper sets and explores relations between learning and labeling. The article develops a new method requesting labeling combining abstention and active learning. The authors develop a new method and detail their corresponding algorithm DPL-IWAL. They also provide asymptotic statistical guarantees concerning their approach to show the efficacy of their approach (lower and upper bounds).,"The authors propose a new learning problem that combines aspects of active learning and learning with abstention. They formalize the setting, provide an algorithm. They also prove an upper bound on the algorithm’s label complexity and a matching lower bound for any algorithm in this setting. Experiments are presented, too.",0.19298245614035087,0.21568627450980393,0.20370370370370372
2586,SP:ea7daa9dbbcba08e7c094630ef2bb55badc4fde5,"This paper proposes to replace batch normalization statistics, which are typically computed as the batch moments during training or a fixed training average during testing, with the outputs of learned neural networks. These networks are trained to minimize the KL divergence between their output and the expected or desired batch statistics. In this way, the statistics computation is amortized and can hopefully generalize in the face of small batches and distribution shift.","This paper describes a new method for normalizing few-shot learning episodes. The authors point out that the statistics of an episode are unreliable when the size of the episode is small or when the data distribution changes from episode to episode. To remedy this, the authors propose a method called ‘MetaNorm’ which uses a meta-learning approach to infer the means and variances to be used in the batch normalization layers that are employed in the feature extractor component. In particular, they meta-learn the parameters for a set of hypernetworks in an amortized fashion that learn to generate the means and variances of the batch normalization layers conditioned on the contents of the episode. The paper focuses entirely on the few-shot image classification scenario where MetaNorm is evaluated in various settings including standard few-shot classification and domain generalization (including a novel few-shot domain generalization setting).",0.2638888888888889,0.12666666666666668,0.1711711711711712
2587,SP:ea8267af45b09cc35349456d85eb39c58447e319,"The work is motivated by the goal of having a comprehensive exploration of an agent in deep RL. For achieving that, the authors propose a count-based NGU agent, combining intrinsic and extrinsic bonuses as new rewards. An extrinsic/ long-term novelty module is used to control the amount of exploration across episodes, a life-long curiosity factor as its output. In the intrinsic/episodic novelty module, an embedding net and a KNN on episodic memory are applied to compute the current episodic reward. In the experiment, a universal value function approximator (UVFA) framework is used to simultaneously approximate the optimal value function with a set of rewards. The proposed method is tested on several hard exploration games. Other recent count-based models are compared in the paper.","The paper proposes a novel intrinsic reward/curiosity metric that combines both episodic and “life-long” novelty. Essentially two competing pressures that push agents to explore as many novel states in a single rollout as possible and to explore as many states as possible as evenly as possible. The primary contribution here is the episodic novelty measure, which relies on a state embedding that takes into account stochasticity in the environment. The paper covers this episodic curiosity measure and how it’s integrated with the life-long curiosity metric. It then demonstrates the impact of these metrics and variations compared to baselines on particular games and all 57 Arcade Learning Environment games.",0.15625,0.17857142857142858,0.16666666666666666
2588,SP:ea94a4cd46cec1cbf732d4e4f3ef94482f782fea,"This paper proposes a method, called abstraction refining, for extending MCTS to stochastic environments that leverages the geometry of the state space. Compared to progressive widening with global hyperparameters for every state, abstraction refining groups the states together dynamically depending on each state. Their results show abstraction refining outperforms progressive widening in the way of their experiments of this paper.","The paper proposes a novel extension of MCTS to tackle stochastic state transitions with infinite support. It does so by leveraging the geometry of the state space to ""abstract"" ""similar"" states together during the tree building phase. Abstraction refining is introduced to assure that in the limit of infinite samples, the search-tree converges to the full tree, by introducing a schedule on the maximum abstraction distance, based on the number of samples observed. The authors provide a proof of asymptotic convergence of abstraction refining in the policy evaluation setting. A brief discussion is done on the choice of distance function to employ during the state abstraction. Finally, an experimental campaign is conducted in several evaluation and control tasks, that show that abstraction refining consistently outperforms it's main competitor (progressive widening) in handling stochastic transitions with infinite or very large support.",0.4166666666666667,0.176056338028169,0.24752475247524752
2589,SP:eaac43a5cb483c71834b394b015d191cb8cbd815,"This paper mainly explores the representation ability of invariability of a point cloud network from the theoretical perspective. The universal approximation property for equivariant architectures under shape-preserving transformations is discussed. First, the authors derived two sufficient conditions for equivariant architectures with the universal approximation property. Then, they examined two methods based on the Tensor Field Network to prove that such a property holds for both of them. At last, the authors propose alternative methods which also satisfy the universal approximation property. ","The authors introduce a framework for sufficient conditions for proving universality of a general class of neural networks that operate on point clouds which takes as input a set of coordinates of points and as output a feature for each point, such that the network is invariant to joint translation of the coordinates, equivariant to permutation of the points and equivariant to joint SO(3) transformations of the coordinates and output features of all points. Notably, this class contains Tensor Field Networks (TFN). The authors accomplish this by writing the network as a composition of an equivariant function from a class F_feat and followed by a linear pooling layer. When the F_feat class satisfies a “D-spanning” criterion and the pooling layer is universal, the network is universal. For a simple class of networks and for TFNs, the authors prove D-spanning. Linear universality of the pooling layer follows from simple representation theory.",0.2682926829268293,0.14193548387096774,0.18565400843881857
2590,SP:eaae68b4effc3ed45f560b74377bdcb524220f81,"This paper introduces an unsupervised federated domain adaptation (UFDA) problem and proposes a new model called Federated Adversarial Domain Adaptation (FADA) to transfer the knowledge learned from distributed source domains to an unlabeled target domain. This paper uses a dynamic attention mechanism by leveraging the gap statistics to transfer distributed source knowledge. This paper also proposes a method to disentangle the domain-invariant features from domain-specific features, using adversarial training. Moreover, a theoretical generalization bound for UFDA is derived. An extensive empirical evaluation is performed on UFDA vision and linguistic benchmarks.","The authors present a novel algorithm for dealing with domain adaptation in the setting of federated learning (classification, specifically). That is, they tackle the issue of learning a model on a new domain when access to the data points used in training the source models is not possible due to privacy constraints. The approach uses the gradients of the source models, reweighed to account for the differing shifts between the different sources and the target domain, to fit the model on the target domain.",0.17391304347826086,0.19047619047619047,0.1818181818181818
2591,SP:eab7f68e9d6170869645eb7ca01ee340cf97d7a0,"The authors propose a novel algorithm for the fuzzy clustering of persistence diagrams. To determine cluster centroids, the Wasserstein-2 distance is used to minimize the weighted Fr\’echet mean between a potential cluster center and all PDs considered for clustering. The authors proof convergence of the clustering algorithm and conduct experiments on 1) synthetic data, 2) lattice structures, and 3) decision boundaries of neural networks. In the last experiment is was shown that models whose PDs cluster close to the PDs of a given task lead to higher classification performance than random classifiers, demonstrating the merit of PDs as a useful tool for model selection. ","The paper proposes a new clustering algorithm for persistence diagrams. They use fuzzy c means clustering. The motivation for fuzzy clustering is that it allows each datum (persistence diagram) to have weighted (soft) membership in different clusters. The partial membership value is the ratio of the distance to that cluster center to sum of all memberships to other clusters. Empirical results on synthetic and real data shows that clustering of persistence diagrams outperforms others that depends on geometry. A convergence theorem is provided, based on previous fuzzy k-means convergence proof.",0.19811320754716982,0.23076923076923078,0.2131979695431472
2592,SP:eae08fc9f0786b7522db48420aed2b1d02027ad3,##########################################################################  Summary:   This works proposes a sentiment classification approach for transformer-based models that employs additional embeddings to represent emotion inputs. These additional emotion inputs are generated using pre-trained transformer in a zero-shot fashion. Experimental results show a modest improvement for existing approaches such as BERT and DistilBERT.   ##########################################################################,"This paper proposes a simple way to supplement emotions related information to a downstream classifier. Authors first utilize a pre-trained BART Model to predict probabilities of a pre-defined set of emotion-related words. Then, they prepend the emotion words as text input to the transformer-based classifier. On two public sentiment classification datasets, authors show that adding emotion information leads to decent performance gains.",0.16326530612244897,0.12121212121212122,0.1391304347826087
2593,SP:eaeee8eeb85378f774e98259a43e7b8d794a3560,"The paper contributes a novel method, Drop-Bottleneck (DB), for discretely dropping input features that are irrelevant for predicting the target variable. Key idea is to instantiate the compression term of the information bottleneck framework with learned term that sets irrelevant feature dimensions to 0. To this end, a drop probability is learned for each dimension. Dimensions that have a lower probability than 0.5 (a fixed threshold) of being relevant are set to 0.","This paper proposes an information bottleneck method, Drop-Bottleneck, that allows the input to be compressed by dropping each input feature with probability p_i. The model then learns the drop probability vector p = [p_1, ... , p_n], where dropping ""redundant"" features will reduce the ""compression penalty"" term I(XZ). The approach is demonstrated in experiments in (1) robust exploration setting for RL, (2) adversarial attacks on ImageNet, and (3) an experiment showing that their approach is able to maintain performance on ImageNet with reduced dimensionality.",0.2,0.1744186046511628,0.18633540372670804
2594,SP:eb157345c592d29da7406143706e2523bf5cff77,"This paper investigates the Fisher information matrix (FIM) theoretically. Two equivalent expressions of FIM and their estimators are discussed (rediscovered) for deep neural network with exponential family output units. The closed-form variance (and simpler-form upper bounds) for the two estimators is proposed; the convergence rate of the positiveness definiteness are also analyzed. Finally, the variance is connected with the structure of the corresponding deep neural networks.","Update: I thank the authors for their response, and I will keep the score as is. It would be nice to have a simple empirical analysis in the final supplemental material.   The paper discusses the covariance of two FIM estimators, which is useful in deep learning where the exact FIM over the full dataset can be hard to compute. One is based on the variance of the score (type 1) and the other is based on the Hessian of the relative entropy (type 2). Comparing these covariances can depend on the exponential family used in the model, type 1 has a higher variance for Normal and Poisson whereas type 2 has a higher variance for Bernoulli. Convergence rate results are given which is $O(N^{-0.5))$ with constant determined by the variances. These results provide some theoretical justification as to which estimator of FIM to use when using it to perform natural gradient in deep learning. ",0.3088235294117647,0.1337579617834395,0.18666666666666668
2595,SP:eb16e608d4bb9be2c7f2e358a5166c6c202272cc,"This paper proposes methods to induce diversity in the networks of ensemble-based Q-Learning methods. This is achieved my maximizing a variety of measures of inequality based on the L2 parameter norms of individual networks in an ensemble. This is motivated by the benefit of having diversity in the learned features, which itself is motivated by observations on the CKA of some ensembleDQN networks.","Q-learning is known to have overestimation bias. Approaches like EnsembleDQN and MaxminDQN try to use different estimates from ensembles of learners to reduce the bias. The authors study a specific observation and try to tackle it by regularization technique to maximise the diversity of representation space. Five different regularization functions are evaluated in the paper. And experiments show that the proposed regularization helps on the diversity and outperform MaxminDQN and EnsembleDQN. Note that the reviewer is not very familiar with methods to introduce diversity in representation, but based on educated guess, the proposed method look interesting.",0.2,0.13402061855670103,0.16049382716049382
2596,SP:eb3a644606a97c248271782c2d9c83e699a329b9,"This paper propose a decomposition for non-symmetric determinantal point process (NDPP) kernels (M*M) which reduces the requirements of storage and running to linear in cardinality (M). Additionally, they derive a NDPP maximum a posteriori inference algorithm that applies to both their proposed kernel and the previous work (NDPP). In their experiments, they show both learning kernels and the MAP inference for subset selection on real-life datasets. ","Nonsymmetric determinantal point processes (NDPPs) received some attention recently because they allow modeling of both negative and positive correlations between items. This paper developed scalable learning and MAP inference algorithms with space and time complexity linear in ground set size, which is a huge improvement compared to previous approaches. Experimental results show that the algorithms scale significantly better, and can roughly match the predictive performance of prior work.",0.17391304347826086,0.17647058823529413,0.1751824817518248
2597,SP:eb3da4f2226e3765f1aa4a65041cbbb10af71cda,The paper proposes a new data augmentation method for Graph Neural Networks based on Markov Chain Monte Carlo sampling and in particular the Metropolis-Hastings algorithm in the context of semi-supervised learning. The main intuition of the paper is to define a target distribution for the whole graph which is representative of the changes in the number of messages that are exchanged in the k-hop neighborhood of each node and then apply the Metropolis-Hastings algorithm for obtaining samples that are representative of this distribution. The experimental section compares the proposed method (MH-Aug) to other recent data augmentation methods showing favorable results w.r.t. the baselines.,This paper introduces a MH-style data augmentation to boost the generalization ability of the existing GNNs by generating sequence of augmented graphs. The generation is proven to be converging to the desired target distribution. The experimental results shows a promising result for applying augmented graph during the GNN training. ,0.15454545454545454,0.34,0.2125
2598,SP:eb5d45ef0112f93ade7aa89d9a5132062590f9e1,"This paper, inspired by the established technique of model ensembling, proposes two methods (AGG-Mean and AGG-Var) for aggregating different model explanations into a single unified explanation. The authors mathematically prove that the derived explanation is guaranteed to be more truthful than the average performance of the constituent explanations. In practice, the aggregation consistently outperforms *all* individual explanations, not just their aggregated performance. Additionally, the paper introduces a new quantitative evaluation metric for explanations, free of human intervention: IROF (Incremental Removal of Features) incrementally grays out the segments deemed as relevant by an explanation method and observes how quickly the end-task performance is degraded (good explanations will cause fast degradation). Solid validation confirms that the IROF metric is sound.",The paper has two main messages: 1- Averaging over the explanation (saliency map in the case of image data) of different methods results in a smaller error than an expected error of a single explanation method. 2- Introducing a new saliency map evaluation method by seeking to mitigate the effect of high spatial correlation in image data through grouping pixels into coherent segments. The paper then reports experimental results of the methods introduced in the first message being superior to existing saliency map methods using the second message (and an additional saliency map evaluation method in the literature). They also seek to magnify the capability of the 2nd message's evaluation method by showing its better capability at distinguishing between a random explanation and an explanation method with a signal in it.,0.17355371900826447,0.1590909090909091,0.16600790513833993
2599,SP:eb68990c667caac32adfbcc8d355ec87fdb9dca4,"Combiner - a new cheaper computationally attention algorithm. By introducing a new factorization structure, the design an algorithm with low complexity but capability close to full attention. Numerous experiments demonstrate the utility of the proposed approach.","This paper focuses on the problem of reducing the computational cost of attention in transformers. In particular, it addresses the lack of expressiveness in existing attention approaches that leverage sparsity. To this end, the authors propose to view attention as a conditional expectation of embeddings for each token which can be approximated with a structured factorization that includes a direct expectation and an indirect/local expectation term.  Existing sparse attention patterns with sub-quadratic cost can then be used to design such factorizations which result in more expressive attention mechanisms with the same theoretical cost. The evaluation shows that this model can also reach competitive performance in several benchmarks.",0.2571428571428571,0.08256880733944955,0.125
2600,SP:eb76b7126106346a97624a40277bb28c57f0629b,"The paper proposes a spectral non-local block, which is a generalized method of the non-local block and non-local stage in the literature. The proposed spectral non-local block can be plugged into a neural network to improve its effectiveness. The paper also provides theoretical analyses of the stability of the proposed method, and also extend the method by including more  Chebyshev polynomial terms. Experiments are conducted on image classification and action recognition tasks, and they valid the effectiveness of the proposed method. ","In this paper, authors propose a spectral nonlocal block. First, they re-interpret the nonlocal blocks in a graph view and then use Chebyshev approximation to obtain the spectral nonlocal block which is quite simple by adding a ZW_1 term. Furthermore, they analyze the steady-state to build up a deeper nonlocal structure. Also, the gSNL is simple by adding a (2A-I)ZW_3 term.",0.16470588235294117,0.208955223880597,0.18421052631578946
2601,SP:eb8b8a0bae8d3f488caf70b6103ed3fd9631cb9f,"In this paper, the authors proposed a new training strategy in achieving better balance between training efficiency and evaluation accuracy with weight sharing-based NAS algorithms. It is consisted of two phrases: in phrase 1, all path are uniformly trained to avoid bias, in phrase 2, less competitive options are pruned to save cost. The proposed method achieved the SOTA on IN mobile setting. ","This paper introduces a better searching strategy in the context of automatic neural architecture search (NAS). Especially, they focus on improving the search strategy for previously proposed computationally effective weight sharing methods for NAS. Current search strategies for the weight sharing NAS methods either focus on uniformly training all the network paths or selectively train different network paths with different frequency, where both have their own issues like wasting resources for unpromising candidates and unfair comparison among network paths. To this end, this paper proposes a balanced training strategy with “selective drop mechanism”. Further, they validate their approach by showing leading performance on ImageNet under mobile settings.",0.1875,0.11214953271028037,0.14035087719298245
2602,SP:eb9803ef7698cade762d39290f842a7b3bf897d0,"In this paper the authors propose an architecture based on variational autoencoders and hyper-networks. The basic idea is that the weights of the underlying RNN/autoencoder are not fixed, but are coming from another RNN/feed-forward network which captures the underlying dynamics and adjusts the weights accordingly. The experimental results show the benefit of the model compared to a similar method without hypernets.","This paper proposes a variational hyper recurrent neural network which is a combination of the variational RNN and the hypernetwork. The hypernetwork is an RNN whose output modifies the parameters of the variational RNN dynamically at runtime. Overall, this seems like an extension of the idea of using a hypernetwork with the VRNN (rather than the RNN as done in Ha. et. al). The model is trained via the FIVO objective. The model and learning algorithm are compared to the variational RNN and tested on a variety of synthetic settings where the VHRNN outperforms the VRNN in held-out likelihood. The performance gains are investigated on synthetic datasets where the paper notes that the VHRNN is often quicker to adapt variations that happen within seqences (for example, the paper considers a dataset where multiple patterns are stitched together into a sequence and study the changes in the KL divergence and reconstruction at switch points). On four real-world sequential datasets, the paper finds that the model outperforms the VRNN across many configurations and with a fewer number of parameters.",0.3230769230769231,0.11731843575418995,0.1721311475409836
2603,SP:ebc8e7787e6477033ffc0f2456b2ac0500b13488,"This paper proposes a soft relaxation of the box lattice (BL) model of Vilnis et al. 2018 and applies it to several graph prediction tasks. Results are comparable to the BL model on existing artificially-balanced data but significantly better on more natural unbalanced data with a large number of negatives. The paper assumes some familiarity with the problem domain and existing works (there is not a lot of exposition for an unfamilar reader), but should be of strong interest to anyone working on embeddings or graph prediction.","The paper proposes a method for learning embedding of hierarchies. Specifically, the paper builds on a a geometrically inspired embedding method using box representations. The key contribution of the paper is facilitating optimization of these models by gradient based methods, which eventually leads to improved accuracy on relevant benchmark data (on par or beyond SOTA). The observation is that when two boxes are disjoint in the model but have overlap in the ground truth, no gradient can flow to the model to correct the problem (which is happens in case of sparse-data.",0.19318181818181818,0.1827956989247312,0.18784530386740333
2604,SP:ebdfa4469869810fcf661a90c9ce1d7a6c07171b,"This paper interprets the fitted Q-learning, policy evaluation and actor-critic as a bi-level optimization problem. Then, it uses two-timescale stochastic approximation to prove their convergence under nonlinear function approximation. It provides interesting view of the these existing popular reinforcement learning algorithms that is widely used in DRL. However, there are several points to be addressed in the revision, which are mainly in some of its claims.","The paper casts the problems of value learning and policy optimization, which can be problematic the non-linear setting, into the bilevel optimization framework. It proposes two novel algorithms with convergence guarantees. Although other works with similar guarantees exist, these algorithms are very appealing for their simplicity. A limited empirical evaluation is provided for the value-based method in Acrobot and Mountain Car and in the Atari games Pong and Breakout for the proposed bilevel Actor Critic.",0.2,0.18181818181818182,0.1904761904761905
2605,SP:ebf224ba53e628c06a426f49cf8f1761f3da7fc8,"This basic idea of this paper is to decompose the common building blocks of large network into atomic blocks, which equips NAS with more fine-grained search space. What's more, the authors propose a resource-aware search to reduce the computation and dynamically shrinkage the model to accelerate the learning. Retraining the final network is no longer needed. They achieve state of art on ImageNet under several complexity constraints.","[Summary] This paper proposes a channel-wise neural architecture search (NAS) approach. The NAS search algorithm is similar to previous one-shot NAS, but the search space is channel-wise: each channel has it’s own kernel size, which is quite novel and interesting. Results are strong in terms of FLOPS and parameters.",0.14285714285714285,0.18867924528301888,0.16260162601626016
2606,SP:ebf3053dcae6ca7e0bdbc98e5a71151c55eb384f,"This paper proposes a lookahead-minmax algorithm for optimizing minmax problems such as GANs, which updates the parameters (of both the generator and the discriminator) with the extrapolation. With a bilinear example, the authors show that the use of lookahead-minimax allows for convergence in cases where other methods does not, and yields good performance under high variance. Experiments of generative performance on several well-known public datasets demonstrates the effectiveness of the proposed method.","This work extends the recently proposed lookahead optimizer (which was designed for single-objective optimization) to minimax optimization, particularly GAN training. The authors claim that the backtracking step in lookahead optimizer alleviates the notorious rotational behavior in GAN dynamics. Moreover, the authors argue that the lookahead optimizer implicitly handles the high variance in the small-batch setting. Both arguments are backed up by toy experiments on stochastic bilinear games.  Finally, on standard image datasets, the lookahead minimax algorithm outperforms some popular algorithms and achieves state-of-the-art performance on CIFAR-10.",0.25333333333333335,0.20652173913043478,0.22754491017964074
2607,SP:ec03a452d165bcff98d9e40050a495dc1f30255b,"This work uses dual formulations of Neural Networks with ReLU activations. It starts explaining the dual formulations with simplest single layer unregularised linear neural networks with a single dimensional output layer. Then gradually extends the models to deep, regularised models with ReLU activations. There is also an assumption on the data to be of rank one or whitened. The experiments are limited and not essential, since they only show that the theory can be confirmed with experiments, albeit they also demonstrate the limitations of simplified models studied here.","The authors consider training neural networks with a variety of losses and regularization (such as weight decay).  The authors introduce a novel convex-dual formulation which allows them to characterize optimal solutions as being extreme points of particular convex sets.    For multi-layer linear networks, the authors prove that the optimal weight matrices have rank equal to the number of outputs of the network, and whose singular vectors align with those of neighboring layers.  For ReLU nets in one-dimension, the authors prove that optimal solutions act as linear spline interpolators (the kinks between linear pieces occur at data points), and the authors prove closed form expressions for optimal weights at intermediate layers when input data is whitened.  ",0.19318181818181818,0.1440677966101695,0.1650485436893204
2608,SP:ec29980f445635a36feeac3af690b15be87ccc04,"The paper describes a generalization of group equivariant neural networks that typically rely on linear operators such as the group convolution, or pseudo linear operators such as attentive group convolution. The authors take a look at the aggregation function of the convolution operator (which is usually linear via a kernel times feature values followed by sum aggregation) and replaces it with a non-linear function that generally could depend not just on relative positions, but also on the central and neighbor feature values. The result is a more non-linear operator than group convolutions, which are a special case of this framework.  The paper is accurate and has an appropriate experimental section with decent ablation studies. The proposed work compares favorably compared to the baselines both in terms of accuracy, parameters and nr of operations (FLOPs).","This paper introduces a functional abstraction for group-convolutional networks employing first- and second-order features. Based on this functional abstraction, a new functional form for second-order group-convolutional networks is devised, which can be made more parameter-efficient than existing approaches. Experiments are performed on rotated MNIST and CIFAR, evaluating error, number of parameters and certain ablations.",0.10294117647058823,0.23728813559322035,0.14358974358974358
2609,SP:ec2f239db5f53132ea1554f322ea268ae1da6f17,"The paper discusses how to find bipartite components in a hyper graph.  A bipartite component consists of two subsets of vertices L and R.  Bipartite implies  there is minimal connection within L as well as within R.  Component implies that there is minimal connection between vertices in L union R and vertices outside.    The algorithm is based on diffusion process to find sets with small hyper graph bipartiteness.  The paper provides a couple of theorems for the existence of a polynomial algorithm.  Experiments are conducted on both synthetic as well as real-world datasets, including Penn Treebank and DBLP.",This paper proposes a polynomial-time algorithm that finds densely connected bipartite components in a hypergraph. The algorithm is based on a heat diffusion process generalized from graphs to hypergraphs. Cheeger-type approximation guarantee is established. Empirical results show that the new method has superior performance for both synthetic and real hypergraphs.,0.18181818181818182,0.34615384615384615,0.23841059602649012
2610,SP:ec387dc36bcda590bbe0a3cf735b83b49616da3e,"Despite its success, Gaussian process based Bayesian optimization still struggles in high dimensional search spaces. Current approaches aim to learn an embedding to optimize the objective in a low dimensional continuous latent space. This paper provides evidence that with current approaches, different data points in the input space can be mapped to same point in the latent space. To avoid these collisions, the paper proposes a new regularization technique based on pairs of observed datapoints.","This paper is concerned with latent space Bayesian optimisation that typically involves a step of learning a lower-dimensional latent representation. The authors focus on non-linear embeddings generated through neural networks. They observe a collision problem in the latent space and attempt to resolve it by introducing a regulariser based on Lipschitz continuity. In a set of experiments, they demonstrate that such a method is effective in various benchmarks. Although interesting, I still find this paper lacking as presented in the next section. ",0.18666666666666668,0.16666666666666666,0.1761006289308176
2611,SP:ec3b4ae82ca6f34505dbb909d0a705804f8eb22c,"This paper proposes two machine learning adaptations of the Bayesian truth serum approach to aggregating predictions from human experts. The first method proposed involves training two regression models for each classifier in the ensemble that predicts the proportion of other classifiers that assign the same label to a novel instance. The second approach is to train a binary classifier that, based on the features associated with an instance, determines whether the most common or second most common prediction made by individual ensemble members should be the prediction made by the ensemble.","Inspired by work in ensembling human decisions, the authors propose an ensembling technique called ""Machine Truth Serum"" (based off ""Bayesian Truth Serum""). Instead of using majority vote to ensemble the decisions of several classifiers, this paper follows the ""surprisingly popular"" algorithm; the ensembled decision is the decision whose posterior probability (based on several classifiers) most exceeds a prior probability (given by classifier(s) trained to predict the posterior predictions). It's quite a nice idea to bring this finding from human decision-making to machine learning. If it worked in machine learning, it would be quite surprising, as the surprisingly popular algorithm risks that the ensemble makes a decision against the majority vote, which is usually consider the safe/default option for ensembling.",0.21978021978021978,0.16260162601626016,0.18691588785046728
2612,SP:ec3d792f859916d782bce86107d178f6965fc9b1,"This paper continues an emerging line of research to find interpretable (post-hoc) counterfactual explanations of classifier predictions. While prior work has made advances in ensuring that resulting counterfactuals lie in the same data distribution as the original dataset by using auto-encoders, this paper provides a semi-supervised approach in an attempt to also ensure that they lie in the data distribution corresponding to the counterfactual label. The authors show the benefits of their approach on six datasets:  German Credit data, Adult Census data, MNIST, COMPAS, PIMA, and Breast Cancer Wisconsin data.","This paper presents a new approach for generating counterfactual explanations. Specifically, the presented method optimizing for a counterfactual explanation using a weighted loss function of L_pred, L_sparsity, L_recon, and L_proto, and differs from previous works in the manner in which the latter two losses are computed. In more detail, whereas prior work computes L_recon and L_proto using the reconstruction and latent space distance of *unsupervised* models, the presented method computes these losses using a semi-supervised setup whereby a model is jointly trained to minimize reconstruction and class-conditional loss. The authors conduct experiments on a number of real- and mixed-valued datasets, which is welcome in a field where broad experimentation is historically lacking.",0.1935483870967742,0.1487603305785124,0.16822429906542055
2613,SP:ec463ec2a5bde3efb2f9daa1fd29dd71c7472341,"This paper proposes a novel meta-learning method, aimed at solving the following problem: at test time, the agent has N episodes to gather information [exploration phase], and we care about its return in the N+1th episode [exploitation phase]. To this end, the authors propose to learn a separate exploration and exploitation policy. The core of the algorithm is to use an exploration bonus for the exploration policy that rewards finding novel trajectories. This should help it to collect valuable information during meta training and meta testing. The exploration policy is only used in the N+1th episode, and  is conditioned on a context vector which is computed from the exploration trajectories. ","The paper presents a method for efficient task identification to improve adaptation in a meta RL setting. The approach is based on learning an exploration policy to quickly discriminate the task at hand, so that to leverage a task-specific policy for exploitation. To do so, it employs an intrinsic reward proportional to the information gain (or prediction error) over both the transition and reward models. Finally, the algorithm is evaluated over a set of continuous control domains with sparse rewards.",0.168141592920354,0.2345679012345679,0.1958762886597938
2614,SP:ec5a3d26769b738d3cc12b0bfdfe90fb51fb4b36,"The paper views different variants of DRO are simply instances of a finite-sum composite optimization, from which efficient optimization algorithms were proposed. The convergence analysis was established for strongly-convex and non-convex settings.  The effectiveness of the proposed algorithm are well demonstrated in experiments. ","This paper targets on solving distributionally robust optimization (DRO) that considering   distribution shifts in the data. In this paper, they show that  how different variants of DRO are simply instances of a finite-sum composite optimization for which they provide scalable methods by utilizing variance reduction algorithm. They also provide empirical results that demonstrate the effectiveness of our proposed algorithm with respect to the prior art in order to learn robust models from very large datasets. ",0.4782608695652174,0.2894736842105263,0.360655737704918
2615,SP:ec83ad5b38ab973df53f6cf9c3bad784ef6a5170,"The paper proposes a contrastive learning approach for self-supervised learning in which multiple heads are trained to be invariant to all but one type of data augmentation. The rationale is that different downstream tasks may require different types of invariances (e.g. we may want to be rotation invariant for pictures of flowers, but not for pictures of animals), and one does not know a-priori which kind of invariances will be required. After training multiple representation heads, one can later concatenate them or use the general embedding (the input to all the variant-specific heads) for the downstream task.","The authors observe that, while effective, contrastive learning unavoidably introduces some bias depending on the choice of augmentations the algorithm is made invariant to, and that deteriorates performance depending on the task. The authors corroborate this hypothesis with experiments with the MoCo baseline and proceed to propose a modification to the usual contrastive learning setup: learning a shared representation and multiple projection heads, each invariant to a different augmentation type. They empirically show the effectiveness of the proposed solution on several tasks, including few-shot learning and data corruption datasets.",0.13861386138613863,0.15555555555555556,0.14659685863874347
2616,SP:ec977883a2d15b6310ca77e0608c646e4919a13c,The paper proposes a novel approach to providing an explanation for the prediction made by off-the-shelf tensor factorization models by using its scores to create an augmented weighted knowledge graph and scoring higher order paths (aka templates) as explanations. The presentation is mostly clear and the results are convincing of the proposed idea. The paper however suffers from lack of sufficient novelty and adequate experimental comparison with other state-of-the-art approaches that offer explanations.,"The authors propose a novel method OxKBC for generating post-hoc explanations of a trained factorization model for link prediction. The authors identify five different templates which explain a predicted triple (s,r,o): Similarity between tail entities, similarity between relations, both occurring simultaneously, similarity between r and the hadamard product of a two-hop relation in the KB, and o being a frequent tail entity for r. Since the predefined scoring functions do not obviously generalize between different templates, OxKBC performs a two-step computation for each predicted triple where first the best template is selected, and second that template is grounded in the knowledge graph. The authors evaluate OxKBC using a paired comparisons test with Amazon Mechanical Turk, comparing against a rule-mining baseline. Results show OxKBC to handily outperform the baseline.",0.20512820512820512,0.11940298507462686,0.15094339622641506
2617,SP:ecb271a825f6d8cbc5c045436d6bc937a735e6a1,"In this paper, a greedy algorithm that can find a structure of a certain class of tensor networks is proposed. The algorithm consists of bi-level optimization, where tensor network structure is optimized in the outer loop and tensor decomposition is computed to approximate a given tensor in the inner loop. The tradeoff between error and the number of parameters of the proposed algorithm is empirically compared with synthetic data, image compression, and neural network compression.","First, the idea of rank incremental method for Tensor network decomposition and determination of TN structures is not novel.  Second, decomposition with weight transfer is obvious and widely used in the rank incremental method.  For generalized tensor networks decomposition, the authors should consider the works.  S.  Handschuh,  “Numerical  Methods  in  Tensor  Networks,” PhD  thesis,Facualty of Mathematics and Informatics, University Leipzig, Germany,Leipzig, Germany, 2015.  Mike Espig, Wolfgang Hackbusch, Stefan Handschuh, and Reinhold Schneider,   Optimization Problems in Contracted Tensor Networks, 2012",0.17105263157894737,0.16049382716049382,0.16560509554140126
2618,SP:ecdae30f9692bf6d23cd5a571dabb82fe782c244,"This paper addresses the continual learning setting, and aims to mitigate catastrophic forgetting, with results on Permuted MNIST, Split MNIST, Vision Datasets Mixture, and their own class-imbalanced version of the Permuted MNIST dataset. The authors propose to augment differentiable plastic weights - a general neural network component - with class-specific updates (similarly to prior work, such as the Hebbian softmax) at the final layer of a neural network, prior to a softmax. While well-motivated in terms of the background and methodology (indeed, this is a simple way to prevent interference in fast weights), and nicely explored experimentally with lots of examinations into the workings of the method, the weak results on the simpler continual learning settings lead me to consider this a weak reject.","The authors introduce DIFFERENTIABLE HEBBIAN CONSOLIDATION,a new framework for continual learning that can be implemented in the usual differentiable programming setups. This framework is motivated in terms of complementary learning system (CLS) theory which features an episodic memory module. The method is shown to be easily implemented as seen in their pytorch pseudocode (authors also suggest code will be released). Additionally, authors show the method leads to significant  improvements over simple baselines, and can complement other task-specific hebbian-based learning paradigms",0.128,0.1927710843373494,0.15384615384615385
2619,SP:ed01a0233c76094bf814ffeb5fcc10548a26e4bd,"The authors propose a simple recurrent network as a model of spatial navigation in the MEC/Hippocampal network. This model assumes that grid cells only regularly receive egocentric movement information, an important aspect for understanding the origin of these functional cell types in-vitro. Overall, this article should be of interest for any ICLR members interested in biological  spatial navigation. ",The authors develop a model for learning the observed responses of grid cells (GC) in the entorhinal cortex from the animal movement vectors. Their key assumption is that the GC activity vector rotates with the movement magnitude according to the Lie group formalism and the corresponding Lie group generator is also rotated by the change in movement orientation. Their claim is supported by a numerical optimization of the objective function reflecting these assumptions as well as the projection onto the place cell representation in the hippocampus.,0.23333333333333334,0.16279069767441862,0.19178082191780824
2620,SP:ed029e890b8a91e1f8a6ecabb0ee830759638b36,"In this paper, authors proposed a generative QA model, which optimizes jointly the distribution of questions and answering given a document/context. More specifically, it is decomposed into two components: the distributions of answers given a document, which is modeled by a single layer neural network; and the distribution of questions given an answer and document, which is modeled by a seq2seq model with a copy mechanism. During inference, it firstly extracts the most likely answer candidates, then evaluates the questions conditioned on the answer candidates and document and finally returns the answer with the max joint score from two aforementioned components.","This paper proposes a generative approach to textual QA on SQUAD and visual QA on CLEVR dataset, where, a joint distribution over the question and answer space, given the context (image or Wikipedia paragraphs) is learned (p(q,a|c)). During inference the answer is selected by argmax p(q,a|c) that is equal to p(a|c,q) if the question is given. Authors propose an architecture shown in Fig. 3 of the paper, where generation of each question word is condition on the corresponding answer, context and all the previous words generated in the question so far. The results compared to discriminative models are worse on SQUAD and CLEVR. Nevertheless, authors show that given the nature of the model that captures more complex relationships, the proposed model performs better than other models on a subset of SQUAD that they have created based on answer type (number/date/people), and also on adversarial SQUAD. ",0.2549019607843137,0.16666666666666666,0.20155038759689922
2621,SP:ed090d8999fb0edf10ab2d239f7c0b309c2b9fea,"This paper proposes a new regularization scheme, which involves randomly permuting nearby (in terms of spatial locations in the downsized feature tensor) depth blocks. The authors show its effectiveness in supervised learning tasks and establish a SOTA-like result over Procgen generalization, and also provide several empirical ablations and visualizations over the method to understand its inner workings. The paper shows that regularization which involves the locality of objects is particularly effective.","In this work, a novel regularization method for deep neural networks is introduced. By locally swapping dimensions of intermediate feature maps, the authors report generalization improvements in supervised learning and on several reinforcement learning benchmarks. The method is evaluated against several other common regularization techniques and was found to lead to better results.",0.20833333333333334,0.2830188679245283,0.24000000000000002
2622,SP:ed0cc0a06769db9ce8ea1f5d466e5e354a2b13ad,"This paper proposes a novel active learning method - called BEMPS (Bayesian Estimate of Mean Proper Scores) - in the context of text classification. Based on the ELR (expected loss reduction) approach, the authors propose to estimate the increase in the so-called ""strictly proper scores""  such as the log probability or negative mean square error. They show that the proposed method, BEMPS, makes the classifier asymptotically converge to the optimal classifier as the active learning process continues. For proof, it builds upon techniques that were recently utilized for proving the convergence of the active learning scheme based on weighted MOCU (mean objective cost of uncertainty). Based on extensive evaluations on various benchmarks, this study shows that BEMPS generally outperforms other state-of-the-art active learning methods.  ","The paper addresses the problem of active learning by querying examples that will lead to the most reduction in classification error, which is a fairly common idea. It proposes to place this in the context of strictly proper scoring rules in order to derive new example acquisition functions and generalize existing ones. Experiments on multiple datasets illustrate this for two common scoring rules, with extensive analysis, showing that the proposed methods perform well. ",0.12698412698412698,0.2191780821917808,0.16080402010050251
2623,SP:ed3aac329a61708dcf1038eb390b0a2c5216bc46,"This paper addresses the problem of model robustness to subpopulation shift. Authors propose building large-scale subpopulation shift benchmarks wherein the data subpopulations present during model training and evaluation differ. In this regard, their approach is based on leveraging existing dataset labels and use them to identify superclasses to construct classification tasks over such superclasses and repurpose the original dataset classes to be the subpopulations of interest. They train some learning models over the generated benchmarks to evaluate model robustness to subpopulation shift and, finally, they try various learning interventions (from the literature) to decrease model sensitivity to this sort of data perturbations.","The authors develop a framework named BREEDS for studying population shift, putting it in their words, they address the problem of how well do models generalize to data subpopulations they have seen during training, in the specific domain of images, without altering the inputs or requiring new data. They propose to create large scale subpopulation shift benchmarks  to assess how models generalize beyond the diversity of the training examples.  The underlying idea is to identify superclasses from the dataset. ",0.17475728155339806,0.22784810126582278,0.19780219780219777
2624,SP:ed590dec0a3cd9b7ac1cb1c5407c51509e59a878,"The paper studies the offline training and online fine-tuning setting for MARL, and show that it is promising to learn policy representatrions to improve the performance on downstream MARL tasks. The paper proposes to integrate the transformer architecture to improve efficiency and generalization ability. Authors conduct extensive experiments to validate its effectiveness.","This is the first paper to pre-train a multi-agent model with offline datasets and online fine-tune it to a particular task. The authors propose MADT an offline pre-training architecture for multi-agent RL integrating transformers with imitation learning on an a collected data set of offline data. Towards this end, the authors contribute a data set of offline multi-agent interactions collected from running multi-agent PPO on 5 tasks from SMAC. On this data set, the proposed MADT method is shown to outperform popular single agent offline RL algorithms from the literature and excel at fine-tuning a pre-trained offline model.  ",0.2830188679245283,0.14018691588785046,0.18749999999999997
2625,SP:edaff421cdd69bd00ceda7e23fcb8b64c02c521f,"This paper proposes an efficient algorithm to learn  neural embedding models with a dot-product structure over very large corpora. The main method is to reformulate the objective function in terms of generalized Gramiam matrices, and maintain estimates of those matrices in the training process. The algorithm uses less time and achieves significantly better quality than sampling based methods. ","This paper proposes a method for estimating non-linear similarities between items using Gramian estimation. This is achieved by having two separate neural networks defined for each item to be compared, which are then combined via a dot product. The proposed innovation in this paper is to use Gramian estimation for the penalty parameter of the optimization which allows for the non-linear case. Two algorithms are proposed which allow for estimation in the stochastic / online setting. Experiments are presented which appear to show good performance on some standard benchmark tasks. ",0.23728813559322035,0.15384615384615385,0.18666666666666668
2626,SP:edc0f188be1033f314501ac1cfa157e6ebabed48,"This paper presents a simple approach for domain adaptation in Knowledge Graph Question Answering. The paper consider the setting where the knowledge graph used to back the QA system contains the necessary facts for a test-time domain, but the training domain didn't cover an examples that required inference over that subdomain. To bridge the gap, the paper proposed a simple procedure for constructing synthetic questions over the relations in the test domain.","This paper studies the problem of answering ""first-order"" questions (more on the terminology later) that correspond to a single fact in a knowledge graph (KG) and focuses on the cross-domain setting where no curated training examples are provided for the unseen test domain. The proposed base KGQA model is modified from the state-of-the-art model on SimpleQuestions from (Petrochuk and Zettlemoyer, 2018) but with the relation prediction component changed from a classification model to a ranking model to better handle unseen relations (more on this later). The key contribution is a way of generating synthetic questions for the relations in the unseen domain for data augmentation. The generation model is from (ElSahar et al., 2018) but is augmented with relation-specific keywords mined from Wikipedia via distant supervision. Evaluation on reshuffled SimpleQuestions shows that the proposed method can achieve a reasonable performance on 6 selected test domains of large to moderate scale, and the question generation strategy is better than several baselines.",0.32432432432432434,0.14457831325301204,0.2
2627,SP:edda5940fcfe72533d9925b2d73f5ed4c411e4bb,"This paper proposed a personalized federated learning algorithm which takes into account the similarity of gradient of different users to update the model. More formally, the authors define $\tilde{S}(i,j)$ as a measure of similarity between the gradients of two user $i$ and $j$, and then update the model of user $i$by weighting the gradient of user $j$ by $\tilde{S}(i,j)$. The authors study their method in various numerical settings. ","This paper proposes two methods for personalized federated learning, one synchronous and one asynchronous. The general approach taken in both cases is to adapt the weights when averaging information from different clients, so that clients with more similar gradients are given more weight in the update for each client. The two approaches are called SPFL (synchronous) and PLGA (asynchronous). The approaches are illustrated on small image classification tasks.",0.18666666666666668,0.20588235294117646,0.19580419580419578
2628,SP:ede5907e363a0dcaa8e5b090a52c19dab1b27bce,"This paper proposes SPO-LF, a safe learning algorithm for sequential decision making. The key idea is to predict a pessimistic safe space and an optimistic safe space based on the confidence intervals, and constrains the exploration in the safe space. The proposed algorithm is evaluated in the mini-grid and the safety-gym environments, compared with several baselines, and claimed to be able to handle large-scale problems, and behave more safely than the CMDP-based deep RL algorithms.","This paper studies the problem of safe exploration in reinforcement learning contexts. It develops a new algorithm which, by making several assumptions, can stay safe while exploring and achieves good sample efficiency. The proposed approach incorporates sensor measurements (""far-sighted observations"") and estimates of safety based on those observations, as well as the idea of an optimistic and pessimistic safe set, to stay safe during exploration. It also introduces a novel way to ensure that the algorithm does not get stuck in a safe area by detecting this case and more aggressively expanding the set of considered exploration actions.",0.2375,0.1919191919191919,0.2122905027932961
2629,SP:edf6b1f46c66ca835d3ab608b17a07bed0aeef36,"This paper studies how to solve RL problems with a set of success states instead of a standard reward function. The central idea is to firstly train a Bayesian classifier from both the input success examples and the on-policy sampling using the conditional normalized maximum likelihood (CNML) and then use the learned classifier as a reward function to guide exploration. It is proved that in a tabular case, the success classifier trained with CNML is equivalent to a version of count-based exploration and it is claimed that with function approximation, the classifier attains non-negligible generalization. Empirically, it is claimed that this approach outperforms existing algorithms on a number of navigation and robotic manipulation domains.","This paper considers the problem of learning a policy for an MDP with unspecified reward, given user-provided goal states. To this end, a reward model and a policy are jointly learned: the reward model is the conditional normalized maximum likelihood (CNML) learned from a training set consisting of the example goal states as positive examples, and the policy trajectories as negative examples; the policy is trained to optimize the MDP using the learned reward. Meta-learning is applied to reduce the cost of learning the CNML models.",0.20512820512820512,0.2727272727272727,0.23414634146341462
2630,SP:ee20fb0517e11ddb87a713434d3bd8f29812a521,"The paper investigates the over-parameterization of attention heads in Transformer’s multi-head attention. The authors show that query-key projections are redundant because trained concatenated heads tend to compute their attention patterns on common features. They propose a reparameterization of multi-head attention allowing the parameters of queries and keys to be shared between heads: this is called “collaborative attention”. This attention can be applied either instead of the standard attention during training, or as a drop-in replacement for an already trained model. To use as a drop-in replacement, the method requires to use tensor decomposition and subsequent model fine-tuning.","This paper analyzes the multi-head attention in transformers and suggests to use collaboration instead of concatenation of multiple heads. Empirical results on WMT’16 English-German demonstrates that the proposed approach reduces the of parameters without sacrificing performance. Further experiments on pre-trained BERT models also demonstrate its efficiency.  Overall, the paper is well motivated and provides a deep analysis of redundancy of the multi-head attention. ",0.12380952380952381,0.19117647058823528,0.15028901734104047
2631,SP:ee3c5ca2ee8cb1876ff593863745050eb7e9f941,"Summary This submission studies lottery ticket hypothesis for deep neural network based inverse imaging. It considers two scenarios: 1-inference for compressed sensing based on pre-trained deep generative models, 2-deep image prior where all network parameters are fit to a single image. Both scenarios are dealing with a single image training task, or, an overfitting task, which makes this work different from the past work using LTH. The empirical results suggest that with a high level of sparsity not only the model size can be made much smaller, but also the generalization can improve which suggests pruning as a regularization. They also suggest good transferability from one image restoration task to another.  ","This paper researches the lottery ticket hypothesis for networks as a deep image prior or deep generative prior. The specific approach is to (1) train deep networks to reconstruct multiple images for DIP (Ticket ﬁnding objectives), (2) conduct iterative magnitude pruning to the trained network, (3) obtain the pruned mask and reset the model parameter to initialization weight and (4) perform deep image prior to new (or training) images.  The proposed objective is an important design for the system to work, i.e., the author optimizes the network by minimizing the expected error on multiple images. The experimental results are somehow interesting that (1) different pruning methods actually performs differently and (2) there are winning tickets in the studied problem. As for GAN compressive sensing task, there are also winning tickets that exists. The point I am more interested in is that some networks are more suitable to be used as deep image prior than others. ",0.21929824561403508,0.16025641025641027,0.18518518518518517
2632,SP:ee3f3ba07e22b31ba47ef01b1fc523bbbddddd5c,"The authors present a method for online policy adaptation during domain transfer in the case no reward is available in the target domain. They achieve this by adding an auxiliary self-supervised task, such as inverse dynamics prediction, that helps shape a set of features shared with the policy during training. At test time, gradient updates are then performed on these shared features based on only the self-supervised loss. The authors evaluate their method on a number of visual continuous control tasks and discrete navigation tasks and show a significant improvement over direct transfer, domain randomisation, and using self-supervision only during training.","This paper studies an important problem in vision-based RL: how to adapt a pre-trained policy to an unseen environment in a self-supervised manner. To do this, the authors introduce an auxiliary task branch that can be used to tune the intermediate representation of the policy network on the fly in a self-supervised manner(e.g. inverse dynamic prediction). The experiments in the DeepMind Control suite, CRLMaze, and robot manipulation tasks show the generalization and effectiveness of the proposed method in various vision-based RL problems.",0.20192307692307693,0.23595505617977527,0.21761658031088082
2633,SP:ee3f9c45e31d0e04b40d2547215df4e4d34e0e0d,"The authors address transfer learning scenarios. In particular, the authors resort to training to a diverse set of experts and ""cheap"" performance proxies to select, for a given task, the relevant expert. This ""per-task routing"" is conducted via a nearest neighbor classifier based on a reduced representation for each expert. Two variants are considered: (1) full ResNet50 models are used (one for each expert) and (2) ""compact adapter modules"", which depict expert layers between ResNet block (all experts are learnt simultaneously with the same model backbone).","This paper presents a novel method for obtaining better representations for transfer learning. Specifically, instead of using a generic representation for various down-stream tasks, this paper proposed to create a family of expert models in pre-training, and selectively choose one expert to generate representation depending on the target transfer learning task. A simple yet effective k-nearest neighbor strategy is used for picking the best-fitting expert. This paper has extensive experiments including pre-training models on two large-scale image datasets, and evaluated on two transfer learning benchmarks (VTAB and datasets from DAT).",0.1839080459770115,0.16666666666666666,0.17486338797814208
2634,SP:ee58edd03a89f8fa07ba73d3b36b32ad551970da,"This manuscript presents a method for generating protein sequences conditioned on protein structures. The core idea is to represented protein structures by their secondary structures in 3D space. This voxel grid is then encoded into a vector representation and decoded to a distribution over sequences. The authors propose to learn this model jointly with a sequence encoder, combining the sequence and structure representations to decode the sequence during training. For inference, the sequence encoder component is not used. Learning to generate protein sequence conditioned on structure is an interesting and important problem and has been attracting increasing attention from the ML community. Representing structures as voxel grids is an approach worth exploring and flexible structure representations could be promising. However, it isn’t clear to me that this work achieves those goals and comparisons against key baselines (namely Ingraham 2019) are missing. Furthermore, the authors make many unsupported and unsubstantiated claims about their method. Specific comments and questions follow below.","This paper tackle the challenge of designing protein sequences that are consistent with a given 3D fold. To address this challenge, the authors propose a transformer-based generative framework that designs protein sequences conditioned on a given fold. There are two central contributions - the first is a novel fold representation, in which the 3D structure is represented by the voxels of secondary structure elements, and then a fold representation is learned via a transformer-based structure encoder. The second is a joint sequence-fold embedding learning framework. The authors use ablation studies to show that learning a joint latent space between sequences and folds enables the model to better capture the the sequence-fold relationship, improving experimental results. The authors provide a good summary of related work. ",0.1625,0.2047244094488189,0.18118466898954702
2635,SP:ee608c38bc5cba62161a824d237c680050ba3484,"In this paper, the authors proposed a new attention module, named Dual Multi-Scale Attention. Three commonly used methods are combined: multi-scale, channel-attention, and position attention. By introducing the new module (which is a simple combination without any novelty) to ResNet, it SIGNIFICANTLY improves the performance, e.g, 75.20 to 80.02  (and 76.83 to 81.54 for ResNet101) on ImageNet, 36.4 to 41.4 on MS COCO.","In this paper, the authors propose a new attention module that shows better performance and lesser computation than most existing attention modules. Based on this module, the so-called Dual Multi Scale Attention Network is proposed. Several experiments are conducted to verify the performance on image classification, object detection and instance segmentation. Results shows that the proposed network has some advantages than previous works.",0.2465753424657534,0.28125,0.26277372262773724
2636,SP:ee6799af570d8ea4ff6671996140f1d82e7dba0d,"The authors examine trajectory growth of deep ReLU neural networks whose weights come from a (random) “sparse-Gaussian”, “sparse-uniform”, and “sparse-discrete” distribution. They give definitions of these distributions in the paper. They do this by extending the proof of Raghu (2017) so that it can handle more general distributions than the standard Gaussian. They also provide some numerical experiments verifying their theories.","This submission proposes an alternative way to lower bound the trajectory growth through random networks. It generalizes to a variety of weights distributions. For example, the authors showcase their approach on sparse-Gaussian, sparse-uniform, and sparse-discrete-valued random nets and prove that trajectory growth can be exponential in depth with these distributions, with the sparsity appearing in the base of the exponential. ",0.28125,0.28125,0.28125
2637,SP:ee6c7dc9a106d5bebb879ca226723a2fc294b9fb,"The paper provides both theoretical progress and experimental results on certified robustness of top-$k$ predictions. Specifically, on the theory side, the paper shows that the randomized ablation (Levin & Feizi) has $\ell_0$-norm certified radius of top-$k$ predictions. Also, the paper proves that the certified radius is tight for k = 1 and almost tight for k > 1. (The certified radius cannot be larger than “the derived radius plus 1”.) On the experiment side, the paper compares the proposed method to existing competitors and explored the impact of the related parameters.","This paper provides an almost tight l0-norm certified robustness guarantee for top-k predictions against adversarial perturbations, which extends certified radius of the top-1 prediction from Levine & Feizi (2019) to that of the top-k predictions, and the l2-norm certified radius from Jia et al. (2020) to the l0-norm certified radius. The experiments on CIFAR10 and ImageNet show that the proposed method substantially outperforms state-of-the-art for top-k predictions.",0.2826086956521739,0.34210526315789475,0.30952380952380953
2638,SP:ee878ec4dca26f7c082fc452a28b5b03926e9c19,"The paper proposes an IL method based on the f-divergence. Specifically, the paper extends f-VIM (Ke et al., 2019), which uses the f-divergence for IL, by using a sigmoid function for discriminator output’s activation function. This choice of activation function yields an alternative objective function, where the reward function for an RL agent does not directly depend on the convex conjugate of the function f; the paper claims that this independency improves stability of policy learning. This proposed method is named f-VIM-sigmoid. The paper extends f-VIM-sigmoid to the setting of IL with observation and proposes f-VIMO-sigmoid. Experiments on Mujoco locomotion tasks show that f-VIM-sigmoid and f-VIMO-sigmoid perform better than existing methods.","This paper proposes the application of the f-VIM framework (Ke et. al., 2019) to the problem of imitation learning from observations (no expert actions). The authors first identify a potential source of numerical instability in the application of f-VIM to imitation learning – the rewards for the policy-gradient RL are given by a combination of a convex conjugate and an activation function. To alleviate this, f-VIM is reparameterized by curating the activation using conjugate inverse (Equation 8), yielding a potentially more stable reward for deep-RL. ",0.192,0.2696629213483146,0.22429906542056074
2639,SP:ee9150a3bbdc0fa36a2a1876c4de2c9002270a06,"The paper presents a new method for embedding visual images into a state space suitable for effective control by an actor-critic style RL algorithm. They show how a previously explored idea of using a bisimulation between state abstractions and reward sequences to group states that are similar from a decision theoretic perspective can be extended to a continuous deep embedded representation using twin network style learning through standard gradient descent optimization. They call the approach Deep Bisimulation for Control (DBC).  The paper also argues for the correctness of their approach using a contraction proof and a theoretical argument for generalization to new problem domains. The approach contrasts directly with algorithms that use an autoencoder to find a compact representation by reconstructing input frames or predicting future input frames. These approaches necessarily represent enough information to reconstruct both task relevant and incidental details. Experimentally, the paper shows that performance of reconstruction-based approaches degrades by a large and significant amount when extraneous background detail is present in image frames, while the proposed method is immune. The evaluation is done on widely respected benchmark of Deep Mind MuJoCo based articulated figure simulations and a CARLA realistic image simulation of car driving which shows that focusing on task specific detail is important on realistic tasks. ","The paper focuses on how learning state-representations that encode information relevant to the task can improve reinforcement learning from pixels. Often, observations in an MDP can contain information that are irrelevant (“distractors”) to the task at hand and can likely “distract” the downstream RL algorithm used. Unlike existing reconstruction based approaches (which don’t explicitly incentivize ignoring task-irrelevant information), the authors propose Deep Bisimulation Control (DBC) that relies on bi-simulation metrics (as the task-aware criterion) that encode behavioral similarity b/w states with respect to the reward structure. Instead of explicitly learning a bi-similarity distance function, authors enforce the representations which under L1 distances correspond to bi-simulation metrics. DBC demonstrates learning these representations in conjunction with the control policy, reward and a dynamics model. Furthermore, the authors highlight connections to causal inference which can hopefully further provide insights into which “new” reward structures can the learned representations generalize to (since bi-similarity metrics themselves are heavily dependent on the reward structure). Results obtained by the authors demonstrate that DBC can learn task specific representations and a control policy in a robust manner in the presence of distractors on the Deepmind Control Suite and the CARLA simulator. Additionally, the authors also demonstrate how DBC can generalize to new reward functions on Mujoco.",0.15492957746478872,0.15207373271889402,0.15348837209302324
2640,SP:ee9c1549531b0ed933020491aee532835368a862,"This paper devises an analytic method for explainability based on the observation of filter-wise parameter saliency distribution, and tests on several models. And several experiments are conducted to deminstrate the conjecture. The motivation is straightforward and easy to understand. ","This paper introduces a parameter-space saliency map to explore the salient parameters that are responsible for miscalssification. A set of experiments and visulizations are conducted on the salient parameters, leading to several interesting findings, such as, the nearest parameter neighbors share similar semantic information. Besides, the authors are also trying to improve the prediction accuarcy by turning off or fine-tuning the salient parameters. ",0.275,0.16923076923076924,0.20952380952380953
2641,SP:eed69b6741cbda0f04bbe38fd8c11e65ed118319,"This paper considers the problem of novel class discovery (NCD). Specifically, the authors propose a Dual Ranking Statistics method that can leverage both global and local factors for learning novel classes. In addition, a Mutual Knowledge Distillation approach is proposed to explore the relationship between the global and local branches, which can further improve the results. Experiments on several datasets, especially on fine-grained cases, show the benefit of the proposed method.",The paper tackles novel class discovery of unlabeled data via transfer learning-based two-brach learning with pairwise pseudo-labels by two different criteria: similarity on global descriptor and local features. The distinct criteria generate more robust pseudo labels than the single ones and alleviate the negative impact from false pseudo-labels in a complementary manner. The proposed mutual knowledge distillation further facilitates effective mutual learning between two branches. Extensive experiments on standard classification datasets and more challenging fine-grained datasets show that their method has significant advantages over SOTA owing to robust pseudo-labels by dual rank statistics. ,0.2916666666666667,0.21212121212121213,0.2456140350877193
2642,SP:eef7b413ff0071fd73687ae4ccc3bc753df12742,"The paper proposes a new technique to generate embeddings agnostic of the search space. This can be achieved by  first computing the data jacobian of the network with respect to datapoints sampled from different neighbourhoods. This jacobian matrix is then input to a  contrastive network which produces architecture embeddings. The contrastive views in this case are different initializations of the same network, which in turn must yield the same embedding. As these embeddings are high dimensional, they are reduced to lower dimension while ensuring that the distance between the embeddings is preserved in the lower dimensional space and the volume associated with each architecture is also preserved. ","The paper proposes a self-supervised embedding learning method to learn embeddings of various-sized neural network architectures. Each network is first represented as a low rank projection of a Jacobian matrix, where the rows are Jacobians (output-averaged if multivariate) evaluated at various inputs at random initialization time, called EDJM. Since EDJM is random, multiple such representations are treated as positive pairs for contrastive learning. From the contrastively learned embedding, a further dimensionality-reduction stage is optimized to (1) preserve distances and (2) achieve uniform volume for each architecture. The main application of the final embedding is NAS, where the method outperform baselines.",0.19626168224299065,0.20192307692307693,0.19905213270142183
2643,SP:ef00d1cc6981df5591b757e7a46ba9179d1fc50a,"This paper focuses on the problem of developing deep learning systems that can prove theorems in a mathematical formalism -- in this case, MetaMath. This has been a rapidly growing topic in the past few years, as evidenced by the numerous cited works. What sets this work apart from others is its focus on the instrumental task of generating data to train a prover, rather than directly training the prover on human theorems (via reinforcement learning) or human proofs (via imitation learning).","This paper proposes a generative model for proofs in Metamath, a language for formalizing mathematics. The model includes neural networks, which provide guidance about which fact to try to prove next and how to prove the fact from the facts derived so far. The parameters of these networks are learned from existing proofs or theorem statements. The main purpose of this model is to generate synthetic theorems and proofs that can be used to train the neural networks of a data-driven search-based theorem prover. The experiments with the Metamath set.mm knowledge base show the benefits of the synthetically generated proofs for building a data-driven theorem prover.",0.20987654320987653,0.15454545454545454,0.17801047120418848
2644,SP:ef1d9ed2d961186f3bcc7bcb6f58cdd9fa57ecca,"Motivated by the fact that RL algorithms are notoriously sample inefficient from pixels and that humans use attention, the authors propose Attention-driven Robotic Manipulation (ARM), which they claim can be applied to several robotics tasks without prior task knowledge. Compared to current methods which fail to train, ARM trains in only a few hours and is successful at the end manipulation tasks. The authors’ main algorithmic improvements with ARM include 1) a Q-attention agent that extracts interesting pixel locations with an explicit attention module, 2) a confidence-aware critic that leads to increased stability of training, and 3) a data augmentation strategy around expert demonstrations. ","This work focuses on sparse-reward robotic manipulation tasks from image and point cloud inputs, given a few demonstrations, and proposes an algorithm that consists of a Q-attention module and a confidence-aware critic. The Q-attention module is an RL agent, which takes image and point cloud inputs with pixel positions as actions. The image and point cloud observations are then cropped, centered at this pixel position output, and passed down the pipeline to the critic. To make the best use of the demonstrations, the replay buffer is initialized with the demonstrations and further augmented with transitions from demo states, chosen through a keyframe selection process. ",0.16822429906542055,0.16666666666666666,0.16744186046511628
2645,SP:ef3afd5d34fbb7c8310a1dc9d6e49c2f37db07e6,"In this paper, the authors curated two datasets: ImageNet-Vid and Youtube-BB in order to create human-reviewed perceptibly similar sets (Imagenet-Vid-Robust and YTBB-Robust). The obtained datasets are evaluated over 45 different models pre-trained on ImageNet in order to see their drop in accuracy on natural perturbations. Three detection models are also evaluated and show that not only classification models are sensitive to these perturbations, but that it also yields to localization errors.","This paper presents new datasets based on ImageNet and Youtube-BB to assert networks performance consistency across time. Compared to previous work, it uses human labeler to further validate the dataset and discard frames that are deemed too different from the reference one. It provides results on image classification and detection using popular network architectures. Based on these results, the paper claims an accuracy drop of 10 to 16%.",0.20512820512820512,0.2318840579710145,0.217687074829932
2646,SP:ef4369d2452cc6bc680eff611350cbf6f20e2e3b,This work proposes a multi-scale fusion self-attention module to help extract phase-level at different scales. It utilizes convolution operations with kernels of different sizes to achieve this end. The authors conduct experiments on the relation extraction and GLUE tasks to demonstrate its effectiveness.,"The manuscript presents a multi-scale self-attention method for NLP tasks. The aim is to better extract phrase- and word-level features. The main contribution of the proposed method is to apply different kernel sizes for feature extraction and multi-scale attention fusion. Additionally, a mechanism called dynamic sparse module is applied to adjust the weights of the obtained attention matrix.",0.30434782608695654,0.22580645161290322,0.25925925925925924
2647,SP:ef5393fc2cb635a8e9d8817afc28429be68b77df,"This paper proposed a certified defense method for adversarial patches. The paper is motivated by the finding that several existing works on adversarial patch defenses are easily ""breakable"" by in the white-box setting. The idea of the proposed method is derived Interval Bound Propagation (IBP), which is originally proposed for certified defense against adversarial noise. To simplify the certificate training in the patch defense setting (which original scales quadratically with respect to the image size), two randomized training methods are proposed. Lastly, experimental results indeed verify the effectiveness of the proposed method.","This paper attempts to extend the Interval Bound Propagation algorithm from (Gowal et al. 2018) to defend against adversarial patch-based attacks. In order to defend against patches which could appear at any location, all the patches need to be considered. This is too computationally expensive, hence they proposed to use a random subset of patches, or a U-net to predict the locations of the patches and then use those patches to train. The algorithm is tested on the MNIST and CIFAR-10 datasets and it was shown that sometimes the IBP approach is useful for defense, although often with a significant loss on accuracy on clean data (e.g. on CIFAR the loss on clean accuracy is an astounding 300% -- from 66.5% - 35.7%).",0.1827956989247312,0.13385826771653545,0.15454545454545454
2648,SP:ef685ddc158f7b74eec0f2139f14d7443b1192a7,"The work proposes a method to improve conditional VAE with a learnable prior distribution using normalizing flow. The authors also design two regularization methods for the CF-VAE to improve training stability and avoid posterior collapse. The paper is clearly motivated and easy to follow. Experiment results on MNIST, Stanford Drone and HighD datasets show the proposed that the model achieves better results than previous state-of-the-art models by significant margins.","The paper proposes a combination of conditional VAE wtih normalising flows priors and posterior regularisation strategies to capture the diversity of multi-modal trajectories of complex motion patterns. The paper argues that more flexible priors over the latent space can provide posteriors that more closely resemble the trajectories observed in the training data. To this end, the paper presents a derivation of the evidence lower bound for VAEs with normalising flows and discusses the effect of fixing the variance of the posterior to reduce instability during training. Additionally, it shows that conditioning the regularisation on whether or not the dataset contains a dominating mode leads to more diversity and captures minor modes more effectively. Experiments are reported on sequence datasets of handwritten digits, and two datasets with trajectories of vehicles in traffic. ",0.2328767123287671,0.12878787878787878,0.16585365853658535
2649,SP:ef74c56a1e29fc366078c7d3ac2746e5282f496f,"The paper proposes a method for Neural Architecture Search (NAS) with two stages of search. In the first  stage, the topology of the cell is searched with only one operator (skip connection) using graph pruning through gradient descents. In the later stage, there are two ways to search the operators. In the first approach, the found topology is equipped with some operators (e.g., 3x3 convolution,  skip connection, and 3x3 dilated convolution) and then the architecture parameters are optimized. Another approach is to replace all operators with one single operator e.g. convolution. The experiments show that the searching time is reduced significantly compared to DARTS and the results on CIFAR-10 and ImageNet are very competitive.","This work researches the issue of neural architecture search (NAS), which is of significance for practical applications of deep neural networks and has become an active research topic in the past several years. Many methods on NAS have been developed recently. The computational efficiency of search has been one of the obstacles for this line of research.",0.1111111111111111,0.22807017543859648,0.14942528735632185
2650,SP:ef7767ba3c6dc35148cd102148b1f87713b93922,"This paper proposes TrojanNet, a new threat model and corresponding attack in ML security. The paper demonstrates that it is possible for an adversary to train a network that performs well on some benign ""base task,"" while also being able to perform a (potentially malicious) secret task when the weights are permuted in a specific manner. Leveraging tools from traditional security and cryptography, the paper demonstrates that combined with a small piece of software that can apply permutations to the weights, an attacker can then leverage the network to perform the secret task once it is deployed.","This paper proposed a novel an very interesting attacking scenario (the authors called it the Trojan horse attack) that aims to embed a secret model for solving a secret task into a public model for solving a different public task, through the use of weight permutations, where the permutations can be considered as a key in the crypto setting. The authors prove the computational complexity (NP-completeness) of detecting such as a secret model. Experimental results show that it is possible to secretly embed multiple and different secret models into one publish model via joint training with permutation, while the performance of each model is similar to the individually trained models.",0.21649484536082475,0.1891891891891892,0.20192307692307693
2651,SP:ef7cf9c0569adc304bdc8601229ac7579178a871,"This paper proposes a brain-inspired recurrent neural network architecture, named Recurrent Leaky Integrate-and-Fire (RLIF). Computationally, the model is designed to mimic how biological neurons behave, e.g. producing binary values. The hope is that this will allow such computational models to be easily implemented on neuromorphic chips and the solution will be more energy-efficient. On neuromorphic MNIST and CIFAR, the proposed model achieves higher classification accuracy than other listed methods. On ROGUE, a text summarization benchmark, the proposed model achieves competitive performance. ","Recently, it has been shown that spiking neural networks (SNN) can be trained efficiently, in a supervised manner, using backpropagation through time. Indeed, the most commonly used spiking neuron model, the leaky integrate-and-fire neuron (LIF), obeys a differential equation which can be approximated using discrete time steps, leading to a recurrent relation for the potential. The firing threshold causes a non-differentiability issue, but it can be overcome using a surrogate gradient. In practice, it means that SNNs can be trained on GPUs using standard deep learning frameworks such as PyTorch or TensorFlow.",0.11627906976744186,0.10526315789473684,0.11049723756906077
2652,SP:ef9027da9feec26a1fe583b9cd8c77e260bdc00f,"This paper studies the loss landscapes of sparse linear networks. It proves that under squared loss, (1) spurious local minimum does not exist when the output dimension is one, or with separated first layer and orthogonal training data; and (2) for two-layer sparse linear networks, the good property in (1) does not exist anymore when the conditions are violated. The authors also report experimental results to show that two-layer sparse linear networks with two hidden neurons have spurious local minima.","This paper studies the optimization landscape of (deep) sparse linear networks. The study of sparse neural networks is well motivated: on the one hand, there is a lot of experimental evidence that the loss of the trained network does not decrease much after removing a large subset of the connections; on the other hand, there is little theoretical evidence of what makes this behaviour possible (or how to provably construct sparse networks from dense ones). As a result, an investigation of the optimization landscape of sparse networks, even in the simple case of a linear activation function, is timely and interesting to the ICLR community, since it can potentially shed light on the questions above.",0.25609756097560976,0.1826086956521739,0.2131979695431472
2653,SP:efc663895e7ee0d78501c66be7c242d7f882d45d,"This paper studies the problem of learning disentangled representation in a hierarchical manner. It proposed a hierarchical disentangle network (HDN) which tackles the disentangling process in a coarse-to-fine manner. Specifically, common representations are captured at root level and unique representations are learned at lower hierarchical level. The HDN is trained in a generative adversarial network (GAN) manner, with additional hierarchical classification loss enforcing the disentanglement. Experiments are conducted on CelebA (attributes), Fashion-MNIST (category), and CAD Cars (category & pose).",This paper proposed the hierarchical disentangle network (HDN) that leverages hierarchical characteristics of object categories to learn disentangled representation in multiple levels. Their coarse-to-fine manner approach allows each level to focus on learning specific representations in its granularity. This is achieved through supervised learning on each level where they train classifiers to distinguish each particular category from its ‘sibling’ categories which are close to each other. Experiments are conducted on four datasets to validate the method.  ,0.2345679012345679,0.24358974358974358,0.2389937106918239
2654,SP:efef763fd83336660ba89b2070325cca5b989fe4,"The authors introduced the idea of quantum deformed neural network (DQNN) which allows substitution of the positive probabilities in Baysian statistics with complex amplitude inspired by Born representation of quantum wavefunction, thus allowing interference phenomena leading to possible speed up for running neural networks on quantum computers. Combining the complex amplitude and binary neural network the author introduces a new class of quantum neural networks which are the generalized probabilistic neural network. Then, they argue that this class of DQNN can efficiently run on quantum computers using phase estimation algorithms which scale linearly with the number of qubits. By creating entanglement between the activation and weights they show that this new form of DQNN can be simulated on classical computers for certain classes of problems that hold low entanglement. As a numerical experiment they show modest gain in accuracy on real world data both MNIST and fashion MNITS data.","The fundamental idea in this paper is to endow classical signals with a complex Hilberspace structure so as to harness the probabilistic nature of quantum mechaniscs for pattern recognition based on quantum computing principles. Following this idea, the authors consider (probabiistic) binary neural networks and develop a corresponding kind of quantum neural networks building on the concept of quantum phase estimation. They (convincingly) argue that this idea would make good use of the exponential speedup offered by quantum computers but can still be implemented on classical, digital devices. Experiments with image data corroborate this claim and demonstrate that simulations of the proposed quantum deformation showed improved accuracies when compared to  classical probabilistic binary neural networks.",0.2214765100671141,0.28695652173913044,0.25
2655,SP:effbd7dfc21aa044490195e86e14fa5a0d0bf8be, This paper studies the problem of improving the expressive power of GNN models. It computes the automorphism equivalence set for each node and uses the set to enhance the message passing. This method is proven to be more expressive than standard MPNN. ,"In this paper, the author proposed a GNN model that leverages the concept of automorphic equivalence. Specifically, they proposed GRAPE that uses learnable AE-aware aggregators to explicitly differentiate the structural equivalences of each node's neighbors with the aids of various subgraph templates. Moreover, the author theoretically prove that GRAPE is expressive in terms of generating distinct representations for nodes with different AE features. Experiment on real-world dataset proves the effectiveness of GRAPE.",0.2857142857142857,0.16,0.20512820512820512
2656,SP:f010fddc7ee6523ff0afa0ea2b9e1a55027b09de,"The authors present a modification to spatial transformer networks that restricts the transformations to the group of diffeomorphisms. When combined with shape priors, this imposes topological constraints on the mappings produced by the network. These are important considerations in applications such as segmentation tasks where we expect there to be constraints on, for example, the number of connected components. The authors demonstrate the effectiveness of their approach in MNIST experiments and a breast tissue segmentation task. ",This paper propose a novel method to incorporate shape prior in neural networks based on Diffeomorphic transformation. This is useful as by design it preserves certain desirable properties of output such as smooth boundaries and connected components which are of interest in medical imaging applications.   The method is validated on Mnist for data invariance and a medical imaging task for segmentation.,0.19736842105263158,0.2459016393442623,0.21897810218978103
2657,SP:f0163ce76f64a095d124ea46dce4fb2337125157,"**Update after reading the other reviews and authors' responses:** Some valid criticism has been raised and addressed by the authors to a reasonable degree (given e.g. the limitations of a conference-format paper). Given all current information I remain in favor of accepting the paper (my score and confidence remains unchanged).  **Summary:**  The paper investigates the lottery-ticket effect in detail in reinforcement learning tasks. While it has been shown before that lottery-tickets also exist in deep reinforcement learning, this paper performs a thorough analysis using (i) both discrete and continuous action- and observation-spaces, (ii) an on- and an off-policy RL algorithm (as well as a behavioral cloning baseline), and (iii) careful ablations to distinguish the importance of the binary mask and the initial weight values which together form a winning ticket. Various controls and ablations are performed, leading to a plethora of experimental results. The main result is that winning tickets can be found efficiently via iterative magnitude-based pruning in RL tasks, and that in many tasks the binary mask contributes more to performance than the initial weight values. Compared to the supervised (behavioral cloning) baseline, RL performance degrades more rapidly with increasing sparsity levels which is attributed to the distributional shift introduced by exploration in RL. Finally, the paper also investigates the effect of pruning (in winning tickets) of the first-layer weights, and shows that in many cases multiple input dimensions (or regions, which are often semantically meaningful) can be pruned without loss in task performance. This observation could be an interesting approach to producing sparse input representations in RL.  **Main contributions**  1) Investigation of the lottery ticket effect in RL. Significance: though it has been reported before that winning tickets can be found in RL, the paper performs an impressive amount of empirical investigations, including many baselines and ablations across a range of continuous and discrete tasks and an on- and off-policy RL algorithm as well as a supervised baseline. Naturally, results vary somewhat between settings and variations, but the sheer number of results allows to extract trends that hold across many variations. This significantly increases the reliability of the findings. 2) Disentangling the lottery ticket effect through control experiments that allow to attribute the effect strength to (i) the binary mask, (ii) the initial weight-values, or (iii) the layer-specific pruning ratios, which are all combined in a winning ticket. Significance: these control experiments shed some important light on the role of the three components. Interestingly, the binary mask seems to play the most important role in RL tasks, whereas initial weight-values seem to matter more in the supervised setting. This is an interesting, and very consistent insight which might spawn further investigation into the topological structure induced by the winning mask.  3) Investigation of first-layer weights of winning tickets. In many cases whole input dimensions (in continuous tasks) or input regions (in discrete tasks) that are irrelevant to the problem are pruned. This reflects an important (implicit?) regularizing effect - the corresponding weights remain at low magnitudes and can be safely pruned. Investigation of the pruning patterns or pruned dimensions also provides semantic insight which allows for interesting hypotheses regarding how the network solves the task and which information it ignores. Significance: this is an interesting artifact of the analysis of winning tickets in RL. Results are promising and ask for further investigation and perhaps even formulation of a method for sparse/compressed input representations for RL (the identified irrelevant dimensions also transfer to non-pruned architectures). ","This paper investigates the Lottery Ticket hypothesis in the context of deep RL for identification of sparse task representation in low-dimensional control tasks. This is primarily an empirical investigation where several experiments and consequent analysis reveal what a ""winning ticket"" means in case of policy models or Q function approximators given that Deep RL is prone to gradual distribution shift. The experiments also help to identify how standard magnitude pruning will behave under different environment updates, feedback schedules or initialization dynamics.  ",0.04568527918781726,0.32926829268292684,0.08023774145616643
2658,SP:f077ef67a022348d5d4d455cb313a691cfe63e47,"This paper aims to propose a novel framework for neural architecture search. Although there have been many solutions in the literature, the authors try to build a NAS model that is sparse in structure while being similarly effective as conventional dense models.  The method is straightforward - they select a single fixed operation as edges, and channels as vertices, and the problem of NAS can be directly solved by a gradient descent method. The sparsity can also be achieved on the level of channels.","This paper aims to search a sparse but competitive architecture with using a single fixed type of operation by proposing a channel-level neural architecture search (CNAS). Different from most previous NAS works, this paper conducts NAS process on channel-level such that different cell has different topology. CNAS provides a heuristic algorithm to calculate the saliency vector and zero out the channels iteratively until satisfying a given sparsity. This paper performs CNAS on Cifar-10 and ImageNet, and analyzes the topological properties of the final model. The results of experiment demonstrate CNAS can reach a competitive model with dense models searched by baselines. ",0.2289156626506024,0.18269230769230768,0.20320855614973263
2659,SP:f084e2389b58c739098e7f3e8c428f71deb15db3,"This paper introduces a method to improve fairness generalization.  The authors utilize a modified version of mixup where they regularize in favor of invariance of classifier prediction for interpolations between sensitive groups.  The idea is that we expect changes to sensitive attributes not to affect classification decisions.  They introduce a number of regularization terms for both demographic parity and equal opportunity.  Because the mixup interpolations are initially taken as linear interpolations between data --- and thus may not be naturally occurring --- they also introduce a version where samples are taken from a latent space.  They perform assessments on a number of datasets and modalities including Adult, CelebA, and  Jigsaw toxic comments.  They find their methods improve fairness generalization compared to a few baselines, including directly regularizing the model for fairness.","This paper proposed a data augmentation method for training a classifier which is intended to have predictive parity between two identified groups. It is based on the “mixup” idea – samples from the two groups are interpolated between, and the smoothness of this path is encouraged. The authors recommend doing the interpolation in latent space. An optimal solution in a constrained setting is derived, and experiments show the empirical success of the model at this task on 3 datasets.",0.15503875968992248,0.2564102564102564,0.19323671497584538
2660,SP:f08e59bd838b72a61a2ddcbd9027df8bca75ccea,"This submission studies the problem of transfer learning and fine tuning. This submission proposes four insights: Momentum hyperparameters are essential for fine-tuning; When the hyperparameters satisfy some certain relationships, the results of fine-tuning are optimal; The similarity between source and target datasets influences the optimal choice of the hyperparameters; Existing regularization methods for DNN is not effective when the datasets are dissimilar. This submission provides multiple experiments to support their opinion.","This paper studies the role of different hyperparameters in finetuning image recognition models on new target tasks. The authors run a large set of experiments and show that, perhaps non-surprisingly, hyperparameters matter. In particular, they show that momentum, which is typically ignored in finetuning, is quite important, and that the momentum values  that work well depend on the similarity between the source and target datasets. They also show important correlations between momentum, learning rate, and weight decay.",0.2054794520547945,0.19230769230769232,0.19867549668874174
2661,SP:f0962d6f8e5bc3a7dc5488d4d0bd4731fdd63756,"The focus of the presented paper is on formulating the automated discovery of self-organized patterns in high-dimensional dynamic systems. The introduced framework uses cellular automata (game of life) as a testbed for experimentation and evaluation and existing machine learning algorithms (POP-IMGEPs). The goal of the paper is to show that these algorithms can be used to discover and represent features of patterns. Moreover, an extension of SOTA algorithms is introduced and several approaches to define goal space representations are compared. ","The paper uses the continuous Game of Life as a testing ground for algorithms that discover diverse behaviors. The problem is interesting, under-explored, and rich. The  combines a variety of interesting ideas including compositional pattern producing networks (CPPNs) to learn structured primitives. Although the authors do propose formal measures of behavioral diversity and so show performance improvements, at the end of the day this work, like much empirical work on generative adversarial networks, is drifting towards art -- where performance is ultimately judged by human eyes rather than quantiative metrics. ",0.1927710843373494,0.17777777777777778,0.18497109826589597
2662,SP:f0a5dede9342f691734c7279082a8898f54e9883,"The authors proposed a unified message passing model to make a graph neural network to be able to incorporate both label propagation and feature propagation. Compared to previous work, the proposed model can also make use of partial label information in both training and inference stages. Experiments on three OGBN datasets show that the proposed methods achieve promising performance.","The paper proposes a new Graph Transformer (UniMP) based model with the motive of combining two powerful semi-supervised node classification techniques, GNN and LPA. Proposed Graph Transformer unifies feature and label propagation in conjunction to provide a better performance in semi-supervised node property classification task. UniMP also benefits from a masked label prediction strategy which is inspired by [Devlin et al.](https://arxiv.org/abs/1810.04805)",0.15254237288135594,0.13043478260869565,0.140625
2663,SP:f0d57ecb04e778150efd2cde164bf70fa349b886,"The paper proposes a GAN variant, called ChainGAN, which expresses the generator as a ""base generator"" -- which maps the noise vector to a rough model sample -- followed by a sequence of ""editors"" -- which progressively refine the sample. Each component of the generator is trained independently to fool its own separate discriminator, without backpropagating through the entire chain of editors. The proposed ChainGAN model is trained on MNIST, CIFAR10, and CelebA. The paper presents model samples for all three datasets, as well as Inception scores for CIFAR10.","The authors present a straightforward method to improve generative quality of GANs that can allow for fewer parameters by separating the task into a basic-generation followed by a chain of multiple edits to the base generation with different editor networks. The fact that separating the task allows for smaller networks is key to the reduction in parameters.  Each editor is trained separately in alternance, with its associated critic. Authors test their approach mostly on CIFAR10, as well as CelebA and MNIST.",0.23255813953488372,0.24390243902439024,0.2380952380952381
2664,SP:f0e1e582416c286895d04d95a52031ecd5b480be,"The authors study N:M structured sparsity, specifically the challenge of finding N:M transposable masks so that N:M sparsity hardware acceleration can be exploited for part of the backward pass computation in addition to the forward pass. The authors additionally tackle the challenge of adapting models trained with other kinds of unstructured or structured sparsity to specific topology constraints supported by hardware. The authors provide a detailed analysis of the problem of finding transposable N:M masks and asymptotics associated with solving the problems and present a practical solution that achieves good results in practice.","The paper proposes a method to quickly find masks that allow DNN models to train with N:M sparsity. Prior works mainly leverage N:M sparsity for inference (i.e., forward pass), but training cannot directly benefit from N:M sparsity because model weights are transposed during backpropagation to calculate gradients. Therefore, the N:M sparsity constraints may no longer be satisfied during backward pass. The paper suggests that it is possible to find so-called N:M transposable masks, which allow both the forward pass and the backward pass of a DNN training to perform N:M sparse computation. One key challenge in this task is to find such transposable masks in a lightweight way since sparsity masks may need to dynamically change in order to get on-par accuracy as dense training. To quickly find masks that satisfy the N:M transposable mask constraints, the paper proposes to use a greedy-based approximation method. The authors show that such a method adds a modest amount of runtime overhead and scales almost linearly with respect to the input sizes. The paper conducts evaluations against some computer vision (e.g., ResNet) and NLP tasks (e.g., BERT fine-tuning tasks) to show that such a training regime can bring comparable accuracy as dense training. ",0.30927835051546393,0.14018691588785046,0.19292604501607716
2665,SP:f0e5ce3203471c42f457ccdf92ed6626bdd2a786,"This paper proposes two nonstandard identification strategies for the joint distribution of counterfactuals. One is based on a single proxy $Z$ for the unknown confounder with at least $4$ levels, such that $p(y|do(z))$ is identifiable. The other one is based two proxies $Z$ and $W$ with at least $4$ levels for each. Both identification strategies are fully nonparametric. They are given by solutions of a complex system which are nonlinear in the observed distributions. Beyond identification, the paper also proposes estimation procedures and proves the asymptotic normality of the estimators. The estimation procedures are essentially the plug-in version of the system involved in the identification strategy. ","This paper studies the identification and estimation problem of the joint probabilities of potential outcomes. To solve this problem, this paper proposes two sets of identification conditions using covariate information. Furthermore, this paper proposes a novel statistical estimation method based on the augmented Lagrangian method to evaluate the joint probabilities of potential outcomes under the proposed identification conditions. ",0.15454545454545454,0.29310344827586204,0.20238095238095236
2666,SP:f11cb678d88f2f222b2d927c9235a96d59fa8c84,"The paper proposes to learn ultrahyperbolic representations with neural networks. Unlike prior work in ultrahyperbolic representation learning, the paper proposes dealing with an ultrahyperbolic quotient manifold to attain geodesic completeness and enable optimization of parametric models that use this space as an intermediate representation. The optimization of ultrahyperbolic neural networks is then developed in the paper, and an extension to Graph Neural Networks (GNNs) is introduced. Afterwards, the approach is evaluated in various different graph classification tasks.","This paper presents a (graph) neural network in ultrahyperbolic (semi-Riemannian) space that can be used to model hierarchical graphs with cycles. The motivation is that ultrahyperbolic manifold generalizes hyperbolic and spherical manifolds, thus providing inductive bias to those geometries. In order to avoid broken cases, the paper considers ultrahyperbolic quotient manifold such that every two points in the manifold can be connected by a geodesic. The method is evaluated in graph and node classification tasks. ",0.24675324675324675,0.25,0.24836601307189543
2667,SP:f14dd8e540a6b76297d4f8f1c68f68bb023cd9be,"This paper addresses neural networks miscalibration by introducing a soft version of two different calibration measures, namely ECE and AvUC.   To make ECE differentiable, the authors propose to soften the bin membership in ECE calculation and define differentiable bin size, bin confidence, and bin accuracy based on the soft membership function. The membership function is characterized by a categorical distribution (implemented by softmax) over the temperature-scaled Euclidean distances between the confidence score of a sample and the centers of the bins. The centers of the bins are pre-determined as the center of equal-width binning with some pre-known number of bins. The authors use the differentiable ECE as an additional term added to traditional loss functions for training classifiers. They also use this loss alone for post-hoc calibration. In addition to ECE, they soften the newly introduced AvUC loss with similar tricks.  Experiments on benchmark datasets are conducted to demonstrate the effectiveness of the proposed method regarding ECE performance metrics.","The paper presents differentiable loss functions to improve the calibration of deep nets class probability estimates. To achieve this, the authors propose a soft approximation of binning operation, which is at the core of popular measures for model calibration error. Empirical evidence shows that the new approach achieves improved calibration performance compared to existing methods while maintaining accuracy to the extent possible.",0.09146341463414634,0.24193548387096775,0.13274336283185842
2668,SP:f14e55698af04d3b1990c9cc6f86951b56276742,"This paper presents an argument that model capacity differences are not necessarily the root reason for the performance gap between the student and the teacher, and the distillation data matters when the student capacity is greater than a threshold. Based on this, the authors develop KD+ to reduce the performance gap between them and enable students to match or outperform their teachers. In addition, this paper designs experiments to confirm the proposed arguments. ","The paper studies knowledge distillation. In particular, it tries to disentangle the effect of student model capacity and distillation dataset on the performance of the student. The paper goes on to present KD+, a knowledge distillation approach that goes beyond in-distribution data. Experiments on multiple image recognition models and datasets show that KD+ outperforms KD consistently.",0.1643835616438356,0.21052631578947367,0.18461538461538463
2669,SP:f150b1d2a3ad4d9614e1ef434ef18d742ee78e47,"The paper builds on top of prior work in hindsight policy gradients (Rauber et.al.) and trust region policy optimization (Schulman et.al.), proposing a hindsight trust region policy optimization. Conceptually this direction makes a lot of sense, since hindsight is in general shown to be useful when training goal conditioned policies. The formulation generally  appears to be sound and is a straightforward extension of the importance sampling techniques from Rabuer et.al. to the TRPO setting. Experimental results show that the proposed changes bring significant improvements over baselines on sparse reward settings.","This paper augments the TRPO policy optimization objective with hindsight data, where the hindsight data is generated from goals based on trajectories. The key contribution of the paper is based on deriving an on-policy adaptation of hindsight based TRPO, that can be useful for sparse reward environments. The paper draws ideas from existing papers such as HPG and considers the IS based variant of HPG for on-policy, similar to TRPO, that can achieve monotonic performance improvements. Furthermore, the authors introduce a logarithmic form of constraint, by re-deriving the KL constraint and leading to a f-divergence based constraint, which is argued to have useful effects in terms of lowering the variance. Experimental results are compared with baselines including HPG and its variants on standard sparse reward benchmark tasks. ",0.24731182795698925,0.17557251908396945,0.20535714285714288
2670,SP:f16157d7cd025cddd1b7f8024983737cfed9e8d4,"This paper explores a series of incremental variations of existing pruning techniques for compressing Resnet-50 for ImageNet. Specifically, it proposes concentrating all pruning during an early ""era"" of training (the first 20-50 epochs out of 100 total). It also explores hybrids between sparse pruning and structured pruning. Finally, it considers the adversarial robustness of the resulting networks to the FGSM attack. ","This paper introduces a strategy to prune a convolutional neural network during training. To speed up training, the proposed method prunes the weights with the smallest magnitude during only a small number of epochs at the beginning of training, later on continuing training with a fixed sparsity pattern. Several granularity levels for convolutional and fully-connected layers are studied. Furthermore, the robustness of the resulting pruned networks to adversarial attacks is investigated.",0.25396825396825395,0.2222222222222222,0.23703703703703705
2671,SP:f19f24d32d2198e2512cee9f90386a5175255624,"The paper proposes a label-smoothing method upon the low-rank assumption of the output dimension, especially when the output dimension is large. The contribution of this work is two folds: first, highlighted the importance of informative label smoothing through better bound, and second, proposed one label smoothing with low-rank assumption. It is overall a good paper but there are a few concerns: ","This paper theoretically analyzes ""label smoothing” (LS)  with PAC-Bayesian bound and motivated from their analysis, proposes a new method: LORAS.  In their theoretical analysis, they identify that the generalization error depends on the smoothing distribution. So they propose to learn the smoothing distribution in LORAS. In doing so, to overcome the computational issues & overfitting to diagonal smoothing, they propose Low-rank approach which seems to be successful. The authors show experimental results on semantic parsing dataset (ATIS, SNIPS, and TOPv2) where the LORAS shows better performance than no LS, LS, and some other SOTA model (with one exception of LORAS  vs. no LS on ATIS)",0.1875,0.11320754716981132,0.14117647058823532
2672,SP:f1a3e5960a15dd52bfb74d311e70083fbfc9717e,"The paper examines an architectural feature in GAN generators -- self-modulation -- and presents empirical evidence supporting the claim that it helps improve modeling performance. The self-modulation mechanism itself is implemented via FiLM layers applied to all convolutional blocks in the generator and whose scaling and shifting parameters are predicted as a function of the noise vector z. Performance is measured in terms of Fréchet Inception Distance (FID) for models trained with and without self-modulation on a fairly comprehensive range of model architectures (DCGAN-based, ResNet-based), discriminator regularization techniques (gradient penalty, spectral normalization), and datasets (CIFAR10, CelebA-HQ, LSUN-Bedroom, ImageNet). The takeaway is that self-modulation is an architectural feature that helps improve modeling performance by a significant margin in most settings. An ablation study is also performed on the location where self-modulation is applied, showing that it is beneficial across all locations but has more impact towards the later layers of the generator.","The manuscript proposes a modification of generators in GANs which improves performance under two popular metrics for multiple architectures, loss, benchmarks, regularizers, and hyperparameter settings. Using the conditional batch normalization mechanism, the input noise vector is allowed to modulate layers of the generator. As this modulation only depends on the noise vector, this technique does not require additional annotations. In addition to the extensive experimentation on different settings showing performance improvements, the authors also present an ablation study, that shows the impact of the method when applied to different layers.",0.14465408805031446,0.25555555555555554,0.1847389558232932
2673,SP:f1be80ff3839e9408ac1c693412c93d4f2483b95,"Distractions are alterations of states or observations outside the control of the agent.  Conventional learning methods tend to be quite sensitive to them.  This work proposes a method for learning representations robust to such distractions using an encoder-decoder architecture whose encoder uses actions as input, instead of an observation as conventional autoencoders do.  In addition, the paper evaluates two variants of this method that employ an additional regularization term, one being the KL divergence as used by variational autoencoders, the other the $L_2$ norm of the latent activation vector (to avoid penalizing its variance as the KL divergence does).","This paper approaches the problem of representation learning for robotic learning, with a focus on being robust to potentially misleading distractor objects. Concretely, they propose a method which learns a representation of sequences of actions by reconstructing a future state, and uses this representation of actions to learn skills. They show that this leads to some improvement in identifying more diverse ""skills"" in settings where there are external distractors.",0.1188118811881188,0.17391304347826086,0.14117647058823526
2674,SP:f1ebe848f41ba7f65c07419c8b5c8473fcef0b2a," The paper proposes a method for few shot object detection. The key idea is to leverage the similarity of a novel object class with an existing base class, and then train a local classifier for better discrimination. The class similarity is based on semantic word similarity between the classes’ textual names and the new class to base class mapping is an injective mapping. Once the assignment is calculated the feature network is trained so that the features of the new class align with its corresponding base class. Finally further discriminator layers are used which are then trained to classify base and new classes distinctly. Empirical results are shown on PASCAL VOC 2007 2012 and COCO datasets, where the proposed method outperforms existing methods especially in very low shot settings. ","The paper proposes a novel approach for few-shot object detection by first assigning a novel (few-shot) class to a base category (Association) and then disentangling the classification of base and novel classes (Discrimination). After the first step of base training, the proposed approach assigns each novel class to a base class using the WordNet hierarchy. Then, the method aligns the feature distribution of the novel class to the associated base class. Finally, the method proposes to disentangle the classification branches of base and novel classes to remove confusion between base and novel classes. ",0.27906976744186046,0.37894736842105264,0.32142857142857145
2675,SP:f1f2bf25084fcf5ead33606aa51da31e54884eed,"This paper proposes a Dirichlet energy-based method to alleviate the over-smoothing and over-separating problems which are commonly observed in deep GNNs. Different from existing methods that rely on techniques from CNNs or heuristic strategies, this work provides theoretical proof of the lower and upper bound of the Dirichlet energy in GNNs and proposes EGNN which enables deeper GNNs. The effectiveness of EGNN is evaluated on commonly used benchmarks.","This paper proposes Dirichlet energy constrained learning as a generalizable principle to guide the training of deep GNNs through regularizing Dirichlet energy at each layer. Following this principle, a novel deep architecture called Energetic Graph Neural Networks (EGNN) is proposed, which could learn an optimal Dirichlet energy to enable effective training of deep networks. Empirical results demonstrate that EGNN can be trained to achieve better results with more layers and outperform other GNN deepening approaches. ",0.2112676056338028,0.2,0.2054794520547945
2676,SP:f234ce685370ba94d828ba354869e6038b643283,"This paper investigates how one can achieve group fairness under a decentralized setting. The authors develop a theoretical framework for decentralized fair learning algorithms and analyzed the performance of existing approaches including UFL, FFL via FedAvg, and CFL. They provide novel insights showing that UFL<FFL via FedAvg<CFL. They also propose a new federated fair learning algorithm FEDFB by letting each client share extra information about the unfairness of its local classifier with the server, which then computes the optimal samples weights for the following round of local training. The experimental results demonstrate that FEDFB achieves state-of-the-art performance, while still ensuring data privacy. ","The authors propose a novel algorithm to train statistical models respecting fairness criteria like client parity or demographic parity. This problem has been investigated in the literature for the centralized setting and the authors propose to extend FairBatch (FB) to the federated setting. Finally, the authors show experimentally that their algorithm FedFB provides better fairness than when a server centralizes all the clients data. This work is quite novel but its theoretical statements solely rely on very specific use cases and lack clarity.",0.14018691588785046,0.18072289156626506,0.15789473684210525
2677,SP:f24a7a7fc8b74ec71744ce6998c37a01995b6ee3,"The authors propose a new network architecture for multi-agent reinforcement learning. The new architecture addresses three issues: (1) the applicability of existing algorithms to semi-cooperative or competitive settings; (2) the ability to use local rewards during agent training; (3) the credit assignment problem with global multi-agent rewards. The authors address these issues with a new architecture that is comprised of several LSTM controllers with tied weights that transmit a continuous vector to each other, and that are augment with a gating mechanism that allows them to abstain from communicating.","From a methodological perspective, this paper describes a simple bu clever learning architecture with individual agents able to decide when to communicate through a learned gating mechanism. Each agent is an LSTM able to decide at each time point which aspects of its internal state should be exposed to other agents through this gating mechanism. The presentation of this method is clear to a level that should allows the reader to implement this him/herself. It would be great if the code associated to this could be released but the presentation allows for reproducibility. ",0.17391304347826086,0.1702127659574468,0.17204301075268816
2678,SP:f24b5b36d4329213d20b80cf6da2ed289f52890d,"This paper makes an attempt to study the dynamic graph representation learning. The paper proposes a couple tricks for the combination with graph transformer networks. The tricks include sampling, union graph, pretraining etc. Some experiments have been conducted.","In this study, the authors propose a new graph transformer network for dynamic graph representation. To solve the challenges of static graphs learning and the temporal information aggregating, this paper introduces a Dynamic Graph Transformer (DGT) which contains three components: (1) a two-tower Transformer-based method, (2) temporal-union graph construction (3) a complementary pre-training task. Extensive experiments on the two datasets of link prediction and node classification demonstrate the superiority of the model. The ablation studies justify the effectiveness of each module in the DGT model.",0.39473684210526316,0.16853932584269662,0.2362204724409449
2679,SP:f25f1a55b9c3945008f4c769ee1cc6414016da1a,"This paper proposes a user-guided training for CNN to focus more on casual features which are based on human perspective and termed as casually focused convolutional neural network. Human guidance is used to make a rough binary segmentation mask of foreground objects/pixels.    For an input image, mask and label are both utilized to compute final loss. Final loss is composed of 1) activation loss which is computed using the binary mask and last convolution layer features and 2) cross-entropy loss which is calculated using predicted probability and class label of the input image. Images for which binary mask is not available, dummy mask is created as all foreground pixel. Two types of networks, all convolutional layers (CFCN-C) and fully-connected classifiers (CFCN-F) are utilized with the proposed methodology.  Experiments are performed on a total of 4 datasets of natural and medical images. Accuracy and visual activations are compared with baseline CNN, GAIN [1], and both CFCN-C and CFCN-F. ","The paper proposes to alternate the loss of classification CNNs by adding additional loss term that focuses the model's attention on the object present in the image rather than on the background. To do so, the model is provided with an additional input (a binary mask) that is used to guide the learning of the model. The approach is validated on four datasets showing some benefits in terms of classification performance on small-scale datasets while decreasing the classification performance on larger scale datasets.",0.10909090909090909,0.21176470588235294,0.144
2680,SP:f26a952abe712256ad3046d86187c08c6eb2e395,"This work studies the learning dynamics of neural networks in terms of robust and non-robust features. In particular, the authors argue that depending on various factors (e.g. learning rate, data augmentation), neural networks will have learning dynamics according to 1 of 2 pathways. Neural networks will either (1) first learn predictive robust features and weakly predictive non-robust features, followed by predictive non-robust features; or (2) only learn robust features, then overfit the training set, thereby not learning non-robust features. The paper has a good discussion expanding upon the robust/non-robust features model of Ilyas et. al. 2019, interesting experiments measuring what features the models is learning, and a digression that presents further results on non-robust features in different datasets.","The paper posits some phenomena on neural network training: 1. With some proper regularizing effect, NN training tends to learn predictive robust features (and weakly predictive non-robust features) first and non-robust features next. 2. Without regularization, NN training does a similar thing as case 1 first but does not learn predictive non-robust features and overfits the training examples. ",0.19047619047619047,0.39344262295081966,0.25668449197860965
2681,SP:f27bf5238c835413eff4edb3315386543b0aad6c,"The paper focuses on the policy architecture of deep reinforcement learning algorithms. Specifically, the authors apply the probabilistic mixture-of-experts (PMOE) model in the policy of a reinforcement learning agent, where each primitive is a unimodal Gaussian distribution and the gating model is a simple state-conditioned categorical distribution. The authors derive the corresponding policy gradient objective for the PMOE policy.","The paper studies the problem of differentiating through the policy return when the policy is a Gaussian mixture model. The main contribution of the paper is a heuristic approach for computing this gradient. Having defined the policy update, the authors integrate it to two RL algorithms: PPO and SAC. The experiments show that the algorithms with GMMs behave roughly the same as with a single Gaussian save for one (SAC) or two (PPO) environments. On the other side the authors show that their algorithm can learn multiple solutions on a reaching task and that exploration is better behaved on this task too.",0.2903225806451613,0.17647058823529413,0.21951219512195125
2682,SP:f28b29a379b100a68f8bc3e01146f6a7b06aebf8,"The paper presents an evaluation of different models in their capacity to reflect epistemic and aleatoric uncertainty and reviews different methods for uncertainty performance measurement. Models are classifiers trained on ImageNet. The number of models reported is 484.  The analysis also considers the cases when the data is in-distribution and out-of-distribution. The conclusions lead to a group of models (trained with distillation), improving uncertainty estimation performance, and the vision transformers architecture having the best uncertainty estimation performance.    ","The paper provides an empirical comparison of uncertainty estimates obtained from 484 deep neural networks (DNN), trained for image classification tasks on the ImageNet dataset. They compared uncertainty estimation performance of different architectures and training strategies (knowledge distillation) on many quantitative metrics such as AUC-ROC on classification tasks, Area under the risk coverage curve (AURC), etc. The authors finally summarize their findings on what architectures are best at providing uncertainty estimations and how to compare different methods on OoD detection and uncertainty in in-distribution samples. ",0.2,0.1839080459770115,0.19161676646706585
2683,SP:f29168fb83f6f94f6ce04982924f82136595ddb1,This work introduces a continuous Wasserstein-2 benchmark to assess the qualities of different neural optimal transport solvers. The work uses input convex neural networks (ICNN) to construct pairs of measures whose ground truth OT maps can be obtained analytically. This strategy yields pairs of continuous benchmark measures in high-dimensional spaces such as spaces of images. The authors thoroughly evaluate existing optimal transport solvers. The study reveals crucial limitations of existing solvers.,"The authors present a continuous Wasserstein-2 benchmark using input convex neural networks to obtain ground truth continuous OT maps. They evaluate continuous OT solvers based on how well they reproduce the ground truth transport map, how well they approximate the derivative of the potential, and how well they perform in a GAN framework. This provides a basis to evaluate current and future continuous 2-Wasserstein solvers.",0.273972602739726,0.29850746268656714,0.2857142857142857
2684,SP:f2938ae4449d8ca4eef132942c42339209c90985,"This paper studies the problem of link prediction for knowledge graph completion with rule-based methods. Specifically, it builds on a recent strong rule-based method, AnyBURL, for mining rules from a KG, and mainly studies the application of the mined rules. Recognizing the limitations of the Maximum and Noisy-OR rule aggregation strategies used in prior work, this paper proposes SAFRAN, a rule application strategy that clusters rules of the same relation based on their similarity with the hope that redundant rules will be clustered together. The Maximum strategy is then used within each cluster and the Noisy-OR strategy is used to aggregate clusters. Empirical results on FB15K-237, WN18RR, and YAGO3-10 are strong, outperforming embedding-based methods as well as the Maximum and Noisy-OR baselines.","The paper introduces SAFRAN rule application framework to improve upon the existing AnyBURL interpretable rule-based link prediction approach. SAFRAN helps to solve the redundancies that affect the aggregation step in AnyBURL and introduces Non-redundant Noisy-OR (NRNO) to detects and clusters redundant rules before the aggregation step. In several link prediction benchmarks, SAFRAN achieves SOTA performances for rule-based algorithms and in two out of three datasets even beats multiple embedding-based algorithms with good explainability.",0.13846153846153847,0.23076923076923078,0.1730769230769231
2685,SP:f2a32676f88aaeda591223904a57338a1a2b699a,"This paper presents an end-to-end deep retrieval method for recommendation. The model encodes all candidates into a discrete latent space, and learns the latent space parameters alongside the other neural network parameters. Recommendation is performed through beam search. The paper compares the method on two public dataset against several methods (DNN, CF, TDM) and concludes that it can achieve the same result as a brute-force solution in sub-linear time.","The paper presents a method for ""end-to-end"" learning for retrieving top-k items in recommendation system setup. This is achieved by learning the hidden representations of the items and under neural network as a single objective function optimized using the expectation maximization framework. It is claimed that the proposed method achives better results than state-of-the-art tree-based models and those approaches which learn these components separately.",0.2054794520547945,0.2112676056338028,0.20833333333333331
2686,SP:f2bede94ecbf910aeafa0355e1d2576f5716dc7d,"This paper describes a new PyTorch package, NNGeometry, for computing complicated neural network objects, such as the Fisher Information Matrix (FIM) and the Neural Tangent Kernel (NTK). The package uses an abstract representation to allow the user to implicitly choose between different approximations to these objects and automatically makes a bunch of efficient choices ""under the hood"" for the user. The paper concludes with a selection of experiments that compare these approximations as well as verify their validity against Monte-Carlo estimates of these matrices.","This paper introduces a new PyTorch library for computing Fisher Information Matrices and Neural Tangent Kernel (NTK) in deep learning; with applications ranging from Frobenius norm regularization, second-order optimization, and generalization analysis. The authors begin by providing a background on Fisher matrices and NTK and then present the main components of their proposed NNGeometry library (consisting of Layer Collection, Generator, and  Concrete Representations modules). A brief experimental study is provided in the last part of the paper. ",0.24705882352941178,0.2692307692307692,0.25766871165644173
2687,SP:f2ed2231574562ccb4154e423154e1095c58ffa8,"The paper introduces the Graph Information Bottleneck (GIB) which aims to learn the most-informative compressed representation $Z$ given graph $G$ with associated label $Y$. Further, it defines GIB-Subgraph which aims to learn the compressed representation as the subgraph $G_{sub}$ which maximizes the mutual information within the family of subgraphs ${\cal G}_sub$ of $G$. The paper introduces bi-level optimization objective which has the following parts: ","I think this is a nice paper that successfully used information theoretic objective functions for graph representation learning. The authors leveraged the DONSKER approximation of mutual information for a global information bottleneck loss used on the input-space instead of learned latent-space. To help stabilise optimisation, the authors also use bi-level optimisation with more iterations on the inner $I(G, G_{sub})$ as well as automatic masks learning through their $L_{con}$ loss. The authors also showed many experiments on graph classification, denoising, and interpretation tasks. ",0.2028985507246377,0.1590909090909091,0.178343949044586
2688,SP:f2f42c4a7163bf5a94e00d0d0ab05c8ea5e44727,"In this paper, an EVIT method is proposed for vision transformer speedup. It reduces image tokens based on the token attentiveness, which is measured by the class token. The inattentive tokens are reorganized as one to support attentive tokens. Experiments have shown on the benchmarks for visual recognition.","This paper aims to expediting vision transformers by reducing the number of tokens. The main contribution is  the attentive token identification, which is based on calculating the attentiveness of the class token with respect to each image token. Experiments on DeiT and LV-ViT show that the proposed approach is able to successfully reduce the computational cost of the baseline models with nearly no performance drop.",0.3125,0.22727272727272727,0.2631578947368421
2689,SP:f32600d6223672363a45f0797dd6be29e6fd491d,"The paper highlights a problem in existing goal-reaching RL agents, in that they do not explicitly allow for trading off speed (how fast you reach the goal) and reliability (how often you reach the goal). While this tradeoff is implicitly determined by the discount factor in training, the paper asserts that in practice the ability to more flexibly determine this during inference is more desirable. Given this shortcoming of existing work, the paper then proposes ""C-Learning"" which learns a policy conditioned on both a goal and a desired horizon (h) -- i.e., a time limit on the policy. The paper presents favorable results of C-Learning on a few simulated domains compared to existing goal-reaching RL agents.","The paper proposes C-learning, which is an essentially a horizon aware Q-learning. In a nutshell, the authors proposes changing the Q function from Q(s, a) to C(s, a, h) where s is the state, a is the action and h is allowed time horizon i.e. the agent should get to the goal state using less than h states. Since C can be framed as a modified Q, the authors demonstrate that familiar Q-learning properties such as Bellman property and backprop can be used for C-learning. ",0.15,0.1956521739130435,0.16981132075471697
2690,SP:f3287af29c0148119a9b84df7681dbccb4884ef7,"The paper addresses the challenge of intrinsically-driven exploration in tasks with sparse or delayed rewards. First, the authors try to bridge the gap between the objectives of intrinsically-motivated goal generation and maximum state entropy exploration. Then, they propose a new exploration method, called novelty-pursuit, that prescribes the following receipt: first, reach the exploration boundary through a goal-conditioned policy, then take random actions to explore novel states. Finally, the authors compare their approach to a curiosity-driven method based on Random Network Distillation in a wide range of experiments: from toy domains to continuous control, to hard-exploration video games.","This paper proposes novelty-pursuit for exploration in large state space. In theory, novelty-pursuit is motivated by connecting intrinsically motivated goal exploration process (IMGEP) and the maximum state entropy exploration (MSEE), showing that exploring least visited state can increase state distribution entropy most. In practice, novelty-pursuit works in two stages: First, it selects a goal (with largest value prediction error) to train a goal reaching policy to reach the boundary of explored and unexplored states. Second, after reaching goal states, it uses a randomly policy to explore, hopefully can get to unexplored states. Experiments on Empty Room show that the novelty-pursuit with perfect goal reaching policy and visit count information can maximize state distribution entropy. Experiments on Empty Room, Four Rooms, FetchReach and SuperMarioBros show that the proposed method can achieve better performance than vanilla (policy gradient?) and bonus (exploration bonus using Random Network Distillation).",0.2621359223300971,0.18243243243243243,0.21513944223107567
2691,SP:f3373b0ef10578400b8dd9cf54bf71435bd0f726,"This paper is an analysis paper that uses well-known existing pretraining techniques to study the effect of pretrained representations on out-of-distribution generalization performance. The paper mainly uses the VAEs to train the visual representation network. While I believe this is an important topic, the paper only analyzed one pretraining technique and in a visually simple environment.",The paper discusses a study of different learned autoencoder based representations in the context of generalisation (in and out of distribution) in reinforcement learning. It focuses on two types of VAE models and a robotic block reaching/pushing setting. Comparisons are performed to separately test OOD data for the representation and learned policy as well as generalisation to a real world setting after training in simulation. The analysis shows correlations between various properties and metrics and final downstream RL performance  ,0.2033898305084746,0.15,0.1726618705035971
2692,SP:f352e3f7154d22c662b5a80eb2a309ce0345b453,"This work proposes DynamicsAL, a novel AL criteria that selects new training example base on its ability to maximize the training dynamics $\frac{\partial}{\partial t} l(f, y)$.  The authors supplied a practical algorithm (Section 3.2) and compared the proposed criteria with existing methods (Section 3.3).   The authors also derived theoretical result on faster converges leads to better generalization (Section 4) under the assumption that the network has infinite width, and also empirically verified their result based in the non-i.i.d. case. Experiments on standard benchmark and architecture (CNNs on CIFAR/SVHN/Caltech101) are conducted, where DynamicsAL is shown to outperform existing approaches.","The authors address the problem of active learning in the context of deep learning. Instead of querying new examples based on the decision boundary (which in nonlinear models can be tricky or even ill-defined), as it is usually done for linear models, they rely on the train-faster--generalize-better paradigm. Thus, they propose to optimize the ""training dynamics"", which is the time derivative of the loss function in the ultra-wide limit. By using pseudo labeling and subset approximation, their method allows for fast selection of the examples that should be added to the dataset. They justify their active learning strategy through an analysis in the limit of very wide models, through the neural tangent kernel, which is particularly convenient since the NTK does not depend on time in the ultra-wide limit.  They study a quantity that they call ""alignment"" (which measures the correlation between input and output in the NTK space) and show that a higher alignment is related to better generalization (a better bound) and faster training (--> larger training dynamics). They then show that this is also true in the active-learning setting, where the data is no more iid, with the help of some empirical evidence. Finally, they test their method and compare it with other active learning strategies, which they systematically outperform. ",0.19444444444444445,0.0958904109589041,0.12844036697247704
2693,SP:f3620e9c72efa8512c624f0e055aa229b1af949e,"This paper is a follow-up paper of Zhang et al. (2021). In Zhang et al. (2021), the authors proposed a new network architecture, l_infty distance net. By construction, the network is 1-Lipschitz w.r.t. l_infty distance. However, the training procedure therein is problematic. This paper resolves the issue by a new loss design of scaled cross entropy loss + clipped hinge loss. Without using MLP on top of the l_infty distance net backbone, the proposed new training method outperforms the original one in Zhang et al. (2021) and improves over the state-of-the-art by more than 5% for 8/255 and other radiuses. Theoretically, the paper shows the expressive power of l_infty distance net for well-separated data.","This paper proposed a simple modification of $\ell_\infty$ net training, which boosts the accuracy for certified robustness under $\ell_\infty$ attack. It provides a trainable scale on the output of the network and uses a clipped hinge loss. The paper also proves the expressive ability of $\ell_\infty$ nets for classification problems.",0.16666666666666666,0.39622641509433965,0.2346368715083799
2694,SP:f39d50648208f976167aeb0aac498effa4bd0a18,"The paper proposed a Loop-Enc-Dec framework to perform an image reconstruction in a neural decoding task. The solution is based on an end-to-end encoder-decoder model under the guidance of Foreground-attention to enhance the perceptual quality of reconstructed images. The experimental results show visible improvements in the quality of reconstructed images without requiring additional fMRI training data. Also, the proposed method shows improvements in the structural similarity of image reconstruction.","The authors proposed a model to decoding the fMRI signal from the human visual cortex by introducing the Foreground-attention. They also proposed a enc-dec training strategy called Loop-Enc-Dec, which is guided by the F-attention, to successfully reconstruct the visual images from the fMRI data. A higher score based on pairwise SSIM is achieved compared to previous works.",0.2,0.24193548387096775,0.21897810218978103
2695,SP:f3cd4edcd106270bf2b809a5adc3dc8fc86f6f5b,"This paper researched on the recently proposed long-tailed regression problem with self-supervised learning method. Two questions are investigated by this paper: 1) how to measure the similarity and dissimilarity under the regression sense; 2) it is not guaranteed that the sampled with perturbations are similar to the original samples without any noise. The former problem is addressed by providing a formal definition of similarity and the later question is addressed by limiting the volume of noise on the output. Authors report the results on three datasets to demonstrate the superiority of our proposed methods, including IMDN-WIKI-DIR, AgeDB-DIR and NYUD2-DIR.","This paper proposes a novel algorithm SSIR to address the imbalanced problem in regression tasks, which seamlessly combines self-supervised learning and imbalanced regression by giving the formal definition of similarity in the regression task. Besides, the authors specifically propose to limit the volume of noise on the output, and in doing so to find meaningful noise on the input by back propagation. Experimental results show that our approach achieves the state-of-the-art performance.",0.24761904761904763,0.34210526315789475,0.28729281767955805
2696,SP:f40dca43bbc623c43dcbe48e4d385d2cf660dc28,"This paper proposes a method for mathematical problem embedding, which firstly decomposes problems into concepts by an abstraction step and then trains a skip-gram model to learn concept embedding. A problem can be represented as the average concept (corresponding to those in the problem) embeddings. To handle the imbalanced dataset, a negative pre-training method is proposed to decrease false and false positives. Experimental results show that the proposed method works much better than baselines in similar problem detection, on an undergraduate probability data set. ","The paper proposed a hierarchical framework for problem embedding and intended to apply it to adaptive tutoring. The system first used a rule-based method to extract the concepts for problems and then learned the concept embeddings and used them for problem representation. In addition, the paper further proposed negative pre-training for training with imbalanced data sets to decrease false negatives and positives. The methods are compared with some other word-embedding based methods and showed 100% accuracy in a similarity detection test on a very small dataset. ",0.27906976744186046,0.2696629213483146,0.27428571428571424
2697,SP:f410dbc73c4d044a0f3b113ca08f0a6e9e40b07a,"This paper focuses on undirected exploration strategies in reinforcement learning. Following the prior work, this paper proposes an exploration method unifying the step-based and trajectory-based exploration. The authors propose to perturb only the last(linear) layer of the policy for exploration, instead of perturbing all layers of the policy network. Also, the authors use analytical and recurrent integration for policy updates. Experiments show that the proposed exploration strategy mostly helps A2C, PPO and SAC in three Mujoco environments.","This paper proposes Deep Coherent Exploration that unifies step-based exploration and trajectory-based exploration on continuous control. There exists a prior work that bridges a gap between the two exploration methods for linear policies, and this paper generalizes the prior work for various deep RL methods: on-policy (A2C, PPO) and off-policy (SAC). Finally, Deep Coherent Exploration enhances the performance of baseline algorithms and has better performance than prior works (NoisyNet, PNSE) on Mujoco tasks.",0.25,0.2597402597402597,0.25477707006369427
2698,SP:f41c5f442f7cf3de3a4fc1f84015435e29002013,"They main goal of this article is to investigate if it's possible to build a (specific) generative audio model out of short audio snippet. They use a ""progressive GAN""-ish model with an additional reconstruction loss, to explore this paradigm. Thei experiment with a fair amount of use cases, demonstrating some degree of success.","The authors demonstrate that a SinGAN model can be adapted for audio, training a model on a single instance of audio, and generating continuations and inpainting in both the time and frequency domain. They utilize a multi-scale decomposition to create a pyramid of generators and discriminators, and also force reconstructions for one of the points of the generator's latent space. They make several model accomodations to training on the audio domain, including a criteria for automatically tuning the selected scales of their pyramid to the low-frequency power content of the target audio. They show many applications for their technique, including unconditional temporal continuations, conditional regeneration of higher frequency content to create new song sections, bandwidth extension of low resolution audio, inpainting of audio segments, and implicit denoising through the reconstruction signal. Qualitative and quantitative results support their findings, including listening tests and an extensive page of examples. ",0.21818181818181817,0.08,0.11707317073170732
2699,SP:f428ec6777a6b4119612bb27b43fe6128ef23c58,"The paper introduces a new algorithm for parallelizing monte carlo tree search (MCTS). MCTS is hard to parallelize as we have to keep track of the statistics of the node of the tree, which are typically not up-to-date in a parallel execution. The paper introduces a new algorithm that updates the visitation counts before evaluating the rollout (which takes long), and therefore allows other workers to explore different parts of the tree as the exploration bonus is decreased for this node. The algorithm is evaluated on the atari games as well on a proprietary game and compared to other parallelized MCTS variants.","This paper introduces a new algorithm for parallelizing Monte-Carlo Tree Search (MCTS). Specifically, when expanding a new node in the search tree, the algorithm updates the parent nodes’ statistics of the visit counts but not their values; it is only when the expansion and simulation steps are complete that the values are updated as well. This has the effect of shrinking the UCT exploration term, and making other workers less likely to explore that part of the tree even before the simulation is complete. This algorithm is evaluated in two domains, a mobile game called “Joy City” as well as on Atari. The proposed algorithm results in large speedups compared to serial MCTS with seemingly little impact in performance, and also results in higher scores on Atari than existing parallelization methods.",0.3942307692307692,0.3106060606060606,0.34745762711864403
2700,SP:f42b9d3416085bf309889db41c1981a32b7d8b21,"The authors report on an empirical study of emergent behavior of multiple RL agents learning to play hide-and-seek (a sparse reward task). The main point of this paper is that RL agents learning at scale (large number of samples, batch-size 64000). can learn to solve tasks with strategies that are human-interpretable (e.g., using ramps, boxes). Scale also requires various simplifications (e.g., keeping the learning setup as close as possible to a single-agent problem as possible).","Authors in introduce a new competitive/cooperative physics-based environment in which different teams of agents compete in a visual concealment and search task with visibility-based team-based rewards (although There are no explicit incentives for agents to interact with objects in the environment). They show that, complex behaviour emerge as the episode progresses and agents are able to learn 6 emergent skills/(counter-)strategies (including tool use), where agents intentionally change their environment to suit their needs. Agents trained using self-play ",0.13414634146341464,0.13095238095238096,0.13253012048192772
2701,SP:f43350cd5ad80de839715bb0def9efaf1bed39fb,"This paper tackles label shift in supervised learning via distributionally robust optimization. The main idea is to train by solving a min-max problem, where the max problem searches for the worst-case label shift in an Kullback-Leibler divergence ambiguity set. The KL ambiguity set will generate some form of adversarial reweighing of the sample training points, which gives us hope that the learned parameters will perform better in the test data (with shift). The paper proposes to solve the Lagrangian version instead of the constrained version of the DRO problem, and proposes a gradient descent-ascent type of algorithm.","This paper attacks the issue of mismatch in distribution of labels between train and test samples. The authors propose a DRO-based approach which amounts to solving a modified ERM problem. Compared to classical approaches, the proposed method doesn’t entail fitting many different models: just a single model. The method builds on recent progress on solving nonconvex-concave games for approximate stationary points. The resulting algorithm is a mirror-descent scheme with explicit convergence rates, under Setting : train and test label distribution do not match",0.13861386138613863,0.16279069767441862,0.14973262032085563
2702,SP:f44604decdd75946cc41dbdc8f25039e141276fe,"The paper proposes to use Generative Adversarial Networks (GANs) in the context of natural language processing and introduces two models for generating document embeddings. The first model, weGAN, aggregates multiple sets of single-corpus word2vec embeddings into one set of cross-corpus word representations; document embeddings are a function of these updated word embeddings. The second model, deGAN, side-steps word-level embeddings and directly generates document-level representations. For both models, the real examples come from word2vec and tf-idf, while the artificial examples are the ones generated by the network. The authors show that their document embeddings are better than the word2vec/tf-idf baseline at clustering documents according to the corpus they originate from.","The paper proposes extensions of Generative Adversarial Networks to modeling multiple text corpora. Concretely, the paper looks at two problems: 1) given independently pretrained word embeddings from K corpora, finding a common word embdding, 2) extracting document representations from a discriminator of a GAN trained to generate tf-idf vectors. Preliminary experiments show that the proposed approaches outperform baseline classifiers trained with word2vec.",0.1794871794871795,0.3333333333333333,0.23333333333333334
2703,SP:f447505525e50eabf0dd4dd7a09ce763f16a233c,"This paper presents a new reversible flow-based graph generative model wherein the whole graph i.e., representative attributes such as node features and adjacency tensor is modeled using seperate streams of invertible flow model. This allows training of generative model using exact likelihood maximization over the underlying graph dataset.The model avoids encoding any domain specific heuristics and thus can be applied to any structured graph data. The paper focusses it applicability for molecular graphs. Given that this approach avoids sequential generation of graph, it is faster by an order of magnitude than prior models for molecular generation. Empirical experiments on couple of molecular graph data suggets that GraphNVP approach performs as well as prior approach but albeit without any rule checker.","In this paper, a GraphNVP framework for molecular graph generation is proposed. The main difference from the previously proposed models is the use of the invertible normalizing flow idea for the generative model, which doesn’t require a separate decoder for sampling. This architecture is implemented with coupling layers combined with a multi-layer perceptron. The model is evaluated and compared on QM9 and ZINC chemical molecular datasets.",0.13008130081300814,0.23529411764705882,0.16753926701570682
2704,SP:f449c577ca1054d989dbba00eaf37d9f8dfaf7f7,"This paper proposes to explore an interesting application of existing point cloud generative models to the problem of generation of jets: high energy sprays of particles from elementary particle colliders. Jets are analogous in a way to point clouds with a difference in considered per-object features: per-particle momenta are considered for jets contrary to per-point 3D coordinates for point clouds. With sufficient level of quality such generative models could potentially be used instead of costly Monte Carlo simulations.  The authors explore existing point cloud gan-based generative models and propose an adaptation of existing message-passing networks to be used in generators and discriminators of resulting particle cloud gans. Several metrics are proposed for evaluation, including adaptation of existing point cloud generation task metrics, and the distance between momenta distributions for real and generated jets.","This paper introduces a new particle cloud dataset (JetNet) for high-energy physics. The authors set up a benchmark for particle cloud generation with a few physics-inspired and vision-related metrics. As existing point cloud GANs are not suitable for physics applications, they have also developed a new message-passing GAN (MPGAN) and have achieved good empirical performance.",0.10869565217391304,0.2542372881355932,0.15228426395939088
2705,SP:f467d9904b9633d00e56dbc297caae6a21208b18,This paper provides a unified theoretical framework for regularizing GAN losses. It accounts for most regularization technics especially spectral normalization and gradient penalty and explains how those two methods are in fact complementary. So far this was only observed experimentally but without any theoretical insight. The result goes beyond that as the criterion could be applied to general convex cost functional.,"The work studies the relationship between the stability and the smoothness of GANs based on the proposition which was proposed by Bertsekas . It explains many nontrivial empirical observations when one is training GANs, including both of the necessities of the spectral normalization and the gradient penalty, in a theoretical perspective. And the work points out that most common GAN losses do not satisfy the all of the smoothness conditions, thereby corroborating their empirical instability. Meanwhile, it develops regularization techniques that enforce the smoothness conditions, which can lead to stability of the GAN.",0.19672131147540983,0.13043478260869565,0.15686274509803919
2706,SP:f483515944bbc2d86ae50a331ff82ff7c36b299e,"This paper proposes an algorithm learning a kind of universal value function (UVFA), so that given a buffer with a good coverage of transitions it returns the optimal behavior for any reward function or any goal state by computing a simple average.  The idea comes from the fact that the Q-function for a given policy $\pi$ -- that induces a reaching probability from any ($s,a$) $M^\pi(s, a, s', a')$ -- can be expressed as the scalar produce $Q^\pi(s,a) = \sum_{s',a'} M^\pi(s,a, s', a') r(s',a') = \langle M(s,a); r\rangle$. Then, if we learn $F(s,a,z)$ and $B(z)$ such that $M^{\pi_z}(s,a) = F(s,a, z)^T B(z)$ we obtain $Q^\pi_z = \langle F(s,a, z)^T B(z); r\rangle = F(s,a, z_r)^T z_r$ where $z_r = \langle B(z); r\rangle$.  The greedy policy given such a Q-function should maximize (over action) $F(s,a, z_r)^T z_r$. Now, there is a fix point {$F^*, B^*, \pi^*$} such that for all $z$, $Q^{\pi^*}(s, a) = F^*(s,a, z)^T z$, which coincides with the optimal Q-function for the given $z$.   The paper provides an algorithm that learns these optimal $F^*$ and $B^*$. Then, given any reward function, they compute $z_r = \langle B^*(z); r\rangle$ and return the optimal Q-function $Q^*(s,a) = F^*(s,a, z_r)^T z_r$. ","This paper considered the representation learning in reward-free MDPs to encode the optimal policy given any reward function without planning. The proposed unsupervised learning algorithm FB offered two features $F$ and $B$ that encoded the information of the transition to extract the optimal policy. They showed that as long as $F^\top B$ approximates the probability of visiting one state-action to another, then we can extract the optimal policy given any reward function directly. Motived by the nice theoretical properties of $F$ and $B$, they showed that the unsupervised learning algorithm can achieve the same level of learning compared with DQN, DQN with HER, etc. on several benchmark environments. They also incorporated some engineering tricks to make the theory-boosted algorithm more effective.",0.10980392156862745,0.224,0.14736842105263157
2707,SP:f485de73661d59efd25025ddf9778652edb306c1,"In this paper, the authors focus on vehicular motion forecasting on roadways. To this end, they propose an interesting tweak to existing approaches. In addition to maximizing the likelihood of ground truth trajectories, the authors consider an ""unlikelihood"" weighted subloss which penalizes sections of the event space that shouldn't happen with context (such a driving on the wrong side of the road). They do this by sampling trajectories and labeling them with a context checker. They evaluate their approach qualitatively and quantitatively on the Argoverse and nuScenes datasets. They show improved quantitative performance over baselines.","The present paper considers the problem of context integration in probabilistic agent trajectory predictors, particularly Trajectron++. It starts with the observation that these predictors often do a bad job at considering non-drivable areas in their predictions even if context information is injected as part of the input. The paper proposes adjusting the loss function by adding an unlikelihood loss term. This term modifies existing MLE-type losses in a way that discourages context violations (in the present case, it discourages prediction of trajectories that are on non-drivable space). ",0.14583333333333334,0.15555555555555556,0.15053763440860213
2708,SP:f48d609519e10cdf6de5dd0341edd5544d96402c,"Model validation curve typically aggregates accuracies of all labels. This paper investigates the fine-grained per-label model validation curve. It shows that the optimal epoch varies by label. The paper proposes a visualization method to detect if there is a disparity between the per-label curves and the summarized validation curve. It also proposes two methods to exploit per-label metrics into model evaluation and selection. The experiments use three datasets: CIFAR 100, Tiny ImageNet, PadChest.","The paper examines the common practice of performing model selection by choosing the model that maximizes validation accuracy. In a setting where there are multiple tasks, the average validation error hides performance on individual tasks, which may be relevant. The paper casts multi-class image classification as a multi-task problem, where identifying each different class is a different task.",0.12987012987012986,0.16666666666666666,0.14598540145985398
2709,SP:f4a2e63fc2cd7787434a51f3a9511ed64b6a7e0d,"The paper provides a interesting direction in open question answering. In particular, it proposes an open QA problem over both tabular and textual data, and present a new large-scale dataset Open Table-and-Text Question Answering (OTT-QA) to evaluate performance on this task. Two techniques are introduced to address the challenge of retrieving and aggregating evidence for OTT-QA. Results show that the newly introduced techs bring improvements.","In this paper, the authors introduce the task of open domain QA using table and text. Unlike recent tasks on table and text retrieval, where the table associated with the text is known, in this task both tables and text need to be retrieved from a large collection. Similar to the recent HybridQA task, questions may require fusing information both tables and text to answer questions. The dataset has been constructed by reusing the Hybrid QA dataset as well as crawling additional tables and passages from Wikipedia. Since the questions in the dataset may be non-contextual (for instance, not explicitly mentioning the name of a country when the data is only for that country), the authors used crowd-sourced workers to insert words or phrases from the section title, caption etc and make the question self-contained. However, this can cause the questions to become unnatural and excessively long  - the authors manually select the 25% worst questions and get them refined by a second set of annotation tasks. Additionally, to include new samples beyond Hybrid QA, they collect 2200 new QA pairs using the additional tables crawled and include them as part of the dev and test set. The exact answer in the table is annotated using distant supervision and has an extraction accuracy of 85%.  The overall dataset contains 41.5K questions in train and approximately 2K questions each in the dev and test set.",0.24285714285714285,0.07172995780590717,0.11074918566775244
2710,SP:f4d222bb790b8a0c1613aa56d0778817eca75506,"The paper proposes to quantize activation outputs in FGSM training. The algorithm itself is not novel. The straight through approach for training quantized network has been used in previous papers, as also pointed out by the authors. The new thing is that the authors found that quantization of activation function improves robustness, and the approach can be naturally combined with FGSM adversarial training. Experimental results show comparable (and slightly worse) results compared to adversarial training with PGD, while the proposed approach is faster in training time. ","This paper proposes to use a  stochastically quantized network combined with adversarial training to improve the robustness of models against adversarial examples. The main finding is that, compared to a full precision network, the quantized network can generalize to unseen adversarial attacks better while training only on FGSM-perturbed input. This provides a modest speedup over traditional adversarial training.",0.1744186046511628,0.2542372881355932,0.20689655172413793
2711,SP:f4db6a77d6afe5ccbefcdd0f7550dc7669843f58,"This paper studies existing sampling schemes employed in training graph neural network architectures (e.g., FastGCN [Chen et al.] and LADIES [Zon et al.]) that are improvements to graph convolutional networks (GCN) [Kipf & Welling 2017] from a matrix approximation perspective (looking a Frobenius norm).  The paper focuses on layer-wise sampling (cf. node and subgraph sampling) and observes that there are two drawbacks in common practice layer-wise sampling. First drawback is current probabilities (probability distributions) used for sampling are sub-optimal. The reason the paper gives is that a core assumption made by certain GCN schemes such as FastGCN and LADIES do not hold in datasets such as Reddit and OGB. Second drawback is the implementations of these schemes slightly deviate from their respective theoretical results. The implementations use sampling without replacement, and thus introduces bias.  To this, the paper presents new sampling probabilities (uniform proposal distribution), and an algorithm to reduce the bias. With these adjustments, training of GCN converges faster and potentially leads to higher prediction accuracy (for node prediction). Theoretical analysis is presented and experiments are conducted on common benchmarks (Reddit, ogbn-{arxiv,proteins,products,mag}). ","This paper revisits layer-wise sampling methods of graph neural networks by addressing issues such as sub-optimal sampling probabilities and the approximation bias due to the usage of sampling without replacement. This paper also presents a new metric to evaluate the performance of the sampling strategy. Through comprehensive experiments, the authors validate the effectiveness of their proposed methods.",0.12105263157894737,0.3898305084745763,0.18473895582329317
2712,SP:f4f12cb05a36fbd1d301ae1a1b5aeddf84e6e500,"Summary:   The paper is dedicated to validating the lottery tickets hypothesis and delivering an effective one-time pruning. The authors investigate dynamical systems theory and inertial manifold theory to offer a theoretical justification. Specifically, they reduce the high-dimensional system of dense networks onto inertial manifolds to obtain a low-dimensional system regarding pruned subnetworks. Experiments on CIFAR and ImageNet with ResNet-18 and ResNet-32 validate the effectiveness of the proposal. ","This work aims to theoretically verify the lottery ticket hypothesis and the existence of winning lottery tickets. Dynamical systems and inertial manifold theory are used.  Lots of mathematical proof and definitions are included in the papers, and experiments are conducted to test the performance of the proposed method.  ",0.25,0.375,0.3
2713,SP:f4fc78afa84a20e4b7ceee32e9e1d2bf3bf0edb0,"The paper attempts to formally explore the necessary and sufficient conditions for compositional representations, leveraging the formal tools from group theory. While the ideas look potentially promising, the presentation is fundamentally flawed, with certain key notions left without formal definitions. As a consequence, it becomes impossible to estimate the theoretical significance of the contribution or use the obtained results in practice.","This paper applies concepts from group theory to help find necessary and sufficient representations on the presence of compositionality in representations and on mappings between them.  This topic is very important, as people tend to use ""compositional"" in many ways, often not explicitly defined.  The paper, however, is hard to follow, because the main concepts and theorems are not adequately illustrated with examples.  In the final section, when examples are provided, it's still not clear how they apply to representation learning, the topic of this conference.  Thus, while the topic is very relevant and the approach welcome, it is hard to know what lesson we have learned from the theorems in the paper.",0.2786885245901639,0.14912280701754385,0.19428571428571426
2714,SP:f4ff50a3da561f589df8ba890626f51efb5dcd1d,"This paper proposes a teacher-student training scheme to incorporate the useful information of trajectory to improve the predictive performance of model-free methods. The teacher network tries to ""guide"" the student network at the training stage by presenting an interpretation of the trajectory. The guidance is implemented by adding to the loss function a regularization term that penalizes the ""distance"" between the teacher's output and the hidden states of the student. The proposed method was tested and compared to other model-free methods.","This paper proposes a learning framework for predicting the labels of dynamic systems. Unlike existing model-based approaches and model-free approaches, the proposed model takes a middle ground and uses a knowledge distillation-based framework. It uses a teacher model to learn to interpret a trajectory of the dynamic system, and distills target activations for a student model to learn to predict the system label based only on the current observation.",0.2,0.2361111111111111,0.2165605095541401
2715,SP:f5176a9f6a90964e0650d7c1e35eb13c1113fd74,"This paper proposes an efficient S/T protocol meta-learning algorithm. Specifically, in order to reduce the number of required target models and the high computational cost, only the target models on those hardest tasks are constructed by fine-tunning the pre-trained network, then the knowledge distillation is used to match the task-specific solvers to target models in the output space. Experiment results verify the effectiveness of the proposed algorithms. ","This paper investigated the S/T meta-learning framework which is not widely used due to the huge computational cost. The proposed method estimates the hardness of tasks and selects the target models of a small ratio of hard tasks. Then, the meta-model is learned with the S/Q meta-loss and the knowledge distillation loss between the selected target models and solvers. Experiments show that the proposed method outperforms the two classic meta-learning methods with the cost of constructing target models. ",0.3333333333333333,0.2857142857142857,0.30769230769230765
2716,SP:f55167c38de1d6b8528b2d4ef865f5e2e87a5bdc,The paper proposes a new FL method that computes in every communication round for each client a personalized model as starting point for the next round of federation. The paper defines the client-specific objective as some loss function of the weighted combination of all (or subset) models on a client-specific validation set. This personalized weighted combination of the models especially fits situations where not all clients have congruent objectives such as in non-IID settings. The paper evaluates the proposed FL algorithm on standard datasets for image classification by comparing to alternative FL methods. ,"**Paper Summary:** The paper addresses an important topic in federated learning which is personalization. The authors propose a two steps process to achieve the personalization: 1. Figuring out which models to send to which clients; 2. Computing their personalized weighted combinations for each client. To determine the weights, the authors use first order approximation. ",0.10416666666666667,0.18518518518518517,0.13333333333333333
2717,SP:f554da725b64a1c3aa0b5664169efe51316ed16e,Overview and contributions: The authors propose the ModifAE model that is based on an autoencoder neural network for continuous trait image modifications. ModifAE requires fewer parameters and less time to train than existing generative models. The authors also present experiments to show that ModifAE produces more convincing and more consistent continuous face trait modifications than the current baselines.,"The paper is about changing the attributes of a face image to let it look more aggressive, trustworthy etc. by means of a standalone autoencoder (named ModifAE). The approach is weak starting from the construction of the training set. Since continue social attributes on face images does not exist yet, CelebA dataset is judged by Song et al. (2017) with continuous face ratings and use the predicted ratings to train ModifAE. This obviously introduces a bias driven by the source regression model. The hourglass model is clearly explained. The experiments are not communicating: the to qualitative examples are not the best showcase for the attributes into play (attractive, emotional), and requires to severely magnify the pdf to spot something. This obviously show the Achille’s heel of these works, i.e., working with miniature images. Figure 5, personally, is about who among modifAE and stargan does less bad, since the resulting images are of low quality (the last row speaks loud about that)",0.27586206896551724,0.09815950920245399,0.14479638009049775
2718,SP:f5783ca08d51aa886277c95f86438981e3e74810,"This paper proposes an architecture search method for deep convolutional neural network models that progressively increases the number of filters per layer as well as the number of layers, and the authors refer to this general approach as boosting networks. The algorithm for increasing the number of filters is based on split linear Bregman iteration, and the algorithm for increasing the number of layers proceeds block by block, increasing the layers per block until the accuracy does not increase. The experiments convincingly demonstrate gains in performance and smaller network sizes compared to baseline models, naive boosting methods, and a related method called Autogrow.","This paper focuses on topic of searching for the optimal architecture for the deep network. Building on the split linearized bregman iteration strategy, the authors propose two practical algorithms to boost network, namely GT-filters Alg and GT-layers Alg. The proposed algorithms can simultaneously grow and train a network by progressively adding both convolutional filters and layers. The experiments conducted on VGG and ResNets display the comparable accuracies between the BoN and the standard big models, but with much more compact representations and balanced computational cost.",0.1941747572815534,0.22988505747126436,0.2105263157894737
2719,SP:f58299e9a0a1bb4cc1b3065de05de792546626d7,"This work suggests a new model incorporating deep topic model (text decoder),  VHE (image encoder), and GAN. The topic model and the VHE shares the topic parameters, and the GAN generate an image regarding the topic. Then, for ZSL, the image is encoded to corresponding topic parameters, and the parameter can tell which text description (unseen) is matched with the highest probability. GAN model is used to generate an image given the topic distribution. During the training of the GAN, the VHE and topic model is jointly trained and can enhance the ZSL performance marginally.","Paper Summary: This paper studies the zero-shot learning problem with deep generative models. More specifically, it proposed a hybrid framework that combines VAEs (more precisely, the variational hetero-encoder or VHE) and GANs all together. The entire model is composed of an image encoder (Weibull upward-downward variational encoder), a text decoder (Poisson Gamma belief network), and an image generator (generative adversarial network). Once learned, the generative models can be directly used for zero-shot classification and various image generation applications. In the experiments, two benchmark datasets CUB and Oxford-Flowers are used.",0.15789473684210525,0.1595744680851064,0.15873015873015872
2720,SP:f5c1034fb2f5310c11abff0020b3b665ee9d9088,"The authors train neural networks completely under an MPC setting and get accuracy results that are close to training in the clear. They utilize many techniques and tricks in a clever way, such as replicated secret sharing, domain conversion, quantization, oblivious selection and so on. They run experiments on MNIST and Fashion-MNIST datasets to find that training under an MPC setting slows down the training considerably by increasing the number of iterations required for convergence of the model with an accuracy of 98.5%. ","The paper presents a secure multi-party computation (MPC) implementation of training several neural network architectures on MNIST. A 3-party semi-honest setup is considered with every individual party being honest-but-curious about the inputs of the other two parties. For a neural network with two convolution and two fully-connected layers, the paper reports the accuracy of 98.5% in 150 epochs of secure MPC training. The main contribution of the paper is to present an interesting combination of known MPC building blocks that are carefully selected from the literature. ",0.15294117647058825,0.13978494623655913,0.14606741573033707
2721,SP:f5dcd5cbcfc1a465e3791c0cc42c594845122a26,"This paper studied the information bottleneck principle for deep learning. In the paper by (Schwatz-Ziv & Tishby 17'), it is empirically shown that the mutual information I(X;T) between input X and internal layers T decreases, which is called a compression phase. In this paper, the author found that the compression phase is not always happening and the shape of the curve of I(X;T) highly depends on the ""bining size"" which is used for estimating mutual information by (Schwatz-Ziv & Tishby 17'). Then the authors proposed to use a noisy DNN to make sure the map X->T is stochastic, then proposed a guaranteed mutual information estimator. Then some empirical results are shown.","This paper provides a principled way to examine the compression phrase, i.e, I(X;T) in deep neural networks. To achieve this, the authors provides an theoretical sounding entropy estimator to estimate mutual information.  Empirically, the paper did observe this compression phrase across both synthetic and real-world data and relates this compression behavior with geometric clustering. ",0.11206896551724138,0.22413793103448276,0.14942528735632185
2722,SP:f5e27c7a2ae2bda209fb5befbc3ea366b4d71adc,"1. Summary: The authors proposed a deep neural network-based model to generate responses fro task-oriented dialogue systems. The model mainly contains two parts, the first part is to retrieve relevant responses based on question and encode them into templates, the second part is a decoder to generate the response based on the encoded templates and input utterances.","This paper describes a method to incorporate candidate templates to aid in response generation within an end-to-end dialog system. While the motivation and task setup is interesting, the paper is clearly unfinished. Most jarringly, Table 2 which should contain the main results comparing the proposed RGTI model to existing baseline models is not filled in, and there appears to be no table showing results of the ablation study briefly described in Section 3.4.",0.15254237288135594,0.11842105263157894,0.13333333333333333
2723,SP:f6277acaa779b79d58b41fdcbd2a5dc02697cc3f,"	The authors propose a generalized neighborhood message aggregation function for GNNs. The proposed choice of generalized aggregation functions is SoftMax and PowerMean, which generalizes Max and Mean functions and interpolates them. Additionally, they propose a variant of these two methods, which can also encompass the Sum function. By making the components of these generalized aggregator functions differentiable, the GNNs can choose an approximate instantiation of the aggregation function that best optimizes the task. ","This work proposes a generalized aggregation function for graph neural networks. This generalized aggregation function can cover commonly used aggregation functions (i.e., mean, max, and sum) by particular setting of hyperparameters. Also, these hyperparameters can be learned with model in an end-to-end fashion instead of being predefined manually. The experimental results on OGB is impressive and can demonstrate the effectiveness of the proposed approaches. ",0.2602739726027397,0.2835820895522388,0.2714285714285714
2724,SP:f643363fb9654443375b1772cd88b53dbe1bed87,"This paper proposes a novel MARL framework named FSV, which incorporates the idea of energy-based policies and an efficient linear decomposition architecture in the joint action-value function with multi-agent maximum entropy reinforcement learning. Besides, the authors propose the IGO, which extends the IGM in stochastic policy cases. FSV suits in both the discrete and continuous action space scenarios. Experiments conducted on two simple examples with discrete and continuous action settings show that FSV could overcome the relative overgeneralization problem with the proper temperature setting. Furthermore, FSV in the challenging SMAC benchmark outperforms VDN, QMIX, and QTRAN in three scenarios.","The paper proposes a Q-factorization method by assuming an energy-based policies model. Q-functions are formulated as soft value functions with the energy parameters, and this adoption renders the function factorization more flexible compared to existing ones. The proposed solution applies to continuous-action tasks, a feat left unconquered by some of the existing methods. Authors exhibit that FSV outperforms others in various environments characterized by local optima.",0.16666666666666666,0.24285714285714285,0.19767441860465115
2725,SP:f6624fed0b38b3937355e3b4c9e4c1070d60dcc3,"This paper aims to adapt the standard neural architecture search scheme to search a two-input convolutional neural network for video representations. To this end, the paper formulates a direct acyclic graph with two input nodes (for RGB image and optical flow), where each node represents some pre-composed layers and edge represents the data flow with a trainable weight. The searching policy is a modified evolutionary algorithm, which is guided by the trainable weights on the edge, and a set of graph limitations are in-place to avoid over-complicated graphs. The best-selected model outperforms previous baselines and achieves a new state-of-the-art on two video datasets.","This paper is a neural architecture search paper. In particular, it applies this to finding better neural architectures for video understanding, emphasizing exploring the video temporal resolutions needed and how to combine intermediate representations capturing appearance and motion. It introduces a somewhat new algorithm for connection-strength-weighted architecture evolution focused on this high-level information fusion problem of video understanding.",0.15315315315315314,0.2786885245901639,0.19767441860465115
2726,SP:f66b8d030e2dfef6e9c4fc7b35abd996d957a3fc,"This paper proposes a meta-learner that learns how to make parameter updates for a model on a new few-shot learning task. The proposed meta-learner is an LSTM that proposes at each time-step, a point-wise multiplier for the gradient of the hidden units and for the hidden units of the learner neural network, which are then used to compute a gradient update for the hidden-layer weights of the learner network. By not directly producing a learning rate for the gradient, the meta-learner’s parameters are only proportional to the square of the number of hidden units in the network rather than the square of the number of weights of the network. Experiments are performed on few-shot learning benchmarks. The first experiment is on Mini-ImageNet. The authors build upon the method of Sun et al, where they pre-train the network on the meta-training data and then do meta-training where the convolutional network weights are frozen and only the fully-connected layer is updated on few-shot learning tasks using their meta-learner LSTM. The other experiment is on Omniglot 20-way classification, where they consider a network with only full-connected layers and show that their meta-learner LSTM performs better than MAML.","This submission proposes NORML, a meta-learning method that 1) learns initial parameters for a base model that leads to good few-shot learning performance and 2) where a recurrent neural network (LSTM) is used to control the learning updates on a small support set for a given task. The method is derived specifically for full connected neural networks, where the meta-learner produces gating factors on the normal gradients (one for each neuron that the parameter is connecting). The method is compared with various published few-shot learning methods on miniImageNet, and an ablation study and detailed comparison with MAML is presented on Omniglot.",0.16901408450704225,0.34285714285714286,0.22641509433962265
2727,SP:f672b0e2321eb48b3969b42bef1c55cec4906cce,"This paper proposes using Divergence Correction to compose max ent policies. Based on successor features, this method corrects the optimistic bias of Haarnoja 2018. The motivation for composing policies is sound. This paper addresses the problem statement where policies must accomplish different linear combinations of different reward functions. This method does not require observation the reward weights.",The authors introduce Divergence Correction (DC) for the problem of transfer learning by composing policies. There approach builds on GPI with a maximum entropy objective. They also prove that DC solves for the max-entropy optimal interpolation between two policies and derive a practical approximation for this algorithm. They provide experimental results in a gridworld problem and study their approximate algorithm in two continuous control problems.,0.15789473684210525,0.13636363636363635,0.14634146341463414
2728,SP:f676894db5781369ec25d27ccf44e51c12d081ea,"This paper addresses the problem of constructing a sentence embedding using a generative transformer model which encodes semantic aspects and language-specific aspect separately. They use transformers to encode and decode sentence embedding, and the objective reconstructs input with a latent variables (language variables for each language and semantic language).  These latent variables are sampled from multivariate Gaussian prior, and the learning uses evidence lower bound (ELBO) for variational approximation of the joint distribution of latent variables and input. ","This paper presents a bilingual generative model for sentence embedding based variational probabilistic framework. By separating a common latent variable from language-specific latent variables, the model is able to capture what's in common between parallel bilingual sentences and language-specific semantics. Experimental results show that the proposed model is able to produce sentence embeddings that reach higher correlation scores with human judgments on Semantic Textual Similarity tasks than previous models such as BERT. ",0.17721518987341772,0.18666666666666668,0.1818181818181818
2729,SP:f678d71f2069174960ce68f8373c5bda1812fcaf,"This paper introduces the Neural Rendering Model (NRM), a generative model in which the computations involved in inference correspond to those of a CNN forward pass. The NRM’s supervised learning objective is lower bounded by a variant of the cross-entropy objective. This objective is used to formulate a max-min network, which has a particular type of weight sharing between a standard branch with max pooling / ReLUs and a second branch with min pooling / NReLUs. The max-min objective and network show strong performance on semi-supervised learning tasks. ","The paper claims to propose a novel generative probabilistic neural network model such that its encoder (classifying an image) can be approximated by a convolutional neural network with ReLU activations and MaxPooling layers. Besides the standard parameters of the units (weights and biases), the model has two additional latent variables per unit, which decide whether and where to put the template (represented by the weights of the neuron) in the subsequent layer, when generating an image from the class. Furthermore, the authors claim to derive new learning criteria for semi-supervised learning of the model including a novel regulariser and claim to prove its consistency. ",0.16483516483516483,0.14285714285714285,0.1530612244897959
2730,SP:f68087fb27b761dc1b71889ab84723526b621a6c,"This work proposes a framework for solving de-mixing problems. The hard constraints from human inputs about a specific problem are relaxed into continuous constraints (the ""slow"" reasoning part), and a reconstruction loss measures the fitness of the inferred labels with the observations (the ""fast"" pattern recognition part). Due to the relaxation inference becomes an optimization problem, and on a Sudoku task and a crystal-structure-phase-mapping recovery task (both de-mixing tasks), the proposed method gets very good performance (100% for all Sudoku tasks including one in the appendix).","This paper proposes a new encoder-decoder framework that combines prior knowledge-based regularization and constrained reconstruction for unsupervised and weakly-supervised classification in structure rich scenarios. This framework injects prior knowledge in the form of relaxed constraints that act as regularization during the training of the encoder network. Some of the constraints concern sets of training examples. In this case, the paper proposes corresponding sampling schemes. Three experiments demonstrate the efficacy of the model. The first is a synthetically created 4x4 Sudoku made of overlaid MNIST digits. The other two are based on predicting crystal structures from x-ray diffraction measurements. Here, the first experiment is on simulated data for the Al-Li-Fe oxide system, while the other is performed on real measurements for the Bi-Cu-V oxide system.",0.23076923076923078,0.1590909090909091,0.18834080717488788
2731,SP:f686bbac0c991408e1723e1590faf645d62131bc,"This paper investigates maximum entropy (MaxEnt) inference and compares it to a Bayesian estimator and regularized maximum likelihood for finite models. To assess the accuracy of the different estimators, the authors use the average KL-divergence between the ground truth and the estimator, where the average is computed over all datasets of a given size $M$ and all probabilistic models of size $n$ (generated by some prior, either a single Dirichlet or a mixture of Dirichlets). Using numerical experiments, the authors find that the performance of MaxEnt deteriorates for sparse data generated from uniform models. However, by exploiting knowledge about the order of probabilities, MaxEnt can outperform regularized maximum likelihood. ","This paper considers the maximum entropy (MAXENT) method for estimating underlying probabilities over a finite alphabet, i.e., the multinomial model. The authors compare MAXENT with the regularized maximum likelihood, that is the Bayesian estimator under the Dirichlet prior with a common hyperparameter, and the Bayesian estimator with a general Dirichlet prior in terms of the Bayes risk, i.e., the KL-divergence from the true distribution to the estimated distribution averaged over the prior. The authors also consider the case where the prior is extended to the mixture of Dirichlet distributions. These comparisons are done numerically with synthetic data.",0.21818181818181817,0.24,0.2285714285714286
2732,SP:f68cb310366c55ef0bb74f3ec61cf95eb62f8f9c,"To enable robust policy learning with image observations, the paper proposes a simple data augmentation technique that can be used with existing model-free reinforcement learning algorithms. It defines a notion of optimality invariant state transformation which preserves the Q function. An example of such transformations can be random image translations. It uses these transformations to (i) transform the input images, (ii) average the target Q values, and (iii) average the Q function themselves. Using this simple technique, they are able to get SOTA on DM control tasks and Atari 100k benchmark. On DM control tasks, it’s able to outperform SAC trained on state representations. Additionally, the paper provides ablation studies on different image transformations and robustness analysis with respect to hyperparameter settings.","This paper investigates data augmentation in the context of RL and proposes a novel augmentation algorithm to enabling robust learning directly from pixels without the need for auxiliary losses or pre-training. The authors propose to average both the Q function and its target over multiple image transformations. The experiments on DeepMind control suite and Atari 100k benchmark show that their method outperforms previous model-free, model-based and contrastive learning approaches.",0.1532258064516129,0.2638888888888889,0.19387755102040816
2733,SP:f6af733aa873bf6ee0f69ec868a2d7a493a0dd0b,"The suggest two improvements to boundary detection models: (1) a curriculum learning approach, and (2) augmenting CNNs with features derived from a wavelet transform. For (1), they train half of the epochs with a target boundary that is the intersection between a Canny edge filter and the dilated groundtruth. The second half of epochs is with the normal groundtruth. For (2), they compute multiscale wavelet transforms, and combine it with each scale of CNN features. They find on a toy MNIST example that the wavelet transform doesn’t impact results very much and curriculum learning seems to provide some gains. On the Aerial Road Contours dataset, they find an improvement of ~15% mAP over the prior baseline (CASENet).","The main idea of the paper is adding a curriculum learning-based extension to CASEnet, a boundary detection method from 2017. In the first phase, the loss emphasizes easier examples with high gradient in the image, and in the second phase, the method is trained on all boundary pixels. This change seems to improve edge detection performance on a toy MNIST and an aerial dataset. ",0.16101694915254236,0.2923076923076923,0.20765027322404372
2734,SP:f6b70565d5b35e145ed9f8cae717dee238f0086c,This paper studies the problem of estimating a vector valued regression function by neural networks. They provide a bound on the in-sample prediction error for a neural network estimator under two types of regularizations; one that induces connection sparsity and another that induces node sparsity. The in-sample error is bounded by the in sample error of an estimator computed in the noiseless case.,"This paper studies mean-squared-error bounds for neural networks with small $\ell_1$-norm. The use of $\ell_1$-norm constraint is analogous to the use of LASSO in sparse linear regression. They give a ""mean-squared-error"" bound because they only analyze a fixed-design setting (where the goal is only to analyze the effect of noise) instead of the random-design setting which requires an additional analysis of generalization to fresh data. ",0.23076923076923078,0.2,0.21428571428571427
2735,SP:f6d063e2c65f57d832768db00a3a1816d6628b72,"This paper is clearly written and identifies an important point that exploration is dangerous in the autonomous driving domain. My key objection to this paper is that, even though the method is intended to deal with problems where exploration is dangerous and therefore should not be done, the method relies on negative examples, which are presumably dangerous. If simulations are used to generate negative examples and those are used, then the benefit of the presented method over standard reinforcement learning goes away.","Despite many high profile successes in research, DeepRL is still not widely used in applications. One reason for this is that current methods typically assume the agent can learn by exploring many states and actions, however, in many real world tasks, such as driving used here, poor actions can be dangerous. Therefore, methods that can provides the flexible benefits of RL while avoiding this are of significant interest, one promising general ideas pursued for this has been to use human demonstrations.",0.13414634146341464,0.13580246913580246,0.13496932515337423
2736,SP:f70037a4e9a9be5eeedca1384b11aeb11ae248f6,"This paper presents an approach to incorporate span information in pre-trained language models like BERT during fine-tuning. In the proposed approach, the segmentation of a sentence is obtained according to a pre-sampled n-gram dictionary. The fine-grained representation in a same span within the segmentation is aggregated to a span-level representation using a CNN model. These span-level representations are further aggregated using a CNN model to generate sentence-level representation. The experiments show that the proposed model can achieve similar performance gain as other span-based language models which includes span information during pre-training.    ","Previous works reveal that span-level information can enhance the performance of PrLMs if they are used in pre-training. However, the existing methods require enormous resources and lack adaptivity. To this end, the paper proposes a method that combines span-level information into the representations generated by PrLMs during the fine-tuning phase. To combine span-level information, the paper first breaks a sentence into various span components. Then, an accumulated representation with enhanced span-level information is built based on the sub-token-level representation provided by PrLMs. The experimental results on the GLUE benchmark show that the proposed method improves the performance of PrLMs. The main contribution of this paper is the introduction of generating the span components via a pre-sampled dictionary. Overall, the proposed method is not novel since similar methods or ideas have been widely used in NPL.",0.25742574257425743,0.18055555555555555,0.21224489795918364
2737,SP:f70ab30f1b31fa2dcf450582b6798c4da8841687,"This paper proposes a MIL clustering method. The proposed MIL setup is called ""unique class count (ucc)"", this is, for a bag os samples ucc is the number of clusters in the bag. The method learns the features of the samples using two losses: an autoender loss and the ucc loss. Once trained on a dataset the method can perform clustering on classes (classify) better than a fully unsupervised clustering algorithm and worse than a fully supervised model. The method is evaluated on MNIST, CIFAR10, CIFAR100  and on binary breast cancer segmentation.","This paper proposes a new type of weakly supervised clustering / multiple instance learning (MIL) problem in which bags of instances (data points) are labeled with a ""unique class count (UCC)*, rather than any bag-level or instance-level labels.  For example, a histopathology slide (the bag), consisting of many individual pixels to be labeled (the instances) could be labeled at the bag level only with UCC = 1 (for only healthy or only metastatic) or UCC = 2 (for mixed / border case).  The paper then proposes an approach for clustering instances based on the following two-step approach: (1) a UCC model is trained to predict the UCC given an input bag, and (2) the features of this learned UCC model are used in an unsupervised clustering algorithm to the get the instance-level clusters / labels.  The paper also provides a theoretical argument for why this approach is feasible.",0.30434782608695654,0.19047619047619047,0.23430962343096234
2738,SP:f719db5d0209fd670518cf1e28a66dfcd9de0a8c,"The paper presents a novel method for training video-to-video translation (vid2vid) models. The authors introduce a spatio-temporal adversarial discriminator for GAN training, that shows significant benefits over prior methods, in particular, parallel (as opposed to joint) spatial and temporal discriminators. In addition the authors introduce a self-supervised objective based on cycle dependency that is crucial for producing temporally consistent videos. A new set of metrics is introduced to validate the claims of the authors.","Augments the loss of video generation systems with a discriminator that considers multiple frames (as opposed to single frames independently) and a new objective termed ping-pong loss which is introduced in order to deal with “artifacts” that appear in video generation. The paper also proposes a few automatic metrics with which to compare systems. Although the performance does not convincingly exceed its competitors, the contribution seems to be getting the spatio-temporal adversarial loss to work at all.",0.21794871794871795,0.21518987341772153,0.21656050955414013
2739,SP:f71ceed51963fee2042d66da98c14aeb91b93f74,"This paper demonstrates that magnetic side channel information from a GPU (that is processing a deep neural net) can be snooped to recover the architecture and hyperparameters of the neural network. While the concept of side channel information snooping to recover codes/software (including ML models) is widely studied, the novelty claim is that recovering detailed structures of deep models is new. The paper also demonstrates that black-box attacks mounted using a recovered model is quite powerful compared to traditional black-box attacks. ","The paper presents a method for capturing the shape (type of layers) and their respective parameters of a neural network through the magnetic field induced as the GPU drains power. In particular, the GPU is snooped using an off-the-shelf magnetic induction sensor which is placed along the power cable of the GPU. It turns out that under some assumptions (knowledge of GPU model and deep learning framework, knowledge of input size and ability to launch query of specific batch size), based on the correlation of the power consumption pattern of the GPU with the operations being performed it is possible to recognize the type of operation being performed as well as the respective hyper-parameters with very few errors.",0.20238095238095238,0.14049586776859505,0.16585365853658535
2740,SP:f739460e1667818cdece0a4a64697a5d9cdec8d6,"The authors present a novel adversarial attack scheme where a neural net is repurposed or ""reprogrammed"" to accomplish a different task than it the one it was originally trained on. This reprogramming from task1 to task2  is done through a given image from task2 additively enhanced with an adversarial program which is trained given the knowledge of the models parameters. A mapping from the repurposed output from task1 to relevant output for taks2 is also necessary (h_g function).","This paper proposed ""adversarial reprogramming"" of well-trained and fixed neural networks, which can be viewed as learning a trainable input perturbation on a fixed network for multi-tasking by using a different dataset (e.g., MNIST) from the original dataset (ImageNet) as input. Domain mapping functions (h_g and h_f) are required if the data have different dimensions. The key factor to enable adversarial reprogramming of a fixed network to perform a different task is by training the additive adversarial program as defined in (1). Experimental results show that 7 different ImageNet models (adversarially trained or not) can be reprogrammed for performing counting tasks, and MNIST and CIFAR-10 classifications. The authors also show that adversarial reprogramming is less effective on untrained networks. ",0.16455696202531644,0.104,0.12745098039215685
2741,SP:f746ca9d21491dd433de8667cb51e6a137f2898f,"This paper evaluated four unsupervised learning approaches (BCPNN, KH, RBM, AE) by training a supervised classification layer on top of the hidden representation. Specifically, the authors qualitatively compared the receptive fields and quantitatively compared the classification performance across four models. The authors emphasized the advantages of BCPNN since it applies biologically plausible local learning rules and requires fewer epochs for convergence.","The Bayesian Confidence Propagating Neural Network has recently been extended to the case of unsupervised learning (Ravichandran et al., IJCNN, 2020). This paper compares this extension to restricted Boltzmann machines, autoencoders, and a biologically plausible model proposed by (Krotov & Hopfield, PNAS, 2019) on the MNIST dataset. For evaluation the authors consider the learned receptive fields and the classification performance of a linear classifier. The paper is very similar to (Ravichandran et al., IJCNN, 2020) but with an extended experimental section.",0.2459016393442623,0.1875,0.21276595744680848
2742,SP:f76ec36462a44eabd6c76768a6fe8b0b8146b75e,"The paper proposes a spatio-temporal approach for unsupervised out-of-distribution detection. In particular, it suggests a 'hierarchical' evaluation method based on computation of existing distance/similarity scores on hidden embeddings of high-dimensional data succeeded by a temporal component, that is also based on existing work, that treats chunks of  scores, computed by the first step, of input data as a stream. The suggested pipeline achieves state-of-the-art results on datasets coming from different domains ( image, audio, clinical data). More importantly, it demonstrates the importance of semantic context when deciding whether a sample is ood exhibiting better performance than existing baselines when semantic overlap should be taken into consideration. ","This paper was fundamentally about out of distribution detection. The authors tried to use the changing confidence around prediction values to predict changing distributions. They did so specifically for high dimensional, unstructured data, where distributions are often difficult to understand or quantify and compared their results to a number of current methods in the area on a wide variety of high dimensional data.",0.12389380530973451,0.2222222222222222,0.1590909090909091
2743,SP:f771887b75818f23da58a6d8f4cfa7f0ce640cc7,"This paper introduces a new algorithm for learning adversarially robust models in the semi-supervised setting, where a small amount of labeled data is available together with a sizeable unlabeled dataset. The proposed approach BYORL adapts an existing self-supervised learning method BYOL by introducing a new adversarial augmentation technique based on maximizing the cosine similarity between representations. BYORL is evaluated on CIFAR-10 and compared against a recent pseudo-labelling based approach UAT-FT for the semi-supervised setting, and is shown to outperform UAT-FT in terms of robust accuracy under $\ell_2$ and $\ell_\infty$ attacks under the low-labelled data regime. The representations learnt by BYORL are also shown to be better than that of UAT-FT when transferred to other datasets. Finally, robust representations are shown to be more important than learning a robust linear classifier on top.","The paper proposes a new self-supervised technique, Bootstrap Your Own Robust Latents (BYORL), based on an existing technique, BYOL. BYORL proposes to provide adversarially robust representations for low-label regimes. The paper claims that BYORL achieves state-of-the-art performance on CIFAR-10 even with data that is labeled as low as 1%. In fact, the authors highlight that the representations resulted from BYORL avoid the explicit training for adversarial robustness, because they are already robust.",0.14685314685314685,0.2692307692307692,0.1900452488687783
2744,SP:f7840e45f8b41d0b1bb4a90379172e9702af167a,"In this paper, the authors consider the problem of learning Gaussian latent tree models when the nodes of the tree are vector variables and the observations are arbitrarily corrupted. The paper uses the algorithms of Choi et al. (2011) as the base and extends their results (which are for the case when the nodes in the tree are scalar and there is no corruption) to vector variables with an arbitrarily corrupted subset of samples. Furthermore, they provide a more refined sample complexity analysis and highlight the advantage of using Chow-Liu based initialization in the sample complexity. They also provide novel impossibility results.","Summary:  The paper studies the structural learning problems on latent tree models, in which a subset of vector observations have been arbitrarily corrupted. The paper proposes a series of ""robustified"" algorithms, including the robustified recursive grouping (RRG), robustified Chow-Liu recursive grouping (CLRG), robustified neighbor joining (RNJ), and robustified spectral neighbor joining (RSNJ). The authors analyze the sample complexity of the algorithms and show that a number of corruptions up to the square root of the number of clean samples can be tolerated. The paper also provides an information theoretic lower bound for this class of graphical models.",0.2524271844660194,0.2653061224489796,0.2587064676616916
2745,SP:f78edf237bfd944156163801e210e08fd16f8625,"This paper aims at revealing the relationship between the quality of deep representations and the attack susceptibility of deep classification models. To this end, they propose the zero-shot test to investigate the ""quality"" of learned representations for unknown classes. Specifically, they leverage two kinds of quality metrics on data of unknown classes. The first one is based on clustering named Davies-Bouldin Index which measures the compactness of intra-cluster. The second one is based on the difference of soft-label histogram distributions with/without unknown classes during training, which may describe the generalization for unknown classes or bias towards known classes of learned features. Finally, with these two metrics, they rank the quality of different models and compare such ranking results with the attack robustness obtained by different attack techniques on CIFAR-10 dataset.","This paper proposes to evaluate the robustness of the neural networks by extrapolating to the unseen classes. However, the authors only include evaluation for non-robust trained models, without considering the robust trained model, such as Madry et al. [1]. The conclusion is not convincing that the authors studied the robustness using only non-robust models, because it is well known that the accuracy for attacking non-robust model can be 100% (for CIFAR-10). It is useful if the authors study whether their method can be used to measure the robustness of the robust trained models.",0.13970588235294118,0.1958762886597938,0.1630901287553648
2746,SP:f79983e744e2ab8088594023a7868e6db6f95036,"The paper shows that we could have a better document/sentence embedding by partitioning the word embedding space based on a topic model and summing the embedding within each partition. The writing and presentation of the paper are clear. The method is simple, intuitive, and the experiments show that this type of method seems to achieve state-of-the-art results on predicting semantic similarity between sentences, especially for longer sentences. ","Paper overview: The paper extends the method proposed by Arora 2017 for sentence embeddings to longer document embeddings. The main idea is that, averaging word embedding vectors mixes all the different topics on the document, and therefore is not expressive enough. Instead they propose to estimate the topic of each word (using dictionary learning) through the $\alpha$ weights (see page 4).These weights give ""how much"" this word belongs to a certain topic. For every topic we compute the $\alpha$-weighted vector of the word and  concatenate them (see word topic vector formation). Finally, we apply SIF (Arora 2017) using these word embeddings on all the document.   ",0.22535211267605634,0.14953271028037382,0.1797752808988764
2747,SP:f7b7dfafb03090a2c940ba738234a6c80bd5ad0e,"This paper proposed a method to leverage the constrained optimization for policy training to learn diverse policies given some references. Based on a diversity metric defined on policy divergences, the paper employs two constrained optimization techniques for this problem with some modifications. Experiments on mujoco environments suggest that the proposed algorithms can beat existing diversity-driven policy optimization methods to learn both better and novel policies. Generally, the paper is well-written and easy to follow. Some concerns/comments:","This paper aims at novel policy seeking which incorporates curiosity-driven exploration for better reinforcement learning. This paper first propose to use  a Wasserstein-based metric to calculate the difference between policies, and use it to define  the policy novelty. With these, the authors modeled the novel policy seeking as a constrained markov decision process(CMDP) and solved it using CTNB and IPD.",0.1518987341772152,0.19047619047619047,0.16901408450704225
2748,SP:f7fe527d868909ae00d2edba74cfd36b731e6b08,"This paper shows that deep ""narrow"" neural networks (i.e. all hidden layers have maximum width at most the input dimension) with a variety of activation functions, including ReLU and sigmoid, can only learn functions with unbounded level set components, and thus cannot be a universal approximator. This complements previous work, such as Nguyen et. al 2018 which study connectivity of decision regions and Lu et. al 2017 on ReLU networks in different ways.","This paper proves a theoretical limitation of narrow-and-deep neural networks. It shows that, for any function that can be approximated by such networks, its level set (or decision boundary for binary classification) must be unbounded. The conclusion means that if some problem's decision boundary is a closed set, then it cannot be represented by such narrow networks.",0.16216216216216217,0.2,0.1791044776119403
2749,SP:f7ff3ea337acc5902d501c41e453471c43887711,The paper considers the problem of active learning for training convolutional neural networks (CNN) in a sample-efficient manner. The proposed approach is built upon the existing idea of selecting points that maximally reduce expected mean squared error (MSE) on a large representative sample of points. MC-dropout is used for obtaining the estimates of model uncertainty. This idea is used for active learning in regression and classification problems with CNNs. A greedy method is proposed to select a batch of points by maximizing the acquisition function score sequentially obtained by updating the covariance matrix on previous points selected in the batch. Experiments are performed on two regression and one classification task. ,"The paper proposes a method for pool-based active learning in CNNs, selecting the next (batch of) data from an unlabeled pool to query their labels to expedite the learning process. The method computes the expected reduction in the predictive variance across a representative set of points and selects the next data point to be queried from the same set. In batch settings, the data points are sequentially selected in a batch (in a greedy way), with predictive variance representation updated after each selection. Experiments are performed on MNIST classification, and regression tasks of alternative splicing prediction, and face age prediction.",0.23214285714285715,0.25742574257425743,0.24413145539906103
2750,SP:f819e7a08540c2ebf35d975caf628971376e5c82,"This paper proposes a novel metric ""discrepancy ratio"" for evaluating the performance of a model where the ground truth for each data point comes from many expert-yet-imperfect annotators. The authors suggested that this problem has remained largely unexplored. The proposed metric is intuitive and is easy-to-use. The authors suggested that this metric can be used for many applications. For example, to evaluate if a model is better than the annotators on average, to evaluate the annotator, to compare between models. ","This paper proposed to evaluate model performance when the ground truth labels were not available and noisy labels provided by multiple uncertain experts were provided instead. The proposed evaluation metric, called discrepancy ratio, is defined as the ratio between the average model-annotator discrepancy and the average annotator-annotator discrepancy. It can be applied to compare 1) the relative performance of different models; and 2) the relative performance of average annotators and the model. Experimental results on the MNIST classification task showed the proposed metric can compare model performance under different noise levels and is robust w.r.t. the number of annotators and a single annotator's strictness. Experimental results on a real-world medical image classification was also presented. ",0.23809523809523808,0.1652892561983471,0.19512195121951217
2751,SP:f8273f8001de97cfdf085bb2c45d92f6823bee1a,"The paper suggest a shrinkage-based estimator (James-Stein estimator) to compute policy gradients in reinforcement learning to reduce the variance by trading some bias. Two versions are suggested: The on-policy gradients is shrinked either towards (i) model based gradient, or towards (ii) a delayed average of previous on-policy gradients. Empirically, both methods have better performance than the baseline.","This paper presents two algorithms that improve on PPO by using James-Stein (JS) shrinkage estimator. The first algorithm, PPO-MBS, combines low bias of on-policy methods with low variance of model-based RL algorithms. The second, PPO-STS, uses JS to create a statistical momentum and reduce variance of the PPO algorithm. Both algorithms are evaluated on Mujoco environments aiming to show improvements in average cumulative reward, reduced bias and variance.",0.21311475409836064,0.1780821917808219,0.19402985074626866
2752,SP:f844e76015e784261dfd23a4d30f033a8cb332f6,"The paper proposes a framework to learn 6D object pose estimation without GT pose annotations and CAD models (while GT object masks are available, and each object is already isolated). The key is to jointly learn canonical shapes and poses by a SE(3)-equivariance network. It shows promising performance on both synthetic and real depth data.","This paper proposes a self-supervised approach to 6 DoF pose estimation. Usually such methods are either instance-level, assuming known CAD models for all object instances; or category-level, assuming a reference frame that can be generalized to all instances of a certain category. The second approach is more generalizable, however it requires a substantial amount of annotated training data, often from synthetic datasets. So far, self-supervision in this setting has been limited to instance-level, with CAD models but without pose annotations. This paper proposed category-level self-supervision and claims to be the first to do so, eliminating the need of both CAD models and large-scale annotated data. ",0.2807017543859649,0.1415929203539823,0.18823529411764706
2753,SP:f8b6ecb2877d258f483cf38966828974ad39f2e8,"The paper introduces MultiModalQA, a dataset that requires joint reasoning over table, text and images. The dataset has been created in a semi-automatic way through Wikipedia tables, the Wikientities in them, their related images and related textual question answer pairs from known text QA datasets. For the collection of the dataset, authors collect single modality questions and then use a programmatic way to generate the multimodality versions. The paper also introduces a multi-hop baseline that guesses the question type and then does two hops over the different single modality modules to generate the final answer. ","The authors present a new dataset, MultiModalQA, with the intent of measuring a model’s ability to reason across different modalities (free text, structured tables, and images) in question answering, and in which a large percentage of the questions requires cross-modal reasoning. The authors provide a detailed look at the framework used to generate questions in the context of several modalities. Finally, the authors propose a multimodal model that performs multi-hop reasoning (removing the need for explicit question decomposition), which outperforms strong baselines, but is still far behind human performance, indicating that the task is nontrivial and would benefit the research community.",0.23711340206185566,0.22115384615384615,0.2288557213930348
2754,SP:f8b977f856c6d8d80e9adc568c0cdeff9853acbe,This paper proposes to train a Universal Phonetic Model for building speech recognition for new languages without any training data. It suggests to use X-SAMPA to map phones from all the languages into a single phonetic space. The prediction models are designed to first predict the phonetic features and then the phones depending on the target language.,"This paper presents an approach to address the task on zero-shot learning for speech recognition, which consist of learning an acoustic model without any resources for a given language. The universal phonetic model is proposed, which learns phone attributes (instead of phone label), which allows to do prediction on any phone set, i.e. on any language. The model is evaluated on 20 languages and is shown to improve over a baseline trained only on English.",0.2413793103448276,0.18181818181818182,0.2074074074074074
2755,SP:f901a2a16fcd431750c0f346afef7061ebcae630,". The authors propose a novel adversarial training method, e2SAD, that relies on a two-step process for generating sets of two training adversarial samples for each clean training sample. The first step is a classical FGSM that yields the first adversarial sample. The second adversarial sample is calculated with a FGSM that is based on the cross-entropy between the probabilities generated by the first adversarial sample and the probabilities generated by the second adversarial sample. The method is computationally efficient (two forward/backward passes per clean sample) w.r.t. powerful iterative attacks such as IFGSM or PGD requiring 40+ steps and the authors claim it gives comparable results to adversarial training with multi-step attacks methods in white and black-box settings.","The paper introduces a two-step adversarial defense method, to generate two adversarial examples per clean sample and include them in the actual training loop to achieve robustness. The main claim is that the proposed two-step scheme can outperform more expensive iterative methods such as IFGSM; hence achieving robustness with lower computation. The first example is generated in a standard way (FGSM) method, while the second example is chosen to maximally increase the cross entropy between output distribution of the first and second adversarial example.",0.20967741935483872,0.3023255813953488,0.24761904761904757
2756,SP:f903ae576435d5cc18300b28ea637b6eb052068e,"This paper proposes to improve the sample efficiency of transfer learning for Deep RL by mapping a new visual domain (target) onto the training one (source) using GANs. First, a deep RL policy is trained on a source domain (e.g., level 1 of the Atari Road Fighter game). Second, a GAN (e.g. UNIT or CycleGAN) is trained for unsupervised domain adaptation from target images (e.g., level 2 of Road Fighter) to source ones. Third, the policy learned in the source domain is applied directly on the GAN-translated target domain. The experimental evaluation uses two Atari games: i) transfer from Breakout to Breakout with static visual distractors inpainted on the screen, ii) from one Road Fighter level to others. Results suggest that this transfer learning approach requires less images than retraining from scratch in the new domain, including when fine-tuning does not work.",This paper propose an intermediate stage before transfer learning on playing new games that is with slight visual change. The intermediate stage is basically a mapping function to translate the images in the new game to old game with certain correspondence. The paper claims that the adding of intermediate stage can be much more efficient than re-train the model instead. ,0.1292517006802721,0.3114754098360656,0.18269230769230768
2757,SP:f91fdc5524985ac08760d20a7dde843a45825a9d,"The paper starts by introducing Kaleidoscope-matrices (K-matrices). The core idea here is:  1. Most of the interesting operations in NAS spaces are linear and can be expressed as a matrix multiplication $A_W x$ 2. The operations can therefore be diagonalized by a DFT 3. We can factorize the DFT matrices into “butterfly matrices” (such that, for a factorization of factor $N$, we can write $F =$ the product of the $N$ butterfly matrices and a permutation matrix).  4. By allowing this factor $N$ to vary, the matrix multiplication $A_W x$ can be generalized to express a wider family of operations   The core contribution of this paper appears to be using K-matrices in a NAS setting (which involves a reasonable amount of work): - The architecture parameters are continuous  - K-matrices can’t express parameter-free ops - Finding/evaluating new operations in a NAS setting  Their NAS process then looks like: 1. Take in a backbone and generalize it to a supernet  2. Simultaneously train the architecture parameters and the weights  3. Extract a net + weights for inference  The paper then explores a few unusual tasks and shows that this generalization process is worthwhile.  ","The core contribution of this work is to re-image of NAS operation spaces to include both standard operations as well as new operations. This work replaces the Discrete Fourier Transform (DFT) in the diagonal decomposition by a more expressive family of efficient liner transforms known as Kaleidoscope or K-matrices (Expressive Diagonalization Operations), which comprises of a large search space of various types of grid-based convolutions and pooling, permutations, graph convolutions, the Fourier Neural Operator, and more. This work developed a simple procedure which transforms any backbone convolutional neural network into an architecture search space by replacing its operations with XD-operations. This space is then searched using a simple weight-sharing algorithm. This work yields models that are 15% more accurate than standard discrete search spaces on permuted CIFAR-10, highlighting the fragility of standard NAS operation spaces on new datasets, and thus the need for XD-operations.",0.14795918367346939,0.19205298013245034,0.1671469740634006
2758,SP:f93ca5c4d2f3a07efc1eea35c1e188156c981287,"This paper disentangles the threshold parameters in LISTA-type models from the reconstruction errors, proposing the Error-Based Threholding (EBT) mechanism which mainly follows a theoretical results in (Chen et al., 2019; Liu et al., 2018), where the threshold at one layer is proportional to the recovery error of current iterate. The benefits brought by the proposed EBT method are faster convergence and better adaptivity to a wider range of samples. To bypass the requirement of ground truth sparse signals, EBT uses the reconstruction error following a learned linear transform, which in theory has good coherence property with the dictionary and therefore can approximate the recovery error well. The authors theoretically show that the proposed EBT mechanism enjoys faster convergence in both cases with and without the support selection technique. Emprirical experiments on standard synthetic setting and cross-sparsity setting are shown to support the efficacy of EBT. The authors also do real-world photometric stereo analysis to show the superiority of EBT.","In the paper, authors propose a new error-based thresholding mechanism for LISTA which introduces a function of the evolving estimation error to provide each threshold in the shrinkage functions. They provided the theoretical analysis for EBT-LISTA and EBT-LISTA with support selection and proved that the  estimation error of the proposed algorithm is theoretically lower than compared methods. The authors also evaluated the proposed method on multiple synthetic or real tasks. Experimental results show that the proposed method achieves a better estimation error and  higher adaptivity to different observations with a variety of sparsity.",0.17177914110429449,0.2916666666666667,0.21621621621621623
2759,SP:f949cb0fd9e1b4afc31725a740ef87dd2d5d5a49,This paper proposes a low rank training method called the Streaming Kronecker Sum approximation (SKS algorithm) for training low precision models on edge devices. The authors compare their method to SGD for convolutional networks on MNIST and demonstrate improvements in terms of accuracy. The authors make use of the Optimal Kronecker-sum algorithm of Benzing et al and propose further improvements to it in the form of the SKS algorithm.,"While inference on edge devices is a popular and well-studied problem in recent days, training on these devices comes with many challenges. This paper proposes a low-rank training schema that helps mitigate some of the critical challenges that occur during training models on NVM memory-based edge devices. Additionally, two techniques, namely streaming batch norm and gradient max norm, are proposed to help training in an online setting. The proposed method is mainly based on approximating the Kronecker sum and is largely inspired by (Benzing et al, ICML 2019, Optimal Kronecker-sum approximation of real time recurrent learning). The proposed approach provides a few optimizations that improves this performance further, and outperforms SGD in terms of accuracy and the number of weights updates in a limited experimental setting.",0.37142857142857144,0.2,0.26
2760,SP:f952feef70a17987e9691ce2faef013e1b59168e,"This paper proposes a unified PAC-Bayesian-based informativeness measure (PABI) to quantify the value of incidental signals. PABI can measure various types of incidental signals such as partial labels, noisy labels, constraints, auxiliary signals, cross-domain signals, and their combinations. In NER and QA tasks, they showed the strong correlation signals between PABI and the relative improvements for various incidental signals. ","This paper proposes PABI (PAC-Bayesian Informativeness?), a way of measuring and predicting the usefulness of “incidental supervision signal” for a downstream classification task. In particular, when labeled data is only available in noisy or partial form, or over a different domain than the target test domain, this data may still be used to improve a classifier, but it’s unclear how to tell which forms of incidental supervision will be most useful. Having a measure which allows us to compare different types of such supervision enables us to make intelligent tradeoffs.",0.20967741935483872,0.14130434782608695,0.16883116883116883
2761,SP:f97c429a41ec4715cb88acf6dde1c4d4ffa5957d,"In this paper, the authors relax the generally used Lipschitz smoothness condition in optimization, to a more general smoothness condition that may depend on norm of the gradient. The authors proved that, with this relaxed condition, under such cases, both GD and clipped GD can converge within O(1/\epsilon^2) time, but when their exists x where the gradient norm can be very large, the clipped GD will converge provably faster than GD with a proved GD convergence rate lower bound. The authors also generalize their results to SGD. Experiments show that in deep neural network local gradient Lipschitz constant is scale with gradient norm, and use clipped gradient can accelerate convergence while keep good generalization performance as expected, which is well observed by other researchers.","This paper applies new assumption on smoothness that assume the norm of Hessian is bounded by a scalar plus norm of gradient. The traditional smoothness is only bounded with a scalar, the proposed assumption is more relaxed because now the norm of Hessian can grow with the norm of gradient. Under this assumption, the authors show clipped gradient converges faster than gradient for general nonconvex problems. The authors provide insights on why the proposed assumption is good for describing neural networks, and empirically verify the assumption with ResNet on CIFAR and LSTM on PTB. ",0.1732283464566929,0.23404255319148937,0.19909502262443438
2762,SP:f99c39367808a1148a8b9559eef7d88cbccc8e6b,"The paper shows a way to compare what is learned by two very different networks trained for a video classification task. The two architectures are state-of-the-art methods, one relying on 3d-CNNs (time= one dimension), the other on conv-LSTMs (time is treated sequentially, using hidden states to pass information). The idea of the authors is (i) to provide saliency maps for each of them, and (ii) to create interesting perturbations in order to measure the influence on the networks. The results indicate that these complex networks are usually focused on interesting features, and as we would imagine, LSTMs is more learning from temporal coherence than CNNs.","This paper presents a paradigm for generating saliency maps for video models, specifically, I3D (3D CNN) and C-LSTM. It extends Fong & Vedaldi, 2017 to generate a temporal mask and introduces two types of ""meaningful perturbations"" for videos: freezing and reversing frames; they use Grad-CAM (with no modifications) for generating spatial masks. The problem is well-motivated, as saliency maps have been extensively studied for image classification models, but rarely for video classification. Quantitatively, they demonstrate that frame-reversal is meaningful for the Something-something dataset but less for KTH because those actions rely more on spatial information than temporal (i.e., running, clapping). Qualitatively, they show their spatial and temporal masks on both datasets and suggest the a few insights: ",0.14545454545454545,0.13114754098360656,0.13793103448275865
2763,SP:f9d1d627589f50a87c503a6df484145dc01ebcca,"This paper focuses on offline policy learning with a limited dataset and proposes a sample efficient algorithm called Q-Value Weighted Regression. Based on the Advantage Weighted Regression algorithm, this algorithm calculates the advantage of the sampling policy \mu by estimated Q-value function. Experiment results show that the QWR algorithm has better performance than the AWR algorithm with limited data.","This paper presents a Q-value weighted regression (QWR) on top of the advantage weighted regression (AWR) to improve the sample efficiency for offline RL settings. Through the analysis to the AWR, the authors claim that it performs poorly in scenarios with discrete actions, which motivates the development of QWR. Empirically, the authors show that QWR is comparable to SAC in continuous tasks and a variant of Rainbow in discrete tasks. ",0.29508196721311475,0.2535211267605634,0.2727272727272727
2764,SP:f9e75eedd1a665ef03d4e197d336e43f1acb1f61,"This work built on top of DARTS. In their setting, each edge on the DAG (same as the one proposed in DARTS) has one agent associated with it and every agent maintains weights to propose operations. The author introduced two ways to update these weights: 1) solving a least squares assuming the validation loss decomposes linearly on the operations (MANAS-LS); 2) only update the weights for the activated operations (MANAS). Due to the usage of bandit framework, theoretical guarantees on the regret can be derived. ","In this paper, the authors proposed MANAS, which is based on DARTS, by approximating the problem space by factorizing them into smaller spaces, which will be solved by multiple agents. The authors claimed that this can simplified the search space so that the joint search can be more efficient to enable us to search a larger space faster. While the overall idea seems simple but the coordinating among agents can be difficult, where the authors proposed credit assignment techniques to address the issue. The final algorithm is evaluated on CV datasets as well as 3 new datasets. ",0.16279069767441862,0.14432989690721648,0.15300546448087432
2765,SP:f9ed35b4b0c9410d718d872f80a50e182455e04d,"This paper analyzes convergence of asynchronous methods on general non-smooth and non-convex functions (typically arising from deep leaning). Stochastic sub-gradient asynchronous methods are of particular challenging when coupled with complicated hardware behavior of modern NUMA architecture. To validate the analysis, and study the impact of momentum, variable partitioning, numerical experiments on deep learning training are given.","This paper proposes a model to study asynchronous stochastic subgradient methods for minimizing a nonsmooth nonconvex function. Studying stochastic subgradient methods in the nonsmooth nonconvex setting is already very challenging. Throwing asynchronous updates into the mix further complicates the analysis. This is overcome by proposing a model for asynchrony which captures the salient features of computation platforms, while being amenable to analysis.",0.1864406779661017,0.1774193548387097,0.18181818181818182
2766,SP:fa0ebf93ac2ed036fcd7d1e81761fefb43a4961e,"Authors present a novel and effective method leveraging a generative adversarial approach to a specific MARL problem with regard to missing training data. The approach presented treats the missing data as targets of imputation, loosely similar to that of inpainting problems in computer vision, where missing pixels are ""filled in"". Results show that IA-MARL outperforms one baseline (MADDPG) that has not been originally devised for missing training data.",The submission proposes a cooperative MARL problem settings in which the observation-action-reward tuples generated during training are unavailable with some non-zero probability. The submission suggests addressing this problem setting by first imputing the missing training data and what they call a mask based update. The submission presents experiments for multi-agent particle environments.,0.13043478260869565,0.16071428571428573,0.14400000000000002
2767,SP:fa2b9bec0d7e6eeebdc41d031bcae23b72535cf5,"This paper considers the less-explored baseline selection issue in attribution methods for one-vs-one explanations of multi-class classifiers. The key insight is to construct the closest and realistic target class baseline. To this end, an existing image-to-image translation GAN model, namely StarGAN, is leveraged to transform an input example to another example in a target class yet is close to the input. This baseline can be integrated with a variety of attribution methods, including integrated gradient, DeepLIFT, Occlusion, and deepSHAP, and shows consistent improvements over zero baseline and minimum distance training sample for one-vs-one explanations. The experiments are conducted on three datasets – MNIST, SVHN, and apple2orange.","This paper proposes a new 'baseline' for attribution methods tailored to deep neural networks. DNN attribution methods like integrated gradients, deep lift and others require a baseline to compare to as part of the computation. The choice of a baseline has been controversial in the literature, and a good method to select a baseline remains an open problem. This paper seeks to address that problem. Specifically, this paper seeks to develop a baseline for one-vs-one explanations as opposed to one-vs-all explanations. Consider an MNIST model, a one-vs-one attribution would attribute why an input is say a '2' and not a '4', i.e., it is contrastive against a particular target class and not all classes. This paper proposes to use a StarGAN for generating these baselines. The paper then evaluates explanations derived using the new baseline and shows that they explanations 'perform' better. ",0.22123893805309736,0.16778523489932887,0.1908396946564886
2768,SP:fa33e5a45b74feb3277ec2c9c980719fabd472dd,"The paper proposed CoAE-MLSim to learn with relatively fewer samples of PDE solutions and solve PDEs. CoAE-MLSim uses the idea of domain decomposition: first learn the solution on local subdomains using autoencoder, and then couple these sub-solutions by an iterative algorithm. Numerical experiments are performed to test the efficiency of the method.","This paper proposes a new ML approach called CoAE-MLSim that is a faster alternative to PDE solvers. Compared to previous ML work on this problem, it aims to be more accurate and generalize better across PDE conditions. They also aim to require fewer PDE solutions to train the model. ",0.18181818181818182,0.2,0.1904761904761905
2769,SP:fa3f5e47eea572915c94134222535f4f48b2fe83,"This paper proposes a multi-hop transformer method for the video-based object permanence task. The proposed method performs multi-hop reasoning via the encoder-decoder architecture of transformers over critical frames in the video. To mitigate the problem of lacking ground truth for the middle hops, the paper proposes some interesting training tricks. Overall, the paper is well organized and easy to follow.","This paper introduces an architecture (Multi-Hop Transformer) for spatio-temporal reasoning in video, focusing on a localisation task for scenes where the object of interest is often occluded (Snitch Localisation task in CATER). The model extracts objects using an external object-detector and predicts objects’ trajectories using the Hungarian algorithm. The Multi-Hop Transformers learns to hop over unnecessary frames, by focusing only on a set of few critical steps (at each time step, the next critical frame is the one containing the most attended object). To alleviate the problems encountered during the training procedure (such as error propagation), several auxiliary training methods are proposed to guide the first few hops or to ensure contrastive debias. Additionally, a harder version of the existing CATER dataset is created, to alleviate the temporal bias existent in the previous version of the dataset.",0.359375,0.16312056737588654,0.22439024390243906
2770,SP:fa4272fd8c8acea21a01d8fd6542a51534c1aee8,"The paper proposes a method for selecting a subset of a large dataset to reduce the computational costs of deep neural netwoks. The main idea is to train a proxy model, a smaller version of the full neural network, to choose important data points for active learning or core-set selection. Experiments on standard classification tasks demonstrate that this approach can yield substantial computational savings with only a small drop in accuracy.  ","This paper presents a method to speed up the data selection in active learning and core-set learning. The authors present a simple idea: instead of using the full model to select data points, they use a smaller model with fewer layers, potentially trained for fewer iterations. The authors show that this simple approach is able to speed up the data selection portion of both processes significantly with minimal loss in performance, and also results in significant speedup of the entire pipeline (data selection + training).",0.2638888888888889,0.2235294117647059,0.24203821656050956
2771,SP:fa64a906a5800aa62bed00e9c2b29b9fcffd0412,"In this paper the authors present a new generative model for audio in the frequency domain to capture better the global structure of the signal. For this, they use an autoregressive  procedure combined with a multiscale generative model for two-dimensional time-frequency visual representation (STFT spectrogram). The proposed method is tested across a diverse set of audio generation tasks","The authors introduce MelNet, an autoregressive model of Mel-frequency scaled spectrograms. They convert audio into high resolution spectrograms to reduce the audio artifacts introduced by inverting spectrograms (here they use gradient-based inversion over Griffin-Lim). To improve modeling of long term dependencies, they perform multi-scale splitting of the spectrograms and maximize the likelihood at each scale (avoiding dominance of noise at higher resolutions). They condition generation at finer scales from coarser scales, enabling sampling through an ancestral process. The authors also highlight the difference between temporal and frequency dimensions, creating different conditioning stacks for the past in time vs. the ""past"" in frequency (lower frequencies), and mixing conditioning between the two stacks through layers of the network. Multilayer RNNs are used throughout the network and external conditioning is incorporated at the input. ",0.25,0.1111111111111111,0.15384615384615383
2772,SP:fa6f35939da0aa66e90846ba9077b67c91f33eb4,"The paper proposes a methodology to overcome the problem of processing long sequences with a pre-trained Transformer model, which suffers from high computational costs due to the complexity being quadratic in the length of the sequence. The authors also point out that BERT needs to be retrained from scratch if sequences longer than the specified maximum length (512) are to be processed. Their method (BERT-AL) chunks the input text into segments of maximum length. Each segment is propagated through several layers of a pre-trained Transformer layer followed by a multi-channel LSTM. Herein, the positional embeddings in each segment are the same. The model is applied to extractive summarization, and directly compared to the BERTSUM model, which can only process documents up to length 512. The comparison is made for 4 application scenarios, each corresponding to an artificial maximum length after which the BERTSUM model truncates the input: after 8, 16, 128, and 256 tokens. The experimental results suggest that BERT-AL outperforms BERTSUM in all 4 scenarios: Substantially for max length 8 and 16, and marginally for 128 and 256. BERTSUM without any truncation still performs best, however.","This paper proposed another variant of BERT, called BERT-AL, which can deal with arbitrarily long inputs. The authors constructed the proposed method by combining the segment-wise BERT with the multi-channel LSTM. The authors validated the proposed method on the text summarization task and achieved higher performance than existing works. Their proposed method can be combined with other transformer-based approaches, such as XLNet or RoBERTa.",0.09375,0.2647058823529412,0.13846153846153847
2773,SP:fa7fa24dcbfa67ffc00471e14aea2ed451bb1bea,"This paper first examines that typical color jittering augmentation is harmful to feature representation learning. Then the authors proposed a physics-based color augmentation, called Planckian jitter to improve the performance. The proposed Planckian jitter performs better with the recent contrastive and self-supervised learning schemes.","**Overview.** This paper proposes a novel type of image colour augmentation to be used during self-supervised learning (SSL).  **Background.** In a typical SSL setting, similar samples are generated by randomly augmenting an image in a variety of different ways: random cropping, colour jittering, random rotations, etc. These similar images are then passed through a neural network, and the predicted features for similar samples are trained to be close to each other based on some similarity metric (ignoring the contrastive term description here as it is not directly related to the paper).  **Motivation.** In this paper, the authors address the issue of using colour jittering as augmentation during SSL. Specifically, using colour jittering pushes the network towards invariance to image colours, while relying more on the shape and texture of objects when making predictions. The authors point out that despite the benefits of this for many general detection tasks, this will be a detrimental property when dealing with more colour-dependant tasks.  **Method.** Thus, they propose to use Planckian jittering instead of colour jittering. Planckian jittering is a physics based augmentation method proposed by the authors (although the formulations for it come from existing literature) to re-illuminate the training images within a realistic distribution which leads to more realistic and constrained colour augmentations than colour jittering. The paper claims that Planckian jittering still helps improve network's dependence on shape and texture of objects (although less than colour jittering), while limiting the network's invariance to image colours.  **Experiments.**  6 SSL models were trained independently on CIFAR-100: 3 used different variants of the Planckian jittering, 2 used different variants of colour jittering (w/ and w/o Random GrayScale), and 1 used no augmentations. Linear classifiers for CIFAR-100 and FLOWERS-102 classification tasks were then trained on top of each of the SSL models' features, where FLOWERS-102 is the task that is claimed to be more heavily colour-dependant. Moreover, an extra linear classifier was trained on the concatenation of features from a Planckian jittering and a colour jittering model (called the ""Latent space combination"" model). Based on accuracy, ""Latent space combination"" outperforms all other models by a significant margin on both datasets. Planckian jitter seems to outperform other augmentations on FLOWERS-120 (Table 1), which supports the claim of the authors. On CIFAR-100, Planckian jitter performs slightly worse than colour jittering, which the authors attribute to the reduction of colour invariance in the features.  A very similar experiment was also done with different datasets (SSL training on tiny-imagenet, linear classifier trained on FLOWERS-102, CUB200, VEGFRU, T1K+), which also obtained similar results and conclusions. Moreover, in another similar experiment, the SSL models were trained with different SSL configurations (SimSiam, SimCLR, Barlow Twins) to indicate the generality of Planckian jitter for different types of SSL configurations. In another experiment, the robustness of the different models on augmented images using Planckian jittering was evaluated. Lastly, the colour sensitivity was analyzed to inspect the impact of colour information in neuron activations for each model.",0.5,0.045364891518737675,0.08318264014466546
2774,SP:fa852f6d762a09e601ec0d78694c23155548b214,"Although a mesh embedded in 3D space may be treated as a graph, a graph convolution network uses the same weights for each neighbor and is thus permutation invariant, which is the incorrect inductive bias for a mesh: the neighbors of a node are spatially related and may not be arbitrarily permuted.  CNNs, GCNs, and G-CNNs demonstrate the value of a weight sharing scheme which correctly reflects the symmetry of the underlying space of the data.  The authors argue convincingly that for a signal on a mesh, the appropriate bias is symmetry to local change-of-gauge.  In short, the weights should depend on the relative orientation of a node’s neighbors.  They design a network GEM-CNN which is equivariant to change of gauge.  The design is similar to a GCN but incorporates parallel transport to account for underlying geometry and uses kernels similar to those of $SO(2)$-equivariant $E(2)$-CNN (Weiler & Cesa 2019).  The experiments show the network is able to adapt to different mesh geometries and obtain very high accuracy in the shape correspondence task. ","The work presents a novel message passing GNN operator for meshes that is equivariant under gauge transformations. It achieves that by parallel transporting features along edges and spanning a space of gauge equivariant kernels. Further, a DFT-based non-linearity is proposed, which preserves the equivariance in the limit of sampling density. The method is evaluated on an MNIST toy experiment and the Faust shape correspondence task.",0.10497237569060773,0.2835820895522388,0.15322580645161288
2775,SP:fa9f5943cd6501a9e72e66ca071ba4b15923bfa1,"The paper empirically studies the category selectivity of individual cells in hidden units of CNNs. It is a sort of ""meta-study"" and comparison of different metrics proposed to identify cells with a preference for a specific target category. The claimed finding is that there are no cells that are ""sufficiently"" selective to be called object detectors.","The paper makes an empirical claim that CNNs for object recognition do not contain hidden neuron which is highly selective to each class, mainly based on three aspects: (a) metrics related to the maximum informedness, (b) jitterplots of activation data, and (c) a user study assessing whether generated images maximizing a given unit is perceptible to the user. The paper point out these results are in contrast to the case of RNN, where it has been reported that many localist hidden units emerge. It is also noticed that the existing metrics for selectivity do not adequately discriminate highly selective units in CNN.  ",0.22807017543859648,0.12745098039215685,0.16352201257861634
2776,SP:faa869ec6fa32409248e46b957223595524e88df,"The paper discusses a generalization to low bit quantization and combines the approaches of binary and ternary quantization methods. Past methods such as Binary Connect and Binary Weights Network have shown that you can train a network efficiently with 1-bit quantization, and methods such as Ternary Weights Network demonstrate 2-bit quantization with weights taking one of {-1, 0, 1} * mu, with mu being a scale computed per weight tensor. The authors generalize these two methods so that the choice of binary vs ternary weights can be made per layer automatically during training. The primary contribution to make that work is by incorporating a generic regularizer with addition hyper-parameters to trade-off between the binary weight regularizer and ternary weight regularizer. In addition to that, the regularization also includes a prior to make the layers prefer binary weights by default. This is done by adding a cost that penalizes the choice of ternary weights for each layer.","This paper studies mixed-precision quantization in deep networks where each layer can be either binarized or ternarized. The authors propose  an adaptive regularization function that can be pushed to either 2-bit or 3-bit through different parameterization, in order to automatically determine the precision of each layer. Experiments are performed on small-scale image classification data sets MNIST and CIFAR-10.",0.09433962264150944,0.23809523809523808,0.13513513513513511
2777,SP:faca1e6eda4ad3b91ab99995e420398c01cc0e42,"This paper presents a computational model of motivation for Q learning and relates it to biological models of motivation. Motivation is presented to the agent as a component of its inputs, and is encoded in a vectorised reward function where each component of the reward is weighted. This approach is explored in three domains: a modified four-room domain where each room represents a different reward in the reward vector, a route planning problem, and a pavlovian conditioning example where neuronal activations are compared to mice undergoing a similar conditioning.","The authors investigate mechanisms underlying action selection in artificial agents and mice. To achieve this goal, they use RL to train neural networks to choose actions that maximize their temporally discounted sum of future rewards. Importantly, these rewards depend on a motivation factor that is itself a function of time and action; this motivation factor is the key difference between the authors' approach and ""vanilla"" RL. In simple tasks, the RL agent learns effective strategies (i.e., migrating between rooms in Fig. 1, and minimizing path lengths for the vehicle routing problem in Fig. 5). ",0.16666666666666666,0.15789473684210525,0.16216216216216214
2778,SP:facb7e43da318900edf3d247467a45c3d3ae7d42,"This paper proposes multi-hop dense retrieval for open-domain multi-hop question answering. It extends previous dense passage retrieval into the corresponding multi-hop version by using retrieved passages to latently reformulate the query representation after each retrieval pass. In the end, it can significantly improve the performance on HotpotQA and multi-evidence FEVER dataset. The analyses are very comprehensive and extensive from almost every relevant perspective.","This paper extends the recently proposed dense retrieval methods to the multi-hop open-domain questions, so as to handle complex multi-hop queries. The overall idea is simple, direct but effective. The authors conduct extensive experiments on two multi-hop datasets, HotpotQA and multi-evidence FEVER, and evaluation results demonstrate that the proposed model achieves impressive results on both the knowledge retrieval task and multi-hop QA. ",0.27941176470588236,0.27941176470588236,0.27941176470588236
2779,SP:fad2af574548c00ab1e950a118a2e0d206663b94,"Based on a previous classic binary coding scheme, this paper proposed to introduce a modification $m_i$ on the binarization scaling factor $\alpha$, by considering the weight magnitude. It further use 3 hyperparamters to refine $m_i$ by constraining its upper/lower bound and exponent. Besides,  this work spent lengthy content to describe how to determine the hyperparamters.","The paper employs the binary-coding-based post-training quantization (without retraining) for language modeling. The key contribution is that weight importance is considered while determining binary code (a, B). Two methods, Greedy and Alternating, are also modified to use the importance. The algorithm uses a novel normalized importance, which directly uses weight magnitude and some hyper-parameters. Because the performance is sensitive to hyperparameters, Bayesian optimization is used to find task- and model-specific settings.",0.1724137931034483,0.13157894736842105,0.1492537313432836
2780,SP:faefbfe1f151c4b3e0db3ef30e3317f45dd82274,The paper proposes combining the latent space of a variational autoencoder with two losses that regularize the latent space. The first loss is the cluster hardening loss in Aljalbout et. al [https://arxiv.org/pdf/1801.07648.pdf]. This loss attempts to convert from a  soft-assignments of points (in latent space) to cluster centers (where the assignments are based on similarities computed via a Student t kernel) to a hard assignments of points in latent space to cluster centers. The transformation is posed as the minimization of a KL divergence.,"This paper proposes VarPSOM, a method which utilizes variational autoencoders (VAEs) and clustering techniques based on self-organizing maps (SOMs) to learn clustering of image data (MNIST and Fashion MNIST in particular). An LSTM-based extension termed VarTPSOM is also evaluated on medical time series data. For the most part, the experimental results are promising, and the visualizations are particularly nice.",0.12087912087912088,0.18032786885245902,0.1447368421052632
2781,SP:fb02de30da08da7ee574ee8d8625714c445ae004,"The paper shows that dense phrase Representations can be better representations for retrieval than the document-level representations. Specifically they show that DensePhrases representations can be used to identify relevant documents _without any fine-tuning_ on the target QA dataset compared to DPR. Additionally they show why phrase representations might outperform passage-level representations (much harder negatives). On non-QA datasets, fine-tuning the query representations can lead to competitive performance too. Finally they also provide a potential solution to reduce the index size of DensePhrases to match that of DPR while maintaining a higher performance.","This paper explores how dense phrase retrieval (i.e., treating a phrase as the unit of retrieval) compares to dense passage retrieval in the context of QA and specialized document retrieval tasks. To improve phrase retrieval, the authors propose the use of in-passage negatives (i.e., negative phrases taken from a relevant passage) and discuss how this relates to strategies for choosing negative exmaples with passage retrieval. In the evaluation, the proposed approach is more effective than DPR (passage retrieval) for QA and competitive on the other tasks. Additionally, the authors demonstrate that quantization can be used to substantially decrease the phrase index size, which mitigates this potential downside of phrase retrieval.",0.20833333333333334,0.17699115044247787,0.19138755980861244
2782,SP:fb34d6a5be0e6820eeac331137163919d581f120,"The paper casts the problem of 2d fluid flow simulation as an image to image-to-translation task. A cGAN with standard architectures (U-net generator, PatchGAN discriminator) is trained to advance the visualization of the simulation to the next time step, and an extension with an LSTM block is explored. The model is evaluated in an autoregressive setting on the problem of fluid flow around a rectangle, and the results are evaluated with image metrics (PSNR).","The authors pose fluid simulation as an image-to-image translation task. From this perspective, approximating fluid flow using a cGAN can potentially improve speed (at the expense of accuracy) over FEM methods. This can be useful in situations where accuracy can be traded off for speed (e.g. video games). The authors show a U-net can produce good future predictions for Karman vortex sheets, and is faster than an off the shelf multiphysics simulator. In addition the authors ablate various architectural design choices.",0.2597402597402597,0.23529411764705882,0.24691358024691357
2783,SP:fb6ceb7cc788fb39fbe67529b2c4401f51fd74cb,"This paper presents a method to combine information of multivariate time series by extending univariate architectures. The technique uses a graph representation to represent interactions by assuming a bipartite structure, which allows the technique to scale the representation to reduce the complexity from $O(N^2)$ to $O(N K)$ using K additional nodes. The architecture represents each time series as one of N nodes and associate K embeddings (nodes) and thus there are connections between the N nodes and the K nodes but not within each group of nodes. The architecture encodes the confounders, co-linearities, and other information among the time series to improve forecasting. The experiments show the performance (and time efficiency) of the technique against several baselines on METR-LA and PEMS-BAY datasets. The experiments also show the performance on single-step forecasting on four publicly available datasets. Finally, synthetic datasets were used to evaluate the adjacency matrices in control scenarios.  ","The paper proposes using graph neural net (GNN) operations to combine per-series embeddings, to enable multivariate forecasting.  Specifically, N individual series are separately encoded for a given time window to get representations per series.  These representations are then updated with a GNN - either assuming a fully connected graph (with edge weights computed as part of the model), or using a bipartite graph (using a smaller set of K << N auxilliary nodes).  I.e., after multiple layers of the GNN, the representations are updated with information from the other series' representations.  Finally, the final representations are passed through per-series decoders.  The latent bipartite graph formulation enables more efficient operation of the GNN component as instead of computing O(N^2) messages only O(NK) need to be computed in a given pass.  The authors compare the proposed approach with other Graph based forecasting approaches (including ablated versions of the proposed approach) on 6 datasets - 2 where there is a given graph structure (so past work requiring the graph structure to be known can be used) and 4 where there is not.  They demonstrate competitive performance of the proposed approach (including the bipartite graph approach) and significant speed up of forward passes using the bipartite formulation especially for larger N.  They also examine the inferred adjacency matrices for different methods on some synthetic data.  Additionally, they show hyper parameter sensitivity results for varying K (number of latent nodes in the bipartite graph) for one dataset.",0.22435897435897437,0.14285714285714285,0.17456359102244387
2784,SP:fb717cacd65d17e3d1971170a82b902ee94d4dfc,"In this paper, the authors study the adversarial example generation problem, in the difficult case where the attacked model is a black box. Since the model is unknown, the approaches based on the minimization of a loss function with a gradient based optimizer do not apply. The current alternatives, known as decision-based attack, use iterative local updates from a starting point to a local minimum, where the class of the adversarial example is different from the initial example while its distance stays close to the initial one.","This paper proposes a meta-algorithm for the so-called ""decision-based attack"" problem, where a model that can be accessed only via label queries for a given input is attacked by a minimal perturbation to the input that changes the predicted label. The algorithm, BOSH, augments any iterative algorithm for this problem with a diversification strategy based on bayesian optimization and throwing away bad solutions. Empirically, it is shown that BOSH can improve the performance of recently developed algorithms for this problem, by exploring more solutions and refining them intelligently.",0.18181818181818182,0.17582417582417584,0.1787709497206704
2785,SP:fb77e61ebd1844212439bb59e6a07c998486f30a,"This paper provides a systematic evaluation of the performance of different CL methods on RNN. The study suggests that high working memory requirements increase difficulty of learning new tasks, while the average length of input sequence is not strictly related to the difficulty of learning new tasks. The author proposes to overcome this problem by using a hypernetwork-based CL approach, which shows promising results in the experiments.",The authors do an evaluation of the application of weight-importance continual learning methods to recurrent neural networks (RNNs). They draw out the tradeoff between complexity of precessing and just remembering (working memory) in terms of the applicability of these weight importance methods. They also provide some theoretical interpretation based on stying linear RNNs.,0.17647058823529413,0.2222222222222222,0.19672131147540983
2786,SP:fb7cb806814fed554937ff60b5be8fb06f5514fc,"This paper proposes to use skip connections in feedforward artificial neural networks to integrate information over multiple time steps by defining a delay for each connection in the network. Extensive experiments with a ResNet18 architecture show that this execution plan leads to an increase in early prediction accuracy when using anytime predictors, to faster predictions when samples are closer to a class prototype, more robustness to noise and a better out-of-distribution (OOD) detection compared to a sequential architecture. Temporal difference learning (TD) is utilized to train the neural network and an analysis is done on CIFAR-10, CIFAR-100 and TinyImageNet to show that the often used value of lambda=1 is suboptimal for these kinds of tasks.  ","The authors propose to tighten the link with biological neural networks by designing a cascaded network that is more compatible with the dynamics of information processing observed in the brain. In cascaded networks, all layers process the information in parallel and are fed with an updated input at each time step. The authors also introduce a loss, the Temporal Difference, that improve the performance of cascaded networks. The authors demonstrate that the cascaded network offers better trade-off accuracy and better noise robustness than serial one. In addition, the authors demonstrate that class instance that are rapidly recognized tend to be more prototypical in cascaded network",0.13333333333333333,0.1509433962264151,0.1415929203539823
2787,SP:fb90f0ddbb51af6d183e96141f8b8d8c45ed083d,"This paper proposes a method to optimize training data generation for supervised learning approaches to constrained optimization. First the authors show that the existence of various optimal solutions to the problem can make the learning more challenging. Then they Then they proceed with some theoretical insights that link this challenge to the representation capacity of ReLU neural networks. The paper introduces a method for training data generation for CO learning such that CO instances that are close (in terms of specifications) have solutions that are close too. Numerical validation is presented on a job shop scheduling problem (combinatorial optimization) and an Optimal Power Flow problem (non-linear, non-convex constrained pb). ","This paper addresses a different aspect of learning-based problem solvers.   Typical complex optimization problems are hard to find optimal solutions, and therefore learning datasets for a specific optimization problem class are volatile in general. Following this, the paper develops a method for optimal training data design, which is an optimization problem on the total variation of solutions. With the developed methods, two case studies (JSS and OPF) are demonstrated to show the effectiveness of their proposed methods.",0.17117117117117117,0.24358974358974358,0.20105820105820107
2788,SP:fb94b2e6f8ca5b0b8c7567d3251e31d4c5c1765c,"The paper proposes a general framework for multiple hypothesis testing with data generated from bandit algorithms. In particular, the paper proposes a new e-value-based multiple testing method that 1) has a tighter FDR bound and 2) applies to more general settings, compared with previous p-valued-based methods (Jamieson and Jain, 2018). In a special case, the paper investigates the efficiency of its proposed algorithm and shows that the sample complexity needed for the TPR to be above the pre-specified threshold matches that of previous work (Jamieson and Jain, 2018). Additionally, the paper improves the FDR bound of the p-value-based method (Jamieson and Jain, 2018) by leveraging results from Su (2018).","The authors give a unified framework for bandit multiple testing in terms of e-values. This framework is more flexible than prior work, allowing for dependencies between random variables and adaptive algorithm without corrections required in prior work, most notably JJ. The authors apply this result in a setting studied previouly where each arm is sub-gaussian and independent, and a single arm is queried at each step. They give sample complexity bounds matching prior state-of-the-art and show comparable performance in experiments.",0.15517241379310345,0.21176470588235294,0.1791044776119403
2789,SP:fbacc4b906328e10a7f61a351bc02cf99aa33c4c,"The paper focuses on reinforcement learning problems with known successor features and rewards expressible as their linear combination. Building on recent research, it presents a concept of independent features and independent policies and way to construct them. Theoretically it shows that the set of independent policies and their combination with GPE & GPI is enough to solve any induced task. Experimentally, the authors verify the theory and compare to existing approaches to create policy sets, outperforming all. They also provide a set of relevant questions and answers, supported by separate experiments. Finally, they perform experiments in problems without the linear combination assumption and lifelong RL setting, with positive results.","The paper extends the successor features framework to answer the following question: which policies should we learn and store so that, when presented with a new task, we achieve the best performance possible? The paper defines the notion of independent policies (forming a kind of basis over policy space), which can then be combined to solve new tasks (whose rewards are expressible as a linear combination of features) immediately. Experimental results support the theoretical results and show that it is best to learn these independent policies if we wish to maximise performance on downstream tasks.",0.1574074074074074,0.17894736842105263,0.16748768472906403
2790,SP:fbd21efe4c7106337032531053e36b320e241abc,"This paper proposes a novel architecture and regularization technique for RNN, where the hidden state of an RNN is one of (or a soft weighted average of) a finite number of learnable clusters. This has two claimed benefits: (1) extracting finite state automata from an RNN is much simpler, and (2) forces RNN to operate like an automata and less like finite state machines. The authors make (1) immediately clear, and show (2) with empirical results.","This paper is based on the observation that LSTMs use the hidden state to memorize information and the cell state (memory) is not fully utilized. To encourage the LSTM to utilize the cell state, authors constraint the hidden state to a set of centroid states and learn to transition between these centroids in a soft way. Authors demonstrate their model in learning simple regular and context-free languages and also in a couple of non-synthetic tasks. The proposed model also has some interpretability of internal state transitions.",0.17105263157894737,0.14772727272727273,0.1585365853658537
2791,SP:fbeb8df7b683b74f66849b43e92be5050a54a9c0,"The contribution of this paper is twofold. First, the authors introduce a pair of manually collected (via AMT) datasets of creative sketches (birds and general creatures) each along with part annotations. Second, they propose a part-based Generative Adversarial Network for the generation of unseen compositions/configurations of novel parts (legs, body, etc.) for creative sketches. The latter is quantitatively and qualitatively (via human studies) evaluated. ","This paper introduces two creative sketch datasets of birds and creatures, segmented into parts, each with ~10k doodles collected from Amazon MTurk workers. In a user study, people tend to favor sketches from their dataset over the similar Gogole QuickDraw sketches. Additionally, the authors propose a GAN architecture for generating novel sketches in an incremental fashion, one part at a time. They provide many qualitative results as well as human studies to validate their approach.",0.24242424242424243,0.21333333333333335,0.22695035460992907
2792,SP:fbefbf441554c459cac88181fbb20d7b6b440006,"The authors observed that the power consumption is dominated by the bit toggling at the input of the accumulator and decreasing the bit-width of only the weights or only the activations has limited benefit to reduce the the power consumed by the multiplier. The paper proposed PANN, which uses tricks such as unsigned arithmetic in CNN and implement multiplications via additions to achieve a multiplier-free and power-aware neural network. Experiments on both post-training quantization and quantization-aware training showcased better performance compared to other works under the same number of bit-flips. However, the reviewer believes there are fundamental flaws that need to be thoroughly addressed before this paper is ready for ICLR. ","The paper argues that power consumption is a major obstacle in deploying DNNs to end devices and that current quantization approaches do not take power consumption directly into account and therefore are not optimal in reducing it. Using an approximate power model based on the average number of bit flips, they make two observation that are frequently overlooked by existing quantization approaches:  1) A significant portion of the power consumption of the MAC operation is due to the usage of signed integers and using unsigned integers instead can significantly reduce the power consumption. 2) The multipliers power consumption is dominated by the larger bit widths (weight or activation) and therefore using lower bit for one of the two (e.g. weights) is not power efficient.  Based on this the authors introduce a new weight quantization approach (PANN) which removes the multiply operation and replaces it with additions. This allows PANN to efficiently reduces the power consumption. For the same power budget, PANN achieves significantly higher accuracy (or effective bit width), but comes at the cost of higher latency and memory usage. ",0.24786324786324787,0.16022099447513813,0.19463087248322147
2793,SP:fbff504a079c423c1afb1d65623d04d5a360df30,The submitted paper studies the differences in the behavior of typical neural networks and the predictions made by the Neural Tangent Kernel (NTK) framework by showing that the NTK evolves and adapts to the current task during training. The experiments show that the predictions of NTK framework correctly rank tasks in terms of hardness but over- and under-estimate their hardness in different cases. The paper then studies the role of sample size and the directions where NTK evolves.,"Disclaimer: I'm only superficially familiar with the related literature, so this is rather low-confidence review.  The paper investigates whether the study of linearized neural networks via the neural tangent kernel is insightful for understanding generalization in deep learning. It argues that this is indeed the case based primarily on empirical evidence. Overall I am not fully convinced by the significance of the results in this paper, so that I am leaning towards a reject, but I would expect the other reviews to be more informative.",0.21518987341772153,0.19540229885057472,0.20481927710843373
2794,SP:fc2d2ef400ef225020f6aa37cba475fbbbf44fba,"This work proposes to use an augmented RNN model to address the incremental domain adaptation problem. In particular, it designs the progressive memory bank approach which expands the memory capacity by adding parameters every time a new task comes in. The RNN retrieves knowledge from the memory bank via key-value attention. A proof in a highly simplified case is given in addition to empirical results showing that expanding the memory bank is better than expanding the RNN states.","This paper proposes an extensible attention mechanism applied on the previous hidden state of an RNN and resulting in supplementary input for the next RNN step. For each added domain, new pairs of attentions key and values can be added to provide more capacity for the model. This method is applied in the context of incremental domain adaptation for NLP without the possibility of storing of old samples (episodic memory).",0.1518987341772152,0.17142857142857143,0.16107382550335572
2795,SP:fc497267ee411f936495a4b404ed87752f12687f,"The paper suggests a method for quickly computing a ""partial Fourier transform"", which basically means that we want only a small range of output frequencies.  The main technique is an approximation of so called ""twiddle functions"" (which are basically trigonometric functions, or, exponents of complex units if viewed in the complex plane) using polynomials.   The resulting algorithms run in time O(N + M log M) where M is the size of the required frequency range, and N is the input.  This should be compared with Cooley and Tukey's FFT, which is O(N log N).  In fact, the main idea in the paper uses Cooley and Tukey's decomposition of the expression for Fourier transform.","The paper presents a fast approximate algorithm for partial discrete Fourier transform. Given the input signal $a_0...a_N$ in the time domain the algorithm approximately computes the first $O(M)$ frequencies. The running time is $O(r (N + M \log M))$, where $r$ a parameter that controls the accuracy of the output. The algorithm itself proceeds by applying polynomial approximation to the twiddle coefficients in FFT, which makes it possible to reduce the running time.",0.21551724137931033,0.3246753246753247,0.2590673575129534
2796,SP:fc8a52afd27fff291c1fe55d196aa54a759dd42e,This work proposes learning a single control policy for human-in-the-loop learning rather than having a reward learning component and a control component. The key difference is that the action selection can use information from the reward learning module. The authors formulate an assistance game in this setting and show that it can reduce to an equivalent POMDP. The work then describes a communicative assistance problem and shows the equivalence of reward learning to assistance and visa versa. Results show qualitative improvements on variants of the kitchen domain.,"The submission provides a survey of two paradigms for ‘agents learning from human feedback.’ The two paradigms are unified under a new formalism (assistance games), which subsumes them as its special cases. Further, a taxonomy of different problems resulting from the formalism is provided (communicative games, two-phase games, etc.), along with illustrative examples of resulting agent behaviors. Based on the survey and taxonomy, the authors highlight that the assistance paradigm is more advantageous (in terms of possible behaviors that it can result in) than the reward learning paradigm.",0.2111111111111111,0.21348314606741572,0.2122905027932961
2797,SP:fc98effb95b87ad325f609c31b336c7dafd9ac30,"This paper proposes a novel deep reinforcement learning algorithm at the intersection of model-based and model-free reinforcement learning: Risk Averse Value Expansion (RAVE). Overall, this work represents a significant but incremental step forwards for this ""hybrid""-RL class of algorithms. However, the paper itself has significant weaknesses in its writing, analysis, and presentation of ideas.","This paper expands on previous work on hybrid model-based and model-free reinforcement learning. Specifically, it expands on the ideas in Model-based Value Expansion (MVE) and Stochastic Ensemble Value Expansion (STEVE) with a dynamically-scaled variance bias term to increase risk aversion over the course of learning, which the authors call Risk Averse Value Expansion (RAVE). Experimental results indicate notable improvements over their selected model-free and hybrid RL baselines on continuous control tasks in terms of initial learning efficiency (how many environment steps are needed to achieve a particular level of performance), asymptotic performance (how high the performance is given the same large number of environment steps), and avoidance of negative outcomes (how infrequently major negative outcomes are encountered over the course of training).",0.3508771929824561,0.15748031496062992,0.2173913043478261
2798,SP:fc9bd3cf5e1fc8affc1e1d1b183eb4bdd92ddf1d,"This paper proposes a face completion network that synthesizes the missing part in the face images with GANs. Using facial landmarks and facial attributes, face completion became controllable as both are used as conditional information (input) for the generation (synthesis). Moreover, the proposed Frequency-Oriented Attention Module (FOAM) enables an interpretable coarse-to-fine progressive generative process. The proposed methods show significant improvement in the completion quality.","This paper proposes controllable and interpretable high-resolution and fast face completion by learning generative adversarial networks (GANs) progressively from low resolution to high resolution. It combines the masks, landmarks, corrupted images as inputs to generate completed images in high-resolution. The proposed frequency-oriented attentive module (FOAM) encourages GANs to highlight much more to finer details in the coarse-to-fine progressive training, thus enabling progressive attention to face structures.",0.26865671641791045,0.2535211267605634,0.2608695652173913
2799,SP:fcd72bc92c431b2f991d9e765dbdba684cada4e7,"The paper proposes a method to protect deep neural networks against model stealing. The propose defense trains an ensemble of classifiers using two losses one targeting accuracy and the other diversity of the ensemble. In particular, the trained classifiers are consistent on in-distribution data, but contradict each other on out-of-distribution data. The proposed defense does not affect the test accuracy of the victim model while it strongly limits the test accuracy of the clone model.",This paper tackles a timely problem of protecting deep neural networks from mode stealing attacks. This paper proposed an Ensemble of Diverse Model to provide diversity prediction for the adversary’s OOD query. The main contribution of this paper is the introduction of the diversity loss function on OOD data and the discontinuous prediction provided by ensembled models. The results show that EDM defense reduces the accuracy of stolen models.,0.2564102564102564,0.2857142857142857,0.27027027027027023
2800,SP:fcee5370a61cbfb74d07727f29d83623f2f452e5,"The paper proposes a layer-wise method for training the weights of a binary-tree-structured neural network such that it correctly reproduces certain classes of Boolean functions defined by binary-tree-structured Boolean circuits. Specifically, this paper shows analytically that if a circuit satisfies a property termed “local correlation” where there is sufficient correlation between every gate in the circuit and the true output label of the circuit, then this circuit can be learned by a neural network with the same structure as the circuit by training it one layer at a time from the input to the output. The paper motivates this by showing empirically that the k-parity problem with some bias to the labels can be learned by a neural network, but that this does not work when there is no bias in the labels, implying that this bias is necessary for successful learning. The paper shows formally that instances of the k-parity problem satisfy the local correlation assumption and can thus be learned, and also shows that there exists at least one distribution given by a simple generative model that satisfies this assumption and is thus also learnable in this manner. ","This paper aims to study the correlation between the neural network's input and output by abstracting the network as a binary tree Boolean circuit problem. The paper is well-written, motivations are clearly presented, and literature reviews are well placed. The contributions are mainly theoretical, and the experimental plots are simply used for concept illustrations, therefore the correctness of the theoretical analysis has no empirical evaluations. ",0.09644670050761421,0.2835820895522388,0.14393939393939392
2801,SP:fd11668b6b0d122ede44d1dcec6f33e3f4e20e0c,"- To enhance the quality of style-controlled generation, especially in an unsupervised manner and non-parallel setting, this paper proposes a ""style equalization"" mechanism to prevent the content leakage problem. In the style equalization module, the style of a sample is transformed to be the same as the style of ground truth. The authors assumed that content information is time-dependent whereas the style can be time-independent so that the authors employ time-average pooling to learn the global style. Then the style difference is added to the inputs style features. At each time step, a content attended feature queries and attends appropriate style equalized feature via the multihead attention module. The entire model is optimized to maximize the ELBO. The proposed method is demonstrated on speech synthesis and hand-writing synthesis tasks.","In this paper, the authors argue that the typical training algorithms for controllable sequence generative models suffers from the 'training-inference mismatch'. Therefore, to address such a problem, they introduce a style transformation module that is called 'style equalization'. Such a module is designed to enable training using different content and style samples and thereby mitigate the training-inference mismatch problem. To demonstrate the generality of the proposed approach, the 'style equalization' is applied to two tasks of TTS and text-to-handwriting synthesis on three datasets. On both tasks. the models show good results.   Controllable sequential generative models have been studies for years. One of the most fundamental problem is how to effectively capture the content information and style information, respectively. It is a critical while very challenging research problem, because the 'content' and 'style' are entangled in the training samples, and ones must carefully design the training objective such that each of these factor can be learned in a controllable way. The idea of learning the 'style equalization' is interesting, and achieves promising results on tasks in different application scenarios, i.e. TTS and text-to-handwriting synthesis. Despite that, the paper is easy to follow, and the demos show in the project page qualitatively demonstrate the proposed approach.",0.26865671641791045,0.17061611374407584,0.20869565217391306
2802,SP:fd270313e05eb0d810f7e0fc8f807ae3bcdb9dd0,"**General overview:** The paper studies guaranteeing the closed-loop stability of a Markov decision process (MDP) using a given a policy, based on a finite number of trajectories each containing finite number of steps. Both the state and the action spaces are assumed to be subsets of finite dimensional Euclidean spaces. Particularly, the concept of mean square stability (MSS) is used which is guaranteed based on the properties of certain Lyapunov functions. Theoretical results on probabilistic MSS guarantees are provided based on finite samples. A variant of the standard REINFORCE policy gradient method is also presented which searches for a policy having MSS guarantees. Finally, numerical experiments on a simulated cart-pole problem comparing the suggested L-REINFORCE method with the soft actor-critic (SAC) off-policy RL algorithm are shown.","This paper studies the probabilistic stability guarantee of control systems. In general, hard stability guarantee is difficult with only finite samples. The authors instead focus on developing probabilistic stability conditions. High probability bound is derived in terms of the number of trajectories and the length of them. This also leads to a practical policy gradient style algorithm, which is applied to the Cartpole task with desired performance.",0.13740458015267176,0.26865671641791045,0.18181818181818182
2803,SP:fd30a45391475363c65ab80a809f654676cbea71,The paper proposes a new approach to prune weights that is designed keeping large scale pre-trained language representations like BERT. Such a method is desirable for deploying such models on devices with limited memory like phones etc. Experiments on Squad and Glue datasets show that a pruned version of the model maintains high accuracy for these tasks. ,"Models such as BERT are pretrained language models which provide significant improvement for different tasks, however they suffer from high huge size and complexity. This paper has proposed using proximal gradient descent to find sparse weights for BERT to reduce the number of parameters and make the model smaller. They concentrate on the drawbacks of the previous sparse-based approaches and claimed that they have convergence issues (they have provided some evidence in the appendix). therefore, they propose to use reweighed sparse method and optimise it using proximal gradient descent which provides a closed form solution for sparse constraint. ",0.15517241379310345,0.09090909090909091,0.11464968152866242
2804,SP:fd4bc8557b3fd87ae1682252a55de0940854a2e8,"This paper studies the finite depth and width corrections to the neural tangent kernel (NTK) in fully-connected ReLU networks. It gives sharp upper and lower bounds on the variance of NTK(x, x), which reveals an exponential dependence on a quantity beta=d/n, where d is depth, and n is hidden width. This implies that when beta is bounded away from 0, NTK(x, x) is not deterministic at initialization. The paper further analyzes the change of NTK(x, x) after one step of SGD on a single datapoint x, and shows that the change also depends exponentially on beta.",The paper investigates a novel infinite width limit taking depth to infinite at the same time. This is beyond conventional theoretical studies for infinite width networks where depth is kept finite when the width is taken to be infinite. The main object that paper studies is the neural tangent kernel which is of great interest to the theoretical deep learning community as it describes gradient descent dynamics in a tractable way.,0.14705882352941177,0.2112676056338028,0.17341040462427748
2805,SP:fd5ef5edf4f2aba1e3570d05ed55f80a620b50e3,"This paper proposes a layer-flexible adaptive computation time model which enables learning with a different number of layers at each time step.  It proposed a set of mechanisms to make the variable layer possible. It uses attention to re-arrange the hidden states in different layers into a different number of hidden states, thus allowing the hidden layers to be variable between different time steps. It also augmented the RNN to have a transmission state that transmits layer information to the next time step. ","The authors propose Layer Flexible Adaptive Computation Time, an RNN-esque sequence model with varying depth at each time step. The idea is that the model can adaptively choose how much computational effort to spend on each example. The authors evaluate the model empirically on a financial dataset and Wikipedia language modeling, and find that it outperforms a vanilla RNN and the original adaptive computation time (ACT) model.",0.2235294117647059,0.27941176470588236,0.24836601307189546
2806,SP:fd6e2684214576a16d20b00cdfc26ea3e67087a2,"The paper presents a model of spike count distributions in a population of neurons. The model’s spike count distribution depends both on stimulus information and latent variables through a Gaussian process to capture a large range of joint spike count distributions (as the number of factors in the model increases). Moreover, the authors present a set of model fit statistics for evaluating the model fit, and how correlations factor into the model’s predictions.","In this paper authors provide a method for modelling spike counts as a function of input covariates and latent covariates. A Markovin prior is assumed over latent parameters, and the effect of latent parameters and input covariates on spike counts are modelled using a Gaussian process. The authors also suggest a method for calculating Z-scores and tuning index based on their method. The results include analyses of a synthetic dataset and an experimental data, which generally shows the proposed method outperforms considered baselines. ",0.22666666666666666,0.20238095238095238,0.2138364779874214
2807,SP:fd78538153f7e878193f7c975baf7e43baca1a70,"This paper explores the characteristics of the method, Integrated Gradients, as an attribution method, that has been proposed to explain black box models. “Baselines” in analyzing integrated gradients are discussed and the shortcomings of integrated gradients are further evaluated. The paper then proposes Integrated Certainty Gradients and shows its application on data.","In this paper, the authors analyze the fairness of Integrated Gradient-based attribution methods. They exploit SHAP and BShap, two approaches based on the theory of Shapley Values, as the reference of ""fair"" methods.   Specifically, they present an ""attribution transfer"" phenomenon in which the Integrated Gradients are affected by some sharply fluctuated area across the integration path, thereby deviating from the ''fair'' attribution methods. To avoid the attribution transfer issue, they further propose Integrated Certainty Gradients method, where the integration path does not pass through the original fluctuated input space.  Such an objective can be achieved by training the network with perturbed inputs and corresponding certainty maps. Finally, the gradients integral can be calculated by querying the trained network with fixed inputs and varying certainty. Various purpose-designed experiments are performed to demonstrate the advantages of ICG in avoiding attribution transfer.",0.36538461538461536,0.1347517730496454,0.19689119170984454
2808,SP:fd9b13f44129361daef5287b1e96b9ca2fd7e631,"The authors introduce a model-based deep reinforcement learning algorithm that uses tree search based MPC over a learned latent space. In this work, the latent space does not use a vectorized representation but rather a set-based representation with a small bottleneck. The authors then compare their methods to baselines and ablations on a toy environment.","The authors introduce an architecture for focusing agents in model-based reinforcement learning on just the relevant subset of the environment representation for making decisions (reward, termination, and successor state prediction). The approach leans heavily on recent advances in set-based representations and the approach is tested in the MiniGrid-BabyAI framework. Results show promising behaviour, particularly in the ability to generalize across different settings.",0.22807017543859648,0.2,0.21311475409836067
2809,SP:fda41885f51490b9aaf5bc83cf6a772b0edbb9af,"Uses the Meijer-G function to analyse the properties of finite-width Bayesian neural networks.  Provides additional proofs of the infinite-width limit, in addition to results for the infinite depth limit.  Shows that finite networks are heavy tailed and that this increases with depth.","The main result of the paper is a derivation of the exact characterization of priors in function space through Meijer G-functions. The results are obtained for Gaussian priors, ReLU and linear activation functions. The article also provides a solid analysis of the obtained characterization.   **Advantages**:  * It is the first accurate description of hidden units for standard feed-forward neural networks among the concurrent work mentioned in the paper.  * The results are in line with other works on the heavy-tailed nature of hidden units and the Gaussian process limit.  * There is a study on the role of width and depth demonstrating how wider networks lead to more Gaussian-like distributions.  * Authors also introduced generalized He priors that enable to tune the variance induced in the function space.    **Limitations**:  * Only linear and ReLU functions  * Only Gaussian priors  * Without the bias term  ",0.3333333333333333,0.10638297872340426,0.16129032258064516
2810,SP:fdab12cf54b6c3cff52990607369188060910f5c,"The paper analyzes the performative prediction setting (Perdomo 2020) where multiple agents perform gradient descent to converge to a performatively optimal point. The agent are modeled by constrained linear predictive models which are used for linear regression.  The authors show that the learning dynamics  converges to the multi-agent performatively stable point for small learning rates.  The stable point coincides with the optimal point where the sum of the agent's losses are minimized.  The requirement for convergence is that the hessian of the loss must be positive definite, which is satisfied by existence of a potential function.  The authors also show  that the dynamics exhibits Li-York chaos for large enough learning rates.","This paper studied the different behaviours of using exponentiated gradient descent (Def. 2.3) in linear regression with different learning rates. The setting is called performative prediction, which can be viewed as a special case of reinforcement learning (after the model makes a prediction, the environment returns a feedback by changing the data distribution).  The main results consist of two parts, for small enough and large learning rates:  (i) with small enough learning rate, the authors proved that the exponentiated gradient descent is ""stable"" (asymptotically converges to some global minimizer). The proof is based on standard analysis of studying a potential (surrogate/Lyapunov) function for the mean squared error, and arguing that the gradient flow vanishes only if the potential approaches $0$, which implies that the convergence of the flow. Then the discrete gradient update is approximating the flow well if the stepsize is small enough.  (ii) if the learning rate is larger than some threshold value, the authors then showed that the exponentiated gradient descent became Li-Yorke chaotic, where it can periodically oscillate for infinitely many times. The main idea is to use Eq. (7) to characterize the dynamics, and show that under some conditions Eq. (7) induces a sequence of { x_i }_{ i >= 1}, with some recurrent behaviours as shown in Lemma 4.7.  The authors then verified the theoretical findings using simulations on simple examples.",0.2807017543859649,0.13973799126637554,0.18658892128279883
2811,SP:fdd497d17b5a12017b4ceb377de57bfc18ebd815,"In this paper the authors propose a novel architecture, called Mass-Conserving LSTM (MC-LSTM) based on LSTM. The authors base their work over the hypothesis that the real world is based over conservation laws related to mass, energy, etc. Thus, they propose that also the quantities involved in deep learning models should be conserved. To do so, they aim at exploiting the memory cells of the LSTM as mass accumulators and then force the conservation laws via the model equations. The authors finally show successfully the potential of this novel network into three experimental settings where several types of “conservation” are required (e.g. mass conservation, energy conservation, etc).","The paper provides an interesting and novel LSTM structure named MC-LSTM, which extends the inductive bias of LSTM to deal with some real-world problems limited by conservation laws. The authors do some experiments related to traffic forecasting and hydrology to illustrate the effectiveness of MC-LSTM.  The new architecture is well-suited for predicting some physical systems, which is valuable.",0.15454545454545454,0.27419354838709675,0.19767441860465118
2812,SP:fdee0ede48073d769467a45af029bf5c798ab6ce,"The authors present a generative model for videos where the latent trajectories have two components - a term without a slowness loss that represents ""content"" and a term with a slowness loss that represents ""style"". They present results on a dataset simulating the wave equation and on videos of moving MNIST digits and 3D chairs. The results are generally good, especially for long roll-outs, and they demonstrate something like disentangling by showing that the identities of the digits can be swapped in the moving MNIST data.","The paper presents a spatiotemporal disentanglement method for handling sequence data. Solving high-dimensional PDEs, for deriving the exact dynamics, is difficult; hence, this work proposes learning time-invariant and time-dependent representations separately to solve this problem. To achieve this goal, the authors devised a model that incorporates a temporal ODE process. The provided experiments indicate that the method achieves good performance, although the gain is not consistent.",0.13953488372093023,0.17391304347826086,0.15483870967741933
2813,SP:fdf6eccb626f29ace14ead921e976448e2dd8bb8,"The Authors show that scaling factors with hand-crafted or learnable methods are not so important when training Binary Weight Networks (BWNs), while the change of weight signs is crucial. They make two observations: The weight signs of the primary binary sub-networks are determined and fixed at the early training stage. Binary kernels in the convolutional layers of final models tend to be centered on a limited number of fixed structural patterns. Based on these observations, they propose a new method called binary kernel quantization to further compress BWNs. ","This paper proposes some interesting observations for training BWNs. 1: The scaling factors can be removed with batch normalization used. 2: The signs of the weights with large norms are determined and fixed at the early training stage. 3:  The binary weight networks can be further compressed. Moreover, the authors provide some empirical visualizations and results to demonstrate its analysis. However, the paper seems to be incomplete and needs to be further improved. ",0.25555555555555554,0.3150684931506849,0.28220858895705525
2814,SP:fe04f7ffacf4dfa43448503ac2fa7a5f7f14ab3d," The paper focuses on reducing data labeling efforts by improving data efficiency. In contrast to most existing approaches that address this problem only in the classification setup, the paper focuses on both classification and regression set ups. The proposed method primarily is built on leveraging invariance to data stochasticity and model stochasticity. Experiments are conducted on various tasks like age estimation, key point localization, and object recognition. ","The paper presents a g data-efficient approach that encourages invariance to both data and model stochasticity that works for both classification and regression tasks. Furthermore, the proposed minimax loss function can specifically enhance invariance to model stochasticity. The extensive experimental results verify that the proposed method is effective.",0.22388059701492538,0.30612244897959184,0.25862068965517243
2815,SP:fe1017ead727444727d5b16195f6c7d3babf1931,"The paper proposes a new training algorithm to defend against membership inference attacks (MIA) in machine learning models. Motivated by the connection between MIA success and difference between training and test loss distributions, the proposed algorithm sets a positive target mean training loss value and applies gradient ascent if the average loss of current training batch is smaller than it. Furthermore, to avoid hurting model accuracy, the proposed algorithm also flattens the probabilities among incorrect labels during training steps. Extensive results on multiple datasets along with several defense baselines validate the effectiveness of the proposed defense idea.","The study tackles the problem of defense against membership inference attack, with a focus on (1) decreasing the performance of the attack, (2) maintaining the classifier’s performance, (3) assuming the blindness towards the attack model. They achieve (1) by closing the distance between the train and test distributions and maintain the utility of the model by flattening the posterior scores of the non-target classes. Their method is shown to be computationally efficient (i.e., the additional computational cost is negligible), close to optimal in maintaining the trade-off between the utility and attack performance, and effective in the face of attack’s countermeasures.",0.1958762886597938,0.18095238095238095,0.18811881188118812
2816,SP:fe103976fa70a0c45fbc1056c39851a76a3e1451,"This paper studies the problem of dense text retrieval, which represents texts as dense vectors for approximate nearest neighbors (ANN) search. Dense text retrieval has two phases. The first phase learns a representation model to project semantically similar texts to vectors of large similarity scores (e.g. inner products or cosine similarity scores). The second phase adopts an ANN search algorithm to index these vectors and process queries. The paper claims key contributions at the first phase. Specifically, (1) The paper introduces a better negative sampling method to sample good dissimilar text pairs for training.  (2) The new method enables faster converge of model learning. (3) The new method leads to 100x faster efficiency than a BERT-based baseline, while achieving almost the same accuracy as the baseline. ","Authors start from an assumption: “local negative sampling is the bottleneck of dense retrieval’s effectiveness”. To overcome this limitation, authors propose ANCE (Approximate nearest neighbour Negative Contrastive Estimation), a new contrastive representation learning mechanism for dense retrieval. The basic idea is that of constructing negatives exploiting the being trained deep retrieval module. The idea is that the model considers as negatives borderline cases. They also show, theoretically, that this improves the variance of the stochastic gradient estimation thus leading to faster convergence.",0.140625,0.21686746987951808,0.17061611374407581
2817,SP:fe137babff80e9e5f48e44f36a86a71d095d6264,"This paper proposes a new option discovery method for multi-task RL to reuse the option learned in previous tasks for better generalization. The authors utilize demonstrations collected beforehand and train an option learning framework offline by minimizing the expected number of terminations while encouraging diverse options by adding a regularization term. During the offline training, they add one option at a time and move onto the next option when the current loss fails to improve over the previous loss, which enables automatically learning the number of options without manually specifying it. Experiments are conducted on the four rooms environment and Atari 2600 games and demonstrate that the proposed method leads to faster learning on new tasks.","The authors propose to learn reusable options to make use of prior information and claim to do so with minimal information from the user (such as # of options needed to solve the task, which options etc). The claim is that the agent is first able to learn a near-optimal policy for a small # of problems and then is able to solve a large # of tasks by such a learned policy.  The authors build on the idea that minimizing the number of decisions made by the agent results in discovering reusable options. The options are learned offline by learning to solve a small number of tasks. Their algorithm introduces one option at a time until introducing a new option doesn’t improve the objective further. The ideas are interesting, However, the paper as it stands is lacking in thorough evaluation.",0.20512820512820512,0.17142857142857143,0.1867704280155642
2818,SP:fe24152df3ec630eed6ec8adbf88d3a044e78123,"This paper considers reinforcement learning, a common model which has seen success recently in many areas (e.g. games, robotics, autonomous vehicles).  Prototypical reinforcement learning algorithms explore the action space in order to maximize their rewards as much as possible, potentially ignoring impacts of the chosen actions or safety constraints.  Typical to many real-world scenarios, though, are constraints on the selected actions allowing the algorithm designer or practitioner to enforce certain constraints on the selected actions in the environment (e.g. ensure that the autonomous vehicle stays within the dictated lines on the road, etc).  This is typically done by introducing a cost-function and adding an additional constraint that the resulting policies have long-run discounted cost upper bounded by a given constant.  While many RL algorithms have been designed in this setting, they mostly focus on either taking lagrangian relaxations of the given policy constraints, or constructing convex approximations to the non-convex objectives to optimize (which also in turns adds to additional complexity in constructing higher order moments of the objective for optimization).  In contrast, the authors in this paper take a different view, via the following: 1. Construct tight upper and lower bounds on the difference in value functions for arbitrary policies with respect to arbitrary functions $\phi$, a given additional discount parameter $\lambda$ 2. Instantiate the upper bound with $\phi$ taken as the value function to get a lower bound on the difference in value between any two policies 3. Instantiate the lower bound with $\phi$ taken as the cost-value function to get an upper bound on the cost-difference between any two policies  Once these bounds are established, the algorithmic approach is simple.  In the first step they perform a performance improvement step to improve the performance of the policy by maximizing the lower bound on the difference in value between the two policies.  The second step is a projection step, where after lagrangianizing the constraint set they minimize the lower bound on the difference in costs between the two policies.  The authors show a guarantee on per-step improvements on the rewards and cost for this proposed approach assuming exact maximization / minimization of these objectives.  To be more specific, the authors consider the typical RL model with an MDP characterized via $(S, A, P, r, \gamma)$.  They consider the goal of maximizing the expected long term rewards $r$.  However, there is an additional cost function $c$ and they add an additional constraint that the long-run discounted cost is upper bounded by a given constant $b$.  The hope is that the learned policy picks actions which satisfy the long-run average cost constraint while simultaneously maximizing the expected rewards.  The authors first start-off by proposing a novel bound, generalizing the policy performance difference $J(\pi_\theta) - J(\pi_{\theta'})$ between any two policies.  In particular the difference is upper and lower bounded by two terms.  The first term can be interpreted as the expectation between the TD errors of $\pi_\theta$ and $\pi_{\theta'}$ where TD errors are computed for an arbitrary function $\phi$.  The second part is the discounted distribution difference between the two different policies.  These bounds are then instantiated with different functions $\phi$ and parameters in order to get lower and upper bounds on the performance difference between the policies with respect to the costs and rewards of the problem.  Once these lower and upper bounds on the performance difference are established, the algorithm falls naturally by maximizing the reward lower bound and minimizing the cost upper bound.  This is then theoretically justified by providing a per-step improvement with respect to the two different objectives.    To complement the algorithmic framework, the authors present a set of synthetic experiments to compare the efficiency and constraint violation of the resulting policies of their method and others in the literature.  In particular, they test the policies on three different environments and compare to several other existing algorithms in the literature (more on this later).  They show that their algorithm and approach dominates others in terms of performance while simultaneously ensuring the cost constraints.","The paper studies the problem of learning under constrained Markov decision processes. It proposes to solve this problem by an RL algorithm based on generalized advantage estimator (GAE), which they call  Conservative Update Policy (CUP). Although existing works have already proposed GAE-based algorithms, the current paper is the first to provide theoretical foundations for this type of algorithm. Specifically, it proves bounds on performance difference for GAE-based algorithms and one-step improvement for CUP. Numerical experiments have been conducted to showcase the performance of the proposed algorithm.",0.04678362573099415,0.3595505617977528,0.08279430789133246
2819,SP:fe4311ff10c0e6b01762ca54b800211e3825c827,"The paper proposes a way of data augmentation based on human feedback. Namely a human experts is tasked with marking on relevant areas of the state space (visual input, frames) with bounding boxes. The rest of the input is then blurred, which, presumably, should lead to the learning algorithms ""focusing"" on relevant areas and learning to ignore irrelevant (blurred) ones. Experiments on 5 simulated environment show that applying this technique leads to somewhat lower sample complexity and better final performance.  In my estimation this is an interesting idea on using human-in-the-loop for RL training and would be useful for RL practitioners working on such visual environment where data samples are expensive. Real-world robotics would be one such example.","This paper proposes EXPAND - a method for allowing human input and semantic understanding to guide policy learning for RL agents. Humans are asked to provide binary feedback (good/bad) on actions taken by the agent, as well as highlight visual features which helped guide their decision (e.g. stop sign tells human to stop). The binary feedback is used to train an advantage function by leveraging a large margin classification loss. The visual highlighting is used to supervise feature learning by way of a consistency loss on perturbed data (i.e. blur segments not highlighted by human).",0.13114754098360656,0.16494845360824742,0.14611872146118723
2820,SP:fe4532be285cebd1862e5a8f4f115c00946c3cec,"This paper proposes a scheme for incorporating compressed (sparsified) gradients with momentum in distributed SGD. The approach differs from others in the literature, comes with theoretical guarantees, and improved performance. The results are correct, and the experiments illustrate that the proposed approach can make a difference (albeit, modest) in the quality of the resulting model.","Gradient sparsification is an important technique to reduce the communication overhead in distributed training. In this paper, the authors proposed a training method called global momentum compression (GMC) for distributed momentum SGD with sparse gradient. Following existing gradient sparsification techniques such DGC, GMC is also built up on the memory gradient approach; the major distinction between GMC and existing techniques is that GMC keeps track of global gradient to maintain the memory gradient, while the existing technique keeps track of worker-local gradients for memory gradient. The primary contributions in the paper are as the following:",0.2909090909090909,0.16666666666666666,0.2119205298013245
2821,SP:fe4742a7415e0bbb189d999c86edf90781733e46,"In this work, the authors use an LSTM to meta-learn learning rate schedules. This LSTM depends only on the validation loss at time t. They train this LSTM for some tasks and they show that it gives good performance when compared with baselines. Then they transfer one of these trained LSTMs to different tasks and gives good results. ","The paper proposes to parameterize learning rate (LR) schedule with an explicit mapping formulation. This learnable structure allowed the proposed meta-trained MLR-SNet to achieve good LR schedules. For validation, the proposed method is evaluated on both image and text classification benchmark with various network architectures and datasets, as well as transfer the learned network for new task or architectures. ",0.1694915254237288,0.16393442622950818,0.16666666666666666
2822,SP:fe52a638fdb309b8fcb1232b0f23e08c96965721,"This paper explores a new direction, to utilize the searched results (image caption pair) to improve downstream multimodal learning tasks. They first pre-trained a cross-modal model using the contrastive learning on the image caption dataset. Then they use the pre-trained model to search the relevant terms for image or text input, and augment the searched results as the input for the downstream multi-modal tasks.","This paper proposed a cross-modal retrieval augmentation for the multi-modal classification task (VQA). The authors first introduce a transformer-based image caption retrieval architecture that achieves decent performance. Then, the authors proposed to use the retrieval model to retrieve relevant visual and textual information as augmentation. The proposed method experiment on 3 existing method (Visual Bert, ViLBERT, and Movie + MCAN) and show good improvements over the baseline model. ",0.27941176470588236,0.2714285714285714,0.27536231884057966
2823,SP:fe56b465b11b4f99ed9eb8bd07d08254e8603a80,"The paper introduces the problem of subspace spitting, in which an observed mixed-features vector is to be partitioned such that the identified partitions match with given subspaces. The main results of the paper lie in deriving sufficient and necessary conditions for identifiability of these partitions when the subspaces and the entries of the features are randomly positioned in the ambient dimension and the subspaces, respectively. The conditions simply require that there are more entries associated with each subspace than the dimension of the subspace. The paper also presents algorithms to perform the splitting. ","The authors propose a method to perform subspace splitting. That is, the task of clustering the entries of an input vector into sets of coherent subspaces. The contribution of the work is two-fold: (1) the theoretical characterization of the problem, and its well-posedness, and (2) the presentation of three algorithms for tackling the problem of subspace splitting. Quantitative analysis of the performance of the three algorithms is provided by means of synthetic experiments.",0.2127659574468085,0.26666666666666666,0.23668639053254437
2824,SP:fe82ab63dd059eb091d28343b102628022023b0b,"The paper proposes a way to speed up softmax at test time, especially when top-k words are needed. The idea is clustering inputs so that we need only to pick up words from a learn cluster corresponding to the input. The experimental results show that the model looses a little bit accuracy in return of much faster inference at test time. ","This paper presents an approximation to the softmax function to reduce the computational cost at inference time and the proposed approach is evaluated on language modeling and machine translation tasks. The main idea of the proposed approach is to pick a subset of the most probable outputs on which exact softmax is performed to sample top-k targets. The proposed method, namely Learning to Screen (L2S), learns jointly context vector clustering and candidate subsets in an end-to-end fashion, so that it enables to achieve competitive performance.",0.22580645161290322,0.1590909090909091,0.18666666666666665
2825,SP:fe8c2ff8b3d5980861f2b5f81057d361903d985b,"This paper introduced a very interesting idea to facilitate exploration in goal-conditioned reinforcement learning. The key idea is to learn a generative model of goal distribution to match the weighted empirical distribution, where the rare states receive larger weights. This encourages the model to generate more diverse and novel goals for goal-conditioned RL policies to reach.","The paper proposes an exploratory objective that can maximize state coverage in RL. They show that a formal objective for maximizing state coverage is equivalent to maximizing the entropy of a goal distribution. The core idea is to propose a method to maximize entropy of a goal distribution, or a state distribution since goals are full states. They show that the proposed method to maximize the state or goal distribution can lead to diverse exploration behaviour sufficient for solving complex image based manipulation tasks. ",0.3103448275862069,0.21428571428571427,0.2535211267605634
2826,SP:fe963687c10f65d3f824a56f900de29ccabccb43,This paper improves a model-based reinforcement learning method by Kaiser et al. (2020) by introducing three different types of neural network layers to the transition and reward model. These modifications are motivated by intuitions about what would be beneficial to model for object-based environments (in Atari games). There are experiments on 12 games in which the proposed method performs the best most of the time. Ablations show that using any one of the three proposed layers is also beneficial. ,"This paper proposes an approach for Model-based reinforcement learning relying on Posterior Sampling for Reinforcement learning. Posterior sampling for reinforcement learning uses Thompson sampling to balance exploitation and exploration. However this requires maintaining posterior of dynamic transitions which is often intractable. The authors use dropout, which has been shown to approximate posteriors, to maintain approximate posteriors of the transitions and the reward function. The system model presented in the paper specifically applies to object-based tasks. Only three event convolutional layers use dropout: one for object interaction, one for event weighting and one for event translation. These layers can be inserted into any existing neural network model to provide an approximate posterior. The authors combine this model with a PPO agent trained on the model to show its empirical performance on Atari games with a limited number of interactions with the real environment.",0.25925925925925924,0.14583333333333334,0.18666666666666668
2827,SP:feabfeef5c1282d0b8de3d98611588b698013baf,"In this paper, the authors introduce a new quantitative diversity measure advocating its usage for generative models evaluation. In a nutshell, to measure the diversity of a particular set, the authors split it into disjoint train/val subsets and learn a DNN to predict the outputs of another randomly initialized DNN on the train set. Then the generalization gap of the trained DNN is computed on the unseen val subset, and the normalized value of this gap (averaged over several splits/initializations) is considered as a diversity measure.","This paper applies random network distillation (RND) as a method for quantifying how diverse samples from a generative model are. Samples from the generative model (or any dataset) are used to train a neural network to mimic a randomly initialized network. Intuitively, this is a more difficult task on a more diverse dataset, and so the distillation loss can be interpreted as a measure of diversity. The authors argue that this approach has advantages over other diversity metrics because it can capture semantic diversity and does not require a second reference dataset.",0.2159090909090909,0.20652173913043478,0.2111111111111111
2828,SP:feb94b9d13dc703ab029bc4842e32baf0af249f2,"This work considers the task of learning user personalised predictive models in the federated learning setting. It is realised via a local Gaussian Process (GP) on each client which operates on top of features extracted from a neural network that is shared across the entire federation, named pFedGP. The authors motivate the usage of GPs via their Bayesian nature which allows for good performance in the low data regime (common in federated learning) as well as the extraction of prediction probabilities that are calibrated (crucial for safety-critical applications of FL).   Since the authors operate on federated classification tasks,  they employ the GP classification model proposed at [1], which decomposes a multi-class prediction problem into a series of binary predictions. The benefit of this is that one can use the Polya-Gamma augmentation scheme, which can allow for efficient sampling of the posterior distributions, necessary for learning the hyper parameters of the model. The authors then  introduce two additional variants of their overall model which employ inducing points, a common technique in the GP literature. The first one is motivated for improving the performance of the model in the case of limited data, whereas the second one is about making the model more scalable in the case of large local datasets. Finally, the authors also provide a PAC-Bayesian generalization bound for the model performance one new clients that enter the federation.   The paper concludes with a series of experiments that compare the performance of pFedGP against several baselines for federated learning and personalised federated learning.   [1] GP-Tree: A Gaussian Process Classifier for Few-Shot Incremental Learning, Achituve et al., 2021","This paper presents a new framework for personalized federated learning via Gaussian process classification (GPC) model. The key idea is to have each client node maintain its own GPC model but share the NN feature map f(x). Here, the GPC model of client c is equipped with kernel k_c(x, x') = k_c( f(x), f(x'); w_c)  with personalized parameters w_c.   Thus, per iteration, a subset of clients is selected. Each client c downloads the shared f(x) from server and re-build its GPC model (i.e., re-fitting for w_c) using local data D_c. A local updated feature map f(x) (via gradient propagation) is then computed for each client and communicated to the server, which averages the updated model to form a new feature map f(x).  The proposed framework is evaluated on 3 image datasets: CIFAR-10, CIFAR-100 and CINIC-10. The reported performance shows that it outperforms a selected set of baselines substantially when the amount of data per client is small & heterogeneous.",0.12087912087912088,0.1875,0.14699331848552338
2829,SP:fed001660e9a62c1bb55a1a5500f8b27ab40f348,"This work revisits a famous counterexample on the convergence of Adam (originally presented in Reddi 2018). The authors show that, if the EMA parameter beta2 in RMSprop and Adam is chosen high enough, then both methods converge to a bounded region in the stochastic setting. In addition, the authors provide some results for the full-batch case. Crucially, and differently from many other papers on the topic, the gradients are not assumed to be bounded and the beta2 hyperparameter is not chosen to increase to 1.","The paper starts off from the recent realization that there exists divergent examples for any set of hyperparameters for algorithms in the Adam family, such as RMSProp. It sets out to study the effect of the beta2 parameter on convergence for a fixed specific problem. The analysis shows that there exists a beta2 < 1 that leads to convergence for realizable problems, and to convergence to a bounded region of interest for non-realizable problems, without requiring a bounded-gradient assumption. Experiments confirm this new theory.",0.16279069767441862,0.16470588235294117,0.16374269005847952
2830,SP:fed81f79f821a00e7bf5e3fdd1bbf3ce269b46f8,"This paper formulated higher-order CNNs into a Tucker form and provides sample complexity analysis to higher-order CNNs and compressed designs of CNNs via tensor analysis. It uses then theoretically analyzes the efficiency of four block designs from ResNet, MobileNetV1, and MobileNetV2. The paper also conducts numerical experiments to verify its theoretical results and provide some empirical studies to show that increasing the expansive ratio of a bottleneck","This paper provides theoretical analysis of the estimating power of CNN (3 and 5 layers). By formulating the problem using tensors, the authors showed that the estimating error of the learned CNN weights with respect to the true weights is of the order $\sqrt{d/n}$ where $d$ measures model complexity and $n$ is the training sample size. In addition, the authors considered low rank approximation to the convolution tensor through CP and Tucker decompositions, and they derived convergence result for the CNN weights in this case. The authors then applied these results to analyze different block designs through numerical experiments and ablation studies.",0.21739130434782608,0.14423076923076922,0.17341040462427743
2831,SP:ff0683b5929993e2f909081930bc30353a7a4d55,"The paper introduces a randomized compress-to-integer operator with a shared scaling factor for use in data communication in distributed SGD.  The resulting algorithm is provably convergent, matches the behavior of SGD up to constant factors, and works well with the all-reduce primitive.  The authors claim three main contributions: the IntSGD algorithm itself, the analysis of convergence rates, and the IntDIANA variant for heterogeneous data distributions (though this is only discussed in the appendices).","The authors propose a quantized parallel SGD where the gradient coordinates are rounded after scaling: $Q_\alpha(g) = $ round$(\alpha g )/\alpha.$ The scaling factor $\alpha$ determines the quantization error: higher the $\alpha$, lower the quantization error. The authors propose a clever $\alpha$ shared across workers. Such sharing of $\alpha$ allows for in-network aggregation of gradient updates using programmable switches. It also allows for an all-reduce model of parallel SGD which can be much more efficient than the all-gather model. A previous version Heuristic IntSGD uses a scaling factor that is more intuitive (uses all available bits binning the known range), but interestingly its accuracy is suboptimal on some tasks. Other integer rounding methods such as QSGD use a scale $\alpha$ that is not the same across workers and hence it does not allow the all-reduce primitive.  ",0.19736842105263158,0.10638297872340426,0.1382488479262673
2832,SP:ff1a7f2310f3d3c647ede8e418dcc104b9da3e2b,"This paper proposes a pretraining technique for question generation, where an answer candidate is chosen beforehand, and the objective is to predict the answer containing sentence given a paragraph excluding this sentence and the target answer candidate. The intuition of this method is that question generation requires to generate a sentence which contains the information about the answer while being conditioned on the given paragraph. In particular, the paper compares its approach to Devlin’s presentation (https://nlp.stanford.edu/seminar/details/jdevlin.pdf according to the references; is it not a published work?) which uses next sentence generation for pretraining, that is less related to the downstream question generation task.","The paper in the field of machine reading comprehension. The authors address the issue of generating labeled data of question-answer tuples, without the need of manual annotation. Specifically, the authors propose a method that dynamically generates K answers given a paragraph  in order to generate diverse questions and, secondly, pre-training the question generator on answers in a sentence generation task. The authors then show that this method is superior to existing baseline methods.",0.18018018018018017,0.26666666666666666,0.21505376344086022
2833,SP:ff2c79dd5ef9325a3f48750082a994b3ad9be172,"The authors present a method to regularise the learning of Q values within Decentralised partially observable markov decision processes, where the regulariser is one that minimises surprise in some way across the population of agents within the environment.  This it is argued allows the agents to avoid situations in which states are ""rapidly changing"", instead aiming to reach an equilibrium state where just enough surprise is being experienced as part of a reward maximising objective.  The authors present a series of results in which their method outperforms a number of SoTA alternatives on a reasonable looking set of benchmarks, as well as an ablation study showing the criticality of each proposed component. ","This paper introduced a suprise term in optimizing the policies (action-value functions in Q-learning) for solving the non-stationary challenge due to the rapid changes from the environment for MARL scenarios. This work not only proposed the concept of suprising value in the context of MARL, but also gave an operator (i.e. a contration) that can make the sequence of suprising values converges to a fixed point. The general sketch of the proofs is correct. Also, the authors showed that the convex conjugate of the suprising value operator is analogous to the minimization of the uncertainty among agents. By incorporating the suprising value into the Q-learning algorithm, the term led by the ratio between target and behaviour suprising value (suprising ratio) can also be interpreted as an intrinsic reward. Moreover, the authors also compare the proposed surprising minimization objective with the Soft Q-learning objective. ",0.1875,0.14093959731543623,0.16091954022988503
2834,SP:ff33ca31b3a0a1ea2407449a2f2a7317c8a94110,This paper proposes fine-tuning an out-of-distribution detector using an Outlier Exposure (OE) dataset. The novelty is in proposing a model-specific rather than dataset-specific fine-tuning. Their modifications are referred to as Outlier Exposure. OE includes the choice of an OE dataset for fine-tuning and a regularization term evaluated on the OE dataset. It is a comprehensive study that explores multiple datasets and improves dataset-specific baselines.,"This paper describes how a deep neural network can be fine-tuned to perform outlier detection in addition to its primary objective. For classification, the fine-tuning objective encourages out-of-distribution samples to have a uniform distribution over all class labels. For density estimation, the objective encourages out-of-distribution samples to be ranked as less probability than in-distribution samples. On a variety of image and text datasets, this additional fine-tuning step results in a network that does much better at outlier detection than a naive baseline, sometimes approaching perfect AUROC.",0.20833333333333334,0.1595744680851064,0.1807228915662651
2835,SP:ff34a84b45570d684598dda4a9cd63be2a459e51,"The paper combines two recent areas of interest in optimization for machine learning: average-case analysis for acceleration and learning in bilinear games.  Average-case optimal methods are proposed for some distributions on eigenvalues for the Jacobian of the games vector-field. Also, a connection is made between average-case optimal methods in bilinear games and optimally solving the Hamiltonian.","In this submission, first-order methods for solving smooth games are studied in the average case. In particular, first-order methods are derived and studied that are average-case optimal for certain optimization problems. In particular average-optimal first-order methods for solving zero-sum minimax games are presented. Also for finding the root of non-symmetric affine operators average-case optimal operators are derived if either the relevant matrix is normal or the eigenvalues are supported in a disk. Some experiments with the derived methods are conducted but the focus lies clearly on the theoretical results.",0.3,0.18556701030927836,0.22929936305732485
2836,SP:ff4023ed4a9a57ecd8ccabe2a7ceab3d6a0202da,"This paper studies how to conduct statistical inference with M-estimators based on data collected from adaptive algorithms. It proposes an adaptively weighted M-estimator with square-root importance weights and proves that under fairly standard assumptions, the estimator (uniformly) has asymptotic normal distribution and it can be used to construct uniformly valid confidence intervals. By studying M-estimation problems, this paper substantially broadens the scope of estimation problems in this recent literature of statistical inference with adaptively collected data. ","The authors analyze square root importance sampling weighted M-estimators over parametric classes for adaptively collected data.   This work is motivated by the fact that the usual unweigthed M-estimators that one would use for i.i.d. data fail to be asymptotically normally distributed under adaptively collected data.  Under appropriate conditions, the proposed weighting scheme makes the resulting M-estimator asymptotically normal, uniformly over the parameter space.  The authors demonstrate their claims through simulations.",0.1375,0.14666666666666667,0.14193548387096774
2837,SP:ff4879a21fee38d85c20afbb9c7fcac541ee3714,"The authors study how neighbor information on graphs can be used in Graph Neural Networks. It proposes measures on whether the data in neighboring nodes are useful in terms of labels or features. It also provides a new Graph Neural Network algorithm that is a modification of attention-based models incorporating the derived label and feature smoothness measures. The paper demonstrates the usefulness of these measures and algorithms with several different baselines from different families. The writing is mostly smooth, and the authors seem to provide enough detail of the experiments performed.","The paper proposes two graph smoothness metrics for measuring the usefulness of graph information. The feature smoothness indicates how much information can be gained by aggregating neighboring nodes while the label smoothness assesses the quality of this information. The authors show that Graph Neural Networks (GNNs) work best for tasks with high features smoothness and low label smoothness by utilizing information from surrounding nodes which also tends to have the same label. Based on these two metrics, the authors introduce a framework, called Context-Surrounding Graph Neural Network (CS-GNN), that utilizes important information from neighboring nodes of the same label while reduce the disturbance from neighboring nodes from different classes. The results demonstrate considerable improvement across 5 different tasks. ",0.2391304347826087,0.18333333333333332,0.20754716981132076
2838,SP:ff58b8e7f4f0ae436627d7039f8c883a63f15101,"This paper discusses the value of creating more challenging environments for training reinforcement learning agents. Specifically, the paper focuses on three characteristics of the environment that the paper claims are necessary for developing intelligent agents. The first of these properties is stochasticity in the environment transitions, specifically stochasticity that is independent of the action taken by the agent. The next is sparsity of rewards; discontinuing the use of reward shaping to define desired behavior. Finally the paper argues that environments should not be episodic, that natural environments are continuing tasks so research focus should be around solving continuous tasks.","The authors study what they refer to as ecological reinforcement learning, defined as the interaction between properties of the environment and the reinforcement learning agent. They introduce environments with characteristics that reflect natural environments: non-episodic learning, uninformative reward signals, and natural dynamics that cause the environment to change. These factors are shown to significantly affect the learning progress of RL agents and, unexpectedly, the agents can sometimes learn more efficiently in these more challenging conditions.",0.1414141414141414,0.18421052631578946,0.16
2839,SP:ff7ab4e497018b2fa801bd05e7e14d59265babed,"This paper investigates the problem of predicting the truth of quantified boolean formulae using deep reinforcement learning. In this setting, the problem is formulated as a reinforcement learning task, in which the learner is interacting with a solver (CADET), and its goal is to find a sequence of actions (each associated with a choice of a variable and a value) in order to reach a terminal state as fast as possible. The neural architecture includes a GNN encoder for the input formula, a policy neural net for iteratively assessing the quality of literals, and a final softmax layer for choosing the final literal. Experiments, performed on various 2QBF instances, address several questions such as the ability to compete with existing heuristics (VSIDS) in CADET and to generalize predictions on long episodes or different formulae.","This will be an uncharacteristically short review. The work poses an interesting idea: why not mix heuristics and learning. It reads as if the paper was written a while ago and the intro was not updated, since there is a lot of related work using the same concept. Please cite existing work in the introduction, it reflects negatively on the paper.",0.1044776119402985,0.22950819672131148,0.14358974358974358
2840,SP:ff7cdd0d7c011a59c7fc3088f7dbd6145fc3ca72,"This paper provides theoretical analysis of graph neural networks for link prediction, following a number of recent papers that have developed the theoretical understanding of graph neural networks. For example, the work of Xu et al (ICLR 2019) draws on the Weisfeiler-Lehman graph isomorphism test to develop a theoretical framework in which to analyse the expressive power of Graph Neural Networks. In particular, they show that architectural features in common graph neural network models limit the expressivity with respect to problems of node and graph classification and show how one can construct graph neural networks whose expressivity matches the Weisfeiler-Lehmam test. In more recent work, Li et al (NeurIPS 2020) show that augmenting node features with a ""distance encoding"" enables a graph neural network to distinguish node sets in cases where the Weisfeiler-Lehman test fails. This submission is perhaps most closely related to this recent paper of Li et al.","The paper focuses on the link prediction task for graph neural networks. More specifically, it compares GAE and SEAL by providing theoretical evidence why GAE is not able to learn structural link representations, which as a result leads to suboptimal performance in the link prediction task. The paper also introduces a labeling trick that can help GNNs to learn structural link representations. ",0.0915032679738562,0.22580645161290322,0.13023255813953488
2841,SP:ff9b59f83d1d206ef246db96f13b43ac39c54db8,"In this paper the authors study stochastic proximal point algorithm for nonconvex optimization, where the model is iteratively updated by solving a proximal optimization problem based on a randomly selected loss function. The authors develop efficient implementation for solving the proximal optimization problem: first for nonlinear least squares and then for general losses. Then the authors study the convergence rates for the developed algorithm. Upper bounds on the expected average squared gradients are developed for both constant step sizes and diminishing step sizes. Experimental results are also reported to support the algorithm in practical implementations.","This paper studies the stochastic proximal point algorithm (SPPA) for large-scale nonconvex optimization problems. The authors propose to use Gauss-Newton to perform the proximal update in nonlinear least squares and L-BFGS or accelerated gradient for generic problems. The authors derive the convergence of SPPA to a stationary point in expectation for nonconvex problems, and perform numerical experiments to showcase the effectiveness of the proposed method compared to SGD and its variants. ",0.28421052631578947,0.36486486486486486,0.3195266272189349
2842,SP:ffa69b99230ed18f02cbb7acb37cf3cd801ec908,"The paper proposes a new GNN architecture based on Generalized PageRank to handle two weakness in some existing GNNs: the difficulty of neighborhood aggregation on heterophilic graphs, and the oversmoothing problem when stacking GNN layers. The proposed GPR-GNN can be viewed as an extension of the Personalized PageRank-based GNNs, such as APPNP and SGC, which also aimed to handle oversmoothing problem. Pros:  The paper highlights and clearly explains why optimizing the proposed layerwise GPR weights in GNN could tackle the two challenges. Although the final GPR-GNN architecture is simple, the ideas behind are significant. The paper is technically sound. The paper clearly analyzes the differences and relationships between related prior works and the proposed approach. In experiment, datasets are sufficient, including both homophilic and heterophilic graphs (both synthetic datasets and 10 real benchmarks are sufficient) which proves that GPR-GNN can achieve state-of-the-art performances especially on heterophilic graphs.","In this paper, the authors proposed a generalized pagerank version of a graph neural network (GNN). The authors learn a weighted combination of higher powers of the graph adjacency matrix, with the weights themselves being learnable. This allows their method to generalize existing GNN methods that work well when there's graph homophily, but not in the case of heterophily. The proposed method reduces to existing cases under certain weight settings, but in other cases, the learned weights allow for the GNN to act as a ""high pass filter"", which existing methods do not do. By learning these weights, the authors can also go deeper in the graph, and aggregate information from several hops away. Experiments on several standard datasets show that the proposed method outperforms multiple baselines. ",0.14935064935064934,0.1796875,0.1631205673758865
2843,SP:ffacc996034978d7851cf8fa7a0ea41f868c9354,"This paper extends the work of Hindsight Experience Replay to (goal-conditioned) policy gradient methods. Hindsight, which allows one to learn policies conditioned on some goal g, from off-policy experience generated by following goal g’, is cast in the framework of importance sampling. The authors show how one can simply rewrite the goal-conditioned policy gradient by first sampling a trajectory, conditioned on some goal $g’$ and then computing the closed form gradient in expectation over all goals. This gradient is unbiased if the rewards are off-policy corrected along the generated trajectories. While this naive formulation is found to be unstable , the authors propose a simple normalized importance sampling formulation which appears to work well in practice. To further reduce variance and computational costs, the authors also propose goal subsampling mechanisms, which sample goals which are likely along the generated trajectories. The method is evaluated on the same bit-flipping environment as [1], and a variety of discrete environments (grid worlds, Ms. Pac-Man, simulated robot arm) where the method appears highly effective. Unfortunately for reasons which remain unclear, hindsight policy gradients with value baselines appear unstable.","Following recent work on Hindsight Experience Replay (Andrychowicz et al. 2017), the authors extend the idea to policy gradient methods. They formally describe the goal-conditioned policy gradient setup and derive the extensions of the classical policy gradient estimators. Their key insight to deriving a computationally efficient estimator is that for many situations, only a small number of goals will be ""active"" in a single trajectory. Then, they conduct extensive experiments on a range of problems and show that their approach leads to improvements in sample efficiency for goal-conditioned tasks.",0.12698412698412698,0.26373626373626374,0.17142857142857143
2844,SP:fff4e3a93cc5acdc256c9d12c95d23d9ed458a85,"The paper proposes to set up experience replay such that transitions are emphasized based on whether the AN2N algorithm decides to explore more, and how recent the transition was experienced. It is based on observations that the state distribution can dramatically drift over the course of policy improvement, and the intuition that it might be better to perform updates on states that the current policy is more likely to actually visit (recent transitions). They apply the proposed sampling method, *experience replay more* (ERM), to a variety of replay-based deep RL algorithms and evaluate them empirically.","The paper proposes a new method (ERM) to bias the decision over which transitions should be replayed more often. In particular, using ERM, some states are deemed as key and they are replayed more often (following also a recency bias). This new method is then tested in 4 environments on the DeepMind control suite by using 3 different RL algorithms (DDPG, SAC, TD3). ",0.13541666666666666,0.20634920634920634,0.16352201257861632
