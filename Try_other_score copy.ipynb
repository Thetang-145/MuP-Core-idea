{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cats</th>\n",
       "      <td>0.933764</td>\n",
       "      <td>0.933764</td>\n",
       "      <td>0.933764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.891025</td>\n",
       "      <td>0.891025</td>\n",
       "      <td>0.891025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king</th>\n",
       "      <td>0.875994</td>\n",
       "      <td>0.875994</td>\n",
       "      <td>0.875994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>0.874707</td>\n",
       "      <td>0.874707</td>\n",
       "      <td>0.874707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.872291</td>\n",
       "      <td>0.872291</td>\n",
       "      <td>0.872291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sun</th>\n",
       "      <td>0.860979</td>\n",
       "      <td>0.860979</td>\n",
       "      <td>0.860979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pluto</th>\n",
       "      <td>0.809962</td>\n",
       "      <td>0.847728</td>\n",
       "      <td>0.828415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I ate dinner</th>\n",
       "      <td>0.825392</td>\n",
       "      <td>0.815105</td>\n",
       "      <td>0.820216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall        f1\n",
       "cat            1.000000  1.000000  1.000000\n",
       "cats           0.933764  0.933764  0.933764\n",
       "dog            0.891025  0.891025  0.891025\n",
       "king           0.875994  0.875994  0.875994\n",
       "man            0.874707  0.874707  0.874707\n",
       "love           0.872291  0.872291  0.872291\n",
       "sun            0.860979  0.860979  0.860979\n",
       "pluto          0.809962  0.847728  0.828415\n",
       "I ate dinner   0.825392  0.815105  0.820216"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\"cat\", 'cats', \"man\", \"love\", \"dog\", \"king\", \"pluto\", \"sun\", \"I ate dinner\"]\n",
    "# predictions = [\"I love you\", \"I hate you\", \"I really like you\", \"I will go with you\", \"I ate dinner\", \"Physics is very fun\", \"My name is John\", \"There are many dogs\"]\n",
    "references = [predictions[0]]*len(predictions)\n",
    "results = bertscore.compute(predictions=predictions, references=references, lang=\"en\", rescale_with_baseline=False)\n",
    "df_results = pd.DataFrame(results, index=predictions)\n",
    "df_results.drop(columns=[\"hashcode\"], inplace=True)\n",
    "df_results.sort_values(\"f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(results))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts = \"training\"\n",
    "# dts = \"validation\"\n",
    "path = 'MuP_dataset/'+dts+'_complete.jsonl'\n",
    "with open(path, 'r') as json_file:\n",
    "    json_list = list(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>This paper investigates kernel ridge-less regr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:b80bc890180934092cde037b49d94d6e4e06fad9</td>\n",
       "      <td>This paper presents a novel way of making full...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939</td>\n",
       "      <td>This paper proposes a new framework that compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:a1e2218e6943bf138aeb359e23628676b396ed66</td>\n",
       "      <td>This work proposes a deep reinforcement learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66</td>\n",
       "      <td>This paper proposes 3 deep generative models b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695</td>\n",
       "      <td>This paper presents a RNN-RL based method for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</td>\n",
       "      <td>This paper proposes a new pointwise convolutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</td>\n",
       "      <td>This paper presents a new pointwise convolutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>This paper proposes to model various uncertain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>The authors proposed a Bayesian graph neural n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18934 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       paper_id  \\\n",
       "0   SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc   \n",
       "0   SP:b80bc890180934092cde037b49d94d6e4e06fad9   \n",
       "0   SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939   \n",
       "0   SP:a1e2218e6943bf138aeb359e23628676b396ed66   \n",
       "0   SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66   \n",
       "..                                          ...   \n",
       "0   SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695   \n",
       "0   SP:4706017e6f8b958c7d0825fed98b285ea2994b59   \n",
       "0   SP:4706017e6f8b958c7d0825fed98b285ea2994b59   \n",
       "0   SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb   \n",
       "0   SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb   \n",
       "\n",
       "                                              summary  \n",
       "0   This paper investigates kernel ridge-less regr...  \n",
       "0   This paper presents a novel way of making full...  \n",
       "0   This paper proposes a new framework that compu...  \n",
       "0   This work proposes a deep reinforcement learni...  \n",
       "0   This paper proposes 3 deep generative models b...  \n",
       "..                                                ...  \n",
       "0   This paper presents a RNN-RL based method for ...  \n",
       "0   This paper proposes a new pointwise convolutio...  \n",
       "0   This paper presents a new pointwise convolutio...  \n",
       "0   This paper proposes to model various uncertain...  \n",
       "0   The authors proposed a Bayesian graph neural n...  \n",
       "\n",
       "[18934 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name = [\"paper_id\",\"summary\"]\n",
    "summary_df = pd.DataFrame(columns=col_name)\n",
    "for json_str in json_list:\n",
    "    result = json.loads(json_str)\n",
    "    df = pd.DataFrame([[result[\"paper_id\"], result[\"summary\"]]], columns=col_name)\n",
    "    summary_df = pd.concat([summary_df,df])\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_paper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_paper\n",
       "summary           \n",
       "1             2276\n",
       "2             2845\n",
       "3             2116\n",
       "4             1113\n",
       "5               10\n",
       "6               15\n",
       "7                4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_paper = summary_df.groupby(['paper_id']).count()\n",
    "num_paper['num_paper'] = 1\n",
    "num_paper.groupby(['summary']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SP:fff5b8e98a9909fb289cd1455d381df4b75f01fe</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:c258573dc59f202955f20e00f7682963aab0a1e6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:8fb2da71029fc4096f279c5873a2c55e8afaa947</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:348b7ab8ecfe2e7cfce697d8a1f9917880e95f62</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:34963abebc7bff45ac1b8fae499ceea8900c2852</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:f2325f97eb57b82ce95c86638af9d733d325b45d</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:ddc796b9185d372f4d0829f436bbca50c3990867</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:2cf4a3964537ff5dd1f7b600ab567b4d0b3cc03e</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:f202f3d6780876a0bdd7d7bd4d7047719a145177</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:b622788bec805621c2abf11ffa25c0d55e50f4d3</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8379 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary\n",
       "paper_id                                            \n",
       "SP:fff5b8e98a9909fb289cd1455d381df4b75f01fe        1\n",
       "SP:c258573dc59f202955f20e00f7682963aab0a1e6        1\n",
       "SP:8fb2da71029fc4096f279c5873a2c55e8afaa947        1\n",
       "SP:348b7ab8ecfe2e7cfce697d8a1f9917880e95f62        1\n",
       "SP:34963abebc7bff45ac1b8fae499ceea8900c2852        1\n",
       "...                                              ...\n",
       "SP:f2325f97eb57b82ce95c86638af9d733d325b45d        6\n",
       "SP:ddc796b9185d372f4d0829f436bbca50c3990867        7\n",
       "SP:2cf4a3964537ff5dd1f7b600ab567b4d0b3cc03e        7\n",
       "SP:f202f3d6780876a0bdd7d7bd4d7047719a145177        7\n",
       "SP:b622788bec805621c2abf11ffa25c0d55e50f4d3        7\n",
       "\n",
       "[8379 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_paper.drop('num_paper', inplace=True,axis=1)\n",
    "num_paper.sort_values([\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2276\n",
      "2845\n",
      "2116\n",
      "1113\n",
      "10\n",
      "15\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "list_paper_id = []\n",
    "for i in range(1, max(num_paper['summary'])+1):\n",
    "    list_paper_id.append(list((num_paper[num_paper[\"summary\"]==i]).index))\n",
    "for id in list_paper_id:\n",
    "    print(len(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:0007ee9ce7dfaf12a7dff4aa2979403aed9397d7</td>\n",
       "      <td>This paper proposed a novel benchmark for rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:0007ee9ce7dfaf12a7dff4aa2979403aed9397d7</td>\n",
       "      <td>The paper focuses on the relation extraction t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:001a31f7a439ab22943dedb4fa4d46e3dd56e603</td>\n",
       "      <td>This paper is an interesting exploratory study...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:001a31f7a439ab22943dedb4fa4d46e3dd56e603</td>\n",
       "      <td>This paper explores learning chess from raw no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:001e57e71bafdb52d6511bdd6aa73b78d60248f2</td>\n",
       "      <td>The manuscript considers the problem of imitat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:001e57e71bafdb52d6511bdd6aa73b78d60248f2</td>\n",
       "      <td>The paper proposes an imitation method, I2L, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:004f41dfc870c5a9b347d118d7e41d7c3db77b91</td>\n",
       "      <td>This paper uses pruning and model distillation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:004f41dfc870c5a9b347d118d7e41d7c3db77b91</td>\n",
       "      <td>This paper proposes a new framework which comb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:00578dd55a640c10dbf22f647b736e49f6ee3c32</td>\n",
       "      <td>The authors introduce CP-Flows, a way to param...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:00578dd55a640c10dbf22f647b736e49f6ee3c32</td>\n",
       "      <td>This paper proposes the flow based representat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:006c2334ad366e0c4558bcfccdd89f993fb8bba7</td>\n",
       "      <td>The paper proposes a method for exploiting str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:006c2334ad366e0c4558bcfccdd89f993fb8bba7</td>\n",
       "      <td>This paper proposes a method to learn locomoti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:00a3a2ca6324e5f2db45bbad11bf97491037c26c</td>\n",
       "      <td>The proposed method exploits the randomized sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:00a3a2ca6324e5f2db45bbad11bf97491037c26c</td>\n",
       "      <td>This paper present the first certifiable neura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:00af76b0f241598c5d3c11fc330d6426a1dcd473</td>\n",
       "      <td>The authors proposed graph deconvolution layer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:00af76b0f241598c5d3c11fc330d6426a1dcd473</td>\n",
       "      <td>The main contribution of this paper is that th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:00b48a43a5037915e21ddb2f0941cdd26a69d44d</td>\n",
       "      <td>In this paper, the authors propose a new metho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:00b48a43a5037915e21ddb2f0941cdd26a69d44d</td>\n",
       "      <td>This paper introduces Conditionally Reversible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:00e138bcd2ec3bc1fd4566af8434acf78e6f16be</td>\n",
       "      <td>To generate a sequence of high-level visual el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:00e138bcd2ec3bc1fd4566af8434acf78e6f16be</td>\n",
       "      <td>This paper presents an unsupervised method for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      paper_id  \\\n",
       "0  SP:0007ee9ce7dfaf12a7dff4aa2979403aed9397d7   \n",
       "0  SP:0007ee9ce7dfaf12a7dff4aa2979403aed9397d7   \n",
       "0  SP:001a31f7a439ab22943dedb4fa4d46e3dd56e603   \n",
       "0  SP:001a31f7a439ab22943dedb4fa4d46e3dd56e603   \n",
       "0  SP:001e57e71bafdb52d6511bdd6aa73b78d60248f2   \n",
       "0  SP:001e57e71bafdb52d6511bdd6aa73b78d60248f2   \n",
       "0  SP:004f41dfc870c5a9b347d118d7e41d7c3db77b91   \n",
       "0  SP:004f41dfc870c5a9b347d118d7e41d7c3db77b91   \n",
       "0  SP:00578dd55a640c10dbf22f647b736e49f6ee3c32   \n",
       "0  SP:00578dd55a640c10dbf22f647b736e49f6ee3c32   \n",
       "0  SP:006c2334ad366e0c4558bcfccdd89f993fb8bba7   \n",
       "0  SP:006c2334ad366e0c4558bcfccdd89f993fb8bba7   \n",
       "0  SP:00a3a2ca6324e5f2db45bbad11bf97491037c26c   \n",
       "0  SP:00a3a2ca6324e5f2db45bbad11bf97491037c26c   \n",
       "0  SP:00af76b0f241598c5d3c11fc330d6426a1dcd473   \n",
       "0  SP:00af76b0f241598c5d3c11fc330d6426a1dcd473   \n",
       "0  SP:00b48a43a5037915e21ddb2f0941cdd26a69d44d   \n",
       "0  SP:00b48a43a5037915e21ddb2f0941cdd26a69d44d   \n",
       "0  SP:00e138bcd2ec3bc1fd4566af8434acf78e6f16be   \n",
       "0  SP:00e138bcd2ec3bc1fd4566af8434acf78e6f16be   \n",
       "\n",
       "                                             summary  \n",
       "0  This paper proposed a novel benchmark for rela...  \n",
       "0  The paper focuses on the relation extraction t...  \n",
       "0  This paper is an interesting exploratory study...  \n",
       "0  This paper explores learning chess from raw no...  \n",
       "0  The manuscript considers the problem of imitat...  \n",
       "0  The paper proposes an imitation method, I2L, t...  \n",
       "0  This paper uses pruning and model distillation...  \n",
       "0  This paper proposes a new framework which comb...  \n",
       "0  The authors introduce CP-Flows, a way to param...  \n",
       "0  This paper proposes the flow based representat...  \n",
       "0  The paper proposes a method for exploiting str...  \n",
       "0  This paper proposes a method to learn locomoti...  \n",
       "0  The proposed method exploits the randomized sm...  \n",
       "0  This paper present the first certifiable neura...  \n",
       "0  The authors proposed graph deconvolution layer...  \n",
       "0  The main contribution of this paper is that th...  \n",
       "0  In this paper, the authors propose a new metho...  \n",
       "0  This paper introduces Conditionally Reversible...  \n",
       "0  To generate a sequence of high-level visual el...  \n",
       "0  This paper presents an unsupervised method for...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = []\n",
    "for i in range(len(list_paper_id)):\n",
    "    df_list.append(summary_df[summary_df.paper_id.isin(list_paper_id[i])].sort_values(\"paper_id\"))\n",
    "df_list[1][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_scores(n, score_col=[\"Bert\"]):\n",
    "    pairs = []\n",
    "    for i in range(n):\n",
    "        for j in range (i+1,n):\n",
    "            pairs.append(str(i+1)+\"-\"+str(j+1))\n",
    "    col = pd.MultiIndex.from_product([score_col, pairs])\n",
    "    scores = pd.DataFrame(columns=col)\n",
    "    scores.insert(0, \"paper_id\", list_paper_id[n-1])\n",
    "    scores.set_index(\"paper_id\", inplace=True)\n",
    "    return scores\n",
    "\n",
    "def bertscore_cal(n):\n",
    "    df_scores = n_scores(n, [\"Bert\"])\n",
    "    for num_id,id in enumerate(list_paper_id[n-1]):\n",
    "        sumaries = list(df_list[n-1][df_list[n-1][\"paper_id\"]==id][\"summary\"])\n",
    "        sys.stdout.write(\"\\r\" + str(num_id+1) + \"/\" + str(len(list_paper_id[n-1])))\n",
    "        sys.stdout.flush()\n",
    "        # print(id,\"/\",len(list_paper_id[n-1]), flush=True)\n",
    "        for i in range(n):\n",
    "            for j in range(i+1,n):\n",
    "                score = bertscore.compute(predictions=[sumaries[i]], references=[sumaries[j]], lang=\"en\")\n",
    "\n",
    "                pair = str(i+1)+\"-\"+str(j+1)\n",
    "                df_scores.loc[id]['Bert'][pair] = score['f1'][0]\n",
    "        #         print(score)\n",
    "        #         print(score['f1'][0])\n",
    "        #         break\n",
    "        #     break\n",
    "        # break\n",
    "    # df_score2\n",
    "    # len(list_paper_id)\n",
    "    print(\"\\n\")\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating ROUGE on 2 summaries\n",
      "2844/2845\n",
      "\n",
      "Calculating ROUGE on 3 summaries\n",
      "9/2116"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m,\u001b[39mlen\u001b[39m(list_paper_id)):\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCalculating ROUGE on\u001b[39m\u001b[39m\"\u001b[39m, n, \u001b[39m\"\u001b[39m\u001b[39msummaries\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     df_scores \u001b[39m=\u001b[39m bertscore_cal(n)\n\u001b[1;32m      4\u001b[0m     df_scores\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mvisualization_data/BertScore-between-sum/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mdts\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_bertscore_\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(n)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msum.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[39m# break\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m, in \u001b[0;36mbertscore_cal\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[1;32m     20\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,n):\n\u001b[0;32m---> 21\u001b[0m         score \u001b[39m=\u001b[39m bertscore\u001b[39m.\u001b[39;49mcompute(predictions\u001b[39m=\u001b[39;49m[sumaries[i]], references\u001b[39m=\u001b[39;49m[sumaries[j]], lang\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     23\u001b[0m         pair \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m         df_scores\u001b[39m.\u001b[39mloc[\u001b[39mid\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mBert\u001b[39m\u001b[39m'\u001b[39m][pair] \u001b[39m=\u001b[39m score[\u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/evaluate/module.py:444\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m inputs \u001b[39m=\u001b[39m {input_name: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[input_name] \u001b[39mfor\u001b[39;00m input_name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_feature_names()}\n\u001b[1;32m    443\u001b[0m \u001b[39mwith\u001b[39;00m temp_seed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseed):\n\u001b[0;32m--> 444\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcompute_kwargs)\n\u001b[1;32m    446\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_writer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_writer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--bertscore/cf4907b18f8f741f202232c0f8009a3bd49ff98802c245abcb6ea51a37a8c05b/bertscore.py:203\u001b[0m, in \u001b[0;36mBERTScore._compute\u001b[0;34m(self, predictions, references, lang, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcached_bertscorer\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_bertscorer\u001b[39m.\u001b[39mhash \u001b[39m!=\u001b[39m hashcode:\n\u001b[1;32m    189\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_bertscorer \u001b[39m=\u001b[39m scorer(\n\u001b[1;32m    190\u001b[0m             model_type\u001b[39m=\u001b[39mmodel_type,\n\u001b[1;32m    191\u001b[0m             num_layers\u001b[39m=\u001b[39mnum_layers,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m             baseline_path\u001b[39m=\u001b[39mbaseline_path,\n\u001b[1;32m    201\u001b[0m         )\n\u001b[0;32m--> 203\u001b[0m (P, R, F) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcached_bertscorer\u001b[39m.\u001b[39;49mscore(\n\u001b[1;32m    204\u001b[0m     cands\u001b[39m=\u001b[39;49mpredictions,\n\u001b[1;32m    205\u001b[0m     refs\u001b[39m=\u001b[39;49mreferences,\n\u001b[1;32m    206\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    207\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    208\u001b[0m )\n\u001b[1;32m    209\u001b[0m output_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m    210\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m\"\u001b[39m: P\u001b[39m.\u001b[39mtolist(),\n\u001b[1;32m    211\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m\"\u001b[39m: R\u001b[39m.\u001b[39mtolist(),\n\u001b[1;32m    212\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m\"\u001b[39m: F\u001b[39m.\u001b[39mtolist(),\n\u001b[1;32m    213\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhashcode\u001b[39m\u001b[39m\"\u001b[39m: hashcode,\n\u001b[1;32m    214\u001b[0m }\n\u001b[1;32m    215\u001b[0m \u001b[39mreturn\u001b[39;00m output_dict\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/bert_score/scorer.py:220\u001b[0m, in \u001b[0;36mBERTScorer.score\u001b[0;34m(self, cands, refs, verbose, batch_size, return_hash)\u001b[0m\n\u001b[1;32m    217\u001b[0m     idf_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokenizer\u001b[39m.\u001b[39msep_token_id] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    218\u001b[0m     idf_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokenizer\u001b[39m.\u001b[39mcls_token_id] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 220\u001b[0m all_preds \u001b[39m=\u001b[39m bert_cos_score_idf(\n\u001b[1;32m    221\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model,\n\u001b[1;32m    222\u001b[0m     refs,\n\u001b[1;32m    223\u001b[0m     cands,\n\u001b[1;32m    224\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokenizer,\n\u001b[1;32m    225\u001b[0m     idf_dict,\n\u001b[1;32m    226\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    227\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice,\n\u001b[1;32m    228\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    229\u001b[0m     all_layers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mall_layers,\n\u001b[1;32m    230\u001b[0m )\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m ref_group_boundaries \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     max_preds \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/bert_score/utils.py:616\u001b[0m, in \u001b[0;36mbert_cos_score_idf\u001b[0;34m(model, refs, hyps, tokenizer, idf_dict, verbose, batch_size, device, all_layers)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[39mfor\u001b[39;00m batch_start \u001b[39min\u001b[39;00m iter_range:\n\u001b[1;32m    615\u001b[0m     sen_batch \u001b[39m=\u001b[39m sentences[batch_start : batch_start \u001b[39m+\u001b[39m batch_size]\n\u001b[0;32m--> 616\u001b[0m     embs, masks, padded_idf \u001b[39m=\u001b[39m get_bert_embedding(\n\u001b[1;32m    617\u001b[0m         sen_batch, model, tokenizer, idf_dict, device\u001b[39m=\u001b[39;49mdevice, all_layers\u001b[39m=\u001b[39;49mall_layers\n\u001b[1;32m    618\u001b[0m     )\n\u001b[1;32m    619\u001b[0m     embs \u001b[39m=\u001b[39m embs\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m    620\u001b[0m     masks \u001b[39m=\u001b[39m masks\u001b[39m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/bert_score/utils.py:455\u001b[0m, in \u001b[0;36mget_bert_embedding\u001b[0;34m(all_sens, model, tokenizer, idf_dict, batch_size, device, all_layers)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    454\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(all_sens), batch_size):\n\u001b[0;32m--> 455\u001b[0m         batch_embedding \u001b[39m=\u001b[39m bert_encode(\n\u001b[1;32m    456\u001b[0m             model,\n\u001b[1;32m    457\u001b[0m             padded_sens[i : i \u001b[39m+\u001b[39;49m batch_size],\n\u001b[1;32m    458\u001b[0m             attention_mask\u001b[39m=\u001b[39;49mmask[i : i \u001b[39m+\u001b[39;49m batch_size],\n\u001b[1;32m    459\u001b[0m             all_layers\u001b[39m=\u001b[39;49mall_layers,\n\u001b[1;32m    460\u001b[0m         )\n\u001b[1;32m    461\u001b[0m         embeddings\u001b[39m.\u001b[39mappend(batch_embedding)\n\u001b[1;32m    462\u001b[0m         \u001b[39mdel\u001b[39;00m batch_embedding\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/bert_score/utils.py:351\u001b[0m, in \u001b[0;36mbert_encode\u001b[0;34m(model, x, attention_mask, all_layers)\u001b[0m\n\u001b[1;32m    349\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m    350\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 351\u001b[0m     out \u001b[39m=\u001b[39m model(x, attention_mask\u001b[39m=\u001b[39;49mattention_mask, output_hidden_states\u001b[39m=\u001b[39;49mall_layers)\n\u001b[1;32m    352\u001b[0m \u001b[39mif\u001b[39;00m all_layers:\n\u001b[1;32m    353\u001b[0m     emb \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(out[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:853\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    844\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    846\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    847\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    848\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    851\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    852\u001b[0m )\n\u001b[0;32m--> 853\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    854\u001b[0m     embedding_output,\n\u001b[1;32m    855\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    856\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    857\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    858\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    859\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    860\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    861\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    862\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    863\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    864\u001b[0m )\n\u001b[1;32m    865\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    866\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:527\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    518\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    519\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    520\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    525\u001b[0m     )\n\u001b[1;32m    526\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 527\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    528\u001b[0m         hidden_states,\n\u001b[1;32m    529\u001b[0m         attention_mask,\n\u001b[1;32m    530\u001b[0m         layer_head_mask,\n\u001b[1;32m    531\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    532\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    533\u001b[0m         past_key_value,\n\u001b[1;32m    534\u001b[0m         output_attentions,\n\u001b[1;32m    535\u001b[0m     )\n\u001b[1;32m    537\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    538\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:454\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    451\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    452\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 454\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    455\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    456\u001b[0m )\n\u001b[1;32m    457\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    459\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/transformers/pytorch_utils.py:246\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 246\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:466\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m--> 466\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[1;32m    467\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    468\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:364\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 364\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    365\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_vis/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for n in range(2,len(list_paper_id)):\n",
    "    print(\"Calculating BERTScore on\", n, \"summaries\")\n",
    "    df_scores = bertscore_cal(n)\n",
    "    df_scores.to_csv(\"visualization_data/BertScore-between-sum/\"+dts+\"_bertscore_\"+str(n)+\"sum.csv\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c41a15a33a59f0eeae9566b7a824606ae2e90e5c5eb8240ec6145ee367642a6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
